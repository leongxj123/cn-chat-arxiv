<rss version="2.0"><channel><title>Chat Arxiv cs.RO</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.RO</description><item><title>&#36890;&#36807;&#25552;&#20986;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#21452;&#25163;&#32534;&#25490;&#65288;LABOR&#65289;&#65292;&#26412;&#30740;&#31350;&#39318;&#27425;&#24212;&#23545;&#20102;&#22312;&#36830;&#32493;&#31354;&#38388;&#20013;&#36827;&#34892;&#21452;&#25163;&#20219;&#21153;&#21327;&#35843;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2404.02018</link><description>&lt;p&gt;
&#29992;&#20110;&#32534;&#25490;&#21452;&#25163;&#26426;&#22120;&#20154;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Large Language Models for Orchestrating Bimanual Robots
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02018
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25552;&#20986;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#21452;&#25163;&#32534;&#25490;&#65288;LABOR&#65289;&#65292;&#26412;&#30740;&#31350;&#39318;&#27425;&#24212;&#23545;&#20102;&#22312;&#36830;&#32493;&#31354;&#38388;&#20013;&#36827;&#34892;&#21452;&#25163;&#20219;&#21153;&#21327;&#35843;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#20351;&#26426;&#22120;&#20154;&#20855;&#26377;&#35299;&#20915;&#22797;&#26434;&#25805;&#32437;&#20219;&#21153;&#30340;&#33021;&#21147;&#24050;&#32463;&#21462;&#24471;&#20102;&#36805;&#36895;&#36827;&#23637;&#65292;&#20294;&#20026;&#21452;&#25163;&#26426;&#22120;&#20154;&#29983;&#25104;&#25511;&#21046;&#31574;&#30053;&#20197;&#35299;&#20915;&#28041;&#21450;&#20004;&#21482;&#25163;&#30340;&#20219;&#21153;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#21407;&#22240;&#26159;&#22312;&#26377;&#25928;&#30340;&#26102;&#38388;&#21644;&#31354;&#38388;&#21327;&#35843;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#12290;&#20855;&#26377;&#36880;&#27493;&#25512;&#29702;&#21644;&#32972;&#26223;&#23398;&#20064;&#33021;&#21147;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#24050;&#32463;&#25511;&#21046;&#20102;&#21508;&#31181;&#26426;&#22120;&#20154;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#36890;&#36807;&#21333;&#20010;&#31163;&#25955;&#31526;&#21495;&#24207;&#21015;&#36827;&#34892;&#35821;&#35328;&#20132;&#27969;&#30340;&#26412;&#36136;&#20351;&#24471;LLM&#22312;&#36830;&#32493;&#31354;&#38388;&#20013;&#36827;&#34892;&#21452;&#25163;&#20219;&#21153;&#21327;&#35843;&#25104;&#20026;&#19968;&#39033;&#29305;&#27530;&#25361;&#25112;&#12290;&#20026;&#20102;&#39318;&#27425;&#36890;&#36807;LLM&#24212;&#23545;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#21452;&#25163;&#32534;&#25490;&#65288;LABOR&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#21033;&#29992;LLM&#20998;&#26512;&#20219;&#21153;&#37197;&#32622;&#24182;&#35774;&#35745;&#21327;&#35843;&#25511;&#21046;&#31574;&#30053;&#20197;&#35299;&#20915;&#38271;&#26399;&#21452;&#25163;&#20219;&#21153;&#30340;&#20195;&#29702;&#12290;&#22312;&#27169;&#25311;&#29615;&#22659;&#20013;&#65292;LABOR&#20195;&#29702;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02018v1 Announce Type: cross  Abstract: Although there has been rapid progress in endowing robots with the ability to solve complex manipulation tasks, generating control policies for bimanual robots to solve tasks involving two hands is still challenging because of the difficulties in effective temporal and spatial coordination. With emergent abilities in terms of step-by-step reasoning and in-context learning, Large Language Models (LLMs) have taken control of a variety of robotic tasks. However, the nature of language communication via a single sequence of discrete symbols makes LLM-based coordination in continuous space a particular challenge for bimanual tasks. To tackle this challenge for the first time by an LLM, we present LAnguage-model-based Bimanual ORchestration (LABOR), an agent utilizing an LLM to analyze task configurations and devise coordination control policies for addressing long-horizon bimanual tasks. In the simulated environment, the LABOR agent is eval
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#20998;&#24067;&#24335;LLM&#21644;&#31526;&#21512;&#39044;&#27979;&#25216;&#26415;&#30340;&#22810;&#26426;&#22120;&#20154;&#35268;&#21010;&#22120;&#65292;&#23454;&#29616;&#20102;&#39640;&#20219;&#21153;&#25104;&#21151;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.15368</link><description>&lt;p&gt;
&#20351;&#29992;&#31526;&#21512;&#39044;&#27979;&#30340;&#25216;&#26415;&#23454;&#29616;&#35821;&#35328;&#25351;&#23548;&#22810;&#26426;&#22120;&#20154;&#31995;&#32479;&#30340;&#23433;&#20840;&#20219;&#21153;&#35268;&#21010;
&lt;/p&gt;
&lt;p&gt;
Safe Task Planning for Language-Instructed Multi-Robot Systems using Conformal Prediction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15368
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#20998;&#24067;&#24335;LLM&#21644;&#31526;&#21512;&#39044;&#27979;&#25216;&#26415;&#30340;&#22810;&#26426;&#22120;&#20154;&#35268;&#21010;&#22120;&#65292;&#23454;&#29616;&#20102;&#39640;&#20219;&#21153;&#25104;&#21151;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#35821;&#35328;&#25351;&#23548;&#26426;&#22120;&#20154;&#22242;&#38431;&#30340;&#20219;&#21153;&#35268;&#21010;&#38382;&#39064;&#12290;&#20219;&#21153;&#29992;&#33258;&#28982;&#35821;&#35328;&#65288;NL&#65289;&#34920;&#31034;&#65292;&#35201;&#27714;&#26426;&#22120;&#20154;&#22312;&#21508;&#31181;&#20301;&#32622;&#21644;&#35821;&#20041;&#23545;&#35937;&#19978;&#24212;&#29992;&#23427;&#20204;&#30340;&#33021;&#21147;&#65288;&#20363;&#22914;&#31227;&#21160;&#12289;&#25805;&#20316;&#21644;&#24863;&#30693;&#65289;&#12290;&#26368;&#36817;&#20960;&#31687;&#35770;&#25991;&#36890;&#36807;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#35774;&#35745;&#26377;&#25928;&#30340;&#22810;&#26426;&#22120;&#20154;&#35745;&#21010;&#26469;&#35299;&#20915;&#31867;&#20284;&#30340;&#35268;&#21010;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#32570;&#20047;&#20219;&#21153;&#24615;&#33021;&#21644;&#23433;&#20840;&#24615;&#20445;&#35777;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#20998;&#24067;&#24335;LLM&#30340;&#35268;&#21010;&#22120;&#65292;&#33021;&#22815;&#23454;&#29616;&#39640;&#20219;&#21153;&#25104;&#21151;&#29575;&#12290;&#36825;&#26159;&#36890;&#36807;&#21033;&#29992;&#31526;&#21512;&#39044;&#27979;&#65288;CP&#65289;&#26469;&#23454;&#29616;&#30340;&#65292;CP&#26159;&#19968;&#31181;&#22522;&#20110;&#20998;&#24067;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#24037;&#20855;&#65292;&#21487;&#20197;&#22312;&#40657;&#30418;&#27169;&#22411;&#20013;&#23545;&#20854;&#22266;&#26377;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#25512;&#29702;&#12290;CP&#20801;&#35768;&#25152;&#25552;&#20986;&#30340;&#22810;&#26426;&#22120;&#20154;&#35268;&#21010;&#22120;&#20197;&#20998;&#24067;&#26041;&#24335;&#25512;&#29702;&#20854;&#22266;&#26377;&#19981;&#30830;&#23450;&#24615;&#65292;&#20351;&#24471;&#26426;&#22120;&#20154;&#22312;&#20805;&#20998;&#20449;&#20219;&#26102;&#33021;&#22815;&#20570;&#20986;&#20010;&#21035;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15368v1 Announce Type: cross  Abstract: This paper addresses task planning problems for language-instructed robot teams. Tasks are expressed in natural language (NL), requiring the robots to apply their capabilities (e.g., mobility, manipulation, and sensing) at various locations and semantic objects. Several recent works have addressed similar planning problems by leveraging pre-trained Large Language Models (LLMs) to design effective multi-robot plans. However, these approaches lack mission performance and safety guarantees. To address this challenge, we introduce a new decentralized LLM-based planner that is capable of achieving high mission success rates. This is accomplished by leveraging conformal prediction (CP), a distribution-free uncertainty quantification tool in black-box models. CP allows the proposed multi-robot planner to reason about its inherent uncertainty in a decentralized fashion, enabling robots to make individual decisions when they are sufficiently ce
&lt;/p&gt;</description></item></channel></rss>