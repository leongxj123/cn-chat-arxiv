<rss version="2.0"><channel><title>Chat Arxiv cs.RO</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.RO</description><item><title>&#22312;&#22522;&#20110;&#35270;&#35273;&#30340;&#33258;&#20027;&#26080;&#20154;&#26426;&#31454;&#36895;&#20013;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#23558;&#24378;&#21270;&#23398;&#20064;&#21644;&#27169;&#20223;&#23398;&#20064;&#30456;&#32467;&#21512;&#30340;&#26032;&#22411;&#35757;&#32451;&#26694;&#26550;&#65292;&#20197;&#20811;&#26381;&#26679;&#26412;&#25928;&#29575;&#21644;&#35745;&#31639;&#38656;&#27714;&#26041;&#38754;&#30340;&#25361;&#25112;&#65292;&#24182;&#36890;&#36807;&#19977;&#20010;&#38454;&#27573;&#30340;&#26041;&#27861;&#36827;&#34892;&#24615;&#33021;&#21463;&#38480;&#30340;&#33258;&#36866;&#24212;RL&#24494;&#35843;</title><link>https://arxiv.org/abs/2403.12203</link><description>&lt;p&gt;
&#22522;&#20110;&#27169;&#20223;&#30340;&#22686;&#24378;&#23398;&#20064;&#20026;&#22522;&#20110;&#35270;&#35273;&#30340;&#25935;&#25463;&#39134;&#34892;&#24341;&#23548;&#24341;&#23548;
&lt;/p&gt;
&lt;p&gt;
Bootstrapping Reinforcement Learning with Imitation for Vision-Based Agile Flight
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12203
&lt;/p&gt;
&lt;p&gt;
&#22312;&#22522;&#20110;&#35270;&#35273;&#30340;&#33258;&#20027;&#26080;&#20154;&#26426;&#31454;&#36895;&#20013;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#23558;&#24378;&#21270;&#23398;&#20064;&#21644;&#27169;&#20223;&#23398;&#20064;&#30456;&#32467;&#21512;&#30340;&#26032;&#22411;&#35757;&#32451;&#26694;&#26550;&#65292;&#20197;&#20811;&#26381;&#26679;&#26412;&#25928;&#29575;&#21644;&#35745;&#31639;&#38656;&#27714;&#26041;&#38754;&#30340;&#25361;&#25112;&#65292;&#24182;&#36890;&#36807;&#19977;&#20010;&#38454;&#27573;&#30340;&#26041;&#27861;&#36827;&#34892;&#24615;&#33021;&#21463;&#38480;&#30340;&#33258;&#36866;&#24212;RL&#24494;&#35843;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#22522;&#20110;&#35270;&#35273;&#30340;&#33258;&#20027;&#26080;&#20154;&#26426;&#31454;&#36895;&#30340;&#32972;&#26223;&#19979;&#65292;&#23558;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#30340;&#26377;&#25928;&#24615;&#21644;&#27169;&#20223;&#23398;&#20064;&#65288;IL&#65289;&#30340;&#25928;&#29575;&#32467;&#21512;&#22312;&#19968;&#36215;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#30452;&#25509;&#22788;&#29702;&#35270;&#35273;&#36755;&#20837;&#65292;&#32780;&#26080;&#38656;&#26126;&#30830;&#30340;&#29366;&#24577;&#20272;&#35745;&#12290;&#34429;&#28982;&#24378;&#21270;&#23398;&#20064;&#36890;&#36807;&#35797;&#38169;&#25552;&#20379;&#20102;&#19968;&#20010;&#23398;&#20064;&#22797;&#26434;&#25511;&#21046;&#22120;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#20294;&#38754;&#20020;&#30528;&#26679;&#26412;&#25928;&#29575;&#21644;&#35745;&#31639;&#38656;&#27714;&#30340;&#25361;&#25112;&#65292;&#22240;&#20026;&#35270;&#35273;&#36755;&#20837;&#30340;&#32500;&#24230;&#36739;&#39640;&#12290;&#30456;&#21453;&#65292;IL&#22312;&#20174;&#35270;&#35273;&#28436;&#31034;&#20013;&#23398;&#20064;&#26041;&#38754;&#34920;&#29616;&#20986;&#25928;&#29575;&#65292;&#20294;&#21463;&#21040;&#28436;&#31034;&#36136;&#37327;&#30340;&#38480;&#21046;&#65292;&#24182;&#38754;&#20020;&#35832;&#22914;&#21327;&#21464;&#37327;&#28418;&#31227;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32467;&#21512;RL&#21644;IL&#20248;&#21183;&#30340;&#26032;&#22411;&#35757;&#32451;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21253;&#25324;&#19977;&#20010;&#38454;&#27573;&#65306;&#20351;&#29992;&#29305;&#26435;&#29366;&#24577;&#20449;&#24687;&#30340;&#24072;&#20613;&#31574;&#30053;&#30340;&#21021;&#22987;&#35757;&#32451;&#65292;&#20351;&#29992;IL&#23558;&#27492;&#31574;&#30053;&#33976;&#39311;&#20026;&#23398;&#29983;&#31574;&#30053;&#65292;&#20197;&#21450;&#24615;&#33021;&#21463;&#38480;&#30340;&#33258;&#36866;&#24212;RL&#24494;&#35843;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12203v1 Announce Type: cross  Abstract: We combine the effectiveness of Reinforcement Learning (RL) and the efficiency of Imitation Learning (IL) in the context of vision-based, autonomous drone racing. We focus on directly processing visual input without explicit state estimation. While RL offers a general framework for learning complex controllers through trial and error, it faces challenges regarding sample efficiency and computational demands due to the high dimensionality of visual inputs. Conversely, IL demonstrates efficiency in learning from visual demonstrations but is limited by the quality of those demonstrations and faces issues like covariate shift. To overcome these limitations, we propose a novel training framework combining RL and IL's advantages. Our framework involves three stages: initial training of a teacher policy using privileged state information, distilling this policy into a student policy using IL, and performance-constrained adaptive RL fine-tunin
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#30740;&#31350;&#22312;&#21160;&#24577;&#35268;&#21010;&#39046;&#22495;&#20013;&#27169;&#25311;&#24037;&#20855;&#20351;&#29992;&#30340;&#30446;&#26631;&#65292;&#25105;&#20204;&#28145;&#20837;&#25506;&#35752;&#20102;&#20027;&#21160;&#25512;&#26029;&#20013;&#30340;&#21160;&#24577;&#35268;&#21010;&#65292;&#35813;&#39046;&#22495;&#32771;&#34385;&#21040;&#29983;&#29289;&#30446;&#26631;&#23548;&#21521;&#34892;&#20026;&#30340;&#20004;&#20010;&#20851;&#38190;&#26041;&#38754;</title><link>https://arxiv.org/abs/2402.11658</link><description>&lt;p&gt;
&#20998;&#23618;&#20027;&#21160;&#25512;&#26029;&#20013;&#30340;&#21160;&#24577;&#35268;&#21010;
&lt;/p&gt;
&lt;p&gt;
Dynamic planning in hierarchical active inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11658
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#30740;&#31350;&#22312;&#21160;&#24577;&#35268;&#21010;&#39046;&#22495;&#20013;&#27169;&#25311;&#24037;&#20855;&#20351;&#29992;&#30340;&#30446;&#26631;&#65292;&#25105;&#20204;&#28145;&#20837;&#25506;&#35752;&#20102;&#20027;&#21160;&#25512;&#26029;&#20013;&#30340;&#21160;&#24577;&#35268;&#21010;&#65292;&#35813;&#39046;&#22495;&#32771;&#34385;&#21040;&#29983;&#29289;&#30446;&#26631;&#23548;&#21521;&#34892;&#20026;&#30340;&#20004;&#20010;&#20851;&#38190;&#26041;&#38754;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#21160;&#24577;&#35268;&#21010;&#65292;&#25105;&#20204;&#25351;&#30340;&#26159;&#20154;&#31867;&#22823;&#33041;&#25512;&#26029;&#21644;&#26045;&#21152;&#19982;&#35748;&#30693;&#20915;&#31574;&#30456;&#20851;&#30340;&#36816;&#21160;&#36712;&#36857;&#30340;&#33021;&#21147;&#12290;&#26368;&#36817;&#30340;&#19968;&#20010;&#33539;&#24335;&#65292;&#20027;&#21160;&#25512;&#26029;&#65292;&#20026;&#29983;&#29289;&#26377;&#26426;&#20307;&#36866;&#24212;&#24102;&#26469;&#20102;&#22522;&#26412;&#35265;&#35299;&#65292;&#19981;&#26029;&#21162;&#21147;&#26368;&#23567;&#21270;&#39044;&#27979;&#35823;&#24046;&#20197;&#23558;&#33258;&#24049;&#38480;&#21046;&#22312;&#19982;&#29983;&#21629;&#20860;&#23481;&#30340;&#29366;&#24577;&#12290;&#22312;&#36807;&#21435;&#30340;&#20960;&#24180;&#37324;&#65292;&#35768;&#22810;&#30740;&#31350;&#34920;&#26126;&#20154;&#31867;&#21644;&#21160;&#29289;&#34892;&#20026;&#21487;&#20197;&#35299;&#37322;&#20026;&#20027;&#21160;&#25512;&#26029;&#36807;&#31243;&#65292;&#26080;&#35770;&#26159;&#20316;&#20026;&#31163;&#25955;&#20915;&#31574;&#36824;&#26159;&#36830;&#32493;&#36816;&#21160;&#25511;&#21046;&#65292;&#37117;&#28608;&#21457;&#20102;&#26426;&#22120;&#20154;&#25216;&#26415;&#21644;&#20154;&#24037;&#26234;&#33021;&#20013;&#30340;&#21019;&#26032;&#35299;&#20915;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#25991;&#29486;&#32570;&#20047;&#23545;&#22914;&#20309;&#26377;&#25928;&#22320;&#22312;&#21464;&#21270;&#29615;&#22659;&#20013;&#35268;&#21010;&#34892;&#21160;&#30340;&#20840;&#38754;&#23637;&#26395;&#12290;&#25105;&#20204;&#35774;&#23450;&#20102;&#23545;&#24037;&#20855;&#20351;&#29992;&#36827;&#34892;&#24314;&#27169;&#30340;&#30446;&#26631;&#65292;&#28145;&#20837;&#30740;&#31350;&#20102;&#20027;&#21160;&#25512;&#26029;&#20013;&#30340;&#21160;&#24577;&#35268;&#21010;&#20027;&#39064;&#65292;&#29282;&#35760;&#20004;&#20010;&#29983;&#29289;&#30446;&#26631;&#23548;&#21521;&#34892;&#20026;&#30340;&#20851;&#38190;&#26041;&#38754;&#65306;&#29702;&#35299;&#8230;&#8230;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11658v1 Announce Type: new  Abstract: By dynamic planning, we refer to the ability of the human brain to infer and impose motor trajectories related to cognitive decisions. A recent paradigm, active inference, brings fundamental insights into the adaptation of biological organisms, constantly striving to minimize prediction errors to restrict themselves to life-compatible states. Over the past years, many studies have shown how human and animal behavior could be explained in terms of an active inferential process -- either as discrete decision-making or continuous motor control -- inspiring innovative solutions in robotics and artificial intelligence. Still, the literature lacks a comprehensive outlook on how to effectively plan actions in changing environments. Setting ourselves the goal of modeling tool use, we delve into the topic of dynamic planning in active inference, keeping in mind two crucial aspects of biological goal-directed behavior: the capacity to understand a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;Agent&#21160;&#24577;&#20851;&#31995;&#25512;&#29702;&#26041;&#27861;&#65292;&#36890;&#36807;&#26126;&#30830;&#25512;&#26029;&#20851;&#31995;&#32467;&#26500;&#30340;&#28436;&#21270;&#65292;&#26469;&#23454;&#29616;&#22312;&#31038;&#20132;&#26426;&#22120;&#20154;&#23548;&#33322;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;&#26041;&#27861;&#21253;&#25324;&#25512;&#26029;&#36229;&#36793;&#32536;&#20197;&#23454;&#29616;&#32676;&#20307;&#25512;&#29702;&#21644;&#36712;&#36857;&#39044;&#27979;&#22120;&#29983;&#25104;&#26410;&#26469;&#29366;&#24577;&#12290;</title><link>http://arxiv.org/abs/2401.12275</link><description>&lt;p&gt;
&#22810;Agent&#21160;&#24577;&#20851;&#31995;&#25512;&#29702;&#29992;&#20110;&#31038;&#20132;&#26426;&#22120;&#20154;&#23548;&#33322;
&lt;/p&gt;
&lt;p&gt;
Multi-Agent Dynamic Relational Reasoning for Social Robot Navigation. (arXiv:2401.12275v1 [cs.RO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12275
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;Agent&#21160;&#24577;&#20851;&#31995;&#25512;&#29702;&#26041;&#27861;&#65292;&#36890;&#36807;&#26126;&#30830;&#25512;&#26029;&#20851;&#31995;&#32467;&#26500;&#30340;&#28436;&#21270;&#65292;&#26469;&#23454;&#29616;&#22312;&#31038;&#20132;&#26426;&#22120;&#20154;&#23548;&#33322;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;&#26041;&#27861;&#21253;&#25324;&#25512;&#26029;&#36229;&#36793;&#32536;&#20197;&#23454;&#29616;&#32676;&#20307;&#25512;&#29702;&#21644;&#36712;&#36857;&#39044;&#27979;&#22120;&#29983;&#25104;&#26410;&#26469;&#29366;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#20132;&#26426;&#22120;&#20154;&#23548;&#33322;&#22312;&#26085;&#24120;&#29983;&#27963;&#30340;&#21508;&#31181;&#24773;&#26223;&#19979;&#21487;&#20197;&#25552;&#20379;&#24110;&#21161;&#65292;&#20294;&#38656;&#35201;&#23433;&#20840;&#30340;&#20154;&#26426;&#20132;&#20114;&#21644;&#39640;&#25928;&#30340;&#36712;&#36857;&#35268;&#21010;&#12290;&#22312;&#22810;Agent&#20132;&#20114;&#31995;&#32479;&#20013;&#65292;&#24314;&#27169;&#25104;&#23545;&#30340;&#20851;&#31995;&#24050;&#32463;&#34987;&#24191;&#27867;&#30740;&#31350;&#65292;&#20294;&#26159;&#25429;&#25417;&#26356;&#22823;&#35268;&#27169;&#30340;&#32676;&#20307;&#27963;&#21160;&#30340;&#33021;&#21147;&#26377;&#38480;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31995;&#32479;&#30340;&#20851;&#31995;&#25512;&#29702;&#26041;&#27861;&#65292;&#36890;&#36807;&#26126;&#30830;&#25512;&#26029;&#27491;&#22312;&#28436;&#21464;&#30340;&#20851;&#31995;&#32467;&#26500;&#65292;&#23637;&#31034;&#20102;&#20854;&#22312;&#22810;Agent&#36712;&#36857;&#39044;&#27979;&#21644;&#31038;&#20132;&#26426;&#22120;&#20154;&#23548;&#33322;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;&#38500;&#20102;&#33410;&#28857;&#23545;&#20043;&#38388;&#30340;&#36793;&#32536;&#65288;&#21363;Agent&#65289;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#25512;&#26029;&#36229;&#36793;&#32536;&#30340;&#26041;&#27861;&#65292;&#20197;&#33258;&#36866;&#24212;&#22320;&#36830;&#25509;&#22810;&#20010;&#33410;&#28857;&#65292;&#20197;&#20415;&#36827;&#34892;&#32676;&#20307;&#25512;&#29702;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#25512;&#26029;&#21160;&#24577;&#28436;&#21270;&#30340;&#20851;&#31995;&#22270;&#21644;&#36229;&#22270;&#65292;&#20197;&#25429;&#25417;&#20851;&#31995;&#30340;&#28436;&#21270;&#65292;&#36712;&#36857;&#39044;&#27979;&#22120;&#21033;&#29992;&#36825;&#20123;&#22270;&#26469;&#29983;&#25104;&#26410;&#26469;&#29366;&#24577;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#38160;&#24230;&#21644;&#36923;&#36753;&#31232;&#30095;&#24615;&#36827;&#34892;&#27491;&#21017;&#21270;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Social robot navigation can be helpful in various contexts of daily life but requires safe human-robot interactions and efficient trajectory planning. While modeling pairwise relations has been widely studied in multi-agent interacting systems, the ability to capture larger-scale group-wise activities is limited. In this paper, we propose a systematic relational reasoning approach with explicit inference of the underlying dynamically evolving relational structures, and we demonstrate its effectiveness for multi-agent trajectory prediction and social robot navigation. In addition to the edges between pairs of nodes (i.e., agents), we propose to infer hyperedges that adaptively connect multiple nodes to enable group-wise reasoning in an unsupervised manner. Our approach infers dynamically evolving relation graphs and hypergraphs to capture the evolution of relations, which the trajectory predictor employs to generate future states. Meanwhile, we propose to regularize the sharpness and sp
&lt;/p&gt;</description></item></channel></rss>