<rss version="2.0"><channel><title>Chat Arxiv cs.RO</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.RO</description><item><title>FRAC-Q-Learning&#26159;&#19968;&#31181;&#19987;&#20026;&#31038;&#20132;&#26426;&#22120;&#20154;&#35774;&#35745;&#65292;&#33021;&#36991;&#20813;&#29992;&#25143;&#21388;&#28902;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#27604;&#20256;&#32479;&#31639;&#27861;&#22312;&#20852;&#36259;&#21644;&#21388;&#28902;&#31243;&#24230;&#19978;&#34920;&#29616;&#26356;&#22909;&#65292;&#26377;&#21161;&#20110;&#24320;&#21457;&#19981;&#20250;&#35753;&#29992;&#25143;&#24863;&#21040;&#26080;&#32842;&#30340;&#31038;&#20132;&#26426;&#22120;&#20154;&#12290;</title><link>https://arxiv.org/abs/2311.15327</link><description>&lt;p&gt;
FRAC-Q-Learning: &#19968;&#31181;&#20855;&#26377;&#36991;&#20813;&#21388;&#28902;&#36807;&#31243;&#30340;&#31038;&#20132;&#26426;&#22120;&#20154;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
FRAC-Q-Learning: A Reinforcement Learning with Boredom Avoidance Processes for Social Robots
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.15327
&lt;/p&gt;
&lt;p&gt;
FRAC-Q-Learning&#26159;&#19968;&#31181;&#19987;&#20026;&#31038;&#20132;&#26426;&#22120;&#20154;&#35774;&#35745;&#65292;&#33021;&#36991;&#20813;&#29992;&#25143;&#21388;&#28902;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#27604;&#20256;&#32479;&#31639;&#27861;&#22312;&#20852;&#36259;&#21644;&#21388;&#28902;&#31243;&#24230;&#19978;&#34920;&#29616;&#26356;&#22909;&#65292;&#26377;&#21161;&#20110;&#24320;&#21457;&#19981;&#20250;&#35753;&#29992;&#25143;&#24863;&#21040;&#26080;&#32842;&#30340;&#31038;&#20132;&#26426;&#22120;&#20154;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#32463;&#24120;&#34987;&#24212;&#29992;&#20110;&#31038;&#20132;&#26426;&#22120;&#20154;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#24182;&#26410;&#38024;&#23545;&#31038;&#20132;&#26426;&#22120;&#20154;&#36827;&#34892;&#20248;&#21270;&#65292;&#22240;&#27492;&#21487;&#33021;&#20250;&#35753;&#29992;&#25143;&#24863;&#21040;&#26080;&#32842;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#19987;&#20026;&#31038;&#20132;&#26426;&#22120;&#20154;&#35774;&#35745;&#30340;&#26032;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;FRAC-Q-Learning&#65292;&#21487;&#20197;&#36991;&#20813;&#29992;&#25143;&#24863;&#21040;&#26080;&#32842;&#12290;&#35813;&#31639;&#27861;&#38500;&#20102;&#38543;&#26426;&#21270;&#21644;&#20998;&#31867;&#36807;&#31243;&#22806;&#65292;&#36824;&#21253;&#25324;&#19968;&#20010;&#36951;&#24536;&#36807;&#31243;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#19982;&#20256;&#32479;Q-Learning&#30340;&#27604;&#36739;&#35780;&#20272;&#20102;FRAC-Q-Learning&#30340;&#20852;&#36259;&#21644;&#21388;&#28902;&#31243;&#24230;&#20998;&#25968;&#12290;FRAC-Q-Learning&#26174;&#31034;&#20986;&#26126;&#26174;&#26356;&#39640;&#30340;&#20852;&#36259;&#20998;&#25968;&#36235;&#21183;&#65292;&#24182;&#19988;&#30456;&#36739;&#20110;&#20256;&#32479;Q-Learning&#26356;&#38590;&#35753;&#29992;&#25143;&#24863;&#21040;&#26080;&#32842;&#12290;&#22240;&#27492;&#65292;FRAC-Q-Learning&#26377;&#21161;&#20110;&#24320;&#21457;&#19981;&#20250;&#35753;&#29992;&#25143;&#24863;&#21040;&#26080;&#32842;&#30340;&#31038;&#20132;&#26426;&#22120;&#20154;&#12290;&#35813;&#31639;&#27861;&#36824;&#21487;&#20197;&#22312;&#22522;&#20110;Web&#30340;&#36890;&#20449;&#21644;&#25945;&#32946;&#20013;&#25214;&#21040;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.15327v3 Announce Type: replace-cross  Abstract: The reinforcement learning algorithms have often been applied to social robots. However, most reinforcement learning algorithms were not optimized for the use of social robots, and consequently they may bore users. We proposed a new reinforcement learning method specialized for the social robot, the FRAC-Q-learning, that can avoid user boredom. The proposed algorithm consists of a forgetting process in addition to randomizing and categorizing processes. This study evaluated interest and boredom hardness scores of the FRAC-Q-learning by a comparison with the traditional Q-learning. The FRAC-Q-learning showed significantly higher trend of interest score, and indicated significantly harder to bore users compared to the traditional Q-learning. Therefore, the FRAC-Q-learning can contribute to develop a social robot that will not bore users. The proposed algorithm can also find applications in Web-based communication and educational 
&lt;/p&gt;</description></item></channel></rss>