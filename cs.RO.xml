<rss version="2.0"><channel><title>Chat Arxiv cs.RO</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.RO</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22312;&#28151;&#20081;&#29615;&#22659;&#20013;&#25235;&#21462;&#24050;&#37319;&#25688;&#30340;&#35199;&#32418;&#26623;&#31319;&#26524;&#30340;&#35270;&#35273;&#24341;&#23548;&#26426;&#22120;&#20154;&#31995;&#32479;&#12290;&#35813;&#31995;&#32479;&#21033;&#29992;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#35270;&#35273;&#31995;&#32479;&#26469;&#35782;&#21035;&#31319;&#26524;&#24182;&#30830;&#23450;&#36866;&#21512;&#25235;&#21462;&#30340;&#20301;&#32622;&#65292;&#36890;&#36807;&#22312;&#32447;&#23398;&#20064;&#26469;&#25490;&#24207;&#25235;&#21462;&#23039;&#21183;&#65292;&#24182;&#23454;&#29616;&#26080;&#35302;&#35273;&#20256;&#24863;&#22120;&#25110;&#20960;&#20309;&#27169;&#22411;&#30340;&#22841;&#25345;&#25235;&#21462;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#35813;&#31995;&#32479;&#20855;&#26377;100%&#30340;&#28165;&#29702;&#29575;&#21644;93%&#30340;&#19968;&#27425;&#24615;&#25104;&#21151;&#25235;&#21462;&#29575;&#12290;</title><link>http://arxiv.org/abs/2309.17170</link><description>&lt;p&gt;
&#29992;&#20110;&#22312;&#28151;&#20081;&#29615;&#22659;&#20013;&#25235;&#21462;&#24050;&#37319;&#25688;&#30340;&#35199;&#32418;&#26623;&#31319;&#26524;&#30340;&#35270;&#35273;&#24341;&#23548;&#26426;&#22120;&#20154;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
A Vision-Guided Robotic System for Grasping Harvested Tomato Trusses in Cluttered Environments. (arXiv:2309.17170v1 [cs.RO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.17170
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22312;&#28151;&#20081;&#29615;&#22659;&#20013;&#25235;&#21462;&#24050;&#37319;&#25688;&#30340;&#35199;&#32418;&#26623;&#31319;&#26524;&#30340;&#35270;&#35273;&#24341;&#23548;&#26426;&#22120;&#20154;&#31995;&#32479;&#12290;&#35813;&#31995;&#32479;&#21033;&#29992;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#35270;&#35273;&#31995;&#32479;&#26469;&#35782;&#21035;&#31319;&#26524;&#24182;&#30830;&#23450;&#36866;&#21512;&#25235;&#21462;&#30340;&#20301;&#32622;&#65292;&#36890;&#36807;&#22312;&#32447;&#23398;&#20064;&#26469;&#25490;&#24207;&#25235;&#21462;&#23039;&#21183;&#65292;&#24182;&#23454;&#29616;&#26080;&#35302;&#35273;&#20256;&#24863;&#22120;&#25110;&#20960;&#20309;&#27169;&#22411;&#30340;&#22841;&#25345;&#25235;&#21462;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#35813;&#31995;&#32479;&#20855;&#26377;100%&#30340;&#28165;&#29702;&#29575;&#21644;93%&#30340;&#19968;&#27425;&#24615;&#25104;&#21151;&#25235;&#21462;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#65292;&#23545;&#20110;&#35199;&#32418;&#26623;&#30340;&#31216;&#37325;&#21644;&#21253;&#35013;&#38656;&#35201;&#22823;&#37327;&#30340;&#20154;&#24037;&#25805;&#20316;&#12290;&#33258;&#21160;&#21270;&#30340;&#20027;&#35201;&#38556;&#30861;&#22312;&#20110;&#24320;&#21457;&#19968;&#20010;&#21487;&#38752;&#30340;&#29992;&#20110;&#24050;&#37319;&#25688;&#30340;&#31319;&#26524;&#30340;&#26426;&#22120;&#20154;&#25235;&#21462;&#31995;&#32479;&#30340;&#22256;&#38590;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#25235;&#21462;&#22534;&#25918;&#22312;&#35013;&#31665;&#20013;&#30340;&#31319;&#26524;&#65292;&#36825;&#26159;&#23427;&#20204;&#22312;&#37319;&#25688;&#21518;&#24120;&#35265;&#30340;&#23384;&#20648;&#21644;&#36816;&#36755;&#26041;&#24335;&#12290;&#35813;&#26041;&#27861;&#21253;&#25324;&#19968;&#20010;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#35270;&#35273;&#31995;&#32479;&#65292;&#39318;&#20808;&#35782;&#21035;&#20986;&#35013;&#31665;&#20013;&#30340;&#21333;&#20010;&#31319;&#26524;&#65292;&#28982;&#21518;&#30830;&#23450;&#33550;&#37096;&#30340;&#36866;&#21512;&#25235;&#21462;&#30340;&#20301;&#32622;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#20855;&#26377;&#22312;&#32447;&#23398;&#20064;&#33021;&#21147;&#30340;&#25235;&#21462;&#23039;&#21183;&#25490;&#24207;&#31639;&#27861;&#12290;&#22312;&#36873;&#25321;&#20102;&#26368;&#26377;&#21069;&#26223;&#30340;&#25235;&#21462;&#23039;&#21183;&#20043;&#21518;&#65292;&#26426;&#22120;&#20154;&#25191;&#34892;&#19968;&#31181;&#26080;&#38656;&#35302;&#35273;&#20256;&#24863;&#22120;&#25110;&#20960;&#20309;&#27169;&#22411;&#30340;&#22841;&#25345;&#25235;&#21462;&#12290;&#23454;&#39564;&#23460;&#23454;&#39564;&#35777;&#26126;&#65292;&#37197;&#22791;&#20102;&#19968;&#20010;&#25163;&#30524;&#19968;&#20307;&#30340;RGB-D&#30456;&#26426;&#30340;&#26426;&#22120;&#20154;&#25805;&#32437;&#22120;&#20174;&#22534;&#20013;&#25441;&#36215;&#25152;&#26377;&#30340;&#31319;&#26524;&#30340;&#28165;&#29702;&#29575;&#36798;&#21040;100%&#12290;93%&#30340;&#31319;&#26524;&#22312;&#31532;&#19968;&#27425;&#23581;&#35797;&#26102;&#25104;&#21151;&#25235;&#21462;&#12290;
&lt;/p&gt;
&lt;p&gt;
Currently, truss tomato weighing and packaging require significant manual work. The main obstacle to automation lies in the difficulty of developing a reliable robotic grasping system for already harvested trusses. We propose a method to grasp trusses that are stacked in a crate with considerable clutter, which is how they are commonly stored and transported after harvest. The method consists of a deep learning-based vision system to first identify the individual trusses in the crate and then determine a suitable grasping location on the stem. To this end, we have introduced a grasp pose ranking algorithm with online learning capabilities. After selecting the most promising grasp pose, the robot executes a pinch grasp without needing touch sensors or geometric models. Lab experiments with a robotic manipulator equipped with an eye-in-hand RGB-D camera showed a 100% clearance rate when tasked to pick all trusses from a pile. 93% of the trusses were successfully grasped on the first try,
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#32467;&#21512;&#26426;&#22120;&#20154;&#21644;&#36830;&#32493;&#23398;&#20064;&#27169;&#22411;&#65292;&#36890;&#36807;&#20154;&#26426;&#20132;&#20114;&#30340;&#26041;&#24335;&#19982;60&#21517;&#21442;&#19982;&#32773;&#23454;&#39564;&#65292;&#32467;&#26524;&#34920;&#26126;&#20351;&#29992;&#36830;&#32493;&#23398;&#20064;&#21487;&#20197;&#25552;&#39640;&#26426;&#22120;&#20154;&#30340;&#33021;&#21147;&#65292;&#21442;&#19982;&#32773;&#26356;&#20542;&#21521;&#20110;&#19982;&#20854;&#36827;&#34892;&#21453;&#22797;&#20132;&#20114;&#65292;&#24182;&#25552;&#20379;&#26356;&#22810;&#30340;&#21453;&#39304;&#20449;&#24687;&#12290;</title><link>http://arxiv.org/abs/2305.16332</link><description>&lt;p&gt;
&#36890;&#36807;&#20154;&#26426;&#20132;&#20114;&#23454;&#29616;&#36830;&#32493;&#23398;&#20064;--&#20154;&#31867;&#22312;&#19982;&#26426;&#22120;&#20154;&#21453;&#22797;&#20132;&#20114;&#20013;&#23545;&#26426;&#22120;&#20154;&#36830;&#32493;&#23398;&#20064;&#30340;&#30475;&#27861;
&lt;/p&gt;
&lt;p&gt;
Continual Learning through Human-Robot Interaction -- Human Perceptions of a Continual Learning Robot in Repeated Interactions. (arXiv:2305.16332v1 [cs.RO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16332
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#32467;&#21512;&#26426;&#22120;&#20154;&#21644;&#36830;&#32493;&#23398;&#20064;&#27169;&#22411;&#65292;&#36890;&#36807;&#20154;&#26426;&#20132;&#20114;&#30340;&#26041;&#24335;&#19982;60&#21517;&#21442;&#19982;&#32773;&#23454;&#39564;&#65292;&#32467;&#26524;&#34920;&#26126;&#20351;&#29992;&#36830;&#32493;&#23398;&#20064;&#21487;&#20197;&#25552;&#39640;&#26426;&#22120;&#20154;&#30340;&#33021;&#21147;&#65292;&#21442;&#19982;&#32773;&#26356;&#20542;&#21521;&#20110;&#19982;&#20854;&#36827;&#34892;&#21453;&#22797;&#20132;&#20114;&#65292;&#24182;&#25552;&#20379;&#26356;&#22810;&#30340;&#21453;&#39304;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#22312;&#21160;&#24577;&#30340;&#23454;&#38469;&#29615;&#22659;&#20013;&#38271;&#26399;&#37096;&#32626;&#36741;&#21161;&#26426;&#22120;&#20154;&#65292;&#26426;&#22120;&#20154;&#24517;&#39035;&#32487;&#32493;&#23398;&#20064;&#21644;&#36866;&#24212;&#20854;&#29615;&#22659;&#12290;&#30740;&#31350;&#20154;&#21592;&#24050;&#32463;&#24320;&#21457;&#20102;&#21508;&#31181;&#36830;&#32493;&#23398;&#20064;&#65288;CL&#65289;&#30340;&#35745;&#31639;&#27169;&#22411;&#65292;&#21487;&#20197;&#20351;&#26426;&#22120;&#20154;&#19981;&#26029;&#20174;&#26377;&#38480;&#30340;&#35757;&#32451;&#25968;&#25454;&#20013;&#23398;&#20064;&#65292;&#24182;&#36991;&#20813;&#36951;&#24536;&#20808;&#21069;&#30340;&#30693;&#35782;&#12290;&#34429;&#28982;&#36825;&#20123;CL&#27169;&#22411;&#21487;&#20197;&#32531;&#35299;&#38745;&#24577;&#12289;&#31995;&#32479;&#22320;&#25910;&#38598;&#30340;&#25968;&#25454;&#38598;&#19978;&#30340;&#36951;&#24536;&#65292;&#20294;&#20154;&#20204;&#30446;&#21069;&#23578;&#19981;&#28165;&#26970;&#22312;&#22810;&#27425;&#20132;&#20114;&#20013;&#36830;&#32493;&#23398;&#20064;&#30340;&#26426;&#22120;&#20154;&#26159;&#22914;&#20309;&#34987;&#20154;&#31867;&#29992;&#25143;&#25152;&#24863;&#30693;&#30340;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#31995;&#32479;&#65292;&#23558;&#30446;&#26631;&#35782;&#21035;&#30340;CL&#27169;&#22411;&#19982;Fetch&#31227;&#21160;&#25805;&#32437;&#26426;&#22120;&#20154;&#36827;&#34892;&#25972;&#21512;&#65292;&#24182;&#20801;&#35768;&#20154;&#31867;&#21442;&#19982;&#32773;&#22312;&#22810;&#20010;&#20250;&#35805;&#20013;&#30452;&#25509;&#25945;&#25480;&#21644;&#27979;&#35797;&#26426;&#22120;&#20154;&#12290;&#25105;&#20204;&#24320;&#23637;&#20102;&#19968;&#39033;&#29616;&#22330;&#30740;&#31350;&#65292;60&#21517;&#21442;&#19982;&#32773;&#22312;300&#20010;&#20250;&#35805;&#20013;&#19982;&#25105;&#20204;&#30340;&#31995;&#32479;&#20114;&#21160;&#65288;&#27599;&#20010;&#21442;&#19982;&#32773;5&#27425;&#20250;&#35805;&#65289;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#39033;&#20004;&#32452;&#23454;&#39564;&#30340;&#30740;&#31350;&#65292;&#24182;&#20351;&#29992;&#19977;&#31181;&#19981;&#21516;&#30340;CL&#27169;&#22411;&#65288;&#19977;&#20010;&#23454;&#39564;&#26465;&#20214;&#65289;&#26469;&#20102;&#35299;&#20154;&#31867;&#23545;&#36830;&#32493;&#23398;&#20064;&#26426;&#22120;&#20154;&#30340;&#30475;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
For long-term deployment in dynamic real-world environments, assistive robots must continue to learn and adapt to their environments. Researchers have developed various computational models for continual learning (CL) that can allow robots to continually learn from limited training data, and avoid forgetting previous knowledge. While these CL models can mitigate forgetting on static, systematically collected datasets, it is unclear how human users might perceive a robot that continually learns over multiple interactions with them. In this paper, we developed a system that integrates CL models for object recognition with a Fetch mobile manipulator robot and allows human participants to directly teach and test the robot over multiple sessions. We conducted an in-person study with 60 participants who interacted with our system in 300 sessions (5 sessions per participant). We conducted a between-participant study with three different CL models (3 experimental conditions) to understand huma
&lt;/p&gt;</description></item></channel></rss>