<rss version="2.0"><channel><title>Chat Arxiv cs.RO</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.RO</description><item><title>&#32852;&#37030;&#23398;&#20064;&#22312;&#22810;&#26234;&#33021;&#20307;&#26426;&#22120;&#20154;&#25506;&#27979;&#20013;&#30340;&#24212;&#29992;&#65292;&#21033;&#29992;&#38544;&#24335;&#31070;&#32463;&#26144;&#23556;&#21644;&#22320;&#29699;&#25968;&#25454;&#38598;&#19978;&#30340;&#20803;&#21021;&#22987;&#21270;&#65292;&#23454;&#29616;&#20102;&#23545;&#19981;&#21516;&#39046;&#22495;&#22914;&#28779;&#26143;&#22320;&#24418;&#21644;&#20912;&#24029;&#30340;&#24378;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2404.02289</link><description>&lt;p&gt;
&#34892;&#26143;&#25506;&#27979;&#30340;&#32852;&#37030;&#22810;&#26234;&#33021;&#20307;&#24314;&#22270;
&lt;/p&gt;
&lt;p&gt;
Federated Multi-Agent Mapping for Planetary Exploration
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02289
&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#22312;&#22810;&#26234;&#33021;&#20307;&#26426;&#22120;&#20154;&#25506;&#27979;&#20013;&#30340;&#24212;&#29992;&#65292;&#21033;&#29992;&#38544;&#24335;&#31070;&#32463;&#26144;&#23556;&#21644;&#22320;&#29699;&#25968;&#25454;&#38598;&#19978;&#30340;&#20803;&#21021;&#22987;&#21270;&#65292;&#23454;&#29616;&#20102;&#23545;&#19981;&#21516;&#39046;&#22495;&#22914;&#28779;&#26143;&#22320;&#24418;&#21644;&#20912;&#24029;&#30340;&#24378;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22810;&#26234;&#33021;&#20307;&#26426;&#22120;&#20154;&#25506;&#27979;&#20013;&#65292;&#31649;&#29702;&#21644;&#26377;&#25928;&#21033;&#29992;&#21160;&#24577;&#29615;&#22659;&#20135;&#29983;&#30340;&#22823;&#37327;&#24322;&#26500;&#25968;&#25454;&#26500;&#25104;&#20102;&#19968;&#20010;&#37325;&#35201;&#25361;&#25112;&#12290;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#26159;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#20998;&#24067;&#24335;&#26144;&#23556;&#26041;&#27861;&#65292;&#23427;&#35299;&#20915;&#20102;&#21327;&#20316;&#23398;&#20064;&#20013;&#21435;&#20013;&#24515;&#21270;&#25968;&#25454;&#30340;&#25361;&#25112;&#12290;FL&#20351;&#22810;&#20010;&#26234;&#33021;&#20307;&#20043;&#38388;&#21487;&#20197;&#36827;&#34892;&#32852;&#21512;&#27169;&#22411;&#35757;&#32451;&#65292;&#32780;&#26080;&#38656;&#38598;&#20013;&#21270;&#25110;&#20849;&#20139;&#21407;&#22987;&#25968;&#25454;&#65292;&#20811;&#26381;&#20102;&#24102;&#23485;&#21644;&#23384;&#20648;&#38480;&#21046;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#38544;&#24335;&#31070;&#32463;&#26144;&#23556;&#65292;&#23558;&#22320;&#22270;&#34920;&#31034;&#20026;&#30001;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#30340;&#36830;&#32493;&#20989;&#25968;&#65292;&#20197;&#20415;&#23454;&#29616;&#32039;&#20945;&#21644;&#36866;&#24212;&#24615;&#30340;&#34920;&#31034;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#36890;&#36807;&#22312;&#22320;&#29699;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20803;&#21021;&#22987;&#21270;&#26469;&#22686;&#24378;&#36825;&#19968;&#26041;&#27861;&#65292;&#39044;&#35757;&#32451;&#32593;&#32476;&#20197;&#24555;&#36895;&#23398;&#20064;&#26032;&#30340;&#22320;&#22270;&#32467;&#26500;&#12290;&#36825;&#31181;&#32452;&#21512;&#22312;&#35832;&#22914;&#28779;&#26143;&#22320;&#24418;&#21644;&#20912;&#24029;&#31561;&#19981;&#21516;&#39046;&#22495;&#23637;&#29616;&#20102;&#36739;&#24378;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#25105;&#20204;&#23545;&#36825;&#19968;&#26041;&#27861;&#36827;&#34892;&#20102;&#20005;&#26684;&#35780;&#20272;&#65292;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02289v1 Announce Type: cross  Abstract: In multi-agent robotic exploration, managing and effectively utilizing the vast, heterogeneous data generated from dynamic environments poses a significant challenge. Federated learning (FL) is a promising approach for distributed mapping, addressing the challenges of decentralized data in collaborative learning. FL enables joint model training across multiple agents without requiring the centralization or sharing of raw data, overcoming bandwidth and storage constraints. Our approach leverages implicit neural mapping, representing maps as continuous functions learned by neural networks, for compact and adaptable representations. We further enhance this approach with meta-initialization on Earth datasets, pre-training the network to quickly learn new map structures. This combination demonstrates strong generalization to diverse domains like Martian terrain and glaciers. We rigorously evaluate this approach, demonstrating its effectiven
&lt;/p&gt;</description></item><item><title>ContactHandover&#26159;&#19968;&#20010;&#26426;&#22120;&#20154;&#21521;&#20154;&#31867;&#36882;&#36865;&#29289;&#20307;&#30340;&#31995;&#32479;&#65292;&#36890;&#36807;&#25509;&#35302;&#24341;&#23548;&#30340;&#25235;&#21462;&#21644;&#29289;&#20307;&#36882;&#36865;&#38454;&#27573;&#26469;&#23454;&#29616;&#25104;&#21151;&#30340;&#29289;&#20307;&#36882;&#36865;&#12290;</title><link>https://arxiv.org/abs/2404.01402</link><description>&lt;p&gt;
ContactHandover: &#25509;&#35302;&#24341;&#23548;&#30340;&#26426;&#22120;&#20154;&#21521;&#20154;&#31867;&#36882;&#36865;&#29289;&#20307;
&lt;/p&gt;
&lt;p&gt;
ContactHandover: Contact-Guided Robot-to-Human Object Handover
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01402
&lt;/p&gt;
&lt;p&gt;
ContactHandover&#26159;&#19968;&#20010;&#26426;&#22120;&#20154;&#21521;&#20154;&#31867;&#36882;&#36865;&#29289;&#20307;&#30340;&#31995;&#32479;&#65292;&#36890;&#36807;&#25509;&#35302;&#24341;&#23548;&#30340;&#25235;&#21462;&#21644;&#29289;&#20307;&#36882;&#36865;&#38454;&#27573;&#26469;&#23454;&#29616;&#25104;&#21151;&#30340;&#29289;&#20307;&#36882;&#36865;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#20154;&#21521;&#20154;&#31867;&#36882;&#36865;&#29289;&#20307;&#26159;&#35768;&#22810;&#20154;&#26426;&#21327;&#20316;&#20219;&#21153;&#20013;&#30340;&#37325;&#35201;&#19968;&#27493;&#12290;&#25104;&#21151;&#30340;&#36882;&#36865;&#38656;&#35201;&#26426;&#22120;&#20154;&#20445;&#25345;&#23545;&#29289;&#20307;&#30340;&#31283;&#23450;&#25235;&#21462;&#65292;&#21516;&#26102;&#30830;&#20445;&#20154;&#31867;&#20197;&#19968;&#31181;&#33258;&#28982;&#19988;&#26131;&#20110;&#20351;&#29992;&#30340;&#26041;&#24335;&#25509;&#25910;&#29289;&#20307;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;ContactHandover&#65292;&#36825;&#26159;&#19968;&#20010;&#26426;&#22120;&#20154;&#21521;&#20154;&#31867;&#36882;&#36865;&#29289;&#20307;&#30340;&#31995;&#32479;&#65292;&#21253;&#25324;&#20004;&#20010;&#38454;&#27573;&#65306;&#25509;&#35302;&#24341;&#23548;&#30340;&#25235;&#21462;&#38454;&#27573;&#21644;&#29289;&#20307;&#36882;&#36865;&#38454;&#27573;&#12290;&#22312;&#25235;&#21462;&#38454;&#27573;&#65292;ContactHandover&#39044;&#27979;&#26426;&#22120;&#20154;&#30340;6&#33258;&#30001;&#24230;&#25235;&#21462;&#23039;&#21183;&#21644;&#20154;&#31867;&#25509;&#35302;&#28857;&#22312;&#29289;&#20307;&#19978;&#30340;3D&#21487;&#20379;&#24615;&#22270;&#12290;&#26426;&#22120;&#20154;&#30340;&#25235;&#21462;&#23039;&#21183;&#36890;&#36807;&#24809;&#32602;&#37027;&#20123;&#38459;&#30861;&#20154;&#31867;&#25509;&#35302;&#28857;&#30340;&#23039;&#21183;&#36827;&#34892;&#37325;&#26032;&#25490;&#24207;&#65292;&#24182;&#25191;&#34892;&#25490;&#21517;&#26368;&#39640;&#30340;&#25235;&#21462;&#12290;&#22312;&#36882;&#36865;&#38454;&#27573;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;&#38752;&#36817;&#20154;&#31867;&#30340;&#25509;&#35302;&#28857;&#24182;&#26368;&#23567;&#21270;&#20154;&#31867;&#25163;&#33218;&#20851;&#33410;&#25197;&#30697;&#21644;&#20301;&#31227;&#26469;&#35745;&#31639;&#26426;&#22120;&#20154;&#26411;&#31471;&#25191;&#34892;&#22120;&#23039;&#21183;&#12290;&#25105;&#20204;&#22312;27&#31181;&#19981;&#21516;&#23478;&#29992;&#29289;&#21697;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#31995;&#32479;&#65292;&#24182;&#23637;&#31034;&#20102;o
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01402v1 Announce Type: cross  Abstract: Robot-to-human object handover is an important step in many human robot collaboration tasks. A successful handover requires the robot to maintain a stable grasp on the object while making sure the human receives the object in a natural and easy-to-use manner. We propose ContactHandover, a robot to human handover system that consists of two phases: a contact-guided grasping phase and an object delivery phase. During the grasping phase, ContactHandover predicts both 6-DoF robot grasp poses and a 3D affordance map of human contact points on the object. The robot grasp poses are reranked by penalizing those that block human contact points, and the robot executes the highest ranking grasp. During the delivery phase, the robot end effector pose is computed by maximizing human contact points close to the human while minimizing the human arm joint torques and displacements. We evaluate our system on 27 diverse household objects and show that o
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#38754;&#21521;&#20851;&#33410;&#23545;&#35937;&#30340;&#20581;&#22766;&#24863;&#30693;&#21644;&#25805;&#20316;&#26694;&#26550;RPMArt&#65292;&#20027;&#35201;&#36129;&#29486;&#26159;&#33021;&#22815;&#31283;&#20581;&#22320;&#39044;&#27979;&#20851;&#33410;&#21442;&#25968;&#21644;&#21487;&#20449;&#28857;&#30340;RoArtNet&#12290;</title><link>https://arxiv.org/abs/2403.16023</link><description>&lt;p&gt;
RPMArt&#65306;&#38754;&#21521;&#20851;&#33410;&#23545;&#35937;&#30340;&#20581;&#22766;&#24863;&#30693;&#21644;&#25805;&#20316;
&lt;/p&gt;
&lt;p&gt;
RPMArt: Towards Robust Perception and Manipulation for Articulated Objects
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16023
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#38754;&#21521;&#20851;&#33410;&#23545;&#35937;&#30340;&#20581;&#22766;&#24863;&#30693;&#21644;&#25805;&#20316;&#26694;&#26550;RPMArt&#65292;&#20027;&#35201;&#36129;&#29486;&#26159;&#33021;&#22815;&#31283;&#20581;&#22320;&#39044;&#27979;&#20851;&#33410;&#21442;&#25968;&#21644;&#21487;&#20449;&#28857;&#30340;RoArtNet&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20851;&#33410;&#23545;&#35937;&#22312;&#26085;&#24120;&#29983;&#27963;&#20013;&#24456;&#24120;&#35265;&#12290;&#23545;&#20110;&#30495;&#23454;&#19990;&#30028;&#30340;&#26426;&#22120;&#20154;&#24212;&#29992;&#26469;&#35828;&#65292;&#26426;&#22120;&#20154;&#33021;&#22815;&#34920;&#29616;&#20986;&#23545;&#20851;&#33410;&#23545;&#35937;&#30340;&#20581;&#22766;&#24863;&#30693;&#21644;&#25805;&#20316;&#25216;&#33021;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#20851;&#33410;&#23545;&#35937;&#26041;&#27861;&#19981;&#22815;&#35299;&#20915;&#28857;&#20113;&#20013;&#30340;&#22122;&#22768;&#38382;&#39064;&#65292;&#38590;&#20197;&#24357;&#21512;&#27169;&#25311;&#19982;&#29616;&#23454;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#20174;&#32780;&#38480;&#21046;&#20102;&#22312;&#30495;&#23454;&#22330;&#26223;&#20013;&#30340;&#23454;&#38469;&#37096;&#32626;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#38754;&#21521;&#20851;&#33410;&#23545;&#35937;&#30340;&#20581;&#22766;&#24863;&#30693;&#21644;&#25805;&#20316;&#30340;&#26694;&#26550;&#65288;RPMArt&#65289;&#65292;&#35813;&#26694;&#26550;&#23398;&#20064;&#22914;&#20309;&#20174;&#22024;&#26434;&#30340;&#28857;&#20113;&#20013;&#20272;&#35745;&#20851;&#33410;&#21442;&#25968;&#24182;&#25805;&#20316;&#20851;&#33410;&#37096;&#20998;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#19968;&#20010;&#20581;&#22766;&#20851;&#33410;&#32593;&#32476;&#65288;RoArtNet&#65289;&#65292;&#36890;&#36807;&#23616;&#37096;&#29305;&#24449;&#23398;&#20064;&#21644;&#28857;&#20803;&#32452;&#25237;&#31080;&#33021;&#22815;&#31283;&#20581;&#22320;&#39044;&#27979;&#20851;&#33410;&#21442;&#25968;&#21644;&#21487;&#20449;&#28857;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#20851;&#33410;&#24863;&#30693;&#20998;&#31867;&#26041;&#26696;&#26469;&#22686;&#24378;&#20854;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16023v1 Announce Type: cross  Abstract: Articulated objects are commonly found in daily life. It is essential that robots can exhibit robust perception and manipulation skills for articulated objects in real-world robotic applications. However, existing methods for articulated objects insufficiently address noise in point clouds and struggle to bridge the gap between simulation and reality, thus limiting the practical deployment in real-world scenarios. To tackle these challenges, we propose a framework towards Robust Perception and Manipulation for Articulated Objects (RPMArt), which learns to estimate the articulation parameters and manipulate the articulation part from the noisy point cloud. Our primary contribution is a Robust Articulation Network (RoArtNet) that is able to predict both joint parameters and affordable points robustly by local feature learning and point tuple voting. Moreover, we introduce an articulation-aware classification scheme to enhance its ability
&lt;/p&gt;</description></item><item><title>STAMP&#26159;&#19968;&#31181;&#22522;&#20110;Stein&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#24182;&#34892;&#21270;&#21644;&#21487;&#24494;&#20223;&#30495;&#39640;&#25928;&#22320;&#25628;&#32034;&#22810;&#20010;&#22810;&#26679;&#21270;&#30340;&#20219;&#21153;&#21644;&#36816;&#21160;&#35268;&#21010;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2310.01775</link><description>&lt;p&gt;
STAMP&#65306;&#36890;&#36807;Stein&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#23454;&#29616;&#21487;&#24494;&#30340;&#20219;&#21153;&#21644;&#36816;&#21160;&#35268;&#21010;
&lt;/p&gt;
&lt;p&gt;
STAMP: Differentiable Task and Motion Planning via Stein Variational Gradient Descent. (arXiv:2310.01775v1 [cs.RO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01775
&lt;/p&gt;
&lt;p&gt;
STAMP&#26159;&#19968;&#31181;&#22522;&#20110;Stein&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#24182;&#34892;&#21270;&#21644;&#21487;&#24494;&#20223;&#30495;&#39640;&#25928;&#22320;&#25628;&#32034;&#22810;&#20010;&#22810;&#26679;&#21270;&#30340;&#20219;&#21153;&#21644;&#36816;&#21160;&#35268;&#21010;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#25805;&#20316;&#20219;&#21153;&#65292;&#22914;&#20351;&#29992;&#24037;&#20855;&#25110;&#35013;&#37197;&#38646;&#20214;&#65292;&#24448;&#24448;&#38656;&#35201;&#31526;&#21495;&#21644;&#20960;&#20309;&#25512;&#29702;&#12290;&#20219;&#21153;&#21644;&#36816;&#21160;&#35268;&#21010;&#65288;TAMP&#65289;&#31639;&#27861;&#36890;&#24120;&#36890;&#36807;&#23545;&#39640;&#32423;&#20219;&#21153;&#24207;&#21015;&#36827;&#34892;&#26641;&#25628;&#32034;&#24182;&#26816;&#26597;&#36816;&#21160;&#23398;&#21644;&#21160;&#21147;&#23398;&#21487;&#34892;&#24615;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;&#34429;&#28982;&#24615;&#33021;&#33391;&#22909;&#65292;&#20294;&#22823;&#22810;&#25968;&#29616;&#26377;&#31639;&#27861;&#30340;&#25928;&#29575;&#38750;&#24120;&#20302;&#65292;&#22240;&#20026;&#20854;&#26102;&#38388;&#22797;&#26434;&#24615;&#38543;&#21487;&#33021;&#21160;&#20316;&#21644;&#29289;&#20307;&#25968;&#37327;&#30340;&#22686;&#21152;&#21576;&#25351;&#25968;&#22686;&#38271;&#12290;&#27492;&#22806;&#65292;&#23427;&#20204;&#21482;&#33021;&#25214;&#21040;&#21333;&#20010;&#35299;&#20915;&#26041;&#26696;&#65292;&#32780;&#21487;&#33021;&#23384;&#22312;&#35768;&#22810;&#21487;&#34892;&#30340;&#35745;&#21010;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Stein&#20219;&#21153;&#21644;&#36816;&#21160;&#35268;&#21010;&#65288;STAMP&#65289;&#30340;&#26032;&#31639;&#27861;&#65292;&#23427;&#21033;&#29992;&#24182;&#34892;&#21270;&#21644;&#21487;&#24494;&#20223;&#30495;&#26469;&#39640;&#25928;&#22320;&#25628;&#32034;&#22810;&#20010;&#22810;&#26679;&#21270;&#30340;&#35745;&#21010;&#12290;STAMP&#23558;&#31163;&#25955;&#21644;&#36830;&#32493;&#30340;TAMP&#38382;&#39064;&#36716;&#21270;&#20026;&#21487;&#20197;&#20351;&#29992;&#21464;&#20998;&#25512;&#26029;&#35299;&#20915;&#30340;&#36830;&#32493;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22522;&#20110;Stein&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#65292;&#19968;&#31181;&#27010;&#29575;&#25512;&#26029;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Planning for many manipulation tasks, such as using tools or assembling parts, often requires both symbolic and geometric reasoning. Task and Motion Planning (TAMP) algorithms typically solve these problems by conducting a tree search over high-level task sequences while checking for kinematic and dynamic feasibility. While performant, most existing algorithms are highly inefficient as their time complexity grows exponentially with the number of possible actions and objects. Additionally, they only find a single solution to problems in which many feasible plans may exist. To address these limitations, we propose a novel algorithm called Stein Task and Motion Planning (STAMP) that leverages parallelization and differentiable simulation to efficiently search for multiple diverse plans. STAMP relaxes discrete-and-continuous TAMP problems into continuous optimization problems that can be solved using variational inference. Our algorithm builds upon Stein Variational Gradient Descent, a gra
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181; RL+&#27169;&#22411;&#25511;&#21046;&#26694;&#26550;&#20197;&#24320;&#21457;&#20986;&#21487;&#20197;&#26377;&#25928;&#21487;&#38752;&#22320;&#23398;&#20064;&#30340;&#20581;&#22766;&#25511;&#21046;&#31574;&#30053;&#65292;&#36890;&#36807;&#25972;&#21512;&#26377;&#38480;&#26102;&#38388;&#26368;&#20248;&#25511;&#21046;&#29983;&#25104;&#30340;&#25353;&#38656;&#21442;&#32771;&#36816;&#21160;&#20998;&#25955; RL &#36807;&#31243;&#65292;&#21516;&#26102;&#20811;&#26381;&#20102;&#24314;&#27169;&#31616;&#21270;&#30340;&#22266;&#26377;&#23616;&#38480;&#24615;&#65292;&#22312;&#36275;&#24335; locomotion &#19978;&#23454;&#29616;&#20102;&#22810;&#21151;&#33021;&#21644;&#24378;&#20581;&#65292;&#33021;&#27867;&#21270;&#21442;&#32771;&#36816;&#21160;&#24182;&#22788;&#29702;&#26356;&#22797;&#26434;&#30340;&#36816;&#21160;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2305.17842</link><description>&lt;p&gt;
RL+&#27169;&#22411;&#25511;&#21046;&#65306;&#20351;&#29992;&#25353;&#38656;&#26368;&#20248;&#25511;&#21046;&#23398;&#20064;&#22810;&#21151;&#33021;&#36275;&#24335; locomotion
&lt;/p&gt;
&lt;p&gt;
RL + Model-based Control: Using On-demand Optimal Control to Learn Versatile Legged Locomotion. (arXiv:2305.17842v2 [cs.RO] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17842
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181; RL+&#27169;&#22411;&#25511;&#21046;&#26694;&#26550;&#20197;&#24320;&#21457;&#20986;&#21487;&#20197;&#26377;&#25928;&#21487;&#38752;&#22320;&#23398;&#20064;&#30340;&#20581;&#22766;&#25511;&#21046;&#31574;&#30053;&#65292;&#36890;&#36807;&#25972;&#21512;&#26377;&#38480;&#26102;&#38388;&#26368;&#20248;&#25511;&#21046;&#29983;&#25104;&#30340;&#25353;&#38656;&#21442;&#32771;&#36816;&#21160;&#20998;&#25955; RL &#36807;&#31243;&#65292;&#21516;&#26102;&#20811;&#26381;&#20102;&#24314;&#27169;&#31616;&#21270;&#30340;&#22266;&#26377;&#23616;&#38480;&#24615;&#65292;&#22312;&#36275;&#24335; locomotion &#19978;&#23454;&#29616;&#20102;&#22810;&#21151;&#33021;&#21644;&#24378;&#20581;&#65292;&#33021;&#27867;&#21270;&#21442;&#32771;&#36816;&#21160;&#24182;&#22788;&#29702;&#26356;&#22797;&#26434;&#30340;&#36816;&#21160;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25511;&#21046;&#26694;&#26550;&#65292;&#23558;&#22522;&#20110;&#27169;&#22411;&#30340;&#26368;&#20248;&#25511;&#21046;&#21644;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#30456;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#22810;&#21151;&#33021;&#21644;&#24378;&#20581;&#30340;&#36275;&#24335; locomotion&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#25972;&#21512;&#26377;&#38480;&#26102;&#38388;&#26368;&#20248;&#25511;&#21046;&#29983;&#25104;&#30340;&#25353;&#38656;&#21442;&#32771;&#36816;&#21160;&#26469;&#22686;&#24378; RL &#35757;&#32451;&#36807;&#31243;&#65292;&#35206;&#30422;&#20102;&#24191;&#27867;&#30340;&#36895;&#24230;&#21644;&#27493;&#24577;&#12290;&#36825;&#20123;&#21442;&#32771;&#36816;&#21160;&#20316;&#20026; RL &#31574;&#30053;&#27169;&#20223;&#30340;&#30446;&#26631;&#65292;&#23548;&#33268;&#24320;&#21457;&#20986;&#21487;&#26377;&#25928;&#21487;&#38752;&#22320;&#23398;&#20064;&#30340;&#20581;&#22766;&#25511;&#21046;&#31574;&#30053;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#32771;&#34385;&#20840;&#36523;&#21160;&#21147;&#23398;&#65292;RL &#20811;&#26381;&#20102;&#24314;&#27169;&#31616;&#21270;&#30340;&#22266;&#26377;&#23616;&#38480;&#24615;&#12290;&#36890;&#36807;&#20223;&#30495;&#21644;&#30828;&#20214;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102; RL &#35757;&#32451;&#36807;&#31243;&#22312;&#25105;&#20204;&#30340;&#26694;&#26550;&#20869;&#30340;&#24378;&#20581;&#24615;&#21644;&#21487;&#25511;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#23637;&#31034;&#20102;&#27867;&#21270;&#21442;&#32771;&#36816;&#21160;&#21644;&#22788;&#29702;&#21487;&#33021;&#23545;&#31616;&#21270;&#27169;&#22411;&#26500;&#25104;&#25361;&#25112;&#30340;&#26356;&#22797;&#26434;&#30340;&#36816;&#21160;&#20219;&#21153;&#30340;&#33021;&#21147;&#65292;&#21033;&#29992;&#20102; RL &#30340;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This letter presents a control framework that combines model-based optimal control and reinforcement learning (RL) to achieve versatile and robust legged locomotion. Our approach enhances the RL training process by incorporating on-demand reference motions generated through finite-horizon optimal control, covering a broad range of velocities and gaits. These reference motions serve as targets for the RL policy to imitate, resulting in the development of robust control policies that can be learned efficiently and reliably. Moreover, by considering whole-body dynamics, RL overcomes the inherent limitations of modelling simplifications. Through simulation and hardware experiments, we demonstrate the robustness and controllability of the RL training process within our framework. Furthermore, our method demonstrates the ability to generalize reference motions and handle more complex locomotion tasks that may pose challenges for the simplified model, leveraging the flexibility of RL.
&lt;/p&gt;</description></item></channel></rss>