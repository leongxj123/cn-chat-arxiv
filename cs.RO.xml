<rss version="2.0"><channel><title>Chat Arxiv cs.RO</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.RO</description><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#22522;&#30784;&#27169;&#22411;&#22312;&#30495;&#23454;&#19990;&#30028;&#26426;&#22120;&#20154;&#20013;&#30340;&#24212;&#29992;&#65292;&#37325;&#28857;&#26159;&#26367;&#25442;&#29616;&#26377;&#26426;&#22120;&#20154;&#31995;&#32479;&#20013;&#30340;&#29305;&#23450;&#32452;&#20214;&#12290;&#36825;&#20123;&#22522;&#30784;&#27169;&#22411;&#22312;&#36755;&#20837;&#36755;&#20986;&#20851;&#31995;&#12289;&#24863;&#30693;&#12289;&#36816;&#21160;&#35268;&#21010;&#21644;&#25511;&#21046;&#31561;&#26041;&#38754;&#25198;&#28436;&#20102;&#37325;&#35201;&#35282;&#33394;&#12290;&#26410;&#26469;&#30340;&#25361;&#25112;&#21644;&#23545;&#23454;&#38469;&#26426;&#22120;&#20154;&#24212;&#29992;&#30340;&#24433;&#21709;&#20063;&#34987;&#35752;&#35770;&#21040;&#12290;</title><link>https://arxiv.org/abs/2402.05741</link><description>&lt;p&gt;
&#22522;&#20110;&#22522;&#30784;&#27169;&#22411;&#30340;&#30495;&#23454;&#19990;&#30028;&#26426;&#22120;&#20154;&#24212;&#29992;&#65306;&#19968;&#39033;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Real-World Robot Applications of Foundation Models: A Review
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05741
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#22522;&#30784;&#27169;&#22411;&#22312;&#30495;&#23454;&#19990;&#30028;&#26426;&#22120;&#20154;&#20013;&#30340;&#24212;&#29992;&#65292;&#37325;&#28857;&#26159;&#26367;&#25442;&#29616;&#26377;&#26426;&#22120;&#20154;&#31995;&#32479;&#20013;&#30340;&#29305;&#23450;&#32452;&#20214;&#12290;&#36825;&#20123;&#22522;&#30784;&#27169;&#22411;&#22312;&#36755;&#20837;&#36755;&#20986;&#20851;&#31995;&#12289;&#24863;&#30693;&#12289;&#36816;&#21160;&#35268;&#21010;&#21644;&#25511;&#21046;&#31561;&#26041;&#38754;&#25198;&#28436;&#20102;&#37325;&#35201;&#35282;&#33394;&#12290;&#26410;&#26469;&#30340;&#25361;&#25112;&#21644;&#23545;&#23454;&#38469;&#26426;&#22120;&#20154;&#24212;&#29992;&#30340;&#24433;&#21709;&#20063;&#34987;&#35752;&#35770;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#22522;&#20110;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#21644;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#65288;VLMs&#65289;&#31561;&#22522;&#30784;&#27169;&#22411;&#30340;&#21457;&#23637;&#65292;&#36890;&#36807;&#23545;&#22823;&#37327;&#25968;&#25454;&#30340;&#35757;&#32451;&#65292;&#20026;&#19981;&#21516;&#20219;&#21153;&#21644;&#27169;&#24577;&#30340;&#28789;&#27963;&#24212;&#29992;&#25552;&#20379;&#20102;&#20415;&#21033;&#12290;&#23427;&#20204;&#30340;&#24433;&#21709;&#28085;&#30422;&#20102;&#21253;&#25324;&#21307;&#30103;&#12289;&#25945;&#32946;&#21644;&#26426;&#22120;&#20154;&#31561;&#21508;&#20010;&#39046;&#22495;&#12290;&#26412;&#25991;&#27010;&#36848;&#20102;&#22522;&#30784;&#27169;&#22411;&#22312;&#30495;&#23454;&#19990;&#30028;&#26426;&#22120;&#20154;&#20013;&#30340;&#23454;&#38469;&#24212;&#29992;&#24773;&#20917;&#65292;&#37325;&#28857;&#26159;&#26367;&#25442;&#29616;&#26377;&#26426;&#22120;&#20154;&#31995;&#32479;&#20013;&#30340;&#29305;&#23450;&#32452;&#20214;&#12290;&#24635;&#32467;&#28085;&#30422;&#20102;&#22522;&#30784;&#27169;&#22411;&#20013;&#30340;&#36755;&#20837;&#36755;&#20986;&#20851;&#31995;&#20197;&#21450;&#23427;&#20204;&#22312;&#26426;&#22120;&#20154;&#39046;&#22495;&#20013;&#30340;&#24863;&#30693;&#12289;&#36816;&#21160;&#35268;&#21010;&#21644;&#25511;&#21046;&#31561;&#26041;&#38754;&#30340;&#20316;&#29992;&#12290;&#26412;&#25991;&#36824;&#35752;&#35770;&#20102;&#26410;&#26469;&#25361;&#25112;&#21644;&#23545;&#23454;&#38469;&#26426;&#22120;&#20154;&#24212;&#29992;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent developments in foundation models, like Large Language Models (LLMs) and Vision-Language Models (VLMs), trained on extensive data, facilitate flexible application across different tasks and modalities. Their impact spans various fields, including healthcare, education, and robotics. This paper provides an overview of the practical application of foundation models in real-world robotics, with a primary emphasis on the replacement of specific components within existing robot systems. The summary encompasses the perspective of input-output relationships in foundation models, as well as their role in perception, motion planning, and control within the field of robotics. This paper concludes with a discussion of future challenges and implications for practical robot applications.
&lt;/p&gt;</description></item></channel></rss>