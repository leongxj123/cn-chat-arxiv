<rss version="2.0"><channel><title>Chat Arxiv cs.RO</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.RO</description><item><title>&#22312;&#22522;&#20110;&#35270;&#35273;&#30340;&#33258;&#20027;&#26080;&#20154;&#26426;&#31454;&#36895;&#20013;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#23558;&#24378;&#21270;&#23398;&#20064;&#21644;&#27169;&#20223;&#23398;&#20064;&#30456;&#32467;&#21512;&#30340;&#26032;&#22411;&#35757;&#32451;&#26694;&#26550;&#65292;&#20197;&#20811;&#26381;&#26679;&#26412;&#25928;&#29575;&#21644;&#35745;&#31639;&#38656;&#27714;&#26041;&#38754;&#30340;&#25361;&#25112;&#65292;&#24182;&#36890;&#36807;&#19977;&#20010;&#38454;&#27573;&#30340;&#26041;&#27861;&#36827;&#34892;&#24615;&#33021;&#21463;&#38480;&#30340;&#33258;&#36866;&#24212;RL&#24494;&#35843;</title><link>https://arxiv.org/abs/2403.12203</link><description>&lt;p&gt;
&#22522;&#20110;&#27169;&#20223;&#30340;&#22686;&#24378;&#23398;&#20064;&#20026;&#22522;&#20110;&#35270;&#35273;&#30340;&#25935;&#25463;&#39134;&#34892;&#24341;&#23548;&#24341;&#23548;
&lt;/p&gt;
&lt;p&gt;
Bootstrapping Reinforcement Learning with Imitation for Vision-Based Agile Flight
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12203
&lt;/p&gt;
&lt;p&gt;
&#22312;&#22522;&#20110;&#35270;&#35273;&#30340;&#33258;&#20027;&#26080;&#20154;&#26426;&#31454;&#36895;&#20013;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#23558;&#24378;&#21270;&#23398;&#20064;&#21644;&#27169;&#20223;&#23398;&#20064;&#30456;&#32467;&#21512;&#30340;&#26032;&#22411;&#35757;&#32451;&#26694;&#26550;&#65292;&#20197;&#20811;&#26381;&#26679;&#26412;&#25928;&#29575;&#21644;&#35745;&#31639;&#38656;&#27714;&#26041;&#38754;&#30340;&#25361;&#25112;&#65292;&#24182;&#36890;&#36807;&#19977;&#20010;&#38454;&#27573;&#30340;&#26041;&#27861;&#36827;&#34892;&#24615;&#33021;&#21463;&#38480;&#30340;&#33258;&#36866;&#24212;RL&#24494;&#35843;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#22522;&#20110;&#35270;&#35273;&#30340;&#33258;&#20027;&#26080;&#20154;&#26426;&#31454;&#36895;&#30340;&#32972;&#26223;&#19979;&#65292;&#23558;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#30340;&#26377;&#25928;&#24615;&#21644;&#27169;&#20223;&#23398;&#20064;&#65288;IL&#65289;&#30340;&#25928;&#29575;&#32467;&#21512;&#22312;&#19968;&#36215;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#30452;&#25509;&#22788;&#29702;&#35270;&#35273;&#36755;&#20837;&#65292;&#32780;&#26080;&#38656;&#26126;&#30830;&#30340;&#29366;&#24577;&#20272;&#35745;&#12290;&#34429;&#28982;&#24378;&#21270;&#23398;&#20064;&#36890;&#36807;&#35797;&#38169;&#25552;&#20379;&#20102;&#19968;&#20010;&#23398;&#20064;&#22797;&#26434;&#25511;&#21046;&#22120;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#20294;&#38754;&#20020;&#30528;&#26679;&#26412;&#25928;&#29575;&#21644;&#35745;&#31639;&#38656;&#27714;&#30340;&#25361;&#25112;&#65292;&#22240;&#20026;&#35270;&#35273;&#36755;&#20837;&#30340;&#32500;&#24230;&#36739;&#39640;&#12290;&#30456;&#21453;&#65292;IL&#22312;&#20174;&#35270;&#35273;&#28436;&#31034;&#20013;&#23398;&#20064;&#26041;&#38754;&#34920;&#29616;&#20986;&#25928;&#29575;&#65292;&#20294;&#21463;&#21040;&#28436;&#31034;&#36136;&#37327;&#30340;&#38480;&#21046;&#65292;&#24182;&#38754;&#20020;&#35832;&#22914;&#21327;&#21464;&#37327;&#28418;&#31227;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32467;&#21512;RL&#21644;IL&#20248;&#21183;&#30340;&#26032;&#22411;&#35757;&#32451;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21253;&#25324;&#19977;&#20010;&#38454;&#27573;&#65306;&#20351;&#29992;&#29305;&#26435;&#29366;&#24577;&#20449;&#24687;&#30340;&#24072;&#20613;&#31574;&#30053;&#30340;&#21021;&#22987;&#35757;&#32451;&#65292;&#20351;&#29992;IL&#23558;&#27492;&#31574;&#30053;&#33976;&#39311;&#20026;&#23398;&#29983;&#31574;&#30053;&#65292;&#20197;&#21450;&#24615;&#33021;&#21463;&#38480;&#30340;&#33258;&#36866;&#24212;RL&#24494;&#35843;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12203v1 Announce Type: cross  Abstract: We combine the effectiveness of Reinforcement Learning (RL) and the efficiency of Imitation Learning (IL) in the context of vision-based, autonomous drone racing. We focus on directly processing visual input without explicit state estimation. While RL offers a general framework for learning complex controllers through trial and error, it faces challenges regarding sample efficiency and computational demands due to the high dimensionality of visual inputs. Conversely, IL demonstrates efficiency in learning from visual demonstrations but is limited by the quality of those demonstrations and faces issues like covariate shift. To overcome these limitations, we propose a novel training framework combining RL and IL's advantages. Our framework involves three stages: initial training of a teacher policy using privileged state information, distilling this policy into a student policy using IL, and performance-constrained adaptive RL fine-tunin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#30340;&#38598;&#20013;&#24335;&#35757;&#32451;&#21644;&#20998;&#24067;&#24335;&#25191;&#34892;&#26041;&#27861;&#65292;&#20197;&#22312;&#32447;&#35299;&#20915;&#21160;&#24577;&#38556;&#30861;&#29289;&#36991;&#38556;&#38382;&#39064;&#12290;&#23454;&#39564;&#32467;&#26524;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.16659</link><description>&lt;p&gt;
&#26080;&#20154;&#26426;&#22312;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#21160;&#24577;&#36991;&#38556;&#36335;&#24452;&#35268;&#21010;
&lt;/p&gt;
&lt;p&gt;
UAV Pathfinding in Dynamic Obstacle Avoidance with Multi-agent Reinforcement Learning. (arXiv:2310.16659v1 [cs.RO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16659
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#30340;&#38598;&#20013;&#24335;&#35757;&#32451;&#21644;&#20998;&#24067;&#24335;&#25191;&#34892;&#26041;&#27861;&#65292;&#20197;&#22312;&#32447;&#35299;&#20915;&#21160;&#24577;&#38556;&#30861;&#29289;&#36991;&#38556;&#38382;&#39064;&#12290;&#23454;&#39564;&#32467;&#26524;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#22312;&#21160;&#24577;&#21644;&#19981;&#30830;&#23450;&#30340;&#22330;&#26223;&#20013;&#22312;&#32447;&#35268;&#21010;&#26234;&#33021;&#20307;&#30340;&#21487;&#34892;&#19988;&#23433;&#20840;&#30340;&#36335;&#24452;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#30340;&#38598;&#20013;&#24335;&#35757;&#32451;&#21644;&#20998;&#24067;&#24335;&#25191;&#34892;&#26041;&#27861;&#65292;&#20197;&#22312;&#32447;&#35299;&#20915;&#21160;&#24577;&#38556;&#30861;&#29289;&#36991;&#38556;&#38382;&#39064;&#12290;&#22312;&#35813;&#26041;&#27861;&#20013;&#65292;&#27599;&#20010;&#26234;&#33021;&#20307;&#20165;&#19982;&#20013;&#22830;&#35268;&#21010;&#32773;&#25110;&#20854;&#37051;&#23621;&#36827;&#34892;&#36890;&#20449;&#65292;&#20197;&#22312;&#32447;&#35268;&#21010;&#21487;&#34892;&#19988;&#23433;&#20840;&#30340;&#36335;&#24452;&#12290;&#25105;&#20204;&#22522;&#20110;&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;&#30340;&#24605;&#24819;&#25913;&#36827;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#20197;&#25552;&#39640;&#26234;&#33021;&#20307;&#30340;&#35757;&#32451;&#25928;&#29575;&#21644;&#37319;&#26679;&#21033;&#29992;&#29575;&#12290;&#22312;&#27169;&#25311;&#12289;&#23460;&#20869;&#21644;&#23460;&#22806;&#29615;&#22659;&#20013;&#30340;&#23454;&#39564;&#32467;&#26524;&#39564;&#35777;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-agent reinforcement learning based methods are significant for online planning of feasible and safe paths for agents in dynamic and uncertain scenarios. Although some methods like fully centralized and fully decentralized methods achieve a certain measure of success, they also encounter problems such as dimension explosion and poor convergence, respectively. In this paper, we propose a novel centralized training with decentralized execution method based on multi-agent reinforcement learning to solve the dynamic obstacle avoidance problem online. In this approach, each agent communicates only with the central planner or only with its neighbors, respectively, to plan feasible and safe paths online. We improve our methods based on the idea of model predictive control to increase the training efficiency and sample utilization of agents. The experimental results in both simulation, indoor, and outdoor environments validate the effectiveness of our method. The video is available at htt
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#31070;&#32463;&#20250;&#21512;&#65292;&#19968;&#31181;&#28145;&#24230;&#23398;&#20064;&#23548;&#33322;&#21644;&#25511;&#21046;&#26694;&#26550;&#65292;&#29992;&#20110;&#21487;&#38752;&#12289;&#20934;&#30830;&#21644;&#33258;&#20027;&#22320;&#36973;&#36935;&#24555;&#36895;&#31227;&#21160;&#30340;&#26143;&#38469;&#29289;&#20307;&#12290;&#23427;&#36890;&#36807;&#28857;&#26368;&#23567;&#33539;&#25968;&#36861;&#36394;&#25511;&#21046;&#21644;&#35889;&#24402;&#19968;&#21270;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#24341;&#23548;&#31574;&#30053;&#26469;&#25552;&#20379;&#39640;&#27010;&#29575;&#25351;&#25968;&#19978;&#30028;&#30340;&#39134;&#34892;&#22120;&#20132;&#20184;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2208.04883</link><description>&lt;p&gt;
&#31070;&#32463;&#20250;&#21512;&#65306;&#38754;&#21521;&#26143;&#38469;&#29289;&#20307;&#30340;&#21487;&#38752;&#23548;&#33322;&#21644;&#25511;&#21046;&#30340;&#35777;&#26126;
&lt;/p&gt;
&lt;p&gt;
Neural-Rendezvous: Provably Robust Guidance and Control to Encounter Interstellar Objects. (arXiv:2208.04883v2 [cs.RO] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.04883
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#31070;&#32463;&#20250;&#21512;&#65292;&#19968;&#31181;&#28145;&#24230;&#23398;&#20064;&#23548;&#33322;&#21644;&#25511;&#21046;&#26694;&#26550;&#65292;&#29992;&#20110;&#21487;&#38752;&#12289;&#20934;&#30830;&#21644;&#33258;&#20027;&#22320;&#36973;&#36935;&#24555;&#36895;&#31227;&#21160;&#30340;&#26143;&#38469;&#29289;&#20307;&#12290;&#23427;&#36890;&#36807;&#28857;&#26368;&#23567;&#33539;&#25968;&#36861;&#36394;&#25511;&#21046;&#21644;&#35889;&#24402;&#19968;&#21270;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#24341;&#23548;&#31574;&#30053;&#26469;&#25552;&#20379;&#39640;&#27010;&#29575;&#25351;&#25968;&#19978;&#30028;&#30340;&#39134;&#34892;&#22120;&#20132;&#20184;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26143;&#38469;&#29289;&#20307;&#65288;ISOs&#65289;&#24456;&#21487;&#33021;&#26159;&#19981;&#21487;&#26367;&#20195;&#30340;&#21407;&#22987;&#26448;&#26009;&#65292;&#22312;&#29702;&#35299;&#31995;&#22806;&#34892;&#26143;&#26143;&#31995;&#26041;&#38754;&#20855;&#26377;&#37325;&#35201;&#20215;&#20540;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20854;&#36816;&#34892;&#36712;&#36947;&#38590;&#20197;&#32422;&#26463;&#65292;&#36890;&#24120;&#20855;&#26377;&#36739;&#39640;&#30340;&#20542;&#35282;&#21644;&#30456;&#23545;&#36895;&#24230;&#65292;&#20351;&#29992;&#20256;&#32479;&#30340;&#20154;&#22312;&#29615;&#36335;&#26041;&#27861;&#25506;&#32034;ISOs&#20855;&#26377;&#30456;&#24403;&#22823;&#30340;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#31070;&#32463;&#20250;&#21512;&#30340;&#28145;&#24230;&#23398;&#20064;&#23548;&#33322;&#21644;&#25511;&#21046;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#23454;&#26102;&#20013;&#20197;&#21487;&#38752;&#12289;&#20934;&#30830;&#21644;&#33258;&#20027;&#30340;&#26041;&#24335;&#36973;&#36935;&#24555;&#36895;&#31227;&#21160;&#30340;&#29289;&#20307;&#65292;&#21253;&#25324;ISOs&#12290;&#23427;&#22312;&#22522;&#20110;&#35889;&#24402;&#19968;&#21270;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#24341;&#23548;&#31574;&#30053;&#20043;&#19978;&#20351;&#29992;&#28857;&#26368;&#23567;&#33539;&#25968;&#36861;&#36394;&#25511;&#21046;&#65292;&#20854;&#20013;&#21442;&#25968;&#36890;&#36807;&#30452;&#25509;&#24809;&#32602;MPC&#29366;&#24577;&#36712;&#36857;&#36319;&#36394;&#35823;&#24046;&#30340;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#35843;&#20248;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#31070;&#32463;&#20250;&#21512;&#22312;&#39044;&#26399;&#30340;&#39134;&#34892;&#22120;&#20132;&#20184;&#35823;&#24046;&#19978;&#25552;&#20379;&#20102;&#39640;&#27010;&#29575;&#25351;&#25968;&#19978;&#30028;&#65292;&#20854;&#35777;&#26126;&#21033;&#29992;&#20102;&#38543;&#26426;&#36882;&#22686;&#31283;&#23450;&#24615;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Interstellar objects (ISOs) are likely representatives of primitive materials invaluable in understanding exoplanetary star systems. Due to their poorly constrained orbits with generally high inclinations and relative velocities, however, exploring ISOs with conventional human-in-the-loop approaches is significantly challenging. This paper presents Neural-Rendezvous, a deep learning-based guidance and control framework for encountering fast-moving objects, including ISOs, robustly, accurately, and autonomously in real time. It uses pointwise minimum norm tracking control on top of a guidance policy modeled by a spectrally-normalized deep neural network, where its hyperparameters are tuned with a loss function directly penalizing the MPC state trajectory tracking error. We show that Neural-Rendezvous provides a high probability exponential bound on the expected spacecraft delivery error, the proof of which leverages stochastic incremental stability analysis. In particular, it is used to
&lt;/p&gt;</description></item></channel></rss>