<rss version="2.0"><channel><title>Chat Arxiv cs.RO</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.RO</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;Diffusion-ES&#26041;&#27861;&#65292;&#23427;&#32467;&#21512;&#20102;&#26080;&#26799;&#24230;&#20248;&#21270;&#21644;&#36712;&#36857;&#21435;&#22122;&#25216;&#26415;&#65292;&#29992;&#20110;&#20248;&#21270;&#40657;&#30418;&#38750;&#21487;&#24494;&#30446;&#26631;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#20174;&#25193;&#25955;&#27169;&#22411;&#20013;&#37319;&#26679;&#36712;&#36857;&#65292;&#24182;&#20351;&#29992;&#40657;&#30418;&#22870;&#21169;&#20989;&#25968;&#23545;&#20854;&#36827;&#34892;&#35780;&#20998;&#65292;&#23454;&#29616;&#20102;&#26356;&#39640;&#30340;&#22810;&#26679;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.06559</link><description>&lt;p&gt;
Diffusion-ES:&#22522;&#20110;&#25193;&#25955;&#30340;&#38646;&#26799;&#24230;&#35268;&#21010;&#29992;&#20110;&#33258;&#21160;&#39550;&#39542;&#21644;&#38646;&#38454;&#25351;&#20196;&#36319;&#38543;
&lt;/p&gt;
&lt;p&gt;
Diffusion-ES: Gradient-free Planning with Diffusion for Autonomous Driving and Zero-Shot Instruction Following
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06559
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;Diffusion-ES&#26041;&#27861;&#65292;&#23427;&#32467;&#21512;&#20102;&#26080;&#26799;&#24230;&#20248;&#21270;&#21644;&#36712;&#36857;&#21435;&#22122;&#25216;&#26415;&#65292;&#29992;&#20110;&#20248;&#21270;&#40657;&#30418;&#38750;&#21487;&#24494;&#30446;&#26631;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#20174;&#25193;&#25955;&#27169;&#22411;&#20013;&#37319;&#26679;&#36712;&#36857;&#65292;&#24182;&#20351;&#29992;&#40657;&#30418;&#22870;&#21169;&#20989;&#25968;&#23545;&#20854;&#36827;&#34892;&#35780;&#20998;&#65292;&#23454;&#29616;&#20102;&#26356;&#39640;&#30340;&#22810;&#26679;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#22312;&#20915;&#31574;&#21644;&#25511;&#21046;&#20013;&#23545;&#22797;&#26434;&#21644;&#22810;&#27169;&#24577;&#36712;&#36857;&#20998;&#24067;&#24314;&#27169;&#26377;&#24456;&#24378;&#20248;&#21183;&#12290;&#26368;&#36817;&#25552;&#20986;&#20102;&#22870;&#21169;&#26799;&#24230;&#24341;&#23548;&#21435;&#22122;&#26041;&#27861;&#65292;&#29992;&#20110;&#20135;&#29983;&#22312;&#25193;&#25955;&#27169;&#22411;&#25152;&#25429;&#33719;&#30340;&#25968;&#25454;&#20998;&#24067;&#19979;&#65292;&#21516;&#26102;&#26368;&#22823;&#21270;&#21487;&#24494;&#20998;&#22870;&#21169;&#20989;&#25968;&#21644;&#20284;&#28982;&#24615;&#30340;&#36712;&#36857;&#12290;&#22870;&#21169;&#26799;&#24230;&#24341;&#23548;&#21435;&#22122;&#38656;&#35201;&#19968;&#20010;&#36866;&#21512;&#20110;&#28165;&#27905;&#21644;&#22122;&#22768;&#26679;&#26412;&#30340;&#21487;&#24494;&#20998;&#22870;&#21169;&#20989;&#25968;&#65292;&#20174;&#32780;&#38480;&#21046;&#20102;&#20854;&#20316;&#20026;&#19968;&#31181;&#36890;&#29992;&#36712;&#36857;&#20248;&#21270;&#22120;&#30340;&#36866;&#29992;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;DiffusionES&#65292;&#19968;&#31181;&#23558;&#26080;&#26799;&#24230;&#20248;&#21270;&#21644;&#36712;&#36857;&#21435;&#22122;&#30456;&#32467;&#21512;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#25968;&#25454;&#27969;&#24418;&#20013;&#20248;&#21270;&#40657;&#30418;&#38750;&#21487;&#24494;&#30446;&#26631;&#12290;Diffusion-ES&#20174;&#25193;&#25955;&#27169;&#22411;&#20013;&#37319;&#26679;&#36712;&#36857;&#65292;&#24182;&#20351;&#29992;&#40657;&#30418;&#22870;&#21169;&#20989;&#25968;&#23545;&#20854;&#36827;&#34892;&#35780;&#20998;&#12290;&#23427;&#36890;&#36807;&#25130;&#26029;&#25193;&#25955;&#36807;&#31243;&#23545;&#24471;&#20998;&#39640;&#30340;&#36712;&#36857;&#36827;&#34892;&#21464;&#24322;&#65292;&#35813;&#36807;&#31243;&#24212;&#29992;&#23569;&#37327;&#30340;&#22122;&#22768;&#21644;&#21435;&#22122;&#27493;&#39588;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#26356;&#39640;&#30340;&#22810;&#26679;&#24615;&#21644;&#26356;&#22909;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models excel at modeling complex and multimodal trajectory distributions for decision-making and control. Reward-gradient guided denoising has been recently proposed to generate trajectories that maximize both a differentiable reward function and the likelihood under the data distribution captured by a diffusion model. Reward-gradient guided denoising requires a differentiable reward function fitted to both clean and noised samples, limiting its applicability as a general trajectory optimizer. In this paper, we propose DiffusionES, a method that combines gradient-free optimization with trajectory denoising to optimize black-box non-differentiable objectives while staying in the data manifold. Diffusion-ES samples trajectories during evolutionary search from a diffusion model and scores them using a black-box reward function. It mutates high-scoring trajectories using a truncated diffusion process that applies a small number of noising and denoising steps, allowing for much mo
&lt;/p&gt;</description></item><item><title>NOD-TAMP&#26159;&#19968;&#20010;&#22522;&#20110;TAMP&#30340;&#26694;&#26550;&#65292;&#21033;&#29992;&#31070;&#32463;&#29289;&#20307;&#25551;&#36848;&#31526;&#26469;&#35299;&#20915;&#22797;&#26434;&#25805;&#32437;&#20219;&#21153;&#20013;&#30340;&#27867;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#20174;&#23569;&#37327;&#20154;&#31867;&#28436;&#31034;&#20013;&#25552;&#21462;&#36712;&#36857;&#24182;&#36827;&#34892;&#35843;&#25972;&#65292;&#26377;&#25928;&#35299;&#20915;&#20102;&#38271;&#26102;&#31243;&#20219;&#21153;&#30340;&#25361;&#25112;&#65292;&#24182;&#22312;&#27169;&#25311;&#29615;&#22659;&#20013;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2311.01530</link><description>&lt;p&gt;
NOD-TAMP:&#22810;&#27493;&#39588;&#25805;&#32437;&#35268;&#21010;&#20013;&#30340;&#31070;&#32463;&#29289;&#20307;&#25551;&#36848;&#31526;
&lt;/p&gt;
&lt;p&gt;
NOD-TAMP: Multi-Step Manipulation Planning with Neural Object Descriptors. (arXiv:2311.01530v1 [cs.RO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01530
&lt;/p&gt;
&lt;p&gt;
NOD-TAMP&#26159;&#19968;&#20010;&#22522;&#20110;TAMP&#30340;&#26694;&#26550;&#65292;&#21033;&#29992;&#31070;&#32463;&#29289;&#20307;&#25551;&#36848;&#31526;&#26469;&#35299;&#20915;&#22797;&#26434;&#25805;&#32437;&#20219;&#21153;&#20013;&#30340;&#27867;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#20174;&#23569;&#37327;&#20154;&#31867;&#28436;&#31034;&#20013;&#25552;&#21462;&#36712;&#36857;&#24182;&#36827;&#34892;&#35843;&#25972;&#65292;&#26377;&#25928;&#35299;&#20915;&#20102;&#38271;&#26102;&#31243;&#20219;&#21153;&#30340;&#25361;&#25112;&#65292;&#24182;&#22312;&#27169;&#25311;&#29615;&#22659;&#20013;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23478;&#23621;&#21644;&#24037;&#21378;&#29615;&#22659;&#20013;&#24320;&#21457;&#22797;&#26434;&#25805;&#32437;&#20219;&#21153;&#30340;&#26234;&#33021;&#26426;&#22120;&#20154;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;&#38271;&#26102;&#31243;&#20219;&#21153;&#12289;&#25509;&#35302;&#20016;&#23500;&#30340;&#25805;&#32437;&#20197;&#21450;&#38656;&#35201;&#22312;&#21508;&#31181;&#29289;&#20307;&#24418;&#29366;&#21644;&#22330;&#26223;&#24067;&#23616;&#20043;&#38388;&#36827;&#34892;&#27867;&#21270;&#12290;&#34429;&#28982;&#20219;&#21153;&#21644;&#36816;&#21160;&#35268;&#21010;&#65288;TAMP&#65289;&#25552;&#20379;&#20102;&#19968;&#20010;&#26377;&#24076;&#26395;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#26159;&#23427;&#30340;&#20551;&#35774;&#65292;&#22914;&#21160;&#21147;&#23398;&#27169;&#22411;&#65292;&#38480;&#21046;&#20102;&#23427;&#22312;&#26032;&#39062;&#32972;&#26223;&#20013;&#30340;&#36866;&#24212;&#24615;&#12290;&#31070;&#32463;&#29289;&#20307;&#25551;&#36848;&#31526;&#65288;NODs&#65289;&#22312;&#29289;&#20307;&#21644;&#22330;&#26223;&#27867;&#21270;&#26041;&#38754;&#26174;&#31034;&#20986;&#20102;&#28508;&#21147;&#65292;&#20294;&#22312;&#22788;&#29702;&#26356;&#24191;&#27867;&#20219;&#21153;&#26041;&#38754;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#22522;&#20110;TAMP&#30340;&#26694;&#26550;NOD-TAMP&#20174;&#23569;&#25968;&#20154;&#31867;&#28436;&#31034;&#20013;&#25552;&#21462;&#30701;&#30340;&#25805;&#32437;&#36712;&#36857;&#65292;&#20351;&#29992;NOD&#29305;&#24449;&#26469;&#35843;&#25972;&#36825;&#20123;&#36712;&#36857;&#65292;&#24182;&#32452;&#21512;&#23427;&#20204;&#26469;&#35299;&#20915;&#24191;&#27867;&#30340;&#38271;&#26102;&#31243;&#20219;&#21153;&#12290;&#22312;&#27169;&#25311;&#29615;&#22659;&#20013;&#39564;&#35777;&#21518;&#65292;NOD-TAMP&#26377;&#25928;&#24212;&#23545;&#21508;&#31181;&#25361;&#25112;&#65292;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#24314;&#31435;&#20102;&#19968;&#20010;&#24378;&#26377;&#21147;&#30340;&#25805;&#32437;&#35268;&#21010;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
Developing intelligent robots for complex manipulation tasks in household and factory settings remains challenging due to long-horizon tasks, contact-rich manipulation, and the need to generalize across a wide variety of object shapes and scene layouts. While Task and Motion Planning (TAMP) offers a promising solution, its assumptions such as kinodynamic models limit applicability in novel contexts. Neural object descriptors (NODs) have shown promise in object and scene generalization but face limitations in addressing broader tasks. Our proposed TAMP-based framework, NOD-TAMP, extracts short manipulation trajectories from a handful of human demonstrations, adapts these trajectories using NOD features, and composes them to solve broad long-horizon tasks. Validated in a simulation environment, NOD-TAMP effectively tackles varied challenges and outperforms existing methods, establishing a cohesive framework for manipulation planning. For videos and other supplemental material, see the pr
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#32508;&#36848;&#37325;&#26032;&#24605;&#32771;&#20102;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#33258;&#21160;&#39550;&#39542;&#31995;&#32479;&#20013;&#39044;&#27979;&#21644;&#35268;&#21010;&#30340;&#25972;&#21512;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#23558;&#20854;&#20316;&#20026;&#30456;&#20114;&#20381;&#36182;&#30340;&#32852;&#21512;&#27493;&#39588;&#26469;&#25552;&#39640;&#23433;&#20840;&#24615;&#12289;&#25928;&#29575;&#24615;&#21644;&#33298;&#36866;&#24615;&#30340;&#24517;&#35201;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.05731</link><description>&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#33258;&#21160;&#39550;&#39542;&#31995;&#32479;&#20013;&#30340;&#39044;&#27979;&#21644;&#35268;&#21010;&#30340;&#25972;&#21512;&#65306;&#19968;&#39033;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Rethinking Integration of Prediction and Planning in Deep Learning-Based Automated Driving Systems: A Review. (arXiv:2308.05731v1 [cs.RO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05731
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#32508;&#36848;&#37325;&#26032;&#24605;&#32771;&#20102;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#33258;&#21160;&#39550;&#39542;&#31995;&#32479;&#20013;&#39044;&#27979;&#21644;&#35268;&#21010;&#30340;&#25972;&#21512;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#23558;&#20854;&#20316;&#20026;&#30456;&#20114;&#20381;&#36182;&#30340;&#32852;&#21512;&#27493;&#39588;&#26469;&#25552;&#39640;&#23433;&#20840;&#24615;&#12289;&#25928;&#29575;&#24615;&#21644;&#33298;&#36866;&#24615;&#30340;&#24517;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#39550;&#39542;&#26377;&#21487;&#33021;&#24443;&#24213;&#25913;&#21464;&#20010;&#20154;&#12289;&#20844;&#20849;&#21644;&#36135;&#36816;&#20132;&#36890;&#30340;&#26041;&#24335;&#12290;&#38500;&#20102;&#24863;&#30693;&#29615;&#22659;&#30340;&#24040;&#22823;&#25361;&#25112;&#22806;&#65292;&#21363;&#20934;&#30830;&#22320;&#20351;&#29992;&#21487;&#29992;&#30340;&#20256;&#24863;&#22120;&#25968;&#25454;&#24863;&#30693;&#29615;&#22659;&#65292;&#33258;&#21160;&#39550;&#39542;&#36824;&#21253;&#25324;&#35268;&#21010;&#19968;&#20010;&#23433;&#20840;&#12289;&#33298;&#36866;&#21644;&#39640;&#25928;&#30340;&#36816;&#21160;&#36712;&#36857;&#12290;&#20026;&#20102;&#20419;&#36827;&#23433;&#20840;&#21644;&#36827;&#27493;&#65292;&#35768;&#22810;&#24037;&#20316;&#20381;&#36182;&#20110;&#27169;&#22359;&#21270;&#30340;&#20132;&#36890;&#26410;&#26469;&#36816;&#21160;&#30340;&#39044;&#27979;&#12290;&#27169;&#22359;&#21270;&#30340;&#33258;&#21160;&#39550;&#39542;&#31995;&#32479;&#36890;&#24120;&#23558;&#39044;&#27979;&#21644;&#35268;&#21010;&#20316;&#20026;&#39034;&#24207;&#30340;&#29420;&#31435;&#20219;&#21153;&#22788;&#29702;&#12290;&#34429;&#28982;&#36825;&#32771;&#34385;&#20102;&#21608;&#22260;&#20132;&#36890;&#23545;&#33258;&#36710;&#30340;&#24433;&#21709;&#65292;&#20294;&#23427;&#26410;&#33021;&#39044;&#27979;&#20132;&#36890;&#21442;&#19982;&#32773;&#23545;&#33258;&#36710;&#34892;&#20026;&#30340;&#21453;&#24212;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#23558;&#39044;&#27979;&#21644;&#35268;&#21010;&#25972;&#21512;&#20026;&#30456;&#20114;&#20381;&#36182;&#30340;&#32852;&#21512;&#27493;&#39588;&#26159;&#23454;&#29616;&#23433;&#20840;&#12289;&#39640;&#25928;&#21644;&#33298;&#36866;&#39550;&#39542;&#25152;&#24517;&#38656;&#30340;&#12290;&#34429;&#28982;&#26377;&#21508;&#31181;&#27169;&#22411;&#23454;&#29616;&#20102;&#36825;&#31181;&#38598;&#25104;&#31995;&#32479;&#65292;&#20294;&#23545;&#19981;&#21516;&#21407;&#29702;&#30340;&#20840;&#38754;&#27010;&#36848;&#21644;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#32570;&#20047;&#12290;
&lt;/p&gt;
&lt;p&gt;
Automated driving has the potential to revolutionize personal, public, and freight mobility. Besides the enormous challenge of perception, i.e. accurately perceiving the environment using available sensor data, automated driving comprises planning a safe, comfortable, and efficient motion trajectory. To promote safety and progress, many works rely on modules that predict the future motion of surrounding traffic. Modular automated driving systems commonly handle prediction and planning as sequential separate tasks. While this accounts for the influence of surrounding traffic on the ego-vehicle, it fails to anticipate the reactions of traffic participants to the ego-vehicle's behavior. Recent works suggest that integrating prediction and planning in an interdependent joint step is necessary to achieve safe, efficient, and comfortable driving. While various models implement such integrated systems, a comprehensive overview and theoretical understanding of different principles are lacking.
&lt;/p&gt;</description></item></channel></rss>