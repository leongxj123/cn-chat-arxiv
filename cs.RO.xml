<rss version="2.0"><channel><title>Chat Arxiv cs.RO</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.RO</description><item><title>RFMP&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#27169;&#22411;&#65292;&#21033;&#29992;&#27969;&#21305;&#37197;&#30340;&#20248;&#21183;&#22312;&#26426;&#22120;&#20154;&#35270;&#35273;&#36816;&#21160;&#31574;&#30053;&#20013;&#20855;&#26377;&#39640;&#25928;&#35757;&#32451;&#21644;&#25512;&#26029;&#33021;&#21147;&#65292;&#24182;&#36890;&#36807;&#34701;&#21512;&#40654;&#26364;&#27969;&#24418;&#19978;&#30340;&#20960;&#20309;&#24847;&#35782;&#65292;&#25552;&#20379;&#26356;&#24179;&#28369;&#30340;&#21160;&#20316;&#36712;&#36857;&#12290;</title><link>https://arxiv.org/abs/2403.10672</link><description>&lt;p&gt;
&#29992;&#20110;&#26426;&#22120;&#20154;&#36816;&#21160;&#23398;&#20064;&#30340;&#40654;&#26364;&#27969;&#21305;&#37197;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Riemannian Flow Matching Policy for Robot Motion Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10672
&lt;/p&gt;
&lt;p&gt;
RFMP&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#27169;&#22411;&#65292;&#21033;&#29992;&#27969;&#21305;&#37197;&#30340;&#20248;&#21183;&#22312;&#26426;&#22120;&#20154;&#35270;&#35273;&#36816;&#21160;&#31574;&#30053;&#20013;&#20855;&#26377;&#39640;&#25928;&#35757;&#32451;&#21644;&#25512;&#26029;&#33021;&#21147;&#65292;&#24182;&#36890;&#36807;&#34701;&#21512;&#40654;&#26364;&#27969;&#24418;&#19978;&#30340;&#20960;&#20309;&#24847;&#35782;&#65292;&#25552;&#20379;&#26356;&#24179;&#28369;&#30340;&#21160;&#20316;&#36712;&#36857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#40654;&#26364;&#27969;&#21305;&#37197;&#31574;&#30053;&#65288;RFMP&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#27169;&#22411;&#65292;&#29992;&#20110;&#23398;&#20064;&#21644;&#21512;&#25104;&#26426;&#22120;&#20154;&#35270;&#35273;&#36816;&#21160;&#31574;&#30053;&#12290;RFMP&#21033;&#29992;&#20102;&#27969;&#21305;&#37197;&#26041;&#27861;&#30340;&#39640;&#25928;&#35757;&#32451;&#21644;&#25512;&#26029;&#33021;&#21147;&#12290;&#36890;&#36807;&#35774;&#35745;&#65292;RFMP&#32487;&#25215;&#20102;&#27969;&#21305;&#37197;&#30340;&#20248;&#21183;&#65306;&#33021;&#22815;&#32534;&#30721;&#39640;&#32500;&#24230;&#22810;&#27169;&#24577;&#20998;&#24067;&#65292;&#22312;&#26426;&#22120;&#20154;&#20219;&#21153;&#20013;&#24120;&#35265;&#65292;&#24182;&#19988;&#20855;&#26377;&#38750;&#24120;&#31616;&#21333;&#21644;&#24555;&#36895;&#30340;&#25512;&#26029;&#36807;&#31243;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;RFMP&#22312;&#22522;&#20110;&#29366;&#24577;&#21644;&#22522;&#20110;&#35270;&#35273;&#30340;&#26426;&#22120;&#20154;&#36816;&#21160;&#31574;&#30053;&#20013;&#30340;&#36866;&#29992;&#24615;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#30001;&#20110;&#26426;&#22120;&#20154;&#29366;&#24577;&#23384;&#22312;&#20110;&#40654;&#26364;&#27969;&#24418;&#19978;&#65292;RFMP&#22312;&#26412;&#36136;&#19978;&#34701;&#21512;&#20102;&#20960;&#20309;&#24847;&#35782;&#65292;&#36825;&#23545;&#20110;&#29616;&#23454;&#26426;&#22120;&#20154;&#20219;&#21153;&#33267;&#20851;&#37325;&#35201;&#12290;&#20026;&#20102;&#35780;&#20272;RFMP&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#20004;&#20010;&#27010;&#24565;&#39564;&#35777;&#23454;&#39564;&#65292;&#23558;&#20854;&#24615;&#33021;&#19982;&#25193;&#25955;&#31574;&#30053;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#23613;&#31649;&#36825;&#20004;&#31181;&#26041;&#27861;&#37117;&#25104;&#21151;&#22320;&#23398;&#20064;&#20102;&#25152;&#32771;&#34385;&#30340;&#20219;&#21153;&#65292;&#20294;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;RFMP&#25552;&#20379;&#20102;&#26356;&#24179;&#28369;&#30340;&#21160;&#20316;&#36712;&#36857;&#65292;&#26174;&#33879;&#22320;&#25552;&#39640;&#20102;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10672v1 Announce Type: cross  Abstract: We introduce Riemannian Flow Matching Policies (RFMP), a novel model for learning and synthesizing robot visuomotor policies. RFMP leverages the efficient training and inference capabilities of flow matching methods. By design, RFMP inherits the strengths of flow matching: the ability to encode high-dimensional multimodal distributions, commonly encountered in robotic tasks, and a very simple and fast inference process. We demonstrate the applicability of RFMP to both state-based and vision-conditioned robot motion policies. Notably, as the robot state resides on a Riemannian manifold, RFMP inherently incorporates geometric awareness, which is crucial for realistic robotic tasks. To evaluate RFMP, we conduct two proof-of-concept experiments, comparing its performance against Diffusion Policies. Although both approaches successfully learn the considered tasks, our results show that RFMP provides smoother action trajectories with signifi
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32467;&#26500;&#21270;DNN&#30340;&#25511;&#21046;&#22120;&#65292;&#36890;&#36807;&#35774;&#35745;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#30830;&#20445;&#38381;&#29615;&#31283;&#23450;&#24615;&#65292;&#24182;&#36827;&#19968;&#27493;&#20248;&#21270;&#21442;&#25968;&#20197;&#23454;&#29616;&#25913;&#36827;&#30340;&#25511;&#21046;&#24615;&#33021;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#20851;&#20110;&#36319;&#36394;&#35823;&#24046;&#30340;&#26126;&#30830;&#19978;&#38480;&#12290;</title><link>https://arxiv.org/abs/2403.00381</link><description>&lt;p&gt;
&#22522;&#20110;&#32467;&#26500;&#21270;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#25289;&#26684;&#26391;&#26085;&#31995;&#32479;&#21453;&#27493;&#36712;&#36857;&#36319;&#36394;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Structured Deep Neural Networks-Based Backstepping Trajectory Tracking Control for Lagrangian Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00381
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32467;&#26500;&#21270;DNN&#30340;&#25511;&#21046;&#22120;&#65292;&#36890;&#36807;&#35774;&#35745;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#30830;&#20445;&#38381;&#29615;&#31283;&#23450;&#24615;&#65292;&#24182;&#36827;&#19968;&#27493;&#20248;&#21270;&#21442;&#25968;&#20197;&#23454;&#29616;&#25913;&#36827;&#30340;&#25511;&#21046;&#24615;&#33021;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#20851;&#20110;&#36319;&#36394;&#35823;&#24046;&#30340;&#26126;&#30830;&#19978;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#36234;&#26469;&#36234;&#22810;&#22320;&#34987;&#29992;&#20110;&#23398;&#20064;&#25511;&#21046;&#22120;&#65292;&#22240;&#20026;&#20854;&#20986;&#33394;&#30340;&#36924;&#36817;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#40657;&#30418;&#29305;&#24615;&#23545;&#38381;&#29615;&#31283;&#23450;&#24615;&#20445;&#35777;&#21644;&#24615;&#33021;&#20998;&#26512;&#26500;&#25104;&#20102;&#37325;&#35201;&#25361;&#25112;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#32467;&#26500;&#21270;DNN&#30340;&#25511;&#21046;&#22120;&#65292;&#29992;&#20110;&#37319;&#29992;&#21453;&#25512;&#25216;&#26415;&#23454;&#29616;&#25289;&#26684;&#26391;&#26085;&#31995;&#32479;&#30340;&#36712;&#36857;&#36319;&#36394;&#25511;&#21046;&#12290;&#36890;&#36807;&#36866;&#24403;&#35774;&#35745;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#65292;&#25152;&#25552;&#20986;&#30340;&#25511;&#21046;&#22120;&#21487;&#20197;&#30830;&#20445;&#20219;&#20309;&#20860;&#23481;&#30340;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#23454;&#29616;&#38381;&#29615;&#31283;&#23450;&#24615;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#36827;&#19968;&#27493;&#20248;&#21270;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#65292;&#21487;&#20197;&#23454;&#29616;&#26356;&#22909;&#30340;&#25511;&#21046;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20851;&#20110;&#36319;&#36394;&#35823;&#24046;&#30340;&#26126;&#30830;&#19978;&#38480;&#65292;&#36825;&#20801;&#35768;&#25105;&#20204;&#36890;&#36807;&#36866;&#24403;&#36873;&#25321;&#25511;&#21046;&#21442;&#25968;&#26469;&#23454;&#29616;&#25152;&#38656;&#30340;&#36319;&#36394;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#24403;&#31995;&#32479;&#27169;&#22411;&#26410;&#30693;&#26102;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#25289;&#26684;&#26391;&#26085;&#31070;&#32463;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00381v1 Announce Type: cross  Abstract: Deep neural networks (DNN) are increasingly being used to learn controllers due to their excellent approximation capabilities. However, their black-box nature poses significant challenges to closed-loop stability guarantees and performance analysis. In this paper, we introduce a structured DNN-based controller for the trajectory tracking control of Lagrangian systems using backing techniques. By properly designing neural network structures, the proposed controller can ensure closed-loop stability for any compatible neural network parameters. In addition, improved control performance can be achieved by further optimizing neural network parameters. Besides, we provide explicit upper bounds on tracking errors in terms of controller parameters, which allows us to achieve the desired tracking performance by properly selecting the controller parameters. Furthermore, when system models are unknown, we propose an improved Lagrangian neural net
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#32508;&#36848;&#20102;&#26426;&#22120;&#20154;&#36328;&#39046;&#22495;&#31574;&#30053;&#36716;&#31227;&#26041;&#27861;&#65292;&#35752;&#35770;&#20102;&#20174;&#30446;&#26631;&#39046;&#22495;&#37319;&#38598;&#26080;&#20559;&#25968;&#25454;&#30340;&#25361;&#25112;&#65292;&#20197;&#21450;&#20174;&#28304;&#39046;&#22495;&#33719;&#21462;&#25968;&#25454;&#30340;&#25104;&#26412;&#25928;&#30410;&#24615;&#12290;&#21516;&#26102;&#65292;&#24635;&#32467;&#20102;&#19981;&#21516;&#38382;&#39064;&#35774;&#32622;&#19979;&#30340;&#35774;&#35745;&#32771;&#34385;&#21644;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.04580</link><description>&lt;p&gt;
&#26426;&#22120;&#20154;&#36328;&#39046;&#22495;&#31574;&#30053;&#36716;&#31227;&#32508;&#21512;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
A Comprehensive Survey of Cross-Domain Policy Transfer for Embodied Agents
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04580
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#32508;&#36848;&#20102;&#26426;&#22120;&#20154;&#36328;&#39046;&#22495;&#31574;&#30053;&#36716;&#31227;&#26041;&#27861;&#65292;&#35752;&#35770;&#20102;&#20174;&#30446;&#26631;&#39046;&#22495;&#37319;&#38598;&#26080;&#20559;&#25968;&#25454;&#30340;&#25361;&#25112;&#65292;&#20197;&#21450;&#20174;&#28304;&#39046;&#22495;&#33719;&#21462;&#25968;&#25454;&#30340;&#25104;&#26412;&#25928;&#30410;&#24615;&#12290;&#21516;&#26102;&#65292;&#24635;&#32467;&#20102;&#19981;&#21516;&#38382;&#39064;&#35774;&#32622;&#19979;&#30340;&#35774;&#35745;&#32771;&#34385;&#21644;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#21644;&#20855;&#36523;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#30340;&#34028;&#21187;&#21457;&#23637;&#24341;&#21457;&#20102;&#23545;&#22823;&#37327;&#25968;&#25454;&#30340;&#38656;&#27714;&#22686;&#21152;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#26114;&#36149;&#30340;&#25968;&#25454;&#25910;&#38598;&#36807;&#31243;&#21644;&#20005;&#26684;&#30340;&#23433;&#20840;&#35201;&#27714;&#65292;&#20174;&#30446;&#26631;&#39046;&#22495;&#25910;&#38598;&#36275;&#22815;&#30340;&#26080;&#20559;&#25968;&#25454;&#20173;&#28982;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;&#22240;&#27492;&#65292;&#30740;&#31350;&#20154;&#21592;&#32463;&#24120;&#37319;&#29992;&#26131;&#20110;&#33719;&#21462;&#30340;&#28304;&#39046;&#22495;&#25968;&#25454;&#65288;&#20363;&#22914;&#27169;&#25311;&#21644;&#23454;&#39564;&#23460;&#29615;&#22659;&#65289;&#65292;&#20197;&#23454;&#29616;&#25104;&#26412;&#25928;&#30410;&#30340;&#25968;&#25454;&#33719;&#21462;&#21644;&#24555;&#36895;&#27169;&#22411;&#36845;&#20195;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#28304;&#39046;&#22495;&#30340;&#29615;&#22659;&#21644;&#20855;&#36523;&#26041;&#24335;&#21487;&#33021;&#19982;&#30446;&#26631;&#39046;&#22495;&#30340;&#29305;&#24449;&#30456;&#24046;&#24456;&#22823;&#65292;&#24378;&#35843;&#20102;&#26377;&#25928;&#30340;&#36328;&#39046;&#22495;&#31574;&#30053;&#36716;&#31227;&#26041;&#27861;&#30340;&#38656;&#27714;&#12290;&#26412;&#25991;&#23545;&#29616;&#26377;&#30340;&#36328;&#39046;&#22495;&#31574;&#30053;&#36716;&#31227;&#26041;&#27861;&#36827;&#34892;&#20102;&#31995;&#32479;&#32508;&#36848;&#12290;&#36890;&#36807;&#23545;&#39046;&#22495;&#24046;&#36317;&#30340;&#31934;&#32454;&#20998;&#31867;&#65292;&#25105;&#20204;&#24635;&#32467;&#20102;&#27599;&#20010;&#38382;&#39064;&#35774;&#32622;&#30340;&#24635;&#20307;&#35265;&#35299;&#21644;&#35774;&#35745;&#32771;&#34385;&#12290;&#25105;&#20204;&#36824;&#23601;&#20351;&#29992;&#30340;&#20851;&#38190;&#26041;&#27861;&#36827;&#34892;&#20102;&#39640;&#23618;&#27425;&#35752;&#35770;
&lt;/p&gt;
&lt;p&gt;
The burgeoning fields of robot learning and embodied AI have triggered an increasing demand for large quantities of data. However, collecting sufficient unbiased data from the target domain remains a challenge due to costly data collection processes and stringent safety requirements. Consequently, researchers often resort to data from easily accessible source domains, such as simulation and laboratory environments, for cost-effective data acquisition and rapid model iteration. Nevertheless, the environments and embodiments of these source domains can be quite different from their target domain counterparts, underscoring the need for effective cross-domain policy transfer approaches. In this paper, we conduct a systematic review of existing cross-domain policy transfer methods. Through a nuanced categorization of domain gaps, we encapsulate the overarching insights and design considerations of each problem setting. We also provide a high-level discussion about the key methodologies used
&lt;/p&gt;</description></item></channel></rss>