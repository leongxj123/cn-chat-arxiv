<rss version="2.0"><channel><title>Chat Arxiv cs.RO</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.RO</description><item><title>&#25552;&#20986;&#20102;MATS-Gym&#65292;&#19968;&#20010;&#29992;&#20110;&#22312;CARLA&#20013;&#35757;&#32451;&#26234;&#33021;&#20307;&#30340;&#22810;&#26234;&#33021;&#20307;&#20132;&#36890;&#22330;&#26223;&#26694;&#26550;&#65292;&#33021;&#22815;&#33258;&#21160;&#29983;&#25104;&#20855;&#26377;&#21487;&#21464;&#26234;&#33021;&#20307;&#25968;&#37327;&#30340;&#20132;&#36890;&#22330;&#26223;&#24182;&#25972;&#21512;&#20102;&#21508;&#31181;&#29616;&#26377;&#30340;&#20132;&#36890;&#22330;&#26223;&#25551;&#36848;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.17805</link><description>&lt;p&gt;
&#22810;&#26234;&#33021;&#20307;&#33258;&#20027;&#39550;&#39542;&#22330;&#26223;&#39537;&#21160;&#30340;&#35838;&#31243;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Scenario-Based Curriculum Generation for Multi-Agent Autonomous Driving
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17805
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;MATS-Gym&#65292;&#19968;&#20010;&#29992;&#20110;&#22312;CARLA&#20013;&#35757;&#32451;&#26234;&#33021;&#20307;&#30340;&#22810;&#26234;&#33021;&#20307;&#20132;&#36890;&#22330;&#26223;&#26694;&#26550;&#65292;&#33021;&#22815;&#33258;&#21160;&#29983;&#25104;&#20855;&#26377;&#21487;&#21464;&#26234;&#33021;&#20307;&#25968;&#37327;&#30340;&#20132;&#36890;&#22330;&#26223;&#24182;&#25972;&#21512;&#20102;&#21508;&#31181;&#29616;&#26377;&#30340;&#20132;&#36890;&#22330;&#26223;&#25551;&#36848;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#26679;&#21270;&#21644;&#22797;&#26434;&#35757;&#32451;&#22330;&#26223;&#30340;&#33258;&#21160;&#21270;&#29983;&#25104;&#22312;&#35768;&#22810;&#22797;&#26434;&#23398;&#20064;&#20219;&#21153;&#20013;&#26159;&#37325;&#35201;&#30340;&#12290;&#29305;&#21035;&#26159;&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#24212;&#29992;&#39046;&#22495;&#65292;&#22914;&#33258;&#20027;&#39550;&#39542;&#65292;&#33258;&#21160;&#29983;&#25104;&#35838;&#31243;&#34987;&#35748;&#20026;&#23545;&#33719;&#24471;&#24378;&#20581;&#21644;&#36890;&#29992;&#31574;&#30053;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#22312;&#20805;&#28385;&#25361;&#25112;&#30340;&#20223;&#30495;&#29615;&#22659;&#20013;&#65292;&#20026;&#20132;&#36890;&#22330;&#26223;&#20013;&#30340;&#22810;&#20010;&#24322;&#26500;&#26234;&#33021;&#20307;&#36827;&#34892;&#35774;&#35745;&#36890;&#24120;&#34987;&#35748;&#20026;&#26159;&#19968;&#39033;&#32321;&#29712;&#19988;&#32791;&#26102;&#30340;&#20219;&#21153;&#12290;&#22312;&#25105;&#20204;&#30340;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;MATS-Gym&#65292;&#19968;&#20010;&#29992;&#20110;&#22312;&#39640;&#20445;&#30495;&#39550;&#39542;&#27169;&#25311;&#22120;CARLA&#20013;&#35757;&#32451;&#26234;&#33021;&#20307;&#30340;&#22810;&#26234;&#33021;&#20307;&#20132;&#36890;&#22330;&#26223;&#26694;&#26550;&#12290;MATS-Gym&#26159;&#19968;&#20010;&#29992;&#20110;&#33258;&#20027;&#39550;&#39542;&#30340;&#22810;&#26234;&#33021;&#20307;&#35757;&#32451;&#26694;&#26550;&#65292;&#20351;&#29992;&#37096;&#20998;&#22330;&#26223;&#35268;&#33539;&#29983;&#25104;&#20855;&#26377;&#21487;&#21464;&#26234;&#33021;&#20307;&#25968;&#37327;&#30340;&#20132;&#36890;&#22330;&#26223;&#12290;&#36825;&#31687;&#35770;&#25991;&#23558;&#21508;&#31181;&#29616;&#26377;&#30340;&#20132;&#36890;&#22330;&#26223;&#25551;&#36848;&#26041;&#27861;&#32479;&#19968;&#21040;&#19968;&#20010;&#21333;&#19968;&#30340;&#35757;&#32451;&#26694;&#26550;&#20013;&#65292;&#24182;&#28436;&#31034;&#20102;&#22914;&#20309;&#23558;&#20854;&#19982;&#20854;&#20182;&#33258;&#20027;&#39550;&#39542;&#31639;&#27861;&#38598;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17805v1 Announce Type: cross  Abstract: The automated generation of diverse and complex training scenarios has been an important ingredient in many complex learning tasks. Especially in real-world application domains, such as autonomous driving, auto-curriculum generation is considered vital for obtaining robust and general policies. However, crafting traffic scenarios with multiple, heterogeneous agents is typically considered as a tedious and time-consuming task, especially in more complex simulation environments. In our work, we introduce MATS-Gym, a Multi-Agent Traffic Scenario framework to train agents in CARLA, a high-fidelity driving simulator. MATS-Gym is a multi-agent training framework for autonomous driving that uses partial scenario specifications to generate traffic scenarios with variable numbers of agents. This paper unifies various existing approaches to traffic scenario description into a single training framework and demonstrates how it can be integrated wi
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26680;&#20989;&#25968;&#30340;&#24555;&#36895;&#36941;&#21382;&#25628;&#32034;&#26041;&#27861;&#65292;&#20854;&#22312;&#25628;&#32034;&#31354;&#38388;&#32500;&#24230;&#19978;&#20855;&#26377;&#32447;&#24615;&#22797;&#26434;&#24230;&#65292;&#21487;&#20197;&#25512;&#24191;&#21040;&#26446;&#32676;&#65292;&#24182;&#19988;&#36890;&#36807;&#25968;&#20540;&#27979;&#35797;&#23637;&#31034;&#27604;&#29616;&#26377;&#31639;&#27861;&#24555;&#20004;&#20010;&#25968;&#37327;&#32423;&#12290;</title><link>https://arxiv.org/abs/2403.01536</link><description>&lt;p&gt;
&#20351;&#29992;&#26680;&#20989;&#25968;&#30340;&#24555;&#36895;&#36941;&#21382;&#25628;&#32034;
&lt;/p&gt;
&lt;p&gt;
Fast Ergodic Search with Kernel Functions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01536
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26680;&#20989;&#25968;&#30340;&#24555;&#36895;&#36941;&#21382;&#25628;&#32034;&#26041;&#27861;&#65292;&#20854;&#22312;&#25628;&#32034;&#31354;&#38388;&#32500;&#24230;&#19978;&#20855;&#26377;&#32447;&#24615;&#22797;&#26434;&#24230;&#65292;&#21487;&#20197;&#25512;&#24191;&#21040;&#26446;&#32676;&#65292;&#24182;&#19988;&#36890;&#36807;&#25968;&#20540;&#27979;&#35797;&#23637;&#31034;&#27604;&#29616;&#26377;&#31639;&#27861;&#24555;&#20004;&#20010;&#25968;&#37327;&#32423;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36941;&#21382;&#25628;&#32034;&#20351;&#24471;&#23545;&#20449;&#24687;&#20998;&#24067;&#36827;&#34892;&#26368;&#20339;&#25506;&#32034;&#25104;&#20026;&#21487;&#33021;&#65292;&#21516;&#26102;&#20445;&#35777;&#20102;&#23545;&#25628;&#32034;&#31354;&#38388;&#30340;&#28176;&#36817;&#35206;&#30422;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#26041;&#27861;&#36890;&#24120;&#22312;&#25628;&#32034;&#31354;&#38388;&#32500;&#24230;&#19978;&#20855;&#26377;&#25351;&#25968;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#24182;&#19988;&#23616;&#38480;&#20110;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#35745;&#31639;&#39640;&#25928;&#30340;&#36941;&#21382;&#25628;&#32034;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#26159;&#21452;&#37325;&#30340;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#22522;&#20110;&#26680;&#30340;&#36941;&#21382;&#24230;&#37327;&#65292;&#24182;&#23558;&#20854;&#20174;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#25512;&#24191;&#21040;&#26446;&#32676;&#19978;&#12290;&#25105;&#20204;&#27491;&#24335;&#35777;&#26126;&#20102;&#25152;&#24314;&#35758;&#30340;&#24230;&#37327;&#19982;&#26631;&#20934;&#36941;&#21382;&#24230;&#37327;&#19968;&#33268;&#65292;&#21516;&#26102;&#20445;&#35777;&#20102;&#22312;&#25628;&#32034;&#31354;&#38388;&#32500;&#24230;&#19978;&#20855;&#26377;&#32447;&#24615;&#22797;&#26434;&#24230;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#38750;&#32447;&#24615;&#31995;&#32479;&#30340;&#26680;&#36941;&#21382;&#24230;&#37327;&#30340;&#19968;&#38454;&#26368;&#20248;&#24615;&#26465;&#20214;&#65292;&#36825;&#20351;&#24471;&#36712;&#36857;&#20248;&#21270;&#21464;&#24471;&#26356;&#21152;&#39640;&#25928;&#12290;&#20840;&#38754;&#30340;&#25968;&#20540;&#22522;&#20934;&#27979;&#35797;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#33267;&#23569;&#27604;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;&#24555;&#20004;&#20010;&#25968;&#37327;&#32423;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01536v1 Announce Type: cross  Abstract: Ergodic search enables optimal exploration of an information distribution while guaranteeing the asymptotic coverage of the search space. However, current methods typically have exponential computation complexity in the search space dimension and are restricted to Euclidean space. We introduce a computationally efficient ergodic search method. Our contributions are two-fold. First, we develop a kernel-based ergodic metric and generalize it from Euclidean space to Lie groups. We formally prove the proposed metric is consistent with the standard ergodic metric while guaranteeing linear complexity in the search space dimension. Secondly, we derive the first-order optimality condition of the kernel ergodic metric for nonlinear systems, which enables efficient trajectory optimization. Comprehensive numerical benchmarks show that the proposed method is at least two orders of magnitude faster than the state-of-the-art algorithm. Finally, we d
&lt;/p&gt;</description></item><item><title>MimicTouch&#26159;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#33021;&#22815;&#27169;&#20223;&#20154;&#31867;&#30340;&#35302;&#35273;&#24341;&#23548;&#25511;&#21046;&#31574;&#30053;&#65292;&#36890;&#36807;&#25910;&#38598;&#26469;&#33258;&#20154;&#31867;&#31034;&#33539;&#32773;&#30340;&#22810;&#27169;&#24577;&#35302;&#35273;&#25968;&#25454;&#38598;&#65292;&#26469;&#23398;&#20064;&#24182;&#25191;&#34892;&#22797;&#26434;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2310.16917</link><description>&lt;p&gt;
MimicTouch: &#20351;&#29992;&#22810;&#27169;&#24577;&#35302;&#35273;&#21453;&#39304;&#23398;&#20064;&#20154;&#31867;&#30340;&#25511;&#21046;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
MimicTouch: Learning Human's Control Strategy with Multi-Modal Tactile Feedback. (arXiv:2310.16917v1 [cs.RO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16917
&lt;/p&gt;
&lt;p&gt;
MimicTouch&#26159;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#33021;&#22815;&#27169;&#20223;&#20154;&#31867;&#30340;&#35302;&#35273;&#24341;&#23548;&#25511;&#21046;&#31574;&#30053;&#65292;&#36890;&#36807;&#25910;&#38598;&#26469;&#33258;&#20154;&#31867;&#31034;&#33539;&#32773;&#30340;&#22810;&#27169;&#24577;&#35302;&#35273;&#25968;&#25454;&#38598;&#65292;&#26469;&#23398;&#20064;&#24182;&#25191;&#34892;&#22797;&#26434;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#20154;&#25216;&#26415;&#21644;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#65292;&#35302;&#35273;&#22788;&#29702;&#30340;&#25972;&#21512;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#65292;&#29305;&#21035;&#26159;&#22312;&#23398;&#20064;&#25191;&#34892;&#20687;&#23545;&#20934;&#21644;&#25554;&#20837;&#36825;&#26679;&#22797;&#26434;&#20219;&#21153;&#26102;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30740;&#31350;&#20027;&#35201;&#20381;&#36182;&#26426;&#22120;&#20154;&#36965;&#25805;&#20316;&#25968;&#25454;&#21644;&#24378;&#21270;&#23398;&#20064;&#65292;&#24573;&#35270;&#20102;&#20154;&#31867;&#21463;&#35302;&#35273;&#21453;&#39304;&#24341;&#23548;&#19979;&#30340;&#25511;&#21046;&#31574;&#30053;&#25152;&#25552;&#20379;&#30340;&#20016;&#23500;&#35265;&#35299;&#12290;&#20026;&#20102;&#21033;&#29992;&#20154;&#31867;&#24863;&#35273;&#65292;&#29616;&#26377;&#30340;&#20174;&#20154;&#31867;&#23398;&#20064;&#30340;&#26041;&#27861;&#20027;&#35201;&#21033;&#29992;&#35270;&#35273;&#21453;&#39304;&#65292;&#24120;&#24120;&#24573;&#35270;&#20102;&#20154;&#31867;&#26412;&#33021;&#22320;&#21033;&#29992;&#35302;&#35273;&#21453;&#39304;&#23436;&#25104;&#22797;&#26434;&#25805;&#20316;&#30340;&#23453;&#36149;&#32463;&#39564;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#26694;&#26550;"MimicTouch"&#65292;&#27169;&#20223;&#20154;&#31867;&#30340;&#35302;&#35273;&#24341;&#23548;&#25511;&#21046;&#31574;&#30053;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#20174;&#20154;&#31867;&#31034;&#33539;&#32773;&#37027;&#37324;&#25910;&#38598;&#22810;&#27169;&#24577;&#35302;&#35273;&#25968;&#25454;&#38598;&#65292;&#21253;&#25324;&#20154;&#31867;&#35302;&#35273;&#24341;&#23548;&#30340;&#25511;&#21046;&#31574;&#30053;&#26469;&#23436;&#25104;&#20219;&#21153;&#12290;&#25509;&#19979;&#26469;&#30340;&#27493;&#39588;&#28041;&#21450;&#25351;&#20196;&#30340;&#20256;&#36882;&#65292;&#20854;&#20013;&#26426;&#22120;&#20154;&#36890;&#36807;&#27169;&#20223;&#20154;&#31867;&#30340;&#35302;&#35273;&#24341;&#23548;&#31574;&#30053;&#26469;&#25191;&#34892;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
In robotics and artificial intelligence, the integration of tactile processing is becoming increasingly pivotal, especially in learning to execute intricate tasks like alignment and insertion. However, existing works focusing on tactile methods for insertion tasks predominantly rely on robot teleoperation data and reinforcement learning, which do not utilize the rich insights provided by human's control strategy guided by tactile feedback. For utilizing human sensations, methodologies related to learning from humans predominantly leverage visual feedback, often overlooking the invaluable tactile feedback that humans inherently employ to finish complex manipulations. Addressing this gap, we introduce "MimicTouch", a novel framework that mimics human's tactile-guided control strategy. In this framework, we initially collect multi-modal tactile datasets from human demonstrators, incorporating human tactile-guided control strategies for task completion. The subsequent step involves instruc
&lt;/p&gt;</description></item></channel></rss>