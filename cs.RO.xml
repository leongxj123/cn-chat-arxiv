<rss version="2.0"><channel><title>Chat Arxiv cs.RO</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.RO</description><item><title>&#26412;&#25991;&#39318;&#27425;&#30740;&#31350;&#20102;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23548;&#33322;&#31995;&#32479;&#22312;&#22478;&#24066;&#29615;&#22659;&#20013;&#30340;&#23433;&#20840;&#28431;&#27934;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;NPS Attack&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#28155;&#21152;&#21518;&#32512;&#26469;&#25805;&#32437;&#23548;&#33322;&#27169;&#22411;&#65292;&#23548;&#33268;&#19981;&#27491;&#30830;&#30340;&#34892;&#20026;&#12290;&#35813;&#30740;&#31350;&#23545;&#33258;&#21160;&#39550;&#39542;&#12289;&#29289;&#27969;&#21644;&#32039;&#24613;&#26381;&#21153;&#31561;&#39046;&#22495;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>https://arxiv.org/abs/2402.09546</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#22478;&#24066;&#29615;&#22659;&#20013;&#23548;&#33322;&#26102;&#26377;&#22810;&#23433;&#20840;&#65311;
&lt;/p&gt;
&lt;p&gt;
How Secure Are Large Language Models (LLMs) for Navigation in Urban Environments?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09546
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#27425;&#30740;&#31350;&#20102;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23548;&#33322;&#31995;&#32479;&#22312;&#22478;&#24066;&#29615;&#22659;&#20013;&#30340;&#23433;&#20840;&#28431;&#27934;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;NPS Attack&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#28155;&#21152;&#21518;&#32512;&#26469;&#25805;&#32437;&#23548;&#33322;&#27169;&#22411;&#65292;&#23548;&#33268;&#19981;&#27491;&#30830;&#30340;&#34892;&#20026;&#12290;&#35813;&#30740;&#31350;&#23545;&#33258;&#21160;&#39550;&#39542;&#12289;&#29289;&#27969;&#21644;&#32039;&#24613;&#26381;&#21153;&#31561;&#39046;&#22495;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#20154;&#21644;&#33258;&#21160;&#21270;&#39046;&#22495;&#65292;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#23548;&#33322;&#31995;&#32479;&#26368;&#36817;&#23637;&#31034;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#31995;&#32479;&#30340;&#23433;&#20840;&#24615;&#26041;&#38754;&#21463;&#21040;&#30340;&#20851;&#27880;&#30456;&#23545;&#36739;&#23569;&#12290;&#26412;&#25991;&#22312;&#22478;&#24066;&#25143;&#22806;&#29615;&#22659;&#20013;&#39318;&#27425;&#25506;&#32034;&#20102;LLM-based&#23548;&#33322;&#27169;&#22411;&#30340;&#28431;&#27934;&#65292;&#36825;&#26159;&#19968;&#20010;&#20851;&#38190;&#39046;&#22495;&#65292;&#22240;&#20026;&#35813;&#25216;&#26415;&#24191;&#27867;&#24212;&#29992;&#20110;&#33258;&#21160;&#39550;&#39542;&#12289;&#29289;&#27969;&#21644;&#32039;&#24613;&#26381;&#21153;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;Navigational Prompt Suffix (NPS) Attack&#65292;&#36890;&#36807;&#23558;&#26799;&#24230;&#23548;&#20986;&#30340;&#21518;&#32512;&#28155;&#21152;&#21040;&#21407;&#22987;&#23548;&#33322;&#25552;&#31034;&#65292;&#25805;&#32437;LLM-based&#23548;&#33322;&#27169;&#22411;&#65292;&#20174;&#32780;&#23548;&#33268;&#19981;&#27491;&#30830;&#30340;&#34892;&#20026;&#12290;&#25105;&#20204;&#23545;&#22522;&#20110;LLMs&#30340;&#23548;&#33322;&#27169;&#22411;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#23454;&#39564;&#65292;&#35813;&#27169;&#22411;&#37319;&#29992;&#21508;&#31181;LLMs&#36827;&#34892;&#25512;&#29702;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26469;&#33258;Touchdown&#21644;Map2Seq&#34903;&#26223;&#25968;&#25454;&#38598;&#65292;&#22312;few-shot&#23398;&#20064;&#21644;fine-tuning&#37197;&#32622;&#19979;&#36827;&#34892;&#23454;&#39564;&#65292;&#32467;&#26524;&#35777;&#26126;&#20102;NPS Attack&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09546v1 Announce Type: cross  Abstract: In the field of robotics and automation, navigation systems based on Large Language Models (LLMs) have recently shown impressive performance. However, the security aspects of these systems have received relatively less attention. This paper pioneers the exploration of vulnerabilities in LLM-based navigation models in urban outdoor environments, a critical area given the technology's widespread application in autonomous driving, logistics, and emergency services. Specifically, we introduce a novel Navigational Prompt Suffix (NPS) Attack that manipulates LLM-based navigation models by appending gradient-derived suffixes to the original navigational prompt, leading to incorrect actions. We conducted comprehensive experiments on an LLMs-based navigation model that employs various LLMs for reasoning. Our results, derived from the Touchdown and Map2Seq street-view datasets under both few-shot learning and fine-tuning configurations, demonstr
&lt;/p&gt;</description></item></channel></rss>