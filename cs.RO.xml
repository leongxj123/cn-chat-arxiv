<rss version="2.0"><channel><title>Chat Arxiv cs.RO</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.RO</description><item><title>&#35813;&#35770;&#25991;&#23558;&#32463;&#20856;&#35268;&#21010;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30456;&#32467;&#21512;&#65292;&#36890;&#36807;&#36817;&#20284;&#20154;&#31867;&#30452;&#35273;&#65292;&#20197;&#23454;&#29616;&#22810;&#26234;&#33021;&#20307;&#20219;&#21153;&#35268;&#21010;&#12290;</title><link>https://arxiv.org/abs/2403.17246</link><description>&lt;p&gt;
TwoStep: &#20351;&#29992;&#32463;&#20856;&#35268;&#21010;&#22120;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#22810;&#26234;&#33021;&#20307;&#20219;&#21153;&#35268;&#21010;
&lt;/p&gt;
&lt;p&gt;
TwoStep: Multi-agent Task Planning using Classical Planners and Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17246
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#23558;&#32463;&#20856;&#35268;&#21010;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30456;&#32467;&#21512;&#65292;&#36890;&#36807;&#36817;&#20284;&#20154;&#31867;&#30452;&#35273;&#65292;&#20197;&#23454;&#29616;&#22810;&#26234;&#33021;&#20307;&#20219;&#21153;&#35268;&#21010;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31867;&#20284;&#35268;&#21010;&#39046;&#22495;&#23450;&#20041;&#35821;&#35328;&#65288;PDDL&#65289;&#20043;&#31867;&#30340;&#32463;&#20856;&#35268;&#21010;&#20844;&#24335;&#20801;&#35768;&#30830;&#23450;&#21487;&#23454;&#29616;&#30446;&#26631;&#29366;&#24577;&#30340;&#21160;&#20316;&#24207;&#21015;&#65292;&#21482;&#35201;&#23384;&#22312;&#20219;&#20309;&#21487;&#33021;&#30340;&#21021;&#22987;&#29366;&#24577;&#12290;&#28982;&#32780;&#65292;PDDL&#20013;&#23450;&#20041;&#30340;&#25512;&#29702;&#38382;&#39064;&#24182;&#26410;&#25429;&#33719;&#34892;&#21160;&#36827;&#34892;&#30340;&#26102;&#38388;&#26041;&#38754;&#65292;&#20363;&#22914;&#39046;&#22495;&#20013;&#30340;&#20004;&#20010;&#26234;&#33021;&#20307;&#22914;&#26524;&#24444;&#27492;&#30340;&#21518;&#20917;&#19981;&#24178;&#25200;&#21069;&#25552;&#26465;&#20214;&#65292;&#21017;&#21487;&#20197;&#21516;&#26102;&#25191;&#34892;&#19968;&#20010;&#21160;&#20316;&#12290;&#20154;&#31867;&#19987;&#23478;&#21487;&#20197;&#23558;&#30446;&#26631;&#20998;&#35299;&#20026;&#22823;&#37096;&#20998;&#29420;&#31435;&#30340;&#32452;&#25104;&#37096;&#20998;&#65292;&#24182;&#23558;&#27599;&#20010;&#26234;&#33021;&#20307;&#20998;&#37197;&#32473;&#20854;&#20013;&#19968;&#20010;&#23376;&#30446;&#26631;&#65292;&#20197;&#21033;&#29992;&#21516;&#26102;&#36827;&#34892;&#21160;&#20316;&#26469;&#21152;&#24555;&#35745;&#21010;&#27493;&#39588;&#30340;&#25191;&#34892;&#65292;&#27599;&#20010;&#37096;&#20998;&#20165;&#20351;&#29992;&#21333;&#20010;&#26234;&#33021;&#20307;&#35268;&#21010;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#30452;&#25509;&#25512;&#26029;&#35745;&#21010;&#27493;&#39588;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24182;&#19981;&#20445;&#35777;&#25191;&#34892;&#25104;&#21151;&#65292;&#20294;&#21033;&#29992;&#24120;&#35782;&#25512;&#29702;&#26469;&#32452;&#35013;&#21160;&#20316;&#24207;&#21015;&#12290;&#25105;&#20204;&#36890;&#36807;&#36817;&#20284;&#20154;&#31867;&#30452;&#35273;&#65292;&#32467;&#21512;&#20102;&#32463;&#20856;&#35268;&#21010;&#21644;LLMs&#30340;&#20248;&#21183;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17246v1 Announce Type: new  Abstract: Classical planning formulations like the Planning Domain Definition Language (PDDL) admit action sequences guaranteed to achieve a goal state given an initial state if any are possible. However, reasoning problems defined in PDDL do not capture temporal aspects of action taking, for example that two agents in the domain can execute an action simultaneously if postconditions of each do not interfere with preconditions of the other. A human expert can decompose a goal into largely independent constituent parts and assign each agent to one of these subgoals to take advantage of simultaneous actions for faster execution of plan steps, each using only single agent planning. By contrast, large language models (LLMs) used for directly inferring plan steps do not guarantee execution success, but do leverage commonsense reasoning to assemble action sequences. We combine the strengths of classical planning and LLMs by approximating human intuition
&lt;/p&gt;</description></item></channel></rss>