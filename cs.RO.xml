<rss version="2.0"><channel><title>Chat Arxiv cs.RO</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.RO</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#39640;&#25928;&#30340;&#26080;&#35299;&#30721;&#22120;&#26550;&#26500;&#65292;&#29992;&#20110;&#24320;&#25918;&#35789;&#27719;&#30340;&#35270;&#35273;&#20851;&#31995;&#26816;&#27979;&#65292;&#36890;&#36807;Transformer-based&#22270;&#20687;&#32534;&#30721;&#22120;&#38544;&#24335;&#24314;&#27169;&#23545;&#35937;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#20351;&#29992;&#27880;&#24847;&#21147;&#26426;&#21046;&#25552;&#21462;&#20851;&#31995;&#20449;&#24687;&#65292;&#22312;&#28151;&#21512;&#25968;&#25454;&#19978;&#36827;&#34892;&#31471;&#21040;&#31471;&#35757;&#32451;&#65292;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#20851;&#31995;&#26816;&#27979;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.14270</link><description>&lt;p&gt;
&#22330;&#26223;&#22270;ViT&#65306;&#31471;&#21040;&#31471;&#30340;&#24320;&#25918;&#35789;&#27719;&#35270;&#35273;&#20851;&#31995;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Scene-Graph ViT: End-to-End Open-Vocabulary Visual Relationship Detection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14270
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#39640;&#25928;&#30340;&#26080;&#35299;&#30721;&#22120;&#26550;&#26500;&#65292;&#29992;&#20110;&#24320;&#25918;&#35789;&#27719;&#30340;&#35270;&#35273;&#20851;&#31995;&#26816;&#27979;&#65292;&#36890;&#36807;Transformer-based&#22270;&#20687;&#32534;&#30721;&#22120;&#38544;&#24335;&#24314;&#27169;&#23545;&#35937;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#20351;&#29992;&#27880;&#24847;&#21147;&#26426;&#21046;&#25552;&#21462;&#20851;&#31995;&#20449;&#24687;&#65292;&#22312;&#28151;&#21512;&#25968;&#25454;&#19978;&#36827;&#34892;&#31471;&#21040;&#31471;&#35757;&#32451;&#65292;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#20851;&#31995;&#26816;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35270;&#35273;&#20851;&#31995;&#26816;&#27979;&#26088;&#22312;&#35782;&#21035;&#22270;&#20687;&#20013;&#30340;&#23545;&#35937;&#21450;&#20854;&#20851;&#31995;&#12290;&#20197;&#24448;&#30340;&#26041;&#27861;&#36890;&#36807;&#22312;&#29616;&#26377;&#30446;&#26631;&#26816;&#27979;&#26550;&#26500;&#20013;&#28155;&#21152;&#21333;&#29420;&#30340;&#20851;&#31995;&#27169;&#22359;&#25110;&#35299;&#30721;&#22120;&#26469;&#22788;&#29702;&#27492;&#20219;&#21153;&#12290;&#36825;&#31181;&#20998;&#31163;&#22686;&#21152;&#20102;&#22797;&#26434;&#24615;&#65292;&#38459;&#30861;&#20102;&#31471;&#21040;&#31471;&#35757;&#32451;&#65292;&#38480;&#21046;&#20102;&#24615;&#33021;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#19988;&#39640;&#25928;&#30340;&#26080;&#35299;&#30721;&#22120;&#26550;&#26500;&#65292;&#29992;&#20110;&#24320;&#25918;&#35789;&#27719;&#30340;&#35270;&#35273;&#20851;&#31995;&#26816;&#27979;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#30001;&#22522;&#20110;Transformer&#30340;&#22270;&#20687;&#32534;&#30721;&#22120;&#32452;&#25104;&#65292;&#23558;&#23545;&#35937;&#34920;&#31034;&#20026;&#26631;&#35760;&#65292;&#24182;&#38544;&#21547;&#22320;&#24314;&#27169;&#23427;&#20204;&#30340;&#20851;&#31995;&#12290;&#20026;&#20102;&#25552;&#21462;&#20851;&#31995;&#20449;&#24687;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#36873;&#25321;&#21487;&#33021;&#24418;&#25104;&#20851;&#31995;&#30340;&#23545;&#35937;&#23545;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#21333;&#38454;&#27573;&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#28151;&#21512;&#23545;&#35937;&#21644;&#20851;&#31995;&#26816;&#27979;&#25968;&#25454;&#19978;&#35757;&#32451;&#27492;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;Visual Genome&#21644;&#22823;&#35789;&#27719;GQA&#22522;&#20934;&#27979;&#35797;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#20851;&#31995;&#26816;&#27979;&#24615;&#33021;&#65292;&#21487;&#23454;&#29616;&#23454;&#26102;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14270v1 Announce Type: cross  Abstract: Visual relationship detection aims to identify objects and their relationships in images. Prior methods approach this task by adding separate relationship modules or decoders to existing object detection architectures. This separation increases complexity and hinders end-to-end training, which limits performance. We propose a simple and highly efficient decoder-free architecture for open-vocabulary visual relationship detection. Our model consists of a Transformer-based image encoder that represents objects as tokens and models their relationships implicitly. To extract relationship information, we introduce an attention mechanism that selects object pairs likely to form a relationship. We provide a single-stage recipe to train this model on a mixture of object and relationship detection data. Our approach achieves state-of-the-art relationship detection performance on Visual Genome and on the large-vocabulary GQA benchmark at real-tim
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#20852;&#30340;&#22312;&#32447;&#38750;&#38543;&#26426;&#25511;&#21046;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#19968;&#32452;&#31574;&#30053;&#20013;&#23547;&#25214;&#20302;&#21518;&#24724;&#65292;&#33719;&#24471;&#23545;&#26368;&#20248;&#31574;&#30053;&#30340;&#36817;&#20284;&#12290;</title><link>http://arxiv.org/abs/2211.09619</link><description>&lt;p&gt;
&#22312;&#32447;&#38750;&#38543;&#26426;&#25511;&#21046;&#31616;&#20171;
&lt;/p&gt;
&lt;p&gt;
Introduction to Online Nonstochastic Control. (arXiv:2211.09619v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.09619
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#20852;&#30340;&#22312;&#32447;&#38750;&#38543;&#26426;&#25511;&#21046;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#19968;&#32452;&#31574;&#30053;&#20013;&#23547;&#25214;&#20302;&#21518;&#24724;&#65292;&#33719;&#24471;&#23545;&#26368;&#20248;&#31574;&#30053;&#30340;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#20852;&#30340;&#21160;&#24577;&#31995;&#32479;&#25511;&#21046;&#19982;&#21487;&#24494;&#24378;&#21270;&#23398;&#20064;&#33539;&#24335;&#8212;&#8212;&#22312;&#32447;&#38750;&#38543;&#26426;&#25511;&#21046;&#65292;&#24182;&#24212;&#29992;&#22312;&#32447;&#20984;&#20248;&#21270;&#21644;&#20984;&#26494;&#24347;&#25216;&#26415;&#24471;&#21040;&#20102;&#20855;&#26377;&#21487;&#35777;&#26126;&#20445;&#35777;&#30340;&#26032;&#26041;&#27861;&#65292;&#22312;&#26368;&#20339;&#21644;&#40065;&#26834;&#25511;&#21046;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#25104;&#26524;&#12290;&#19982;&#20854;&#20182;&#26694;&#26550;&#19981;&#21516;&#65292;&#35813;&#26041;&#27861;&#30340;&#30446;&#26631;&#26159;&#23545;&#25239;&#24615;&#25915;&#20987;&#65292;&#22312;&#26080;&#27861;&#39044;&#27979;&#25200;&#21160;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#22312;&#19968;&#32452;&#31574;&#30053;&#20013;&#23547;&#25214;&#20302;&#21518;&#24724;&#65292;&#33719;&#24471;&#23545;&#26368;&#20248;&#31574;&#30053;&#30340;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;
This text presents an introduction to an emerging paradigm in control of dynamical systems and differentiable reinforcement learning called online nonstochastic control. The new approach applies techniques from online convex optimization and convex relaxations to obtain new methods with provable guarantees for classical settings in optimal and robust control.  The primary distinction between online nonstochastic control and other frameworks is the objective. In optimal control, robust control, and other control methodologies that assume stochastic noise, the goal is to perform comparably to an offline optimal strategy. In online nonstochastic control, both the cost functions as well as the perturbations from the assumed dynamical model are chosen by an adversary. Thus the optimal policy is not defined a priori. Rather, the target is to attain low regret against the best policy in hindsight from a benchmark class of policies.  This objective suggests the use of the decision making frame
&lt;/p&gt;</description></item></channel></rss>