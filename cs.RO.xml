<rss version="2.0"><channel><title>Chat Arxiv cs.RO</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.RO</description><item><title>Calib3D&#26159;&#19968;&#20010;&#20174;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#35282;&#24230;&#20986;&#21457;&#65292;&#23545;&#22810;&#20010;3D&#22330;&#26223;&#29702;&#35299;&#27169;&#22411;&#36827;&#34892;&#20102;&#20840;&#38754;&#35780;&#20272;&#65292;&#21457;&#29616;&#29616;&#26377;&#27169;&#22411;&#34429;&#28982;&#20934;&#30830;&#20294;&#19981;&#21487;&#38752;&#65292;&#20174;&#32780;&#38416;&#26126;&#20102;&#23433;&#20840;&#20851;&#38190;&#30340;&#32972;&#26223;&#19979;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.17010</link><description>&lt;p&gt;
Calib3D&#65306;&#26657;&#20934;&#27169;&#22411;&#20559;&#22909;&#20197;&#23454;&#29616;&#21487;&#38752;&#30340;3D&#22330;&#26223;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Calib3D: Calibrating Model Preferences for Reliable 3D Scene Understanding
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17010
&lt;/p&gt;
&lt;p&gt;
Calib3D&#26159;&#19968;&#20010;&#20174;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#35282;&#24230;&#20986;&#21457;&#65292;&#23545;&#22810;&#20010;3D&#22330;&#26223;&#29702;&#35299;&#27169;&#22411;&#36827;&#34892;&#20102;&#20840;&#38754;&#35780;&#20272;&#65292;&#21457;&#29616;&#29616;&#26377;&#27169;&#22411;&#34429;&#28982;&#20934;&#30830;&#20294;&#19981;&#21487;&#38752;&#65292;&#20174;&#32780;&#38416;&#26126;&#20102;&#23433;&#20840;&#20851;&#38190;&#30340;&#32972;&#26223;&#19979;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23433;&#20840;&#20851;&#38190;&#30340;3D&#22330;&#26223;&#29702;&#35299;&#20219;&#21153;&#38656;&#35201;&#30340;&#19981;&#20165;&#20165;&#26159;&#20934;&#30830;&#30340;&#39044;&#27979;&#65292;&#36824;&#38656;&#35201;&#26469;&#33258;3D&#24863;&#30693;&#27169;&#22411;&#30340;&#33258;&#20449;&#39044;&#27979;&#12290;&#26412;&#30740;&#31350;&#25512;&#20986;&#20102;Calib3D&#65292;&#36825;&#26159;&#19968;&#39033;&#24320;&#21019;&#24615;&#30340;&#24037;&#20316;&#65292;&#26088;&#22312;&#20174;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#35282;&#24230;&#22522;&#20934;&#21644;&#23457;&#26597;3D&#22330;&#26223;&#29702;&#35299;&#27169;&#22411;&#30340;&#21487;&#38752;&#24615;&#12290;&#25105;&#20204;&#20840;&#38754;&#35780;&#20272;&#20102;28&#20010;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#22312;10&#20010;&#19981;&#21516;&#30340;3D&#25968;&#25454;&#38598;&#19978;&#65292;&#25581;&#31034;&#20102;&#33021;&#22815;&#22788;&#29702;3D&#22330;&#26223;&#29702;&#35299;&#20013;&#30340;&#35823;&#24046;&#19981;&#30830;&#23450;&#24615;&#21644;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#30340;&#26377;&#35265;&#22320;&#30340;&#29616;&#35937;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#23613;&#31649;&#29616;&#26377;&#27169;&#22411;&#21462;&#24471;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#20934;&#30830;&#24230;&#27700;&#24179;&#65292;&#20294;&#23427;&#20204;&#32463;&#24120;&#26080;&#27861;&#25552;&#20379;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745; -- &#36825;&#20010;&#20851;&#38190;&#30340;&#32570;&#38519;&#20005;&#37325;&#25439;&#23475;&#20102;&#23427;&#20204;&#22312;&#23433;&#20840;&#25935;&#24863;&#29615;&#22659;&#20013;&#30340;&#36866;&#29992;&#24615;&#12290;&#36890;&#36807;&#23545;&#20851;&#38190;&#22240;&#32032;&#65288;&#22914;&#32593;&#32476;&#23481;&#37327;&#12289;LiDAR&#34920;&#31034;&#12289;&#20809;&#26629;&#20998;&#36776;&#29575;&#21644;3D&#25968;&#25454;&#22686;&#24378;&#25216;&#26415;&#65289;&#36827;&#34892;&#20102;&#24191;&#27867;&#20998;&#26512;&#65292;&#25105;&#20204;&#30452;&#25509;&#23558;&#36825;&#20123;&#26041;&#38754;&#19982;&#27169;&#22411;&#26657;&#20934;&#30456;&#20851;&#32852;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17010v1 Announce Type: cross  Abstract: Safety-critical 3D scene understanding tasks necessitate not only accurate but also confident predictions from 3D perception models. This study introduces Calib3D, a pioneering effort to benchmark and scrutinize the reliability of 3D scene understanding models from an uncertainty estimation viewpoint. We comprehensively evaluate 28 state-of-the-art models across 10 diverse 3D datasets, uncovering insightful phenomena that cope with both the aleatoric and epistemic uncertainties in 3D scene understanding. We discover that despite achieving impressive levels of accuracy, existing models frequently fail to provide reliable uncertainty estimates -- a pitfall that critically undermines their applicability in safety-sensitive contexts. Through extensive analysis of key factors such as network capacity, LiDAR representations, rasterization resolutions, and 3D data augmentation techniques, we correlate these aspects directly with the model cal
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#21160;&#24577;&#36816;&#21160;&#29983;&#25104;&#20219;&#21153;&#30340;&#22810;&#20219;&#21153;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#21487;&#29992;&#20110;&#36866;&#24212;&#21333;&#20010;&#36816;&#21160;&#31867;&#21035;&#20013;&#30340;&#38544;&#24335;&#21464;&#21270;&#65292;&#24182;&#22312;&#22836;&#29699;&#20219;&#21153;&#20013;&#21462;&#24471;&#33391;&#22909;&#30340;&#36866;&#24212;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.16471</link><description>&lt;p&gt;
&#19968;&#31181;&#36866;&#29992;&#20110;&#38544;&#24335;&#22810;&#20219;&#21153;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#30340;&#31574;&#30053;&#36866;&#24212;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Policy Adaptation Method for Implicit Multitask Reinforcement Learning Problems. (arXiv:2308.16471v1 [cs.RO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16471
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#21160;&#24577;&#36816;&#21160;&#29983;&#25104;&#20219;&#21153;&#30340;&#22810;&#20219;&#21153;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#21487;&#29992;&#20110;&#36866;&#24212;&#21333;&#20010;&#36816;&#21160;&#31867;&#21035;&#20013;&#30340;&#38544;&#24335;&#21464;&#21270;&#65292;&#24182;&#22312;&#22836;&#29699;&#20219;&#21153;&#20013;&#21462;&#24471;&#33391;&#22909;&#30340;&#36866;&#24212;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21160;&#24577;&#36816;&#21160;&#29983;&#25104;&#20219;&#21153;&#20013;&#65292;&#21253;&#25324;&#25509;&#35302;&#21644;&#30896;&#25758;&#65292;&#31574;&#30053;&#21442;&#25968;&#30340;&#23567;&#25913;&#21464;&#21487;&#33021;&#23548;&#33268;&#26497;&#20854;&#19981;&#21516;&#30340;&#22238;&#25253;&#12290;&#20363;&#22914;&#65292;&#22312;&#36275;&#29699;&#20013;&#65292;&#36890;&#36807;&#31245;&#24494;&#25913;&#21464;&#36386;&#29699;&#20301;&#32622;&#25110;&#26045;&#21152;&#29699;&#30340;&#21147;&#25110;&#32773;&#29699;&#30340;&#25705;&#25830;&#21147;&#21457;&#29983;&#21464;&#21270;&#65292;&#29699;&#21487;&#20197;&#20197;&#23436;&#20840;&#19981;&#21516;&#30340;&#26041;&#21521;&#39134;&#34892;&#12290;&#28982;&#32780;&#65292;&#24456;&#38590;&#24819;&#35937;&#22312;&#19981;&#21516;&#30340;&#26041;&#21521;&#19978;&#22836;&#29699;&#38656;&#35201;&#23436;&#20840;&#19981;&#21516;&#30340;&#25216;&#33021;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#20219;&#21153;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#21333;&#20010;&#36816;&#21160;&#31867;&#21035;&#20013;&#36866;&#24212;&#30446;&#26631;&#25110;&#29615;&#22659;&#30340;&#38544;&#24335;&#21464;&#21270;&#65292;&#21253;&#25324;&#19981;&#21516;&#30340;&#22870;&#21169;&#20989;&#25968;&#25110;&#29615;&#22659;&#30340;&#29289;&#29702;&#21442;&#25968;&#12290;&#25105;&#20204;&#21033;&#29992;&#21333;&#33050;&#26426;&#22120;&#20154;&#27169;&#22411;&#23545;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#22312;&#22836;&#29699;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#36866;&#24212;&#25928;&#26524;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#36866;&#24212;&#30446;&#26631;&#20301;&#32622;&#30340;&#38544;&#24335;&#21464;&#21270;&#25110;&#29699;&#30340;&#24674;&#22797;&#31995;&#25968;&#30340;&#21464;&#21270;&#65292;&#32780;&#26631;&#20934;&#30340;&#39046;&#22495;&#38543;&#26426;&#21270;&#26041;&#27861;&#21017;&#19981;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In dynamic motion generation tasks, including contact and collisions, small changes in policy parameters can lead to extremely different returns. For example, in soccer, the ball can fly in completely different directions with a similar heading motion by slightly changing the hitting position or the force applied to the ball or when the friction of the ball varies. However, it is difficult to imagine that completely different skills are needed for heading a ball in different directions. In this study, we proposed a multitask reinforcement learning algorithm for adapting a policy to implicit changes in goals or environments in a single motion category with different reward functions or physical parameters of the environment. We evaluated the proposed method on the ball heading task using a monopod robot model. The results showed that the proposed method can adapt to implicit changes in the goal positions or the coefficients of restitution of the ball, whereas the standard domain randomi
&lt;/p&gt;</description></item></channel></rss>