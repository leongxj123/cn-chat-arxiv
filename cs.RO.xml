<rss version="2.0"><channel><title>Chat Arxiv cs.RO</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.RO</description><item><title>&#20154;&#20204;&#20250;&#32473;&#33258;&#20027;&#36710;&#36742;&#30340;&#34892;&#20026;&#36171;&#20104;&#30446;&#30340;&#23646;&#24615;&#65292;&#24182;&#22312;&#29983;&#25104;&#35299;&#37322;&#21644;&#35780;&#20272;&#36825;&#20123;&#35299;&#37322;&#26102;&#34920;&#29616;&#20986;&#23545;&#30446;&#30340;&#35770;&#35299;&#37322;&#30340;&#20542;&#21521;&#12290;</title><link>https://arxiv.org/abs/2403.08828</link><description>&lt;p&gt;
&#24403;&#35299;&#37322;&#33258;&#20027;&#36710;&#36742;&#30340;&#34892;&#20026;&#26102;&#65292;&#20154;&#20204;&#20250;&#32473;&#20104;&#20854;&#23646;&#24615;&#30446;&#30340;
&lt;/p&gt;
&lt;p&gt;
People Attribute Purpose to Autonomous Vehicles When Explaining Their Behavior
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08828
&lt;/p&gt;
&lt;p&gt;
&#20154;&#20204;&#20250;&#32473;&#33258;&#20027;&#36710;&#36742;&#30340;&#34892;&#20026;&#36171;&#20104;&#30446;&#30340;&#23646;&#24615;&#65292;&#24182;&#22312;&#29983;&#25104;&#35299;&#37322;&#21644;&#35780;&#20272;&#36825;&#20123;&#35299;&#37322;&#26102;&#34920;&#29616;&#20986;&#23545;&#30446;&#30340;&#35770;&#35299;&#37322;&#30340;&#20542;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#27454;&#20248;&#31168;&#30340;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#30340;&#26631;&#24535;&#26159;&#29992;&#25143;&#21487;&#20197;&#29702;&#35299;&#24182;&#37319;&#21462;&#34892;&#21160;&#30340;&#35299;&#37322;&#12290;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#36825;&#38656;&#35201;&#31995;&#32479;&#25552;&#20379;&#21487;&#29702;&#35299;&#30340;&#22240;&#26524;&#25110;&#21453;&#20107;&#23454;&#35299;&#37322;&#12290;&#35748;&#30693;&#31185;&#23398;&#21487;&#20197;&#24110;&#21161;&#25105;&#20204;&#29702;&#35299;&#29992;&#25143;&#21487;&#33021;&#26399;&#26395;&#30340;&#35299;&#37322;&#31867;&#22411;&#65292;&#20197;&#21450;&#22312;&#21738;&#31181;&#26684;&#24335;&#19979;&#21576;&#29616;&#36825;&#20123;&#35299;&#37322;&#12290;&#26412;&#25991;&#31616;&#35201;&#22238;&#39038;&#20102;&#35748;&#30693;&#31185;&#23398;&#35299;&#37322;&#26041;&#38754;&#30340;&#30456;&#20851;&#25991;&#29486;&#65292;&#29305;&#21035;&#20851;&#27880;&#30446;&#30340;&#35770;&#65292;&#21363;&#20197;&#36798;&#21040;&#30446;&#30340;&#20026;&#35299;&#37322;&#20915;&#31574;&#30340;&#20542;&#21521;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25253;&#21578;&#20102;&#20154;&#20204;&#22914;&#20309;&#20026;&#33258;&#20027;&#36710;&#36742;&#30340;&#34892;&#20026;&#20135;&#29983;&#35299;&#37322;&#20197;&#21450;&#20182;&#20204;&#22914;&#20309;&#35780;&#20272;&#36825;&#20123;&#35299;&#37322;&#30340;&#32463;&#39564;&#25968;&#25454;&#12290;&#22312;&#31532;&#19968;&#39033;&#35843;&#26597;&#20013;&#65292;&#21442;&#19982;&#32773;&#65288;n = 54&#65289;&#35266;&#30475;&#20102;&#36947;&#36335;&#22330;&#26223;&#30340;&#35270;&#39057;&#65292;&#24182;&#34987;&#35201;&#27714;&#20026;&#36710;&#36742;&#30340;&#34892;&#20026;&#29983;&#25104;&#26426;&#26800;&#30340;&#12289;&#21453;&#20107;&#23454;&#30340;&#25110;&#30446;&#30340;&#35770;&#30340;&#35328;&#35821;&#35299;&#37322;&#12290;&#22312;&#31532;&#20108;&#39033;&#35843;&#26597;&#20013;&#65292;&#21478;&#19968;&#32452;&#21442;&#19982;&#32773;&#65288;n = 356&#65289;&#23545;&#36825;&#20123;&#36827;&#34892;&#35780;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08828v1 Announce Type: cross  Abstract: A hallmark of a good XAI system is explanations that users can understand and act on. In many cases, this requires a system to offer causal or counterfactual explanations that are intelligible. Cognitive science can help us understand what kinds of explanations users might expect, and in which format to frame these explanations. We briefly review relevant literature from the cognitive science of explanation, particularly as it concerns teleology, the tendency to explain a decision in terms of the purpose it was meant to achieve. We then report empirical data on how people generate explanations for the behavior of autonomous vehicles, and how they evaluate these explanations. In a first survey, participants (n=54) were shown videos of a road scene and asked to generate either mechanistic, counterfactual, or teleological verbal explanations for a vehicle's actions. In the second survey, a different set of participants (n=356) rated these
&lt;/p&gt;</description></item></channel></rss>