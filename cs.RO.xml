<rss version="2.0"><channel><title>Chat Arxiv cs.RO</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.RO</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23454;&#38469;&#35774;&#32622;&#65292;&#31216;&#20026;&#25351;&#23548;&#35270;&#39057;&#20013;&#30340;&#33258;&#36866;&#24212;&#31243;&#24207;&#35268;&#21010;&#65292;&#20811;&#26381;&#20102;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#27493;&#39588;&#38271;&#24230;&#21464;&#21270;&#30340;&#27169;&#22411;&#19981;&#20855;&#26377;&#27867;&#21270;&#33021;&#21147;&#12289;&#29702;&#35299;&#27493;&#39588;&#20043;&#38388;&#30340;&#26102;&#38388;&#20851;&#31995;&#30693;&#35782;&#23545;&#20110;&#29983;&#25104;&#21512;&#29702;&#19988;&#21487;&#25191;&#34892;&#30340;&#35745;&#21010;&#33267;&#20851;&#37325;&#35201;&#20197;&#21450;&#29992;&#27493;&#39588;&#32423;&#26631;&#31614;&#25110;&#24207;&#21015;&#32423;&#26631;&#31614;&#26631;&#27880;&#25351;&#23548;&#35270;&#39057;&#32791;&#26102;&#19988;&#21171;&#21160;&#23494;&#38598;&#30340;&#38382;&#39064;</title><link>https://arxiv.org/abs/2403.18600</link><description>&lt;p&gt;
RAP&#65306;&#26816;&#32034;&#22686;&#24378;&#22411;&#35268;&#21010;&#22120;&#29992;&#20110;&#25351;&#23548;&#35270;&#39057;&#20013;&#30340;&#33258;&#36866;&#24212;&#31243;&#24207;&#35268;&#21010;
&lt;/p&gt;
&lt;p&gt;
RAP: Retrieval-Augmented Planner for Adaptive Procedure Planning in Instructional Videos
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18600
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23454;&#38469;&#35774;&#32622;&#65292;&#31216;&#20026;&#25351;&#23548;&#35270;&#39057;&#20013;&#30340;&#33258;&#36866;&#24212;&#31243;&#24207;&#35268;&#21010;&#65292;&#20811;&#26381;&#20102;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#27493;&#39588;&#38271;&#24230;&#21464;&#21270;&#30340;&#27169;&#22411;&#19981;&#20855;&#26377;&#27867;&#21270;&#33021;&#21147;&#12289;&#29702;&#35299;&#27493;&#39588;&#20043;&#38388;&#30340;&#26102;&#38388;&#20851;&#31995;&#30693;&#35782;&#23545;&#20110;&#29983;&#25104;&#21512;&#29702;&#19988;&#21487;&#25191;&#34892;&#30340;&#35745;&#21010;&#33267;&#20851;&#37325;&#35201;&#20197;&#21450;&#29992;&#27493;&#39588;&#32423;&#26631;&#31614;&#25110;&#24207;&#21015;&#32423;&#26631;&#31614;&#26631;&#27880;&#25351;&#23548;&#35270;&#39057;&#32791;&#26102;&#19988;&#21171;&#21160;&#23494;&#38598;&#30340;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25351;&#23548;&#35270;&#39057;&#20013;&#30340;&#31243;&#24207;&#35268;&#21010;&#28041;&#21450;&#26681;&#25454;&#21021;&#22987;&#21644;&#30446;&#26631;&#29366;&#24577;&#30340;&#35270;&#35273;&#35266;&#23519;&#29983;&#25104;&#19968;&#31995;&#21015;&#21160;&#20316;&#27493;&#39588;&#12290;&#23613;&#31649;&#36825;&#19968;&#20219;&#21153;&#21462;&#24471;&#20102;&#24555;&#36895;&#36827;&#23637;&#65292;&#20173;&#28982;&#23384;&#22312;&#19968;&#20123;&#20851;&#38190;&#25361;&#25112;&#38656;&#35201;&#35299;&#20915;&#65306;&#65288;1&#65289;&#33258;&#36866;&#24212;&#31243;&#24207;&#65306;&#20808;&#21069;&#30340;&#24037;&#20316;&#23384;&#22312;&#19968;&#20010;&#19981;&#20999;&#23454;&#38469;&#30340;&#20551;&#35774;&#65292;&#21363;&#21160;&#20316;&#27493;&#39588;&#30340;&#25968;&#37327;&#26159;&#24050;&#30693;&#19988;&#22266;&#23450;&#30340;&#65292;&#23548;&#33268;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#65292;&#27493;&#39588;&#38271;&#24230;&#21464;&#21270;&#30340;&#27169;&#22411;&#19981;&#20855;&#26377;&#27867;&#21270;&#33021;&#21147;&#12290;&#65288;2&#65289;&#26102;&#38388;&#20851;&#31995;&#65306;&#29702;&#35299;&#27493;&#39588;&#20043;&#38388;&#30340;&#26102;&#38388;&#20851;&#31995;&#30693;&#35782;&#23545;&#20110;&#29983;&#25104;&#21512;&#29702;&#19988;&#21487;&#25191;&#34892;&#30340;&#35745;&#21010;&#33267;&#20851;&#37325;&#35201;&#12290;&#65288;3&#65289;&#27880;&#37322;&#25104;&#26412;&#65306;&#29992;&#27493;&#39588;&#32423;&#26631;&#31614;&#65288;&#21363;&#26102;&#38388;&#25139;&#65289;&#25110;&#24207;&#21015;&#32423;&#26631;&#31614;&#65288;&#21363;&#21160;&#20316;&#31867;&#21035;&#65289;&#26631;&#27880;&#25351;&#23548;&#35270;&#39057;&#26159;&#32791;&#26102;&#19988;&#21171;&#21160;&#23494;&#38598;&#30340;&#65292;&#38480;&#21046;&#20102;&#20854;&#27867;&#21270;&#33021;&#21147;&#21040;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#23454;&#38469;&#35774;&#32622;&#65292;&#31216;&#20026;&#25351;&#23548;&#35270;&#39057;&#20013;&#30340;&#33258;&#36866;&#24212;&#31243;&#24207;&#35268;&#21010;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18600v1 Announce Type: cross  Abstract: Procedure Planning in instructional videos entails generating a sequence of action steps based on visual observations of the initial and target states. Despite the rapid progress in this task, there remain several critical challenges to be solved: (1) Adaptive procedures: Prior works hold an unrealistic assumption that the number of action steps is known and fixed, leading to non-generalizable models in real-world scenarios where the sequence length varies. (2) Temporal relation: Understanding the step temporal relation knowledge is essential in producing reasonable and executable plans. (3) Annotation cost: Annotating instructional videos with step-level labels (i.e., timestamp) or sequence-level labels (i.e., action category) is demanding and labor-intensive, limiting its generalizability to large-scale datasets.In this work, we propose a new and practical setting, called adaptive procedure planning in instructional videos, where the
&lt;/p&gt;</description></item><item><title>TempFuser&#26159;&#19968;&#31181;&#38271;&#30701;&#26102;&#24207;&#34701;&#21512;&#36716;&#25442;&#22120;&#65292;&#33021;&#22815;&#23398;&#20064;&#31354;&#20013;&#26684;&#26007;&#20013;&#30340;&#25112;&#26415;&#21644;&#25935;&#25463;&#39134;&#34892;&#21160;&#20316;&#12290;&#32463;&#36807;&#35757;&#32451;&#65292;&#27169;&#22411;&#25104;&#21151;&#22320;&#23398;&#20250;&#20102;&#22797;&#26434;&#30340;&#25112;&#26007;&#21160;&#20316;&#65292;&#24182;&#22312;&#38754;&#23545;&#39640;&#32423;&#23545;&#25163;&#26102;&#23637;&#29616;&#20986;&#20154;&#31867;&#19968;&#26679;&#30340;&#25112;&#26415;&#21160;&#20316;&#12290;</title><link>http://arxiv.org/abs/2308.03257</link><description>&lt;p&gt;
TempFuser: &#20351;&#29992;&#38271;&#30701;&#26102;&#24207;&#34701;&#21512;&#36716;&#25442;&#22120;&#23398;&#20064;&#31354;&#20013;&#26684;&#26007;&#20013;&#30340;&#25112;&#26415;&#21644;&#25935;&#25463;&#39134;&#34892;&#21160;&#20316;
&lt;/p&gt;
&lt;p&gt;
TempFuser: Learning Tactical and Agile Flight Maneuvers in Aerial Dogfights using a Long Short-Term Temporal Fusion Transformer. (arXiv:2308.03257v2 [cs.RO] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03257
&lt;/p&gt;
&lt;p&gt;
TempFuser&#26159;&#19968;&#31181;&#38271;&#30701;&#26102;&#24207;&#34701;&#21512;&#36716;&#25442;&#22120;&#65292;&#33021;&#22815;&#23398;&#20064;&#31354;&#20013;&#26684;&#26007;&#20013;&#30340;&#25112;&#26415;&#21644;&#25935;&#25463;&#39134;&#34892;&#21160;&#20316;&#12290;&#32463;&#36807;&#35757;&#32451;&#65292;&#27169;&#22411;&#25104;&#21151;&#22320;&#23398;&#20250;&#20102;&#22797;&#26434;&#30340;&#25112;&#26007;&#21160;&#20316;&#65292;&#24182;&#22312;&#38754;&#23545;&#39640;&#32423;&#23545;&#25163;&#26102;&#23637;&#29616;&#20986;&#20154;&#31867;&#19968;&#26679;&#30340;&#25112;&#26415;&#21160;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31354;&#20013;&#25112;&#26007;&#20013;&#65292;&#31354;&#25112;&#21160;&#20316;&#23545;&#25112;&#26415;&#26426;&#21160;&#21644;&#25935;&#25463;&#25112;&#26007;&#26426;&#30340;&#31354;&#27668;&#21160;&#21147;&#23398;&#37117;&#25552;&#20986;&#20102;&#22797;&#26434;&#30340;&#25361;&#25112;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;TempFuser&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#38271;&#30701;&#26102;&#24207;&#34701;&#21512;&#36716;&#25442;&#22120;&#65292;&#26088;&#22312;&#23398;&#20064;&#31354;&#20013;&#26684;&#26007;&#20013;&#30340;&#25112;&#26415;&#21644;&#25935;&#25463;&#39134;&#34892;&#21160;&#20316;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#20004;&#31181;&#19981;&#21516;&#30340;&#22522;&#20110;LSTM&#30340;&#36755;&#20837;&#23884;&#20837;&#26469;&#32534;&#30721;&#38271;&#26399;&#31232;&#30095;&#21644;&#30701;&#26399;&#23494;&#38598;&#30340;&#29366;&#24577;&#34920;&#31034;&#12290;&#36890;&#36807;&#23558;&#36825;&#20123;&#23884;&#20837;&#36890;&#36807;&#36716;&#25442;&#22120;&#32534;&#30721;&#22120;&#36827;&#34892;&#25972;&#21512;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#25429;&#33719;&#20102;&#25112;&#26007;&#26426;&#30340;&#25112;&#26415;&#21644;&#25935;&#25463;&#24615;&#65292;&#20351;&#20854;&#33021;&#22815;&#29983;&#25104;&#31471;&#21040;&#31471;&#30340;&#39134;&#34892;&#25351;&#20196;&#65292;&#30830;&#20445;&#21344;&#25454;&#20248;&#21183;&#20301;&#32622;&#24182;&#36229;&#36234;&#23545;&#25163;&#12290;&#32463;&#36807;&#23545;&#39640;&#20445;&#30495;&#39134;&#34892;&#27169;&#25311;&#22120;&#20013;&#22810;&#31181;&#31867;&#22411;&#23545;&#25163;&#39134;&#26426;&#30340;&#24191;&#27867;&#35757;&#32451;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#25104;&#21151;&#22320;&#23398;&#20064;&#20102;&#25191;&#34892;&#22797;&#26434;&#30340;&#25112;&#26007;&#21160;&#20316;&#65292;&#19988;&#22987;&#32456;&#34920;&#29616;&#20248;&#20110;&#22810;&#20010;&#22522;&#20934;&#27169;&#22411;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#38754;&#23545;&#39640;&#32423;&#23545;&#25163;&#26102;&#23637;&#29616;&#20986;&#20154;&#31867;&#19968;&#26679;&#30340;&#25112;&#26415;&#21160;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
In aerial combat, dogfighting poses intricate challenges that demand an understanding of both strategic maneuvers and the aerodynamics of agile fighter aircraft. In this paper, we introduce TempFuser, a novel long short-term temporal fusion transformer designed to learn tactical and agile flight maneuvers in aerial dogfights. Our approach employs two distinct LSTM-based input embeddings to encode long-term sparse and short-term dense state representations. By integrating these embeddings through a transformer encoder, our model captures the tactics and agility of fighter jets, enabling it to generate end-to-end flight commands that secure dominant positions and outmaneuver the opponent. After extensive training against various types of opponent aircraft in a high-fidelity flight simulator, our model successfully learns to perform complex fighter maneuvers, consistently outperforming several baseline models. Notably, our model exhibits human-like strategic maneuvers even when facing adv
&lt;/p&gt;</description></item></channel></rss>