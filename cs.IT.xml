<rss version="2.0"><channel><title>Chat Arxiv cs.IT</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IT</description><item><title>&#22312;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20197;&#22266;&#23450;&#32622;&#20449;&#24230;&#36827;&#34892;&#26368;&#20248;&#33218;&#35782;&#21035;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#26469;&#35782;&#21035;&#20855;&#26377;&#26368;&#22823;&#24179;&#22343;&#20540;&#30340;&#33218;&#65292;&#21516;&#26102;&#38480;&#21046;&#20102;&#20915;&#31574;&#38169;&#35823;&#30340;&#27010;&#29575;&#65292;&#24182;&#24314;&#31435;&#20102;&#20572;&#27490;&#26102;&#38388;&#22686;&#38271;&#29575;&#30340;&#19979;&#30028;&#12290;</title><link>http://arxiv.org/abs/2310.13393</link><description>&lt;p&gt;
&#22312;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#20197;&#22266;&#23450;&#32622;&#20449;&#24230;&#36827;&#34892;&#26368;&#20248;&#33218;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Optimal Best Arm Identification with Fixed Confidence in Restless Bandits. (arXiv:2310.13393v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13393
&lt;/p&gt;
&lt;p&gt;
&#22312;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20197;&#22266;&#23450;&#32622;&#20449;&#24230;&#36827;&#34892;&#26368;&#20248;&#33218;&#35782;&#21035;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#26469;&#35782;&#21035;&#20855;&#26377;&#26368;&#22823;&#24179;&#22343;&#20540;&#30340;&#33218;&#65292;&#21516;&#26102;&#38480;&#21046;&#20102;&#20915;&#31574;&#38169;&#35823;&#30340;&#27010;&#29575;&#65292;&#24182;&#24314;&#31435;&#20102;&#20572;&#27490;&#26102;&#38388;&#22686;&#38271;&#29575;&#30340;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#20855;&#26377;&#26377;&#38480;&#25968;&#30446;&#33218;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#20197;&#19981;&#26029;&#21464;&#21270;&#30340;&#24418;&#24335;&#36827;&#34892;&#26368;&#20248;&#33218;&#35782;&#21035;&#12290;&#27599;&#20010;&#33218;&#20135;&#29983;&#30340;&#31163;&#25955;&#26102;&#38388;&#25968;&#25454;&#24418;&#25104;&#20102;&#19968;&#20010;&#21462;&#20540;&#22312;&#20849;&#21516;&#12289;&#26377;&#38480;&#29366;&#24577;&#31354;&#38388;&#20013;&#30340;&#21516;&#36136;&#39532;&#23572;&#21487;&#22827;&#38142;&#12290;&#27599;&#20010;&#33218;&#30340;&#29366;&#24577;&#36716;&#31227;&#30001;&#19968;&#20010;&#36981;&#24490;&#21333;&#21442;&#25968;&#25351;&#25968;&#26063;&#30340;&#36716;&#31227;&#27010;&#29575;&#30697;&#38453;&#65288;TPM&#65289;&#25429;&#33719;&#12290;&#27599;&#20010;&#33218;&#30340;TPM&#30340;&#23454;&#20540;&#21442;&#25968;&#26159;&#26410;&#30693;&#30340;&#65292;&#23646;&#20110;&#32473;&#23450;&#31354;&#38388;&#12290;&#32473;&#23450;&#22312;&#33218;&#30340;&#20849;&#21516;&#29366;&#24577;&#31354;&#38388;&#19978;&#23450;&#20041;&#30340;&#20989;&#25968;f&#65292;&#30446;&#26631;&#26159;&#22312;&#26679;&#26412;&#25968;&#26368;&#23569;&#30340;&#24773;&#20917;&#19979;&#35782;&#21035;&#26368;&#20248;&#33218;&#65292;&#21363;&#22312;&#35813;&#33218;&#30340;&#31283;&#24577;&#20998;&#24067;&#19979;&#35780;&#20272;f&#30340;&#24179;&#22343;&#20540;&#26368;&#22823;&#30340;&#33218;&#65292;&#21516;&#26102;&#28385;&#36275;&#23545;&#20915;&#31574;&#38169;&#35823;&#27010;&#29575;&#65288;&#21363;&#22266;&#23450;&#32622;&#20449;&#24230;&#21306;&#38388;&#65289;&#30340;&#19978;&#30028;&#12290;&#22312;&#28176;&#36827;&#24615;&#30340;&#35823;&#24046;&#27010;&#29575;&#36235;&#20110;&#38646;&#30340;&#24773;&#20917;&#19979;&#65292;&#24314;&#31435;&#20102;&#26399;&#26395;&#20572;&#27490;&#26102;&#38388;&#22686;&#38271;&#29575;&#30340;&#19979;&#30028;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26368;&#20248;&#33218;&#35782;&#21035;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study best arm identification in a restless multi-armed bandit setting with finitely many arms. The discrete-time data generated by each arm forms a homogeneous Markov chain taking values in a common, finite state space. The state transitions in each arm are captured by an ergodic transition probability matrix (TPM) that is a member of a single-parameter exponential family of TPMs. The real-valued parameters of the arm TPMs are unknown and belong to a given space. Given a function $f$ defined on the common state space of the arms, the goal is to identify the best arm -- the arm with the largest average value of $f$ evaluated under the arm's stationary distribution -- with the fewest number of samples, subject to an upper bound on the decision's error probability (i.e., the fixed-confidence regime). A lower bound on the growth rate of the expected stopping time is established in the asymptote of a vanishing error probability. Furthermore, a policy for best arm identification is propo
&lt;/p&gt;</description></item></channel></rss>