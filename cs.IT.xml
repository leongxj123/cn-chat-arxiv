<rss version="2.0"><channel><title>Chat Arxiv cs.IT</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IT</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#27010;&#29575;&#24615;Gram-Schmidt&#26041;&#27861;&#26469;&#36827;&#34892;&#29305;&#24449;&#25552;&#21462;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#26816;&#27979;&#21644;&#21435;&#38500;&#38750;&#32447;&#24615;&#20381;&#36182;&#24615;&#65292;&#20174;&#32780;&#25552;&#21462;&#25968;&#25454;&#20013;&#30340;&#32447;&#24615;&#29305;&#24449;&#24182;&#21435;&#38500;&#38750;&#32447;&#24615;&#20887;&#20313;&#12290;</title><link>https://arxiv.org/abs/2311.09386</link><description>&lt;p&gt;
&#36229;&#36234;PCA&#65306;&#19968;&#31181;&#27010;&#29575;&#24615;Gram-Schmidt&#26041;&#27861;&#30340;&#29305;&#24449;&#25552;&#21462;
&lt;/p&gt;
&lt;p&gt;
Beyond PCA: A Probabilistic Gram-Schmidt Approach to Feature Extraction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.09386
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#27010;&#29575;&#24615;Gram-Schmidt&#26041;&#27861;&#26469;&#36827;&#34892;&#29305;&#24449;&#25552;&#21462;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#26816;&#27979;&#21644;&#21435;&#38500;&#38750;&#32447;&#24615;&#20381;&#36182;&#24615;&#65292;&#20174;&#32780;&#25552;&#21462;&#25968;&#25454;&#20013;&#30340;&#32447;&#24615;&#29305;&#24449;&#24182;&#21435;&#38500;&#38750;&#32447;&#24615;&#20887;&#20313;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26080;&#30417;&#30563;&#23398;&#20064;&#20013;&#65292;&#32447;&#24615;&#29305;&#24449;&#25552;&#21462;&#22312;&#25968;&#25454;&#20013;&#23384;&#22312;&#38750;&#32447;&#24615;&#20381;&#36182;&#30340;&#24773;&#20917;&#19979;&#26159;&#19968;&#20010;&#22522;&#26412;&#25361;&#25112;&#12290;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#27010;&#29575;&#24615;Gram-Schmidt (GS)&#31867;&#22411;&#30340;&#27491;&#20132;&#21270;&#36807;&#31243;&#26469;&#26816;&#27979;&#21644;&#26144;&#23556;&#20986;&#20887;&#20313;&#32500;&#24230;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#36890;&#36807;&#22312;&#19968;&#26063;&#20989;&#25968;&#19978;&#24212;&#29992;GS&#36807;&#31243;&#65292;&#35813;&#26063;&#20989;&#25968;&#39044;&#35745;&#25429;&#25417;&#21040;&#25968;&#25454;&#20013;&#30340;&#38750;&#32447;&#24615;&#20381;&#36182;&#24615;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#31995;&#21015;&#21327;&#26041;&#24046;&#30697;&#38453;&#65292;&#21487;&#20197;&#29992;&#20110;&#35782;&#21035;&#26032;&#30340;&#22823;&#26041;&#24046;&#26041;&#21521;&#65292;&#25110;&#32773;&#23558;&#36825;&#20123;&#20381;&#36182;&#24615;&#20174;&#20027;&#25104;&#20998;&#20013;&#21435;&#38500;&#12290;&#22312;&#21069;&#19968;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#29109;&#20943;&#23569;&#30340;&#20449;&#24687;&#29702;&#35770;&#20445;&#35777;&#12290;&#22312;&#21518;&#19968;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#26576;&#20123;&#20551;&#35774;&#19979;&#65292;&#25152;&#24471;&#31639;&#27861;&#22312;&#25152;&#36873;&#25321;&#20989;&#25968;&#26063;&#30340;&#32447;&#24615;&#24352;&#25104;&#31354;&#38388;&#20013;&#21487;&#20197;&#26816;&#27979;&#21644;&#21435;&#38500;&#38750;&#32447;&#24615;&#20381;&#36182;&#24615;&#12290;&#20004;&#31181;&#25552;&#20986;&#30340;&#26041;&#27861;&#37117;&#21487;&#20197;&#20174;&#25968;&#25454;&#20013;&#25552;&#21462;&#32447;&#24615;&#29305;&#24449;&#24182;&#21435;&#38500;&#38750;&#32447;&#24615;&#20887;&#20313;&#12290;
&lt;/p&gt;
&lt;p&gt;
Linear feature extraction at the presence of nonlinear dependencies among the data is a fundamental challenge in unsupervised learning. We propose using a probabilistic Gram-Schmidt (GS) type orthogonalization process in order to detect and map out redundant dimensions. Specifically, by applying the GS process over a family of functions which presumably captures the nonlinear dependencies in the data, we construct a series of covariance matrices that can either be used to identify new large-variance directions, or to remove those dependencies from the principal components. In the former case, we provide information-theoretic guarantees in terms of entropy reduction. In the latter, we prove that under certain assumptions the resulting algorithms detect and remove nonlinear dependencies whenever those dependencies lie in the linear span of the chosen function family. Both proposed methods extract linear features from the data while removing nonlinear redundancies. We provide simulation r
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#21033;&#29992;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#36827;&#34892;&#20449;&#36947;&#20272;&#35745;&#65292;&#36890;&#36807;&#23545;&#26465;&#20214;&#39640;&#26031;&#20449;&#36947;&#27169;&#22411;&#30340;&#20869;&#37096;&#32467;&#26500;&#36827;&#34892;&#21442;&#25968;&#21270;&#36924;&#36817;&#26469;&#33719;&#24471;&#22343;&#26041;&#26681;&#35823;&#24046;&#26368;&#20248;&#20449;&#36947;&#20272;&#35745;&#22120;&#65292;&#21516;&#26102;&#32473;&#20986;&#20102;&#22522;&#20110;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;&#20272;&#35745;&#22120;&#30340;&#23454;&#29992;&#24615;&#32771;&#34385;&#21644;&#19977;&#31181;&#19981;&#21516;&#35757;&#32451;&#26041;&#24335;&#30340;&#20272;&#35745;&#22120;&#21464;&#20307;&#12290;</title><link>http://arxiv.org/abs/2307.05352</link><description>&lt;p&gt;
&#21033;&#29992;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#36827;&#34892;&#21442;&#25968;&#21270;MMSE&#20449;&#36947;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Leveraging Variational Autoencoders for Parameterized MMSE Channel Estimation. (arXiv:2307.05352v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05352
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#21033;&#29992;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#36827;&#34892;&#20449;&#36947;&#20272;&#35745;&#65292;&#36890;&#36807;&#23545;&#26465;&#20214;&#39640;&#26031;&#20449;&#36947;&#27169;&#22411;&#30340;&#20869;&#37096;&#32467;&#26500;&#36827;&#34892;&#21442;&#25968;&#21270;&#36924;&#36817;&#26469;&#33719;&#24471;&#22343;&#26041;&#26681;&#35823;&#24046;&#26368;&#20248;&#20449;&#36947;&#20272;&#35745;&#22120;&#65292;&#21516;&#26102;&#32473;&#20986;&#20102;&#22522;&#20110;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;&#20272;&#35745;&#22120;&#30340;&#23454;&#29992;&#24615;&#32771;&#34385;&#21644;&#19977;&#31181;&#19981;&#21516;&#35757;&#32451;&#26041;&#24335;&#30340;&#20272;&#35745;&#22120;&#21464;&#20307;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#21033;&#29992;&#22522;&#20110;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;&#30340;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#36827;&#34892;&#20449;&#36947;&#20272;&#35745;&#12290;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#20197;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#24335;&#23558;&#30495;&#23454;&#20294;&#26410;&#30693;&#30340;&#20449;&#36947;&#20998;&#24067;&#24314;&#27169;&#20026;&#26465;&#20214;&#39640;&#26031;&#20998;&#24067;&#12290;&#25152;&#24471;&#21040;&#30340;&#20449;&#36947;&#20272;&#35745;&#22120;&#21033;&#29992;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;&#20869;&#37096;&#32467;&#26500;&#23545;&#26469;&#33258;&#26465;&#20214;&#39640;&#26031;&#20449;&#36947;&#27169;&#22411;&#30340;&#22343;&#26041;&#35823;&#24046;&#26368;&#20248;&#20272;&#35745;&#22120;&#36827;&#34892;&#21442;&#25968;&#21270;&#36924;&#36817;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#20998;&#26512;&#65292;&#20197;&#30830;&#23450;&#20160;&#20040;&#26465;&#20214;&#19979;&#22522;&#20110;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;&#20272;&#35745;&#22120;&#26159;&#22343;&#26041;&#35823;&#24046;&#26368;&#20248;&#30340;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20351;&#22522;&#20110;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;&#20272;&#35745;&#22120;&#23454;&#29992;&#30340;&#32771;&#34385;&#22240;&#32032;&#65292;&#24182;&#25552;&#20986;&#20102;&#19977;&#31181;&#19981;&#21516;&#30340;&#20272;&#35745;&#22120;&#21464;&#20307;&#65292;&#23427;&#20204;&#22312;&#35757;&#32451;&#21644;&#35780;&#20272;&#38454;&#27573;&#23545;&#20449;&#36947;&#30693;&#35782;&#30340;&#33719;&#21462;&#26041;&#24335;&#19981;&#21516;&#12290;&#29305;&#21035;&#22320;&#65292;&#20165;&#22522;&#20110;&#22122;&#22768;&#23548;&#39057;&#35266;&#27979;&#36827;&#34892;&#35757;&#32451;&#30340;&#25152;&#25552;&#20986;&#30340;&#20272;&#35745;&#22120;&#21464;&#20307;&#38750;&#24120;&#20540;&#24471;&#27880;&#24847;&#65292;&#22240;&#20026;&#23427;&#19981;&#38656;&#35201;&#33719;&#21462;&#20449;&#36947;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this manuscript, we propose to utilize the generative neural network-based variational autoencoder for channel estimation. The variational autoencoder models the underlying true but unknown channel distribution as a conditional Gaussian distribution in a novel way. The derived channel estimator exploits the internal structure of the variational autoencoder to parameterize an approximation of the mean squared error optimal estimator resulting from the conditional Gaussian channel models. We provide a rigorous analysis under which conditions a variational autoencoder-based estimator is mean squared error optimal. We then present considerations that make the variational autoencoder-based estimator practical and propose three different estimator variants that differ in their access to channel knowledge during the training and evaluation phase. In particular, the proposed estimator variant trained solely on noisy pilot observations is particularly noteworthy as it does not require access
&lt;/p&gt;</description></item></channel></rss>