<rss version="2.0"><channel><title>Chat Arxiv cs.IT</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IT</description><item><title>DEEP-IoT&#36890;&#36807;&#8220;&#26356;&#22810;&#30417;&#21548;&#65292;&#26356;&#23569;&#20256;&#36755;&#8221;&#30340;&#31574;&#30053;&#65292;&#25361;&#25112;&#21644;&#36716;&#21464;&#20102;&#20256;&#32479;&#30340;&#29289;&#32852;&#32593;&#36890;&#20449;&#27169;&#22411;&#65292;&#22823;&#24133;&#38477;&#20302;&#33021;&#32791;&#24182;&#25552;&#39640;&#35774;&#22791;&#23551;&#21629;&#12290;</title><link>https://arxiv.org/abs/2403.00321</link><description>&lt;p&gt;
DEEP-IoT: &#19979;&#34892;&#22686;&#24378;&#22411;&#39640;&#25928;&#33021;&#29289;&#32852;&#32593;
&lt;/p&gt;
&lt;p&gt;
DEEP-IoT: Downlink-Enhanced Efficient-Power Internet of Things
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00321
&lt;/p&gt;
&lt;p&gt;
DEEP-IoT&#36890;&#36807;&#8220;&#26356;&#22810;&#30417;&#21548;&#65292;&#26356;&#23569;&#20256;&#36755;&#8221;&#30340;&#31574;&#30053;&#65292;&#25361;&#25112;&#21644;&#36716;&#21464;&#20102;&#20256;&#32479;&#30340;&#29289;&#32852;&#32593;&#36890;&#20449;&#27169;&#22411;&#65292;&#22823;&#24133;&#38477;&#20302;&#33021;&#32791;&#24182;&#25552;&#39640;&#35774;&#22791;&#23551;&#21629;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;DEEP-IoT&#65292;&#36825;&#26159;&#19968;&#31181;&#20855;&#26377;&#38761;&#21629;&#24847;&#20041;&#30340;&#36890;&#20449;&#33539;&#20363;&#65292;&#26088;&#22312;&#37325;&#26032;&#23450;&#20041;&#29289;&#32852;&#32593;&#35774;&#22791;&#20043;&#38388;&#30340;&#36890;&#20449;&#26041;&#24335;&#12290;&#36890;&#36807;&#24320;&#21019;&#24615;&#30340;&#8220;&#26356;&#22810;&#30417;&#21548;&#65292;&#26356;&#23569;&#20256;&#36755;&#8221;&#30340;&#31574;&#30053;&#65292;DEEP-IoT&#25361;&#25112;&#21644;&#36716;&#21464;&#20102;&#20256;&#32479;&#30340;&#21457;&#36865;&#26041;&#65288;&#29289;&#32852;&#32593;&#35774;&#22791;&#65289;&#20026;&#20013;&#24515;&#30340;&#36890;&#20449;&#27169;&#22411;&#65292;&#23558;&#25509;&#25910;&#26041;&#65288;&#25509;&#20837;&#28857;&#65289;&#20316;&#20026;&#20851;&#38190;&#35282;&#33394;&#65292;&#20174;&#32780;&#38477;&#20302;&#33021;&#32791;&#24182;&#24310;&#38271;&#35774;&#22791;&#23551;&#21629;&#12290;&#25105;&#20204;&#19981;&#20165;&#27010;&#24565;&#21270;&#20102;DEEP-IoT&#65292;&#36824;&#36890;&#36807;&#22312;&#31364;&#24102;&#31995;&#32479;&#20013;&#38598;&#25104;&#28145;&#24230;&#23398;&#20064;&#22686;&#24378;&#30340;&#21453;&#39304;&#20449;&#36947;&#32534;&#30721;&#26469;&#23454;&#29616;&#23427;&#12290;&#27169;&#25311;&#32467;&#26524;&#26174;&#31034;&#65292;IoT&#21333;&#20803;&#30340;&#36816;&#34892;&#23551;&#21629;&#26174;&#33879;&#25552;&#39640;&#65292;&#27604;&#20351;&#29992;Turbo&#21644;Polar&#32534;&#30721;&#30340;&#20256;&#32479;&#31995;&#32479;&#25552;&#39640;&#20102;&#26368;&#22810;52.71%&#12290;&#36825;&#19968;&#36827;&#23637;&#26631;&#24535;&#30528;&#19968;&#31181;&#21464;&#38761;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00321v1 Announce Type: cross  Abstract: At the heart of the Internet of Things (IoT) -- a domain witnessing explosive growth -- the imperative for energy efficiency and the extension of device lifespans has never been more pressing. This paper presents DEEP-IoT, a revolutionary communication paradigm poised to redefine how IoT devices communicate. Through a pioneering "listen more, transmit less" strategy, DEEP-IoT challenges and transforms the traditional transmitter (IoT devices)-centric communication model to one where the receiver (the access point) play a pivotal role, thereby cutting down energy use and boosting device longevity. We not only conceptualize DEEP-IoT but also actualize it by integrating deep learning-enhanced feedback channel codes within a narrow-band system. Simulation results show a significant enhancement in the operational lifespan of IoT cells -- surpassing traditional systems using Turbo and Polar codes by up to 52.71%. This leap signifies a paradi
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#23545;&#25239;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#22797;&#26434;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#36890;&#36807;&#23558;&#20854;&#19982;&#29233;&#22240;&#26031;&#22374;&#30340;&#29305;&#27530;&#30456;&#23545;&#35770;&#20013;&#30340;&#32416;&#32544;&#27010;&#24565;&#32852;&#31995;&#36215;&#26469;&#65292;&#21457;&#29616;&#36828;&#31243;&#29305;&#24449;&#26679;&#26412;&#21487;&#20197;&#34920;&#29616;&#20986;&#32416;&#32544;&#29616;&#35937;&#65292;&#25361;&#25112;&#20102;&#23545;&#25239;&#21487;&#20256;&#36882;&#24615;&#29616;&#35937;&#30340;&#20256;&#32479;&#25551;&#36848;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2309.15669</link><description>&lt;p&gt;
&#20851;&#20110;&#35745;&#31639;&#32416;&#32544;&#21450;&#20854;&#22312;&#23545;&#25239;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
On Computational Entanglement and Its Interpretation in Adversarial Machine Learning. (arXiv:2309.15669v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15669
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#23545;&#25239;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#22797;&#26434;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#36890;&#36807;&#23558;&#20854;&#19982;&#29233;&#22240;&#26031;&#22374;&#30340;&#29305;&#27530;&#30456;&#23545;&#35770;&#20013;&#30340;&#32416;&#32544;&#27010;&#24565;&#32852;&#31995;&#36215;&#26469;&#65292;&#21457;&#29616;&#36828;&#31243;&#29305;&#24449;&#26679;&#26412;&#21487;&#20197;&#34920;&#29616;&#20986;&#32416;&#32544;&#29616;&#35937;&#65292;&#25361;&#25112;&#20102;&#23545;&#25239;&#21487;&#20256;&#36882;&#24615;&#29616;&#35937;&#30340;&#20256;&#32479;&#25551;&#36848;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#23545;&#25239;&#24615;&#26679;&#26412;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#20855;&#26377;&#27450;&#39575;&#27169;&#22411;&#30340;&#33021;&#21147;&#65292;&#28508;&#22312;&#22320;&#23548;&#33268;&#20005;&#37325;&#21518;&#26524;&#65292;&#22240;&#27492;&#24050;&#25104;&#20026;&#30740;&#31350;&#30340;&#28966;&#28857;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23545;&#23545;&#25239;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#20102;&#20840;&#38754;&#25506;&#32034;&#65292;&#25581;&#31034;&#20102;&#23427;&#20204;&#22266;&#26377;&#30340;&#22797;&#26434;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;&#25105;&#20204;&#30340;&#35843;&#26597;&#25581;&#31034;&#20102;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22797;&#26434;&#24615;&#19982;&#29233;&#22240;&#26031;&#22374;&#30340;&#29305;&#27530;&#30456;&#23545;&#35770;&#20043;&#38388;&#30340;&#26377;&#36259;&#32852;&#31995;&#65292;&#36890;&#36807;&#32416;&#32544;&#30340;&#27010;&#24565;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#23545;&#35745;&#31639;&#32416;&#32544;&#36827;&#34892;&#20102;&#23450;&#20041;&#65292;&#24182;&#35777;&#26126;&#20102;&#36828;&#31243;&#29305;&#24449;&#26679;&#26412;&#21487;&#20197;&#34920;&#29616;&#20986;&#24378;&#30456;&#20851;&#24615;&#65292;&#31867;&#20284;&#20110;&#37327;&#23376;&#39046;&#22495;&#20013;&#30340;&#32416;&#32544;&#12290;&#36825;&#19968;&#21457;&#29616;&#25361;&#25112;&#20102;&#23545;&#24403;&#20195;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#35266;&#23519;&#21040;&#30340;&#23545;&#25239;&#21487;&#20256;&#36882;&#24615;&#29616;&#35937;&#30340;&#20256;&#32479;&#25551;&#36848;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adversarial examples in machine learning has emerged as a focal point of research due to their remarkable ability to deceive models with seemingly inconspicuous input perturbations, potentially resulting in severe consequences. In this study, we embark on a comprehensive exploration of adversarial machine learning models, shedding light on their intrinsic complexity and interpretability. Our investigation reveals intriguing links between machine learning model complexity and Einstein's theory of special relativity, through the concept of entanglement. More specific, we define entanglement computationally and demonstrate that distant feature samples can exhibit strong correlations, akin to entanglement in quantum realm. This revelation challenges conventional perspectives in describing the phenomenon of adversarial transferability observed in contemporary machine learning models. By drawing parallels with the relativistic effects of time dilation and length contraction during computatio
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21160;&#24577;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#29305;&#24449;&#19982;&#21709;&#24212;&#21464;&#37327;&#30340;&#20114;&#20449;&#24687;&#36827;&#34892;&#20248;&#20808;&#32423;&#25490;&#24207;&#65292;&#24182;&#35774;&#35745;&#20102;&#20272;&#35745;&#20114;&#20449;&#24687;&#30340;&#21028;&#21035;&#24335;&#26041;&#27861;&#12290;&#21516;&#26102;&#65292;&#26412;&#25991;&#36824;&#24341;&#20837;&#20102;&#22810;&#39033;&#25913;&#36827;&#25514;&#26045;&#20197;&#24212;&#23545;&#26356;&#22810;&#22330;&#26223;&#12290;</title><link>http://arxiv.org/abs/2306.03301</link><description>&lt;p&gt;
&#21160;&#24577;&#29305;&#24449;&#36873;&#25321;&#20013;&#26465;&#20214;&#20114;&#20449;&#24687;&#30340;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Estimating Conditional Mutual Information for Dynamic Feature Selection. (arXiv:2306.03301v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03301
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21160;&#24577;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#29305;&#24449;&#19982;&#21709;&#24212;&#21464;&#37327;&#30340;&#20114;&#20449;&#24687;&#36827;&#34892;&#20248;&#20808;&#32423;&#25490;&#24207;&#65292;&#24182;&#35774;&#35745;&#20102;&#20272;&#35745;&#20114;&#20449;&#24687;&#30340;&#21028;&#21035;&#24335;&#26041;&#27861;&#12290;&#21516;&#26102;&#65292;&#26412;&#25991;&#36824;&#24341;&#20837;&#20102;&#22810;&#39033;&#25913;&#36827;&#25514;&#26045;&#20197;&#24212;&#23545;&#26356;&#22810;&#22330;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21160;&#24577;&#29305;&#24449;&#36873;&#25321;&#26159;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#33539;&#20363;&#65292;&#23427;&#36890;&#36807;&#39034;&#24207;&#26597;&#35810;&#29305;&#24449;&#20197;&#22312;&#26368;&#23567;&#30340;&#39044;&#31639;&#20869;&#36827;&#34892;&#20934;&#30830;&#39044;&#27979;&#65292;&#20197;&#20943;&#23569;&#29305;&#24449;&#33719;&#21462;&#25104;&#26412;&#65292;&#24182;&#20026;&#39044;&#27979;&#36807;&#31243;&#25552;&#20379;&#36879;&#26126;&#24230;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#36825;&#20010;&#38382;&#39064;&#24456;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;&#23427;&#35201;&#27714;&#20351;&#29992;&#20219;&#24847;&#29305;&#24449;&#38598;&#36827;&#34892;&#39044;&#27979;&#65292;&#24182;&#23398;&#20064;&#31574;&#30053;&#20197;&#30830;&#23450;&#26368;&#26377;&#20215;&#20540;&#30340;&#36873;&#25321;&#12290;&#26412;&#25991;&#20174;&#20449;&#24687;&#29702;&#35770;&#30340;&#35282;&#24230;&#20986;&#21457;&#65292;&#26681;&#25454;&#29305;&#24449;&#19982;&#21709;&#24212;&#21464;&#37327;&#30340;&#20114;&#20449;&#24687;&#23545;&#29305;&#24449;&#36827;&#34892;&#20248;&#20808;&#32423;&#25490;&#24207;&#12290;&#20854;&#20013;&#30340;&#20027;&#35201;&#25361;&#25112;&#26159;&#23398;&#20064;&#27492;&#36873;&#25321;&#31574;&#30053;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#30452;&#25509;&#26032;&#30340;&#24314;&#27169;&#26041;&#27861;&#65292;&#20197;&#21028;&#21035;&#32780;&#38750;&#29983;&#25104;&#27169;&#24335;&#20272;&#35745;&#20114;&#20449;&#24687;&#12290;&#24314;&#31435;&#22312;&#25105;&#20204;&#30340;&#23398;&#20064;&#26041;&#27861;&#20043;&#19978;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20960;&#20010;&#36827;&#19968;&#27493;&#30340;&#25913;&#36827;&#65306;&#20801;&#35768;&#22312;&#26679;&#26412;&#20043;&#38388;&#36827;&#34892;&#21487;&#21464;&#30340;&#29305;&#24449;&#39044;&#31639;&#12289;&#25903;&#25345;&#19981;&#21516;&#29305;&#24449;&#20043;&#38388;&#30340;&#38750;&#22343;&#21248;&#25104;&#26412;&#12289;&#32467;&#21512;&#20808;&#21069;&#30340;&#20449;&#24687;&#21644;&#25506;&#31350;&#29616;&#20195;&#26550;&#26500;&#20197;&#22788;&#29702;&#37096;&#20998;&#36755;&#20837;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dynamic feature selection, where we sequentially query features to make accurate predictions with a minimal budget, is a promising paradigm to reduce feature acquisition costs and provide transparency into the prediction process. The problem is challenging, however, as it requires both making predictions with arbitrary feature sets and learning a policy to identify the most valuable selections. Here, we take an information-theoretic perspective and prioritize features based on their mutual information with the response variable. The main challenge is learning this selection policy, and we design a straightforward new modeling approach that estimates the mutual information in a discriminative rather than generative fashion. Building on our learning approach, we introduce several further improvements: allowing variable feature budgets across samples, enabling non-uniform costs between features, incorporating prior information, and exploring modern architectures to handle partial input in
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19981;&#30830;&#23450;&#26368;&#22823;&#29109;&#21407;&#29702;&#65292;&#35813;&#21407;&#29702;&#21487;&#20197;&#22788;&#29702;&#27169;&#22411;&#20803;&#32032;&#19981;&#21487;&#35266;&#27979;&#30340;&#24773;&#20917;&#65292;&#24182;&#20248;&#20110;&#29305;&#23450;&#26465;&#20214;&#19979;&#30340;&#26368;&#22823;&#29109;&#26041;&#27861;&#12290;&#21516;&#26102;&#23558;&#40657;&#21283;&#23376;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#36755;&#20986;&#29992;&#20316;&#19981;&#30830;&#23450;&#26426;&#22120;&#29109;&#26694;&#26550;&#30340;&#36755;&#20837;&#65292;&#24615;&#33021;&#24471;&#21040;&#20102;&#25552;&#39640;&#12290;</title><link>http://arxiv.org/abs/2305.09868</link><description>&lt;p&gt;
&#19981;&#30830;&#23450;&#26368;&#22823;&#29109;&#21407;&#29702;
&lt;/p&gt;
&lt;p&gt;
The Principle of Uncertain Maximum Entropy. (arXiv:2305.09868v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09868
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19981;&#30830;&#23450;&#26368;&#22823;&#29109;&#21407;&#29702;&#65292;&#35813;&#21407;&#29702;&#21487;&#20197;&#22788;&#29702;&#27169;&#22411;&#20803;&#32032;&#19981;&#21487;&#35266;&#27979;&#30340;&#24773;&#20917;&#65292;&#24182;&#20248;&#20110;&#29305;&#23450;&#26465;&#20214;&#19979;&#30340;&#26368;&#22823;&#29109;&#26041;&#27861;&#12290;&#21516;&#26102;&#23558;&#40657;&#21283;&#23376;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#36755;&#20986;&#29992;&#20316;&#19981;&#30830;&#23450;&#26426;&#22120;&#29109;&#26694;&#26550;&#30340;&#36755;&#20837;&#65292;&#24615;&#33021;&#24471;&#21040;&#20102;&#25552;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#22823;&#29109;&#21407;&#29702;&#22312;&#20449;&#24687;&#29702;&#35770;&#20013;&#30340;&#24341;&#20837;&#65292;&#20026;&#32479;&#35745;&#21147;&#23398;&#65292;&#26426;&#22120;&#23398;&#20064;&#21644;&#29983;&#24577;&#23398;&#31561;&#21508;&#20010;&#39046;&#22495;&#30340;&#21457;&#23637;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;&#20854;&#24471;&#21040;&#30340;&#35299;&#20915;&#26041;&#26696;&#20316;&#20026;&#20652;&#21270;&#21058;&#65292;&#20419;&#36827;&#30740;&#31350;&#20154;&#21592;&#23558;&#20182;&#20204;&#30340;&#32463;&#39564;&#35266;&#23519;&#26144;&#23556;&#21040;&#33719;&#21462;&#26080;&#20559;&#27169;&#22411;&#65292;&#21516;&#26102;&#21152;&#28145;&#20102;&#23545;&#22797;&#26434;&#31995;&#32479;&#21644;&#29616;&#35937;&#30340;&#29702;&#35299;&#12290;&#28982;&#32780;&#65292;&#22312;&#27169;&#22411;&#20803;&#32032;&#19981;&#30452;&#25509;&#21487;&#35266;&#27979;&#30340;&#24773;&#20917;&#19979;&#65292;&#20363;&#22914;&#23384;&#22312;&#22122;&#22768;&#25110;&#30524;&#37096;&#36974;&#25377;&#30340;&#24773;&#20917;&#19979;&#65292;&#26631;&#20934;&#26368;&#22823;&#29109;&#26041;&#27861;&#21487;&#33021;&#20250;&#22833;&#36133;&#65292;&#22240;&#20026;&#23427;&#20204;&#26080;&#27861;&#21305;&#37197;&#29305;&#24449;&#32422;&#26463;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19981;&#30830;&#23450;&#26368;&#22823;&#29109;&#21407;&#29702;&#20316;&#20026;&#19968;&#31181;&#26041;&#27861;&#65292;&#23613;&#31649;&#23384;&#22312;&#20219;&#24847;&#22122;&#22768;&#35266;&#23519;&#65292;&#23427;&#21516;&#26102;&#23558;&#25152;&#26377;&#21487;&#29992;&#20449;&#24687;&#32534;&#30721;&#65292;&#32780;&#19988;&#20248;&#20110;&#19968;&#20123;&#29305;&#23450;&#26465;&#20214;&#19979;&#30340;&#26368;&#22823;&#29109;&#26041;&#27861;&#30340;&#20934;&#30830;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#40657;&#21283;&#23376;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#36755;&#20986;&#29992;&#20316;&#19981;&#30830;&#23450;&#26426;&#22120;&#29109;&#26694;&#26550;&#30340;&#36755;&#20837;&#65292;&#20174;&#32780;&#22312;&#19982;&#26368;&#22823;&#20284;&#28982;&#31639;&#27861;&#30456;&#27604;&#26102;&#24314;&#31435;&#20102;&#25913;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The principle of maximum entropy, as introduced by Jaynes in information theory, has contributed to advancements in various domains such as Statistical Mechanics, Machine Learning, and Ecology. Its resultant solutions have served as a catalyst, facilitating researchers in mapping their empirical observations to the acquisition of unbiased models, whilst deepening the understanding of complex systems and phenomena. However, when we consider situations in which the model elements are not directly observable, such as when noise or ocular occlusion is present, possibilities arise for which standard maximum entropy approaches may fail, as they are unable to match feature constraints. Here we show the Principle of Uncertain Maximum Entropy as a method that both encodes all available information in spite of arbitrarily noisy observations while surpassing the accuracy of some ad-hoc methods. Additionally, we utilize the output of a black-box machine learning model as input into an uncertain ma
&lt;/p&gt;</description></item></channel></rss>