<rss version="2.0"><channel><title>Chat Arxiv cs.IT</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IT</description><item><title>FedStruct&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#21033;&#29992;&#28145;&#23618;&#32467;&#26500;&#20381;&#36182;&#20851;&#31995;&#22312;&#20114;&#32852;&#22270;&#19978;&#36827;&#34892;&#32852;&#21512;&#35299;&#32806;&#23398;&#20064;&#65292;&#26377;&#25928;&#22320;&#32500;&#25252;&#38544;&#31169;&#24182;&#25429;&#25417;&#33410;&#28857;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;</title><link>https://arxiv.org/abs/2402.19163</link><description>&lt;p&gt;
FedStruct&#65306;&#32852;&#21512;&#35299;&#32806;&#23398;&#20064;&#22312;&#20114;&#32852;&#22270;&#19978;
&lt;/p&gt;
&lt;p&gt;
FedStruct: Federated Decoupled Learning over Interconnected Graphs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.19163
&lt;/p&gt;
&lt;p&gt;
FedStruct&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#21033;&#29992;&#28145;&#23618;&#32467;&#26500;&#20381;&#36182;&#20851;&#31995;&#22312;&#20114;&#32852;&#22270;&#19978;&#36827;&#34892;&#32852;&#21512;&#35299;&#32806;&#23398;&#20064;&#65292;&#26377;&#25928;&#22320;&#32500;&#25252;&#38544;&#31169;&#24182;&#25429;&#25417;&#33410;&#28857;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35299;&#20915;&#20102;&#20998;&#24067;&#22312;&#22810;&#20010;&#23458;&#25143;&#31471;&#19978;&#30340;&#22270;&#32467;&#26500;&#25968;&#25454;&#19978;&#30340;&#32852;&#21512;&#23398;&#20064;&#25361;&#25112;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#20851;&#27880;&#20114;&#32852;&#23376;&#22270;&#30340;&#26222;&#36941;&#24773;&#20917;&#65292;&#20854;&#20013;&#19981;&#21516;&#23458;&#25143;&#31471;&#20043;&#38388;&#30340;&#30456;&#20114;&#36830;&#25509;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#38024;&#23545;&#36825;&#31181;&#24773;&#20917;&#30340;&#19968;&#31181;&#26032;&#39062;&#26694;&#26550;&#65292;&#21517;&#20026;FedStruct&#65292;&#23427;&#21033;&#29992;&#28145;&#23618;&#32467;&#26500;&#20381;&#36182;&#20851;&#31995;&#12290;&#20026;&#20102;&#32500;&#25252;&#38544;&#31169;&#65292;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#65292;FedStruct&#28040;&#38500;&#20102;&#22312;&#23458;&#25143;&#31471;&#20043;&#38388;&#20849;&#20139;&#25110;&#29983;&#25104;&#25935;&#24863;&#33410;&#28857;&#29305;&#24449;&#25110;&#23884;&#20837;&#30340;&#24517;&#35201;&#24615;&#12290;&#30456;&#21453;&#65292;&#23427;&#21033;&#29992;&#26174;&#24335;&#20840;&#23616;&#22270;&#32467;&#26500;&#20449;&#24687;&#26469;&#25429;&#25417;&#33410;&#28857;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;&#20845;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#32467;&#26524;&#39564;&#35777;&#20102;FedStruct&#30340;&#26377;&#25928;&#24615;&#65292;&#23637;&#31034;&#20102;&#22312;&#21508;&#31181;&#24773;&#20917;&#19979;&#65288;&#21253;&#25324;&#19981;&#21516;&#25968;&#25454;&#20998;&#21306;&#26041;&#27861;&#12289;&#19981;&#21516;&#26631;&#31614;&#21487;&#29992;&#24615;&#20197;&#21450;&#23458;&#25143;&#20010;&#25968;&#30340;&#65289;&#25509;&#36817;&#20110;&#38598;&#20013;&#24335;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.19163v1 Announce Type: new  Abstract: We address the challenge of federated learning on graph-structured data distributed across multiple clients. Specifically, we focus on the prevalent scenario of interconnected subgraphs, where inter-connections between different clients play a critical role. We present a novel framework for this scenario, named FedStruct, that harnesses deep structural dependencies. To uphold privacy, unlike existing methods, FedStruct eliminates the necessity of sharing or generating sensitive node features or embeddings among clients. Instead, it leverages explicit global graph structure information to capture inter-node dependencies. We validate the effectiveness of FedStruct through experimental results conducted on six datasets for semi-supervised node classification, showcasing performance close to the centralized approach across various scenarios, including different data partitioning methods, varying levels of label availability, and number of cl
&lt;/p&gt;</description></item><item><title>&#20998;&#26512;&#20102;&#26631;&#20934; DP &#22522;&#30784;&#27491;&#21017;&#21270;&#26041;&#27861;&#23545;&#32473;&#23450;&#25935;&#24863;&#23646;&#24615;&#30340;&#39044;&#27979;&#26631;&#31614;&#26465;&#20214;&#20998;&#24067;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25935;&#24863;&#23646;&#24615;&#30340;&#20998;&#24067;&#31283;&#20581;&#20248;&#21270;&#26041;&#27861;&#26469;&#25511;&#21046;&#24402;&#32435;&#20559;&#24046;&#12290;</title><link>https://arxiv.org/abs/2402.18129</link><description>&lt;p&gt;
&#20851;&#20110;&#22522;&#20110;&#20154;&#21475;&#32479;&#35745;&#23398;&#24179;&#31561;&#30340;&#20844;&#24179;&#23398;&#20064;&#31639;&#27861;&#30340;&#24402;&#32435;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
On the Inductive Biases of Demographic Parity-based Fair Learning Algorithms
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18129
&lt;/p&gt;
&lt;p&gt;
&#20998;&#26512;&#20102;&#26631;&#20934; DP &#22522;&#30784;&#27491;&#21017;&#21270;&#26041;&#27861;&#23545;&#32473;&#23450;&#25935;&#24863;&#23646;&#24615;&#30340;&#39044;&#27979;&#26631;&#31614;&#26465;&#20214;&#20998;&#24067;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25935;&#24863;&#23646;&#24615;&#30340;&#20998;&#24067;&#31283;&#20581;&#20248;&#21270;&#26041;&#27861;&#26469;&#25511;&#21046;&#24402;&#32435;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20844;&#24179;&#30340;&#30417;&#30563;&#24335;&#23398;&#20064;&#31639;&#27861;&#22312;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#22791;&#21463;&#20851;&#27880;&#65292;&#36825;&#20123;&#31639;&#27861;&#22312;&#20998;&#37197;&#26631;&#31614;&#26102;&#24456;&#23569;&#20381;&#36182;&#25935;&#24863;&#23646;&#24615;&#12290;&#26412;&#25991;&#20998;&#26512;&#20102;&#26631;&#20934;DP&#65288;&#20154;&#21475;&#32479;&#35745;&#23398;&#24179;&#31561;&#65289;&#22522;&#30784;&#27491;&#21017;&#21270;&#26041;&#27861;&#23545;&#32473;&#23450;&#25935;&#24863;&#23646;&#24615;&#30340;&#39044;&#27979;&#26631;&#31614;&#26465;&#20214;&#20998;&#24067;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#22312;&#20855;&#26377;&#38750;&#22343;&#21248;&#20998;&#24067;&#25935;&#24863;&#23646;&#24615;&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#65292;&#21487;&#33021;&#20250;&#23548;&#33268;&#20998;&#31867;&#35268;&#21017;&#20559;&#21521;&#21344;&#25454;&#22823;&#22810;&#25968;&#35757;&#32451;&#25968;&#25454;&#30340;&#25935;&#24863;&#23646;&#24615;&#32467;&#26524;&#12290;&#20026;&#20102;&#25511;&#21046;DP-based&#20844;&#24179;&#23398;&#20064;&#20013;&#30340;&#36825;&#31181;&#24402;&#32435;&#20559;&#24046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#25935;&#24863;&#23646;&#24615;&#30340;&#20998;&#24067;&#31283;&#20581;&#20248;&#21270;&#65288;SA&#65289;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18129v1 Announce Type: cross  Abstract: Fair supervised learning algorithms assigning labels with little dependence on a sensitive attribute have attracted great attention in the machine learning community. While the demographic parity (DP) notion has been frequently used to measure a model's fairness in training fair classifiers, several studies in the literature suggest potential impacts of enforcing DP in fair learning algorithms. In this work, we analytically study the effect of standard DP-based regularization methods on the conditional distribution of the predicted label given the sensitive attribute. Our analysis shows that an imbalanced training dataset with a non-uniform distribution of the sensitive attribute could lead to a classification rule biased toward the sensitive attribute outcome holding the majority of training data. To control such inductive biases in DP-based fair learning, we propose a sensitive attribute-based distributionally robust optimization (SA
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#20855;&#26377;&#21333;&#35843;&#23545;&#25163;&#30340;Top-K&#25490;&#21517;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#26435;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;(MLE)&#65292;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#26041;&#38754;&#25509;&#36817;&#26368;&#20248;&#12290;&#31639;&#27861;&#21019;&#26032;&#21253;&#25324;&#20102;&#23545;&#21152;&#26435;MLE&#30340;&#31934;&#30830;&#19988;&#32039;&#23494;&#30340;$\ell_\infty$&#35823;&#24046;&#20998;&#26512;&#65292;&#24182;&#19982;&#21152;&#26435;&#27604;&#36739;&#22270;&#30340;&#35889;&#29305;&#24615;&#30456;&#20851;&#32852;&#12290;</title><link>https://arxiv.org/abs/2402.07445</link><description>&lt;p&gt;
&#20855;&#26377;&#21333;&#35843;&#23545;&#25163;&#30340;Top-K&#25490;&#21517;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Top-$K$ ranking with a monotone adversary
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07445
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#20855;&#26377;&#21333;&#35843;&#23545;&#25163;&#30340;Top-K&#25490;&#21517;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#26435;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;(MLE)&#65292;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#26041;&#38754;&#25509;&#36817;&#26368;&#20248;&#12290;&#31639;&#27861;&#21019;&#26032;&#21253;&#25324;&#20102;&#23545;&#21152;&#26435;MLE&#30340;&#31934;&#30830;&#19988;&#32039;&#23494;&#30340;$\ell_\infty$&#35823;&#24046;&#20998;&#26512;&#65292;&#24182;&#19982;&#21152;&#26435;&#27604;&#36739;&#22270;&#30340;&#35889;&#29305;&#24615;&#30456;&#20851;&#32852;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#20855;&#26377;&#21333;&#35843;&#23545;&#25163;&#30340;Top-K&#25490;&#21517;&#38382;&#39064;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#27604;&#36739;&#22270;&#34987;&#38543;&#26426;&#29983;&#25104;&#19988;&#23545;&#25163;&#21487;&#20197;&#28155;&#21152;&#20219;&#24847;&#36793;&#30340;&#24773;&#20917;&#12290;&#32479;&#35745;&#23398;&#23478;&#30340;&#30446;&#26631;&#26159;&#26681;&#25454;&#20174;&#36825;&#20010;&#21322;&#38543;&#26426;&#27604;&#36739;&#22270;&#23548;&#20986;&#30340;&#20004;&#20004;&#27604;&#36739;&#20934;&#30830;&#22320;&#35782;&#21035;&#20986;Top-K&#30340;&#39318;&#36873;&#39033;&#12290;&#26412;&#25991;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#24320;&#21457;&#20986;&#19968;&#31181;&#21152;&#26435;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;(MLE)&#65292;&#23427;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#26041;&#38754;&#36798;&#21040;&#20102;&#36817;&#20284;&#26368;&#20248;&#65292;&#26368;&#22810;&#24046;&#19968;&#20010;$log^2(n)$&#30340;&#22240;&#23376;&#65292;&#20854;&#20013;n&#34920;&#31034;&#27604;&#36739;&#39033;&#30340;&#25968;&#37327;&#12290;&#36825;&#24471;&#30410;&#20110;&#20998;&#26512;&#21644;&#31639;&#27861;&#21019;&#26032;&#30340;&#32467;&#21512;&#12290;&#22312;&#20998;&#26512;&#26041;&#38754;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26356;&#26126;&#30830;&#12289;&#26356;&#32039;&#23494;&#30340;&#21152;&#26435;MLE&#30340;$\ell_\infty$&#35823;&#24046;&#20998;&#26512;&#65292;&#23427;&#19982;&#21152;&#26435;&#27604;&#36739;&#22270;&#30340;&#35889;&#29305;&#24615;&#30456;&#20851;&#12290;&#21463;&#27492;&#21551;&#21457;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#21019;&#26032;&#28041;&#21450;&#21040;&#20102;
&lt;/p&gt;
&lt;p&gt;
In this paper, we address the top-$K$ ranking problem with a monotone adversary. We consider the scenario where a comparison graph is randomly generated and the adversary is allowed to add arbitrary edges. The statistician's goal is then to accurately identify the top-$K$ preferred items based on pairwise comparisons derived from this semi-random comparison graph. The main contribution of this paper is to develop a weighted maximum likelihood estimator (MLE) that achieves near-optimal sample complexity, up to a $\log^2(n)$ factor, where n denotes the number of items under comparison. This is made possible through a combination of analytical and algorithmic innovations. On the analytical front, we provide a refined $\ell_\infty$ error analysis of the weighted MLE that is more explicit and tighter than existing analyses. It relates the $\ell_\infty$ error with the spectral properties of the weighted comparison graph. Motivated by this, our algorithmic innovation involves the development 
&lt;/p&gt;</description></item></channel></rss>