<rss version="2.0"><channel><title>Chat Arxiv cs.IT</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IT</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#19981;&#30693;&#36947;&#28304;&#32479;&#35745;&#27169;&#22411;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#39640;&#25928;&#22320;&#23558;&#26679;&#26412;&#20174;&#28304;&#27169;&#22411;&#36716;&#25442;&#20026;&#30446;&#26631;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#24182;&#26500;&#36896;&#20102;&#20960;&#20010;&#24402;&#32422;&#26041;&#27861;&#12290;&#36825;&#20123;&#24402;&#32422;&#26041;&#27861;&#33021;&#36866;&#24212;&#19981;&#21516;&#30340;&#38382;&#39064;&#65292;&#20363;&#22914;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;&#12289;&#30456;&#20301;&#24674;&#22797;&#21644;&#20449;&#21495;&#38477;&#22122;&#31561;&#65292;&#24182;&#19988;&#21487;&#20197;&#22788;&#29702;&#32570;&#22833;&#25968;&#25454;&#12290;&#27492;&#22806;&#65292;&#35813;&#30740;&#31350;&#36824;&#25351;&#20986;&#20102;&#19968;&#20010;&#28508;&#22312;&#30340;&#24212;&#29992;&#65292;&#21363;&#23558;&#19968;&#20010;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;&#36716;&#25442;&#20026;&#21478;&#19968;&#20010;&#26426;&#21046;&#12290;</title><link>https://arxiv.org/abs/2402.07717</link><description>&lt;p&gt;
&#19968;&#20123;&#32479;&#35745;&#27169;&#22411;&#20043;&#38388;&#30340;&#39640;&#25928;&#24402;&#32422;
&lt;/p&gt;
&lt;p&gt;
Efficient reductions between some statistical models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07717
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#19981;&#30693;&#36947;&#28304;&#32479;&#35745;&#27169;&#22411;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#39640;&#25928;&#22320;&#23558;&#26679;&#26412;&#20174;&#28304;&#27169;&#22411;&#36716;&#25442;&#20026;&#30446;&#26631;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#24182;&#26500;&#36896;&#20102;&#20960;&#20010;&#24402;&#32422;&#26041;&#27861;&#12290;&#36825;&#20123;&#24402;&#32422;&#26041;&#27861;&#33021;&#36866;&#24212;&#19981;&#21516;&#30340;&#38382;&#39064;&#65292;&#20363;&#22914;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;&#12289;&#30456;&#20301;&#24674;&#22797;&#21644;&#20449;&#21495;&#38477;&#22122;&#31561;&#65292;&#24182;&#19988;&#21487;&#20197;&#22788;&#29702;&#32570;&#22833;&#25968;&#25454;&#12290;&#27492;&#22806;&#65292;&#35813;&#30740;&#31350;&#36824;&#25351;&#20986;&#20102;&#19968;&#20010;&#28508;&#22312;&#30340;&#24212;&#29992;&#65292;&#21363;&#23558;&#19968;&#20010;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;&#36716;&#25442;&#20026;&#21478;&#19968;&#20010;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#19981;&#30693;&#36947;&#28304;&#27169;&#22411;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#36817;&#20284;&#22320;&#23558;&#26469;&#33258;&#28304;&#32479;&#35745;&#27169;&#22411;&#30340;&#26679;&#26412;&#36716;&#25442;&#20026;&#30446;&#26631;&#32479;&#35745;&#27169;&#22411;&#30340;&#26679;&#26412;&#30340;&#38382;&#39064;&#65292;&#24182;&#26500;&#36896;&#20102;&#20960;&#20010;&#35745;&#31639;&#19978;&#39640;&#25928;&#30340;&#36825;&#31181;&#32479;&#35745;&#23454;&#39564;&#20043;&#38388;&#30340;&#24402;&#32422;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#35745;&#31639;&#19978;&#39640;&#25928;&#30340;&#31243;&#24207;&#65292;&#21487;&#20197;&#36817;&#20284;&#23558;&#22343;&#21248;&#20998;&#24067;&#12289;Erlang&#20998;&#24067;&#21644;&#25289;&#26222;&#25289;&#26031;&#20998;&#24067;&#30340;&#20301;&#32622;&#27169;&#22411;&#24402;&#32422;&#21040;&#19968;&#33324;&#30340;&#30446;&#26631;&#26063;&#12290;&#25105;&#20204;&#36890;&#36807;&#24314;&#31435;&#19968;&#20123;&#32463;&#20856;&#30340;&#39640;&#32500;&#38382;&#39064;&#20043;&#38388;&#30340;&#38750;&#28176;&#36817;&#24402;&#32422;&#26469;&#35828;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;&#12289;&#30456;&#20301;&#24674;&#22797;&#21644;&#20449;&#21495;&#38477;&#22122;&#31561;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#36825;&#20123;&#24402;&#32422;&#20445;&#25345;&#20102;&#32467;&#26500;&#65292;&#24182;&#21487;&#20197;&#36866;&#24212;&#32570;&#22833;&#25968;&#25454;&#12290;&#25105;&#20204;&#36824;&#25351;&#20986;&#20102;&#23558;&#19968;&#20010;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;&#36716;&#25442;&#20026;&#21478;&#19968;&#20010;&#26426;&#21046;&#30340;&#21487;&#33021;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of approximately transforming a sample from a source statistical model to a sample from a target statistical model without knowing the parameters of the source model, and construct several computationally efficient such reductions between statistical experiments. In particular, we provide computationally efficient procedures that approximately reduce uniform, Erlang, and Laplace location models to general target families. We illustrate our methodology by establishing nonasymptotic reductions between some canonical high-dimensional problems, spanning mixtures of experts, phase retrieval, and signal denoising. Notably, the reductions are structure preserving and can accommodate missing data. We also point to a possible application in transforming one differentially private mechanism to another.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#21033;&#29992;&#40654;&#26364;&#20960;&#20309;&#21644;&#21494;&#38754;&#29702;&#35770;&#21019;&#26032;&#24212;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#40065;&#26834;&#24615;&#30340;&#26032;&#35270;&#35282;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#25968;&#25454;&#31354;&#38388;&#30340;&#20197;&#26354;&#29575;&#20026;&#32771;&#37327;&#22240;&#32032;&#30340; two-step spectral &#23545;&#25239;&#25915;&#20987;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2203.00922</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#30340;&#35268;&#33539;&#21494;&#38754;&#65306;&#40065;&#26834;&#24615;&#24212;&#29992;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Canonical foliations of neural networks: application to robustness. (arXiv:2203.00922v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.00922
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#21033;&#29992;&#40654;&#26364;&#20960;&#20309;&#21644;&#21494;&#38754;&#29702;&#35770;&#21019;&#26032;&#24212;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#40065;&#26834;&#24615;&#30340;&#26032;&#35270;&#35282;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#25968;&#25454;&#31354;&#38388;&#30340;&#20197;&#26354;&#29575;&#20026;&#32771;&#37327;&#22240;&#32032;&#30340; two-step spectral &#23545;&#25239;&#25915;&#20987;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#26131;&#21463;&#21040;&#23545;&#25239;&#25915;&#20987;&#12290;&#32780;&#23545;&#25239;&#23398;&#20064;&#27491;&#22312;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31070;&#32463;&#32593;&#32476;&#40065;&#26834;&#24615;&#35270;&#35282;&#65292;&#37319;&#29992;&#40654;&#26364;&#20960;&#20309;&#21644;&#21494;&#38754;&#29702;&#35770;&#12290;&#36890;&#36807;&#21019;&#24314;&#32771;&#34385;&#25968;&#25454;&#31354;&#38388;&#26354;&#29575;&#30340;&#26032;&#23545;&#25239;&#25915;&#20987;&#65292;&#21363; two-step spectral attack&#65292;&#26469;&#35828;&#26126;&#36825;&#20010;&#24819;&#27861;&#12290;&#25968;&#25454;&#31354;&#38388;&#34987;&#35270;&#20026;&#19968;&#20010;&#37197;&#22791;&#20102;&#31070;&#32463;&#32593;&#32476;&#30340; Fisher &#20449;&#24687;&#24230;&#37327;&#65288;FIM&#65289;&#25289;&#22238;&#30340;&#65288;&#36864;&#21270;&#30340;&#65289;&#40654;&#26364;&#27969;&#24418;&#12290;&#22823;&#22810;&#25968;&#24773;&#20917;&#19979;&#65292;&#35813;&#24230;&#37327;&#20165;&#20026;&#21322;&#27491;&#23450;&#65292;&#20854;&#20869;&#26680;&#25104;&#20026;&#30740;&#31350;&#30340;&#26680;&#24515;&#23545;&#35937;&#12290;&#20174;&#35813;&#26680;&#20013;&#23548;&#20986;&#19968;&#20010;&#35268;&#33539;&#21494;&#38754;&#12290;&#27178;&#21521;&#21494;&#30340;&#26354;&#29575;&#32473;&#20986;&#20102;&#36866;&#24403;&#30340;&#20462;&#27491;&#65292;&#20174;&#32780;&#24471;&#21040;&#20102;&#20004;&#27493;&#36817;&#20284;&#30340;&#27979;&#22320;&#32447;&#21644;&#19968;&#31181;&#26032;&#30340;&#39640;&#25928;&#23545;&#25239;&#25915;&#20987;&#12290;&#35813;&#26041;&#27861;&#39318;&#20808;&#22312;&#19968;&#20010; 2D &#29609;&#20855;&#31034;&#20363;&#20013;&#36827;&#34892;&#28436;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning models are known to be vulnerable to adversarial attacks. Adversarial learning is therefore becoming a crucial task. We propose a new vision on neural network robustness using Riemannian geometry and foliation theory. The idea is illustrated by creating a new adversarial attack that takes into account the curvature of the data space. This new adversarial attack called the two-step spectral attack is a piece-wise linear approximation of a geodesic in the data space. The data space is treated as a (degenerate) Riemannian manifold equipped with the pullback of the Fisher Information Metric (FIM) of the neural network. In most cases, this metric is only semi-definite and its kernel becomes a central object to study. A canonical foliation is derived from this kernel. The curvature of transverse leaves gives the appropriate correction to get a two-step approximation of the geodesic and hence a new efficient adversarial attack. The method is first illustrated on a 2D toy example
&lt;/p&gt;</description></item></channel></rss>