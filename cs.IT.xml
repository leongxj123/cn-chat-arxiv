<rss version="2.0"><channel><title>Chat Arxiv cs.IT</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IT</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#21442;&#25968;&#30340;&#20108;&#20301;&#21327;&#26041;&#24046;&#20272;&#35745;&#22120;&#65292;&#36890;&#36807;&#20351;&#29992;&#21464;&#21270;&#30340;&#25238;&#21160;&#23610;&#24230;&#65292;&#35299;&#20915;&#20102;&#22312;&#21327;&#26041;&#24046;&#30697;&#38453;&#23545;&#35282;&#32447;&#20027;&#23548;&#24773;&#20917;&#19979;&#20272;&#35745;&#22120;&#19982;&#26679;&#26412;&#21327;&#26041;&#24046;&#20043;&#38388;&#30340;&#31639;&#23376;&#33539;&#25968;&#35823;&#24046;&#24046;&#36317;&#20197;&#21450;&#20381;&#36182;&#26410;&#30693;&#21442;&#25968;&#30340;&#25238;&#21160;&#23610;&#24230;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.16059</link><description>&lt;p&gt;
&#19968;&#31181;&#26080;&#38656;&#21442;&#25968;&#30340;&#25913;&#36827;&#20108;&#20301;&#21327;&#26041;&#24046;&#20272;&#35745;&#22120;
&lt;/p&gt;
&lt;p&gt;
A Parameter-Free Two-Bit Covariance Estimator with Improved Operator Norm Error Rate. (arXiv:2308.16059v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16059
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#21442;&#25968;&#30340;&#20108;&#20301;&#21327;&#26041;&#24046;&#20272;&#35745;&#22120;&#65292;&#36890;&#36807;&#20351;&#29992;&#21464;&#21270;&#30340;&#25238;&#21160;&#23610;&#24230;&#65292;&#35299;&#20915;&#20102;&#22312;&#21327;&#26041;&#24046;&#30697;&#38453;&#23545;&#35282;&#32447;&#20027;&#23548;&#24773;&#20917;&#19979;&#20272;&#35745;&#22120;&#19982;&#26679;&#26412;&#21327;&#26041;&#24046;&#20043;&#38388;&#30340;&#31639;&#23376;&#33539;&#25968;&#35823;&#24046;&#24046;&#36317;&#20197;&#21450;&#20381;&#36182;&#26410;&#30693;&#21442;&#25968;&#30340;&#25238;&#21160;&#23610;&#24230;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;Dirksen, Maly and Rauhut&#22312;&#12298;Annals of Statistics&#12299;&#19978;&#24320;&#21457;&#20102;&#19968;&#31181;&#20351;&#29992;&#27599;&#20010;&#26465;&#30446;&#20004;&#20301;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#22120;&#12290;&#35813;&#20272;&#35745;&#22120;&#22312;&#19968;&#33324;&#20122;&#39640;&#26031;&#20998;&#24067;&#19979;&#36798;&#21040;&#20102;&#36817;&#20284;&#26497;&#23567;&#21270;&#36895;&#29575;&#65292;&#20294;&#20063;&#23384;&#22312;&#20004;&#20010;&#38382;&#39064;&#65306;&#29702;&#35770;&#19978;&#65292;&#22312;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#23545;&#35282;&#32447;&#30001;&#23569;&#25968;&#26465;&#30446;&#20027;&#23548;&#26102;&#65292;&#20854;&#20272;&#35745;&#22120;&#19982;&#26679;&#26412;&#21327;&#26041;&#24046;&#20043;&#38388;&#23384;&#22312;&#26412;&#36136;&#19978;&#30340;&#31639;&#23376;&#33539;&#25968;&#35823;&#24046;&#24046;&#36317;&#65307;&#23454;&#38469;&#19978;&#65292;&#20854;&#24615;&#33021;&#20005;&#37325;&#20381;&#36182;&#20110;&#38656;&#35201;&#26681;&#25454;&#19968;&#20123;&#26410;&#30693;&#21442;&#25968;&#36827;&#34892;&#35843;&#25972;&#30340;&#25238;&#21160;&#23610;&#24230;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21516;&#26102;&#35299;&#20915;&#36825;&#20004;&#20010;&#38382;&#39064;&#30340;&#26032;&#22411;&#20108;&#20301;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#22120;&#12290;&#19982;Dirksen&#31561;&#20154;&#37319;&#29992;&#30340;&#22343;&#21248;&#25238;&#21160;&#30456;&#20851;&#30340;&#31526;&#21495;&#37327;&#21270;&#22120;&#19981;&#21516;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#21463;&#22810;&#20301;&#22343;&#21248;&#37327;&#21270;&#22120;&#21551;&#21457;&#30340;&#19977;&#35282;&#25238;&#21160;&#22120;&#20043;&#21518;&#20877;&#36827;&#34892;&#20108;&#20301;&#37327;&#21270;&#12290;&#36890;&#36807;&#20351;&#29992;&#21508;&#20010;&#26465;&#30446;&#20043;&#38388;&#21464;&#21270;&#30340;&#25238;&#21160;&#23610;&#24230;&#65292;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#33719;&#24471;&#20102;&#25913;&#36827;&#30340;&#31639;&#23376;&#33539;&#25968;&#35823;&#24046;&#29575;&#65292;&#35813;&#35823;&#24046;&#29575;&#21462;&#20915;&#20110;...
&lt;/p&gt;
&lt;p&gt;
A covariance matrix estimator using two bits per entry was recently developed by Dirksen, Maly and Rauhut [Annals of Statistics, 50(6), pp. 3538-3562]. The estimator achieves near minimax rate for general sub-Gaussian distributions, but also suffers from two downsides: theoretically, there is an essential gap on operator norm error between their estimator and sample covariance when the diagonal of the covariance matrix is dominated by only a few entries; practically, its performance heavily relies on the dithering scale, which needs to be tuned according to some unknown parameters. In this work, we propose a new 2-bit covariance matrix estimator that simultaneously addresses both issues. Unlike the sign quantizer associated with uniform dither in Dirksen et al., we adopt a triangular dither prior to a 2-bit quantizer inspired by the multi-bit uniform quantizer. By employing dithering scales varying across entries, our estimator enjoys an improved operator norm error rate that depends o
&lt;/p&gt;</description></item></channel></rss>