<rss version="2.0"><channel><title>Chat Arxiv cs.IT</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IT</description><item><title>&#35770;&#25991;&#30740;&#31350;&#20102;&#20108;&#27425;Littlewood-Offord&#38382;&#39064;&#30340;&#32479;&#35745;&#40065;&#26834;&#24615;&#65292;&#20272;&#35745;&#20102;&#23545;&#25239;&#24615;&#22122;&#22768;&#23545;&#20108;&#27425;Radamecher&#28151;&#27788;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#20108;&#27425;&#21644;&#21452;&#32447;&#24615;Rademacher&#28151;&#27788;&#30340;&#32479;&#35745;&#40065;&#26834;&#24615;&#30340;&#19979;&#38480;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2402.10504</link><description>&lt;p&gt;
&#20108;&#27425;Littlewood-Offord&#38382;&#39064;&#30340;&#24377;&#24615;
&lt;/p&gt;
&lt;p&gt;
Resilience of the quadratic Littlewood-Offord problem
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10504
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#30740;&#31350;&#20102;&#20108;&#27425;Littlewood-Offord&#38382;&#39064;&#30340;&#32479;&#35745;&#40065;&#26834;&#24615;&#65292;&#20272;&#35745;&#20102;&#23545;&#25239;&#24615;&#22122;&#22768;&#23545;&#20108;&#27425;Radamecher&#28151;&#27788;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#20108;&#27425;&#21644;&#21452;&#32447;&#24615;Rademacher&#28151;&#27788;&#30340;&#32479;&#35745;&#40065;&#26834;&#24615;&#30340;&#19979;&#38480;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#39640;&#32500;&#25968;&#25454;&#30340;&#32479;&#35745;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25552;&#20379;&#20102;&#20851;&#20110;&#23545;&#25239;&#24615;&#22122;&#22768;&#23545;&#20108;&#27425;Radamecher&#28151;&#27788;$\boldsymbol{\xi}^{\mathsf{T}} M \boldsymbol{\xi}$&#21453;&#38598;&#20013;&#29305;&#24615;&#30340;&#24433;&#21709;&#30340;&#20272;&#35745;&#65292;&#20854;&#20013;$M$&#26159;&#19968;&#20010;&#22266;&#23450;&#30340;&#65288;&#39640;&#32500;&#65289;&#30697;&#38453;&#65292;$\boldsymbol{\xi}$&#26159;&#19968;&#20010;&#20849;&#24418;Rademacher&#21521;&#37327;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;$\boldsymbol{\xi}$&#33021;&#22815;&#25215;&#21463;&#22810;&#23569;&#23545;&#25239;&#24615;&#31526;&#21495;&#32763;&#36716;&#32780;&#19981;&#8220;&#33192;&#32960;&#8221;$\sup_{x\in \mathbb{R}} \mathbb{P} \left\{\boldsymbol{\xi}^{\mathsf{T}} M \boldsymbol{\xi} = x\right\}$&#65292;&#20174;&#32780;&#8220;&#21435;&#38500;&#8221;&#21407;&#22987;&#20998;&#24067;&#23548;&#33268;&#26356;&#8220;&#26377;&#31890;&#24230;&#8221;&#21644;&#23545;&#25239;&#24615;&#20559;&#20506;&#30340;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20026;&#20108;&#27425;&#21644;&#21452;&#32447;&#24615;Rademacher&#28151;&#27788;&#30340;&#32479;&#35745;&#40065;&#26834;&#24615;&#25552;&#20379;&#20102;&#19979;&#38480;&#20272;&#35745;&#65307;&#36825;&#20123;&#32467;&#26524;&#22312;&#20851;&#38190;&#21306;&#22495;&#34987;&#35777;&#26126;&#26159;&#28176;&#36817;&#32039;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10504v1 Announce Type: cross  Abstract: We study the statistical resilience of high-dimensional data. Our results provide estimates as to the effects of adversarial noise over the anti-concentration properties of the quadratic Radamecher chaos $\boldsymbol{\xi}^{\mathsf{T}} M \boldsymbol{\xi}$, where $M$ is a fixed (high-dimensional) matrix and $\boldsymbol{\xi}$ is a conformal Rademacher vector. Specifically, we pursue the question of how many adversarial sign-flips can $\boldsymbol{\xi}$ sustain without "inflating" $\sup_{x\in \mathbb{R}} \mathbb{P} \left\{\boldsymbol{\xi}^{\mathsf{T}} M \boldsymbol{\xi} = x\right\}$ and thus "de-smooth" the original distribution resulting in a more "grainy" and adversarially biased distribution. Our results provide lower bound estimations for the statistical resilience of the quadratic and bilinear Rademacher chaos; these are shown to be asymptotically tight across key regimes.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#22522;&#20110;&#20449;&#24687;&#29702;&#35770;&#30340;&#32479;&#19968;&#21407;&#29702;&#65292;&#29992;&#20110;&#37325;&#26032;&#25512;&#23548;&#21644;&#25512;&#24191;&#29616;&#26377;&#30340;&#21464;&#20998;&#38477;&#32500;&#26041;&#27861;&#65292;&#24182;&#35774;&#35745;&#26032;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#23558;&#22810;&#21464;&#37327;&#20449;&#24687;&#29942;&#39048;&#35299;&#37322;&#20026;&#20004;&#20010;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#26435;&#34913;&#65292;&#35813;&#26694;&#26550;&#24341;&#20837;&#20102;&#19968;&#20010;&#22312;&#21387;&#32553;&#25968;&#25454;&#21644;&#20445;&#30041;&#20449;&#24687;&#20043;&#38388;&#30340;&#26435;&#34913;&#21442;&#25968;&#12290;</title><link>http://arxiv.org/abs/2310.03311</link><description>&lt;p&gt;
&#28145;&#24230;&#21464;&#20998;&#22810;&#21464;&#37327;&#20449;&#24687;&#29942;&#39048;--&#19968;&#31181;&#21464;&#20998;&#25439;&#22833;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Deep Variational Multivariate Information Bottleneck -- A Framework for Variational Losses. (arXiv:2310.03311v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03311
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#22522;&#20110;&#20449;&#24687;&#29702;&#35770;&#30340;&#32479;&#19968;&#21407;&#29702;&#65292;&#29992;&#20110;&#37325;&#26032;&#25512;&#23548;&#21644;&#25512;&#24191;&#29616;&#26377;&#30340;&#21464;&#20998;&#38477;&#32500;&#26041;&#27861;&#65292;&#24182;&#35774;&#35745;&#26032;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#23558;&#22810;&#21464;&#37327;&#20449;&#24687;&#29942;&#39048;&#35299;&#37322;&#20026;&#20004;&#20010;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#26435;&#34913;&#65292;&#35813;&#26694;&#26550;&#24341;&#20837;&#20102;&#19968;&#20010;&#22312;&#21387;&#32553;&#25968;&#25454;&#21644;&#20445;&#30041;&#20449;&#24687;&#20043;&#38388;&#30340;&#26435;&#34913;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#38477;&#32500;&#26041;&#27861;&#20197;&#20854;&#39640;&#31934;&#24230;&#12289;&#29983;&#25104;&#33021;&#21147;&#21644;&#40065;&#26834;&#24615;&#32780;&#38395;&#21517;&#12290;&#36825;&#20123;&#26041;&#27861;&#26377;&#24456;&#22810;&#29702;&#35770;&#19978;&#30340;&#35777;&#26126;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#20449;&#24687;&#29702;&#35770;&#30340;&#32479;&#19968;&#21407;&#29702;&#65292;&#37325;&#26032;&#25512;&#23548;&#21644;&#25512;&#24191;&#20102;&#29616;&#26377;&#30340;&#21464;&#20998;&#26041;&#27861;&#65292;&#24182;&#35774;&#35745;&#20102;&#26032;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#22522;&#20110;&#22810;&#21464;&#37327;&#20449;&#24687;&#29942;&#39048;&#30340;&#35299;&#37322;&#65292;&#20854;&#20013;&#20004;&#20010;&#36125;&#21494;&#26031;&#32593;&#32476;&#30456;&#20114;&#26435;&#34913;&#12290;&#25105;&#20204;&#23558;&#31532;&#19968;&#20010;&#32593;&#32476;&#35299;&#37322;&#20026;&#32534;&#30721;&#22120;&#22270;&#65292;&#23427;&#25351;&#23450;&#20102;&#22312;&#21387;&#32553;&#25968;&#25454;&#26102;&#35201;&#20445;&#30041;&#30340;&#20449;&#24687;&#12290;&#25105;&#20204;&#23558;&#31532;&#20108;&#20010;&#32593;&#32476;&#35299;&#37322;&#20026;&#35299;&#30721;&#22120;&#22270;&#65292;&#23427;&#20026;&#25968;&#25454;&#25351;&#23450;&#20102;&#19968;&#20010;&#29983;&#25104;&#27169;&#22411;&#12290;&#20351;&#29992;&#36825;&#20010;&#26694;&#26550;&#65292;&#25105;&#20204;&#37325;&#26032;&#25512;&#23548;&#20102;&#29616;&#26377;&#30340;&#38477;&#32500;&#26041;&#27861;&#65292;&#22914;&#28145;&#24230;&#21464;&#20998;&#20449;&#24687;&#29942;&#39048;(DVIB)&#12289;beta&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;(beta-VAE)&#21644;&#28145;&#24230;&#21464;&#20998;&#35268;&#33539;&#30456;&#20851;&#20998;&#26512;(DVCCA)&#12290;&#35813;&#26694;&#26550;&#33258;&#28982;&#22320;&#24341;&#20837;&#20102;&#19968;&#20010;&#22312;&#21387;&#32553;&#25968;&#25454;&#21644;&#20445;&#30041;&#20449;&#24687;&#20043;&#38388;&#30340;&#26435;&#34913;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational dimensionality reduction methods are known for their high accuracy, generative abilities, and robustness. These methods have many theoretical justifications. Here we introduce a unifying principle rooted in information theory to rederive and generalize existing variational methods and design new ones. We base our framework on an interpretation of the multivariate information bottleneck, in which two Bayesian networks are traded off against one another. We interpret the first network as an encoder graph, which specifies what information to keep when compressing the data. We interpret the second network as a decoder graph, which specifies a generative model for the data. Using this framework, we rederive existing dimensionality reduction methods such as the deep variational information bottleneck (DVIB), beta variational auto-encoders (beta-VAE), and deep variational canonical correlation analysis (DVCCA). The framework naturally introduces a trade-off parameter between compr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;&#26368;&#23567;&#23616;&#37096;&#22522;&#20110;&#35821;&#27861;&#30340;&#32534;&#30721;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#12289;&#26356;&#31616;&#21333;&#12289;&#26356;&#26222;&#36941;&#30340;&#35777;&#26126;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#26368;&#23567;&#20998;&#22359;&#32534;&#30721;&#20855;&#26377;&#24378;&#22823;&#30340;&#26222;&#36941;&#24615;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#23454;&#39564;&#20063;&#34920;&#26126;&#65292;&#26368;&#23567;&#20998;&#22359;&#32534;&#30721;&#20013;&#30340;&#35268;&#21017;&#25968;&#37327;&#19981;&#33021;&#26126;&#30830;&#21306;&#20998;&#38271;&#35760;&#24518;&#21644;&#26080;&#35760;&#24518;&#30340;&#28304;&#12290;</title><link>http://arxiv.org/abs/2209.13636</link><description>&lt;p&gt;
&#26412;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;&#23616;&#37096;&#22522;&#20110;&#35821;&#27861;&#30340;&#32534;&#30721;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Local Grammar-Based Coding Revisited. (arXiv:2209.13636v2 [cs.IT] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.13636
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;&#26368;&#23567;&#23616;&#37096;&#22522;&#20110;&#35821;&#27861;&#30340;&#32534;&#30721;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#12289;&#26356;&#31616;&#21333;&#12289;&#26356;&#26222;&#36941;&#30340;&#35777;&#26126;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#26368;&#23567;&#20998;&#22359;&#32534;&#30721;&#20855;&#26377;&#24378;&#22823;&#30340;&#26222;&#36941;&#24615;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#23454;&#39564;&#20063;&#34920;&#26126;&#65292;&#26368;&#23567;&#20998;&#22359;&#32534;&#30721;&#20013;&#30340;&#35268;&#21017;&#25968;&#37327;&#19981;&#33021;&#26126;&#30830;&#21306;&#20998;&#38271;&#35760;&#24518;&#21644;&#26080;&#35760;&#24518;&#30340;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;&#26368;&#23567;&#23616;&#37096;&#22522;&#20110;&#35821;&#27861;&#30340;&#32534;&#30721;&#38382;&#39064;&#12290;&#22312;&#36825;&#20010;&#35774;&#32622;&#20013;&#65292;&#23616;&#37096;&#22522;&#20110;&#35821;&#27861;&#30340;&#32534;&#30721;&#22120;&#36880;&#20010;&#31526;&#21495;&#22320;&#23545;&#35821;&#27861;&#36827;&#34892;&#32534;&#30721;&#65292;&#32780;&#26368;&#23567;&#35821;&#27861;&#21464;&#25442;&#36890;&#36807;&#23616;&#37096;&#35821;&#27861;&#32534;&#30721;&#30340;&#38271;&#24230;&#22312;&#39044;&#35774;&#30340;&#35821;&#27861;&#31867;&#21035;&#20013;&#26368;&#23567;&#21270;&#35821;&#27861;&#38271;&#24230;&#12290;&#24050;&#30693;&#65292;&#36825;&#26679;&#30340;&#26368;&#23567;&#32534;&#30721;&#23545;&#20110;&#20005;&#26684;&#27491;&#29109;&#29575;&#30340;&#24773;&#20917;&#20855;&#26377;&#24378;&#22823;&#30340;&#26222;&#36941;&#24615;&#65292;&#32780;&#26368;&#23567;&#35821;&#27861;&#20013;&#30340;&#35268;&#21017;&#25968;&#37327;&#26500;&#25104;&#20102;&#28304;&#30340;&#20114;&#20449;&#24687;&#30340;&#19978;&#30028;&#12290;&#23613;&#31649;&#23436;&#20840;&#26368;&#23567;&#32534;&#30721;&#21487;&#33021;&#26159;&#19981;&#21487;&#34892;&#30340;&#65292;&#20294;&#21463;&#38480;&#30340;&#26368;&#23567;&#20998;&#22359;&#32534;&#30721;&#21487;&#20197;&#26377;&#25928;&#35745;&#31639;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#12289;&#26356;&#31616;&#21333;&#12289;&#26356;&#26222;&#36866;&#30340;&#26368;&#23567;&#20998;&#22359;&#32534;&#30721;&#24378;&#22823;&#26222;&#36941;&#24615;&#30340;&#35777;&#26126;&#26041;&#27861;&#65292;&#19981;&#21463;&#29109;&#29575;&#30340;&#38480;&#21046;&#12290;&#35813;&#35777;&#26126;&#22522;&#20110;&#23545;&#25490;&#21517;&#27010;&#29575;&#30340;&#31616;&#21333;&#30340;Zipfian&#30028;&#38480;&#12290;&#39034;&#20415;&#25552;&#19968;&#19979;&#65292;&#25105;&#20204;&#36824;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#26368;&#23567;&#20998;&#22359;&#32534;&#30721;&#20013;&#30340;&#35268;&#21017;&#25968;&#37327;&#19981;&#33021;&#26126;&#30830;&#21306;&#20998;&#38271;&#35760;&#24518;&#21644;&#26080;&#35760;&#24518;&#30340;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;
We revisit the problem of minimal local grammar-based coding. In this setting, the local grammar encoder encodes grammars symbol by symbol, whereas the minimal grammar transform minimizes the grammar length in a preset class of grammars as given by the length of local grammar encoding. It has been known that such minimal codes are strongly universal for a strictly positive entropy rate, whereas the number of rules in the minimal grammar constitutes an upper bound for the mutual information of the source. Whereas the fully minimal code is likely intractable, the constrained minimal block code can be efficiently computed. In this article, we present a new, simpler, and more general proof of strong universality of the minimal block code, regardless of the entropy rate. The proof is based on a simple Zipfian bound for ranked probabilities. By the way, we also show empirically that the number of rules in the minimal block code cannot clearly discriminate between long-memory and memoryless s
&lt;/p&gt;</description></item></channel></rss>