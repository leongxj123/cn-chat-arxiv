<rss version="2.0"><channel><title>Chat Arxiv cs.CG</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CG</description><item><title>&#26412;&#25991;&#36890;&#36807;&#25935;&#24863;&#24615;&#25277;&#26679;&#26694;&#26550;&#25552;&#20986;&#20102;&#26080;&#32500;&#24230;&#30340;&#26680;&#24515;&#23376;&#38598;&#29992;&#20110;&#20998;&#31867;&#38382;&#39064;&#65292;&#35813;&#23376;&#38598;&#30340;&#22823;&#23567;&#19982;&#32500;&#24230;&#26080;&#20851;&#65292;&#24182;&#36866;&#29992;&#20110;&#21508;&#31181;&#25439;&#22833;&#20989;&#25968;&#21644;&#20998;&#24067;&#36755;&#20837;&#12290;</title><link>https://arxiv.org/abs/2402.05280</link><description>&lt;p&gt;
&#26080;&#32500;&#24230;&#25277;&#26679;&#26680;&#24515;&#23376;&#38598;&#29992;&#20110;&#20998;&#31867;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
No Dimensional Sampling Coresets for Classification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05280
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25935;&#24863;&#24615;&#25277;&#26679;&#26694;&#26550;&#25552;&#20986;&#20102;&#26080;&#32500;&#24230;&#30340;&#26680;&#24515;&#23376;&#38598;&#29992;&#20110;&#20998;&#31867;&#38382;&#39064;&#65292;&#35813;&#23376;&#38598;&#30340;&#22823;&#23567;&#19982;&#32500;&#24230;&#26080;&#20851;&#65292;&#24182;&#36866;&#29992;&#20110;&#21508;&#31181;&#25439;&#22833;&#20989;&#25968;&#21644;&#20998;&#24067;&#36755;&#20837;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36890;&#36807;&#25935;&#24863;&#24615;&#25277;&#26679;&#26694;&#26550;&#23545;&#20110;&#20998;&#31867;&#38382;&#39064;&#30340;&#26680;&#24515;&#23376;&#38598;&#30340;&#24050;&#30693;&#20869;&#23481;&#36827;&#34892;&#20102;&#31934;&#28860;&#21644;&#27010;&#25324;&#12290;&#36825;&#31181;&#26680;&#24515;&#23376;&#38598;&#23547;&#27714;&#36755;&#20837;&#25968;&#25454;&#30340;&#26368;&#23567;&#21487;&#33021;&#23376;&#38598;&#65292;&#20197;&#20415;&#21487;&#20197;&#22312;&#26680;&#24515;&#23376;&#38598;&#19978;&#20248;&#21270;&#25439;&#22833;&#20989;&#25968;&#65292;&#24182;&#30830;&#20445;&#23545;&#20110;&#21407;&#22987;&#25968;&#25454;&#30340;&#36924;&#36817;&#20445;&#35777;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#26080;&#32500;&#24230;&#26680;&#24515;&#23376;&#38598;&#65292;&#22240;&#27492;&#22823;&#23567;&#19982;&#32500;&#24230;&#26080;&#20851;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#26159;&#36890;&#29992;&#30340;&#65292;&#36866;&#29992;&#20110;&#20998;&#24067;&#36755;&#20837;&#24182;&#19988;&#21487;&#20197;&#20351;&#29992;&#29420;&#31435;&#21516;&#20998;&#24067;&#26679;&#26412;&#65292;&#22240;&#27492;&#21487;&#20197;&#25552;&#20379;&#26679;&#26412;&#22797;&#26434;&#24230;&#36793;&#30028;&#65292;&#24182;&#36866;&#29992;&#20110;&#21508;&#31181;&#25439;&#22833;&#20989;&#25968;&#12290;&#25105;&#20204;&#24320;&#21457;&#30340;&#20851;&#38190;&#24037;&#20855;&#26159;&#20027;&#35201;&#25935;&#24863;&#24615;&#25277;&#26679;&#26041;&#27861;&#30340;Radamacher&#22797;&#26434;&#24230;&#29256;&#26412;&#65292;&#36825;&#21487;&#33021;&#26159;&#19968;&#20010;&#29420;&#31435;&#24863;&#20852;&#36259;&#30340;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
We refine and generalize what is known about coresets for classification problems via the sensitivity sampling framework. Such coresets seek the smallest possible subsets of input data, so one can optimize a loss function on the coreset and ensure approximation guarantees with respect to the original data. Our analysis provides the first no dimensional coresets, so the size does not depend on the dimension. Moreover, our results are general, apply for distributional input and can use iid samples, so provide sample complexity bounds, and work for a variety of loss functions. A key tool we develop is a Radamacher complexity version of the main sensitivity sampling approach, which can be of independent interest.
&lt;/p&gt;</description></item></channel></rss>