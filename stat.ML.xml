<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35780;&#20272;&#24046;&#20998;&#38544;&#31169;&#21512;&#25104;&#29983;&#29289;&#21307;&#23398;&#25968;&#25454;&#19978;&#30340;Mann-Whitney U&#26816;&#39564;&#65292;&#20197;&#30830;&#23450;&#22312;&#38544;&#31169;&#20445;&#25252;&#21512;&#25104;&#25968;&#25454;&#19978;&#25191;&#34892;&#30340;&#32479;&#35745;&#20551;&#35774;&#26816;&#39564;&#26159;&#21542;&#21487;&#33021;&#23548;&#33268;&#27979;&#35797;&#26377;&#25928;&#24615;&#30340;&#20007;&#22833;&#25110;&#21151;&#29575;&#19979;&#38477;&#12290;</title><link>https://arxiv.org/abs/2403.13612</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#21512;&#25104;&#25968;&#25454;&#33021;&#23548;&#33268;&#21512;&#25104;&#21457;&#29616;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Does Differentially Private Synthetic Data Lead to Synthetic Discoveries?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13612
&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#24046;&#20998;&#38544;&#31169;&#21512;&#25104;&#29983;&#29289;&#21307;&#23398;&#25968;&#25454;&#19978;&#30340;Mann-Whitney U&#26816;&#39564;&#65292;&#20197;&#30830;&#23450;&#22312;&#38544;&#31169;&#20445;&#25252;&#21512;&#25104;&#25968;&#25454;&#19978;&#25191;&#34892;&#30340;&#32479;&#35745;&#20551;&#35774;&#26816;&#39564;&#26159;&#21542;&#21487;&#33021;&#23548;&#33268;&#27979;&#35797;&#26377;&#25928;&#24615;&#30340;&#20007;&#22833;&#25110;&#21151;&#29575;&#19979;&#38477;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21512;&#25104;&#25968;&#25454;&#24050;&#34987;&#25552;&#20986;&#20316;&#20026;&#20849;&#20139;&#25935;&#24863;&#29983;&#29289;&#21307;&#23398;&#25968;&#25454;&#30340;&#21311;&#21517;&#21270;&#35299;&#20915;&#26041;&#26696;&#12290;&#29702;&#24819;&#24773;&#20917;&#19979;&#65292;&#21512;&#25104;&#25968;&#25454;&#24212;&#20445;&#30041;&#21407;&#22987;&#25968;&#25454;&#30340;&#32467;&#26500;&#21644;&#32479;&#35745;&#29305;&#24615;&#65292;&#21516;&#26102;&#20445;&#25252;&#20010;&#20307;&#20027;&#20307;&#30340;&#38544;&#31169;&#12290;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#30446;&#21069;&#34987;&#35748;&#20026;&#26159;&#24179;&#34913;&#36825;&#31181;&#26435;&#34913;&#30340;&#26368;&#20339;&#26041;&#27861;&#12290;&#26412;&#30740;&#31350;&#30340;&#30446;&#30340;&#26159;&#35780;&#20272;&#22312;&#24046;&#20998;&#38544;&#31169;&#29983;&#29289;&#21307;&#23398;&#25968;&#25454;&#19978;&#36827;&#34892;&#30340;Mann-Whitney U&#26816;&#39564;&#22312;I&#22411;&#21644;II&#22411;&#38169;&#35823;&#26041;&#38754;&#65292;&#20197;&#30830;&#23450;&#22312;&#38544;&#31169;&#20445;&#25252;&#21512;&#25104;&#25968;&#25454;&#19978;&#25191;&#34892;&#30340;&#32479;&#35745;&#20551;&#35774;&#26816;&#39564;&#26159;&#21542;&#21487;&#33021;&#23548;&#33268;&#27979;&#35797;&#26377;&#25928;&#24615;&#30340;&#20007;&#22833;&#25110;&#21151;&#29575;&#19979;&#38477;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13612v1 Announce Type: new  Abstract: Background: Synthetic data has been proposed as a solution for sharing anonymized versions of sensitive biomedical datasets. Ideally, synthetic data should preserve the structure and statistical properties of the original data, while protecting the privacy of the individual subjects. Differential privacy (DP) is currently considered the gold standard approach for balancing this trade-off.   Objectives: The aim of this study is to evaluate the Mann-Whitney U test on DP-synthetic biomedical data in terms of Type I and Type II errors, in order to establish whether statistical hypothesis testing performed on privacy preserving synthetic data is likely to lead to loss of test's validity or decreased power.   Methods: We evaluate the Mann-Whitney U test on DP-synthetic data generated from real-world data, including a prostate cancer dataset (n=500) and a cardiovascular dataset (n=70 000), as well as on data drawn from two Gaussian distribution
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23581;&#35797;&#23558;&#22522;&#20110;&#27010;&#24565;&#28608;&#27963;&#21521;&#37327;&#65288;CAVs&#65289;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#33041;&#30005;&#22270;&#65288;EEG&#65289;&#25968;&#25454;&#30340;&#35299;&#37322;&#24615;&#65292;&#36890;&#36807;&#23450;&#20041;&#35299;&#37322;&#24615;&#27010;&#24565;&#21644;&#36873;&#25321;&#30456;&#20851;&#25968;&#25454;&#38598;&#65292;&#20197;&#23454;&#29616;&#23545;&#22823;&#35268;&#27169;&#36716;&#25442;&#22120;&#27169;&#22411;&#20013;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#29702;&#35299;&#12290;</title><link>http://arxiv.org/abs/2307.12745</link><description>&lt;p&gt;
EEG&#36716;&#25442;&#22120;&#27169;&#22411;&#30340;&#22522;&#20110;&#27010;&#24565;&#30340;&#21487;&#35299;&#37322;&#24615;
&lt;/p&gt;
&lt;p&gt;
Concept-based explainability for an EEG transformer model. (arXiv:2307.12745v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12745
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23581;&#35797;&#23558;&#22522;&#20110;&#27010;&#24565;&#28608;&#27963;&#21521;&#37327;&#65288;CAVs&#65289;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#33041;&#30005;&#22270;&#65288;EEG&#65289;&#25968;&#25454;&#30340;&#35299;&#37322;&#24615;&#65292;&#36890;&#36807;&#23450;&#20041;&#35299;&#37322;&#24615;&#27010;&#24565;&#21644;&#36873;&#25321;&#30456;&#20851;&#25968;&#25454;&#38598;&#65292;&#20197;&#23454;&#29616;&#23545;&#22823;&#35268;&#27169;&#36716;&#25442;&#22120;&#27169;&#22411;&#20013;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30001;&#20110;&#20854;&#35268;&#27169;&#12289;&#32467;&#26500;&#20197;&#21450;&#35757;&#32451;&#36807;&#31243;&#20013;&#30340;&#20869;&#22312;&#38543;&#26426;&#24615;&#32780;&#21464;&#24471;&#22797;&#26434;&#12290;&#36873;&#25321;&#25968;&#25454;&#38598;&#21644;&#24402;&#32435;&#20559;&#35265;&#20063;&#22686;&#21152;&#20102;&#39069;&#22806;&#30340;&#22797;&#26434;&#24615;&#12290;&#20026;&#20102;&#35299;&#37322;&#36825;&#20123;&#25361;&#25112;&#65292;Kim&#31561;&#20154;&#65288;2018&#65289;&#24341;&#20837;&#20102;&#27010;&#24565;&#28608;&#27963;&#21521;&#37327;&#65288;CAVs&#65289;&#65292;&#26088;&#22312;&#20174;&#20154;&#31867;&#23545;&#40784;&#30340;&#27010;&#24565;&#35282;&#24230;&#29702;&#35299;&#28145;&#24230;&#27169;&#22411;&#30340;&#20869;&#37096;&#29366;&#24577;&#12290;&#36825;&#20123;&#27010;&#24565;&#23545;&#24212;&#20110;&#28508;&#22312;&#31354;&#38388;&#20013;&#30340;&#26041;&#21521;&#65292;&#20351;&#29992;&#32447;&#24615;&#21028;&#21035;&#27861;&#36827;&#34892;&#35782;&#21035;&#12290;&#23613;&#31649;&#35813;&#26041;&#27861;&#39318;&#20808;&#24212;&#29992;&#20110;&#22270;&#20687;&#20998;&#31867;&#65292;&#20294;&#21518;&#26469;&#34987;&#36866;&#24212;&#21040;&#21253;&#25324;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#22312;&#20869;&#30340;&#20854;&#20182;&#39046;&#22495;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23581;&#35797;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;Kostas&#31561;&#20154;&#30340;BENDR&#65288;2021&#65289;&#30340;&#33041;&#30005;&#22270;&#65288;EEG&#65289;&#25968;&#25454;&#65292;&#20197;&#23454;&#29616;&#21487;&#35299;&#37322;&#24615;&#12290;&#36825;&#39033;&#21162;&#21147;&#30340;&#20851;&#38190;&#37096;&#20998;&#21253;&#25324;&#23450;&#20041;&#35299;&#37322;&#24615;&#27010;&#24565;&#21644;&#36873;&#25321;&#30456;&#20851;&#25968;&#25454;&#38598;&#20197;&#23558;&#27010;&#24565;&#19982;&#28508;&#22312;&#31354;&#38388;&#30456;&#23545;&#24212;&#12290;&#25105;&#20204;&#30340;&#37325;&#28857;&#26159;EEG&#27010;&#24565;&#24418;&#25104;&#30340;&#20004;&#20010;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning models are complex due to their size, structure, and inherent randomness in training procedures. Additional complexity arises from the selection of datasets and inductive biases. Addressing these challenges for explainability, Kim et al. (2018) introduced Concept Activation Vectors (CAVs), which aim to understand deep models' internal states in terms of human-aligned concepts. These concepts correspond to directions in latent space, identified using linear discriminants. Although this method was first applied to image classification, it was later adapted to other domains, including natural language processing. In this work, we attempt to apply the method to electroencephalogram (EEG) data for explainability in Kostas et al.'s BENDR (2021), a large-scale transformer model. A crucial part of this endeavor involves defining the explanatory concepts and selecting relevant datasets to ground concepts in the latent space. Our focus is on two mechanisms for EEG concept formation
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20219;&#21153;&#32467;&#26500;&#30340;&#21487;&#35782;&#21035;&#24615;&#29702;&#35770;&#65292;&#25299;&#23637;&#20102;&#20808;&#21069;&#20165;&#38480;&#20110;&#21333;&#20219;&#21153;&#20998;&#31867;&#30340;&#24037;&#20316;&#12290;&#20219;&#21153;&#20998;&#24067;&#30340;&#23384;&#22312;&#23450;&#20041;&#20102;&#19968;&#20010;&#28508;&#22312;&#21464;&#37327;&#30340;&#26465;&#20214;&#20808;&#39564;&#65292;&#23558;&#21487;&#35782;&#21035;&#24615;&#30340;&#31561;&#20215;&#31867;&#38477;&#20302;&#21040;&#25490;&#21015;&#21644;&#32553;&#25918;&#12290;&#22312;&#20551;&#35774;&#20219;&#21153;&#20043;&#38388;&#23384;&#22312;&#22240;&#26524;&#20851;&#31995;&#26102;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#31616;&#21333;&#30340;&#26368;&#22823;&#36793;&#38469;&#20284;&#28982;&#20248;&#21270;&#65292;&#24182;&#22312;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#26041;&#38754;&#20855;&#26377;&#19979;&#28216;&#24212;&#29992;&#30340;&#21487;&#34892;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.14861</link><description>&lt;p&gt;
&#21033;&#29992;&#20219;&#21153;&#32467;&#26500;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#34920;&#31034;&#30340;&#21487;&#35782;&#21035;&#24615;
&lt;/p&gt;
&lt;p&gt;
Leveraging Task Structures for Improved Identifiability in Neural Network Representations. (arXiv:2306.14861v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14861
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20219;&#21153;&#32467;&#26500;&#30340;&#21487;&#35782;&#21035;&#24615;&#29702;&#35770;&#65292;&#25299;&#23637;&#20102;&#20808;&#21069;&#20165;&#38480;&#20110;&#21333;&#20219;&#21153;&#20998;&#31867;&#30340;&#24037;&#20316;&#12290;&#20219;&#21153;&#20998;&#24067;&#30340;&#23384;&#22312;&#23450;&#20041;&#20102;&#19968;&#20010;&#28508;&#22312;&#21464;&#37327;&#30340;&#26465;&#20214;&#20808;&#39564;&#65292;&#23558;&#21487;&#35782;&#21035;&#24615;&#30340;&#31561;&#20215;&#31867;&#38477;&#20302;&#21040;&#25490;&#21015;&#21644;&#32553;&#25918;&#12290;&#22312;&#20551;&#35774;&#20219;&#21153;&#20043;&#38388;&#23384;&#22312;&#22240;&#26524;&#20851;&#31995;&#26102;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#31616;&#21333;&#30340;&#26368;&#22823;&#36793;&#38469;&#20284;&#28982;&#20248;&#21270;&#65292;&#24182;&#22312;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#26041;&#38754;&#20855;&#26377;&#19979;&#28216;&#24212;&#29992;&#30340;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25193;&#23637;&#20102;&#30417;&#30563;&#23398;&#20064;&#20013;&#21487;&#36776;&#21035;&#24615;&#30340;&#29702;&#35770;&#65292;&#32771;&#34385;&#20102;&#22312;&#25317;&#26377;&#20219;&#21153;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#30340;&#21518;&#26524;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21363;&#20351;&#22312;&#22238;&#24402;&#30340;&#24773;&#20917;&#19979;&#20063;&#21487;&#20197;&#23454;&#29616;&#21487;&#35782;&#21035;&#24615;&#65292;&#25193;&#23637;&#20102;&#20808;&#21069;&#20165;&#38480;&#20110;&#21333;&#20219;&#21153;&#20998;&#31867;&#24773;&#20917;&#30340;&#24037;&#20316;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20219;&#21153;&#20998;&#24067;&#30340;&#23384;&#22312;&#23450;&#20041;&#20102;&#19968;&#20010;&#28508;&#22312;&#21464;&#37327;&#30340;&#26465;&#20214;&#20808;&#39564;&#65292;&#23558;&#21487;&#35782;&#21035;&#24615;&#30340;&#31561;&#20215;&#31867;&#38477;&#20302;&#21040;&#25490;&#21015;&#21644;&#32553;&#25918;&#65292;&#36825;&#26159;&#19968;&#20010;&#26356;&#24378;&#22823;&#21644;&#26356;&#26377;&#29992;&#30340;&#32467;&#26524;&#12290;&#24403;&#25105;&#20204;&#36827;&#19968;&#27493;&#20551;&#35774;&#36825;&#20123;&#20219;&#21153;&#20043;&#38388;&#23384;&#22312;&#22240;&#26524;&#20851;&#31995;&#26102;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#31616;&#21333;&#30340;&#26368;&#22823;&#36793;&#38469;&#20284;&#28982;&#20248;&#21270;&#65292;&#24182;&#22312;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#26041;&#38754;&#20855;&#26377;&#19979;&#28216;&#24212;&#29992;&#30340;&#21487;&#34892;&#24615;&#12290;&#22312;&#32463;&#39564;&#19978;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#24674;&#22797;&#21512;&#25104;&#21644;&#29616;&#23454;&#19990;&#30028;&#25968;&#25454;&#30340;&#35268;&#33539;&#34920;&#31034;&#26041;&#38754;&#20248;&#20110;&#26356;&#19968;&#33324;&#30340;&#26080;&#30417;&#30563;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work extends the theory of identifiability in supervised learning by considering the consequences of having access to a distribution of tasks. In such cases, we show that identifiability is achievable even in the case of regression, extending prior work restricted to the single-task classification case. Furthermore, we show that the existence of a task distribution which defines a conditional prior over latent variables reduces the equivalence class for identifiability to permutations and scaling, a much stronger and more useful result. When we further assume a causal structure over these tasks, our approach enables simple maximum marginal likelihood optimization together with downstream applicability to causal representation learning. Empirically, we validate that our model outperforms more general unsupervised models in recovering canonical representations for synthetic and real-world data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#25955;&#27169;&#22411;&#20013;&#30340;&#36127;&#33655;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#37319;&#29992;Seq2Seq&#32593;&#32476;&#32467;&#26500;&#26469;&#20998;&#31163;&#20004;&#31181;&#31867;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#24182;&#22788;&#29702;&#24322;&#24120;&#24773;&#20917;&#65292;&#19981;&#20165;&#30528;&#30524;&#20110;&#39044;&#27979;&#26465;&#20214;&#26399;&#26395;&#20540;&#12290;</title><link>http://arxiv.org/abs/2306.01001</link><description>&lt;p&gt;
DiffLoad:&#25193;&#25955;&#27169;&#22411;&#20013;&#30340;&#36127;&#33655;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
DiffLoad: Uncertainty Quantification in Load Forecasting with Diffusion Model. (arXiv:2306.01001v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01001
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#25955;&#27169;&#22411;&#20013;&#30340;&#36127;&#33655;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#37319;&#29992;Seq2Seq&#32593;&#32476;&#32467;&#26500;&#26469;&#20998;&#31163;&#20004;&#31181;&#31867;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#24182;&#22788;&#29702;&#24322;&#24120;&#24773;&#20917;&#65292;&#19981;&#20165;&#30528;&#30524;&#20110;&#39044;&#27979;&#26465;&#20214;&#26399;&#26395;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30005;&#21147;&#36127;&#33655;&#39044;&#27979;&#23545;&#30005;&#21147;&#31995;&#32479;&#30340;&#20915;&#31574;&#21046;&#23450;&#65292;&#22914;&#26426;&#32452;&#25237;&#20837;&#21644;&#33021;&#28304;&#31649;&#29702;&#31561;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#36817;&#24180;&#26469;&#65292;&#21508;&#31181;&#22522;&#20110;&#33258;&#30417;&#30563;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#24050;&#32463;&#34987;&#24212;&#29992;&#20110;&#30005;&#21147;&#36127;&#33655;&#39044;&#27979;&#65292;&#20197;&#25552;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#21644;&#25429;&#25417;&#19981;&#30830;&#23450;&#24615;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#26041;&#27861;&#26159;&#22522;&#20110;&#39640;&#26031;&#20284;&#28982;&#26041;&#27861;&#30340;&#65292;&#23427;&#26088;&#22312;&#22312;&#32473;&#23450;&#30340;&#21327;&#21464;&#37327;&#19979;&#20934;&#30830;&#20272;&#35745;&#20998;&#24067;&#26399;&#26395;&#20540;&#12290;&#36825;&#31181;&#26041;&#27861;&#24456;&#38590;&#36866;&#24212;&#23384;&#22312;&#20998;&#24067;&#20559;&#31227;&#21644;&#24322;&#24120;&#20540;&#30340;&#26102;&#38388;&#25968;&#25454;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25193;&#25955;&#30340;Seq2seq&#32467;&#26500;&#26469;&#20272;&#35745;&#26412;&#20307;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#20351;&#29992;&#40065;&#26834;&#30340;&#21152;&#24615;&#26607;&#35199;&#20998;&#24067;&#26469;&#20272;&#35745;&#29289;&#35937;&#19981;&#30830;&#23450;&#24615;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#20998;&#31163;&#20004;&#31181;&#31867;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#24182;&#22788;&#29702;&#31361;&#21464;&#24773;&#20917;&#65292;&#32780;&#19981;&#26159;&#20934;&#30830;&#39044;&#27979;&#26465;&#20214;&#26399;&#26395;&#12290;
&lt;/p&gt;
&lt;p&gt;
Electrical load forecasting is of great significance for the decision makings in power systems, such as unit commitment and energy management. In recent years, various self-supervised neural network-based methods have been applied to electrical load forecasting to improve forecasting accuracy and capture uncertainties. However, most current methods are based on Gaussian likelihood methods, which aim to accurately estimate the distribution expectation under a given covariate. This kind of approach is difficult to adapt to situations where temporal data has a distribution shift and outliers. In this paper, we propose a diffusion-based Seq2seq structure to estimate epistemic uncertainty and use the robust additive Cauchy distribution to estimate aleatoric uncertainty. Rather than accurately forecasting conditional expectations, we demonstrate our method's ability in separating two types of uncertainties and dealing with the mutant scenarios.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#20960;&#20309;&#32467;&#26500;&#65292;&#21457;&#29616;&#36890;&#36807;&#19968;&#20010;&#26126;&#30830;&#30340;&#20934;&#32447;&#24615;&#37319;&#26679;&#36712;&#36857;&#21644;&#21478;&#19968;&#20010;&#38544;&#24335;&#30340;&#21435;&#22122;&#36712;&#36857;&#24179;&#28369;&#36830;&#25509;&#20102;&#25968;&#25454;&#20998;&#24067;&#21644;&#22122;&#22768;&#20998;&#24067;&#65292;&#24314;&#31435;&#20102;&#22522;&#20110;ODE&#30340;&#26368;&#20248;&#37319;&#26679;&#21644;&#32463;&#20856;&#30340;&#22343;&#20540;&#28418;&#31227;&#31639;&#27861;&#20043;&#38388;&#30340;&#29702;&#35770;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2305.19947</link><description>&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#30340;&#20960;&#20309;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
A Geometric Perspective on Diffusion Models. (arXiv:2305.19947v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19947
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#20960;&#20309;&#32467;&#26500;&#65292;&#21457;&#29616;&#36890;&#36807;&#19968;&#20010;&#26126;&#30830;&#30340;&#20934;&#32447;&#24615;&#37319;&#26679;&#36712;&#36857;&#21644;&#21478;&#19968;&#20010;&#38544;&#24335;&#30340;&#21435;&#22122;&#36712;&#36857;&#24179;&#28369;&#36830;&#25509;&#20102;&#25968;&#25454;&#20998;&#24067;&#21644;&#22122;&#22768;&#20998;&#24067;&#65292;&#24314;&#31435;&#20102;&#22522;&#20110;ODE&#30340;&#26368;&#20248;&#37319;&#26679;&#21644;&#32463;&#20856;&#30340;&#22343;&#20540;&#28418;&#31227;&#31639;&#27861;&#20043;&#38388;&#30340;&#29702;&#35770;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#38024;&#23545;&#25193;&#25955;&#27169;&#22411;&#30340;&#39640;&#25928;&#35757;&#32451;&#21644;&#24555;&#36895;&#37319;&#26679;&#26041;&#27861;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#12290;&#26368;&#36817;&#30340;&#19968;&#20010;&#37325;&#35201;&#36827;&#23637;&#26159;&#20351;&#29992;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDE&#65289;&#26469;&#25551;&#36848;&#25968;&#25454;&#25200;&#21160;&#21644;&#29983;&#25104;&#24314;&#27169;&#65292;&#20197;&#23454;&#29616;&#32479;&#19968;&#30340;&#25968;&#23398;&#26694;&#26550;&#12290;&#26412;&#25991;&#25581;&#31034;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#20960;&#20010;&#26377;&#36259;&#30340;&#20960;&#20309;&#32467;&#26500;&#65292;&#24182;&#20026;&#20854;&#37319;&#26679;&#21160;&#21147;&#23398;&#25552;&#20379;&#20102;&#31616;&#21333;&#32780;&#24378;&#22823;&#30340;&#35299;&#37322;&#12290;&#36890;&#36807;&#20180;&#32454;&#26816;&#26597;&#19968;&#31181;&#27969;&#34892;&#30340;&#26041;&#24046;&#29190;&#28856;SDE&#21450;&#20854;&#20445;&#25345;&#36793;&#38469;&#30340;&#26222;&#36890;&#24494;&#20998;&#26041;&#31243;&#65288;ODE&#65289;&#29992;&#20110;&#37319;&#26679;&#65292;&#25105;&#20204;&#21457;&#29616;&#25968;&#25454;&#20998;&#24067;&#21644;&#22122;&#22768;&#20998;&#24067;&#36890;&#36807;&#19968;&#20010;&#26126;&#30830;&#30340;&#20934;&#32447;&#24615;&#37319;&#26679;&#36712;&#36857;&#21644;&#21478;&#19968;&#20010;&#38544;&#24335;&#30340;&#21435;&#22122;&#36712;&#36857;&#24179;&#28369;&#36830;&#25509;&#65292;&#21363;&#20351;&#22312;&#35270;&#35273;&#36136;&#37327;&#26041;&#38754;&#20063;&#25910;&#25947;&#26356;&#24555;&#12290;&#25105;&#20204;&#36824;&#24314;&#31435;&#36215;&#22522;&#20110;ODE&#30340;&#26368;&#20248;&#37319;&#26679;&#21644;&#32463;&#20856;&#30340;&#22343;&#20540;&#28418;&#31227;&#65288;&#23547;&#25214;&#27169;&#24335;&#65289;&#31639;&#27861;&#20043;&#38388;&#30340;&#29702;&#35770;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent years have witnessed significant progress in developing efficient training and fast sampling approaches for diffusion models. A recent remarkable advancement is the use of stochastic differential equations (SDEs) to describe data perturbation and generative modeling in a unified mathematical framework. In this paper, we reveal several intriguing geometric structures of diffusion models and contribute a simple yet powerful interpretation to their sampling dynamics. Through carefully inspecting a popular variance-exploding SDE and its marginal-preserving ordinary differential equation (ODE) for sampling, we discover that the data distribution and the noise distribution are smoothly connected with an explicit, quasi-linear sampling trajectory, and another implicit denoising trajectory, which even converges faster in terms of visual quality. We also establish a theoretical relationship between the optimal ODE-based sampling and the classic mean-shift (mode-seeking) algorithm, with w
&lt;/p&gt;</description></item></channel></rss>