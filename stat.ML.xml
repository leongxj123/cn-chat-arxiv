<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#20998;&#26512;&#20102;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#21033;&#29992;&#37096;&#20998;&#26410;&#26469;&#22870;&#21169;&#20808;&#30693;&#30340;&#20215;&#20540;&#65292;&#36890;&#36807;&#31454;&#20105;&#24615;&#20998;&#26512;&#24471;&#20986;&#20102;&#26368;&#22351;&#24773;&#20917;&#19979;&#22870;&#21169;&#26399;&#26395;&#30340;&#31934;&#30830;&#27604;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.11637</link><description>&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#20013;&#26410;&#26469;&#22870;&#21169;&#20808;&#30693;&#30340;&#20215;&#20540;
&lt;/p&gt;
&lt;p&gt;
The Value of Reward Lookahead in Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11637
&lt;/p&gt;
&lt;p&gt;
&#20998;&#26512;&#20102;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#21033;&#29992;&#37096;&#20998;&#26410;&#26469;&#22870;&#21169;&#20808;&#30693;&#30340;&#20215;&#20540;&#65292;&#36890;&#36807;&#31454;&#20105;&#24615;&#20998;&#26512;&#24471;&#20986;&#20102;&#26368;&#22351;&#24773;&#20917;&#19979;&#22870;&#21169;&#26399;&#26395;&#30340;&#31934;&#30830;&#27604;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#20013;&#65292;&#20195;&#29702;&#20204;&#19982;&#19981;&#26029;&#21464;&#21270;&#30340;&#29615;&#22659;&#36827;&#34892;&#39034;&#24207;&#20132;&#20114;&#65292;&#26088;&#22312;&#26368;&#22823;&#21270;&#33719;&#24471;&#30340;&#22870;&#21169;&#12290;&#36890;&#24120;&#24773;&#20917;&#19979;&#65292;&#22870;&#21169;&#20165;&#22312;&#34892;&#21160;&#21518;&#34987;&#35266;&#23519;&#21040;&#65292;&#22240;&#27492;&#30446;&#26631;&#26159;&#26368;&#22823;&#21270;&#39044;&#26399;&#32047;&#31215;&#22870;&#21169;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#23454;&#38469;&#22330;&#26223;&#20013;&#65292;&#22870;&#21169;&#20449;&#24687;&#26159;&#25552;&#21069;&#35266;&#23519;&#21040;&#30340; -- &#20132;&#26131;&#21069;&#35266;&#23519;&#21040;&#20215;&#26684;&#65307;&#20102;&#35299;&#37096;&#20998;&#38468;&#36817;&#20132;&#36890;&#20449;&#24687;&#65307;&#32463;&#24120;&#22312;&#20114;&#21160;&#20043;&#21069;&#20026;&#20195;&#29702;&#20998;&#37197;&#30446;&#26631;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#36890;&#36807;&#31454;&#20105;&#24615;&#20998;&#26512;&#30340;&#35270;&#35282;&#65292;&#23450;&#37327;&#20998;&#26512;&#36825;&#31181;&#26410;&#26469;&#22870;&#21169;&#20449;&#24687;&#30340;&#20215;&#20540;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#27979;&#37327;&#20102;&#26631;&#20934;RL&#20195;&#29702;&#30340;&#20215;&#20540;&#19982;&#20855;&#26377;&#37096;&#20998;&#26410;&#26469;&#22870;&#21169;&#20808;&#30693;&#30340;&#20195;&#29702;&#20043;&#38388;&#30340;&#27604;&#29575;&#12290;&#25105;&#20204;&#21051;&#30011;&#20102;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#22870;&#21169;&#20998;&#24067;&#65292;&#24182;&#25512;&#23548;&#20986;&#26368;&#22351;&#24773;&#20917;&#19979;&#22870;&#21169;&#26399;&#26395;&#30340;&#31934;&#30830;&#27604;&#29575;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#32467;&#26524;&#27604;&#29575;&#19982;&#31163;&#32447;RL&#21644;r&#20013;&#24050;&#30693;&#30340;&#25968;&#37327;&#26377;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11637v1 Announce Type: new  Abstract: In reinforcement learning (RL), agents sequentially interact with changing environments while aiming to maximize the obtained rewards. Usually, rewards are observed only after acting, and so the goal is to maximize the expected cumulative reward. Yet, in many practical settings, reward information is observed in advance -- prices are observed before performing transactions; nearby traffic information is partially known; and goals are oftentimes given to agents prior to the interaction. In this work, we aim to quantifiably analyze the value of such future reward information through the lens of competitive analysis. In particular, we measure the ratio between the value of standard RL agents and that of agents with partial future-reward lookahead. We characterize the worst-case reward distribution and derive exact ratios for the worst-case reward expectations. Surprisingly, the resulting ratios relate to known quantities in offline RL and r
&lt;/p&gt;</description></item><item><title>HSIC&#20272;&#35745;&#30340;&#26497;&#23567;&#21270;&#29575;&#23545;&#24179;&#31227;&#19981;&#21464;&#26680;&#30340;&#29420;&#31435;&#24615;&#24230;&#37327;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;</title><link>https://arxiv.org/abs/2403.07735</link><description>&lt;p&gt;
HSIC&#20272;&#35745;&#30340;&#26497;&#23567;&#21270;&#29575;&#23545;&#24179;&#31227;&#19981;&#21464;&#26680;
&lt;/p&gt;
&lt;p&gt;
The Minimax Rate of HSIC Estimation for Translation-Invariant Kernels
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07735
&lt;/p&gt;
&lt;p&gt;
HSIC&#20272;&#35745;&#30340;&#26497;&#23567;&#21270;&#29575;&#23545;&#24179;&#31227;&#19981;&#21464;&#26680;&#30340;&#29420;&#31435;&#24615;&#24230;&#37327;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Kernel&#25216;&#26415;&#26159;&#25968;&#25454;&#31185;&#23398;&#21644;&#32479;&#35745;&#23398;&#20013;&#26368;&#26377;&#24433;&#21709;&#21147;&#30340;&#26041;&#27861;&#20043;&#19968;&#12290;&#22312;&#28201;&#21644;&#26465;&#20214;&#19979;&#65292;&#19982;&#26680;&#30456;&#20851;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#33021;&#22815;&#32534;&#30721;$M\ge 2$&#20010;&#38543;&#26426;&#21464;&#37327;&#30340;&#29420;&#31435;&#24615;&#12290;&#22312;&#26680;&#19978;&#20381;&#36182;&#30340;&#26368;&#26222;&#36941;&#30340;&#29420;&#31435;&#24615;&#24230;&#37327;&#21487;&#33021;&#26159;&#25152;&#35859;&#30340;Hilbert-Schmidt&#29420;&#31435;&#24615;&#20934;&#21017;(HSIC; &#22312;&#32479;&#35745;&#25991;&#29486;&#20013;&#20063;&#31216;&#20026;&#36317;&#31163;&#21327;&#26041;&#24046;)&#12290;&#23613;&#31649;&#33258;&#36817;&#20108;&#21313;&#24180;&#21069;&#24341;&#20837;&#20197;&#26469;&#24050;&#32463;&#26377;&#21508;&#31181;&#29616;&#26377;&#30340;&#35774;&#35745;&#30340;HSIC&#20272;&#35745;&#37327;&#65292;HSIC&#21487;&#20197;&#34987;&#20272;&#35745;&#30340;&#36895;&#24230;&#30340;&#22522;&#26412;&#38382;&#39064;&#20173;&#28982;&#26159;&#24320;&#25918;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#21253;&#21547;&#20855;&#26377;&#36830;&#32493;&#26377;&#30028;&#24179;&#31227;&#19981;&#21464;&#29305;&#24449;&#26680;&#30340;&#39640;&#26031;Borel&#27979;&#24230;&#22312;$\mathbb R^d$&#19978;&#30340;HSIC&#20272;&#35745;&#30340;&#26497;&#23567;&#21270;&#26368;&#20248;&#36895;&#29575;&#26159;$\mathcal O\!\left(n^{-1/2}\right)$&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#24847;&#21619;&#30528;&#35768;&#22810;&#26041;&#38754;&#22312;&#26497;&#23567;&#21270;&#24847;&#20041;&#19978;&#30340;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07735v1 Announce Type: cross  Abstract: Kernel techniques are among the most influential approaches in data science and statistics. Under mild conditions, the reproducing kernel Hilbert space associated to a kernel is capable of encoding the independence of $M\ge 2$ random variables. Probably the most widespread independence measure relying on kernels is the so-called Hilbert-Schmidt independence criterion (HSIC; also referred to as distance covariance in the statistics literature). Despite various existing HSIC estimators designed since its introduction close to two decades ago, the fundamental question of the rate at which HSIC can be estimated is still open. In this work, we prove that the minimax optimal rate of HSIC estimation on $\mathbb R^d$ for Borel measures containing the Gaussians with continuous bounded translation-invariant characteristic kernels is $\mathcal O\!\left(n^{-1/2}\right)$. Specifically, our result implies the optimality in the minimax sense of many 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#20855;&#26377;&#39640;&#26031;&#22122;&#22768;&#39537;&#21160;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#30340;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#22823;&#35268;&#27169;&#21464;&#20998;&#31639;&#27861;&#21644;&#32467;&#26500;&#21270;&#36924;&#36817;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#35780;&#20272;ELBO&#21644;&#33719;&#21462;&#20302;&#26041;&#24046;&#30340;&#38543;&#26426;&#26799;&#24230;&#20272;&#35745;&#65292;&#36890;&#36807;&#21033;&#29992;&#20302;&#31209;&#33945;&#29305;&#21345;&#32599;&#36924;&#36817;&#21644;&#25512;&#26029;&#32593;&#32476;&#30340;&#31934;&#24230;&#30697;&#38453;&#26356;&#26032;&#65292;&#23558;&#36817;&#20284;&#24179;&#28369;&#38382;&#39064;&#36716;&#21270;&#20026;&#36817;&#20284;&#28388;&#27874;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.01371</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#21464;&#20998;&#39640;&#26031;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Large-scale variational Gaussian state-space models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01371
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#20855;&#26377;&#39640;&#26031;&#22122;&#22768;&#39537;&#21160;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#30340;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#22823;&#35268;&#27169;&#21464;&#20998;&#31639;&#27861;&#21644;&#32467;&#26500;&#21270;&#36924;&#36817;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#35780;&#20272;ELBO&#21644;&#33719;&#21462;&#20302;&#26041;&#24046;&#30340;&#38543;&#26426;&#26799;&#24230;&#20272;&#35745;&#65292;&#36890;&#36807;&#21033;&#29992;&#20302;&#31209;&#33945;&#29305;&#21345;&#32599;&#36924;&#36817;&#21644;&#25512;&#26029;&#32593;&#32476;&#30340;&#31934;&#24230;&#30697;&#38453;&#26356;&#26032;&#65292;&#23558;&#36817;&#20284;&#24179;&#28369;&#38382;&#39064;&#36716;&#21270;&#20026;&#36817;&#20284;&#28388;&#27874;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#23884;&#22871;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#21644;&#32467;&#26500;&#21270;&#21464;&#20998;&#36924;&#36817;&#26041;&#27861;&#65292;&#20854;&#20013;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#30001;&#39640;&#26031;&#22122;&#22768;&#39537;&#21160;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#20801;&#35768;&#22312;&#27809;&#26377;&#37319;&#29992;&#23545;&#35282;&#39640;&#26031;&#36924;&#36817;&#30340;&#24773;&#20917;&#19979;&#26377;&#25928;&#22320;&#35780;&#20272;ELBO&#21644;&#20302;&#26041;&#24046;&#38543;&#26426;&#26799;&#24230;&#20272;&#35745;&#65292;&#36890;&#36807;&#21033;&#29992;&#65288;i&#65289;&#36890;&#36807;&#21160;&#21147;&#23398;&#23545;&#38544;&#29366;&#24577;&#36827;&#34892;&#36793;&#32536;&#21270;&#30340;&#33945;&#29305;&#21345;&#32599;&#36924;&#36817;&#30340;&#20302;&#31209;&#32467;&#26500;&#65292;&#65288;ii&#65289;&#19968;&#20010;&#25512;&#26029;&#32593;&#32476;&#65292;&#35813;&#32593;&#32476;&#36890;&#36807;&#20302;&#31209;&#31934;&#24230;&#30697;&#38453;&#26356;&#26032;&#26469;&#36817;&#20284;&#26356;&#26032;&#27493;&#39588;&#65292;&#65288;iii&#65289;&#23558;&#24403;&#21069;&#21644;&#26410;&#26469;&#35266;&#27979;&#32534;&#30721;&#20026;&#20266;&#35266;&#27979;--&#23558;&#36817;&#20284;&#24179;&#28369;&#38382;&#39064;&#36716;&#25442;&#20026;&#65288;&#26356;&#31616;&#21333;&#30340;&#65289;&#36817;&#20284;&#28388;&#27874;&#38382;&#39064;&#12290;&#25972;&#20307;&#32780;&#35328;&#65292;&#24517;&#35201;&#30340;&#32479;&#35745;&#20449;&#24687;&#21644;ELBO&#21487;&#20197;&#22312;$O&#65288;TL&#65288;Sr+S^2+r^2&#65289;&#65289;$&#26102;&#38388;&#20869;&#35745;&#31639;&#65292;&#20854;&#20013;$T$&#26159;&#31995;&#21015;&#38271;&#24230;&#65292;$L$&#26159;&#29366;&#24577;&#31354;&#38388;&#32500;&#25968;&#65292;$S$&#26159;&#29992;&#20110;&#36924;&#36817;&#30340;&#26679;&#26412;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01371v1 Announce Type: cross  Abstract: We introduce an amortized variational inference algorithm and structured variational approximation for state-space models with nonlinear dynamics driven by Gaussian noise. Importantly, the proposed framework allows for efficient evaluation of the ELBO and low-variance stochastic gradient estimates without resorting to diagonal Gaussian approximations by exploiting (i) the low-rank structure of Monte-Carlo approximations to marginalize the latent state through the dynamics (ii) an inference network that approximates the update step with low-rank precision matrix updates (iii) encoding current and future observations into pseudo observations -- transforming the approximate smoothing problem into an (easier) approximate filtering problem. Overall, the necessary statistics and ELBO can be computed in $O(TL(Sr + S^2 + r^2))$ time where $T$ is the series length, $L$ is the state-space dimensionality, $S$ are the number of samples used to app
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#38543;&#26426;&#36807;&#31243;&#20013;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#31614;&#21517;&#26680;&#30340;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#65292;&#23454;&#29616;&#20102;&#23545;&#22240;&#26524;&#20851;&#31995;&#30340;&#25512;&#26029;&#65292;&#20197;&#21450;&#24320;&#21457;&#20102;&#32422;&#26463;&#26465;&#20214;&#30340;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#29992;&#20110;&#24674;&#22797;&#25972;&#20010;&#26377;&#21521;&#22270;&#12290;</title><link>https://arxiv.org/abs/2402.18477</link><description>&lt;p&gt;
&#22312;&#22240;&#26524;&#21457;&#29616;&#20013;&#30340;&#31614;&#21517;&#26680;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#29992;&#20110;&#38543;&#26426;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Signature Kernel Conditional Independence Tests in Causal Discovery for Stochastic Processes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18477
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#38543;&#26426;&#36807;&#31243;&#20013;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#31614;&#21517;&#26680;&#30340;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#65292;&#23454;&#29616;&#20102;&#23545;&#22240;&#26524;&#20851;&#31995;&#30340;&#25512;&#26029;&#65292;&#20197;&#21450;&#24320;&#21457;&#20102;&#32422;&#26463;&#26465;&#20214;&#30340;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#29992;&#20110;&#24674;&#22797;&#25972;&#20010;&#26377;&#21521;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#25512;&#26029;&#38543;&#26426;&#21160;&#21147;&#31995;&#32479;&#32972;&#21518;&#30340;&#22240;&#26524;&#32467;&#26500;&#22312;&#31185;&#23398;&#12289;&#20581;&#24247;&#21644;&#37329;&#34701;&#31561;&#39046;&#22495;&#20855;&#26377;&#24040;&#22823;&#28508;&#21147;&#12290;&#26412;&#25991;&#36890;&#36807;&#21033;&#29992;&#26368;&#36817;&#31614;&#21517;&#26680;&#25216;&#26415;&#30340;&#36827;&#23637;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#20869;&#26680;&#30340;&#8220;&#36335;&#24452;&#31354;&#38388;&#8221;&#19978;&#26465;&#20214;&#29420;&#31435;&#24615;&#65288;CI&#65289;&#27979;&#35797;&#65292;&#29992;&#20110;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#35299;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#30456;&#36739;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#22312;&#36335;&#24452;&#31354;&#38388;&#19978;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;CI&#27979;&#35797;&#34920;&#29616;&#20986;&#20005;&#26684;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#20026;&#38750;&#24490;&#29615;&#38543;&#26426;&#21160;&#21147;&#31995;&#32479;&#24320;&#21457;&#20102;&#22522;&#20110;&#32422;&#26463;&#30340;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#65292;&#21033;&#29992;&#26102;&#38388;&#20449;&#24687;&#26469;&#24674;&#22797;&#25972;&#20010;&#26377;&#21521;&#22270;&#12290;&#22312;&#20551;&#35774;&#24544;&#23454;&#24615;&#21644;CI&#39044;&#35328;&#26426;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#26159;&#23436;&#22791;&#19988;&#27491;&#30830;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18477v1 Announce Type: cross  Abstract: Inferring the causal structure underlying stochastic dynamical systems from observational data holds great promise in domains ranging from science and health to finance. Such processes can often be accurately modeled via stochastic differential equations (SDEs), which naturally imply causal relationships via "which variables enter the differential of which other variables". In this paper, we develop a kernel-based test of conditional independence (CI) on "path-space" -- solutions to SDEs -- by leveraging recent advances in signature kernels. We demonstrate strictly superior performance of our proposed CI test compared to existing approaches on path-space. Then, we develop constraint-based causal discovery algorithms for acyclic stochastic dynamical systems (allowing for loops) that leverage temporal information to recover the entire directed graph. Assuming faithfulness and a CI oracle, our algorithm is sound and complete. We empirical
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#22810;&#22836;&#27880;&#24847;&#21147;&#22312;&#20248;&#21270;&#21644;&#27867;&#21270;&#26041;&#38754;&#30340;&#20248;&#21183;&#65292;&#25512;&#23548;&#20102;&#21333;&#23618;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#27169;&#22411;&#30340;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#25910;&#25947;&#24615;&#21644;&#27867;&#21270;&#20445;&#35777;&#65292;&#24182;&#35777;&#26126;&#20102;&#23545;&#20110;&#19968;&#20010;&#31616;&#21333;&#30340;&#20998;&#35789;&#28151;&#21512;&#27169;&#22411;&#65292;&#21021;&#22987;&#21270;&#26465;&#20214;&#28385;&#36275;&#21487;&#23454;&#29616;&#24615;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2310.12680</link><description>&lt;p&gt;
&#20851;&#20110;&#22810;&#22836;&#27880;&#24847;&#21147;&#30340;&#20248;&#21270;&#19982;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
On the Optimization and Generalization of Multi-head Attention. (arXiv:2310.12680v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12680
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#22810;&#22836;&#27880;&#24847;&#21147;&#22312;&#20248;&#21270;&#21644;&#27867;&#21270;&#26041;&#38754;&#30340;&#20248;&#21183;&#65292;&#25512;&#23548;&#20102;&#21333;&#23618;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#27169;&#22411;&#30340;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#25910;&#25947;&#24615;&#21644;&#27867;&#21270;&#20445;&#35777;&#65292;&#24182;&#35777;&#26126;&#20102;&#23545;&#20110;&#19968;&#20010;&#31616;&#21333;&#30340;&#20998;&#35789;&#28151;&#21512;&#27169;&#22411;&#65292;&#21021;&#22987;&#21270;&#26465;&#20214;&#28385;&#36275;&#21487;&#23454;&#29616;&#24615;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformer&#26680;&#24515;&#26426;&#21046;&#8212;&#8212;Attention&#26426;&#21046;&#30340;&#35757;&#32451;&#21644;&#27867;&#21270;&#21160;&#24577;&#20173;&#26410;&#28145;&#20837;&#30740;&#31350;&#12290;&#27492;&#22806;&#65292;&#29616;&#26377;&#20998;&#26512;&#20027;&#35201;&#38598;&#20013;&#22312;&#21333;&#22836;&#27880;&#24847;&#21147;&#19978;&#12290;&#21463;&#21040;&#20840;&#36830;&#25509;&#32593;&#32476;&#35757;&#32451;&#26102;&#36807;&#21442;&#25968;&#21270;&#30340;&#30410;&#22788;&#21551;&#21457;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20351;&#29992;&#22810;&#22836;&#27880;&#24847;&#21147;&#30340;&#28508;&#22312;&#20248;&#21270;&#21644;&#27867;&#21270;&#20248;&#21183;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#22312;&#25968;&#25454;&#30340;&#36866;&#24403;&#21487;&#23454;&#29616;&#24615;&#26465;&#20214;&#19979;&#65292;&#25512;&#23548;&#20986;&#21333;&#23618;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#27169;&#22411;&#30340;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#25910;&#25947;&#24615;&#21644;&#27867;&#21270;&#20445;&#35777;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24314;&#31435;&#36215;&#21021;&#22987;&#21270;&#26102;&#30830;&#20445;&#21487;&#23454;&#29616;&#24615;&#24471;&#21040;&#28385;&#36275;&#30340;&#22522;&#26412;&#26465;&#20214;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20123;&#26465;&#20214;&#36866;&#29992;&#20110;&#19968;&#20010;&#31616;&#21333;&#30340;&#20998;&#35789;&#28151;&#21512;&#27169;&#22411;&#12290;&#25105;&#20204;&#26399;&#26395;&#36825;&#20010;&#20998;&#26512;&#21487;&#20197;&#25193;&#23637;&#21040;&#21508;&#31181;&#25968;&#25454;&#27169;&#22411;&#21644;&#26550;&#26500;&#21464;&#20307;&#12290;
&lt;/p&gt;
&lt;p&gt;
The training and generalization dynamics of the Transformer's core mechanism, namely the Attention mechanism, remain under-explored. Besides, existing analyses primarily focus on single-head attention. Inspired by the demonstrated benefits of overparameterization when training fully-connected networks, we investigate the potential optimization and generalization advantages of using multiple attention heads. Towards this goal, we derive convergence and generalization guarantees for gradient-descent training of a single-layer multi-head self-attention model, under a suitable realizability condition on the data. We then establish primitive conditions on the initialization that ensure realizability holds. Finally, we demonstrate that these conditions are satisfied for a simple tokenized-mixture model. We expect the analysis can be extended to various data-model and architecture variations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26799;&#24230;&#20998;&#20301;&#25968;&#21098;&#20999;&#30340;&#40065;&#26834;&#24615;&#38543;&#26426;&#20248;&#21270;&#31574;&#30053;&#65292;&#36866;&#29992;&#20110;&#20809;&#28369;&#30446;&#26631;&#19988;&#33021;&#23481;&#24525;&#24322;&#24120;&#20540;&#21644;&#23614;&#37325;&#26679;&#26412;&#12290;&#23545;&#20110;&#24378;&#20984;&#30446;&#26631;&#65292;&#36845;&#20195;&#25910;&#25947;&#21040;&#38598;&#20013;&#20998;&#24067;&#24182;&#23548;&#20986;&#20102;&#20272;&#35745;&#35823;&#24046;&#30340;&#27010;&#29575;&#30028;&#12290;&#22312;&#38750;&#20984;&#24773;&#20917;&#19979;&#65292;&#26497;&#38480;&#20998;&#24067;&#23616;&#37096;&#21270;&#22312;&#20302;&#26799;&#24230;&#37051;&#22495;&#19978;&#12290;&#20351;&#29992;&#28378;&#21160;&#20998;&#20301;&#25968;&#23454;&#29616;&#30340;&#31639;&#27861;&#20855;&#26377;&#24456;&#24378;&#30340;&#40065;&#26834;&#24615;&#21644;&#39640;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.17316</link><description>&lt;p&gt;
&#36890;&#36807;&#26799;&#24230;&#20998;&#20301;&#25968;&#21098;&#20999;&#23454;&#29616;&#40065;&#26834;&#24615;&#38543;&#26426;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Robust Stochastic Optimization via Gradient Quantile Clipping. (arXiv:2309.17316v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.17316
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26799;&#24230;&#20998;&#20301;&#25968;&#21098;&#20999;&#30340;&#40065;&#26834;&#24615;&#38543;&#26426;&#20248;&#21270;&#31574;&#30053;&#65292;&#36866;&#29992;&#20110;&#20809;&#28369;&#30446;&#26631;&#19988;&#33021;&#23481;&#24525;&#24322;&#24120;&#20540;&#21644;&#23614;&#37325;&#26679;&#26412;&#12290;&#23545;&#20110;&#24378;&#20984;&#30446;&#26631;&#65292;&#36845;&#20195;&#25910;&#25947;&#21040;&#38598;&#20013;&#20998;&#24067;&#24182;&#23548;&#20986;&#20102;&#20272;&#35745;&#35823;&#24046;&#30340;&#27010;&#29575;&#30028;&#12290;&#22312;&#38750;&#20984;&#24773;&#20917;&#19979;&#65292;&#26497;&#38480;&#20998;&#24067;&#23616;&#37096;&#21270;&#22312;&#20302;&#26799;&#24230;&#37051;&#22495;&#19978;&#12290;&#20351;&#29992;&#28378;&#21160;&#20998;&#20301;&#25968;&#23454;&#29616;&#30340;&#31639;&#27861;&#20855;&#26377;&#24456;&#24378;&#30340;&#40065;&#26834;&#24615;&#21644;&#39640;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26799;&#24230;&#33539;&#25968;&#20998;&#20301;&#25968;&#20316;&#20026;&#21098;&#20999;&#38408;&#20540;&#30340;&#31574;&#30053;&#65292;&#29992;&#20110;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477; (SGD)&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#26032;&#31574;&#30053;&#22312;&#20809;&#28369;&#30446;&#26631;&#65288;&#20984;&#25110;&#38750;&#20984;&#65289;&#19979;&#25552;&#20379;&#20102;&#19968;&#31181;&#40065;&#26834;&#19988;&#39640;&#25928;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#33021;&#22815;&#23481;&#24525;&#23614;&#37325;&#26679;&#26412;&#65288;&#21253;&#25324;&#26080;&#38480;&#26041;&#24046;&#65289;&#21644;&#25968;&#25454;&#27969;&#20013;&#30340;&#24322;&#24120;&#20540;&#65292;&#31867;&#20284;&#20110; Huber &#27745;&#26579;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#25968;&#23398;&#20998;&#26512;&#21033;&#29992;&#20102;&#24658;&#23450;&#27493;&#38271;&#30340; SGD &#21644;&#39532;&#23572;&#21487;&#22827;&#38142;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#24182;&#20197;&#29420;&#29305;&#30340;&#26041;&#24335;&#22788;&#29702;&#21098;&#20999;&#24341;&#20837;&#30340;&#20559;&#24046;&#12290;&#23545;&#20110;&#24378;&#20984;&#30446;&#26631;&#65292;&#25105;&#20204;&#35777;&#26126;&#36845;&#20195;&#25910;&#25947;&#21040;&#19968;&#20010;&#38598;&#20013;&#20998;&#24067;&#65292;&#24182;&#23548;&#20986;&#20102;&#26368;&#32456;&#20272;&#35745;&#35823;&#24046;&#30340;&#39640;&#27010;&#29575;&#30028;&#12290;&#22312;&#38750;&#20984;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#26497;&#38480;&#20998;&#24067;&#23616;&#37096;&#21270;&#22312;&#20302;&#26799;&#24230;&#37051;&#22495;&#19978;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#28378;&#21160;&#20998;&#20301;&#25968;&#23454;&#29616;&#27492;&#31639;&#27861;&#30340;&#26041;&#27861;&#65292;&#20174;&#32780;&#24471;&#21040;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#20248;&#21270;&#36807;&#31243;&#65292;&#20855;&#26377;&#24456;&#24378;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a clipping strategy for Stochastic Gradient Descent (SGD) which uses quantiles of the gradient norm as clipping thresholds. We prove that this new strategy provides a robust and efficient optimization algorithm for smooth objectives (convex or non-convex), that tolerates heavy-tailed samples (including infinite variance) and a fraction of outliers in the data stream akin to Huber contamination. Our mathematical analysis leverages the connection between constant step size SGD and Markov chains and handles the bias introduced by clipping in an original way. For strongly convex objectives, we prove that the iteration converges to a concentrated distribution and derive high probability bounds on the final estimation error. In the non-convex case, we prove that the limit distribution is localized on a neighborhood with low gradient. We propose an implementation of this algorithm using rolling quantiles which leads to a highly efficient optimization procedure with strong robustn
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23384;&#22312;&#28151;&#28102;&#25928;&#24212;&#26102;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#22823;&#35268;&#27169;&#20551;&#35774;&#26816;&#39564;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#27491;&#20132;&#32467;&#26500;&#21644;&#32447;&#24615;&#25237;&#24433;&#30340;&#32479;&#35745;&#20272;&#35745;&#21644;&#25512;&#26029;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#30001;&#20110;&#26410;&#27979;&#28151;&#28102;&#22240;&#32032;&#24341;&#36215;&#30340;&#20559;&#24046;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.07261</link><description>&lt;p&gt;
&#20855;&#26377;&#26410;&#27979;&#28151;&#28102;&#22240;&#32032;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#21516;&#26102;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Simultaneous inference for generalized linear models with unmeasured confounders. (arXiv:2309.07261v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07261
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23384;&#22312;&#28151;&#28102;&#25928;&#24212;&#26102;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#22823;&#35268;&#27169;&#20551;&#35774;&#26816;&#39564;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#27491;&#20132;&#32467;&#26500;&#21644;&#32447;&#24615;&#25237;&#24433;&#30340;&#32479;&#35745;&#20272;&#35745;&#21644;&#25512;&#26029;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#30001;&#20110;&#26410;&#27979;&#28151;&#28102;&#22240;&#32032;&#24341;&#36215;&#30340;&#20559;&#24046;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22522;&#22240;&#32452;&#30740;&#31350;&#20013;&#65292;&#24120;&#24120;&#36827;&#34892;&#25104;&#21315;&#19978;&#19975;&#20010;&#21516;&#26102;&#20551;&#35774;&#26816;&#39564;&#65292;&#20197;&#30830;&#23450;&#24046;&#24322;&#34920;&#36798;&#30340;&#22522;&#22240;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23384;&#22312;&#26410;&#27979;&#28151;&#28102;&#22240;&#32032;&#65292;&#35768;&#22810;&#26631;&#20934;&#32479;&#35745;&#26041;&#27861;&#21487;&#33021;&#23384;&#22312;&#20005;&#37325;&#30340;&#20559;&#24046;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#23384;&#22312;&#28151;&#28102;&#25928;&#24212;&#26102;&#30340;&#22810;&#20803;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#22823;&#35268;&#27169;&#20551;&#35774;&#26816;&#39564;&#38382;&#39064;&#12290;&#22312;&#20219;&#24847;&#28151;&#28102;&#26426;&#21046;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#32479;&#35745;&#20272;&#35745;&#21644;&#25512;&#26029;&#26041;&#27861;&#65292;&#21033;&#29992;&#27491;&#20132;&#32467;&#26500;&#24182;&#23558;&#32447;&#24615;&#25237;&#24433;&#25972;&#21512;&#21040;&#19977;&#20010;&#20851;&#38190;&#38454;&#27573;&#20013;&#12290;&#39318;&#20808;&#65292;&#21033;&#29992;&#22810;&#20803;&#21709;&#24212;&#21464;&#37327;&#20998;&#31163;&#36793;&#38469;&#21644;&#19981;&#30456;&#20851;&#30340;&#28151;&#28102;&#25928;&#24212;&#65292;&#24674;&#22797;&#28151;&#28102;&#31995;&#25968;&#30340;&#21015;&#31354;&#38388;&#12290;&#38543;&#21518;&#65292;&#21033;&#29992;$\ell_1$&#27491;&#21017;&#21270;&#36827;&#34892;&#31232;&#30095;&#24615;&#20272;&#35745;&#65292;&#24182;&#24378;&#21152;&#27491;&#20132;&#24615;&#38480;&#21046;&#20110;&#28151;&#28102;&#31995;&#25968;&#65292;&#32852;&#21512;&#20272;&#35745;&#28508;&#22312;&#22240;&#23376;&#21644;&#20027;&#35201;&#25928;&#24212;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#32467;&#21512;&#25237;&#24433;&#21644;&#21152;&#26435;&#20559;&#24046;&#26657;&#27491;&#27493;&#39588;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tens of thousands of simultaneous hypothesis tests are routinely performed in genomic studies to identify differentially expressed genes. However, due to unmeasured confounders, many standard statistical approaches may be substantially biased. This paper investigates the large-scale hypothesis testing problem for multivariate generalized linear models in the presence of confounding effects. Under arbitrary confounding mechanisms, we propose a unified statistical estimation and inference framework that harnesses orthogonal structures and integrates linear projections into three key stages. It first leverages multivariate responses to separate marginal and uncorrelated confounding effects, recovering the confounding coefficients' column space. Subsequently, latent factors and primary effects are jointly estimated, utilizing $\ell_1$-regularization for sparsity while imposing orthogonality onto confounding coefficients. Finally, we incorporate projected and weighted bias-correction steps 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20174;&#22810;&#20219;&#21153;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#20013;&#24674;&#22797;&#32447;&#24615;&#25805;&#20316;&#31526;&#30340;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#29616;&#26377;&#30340;&#21508;&#21521;&#21516;&#24615;&#26080;&#20851;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;&#20250;&#23545;&#34920;&#31034;&#26356;&#26032;&#36896;&#25104;&#20559;&#24046;&#65292;&#38480;&#21046;&#20102;&#34920;&#31034;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;&#20026;&#27492;&#65292;&#24341;&#20837;&#20102;&#21435;&#20559;&#24046;&#21644;&#29305;&#24449;&#30333;&#21270;&#30340;&#36866;&#24212;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2308.04428</link><description>&lt;p&gt;
&#20174;&#22810;&#20219;&#21153;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#20013;&#20803;&#23398;&#20064;&#25805;&#20316;&#31526;&#21040;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
Meta-Learning Operators to Optimality from Multi-Task Non-IID Data. (arXiv:2308.04428v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04428
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20174;&#22810;&#20219;&#21153;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#20013;&#24674;&#22797;&#32447;&#24615;&#25805;&#20316;&#31526;&#30340;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#29616;&#26377;&#30340;&#21508;&#21521;&#21516;&#24615;&#26080;&#20851;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;&#20250;&#23545;&#34920;&#31034;&#26356;&#26032;&#36896;&#25104;&#20559;&#24046;&#65292;&#38480;&#21046;&#20102;&#34920;&#31034;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;&#20026;&#27492;&#65292;&#24341;&#20837;&#20102;&#21435;&#20559;&#24046;&#21644;&#29305;&#24449;&#30333;&#21270;&#30340;&#36866;&#24212;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#36817;&#21462;&#24471;&#36827;&#23637;&#30340;&#19968;&#20010;&#24378;&#22823;&#27010;&#24565;&#26159;&#20174;&#24322;&#26500;&#26469;&#28304;&#25110;&#20219;&#21153;&#30340;&#25968;&#25454;&#20013;&#25552;&#21462;&#20849;&#21516;&#29305;&#24449;&#12290;&#30452;&#35266;&#22320;&#35828;&#65292;&#23558;&#25152;&#26377;&#25968;&#25454;&#29992;&#20110;&#23398;&#20064;&#20849;&#21516;&#30340;&#34920;&#31034;&#20989;&#25968;&#65292;&#26082;&#26377;&#21161;&#20110;&#35745;&#31639;&#25928;&#29575;&#65292;&#21448;&#26377;&#21161;&#20110;&#32479;&#35745;&#27867;&#21270;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#20943;&#23569;&#35201;&#22312;&#32473;&#23450;&#20219;&#21153;&#19978;&#36827;&#34892;&#24494;&#35843;&#30340;&#21442;&#25968;&#25968;&#37327;&#12290;&#20026;&#20102;&#22312;&#29702;&#35770;&#19978;&#20570;&#20986;&#36825;&#20123;&#20248;&#28857;&#30340;&#26681;&#28304;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20174;&#22122;&#22768;&#21521;&#37327;&#27979;&#37327;$y = Mx + w$&#20013;&#22238;&#22797;&#32447;&#24615;&#25805;&#20316;&#31526;$M$&#30340;&#19968;&#33324;&#27169;&#22411;&#12290;&#20854;&#20013;&#65292;&#21327;&#21464;&#37327;$x$&#26082;&#21487;&#20197;&#26159;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#65292;&#20063;&#21487;&#20197;&#26159;&#38750;&#21508;&#21521;&#21516;&#24615;&#30340;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#29616;&#26377;&#30340;&#21508;&#21521;&#21516;&#24615;&#26080;&#20851;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;&#20250;&#23545;&#34920;&#31034;&#26356;&#26032;&#36896;&#25104;&#20559;&#24046;&#65292;&#36825;&#23548;&#33268;&#22122;&#22768;&#39033;&#30340;&#32553;&#25918;&#19981;&#20877;&#26377;&#21033;&#20110;&#28304;&#20219;&#21153;&#25968;&#37327;&#12290;&#36825;&#21453;&#36807;&#26469;&#20250;&#23548;&#33268;&#34920;&#31034;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#21463;&#21040;&#21333;&#20219;&#21153;&#25968;&#25454;&#35268;&#27169;&#30340;&#38480;&#21046;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#31216;&#20026;&#21435;&#20559;&#24046;&#21644;&#29305;&#24449;&#30333;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
A powerful concept behind much of the recent progress in machine learning is the extraction of common features across data from heterogeneous sources or tasks. Intuitively, using all of one's data to learn a common representation function benefits both computational effort and statistical generalization by leaving a smaller number of parameters to fine-tune on a given task. Toward theoretically grounding these merits, we propose a general setting of recovering linear operators $M$ from noisy vector measurements $y = Mx + w$, where the covariates $x$ may be both non-i.i.d. and non-isotropic. We demonstrate that existing isotropy-agnostic meta-learning approaches incur biases on the representation update, which causes the scaling of the noise terms to lose favorable dependence on the number of source tasks. This in turn can cause the sample complexity of representation learning to be bottlenecked by the single-task data size. We introduce an adaptation, $\texttt{De-bias &amp; Feature-Whiten}
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#30028;&#22495;&#19978;&#36890;&#36807;&#21333;&#38544;&#34255;&#23618;ReLU&#32593;&#32476;&#36924;&#36817;&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#20171;&#32461;&#20102;&#26032;&#30340;&#27169;&#22411;&#31867;&#23450;&#20041;&#21152;&#26435;&#21464;&#24046;&#31354;&#38388;&#65292;&#35813;&#23450;&#20041;&#19982;&#22495;&#26412;&#36523;&#30456;&#20851;&#12290;</title><link>http://arxiv.org/abs/2307.15772</link><description>&lt;p&gt;
&#21152;&#26435;&#21464;&#24046;&#31354;&#38388;&#19982;&#27973;&#23618;ReLU&#32593;&#32476;&#30340;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
Weighted variation spaces and approximation by shallow ReLU networks. (arXiv:2307.15772v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15772
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#30028;&#22495;&#19978;&#36890;&#36807;&#21333;&#38544;&#34255;&#23618;ReLU&#32593;&#32476;&#36924;&#36817;&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#20171;&#32461;&#20102;&#26032;&#30340;&#27169;&#22411;&#31867;&#23450;&#20041;&#21152;&#26435;&#21464;&#24046;&#31354;&#38388;&#65292;&#35813;&#23450;&#20041;&#19982;&#22495;&#26412;&#36523;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#30028;&#22495;&#937;&#8834;Rd&#19978;&#65292;&#36890;&#36807;&#23485;&#24230;&#20026;n&#30340;&#21333;&#38544;&#34255;&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20986;&#26469;&#36924;&#36817;&#20989;&#25968;f&#30340;&#24773;&#20917;&#12290;&#36825;&#31181;&#38750;&#32447;&#24615;&#30340;n&#39033;&#23383;&#20856;&#36924;&#36817;&#24050;&#32463;&#24471;&#21040;&#24191;&#27867;&#30740;&#31350;&#65292;&#22240;&#20026;&#23427;&#26159;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;(NNA)&#30340;&#26368;&#31616;&#21333;&#24773;&#20917;&#12290;&#23545;&#20110;&#36825;&#31181;NNA&#24418;&#24335;&#65292;&#26377;&#20960;&#20010;&#33879;&#21517;&#30340;&#36924;&#36817;&#32467;&#26524;&#65292;&#24341;&#20837;&#20102;&#22312;&#937;&#19978;&#30340;&#20989;&#25968;&#30340;&#26032;&#22411;&#27169;&#22411;&#31867;&#65292;&#20854;&#36924;&#36817;&#36895;&#29575;&#36991;&#20813;&#20102;&#32500;&#25968;&#28798;&#38590;&#12290;&#36825;&#20123;&#26032;&#22411;&#27169;&#22411;&#31867;&#21253;&#25324;Barron&#31867;&#21644;&#22522;&#20110;&#31232;&#30095;&#24615;&#25110;&#21464;&#24046;&#30340;&#31867;&#65292;&#20363;&#22914;Radon&#22495;BV&#31867;&#12290;&#26412;&#25991;&#20851;&#27880;&#20110;&#22312;&#22495;&#937;&#19978;&#23450;&#20041;&#36825;&#20123;&#26032;&#22411;&#27169;&#22411;&#31867;&#12290;&#24403;&#21069;&#36825;&#20123;&#27169;&#22411;&#31867;&#30340;&#23450;&#20041;&#19981;&#20381;&#36182;&#20110;&#22495;&#937;&#12290;&#36890;&#36807;&#24341;&#20837;&#21152;&#26435;&#21464;&#24046;&#31354;&#38388;&#30340;&#27010;&#24565;&#65292;&#32473;&#20986;&#20102;&#20851;&#20110;&#22495;&#30340;&#26356;&#24688;&#24403;&#30340;&#27169;&#22411;&#31867;&#23450;&#20041;&#12290;&#36825;&#20123;&#26032;&#22411;&#27169;&#22411;&#31867;&#19982;&#22495;&#26412;&#36523;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the approximation of functions $f$ on a bounded domain $\Omega\subset \mathbb{R}^d$ by the outputs of single-hidden-layer ReLU neural networks of width $n$. This form of nonlinear $n$-term dictionary approximation has been intensely studied since it is the simplest case of neural network approximation (NNA). There are several celebrated approximation results for this form of NNA that introduce novel model classes of functions on $\Omega$ whose approximation rates avoid the curse of dimensionality. These novel classes include Barron classes, and classes based on sparsity or variation such as the Radon-domain BV classes.  The present paper is concerned with the definition of these novel model classes on domains $\Omega$. The current definition of these model classes does not depend on the domain $\Omega$. A new and more proper definition of model classes on domains is given by introducing the concept of weighted variation spaces. These new model classes are intrinsic to th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#24179;&#28369;&#38750;&#20984;&#20248;&#21270;&#20013;&#38543;&#26426;&#27425;&#26799;&#24230;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#36136;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#35777;&#26126;&#20102;&#20854;&#22312;&#21333;&#26102;&#38388;&#23610;&#24230;&#21644;&#21452;&#26102;&#38388;&#23610;&#24230;&#24773;&#20917;&#19979;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#65292;&#21253;&#25324;&#20102;&#22810;&#31181;&#24050;&#30693;&#30340;SGD&#31867;&#22411;&#26041;&#27861;&#12290;&#23545;&#20110;&#26377;&#38480;&#21644;&#24418;&#24335;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#35777;&#26126;&#20102;&#36825;&#20123;&#26041;&#27861;&#33021;&#22815;&#22312;&#38543;&#26426;&#36873;&#25321;&#30340;&#27493;&#38271;&#21644;&#21021;&#22987;&#28857;&#19978;&#25214;&#21040;Clarke&#31283;&#23450;&#28857;&#12290;</title><link>http://arxiv.org/abs/2307.10053</link><description>&lt;p&gt;
&#38750;&#24179;&#28369;&#38750;&#20984;&#20248;&#21270;&#20013;&#38543;&#26426;&#27425;&#26799;&#24230;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Convergence Guarantees for Stochastic Subgradient Methods in Nonsmooth Nonconvex Optimization. (arXiv:2307.10053v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10053
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#24179;&#28369;&#38750;&#20984;&#20248;&#21270;&#20013;&#38543;&#26426;&#27425;&#26799;&#24230;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#36136;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#35777;&#26126;&#20102;&#20854;&#22312;&#21333;&#26102;&#38388;&#23610;&#24230;&#21644;&#21452;&#26102;&#38388;&#23610;&#24230;&#24773;&#20917;&#19979;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#65292;&#21253;&#25324;&#20102;&#22810;&#31181;&#24050;&#30693;&#30340;SGD&#31867;&#22411;&#26041;&#27861;&#12290;&#23545;&#20110;&#26377;&#38480;&#21644;&#24418;&#24335;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#35777;&#26126;&#20102;&#36825;&#20123;&#26041;&#27861;&#33021;&#22815;&#22312;&#38543;&#26426;&#36873;&#25321;&#30340;&#27493;&#38271;&#21644;&#21021;&#22987;&#28857;&#19978;&#25214;&#21040;Clarke&#31283;&#23450;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#26041;&#27861;&#21450;&#20854;&#21464;&#31181;&#22312;&#35757;&#32451;&#30001;&#38750;&#24179;&#28369;&#28608;&#27963;&#20989;&#25968;&#26500;&#24314;&#30340;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#25910;&#25947;&#24615;&#36136;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#20026;&#26356;&#26032;&#21160;&#37327;&#39033;&#21644;&#21464;&#37327;&#30340;&#27493;&#38271;&#20998;&#37197;&#20102;&#19981;&#21516;&#30340;&#26102;&#38388;&#23610;&#24230;&#12290;&#22312;&#19968;&#20123;&#28201;&#21644;&#30340;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;&#22312;&#21333;&#26102;&#38388;&#23610;&#24230;&#21644;&#21452;&#26102;&#38388;&#23610;&#24230;&#24773;&#20917;&#19979;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;&#21253;&#21547;&#20102;&#24456;&#22810;&#24050;&#30693;&#30340;SGD&#31867;&#22411;&#26041;&#27861;&#65292;&#21253;&#25324;heavy-ball SGD&#12289;SignSGD&#12289;Lion&#12289;normalized SGD&#21644;clipped SGD&#12290;&#27492;&#22806;&#65292;&#24403;&#30446;&#26631;&#20989;&#25968;&#37319;&#29992;&#26377;&#38480;&#21644;&#24418;&#24335;&#26102;&#65292;&#25105;&#20204;&#22522;&#20110;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;&#35777;&#26126;&#20102;&#36825;&#20123;SGD&#31867;&#22411;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#36136;&#12290;&#29305;&#21035;&#22320;&#65292;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20123;SGD&#31867;&#22411;&#26041;&#27861;&#22312;&#38543;&#26426;&#36873;&#25321;&#30340;&#27493;&#38271;&#21644;&#21021;&#22987;&#28857;&#19978;&#33021;&#22815;&#25214;&#21040;&#30446;&#26631;&#20989;&#25968;&#30340;Clarke&#31283;&#23450;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we investigate the convergence properties of the stochastic gradient descent (SGD) method and its variants, especially in training neural networks built from nonsmooth activation functions. We develop a novel framework that assigns different timescales to stepsizes for updating the momentum terms and variables, respectively. Under mild conditions, we prove the global convergence of our proposed framework in both single-timescale and two-timescale cases. We show that our proposed framework encompasses a wide range of well-known SGD-type methods, including heavy-ball SGD, SignSGD, Lion, normalized SGD and clipped SGD. Furthermore, when the objective function adopts a finite-sum formulation, we prove the convergence properties for these SGD-type methods based on our proposed framework. In particular, we prove that these SGD-type methods find the Clarke stationary points of the objective function with randomly chosen stepsizes and initial points under mild assumptions. Preli
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20302;&#21442;&#25968;&#35757;&#32451;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#23558;&#21367;&#31215;&#20998;&#35299;&#20026;&#24352;&#37327;Tucker&#26684;&#24335;&#65292;&#24182;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#33258;&#36866;&#24212;&#22320;&#20462;&#21098;&#21367;&#31215;&#26680;&#30340;Tucker&#31209;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#38477;&#20302;&#35757;&#32451;&#25104;&#26412;&#12290;</title><link>http://arxiv.org/abs/2305.19059</link><description>&lt;p&gt;
&#35757;&#32451;&#26399;&#38388;&#30340;&#33258;&#36866;&#24212;&#31209;&#35889;&#21098;&#26525;&#21367;&#31215;&#23618;
&lt;/p&gt;
&lt;p&gt;
Rank-adaptive spectral pruning of convolutional layers during training. (arXiv:2305.19059v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19059
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20302;&#21442;&#25968;&#35757;&#32451;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#23558;&#21367;&#31215;&#20998;&#35299;&#20026;&#24352;&#37327;Tucker&#26684;&#24335;&#65292;&#24182;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#33258;&#36866;&#24212;&#22320;&#20462;&#21098;&#21367;&#31215;&#26680;&#30340;Tucker&#31209;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#38477;&#20302;&#35757;&#32451;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#22312;&#35745;&#31639;&#25104;&#26412;&#21644;&#20869;&#23384;&#38656;&#27714;&#26041;&#38754;&#22686;&#38271;&#36805;&#36895;&#65292;&#22240;&#27492;&#24050;&#32463;&#21457;&#23637;&#20102;&#21508;&#31181;&#21098;&#26525;&#25216;&#26415;&#20197;&#20943;&#23569;&#27169;&#22411;&#21442;&#25968;&#12290;&#22823;&#22810;&#25968;&#25216;&#26415;&#20391;&#37325;&#20110;&#36890;&#36807;&#22312;&#23436;&#25972;&#35757;&#32451;&#21518;&#23545;&#32593;&#32476;&#36827;&#34892;&#20462;&#21098;&#20197;&#20943;&#23569;&#25512;&#29702;&#25104;&#26412;&#12290;&#23569;&#37327;&#30340;&#26041;&#27861;&#35299;&#20915;&#20102;&#20943;&#23569;&#35757;&#32451;&#25104;&#26412;&#30340;&#38382;&#39064;&#65292;&#20027;&#35201;&#26159;&#36890;&#36807;&#20302;&#31209;&#23618;&#20998;&#35299;&#26469;&#21387;&#32553;&#32593;&#32476;&#12290;&#23613;&#31649;&#36825;&#20123;&#26041;&#27861;&#23545;&#20110;&#32447;&#24615;&#23618;&#26159;&#26377;&#25928;&#30340;&#65292;&#20294;&#26159;&#23427;&#20204;&#26080;&#27861;&#26377;&#25928;&#22788;&#29702;&#21367;&#31215;&#28388;&#27874;&#22120;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20302;&#21442;&#25968;&#35757;&#32451;&#26041;&#27861;&#65292;&#23558;&#21367;&#31215;&#20998;&#35299;&#20026;&#24352;&#37327;Tucker&#26684;&#24335;&#65292;&#24182;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#33258;&#36866;&#24212;&#22320;&#20462;&#21098;&#21367;&#31215;&#26680;&#30340;Tucker&#31209;&#12290;&#21033;&#29992;&#24494;&#20998;&#26041;&#31243;&#22312;&#24352;&#37327;&#27969;&#24418;&#19978;&#30340;&#20960;&#20309;&#31215;&#20998;&#29702;&#35770;&#30340;&#22522;&#26412;&#32467;&#26524;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#19968;&#20010;&#40065;&#26834;&#30340;&#35757;&#32451;&#31639;&#27861;&#65292;&#35777;&#26126;&#33021;&#22815;&#36924;&#36817;&#23436;&#25972;&#30340;&#22522;&#32447;&#24615;&#33021;&#24182;&#20445;&#35777;&#25439;&#22833;&#19979;&#38477;&#12290;
&lt;/p&gt;
&lt;p&gt;
The computing cost and memory demand of deep learning pipelines have grown fast in recent years and thus a variety of pruning techniques have been developed to reduce model parameters. The majority of these techniques focus on reducing inference costs by pruning the network after a pass of full training. A smaller number of methods address the reduction of training costs, mostly based on compressing the network via low-rank layer factorizations. Despite their efficiency for linear layers, these methods fail to effectively handle convolutional filters. In this work, we propose a low-parametric training method that factorizes the convolutions into tensor Tucker format and adaptively prunes the Tucker ranks of the convolutional kernel during training. Leveraging fundamental results from geometric integration theory of differential equations on tensor manifolds, we obtain a robust training algorithm that provably approximates the full baseline performance and guarantees loss descent. A var
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;ReLU&#21333;&#20803;&#29305;&#24449;&#28608;&#27963;&#20540;&#38598;&#21512;&#36827;&#34892;&#21442;&#25968;&#21270;&#30340;&#20960;&#20309;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#20013;&#30340;&#35268;&#33539;&#21270;&#25216;&#26415;&#65292;&#25913;&#36827;&#20102;ReLU&#32593;&#32476;&#29305;&#24449;&#23398;&#20064;&#65292;&#25552;&#39640;&#20102;&#20248;&#21270;&#31283;&#23450;&#24615;&#21644;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#33719;&#24471;&#26356;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.15912</link><description>&lt;p&gt;
&#25913;&#36827;ReLU&#32593;&#32476;&#29305;&#24449;&#23398;&#20064;&#30340;&#31070;&#32463;&#29305;&#24449;&#28608;&#27963;&#20540;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Neural Characteristic Activation Value Analysis for Improved ReLU Network Feature Learning. (arXiv:2305.15912v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15912
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;ReLU&#21333;&#20803;&#29305;&#24449;&#28608;&#27963;&#20540;&#38598;&#21512;&#36827;&#34892;&#21442;&#25968;&#21270;&#30340;&#20960;&#20309;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#20013;&#30340;&#35268;&#33539;&#21270;&#25216;&#26415;&#65292;&#25913;&#36827;&#20102;ReLU&#32593;&#32476;&#29305;&#24449;&#23398;&#20064;&#65292;&#25552;&#39640;&#20102;&#20248;&#21270;&#31283;&#23450;&#24615;&#21644;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#33719;&#24471;&#26356;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#20013;&#21333;&#20010;ReLU&#21333;&#20803;&#30340;&#29305;&#24449;&#28608;&#27963;&#20540;&#12290;&#25105;&#20204;&#23558;ReLU&#21333;&#20803;&#22312;&#36755;&#20837;&#31354;&#38388;&#20013;&#23545;&#24212;&#30340;&#29305;&#24449;&#28608;&#27963;&#20540;&#38598;&#21512;&#31216;&#20026;ReLU&#21333;&#20803;&#30340;&#29305;&#24449;&#28608;&#27963;&#38598;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#29305;&#24449;&#28608;&#27963;&#38598;&#19982;ReLU&#32593;&#32476;&#20013;&#23398;&#20064;&#29305;&#24449;&#20043;&#38388;&#30340;&#26126;&#30830;&#32852;&#31995;&#65292;&#24182;&#25581;&#31034;&#20102;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#20013;&#20351;&#29992;&#30340;&#21508;&#31181;&#31070;&#32463;&#32593;&#32476;&#35268;&#33539;&#21270;&#25216;&#26415;&#22914;&#20309;&#35268;&#33539;&#21270;&#21644;&#31283;&#23450;SGD&#20248;&#21270;&#12290;&#21033;&#29992;&#36825;&#20123;&#27934;&#35265;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20960;&#20309;&#26041;&#27861;&#26469;&#21442;&#25968;&#21270;ReLU&#32593;&#32476;&#20197;&#25913;&#36827;&#29305;&#24449;&#23398;&#20064;&#12290;&#25105;&#20204;&#32463;&#39564;&#24615;&#22320;&#39564;&#35777;&#20102;&#20854;&#26377;&#29992;&#24615;&#65292;&#20351;&#29992;&#20102;&#19981;&#37027;&#20040;&#31934;&#24515;&#36873;&#25321;&#30340;&#21021;&#22987;&#21270;&#26041;&#26696;&#21644;&#26356;&#22823;&#30340;&#23398;&#20064;&#29575;&#12290;&#25105;&#20204;&#25253;&#21578;&#20102;&#26356;&#22909;&#30340;&#20248;&#21270;&#31283;&#23450;&#24615;&#65292;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#21644;&#26356;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We examine the characteristic activation values of individual ReLU units in neural networks. We refer to the corresponding set for such characteristic activation values in the input space as the characteristic activation set of a ReLU unit. We draw an explicit connection between the characteristic activation set and learned features in ReLU networks. This connection leads to new insights into why various neural network normalization techniques used in modern deep learning architectures regularize and stabilize SGD optimization. Utilizing these insights, we propose a geometric approach to parameterize ReLU networks for improved feature learning. We empirically verify its usefulness with less carefully chosen initialization schemes and larger learning rates. We report improved optimization stability, faster convergence speed, and better generalization performance.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#21644;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#20998;&#26512;&#30340;&#23545;&#20598;&#24615;&#26694;&#26550;&#65292;&#24182;&#35777;&#26126;&#20102;&#23398;&#20064;&#19981;&#20250;&#21463;&#21040;&#32500;&#25968;&#28798;&#38590;&#30340;&#24433;&#21709;&#65292;&#20351; RFMs &#21487;&#20197;&#22312;&#26680;&#33539;&#22260;&#20043;&#22806;&#21457;&#25381;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2305.05642</link><description>&lt;p&gt;
&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#21644;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#20998;&#26512;&#30340;&#23545;&#20598;&#24615;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A duality framework for generalization analysis of random feature models and two-layer neural networks. (arXiv:2305.05642v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05642
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#21644;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#20998;&#26512;&#30340;&#23545;&#20598;&#24615;&#26694;&#26550;&#65292;&#24182;&#35777;&#26126;&#20102;&#23398;&#20064;&#19981;&#20250;&#21463;&#21040;&#32500;&#25968;&#28798;&#38590;&#30340;&#24433;&#21709;&#65292;&#20351; RFMs &#21487;&#20197;&#22312;&#26680;&#33539;&#22260;&#20043;&#22806;&#21457;&#25381;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22312;&#39640;&#32500;&#20998;&#26512;&#20013;&#20986;&#29616;&#30340;&#33258;&#28982;&#20989;&#25968;&#31354;&#38388; $\mathcal{F}_{p,\pi}$ &#21644; Barron &#31354;&#38388;&#20013;&#23398;&#20064;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#23545;&#20598;&#20998;&#26512;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#36825;&#20123;&#31354;&#38388;&#30340;&#36924;&#36817;&#21644;&#20272;&#35745;&#21487;&#20197;&#22312;&#26576;&#31181;&#24847;&#20041;&#19979;&#34987;&#35270;&#20026;&#31561;&#20215;&#30340;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#22312;&#30740;&#31350;&#36825;&#20004;&#31181;&#27169;&#22411;&#30340;&#27867;&#21270;&#26102;&#26356;&#19987;&#27880;&#20110;&#26356;&#23481;&#26131;&#30340;&#36924;&#36817;&#21644;&#20272;&#35745;&#38382;&#39064;&#12290;&#36890;&#36807;&#23450;&#20041;&#19968;&#31181;&#22522;&#20110;&#20449;&#24687;&#30340;&#22797;&#26434;&#24230;&#26469;&#26377;&#25928;&#22320;&#25511;&#21046;&#20272;&#35745;&#35823;&#24046;&#65292;&#24314;&#31435;&#20102;&#23545;&#20598;&#31561;&#20215;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#23545;&#20004;&#20010;&#20855;&#20307;&#24212;&#29992;&#36827;&#34892;&#32508;&#21512;&#20998;&#26512;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#23545;&#20598;&#24615;&#26694;&#26550;&#30340;&#28789;&#27963;&#24615;&#12290;&#31532;&#19968;&#20010;&#24212;&#29992;&#26159;&#30740;&#31350;&#20351;&#29992; RFMs &#23398;&#20064; $\mathcal{F}_{p,\pi}$ &#20013;&#30340;&#20989;&#25968;&#12290;&#25105;&#20204;&#35777;&#26126;&#21482;&#35201; $p&gt;1$&#65292;&#23398;&#20064;&#19981;&#20250;&#21463;&#21040;&#32500;&#25968;&#28798;&#38590;&#30340;&#24433;&#21709;&#65292;&#36825;&#24847;&#21619;&#30528; RFMs &#21487;&#20197;&#22312;&#26680;&#33539;&#22260;&#20043;&#22806;&#21457;&#25381;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of learning functions in the $\mathcal{F}_{p,\pi}$ and Barron spaces, which are natural function spaces that arise in the high-dimensional analysis of random feature models (RFMs) and two-layer neural networks. Through a duality analysis, we reveal that the approximation and estimation of these spaces can be considered equivalent in a certain sense. This enables us to focus on the easier problem of approximation and estimation when studying the generalization of both models. The dual equivalence is established by defining an information-based complexity that can effectively control estimation errors. Additionally, we demonstrate the flexibility of our duality framework through comprehensive analyses of two concrete applications.  The first application is to study learning functions in $\mathcal{F}_{p,\pi}$ with RFMs. We prove that the learning does not suffer from the curse of dimensionality as long as $p&gt;1$, implying RFMs can work beyond the kernel regime. Our 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#31216;&#20026;&#32553;&#20943;&#24322;&#26041;&#24046;PCA&#65292;&#23427;&#22312;&#20811;&#26381;&#30149;&#24577;&#38382;&#39064;&#30340;&#21516;&#26102;&#23454;&#29616;&#20102;&#36817;&#20046;&#26368;&#20248;&#21644;&#26080;&#26465;&#20214;&#25968;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2303.06198</link><description>&lt;p&gt;
&#20811;&#26381;&#24322;&#26041;&#24046;PCA&#20013;&#30149;&#24577;&#38382;&#39064;&#30340;&#32553;&#20943;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Deflated HeteroPCA: Overcoming the curse of ill-conditioning in heteroskedastic PCA. (arXiv:2303.06198v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06198
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#31216;&#20026;&#32553;&#20943;&#24322;&#26041;&#24046;PCA&#65292;&#23427;&#22312;&#20811;&#26381;&#30149;&#24577;&#38382;&#39064;&#30340;&#21516;&#26102;&#23454;&#29616;&#20102;&#36817;&#20046;&#26368;&#20248;&#21644;&#26080;&#26465;&#20214;&#25968;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a novel algorithm, called Deflated-HeteroPCA, that overcomes the curse of ill-conditioning in heteroskedastic PCA while achieving near-optimal and condition-number-free theoretical guarantees.
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;&#20110;&#20174;&#21463;&#27745;&#26579;&#30340;&#25968;&#25454;&#20013;&#20272;&#35745;&#20302;&#31209;&#30697;&#38453;X*&#30340;&#21015;&#23376;&#31354;&#38388;&#12290;&#24403;&#23384;&#22312;&#24322;&#26041;&#24046;&#22122;&#22768;&#21644;&#19981;&#24179;&#34913;&#30340;&#32500;&#24230;&#65288;&#21363;n2 &gt;&gt; n1&#65289;&#26102;&#65292;&#22914;&#20309;&#22312;&#23481;&#32435;&#26368;&#24191;&#27867;&#30340;&#20449;&#22122;&#27604;&#33539;&#22260;&#30340;&#21516;&#26102;&#33719;&#24471;&#26368;&#20339;&#30340;&#32479;&#35745;&#31934;&#24230;&#21464;&#24471;&#29305;&#21035;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#34429;&#28982;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;HeteroPCA&#25104;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#24378;&#26377;&#21147;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#23427;&#36973;&#21463;&#20102;&#8220;&#30149;&#24577;&#38382;&#39064;&#30340;&#35781;&#21650;&#8221;&#65292;&#21363;&#38543;&#30528;X*&#30340;&#26465;&#20214;&#25968;&#22686;&#38271;&#65292;&#20854;&#24615;&#33021;&#20250;&#19979;&#38477;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#20851;&#38190;&#38382;&#39064;&#32780;&#19981;&#24433;&#21709;&#20801;&#35768;&#30340;&#20449;&#22122;&#27604;&#33539;&#22260;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#31216;&#20026;&#32553;&#20943;&#24322;&#26041;&#24046;PCA&#65292;&#23427;&#22312;$\ell_2$&#21644;$\ell_{2,\infty}$&#32479;&#35745;&#31934;&#24230;&#26041;&#38754;&#23454;&#29616;&#20102;&#36817;&#20046;&#26368;&#20248;&#21644;&#26080;&#26465;&#20214;&#25968;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#23558;&#35889;&#20998;&#25104;&#20004;&#37096;&#20998;
&lt;/p&gt;
&lt;p&gt;
This paper is concerned with estimating the column subspace of a low-rank matrix $\boldsymbol{X}^\star \in \mathbb{R}^{n_1\times n_2}$ from contaminated data. How to obtain optimal statistical accuracy while accommodating the widest range of signal-to-noise ratios (SNRs) becomes particularly challenging in the presence of heteroskedastic noise and unbalanced dimensionality (i.e., $n_2\gg n_1$). While the state-of-the-art algorithm $\textsf{HeteroPCA}$ emerges as a powerful solution for solving this problem, it suffers from "the curse of ill-conditioning," namely, its performance degrades as the condition number of $\boldsymbol{X}^\star$ grows. In order to overcome this critical issue without compromising the range of allowable SNRs, we propose a novel algorithm, called $\textsf{Deflated-HeteroPCA}$, that achieves near-optimal and condition-number-free theoretical guarantees in terms of both $\ell_2$ and $\ell_{2,\infty}$ statistical accuracy. The proposed algorithm divides the spectrum
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24191;&#20041;&#31574;&#30053;&#25552;&#21319;&#31639;&#27861;&#65292;&#32467;&#21512;&#20102;&#22312;&#32447;&#26041;&#27861;&#30340;&#31574;&#30053;&#25552;&#21319;&#20445;&#35777;&#21644;&#31163;&#32447;&#31574;&#30053;&#31639;&#27861;&#36890;&#36807;&#26679;&#26412;&#37325;&#29992;&#26377;&#25928;&#21033;&#29992;&#25968;&#25454;&#30340;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2206.13714</link><description>&lt;p&gt;
&#24102;&#29702;&#35770;&#25903;&#25345;&#30340;&#26679;&#26412;&#37325;&#29992;&#30340;&#24191;&#20041;&#31574;&#30053;&#25552;&#21319;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Generalized Policy Improvement Algorithms with Theoretically Supported Sample Reuse. (arXiv:2206.13714v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.13714
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24191;&#20041;&#31574;&#30053;&#25552;&#21319;&#31639;&#27861;&#65292;&#32467;&#21512;&#20102;&#22312;&#32447;&#26041;&#27861;&#30340;&#31574;&#30053;&#25552;&#21319;&#20445;&#35777;&#21644;&#31163;&#32447;&#31574;&#30053;&#31639;&#27861;&#36890;&#36807;&#26679;&#26412;&#37325;&#29992;&#26377;&#25928;&#21033;&#29992;&#25968;&#25454;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#39537;&#21160;&#30340;&#23398;&#20064;&#25511;&#21046;&#26041;&#27861;&#20855;&#26377;&#25913;&#21892;&#22797;&#26434;&#31995;&#32479;&#36816;&#34892;&#30340;&#28508;&#21147;&#65292;&#32780;&#22522;&#20110;&#27169;&#22411;&#30340;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20195;&#34920;&#20102;&#19968;&#31181;&#27969;&#34892;&#30340;&#25968;&#25454;&#39537;&#21160;&#25511;&#21046;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#31639;&#27861;&#31867;&#21035;&#22312;&#23454;&#38469;&#25511;&#21046;&#37096;&#32626;&#30340;&#20004;&#20010;&#37325;&#35201;&#35201;&#27714;&#20043;&#38388;&#23384;&#22312;&#26435;&#34913;&#65306;&#65288;i&#65289;&#23454;&#38469;&#24615;&#33021;&#20445;&#35777;&#21644;&#65288;ii&#65289;&#25968;&#25454;&#25928;&#29575;&#12290;&#31163;&#32447;&#31574;&#30053;&#31639;&#27861;&#36890;&#36807;&#26679;&#26412;&#37325;&#29992;&#26377;&#25928;&#21033;&#29992;&#25968;&#25454;&#65292;&#20294;&#32570;&#20047;&#29702;&#35770;&#20445;&#35777;&#65292;&#32780;&#22312;&#32447;&#31574;&#30053;&#31639;&#27861;&#20445;&#35777;&#20102;&#35757;&#32451;&#26399;&#38388;&#30340;&#36817;&#20284;&#31574;&#30053;&#25913;&#36827;&#65292;&#20294;&#21463;&#21040;&#39640;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#24433;&#21709;&#12290;&#20026;&#20102;&#24179;&#34913;&#36825;&#20123;&#31454;&#20105;&#30446;&#26631;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31867;&#24191;&#20041;&#31574;&#30053;&#25552;&#21319;&#31639;&#27861;&#65292;&#23427;&#32467;&#21512;&#20102;&#22312;&#32447;&#26041;&#27861;&#30340;&#31574;&#30053;&#25552;&#21319;&#20445;&#35777;&#21644;&#26679;&#26412;&#37325;&#29992;&#30340;&#25928;&#29575;&#12290;&#36890;&#36807;&#23545;&#26469;&#33258;DeepMind C&#30340;&#22810;&#31181;&#36830;&#32493;&#25511;&#21046;&#20219;&#21153;&#36827;&#34892; extensive &#30340;&#23454;&#39564;&#20998;&#26512;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#26032;&#31867;&#31639;&#27861;&#30340;&#30410;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data-driven, learning-based control methods offer the potential to improve operations in complex systems, and model-free deep reinforcement learning represents a popular approach to data-driven control. However, existing classes of algorithms present a trade-off between two important deployment requirements for real-world control: (i) practical performance guarantees and (ii) data efficiency. Off-policy algorithms make efficient use of data through sample reuse but lack theoretical guarantees, while on-policy algorithms guarantee approximate policy improvement throughout training but suffer from high sample complexity. In order to balance these competing goals, we develop a class of Generalized Policy Improvement algorithms that combines the policy improvement guarantees of on-policy methods with the efficiency of sample reuse. We demonstrate the benefits of this new class of algorithms through extensive experimental analysis on a variety of continuous control tasks from the DeepMind C
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#28982;lasso&#21464;&#20307;&#30340;MARS&#26041;&#27861;&#65292;&#36890;&#36807;&#20943;&#23569;&#23545;&#32500;&#24230;&#30340;&#20381;&#36182;&#26469;&#33719;&#24471;&#25910;&#25947;&#29575;&#65292;&#24182;&#19982;&#20351;&#29992;&#24179;&#28369;&#24615;&#32422;&#26463;&#30340;&#38750;&#21442;&#25968;&#20272;&#35745;&#25216;&#26415;&#32852;&#31995;&#22312;&#19968;&#36215;&#12290;</title><link>http://arxiv.org/abs/2111.11694</link><description>&lt;p&gt;
MARS via LASSO.&#65288;arXiv:2111.11694v2 [math.ST] &#24050;&#26356;&#26032;&#65289;
&lt;/p&gt;
&lt;p&gt;
MARS via LASSO. (arXiv:2111.11694v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.11694
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#28982;lasso&#21464;&#20307;&#30340;MARS&#26041;&#27861;&#65292;&#36890;&#36807;&#20943;&#23569;&#23545;&#32500;&#24230;&#30340;&#20381;&#36182;&#26469;&#33719;&#24471;&#25910;&#25947;&#29575;&#65292;&#24182;&#19982;&#20351;&#29992;&#24179;&#28369;&#24615;&#32422;&#26463;&#30340;&#38750;&#21442;&#25968;&#20272;&#35745;&#25216;&#26415;&#32852;&#31995;&#22312;&#19968;&#36215;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20803;&#33258;&#36866;&#24212;&#22238;&#24402;&#26679;&#26465;&#65288;Multivariate Adaptive Regression Splines&#65292;MARS&#65289;&#26159;Friedman&#22312;1991&#24180;&#25552;&#20986;&#30340;&#19968;&#31181;&#38750;&#21442;&#25968;&#22238;&#24402;&#26041;&#27861;&#12290;MARS&#23558;&#31616;&#21333;&#30340;&#38750;&#32447;&#24615;&#21644;&#38750;&#21152;&#24615;&#20989;&#25968;&#25311;&#21512;&#21040;&#22238;&#24402;&#25968;&#25454;&#19978;&#12290;&#26412;&#25991;&#25552;&#20986;&#24182;&#30740;&#31350;&#20102;MARS&#26041;&#27861;&#30340;&#19968;&#31181;&#33258;&#28982;lasso&#21464;&#20307;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#22522;&#20110;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#65292;&#36890;&#36807;&#32771;&#34385;MARS&#22522;&#30784;&#20989;&#25968;&#30340;&#26080;&#38480;&#32500;&#32447;&#24615;&#32452;&#21512;&#24182;&#24378;&#21152;&#22522;&#20110;&#21464;&#20998;&#30340;&#22797;&#26434;&#24230;&#32422;&#26463;&#26465;&#20214;&#26469;&#33719;&#24471;&#20989;&#25968;&#30340;&#20984;&#31867;&#12290;&#34429;&#28982;&#25105;&#20204;&#30340;&#20272;&#35745;&#26159;&#23450;&#20041;&#20026;&#26080;&#38480;&#32500;&#20248;&#21270;&#38382;&#39064;&#30340;&#35299;&#65292;&#20294;&#20854;&#21487;&#20197;&#36890;&#36807;&#26377;&#38480;&#32500;&#20984;&#20248;&#21270;&#26469;&#35745;&#31639;&#12290;&#22312;&#19968;&#20123;&#26631;&#20934;&#35774;&#35745;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#20165;&#22312;&#32500;&#24230;&#19978;&#23545;&#25968;&#25910;&#25947;&#65292;&#22240;&#27492;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#36991;&#20813;&#20102;&#36890;&#24120;&#30340;&#32500;&#24230;&#28798;&#38590;&#12290;&#25105;&#20204;&#36824;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33258;&#28982;&#22320;&#19982;&#22522;&#20110;&#24179;&#28369;&#24615;&#32422;&#26463;&#30340;&#38750;&#21442;&#25968;&#20272;&#35745;&#25216;&#26415;&#30456;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multivariate adaptive regression splines (MARS) is a popular method for nonparametric regression introduced by Friedman in 1991. MARS fits simple nonlinear and non-additive functions to regression data. We propose and study a natural lasso variant of the MARS method. Our method is based on least squares estimation over a convex class of functions obtained by considering infinite-dimensional linear combinations of functions in the MARS basis and imposing a variation based complexity constraint. Our estimator can be computed via finite-dimensional convex optimization, although it is defined as a solution to an infinite-dimensional optimization problem. Under a few standard design assumptions, we prove that our estimator achieves a rate of convergence that depends only logarithmically on dimension and thus avoids the usual curse of dimensionality to some extent. We also show that our method is naturally connected to nonparametric estimation techniques based on smoothness constraints. We i
&lt;/p&gt;</description></item></channel></rss>