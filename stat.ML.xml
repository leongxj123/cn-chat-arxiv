<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861; RECO-SLIP&#65292;&#29992;&#20110;&#22312;&#23646;&#24615;&#22270;&#20013;&#26816;&#27979;&#23646;&#20110;&#26032;&#31867;&#21035;&#30340;&#33410;&#28857;&#65292;&#33021;&#22815;&#26377;&#25928;&#35299;&#20915;&#23376;&#32676;&#20307;&#36716;&#31227;&#19979;&#30340;&#33410;&#28857;&#26816;&#27979;&#38382;&#39064;&#65292;&#23454;&#39564;&#35777;&#26126;&#20854;&#24615;&#33021;&#20248;&#36234;&#12290;</title><link>https://arxiv.org/abs/2404.01216</link><description>&lt;p&gt;
&#22312;&#23376;&#32676;&#20307;&#36716;&#31227;&#19979;&#30340;&#26032;&#39062;&#33410;&#28857;&#31867;&#21035;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Novel Node Category Detection Under Subpopulation Shift
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01216
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861; RECO-SLIP&#65292;&#29992;&#20110;&#22312;&#23646;&#24615;&#22270;&#20013;&#26816;&#27979;&#23646;&#20110;&#26032;&#31867;&#21035;&#30340;&#33410;&#28857;&#65292;&#33021;&#22815;&#26377;&#25928;&#35299;&#20915;&#23376;&#32676;&#20307;&#36716;&#31227;&#19979;&#30340;&#33410;&#28857;&#26816;&#27979;&#38382;&#39064;&#65292;&#23454;&#39564;&#35777;&#26126;&#20854;&#24615;&#33021;&#20248;&#36234;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#22270;&#25968;&#25454;&#20013;&#65292;&#20998;&#24067;&#36716;&#31227;&#21487;&#20197;&#36890;&#36807;&#21508;&#31181;&#26041;&#24335;&#34920;&#29616;&#65292;&#20363;&#22914;&#26032;&#31867;&#21035;&#30340;&#20986;&#29616;&#21644;&#29616;&#26377;&#31867;&#21035;&#30456;&#23545;&#27604;&#20363;&#30340;&#21464;&#21270;&#12290;&#22312;&#36825;&#31181;&#20998;&#24067;&#36716;&#31227;&#19979;&#65292;&#26816;&#27979;&#23646;&#20110;&#26032;&#31867;&#21035;&#30340;&#33410;&#28857;&#23545;&#20110;&#23433;&#20840;&#25110;&#27934;&#23519;&#21457;&#29616;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#31216;&#20026;&#20855;&#26377;&#36873;&#25321;&#24615;&#38142;&#36335;&#39044;&#27979;&#30340;&#21484;&#22238;&#32422;&#26463;&#20248;&#21270;&#65288;RECO-SLIP&#65289;&#65292;&#29992;&#20110;&#22312;&#23376;&#32676;&#20307;&#36716;&#31227;&#19979;&#26816;&#27979;&#23646;&#24615;&#22270;&#20013;&#23646;&#20110;&#26032;&#31867;&#21035;&#30340;&#33410;&#28857;&#12290;&#36890;&#36807;&#23558;&#21484;&#22238;&#32422;&#26463;&#23398;&#20064;&#26694;&#26550;&#19982;&#39640;&#25928;&#26679;&#26412;&#39044;&#27979;&#26426;&#21046;&#30456;&#32467;&#21512;&#65292;RECO-SLIP&#35299;&#20915;&#20102;&#25269;&#25239;&#23376;&#32676;&#20307;&#36716;&#31227;&#21644;&#26377;&#25928;&#21033;&#29992;&#22270;&#32467;&#26500;&#30340;&#21452;&#37325;&#25361;&#25112;&#12290;&#25105;&#20204;&#22312;&#22810;&#20010;&#22270;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#35777;&#35780;&#20272;&#65292;&#32467;&#26524;&#34920;&#26126;RECO-SLIP&#30456;&#23545;&#20110;&#29616;&#26377;&#26041;&#27861;&#20855;&#26377;&#26356;&#20248;&#24322;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01216v1 Announce Type: new  Abstract: In real-world graph data, distribution shifts can manifest in various ways, such as the emergence of new categories and changes in the relative proportions of existing categories. It is often important to detect nodes of novel categories under such distribution shifts for safety or insight discovery purposes. We introduce a new approach, Recall-Constrained Optimization with Selective Link Prediction (RECO-SLIP), to detect nodes belonging to novel categories in attributed graphs under subpopulation shifts. By integrating a recall-constrained learning framework with a sample-efficient link prediction mechanism, RECO-SLIP addresses the dual challenges of resilience against subpopulation shifts and the effective exploitation of graph structure. Our extensive empirical evaluation across multiple graph datasets demonstrates the superior performance of RECO-SLIP over existing methods.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25968;&#25454;&#39044;&#22788;&#29702;&#31639;&#27861;&#65292;&#27491;&#20132;&#20110;&#20559;&#35265;&#65288;OB&#65289;&#65292;&#36890;&#36807;&#30830;&#20445;&#25968;&#25454;&#19982;&#25935;&#24863;&#21464;&#37327;&#19981;&#30456;&#20851;&#65292;&#23454;&#29616;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#30340;&#21453;&#20107;&#23454;&#20844;&#24179;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.17852</link><description>&lt;p&gt;
&#36890;&#36807;&#23558;&#25968;&#25454;&#36716;&#21270;&#20026;&#19982;&#20559;&#35265;&#27491;&#20132;&#30340;&#26041;&#24335;&#23454;&#29616;&#21453;&#20107;&#23454;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Counterfactual Fairness through Transforming Data Orthogonal to Bias
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17852
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25968;&#25454;&#39044;&#22788;&#29702;&#31639;&#27861;&#65292;&#27491;&#20132;&#20110;&#20559;&#35265;&#65288;OB&#65289;&#65292;&#36890;&#36807;&#30830;&#20445;&#25968;&#25454;&#19982;&#25935;&#24863;&#21464;&#37327;&#19981;&#30456;&#20851;&#65292;&#23454;&#29616;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#30340;&#21453;&#20107;&#23454;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#35299;&#20915;&#21508;&#20010;&#39046;&#22495;&#30340;&#22797;&#26434;&#38382;&#39064;&#20013;&#23637;&#29616;&#20986;&#20102;&#21331;&#36234;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#26377;&#26102;&#21487;&#33021;&#34920;&#29616;&#20986;&#26377;&#20559;&#35265;&#30340;&#20915;&#31574;&#65292;&#23548;&#33268;&#19981;&#21516;&#32676;&#20307;&#20043;&#38388;&#30340;&#24453;&#36935;&#19981;&#24179;&#31561;&#12290;&#23613;&#31649;&#20844;&#24179;&#24615;&#26041;&#38754;&#30340;&#30740;&#31350;&#24050;&#32463;&#24456;&#24191;&#27867;&#65292;&#20294;&#22810;&#20803;&#36830;&#32493;&#25935;&#24863;&#21464;&#37327;&#23545;&#20915;&#31574;&#32467;&#26524;&#30340;&#24494;&#22937;&#24433;&#21709;&#23578;&#26410;&#24471;&#21040;&#20805;&#20998;&#30740;&#31350;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25968;&#25454;&#39044;&#22788;&#29702;&#31639;&#27861;&#65292;&#21363;&#27491;&#20132;&#20110;&#20559;&#35265;&#65288;OB&#65289;&#65292;&#26088;&#22312;&#28040;&#38500;&#36830;&#32493;&#25935;&#24863;&#21464;&#37327;&#30340;&#24433;&#21709;&#65292;&#20174;&#32780;&#20419;&#36827;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#30340;&#21453;&#20107;&#23454;&#20844;&#24179;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#65288;SCM&#65289;&#20013;&#32852;&#21512;&#27491;&#24577;&#20998;&#24067;&#30340;&#20551;&#35774;&#65292;&#35777;&#26126;&#20102;&#36890;&#36807;&#30830;&#20445;&#25968;&#25454;&#19982;&#25935;&#24863;&#21464;&#37327;&#19981;&#30456;&#20851;&#21363;&#21487;&#23454;&#29616;&#21453;&#20107;&#23454;&#20844;&#24179;&#24615;&#12290;OB&#31639;&#27861;&#19982;&#27169;&#22411;&#26080;&#20851;&#65292;&#36866;&#29992;&#20110;&#22810;&#31181;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17852v1 Announce Type: new  Abstract: Machine learning models have shown exceptional prowess in solving complex issues across various domains. Nonetheless, these models can sometimes exhibit biased decision-making, leading to disparities in treatment across different groups. Despite the extensive research on fairness, the nuanced effects of multivariate and continuous sensitive variables on decision-making outcomes remain insufficiently studied. We introduce a novel data pre-processing algorithm, Orthogonal to Bias (OB), designed to remove the influence of a group of continuous sensitive variables, thereby facilitating counterfactual fairness in machine learning applications. Our approach is grounded in the assumption of a jointly normal distribution within a structural causal model (SCM), proving that counterfactual fairness can be achieved by ensuring the data is uncorrelated with sensitive variables. The OB algorithm is model-agnostic, catering to a wide array of machine 
&lt;/p&gt;</description></item><item><title>&#24418;&#24577;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#23384;&#22312;&#25361;&#25112;&#65292;&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#22522;&#20110;&#26799;&#24230;&#19979;&#38477;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#25506;&#35752;&#20102;&#22522;&#20110;&#24494;&#20998;&#26041;&#27861;&#21644;&#21453;&#21521;&#20256;&#25773;&#23545;&#24418;&#24577;&#32593;&#32476;&#30340;&#28508;&#21147;&#21644;&#23616;&#38480;&#24615;&#65292;&#25552;&#20379;&#20102;&#20851;&#20110;&#21021;&#22987;&#21270;&#21644;&#23398;&#20064;&#29575;&#30340;&#29702;&#35770;&#25351;&#23548;&#12290;</title><link>https://arxiv.org/abs/2403.12975</link><description>&lt;p&gt;
&#29992;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#24418;&#24577;&#31070;&#32463;&#32593;&#32476;&#65306;&#19968;&#20123;&#29702;&#35770;&#35265;&#35299;
&lt;/p&gt;
&lt;p&gt;
Training morphological neural networks with gradient descent: some theoretical insights
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12975
&lt;/p&gt;
&lt;p&gt;
&#24418;&#24577;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#23384;&#22312;&#25361;&#25112;&#65292;&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#22522;&#20110;&#26799;&#24230;&#19979;&#38477;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#25506;&#35752;&#20102;&#22522;&#20110;&#24494;&#20998;&#26041;&#27861;&#21644;&#21453;&#21521;&#20256;&#25773;&#23545;&#24418;&#24577;&#32593;&#32476;&#30340;&#28508;&#21147;&#21644;&#23616;&#38480;&#24615;&#65292;&#25552;&#20379;&#20102;&#20851;&#20110;&#21021;&#22987;&#21270;&#21644;&#23398;&#20064;&#29575;&#30340;&#29702;&#35770;&#25351;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24418;&#24577;&#31070;&#32463;&#32593;&#32476;&#25110;&#23618;&#21487;&#20197;&#25104;&#20026;&#25552;&#21319;&#25968;&#23398;&#24418;&#24577;&#23398;&#36827;&#23637;&#30340;&#24378;&#22823;&#24037;&#20855;&#65292;&#26080;&#35770;&#26159;&#22312;&#29702;&#35770;&#26041;&#38754;&#65292;&#22914;&#23436;&#25972;&#26684;&#31639;&#23376;&#30340;&#34920;&#31034;&#65292;&#36824;&#26159;&#22312;&#22270;&#20687;&#22788;&#29702;&#27969;&#31243;&#30340;&#24320;&#21457;&#26041;&#38754;&#12290;&#28982;&#32780;&#65292;&#24403;&#36825;&#20123;&#26550;&#26500;&#21253;&#21547;&#22810;&#23618;&#24418;&#24577;&#23398;&#26102;&#65292;&#33267;&#23569;&#22312;&#20351;&#29992;&#22522;&#20110;&#26799;&#24230;&#19979;&#38477;&#30340;&#20248;&#21270;&#31639;&#27861;&#30340;&#27969;&#34892;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#20869;&#65292;&#36825;&#20123;&#32593;&#32476;&#24456;&#38590;&#36827;&#34892;&#35757;&#32451;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#22522;&#20110;&#24494;&#20998;&#26041;&#27861;&#21644;&#21453;&#21521;&#20256;&#25773;&#24212;&#29992;&#20110;&#24418;&#24577;&#32593;&#32476;&#30340;&#28508;&#21147;&#21644;&#23616;&#38480;&#24615;&#65292;&#32771;&#34385;&#21040;Bouligand&#23548;&#25968;&#30340;&#38750;&#20809;&#28369;&#20248;&#21270;&#27010;&#24565;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#35265;&#35299;&#21644;&#39318;&#20010;&#29702;&#35770;&#25351;&#21335;&#65292;&#29305;&#21035;&#26159;&#20851;&#20110;&#21021;&#22987;&#21270;&#21644;&#23398;&#20064;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12975v1 Announce Type: cross  Abstract: Morphological neural networks, or layers, can be a powerful tool to boost the progress in mathematical morphology, either on theoretical aspects such as the representation of complete lattice operators, or in the development of image processing pipelines. However, these architectures turn out to be difficult to train when they count more than a few morphological layers, at least within popular machine learning frameworks which use gradient descent based optimization algorithms. In this paper we investigate the potential and limitations of differentiation based approaches and back-propagation applied to morphological networks, in light of the non-smooth optimization concept of Bouligand derivative. We provide insights and first theoretical guidelines, in particular regarding initialization and learning rates.
&lt;/p&gt;</description></item><item><title>&#35777;&#26126;&#22312;1-D&#25968;&#25454;&#19978;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#31561;&#20215;&#20110;&#35299;&#20915;&#19968;&#20010;&#20855;&#26377;&#22266;&#23450;&#29305;&#24449;&#23383;&#20856;&#30697;&#38453;&#30340;&#20984;Lasso&#38382;&#39064;&#65292;&#20026;&#20840;&#23616;&#26368;&#20248;&#32593;&#32476;&#21644;&#35299;&#31354;&#38388;&#25552;&#20379;&#20102;&#27934;&#23519;&#12290;</title><link>https://arxiv.org/abs/2403.01046</link><description>&lt;p&gt;
&#19968;&#20010;&#38236;&#23376;&#30340;&#24211;&#65306;&#20302;&#32500;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26159;&#20855;&#26377;&#21453;&#23556;&#29305;&#24449;&#30340;&#20984;Lasso&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Library of Mirrors: Deep Neural Nets in Low Dimensions are Convex Lasso Models with Reflection Features
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01046
&lt;/p&gt;
&lt;p&gt;
&#35777;&#26126;&#22312;1-D&#25968;&#25454;&#19978;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#31561;&#20215;&#20110;&#35299;&#20915;&#19968;&#20010;&#20855;&#26377;&#22266;&#23450;&#29305;&#24449;&#23383;&#20856;&#30697;&#38453;&#30340;&#20984;Lasso&#38382;&#39064;&#65292;&#20026;&#20840;&#23616;&#26368;&#20248;&#32593;&#32476;&#21644;&#35299;&#31354;&#38388;&#25552;&#20379;&#20102;&#27934;&#23519;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;&#22312;1-D&#25968;&#25454;&#19978;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#31561;&#20215;&#20110;&#35299;&#20915;&#19968;&#20010;&#24102;&#26377;&#22266;&#23450;&#12289;&#26126;&#30830;&#23450;&#20041;&#30340;&#29305;&#24449;&#23383;&#20856;&#30697;&#38453;&#30340;&#20984;Lasso&#38382;&#39064;&#12290;&#20855;&#20307;&#30340;&#23383;&#20856;&#21462;&#20915;&#20110;&#28608;&#27963;&#20989;&#25968;&#21644;&#28145;&#24230;&#12290;&#25105;&#20204;&#32771;&#34385;&#20855;&#26377;&#20998;&#27573;&#32447;&#24615;&#28608;&#27963;&#20989;&#25968;&#30340;&#20004;&#23618;&#32593;&#32476;&#65292;&#28145;&#31364;&#30340;ReLU&#32593;&#32476;&#26368;&#22810;&#26377;4&#23618;&#65292;&#20197;&#21450;&#20855;&#26377;&#31526;&#21495;&#28608;&#27963;&#21644;&#20219;&#24847;&#28145;&#24230;&#30340;&#30697;&#24418;&#21644;&#26641;&#32593;&#32476;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#22312;ReLU&#32593;&#32476;&#20013;&#65292;&#31532;&#22235;&#23618;&#21019;&#24314;&#20195;&#34920;&#35757;&#32451;&#25968;&#25454;&#20851;&#20110;&#33258;&#36523;&#30340;&#21453;&#23556;&#30340;&#29305;&#24449;&#12290;Lasso&#34920;&#31034;&#27861;&#25581;&#31034;&#20102;&#20840;&#23616;&#26368;&#20248;&#32593;&#32476;&#21644;&#35299;&#31354;&#38388;&#30340;&#27934;&#23519;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01046v1 Announce Type: cross  Abstract: We prove that training neural networks on 1-D data is equivalent to solving a convex Lasso problem with a fixed, explicitly defined dictionary matrix of features. The specific dictionary depends on the activation and depth. We consider 2-layer networks with piecewise linear activations, deep narrow ReLU networks with up to 4 layers, and rectangular and tree networks with sign activation and arbitrary depth. Interestingly in ReLU networks, a fourth layer creates features that represent reflections of training data about themselves. The Lasso representation sheds insight to globally optimal networks and the solution landscape.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#24102;&#26377;&#25104;&#26412;&#20998;&#24067;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;CABAI&#26041;&#27861;&#20197;&#23454;&#29616;&#26368;&#23567;&#26399;&#26395;&#25104;&#26412;&#19979;&#35782;&#21035;&#20986;&#26368;&#22823;&#22870;&#21169;&#33218;&#65292;&#24182;&#35774;&#35745;&#20102;$\mathsf{CTAS}$&#21644;CO&#20004;&#31181;&#31639;&#27861;&#26469;&#36924;&#36817;&#29702;&#35770;&#19979;&#38480;&#24182;&#20248;&#21270;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.16710</link><description>&lt;p&gt;
&#25104;&#26412;&#24847;&#35782;&#26368;&#20339;&#33218;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Cost Aware Best Arm Identification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16710
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#24102;&#26377;&#25104;&#26412;&#20998;&#24067;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;CABAI&#26041;&#27861;&#20197;&#23454;&#29616;&#26368;&#23567;&#26399;&#26395;&#25104;&#26412;&#19979;&#35782;&#21035;&#20986;&#26368;&#22823;&#22870;&#21169;&#33218;&#65292;&#24182;&#35774;&#35745;&#20102;$\mathsf{CTAS}$&#21644;CO&#20004;&#31181;&#31639;&#27861;&#26469;&#36924;&#36817;&#29702;&#35770;&#19979;&#38480;&#24182;&#20248;&#21270;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#24102;&#26377;&#21452;&#37325;&#23545;&#35937;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#12290;&#38500;&#20102;&#20256;&#32479;&#30340;&#22870;&#21169;&#22806;&#65292;&#27599;&#20010;&#33218;&#36824;&#19982;&#25104;&#26412;&#20998;&#24067;&#30456;&#20851;&#32852;&#65292;&#30446;&#26631;&#26159;&#20351;&#29992;&#26368;&#23567;&#26399;&#26395;&#25104;&#26412;&#35782;&#21035;&#20986;&#26368;&#22823;&#22870;&#21169;&#33218;&#12290;&#25105;&#20204;&#31216;&#20043;&#20026;&#8220;&#25104;&#26412;&#24847;&#35782;&#26368;&#20339;&#33218;&#35782;&#21035;&#8221;&#65288;CABAI&#65289;&#65292;&#23427;&#25429;&#25417;&#20102;&#20135;&#21697;&#24320;&#21457;&#27969;&#31243;&#20013;&#27979;&#35797;&#21644;&#23454;&#26045;&#38454;&#27573;&#20043;&#38388;&#30340;&#20998;&#31163;&#65292;&#24182;&#27169;&#25311;&#20102;&#38454;&#27573;&#20043;&#38388;&#30340;&#30446;&#26631;&#36716;&#21464;&#65292;&#21363;&#27979;&#35797;&#30340;&#25104;&#26412;&#21644;&#23454;&#26045;&#30340;&#22870;&#21169;&#12290;&#25105;&#20204;&#39318;&#20808;&#20026;CABAI&#25512;&#23548;&#20102;&#19968;&#20010;&#29702;&#35770;&#19979;&#38480;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;$\mathsf{CTAS}$&#30340;&#31639;&#27861;&#26469;&#28176;&#36817;&#21305;&#37197;&#23427;&#12290;&#20026;&#20102;&#20943;&#23569;$\mathsf{CTAS}$&#30340;&#35745;&#31639;&#37327;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#24179;&#26041;&#26681;&#35268;&#21017;&#30340;&#20302;&#22797;&#26434;&#24230;&#31639;&#27861;&#31216;&#20026;CO&#65292;&#22312;&#31616;&#21270;&#30340;&#21452;&#33218;&#27169;&#22411;&#20013;&#35777;&#26126;&#20102;&#20854;&#26368;&#20248;&#24615;&#65292;&#24182;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#24778;&#20154;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16710v1 Announce Type: cross  Abstract: In this paper, we study a best arm identification problem with dual objects. In addition to the classic reward, each arm is associated with a cost distribution and the goal is to identify the largest reward arm using the minimum expected cost. We call it \emph{Cost Aware Best Arm Identification} (CABAI), which captures the separation of testing and implementation phases in product development pipelines and models the objective shift between phases, i.e., cost for testing and reward for implementation. We first derive an theoretic lower bound for CABAI and propose an algorithm called $\mathsf{CTAS}$ to match it asymptotically. To reduce the computation of $\mathsf{CTAS}$, we further propose a low-complexity algorithm called CO, based on a square-root rule, which proves optimal in simplified two-armed models and generalizes surprisingly well in numerical experiments. Our results show (i) ignoring the heterogeneous action cost results in 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#22312;&#22343;&#22330;&#26497;&#38480;&#19979;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#35780;&#20272;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#30340;&#27867;&#21270;&#35823;&#24046;&#65292;&#36890;&#36807;&#25512;&#23548;&#20986;&#25910;&#25947;&#36895;&#24230;&#20026;$O(1/n)$&#30340;&#19978;&#30028;&#65292;&#20026;&#25105;&#20204;&#23545;&#32593;&#32476;&#22312;&#26410;&#35265;&#25968;&#25454;&#19978;&#30340;&#24615;&#33021;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2402.07025</link><description>&lt;p&gt;
&#22343;&#22330;&#26497;&#38480;&#19979;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#35823;&#24046;
&lt;/p&gt;
&lt;p&gt;
Generalization Error of Graph Neural Networks in the Mean-field Regime
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07025
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#22312;&#22343;&#22330;&#26497;&#38480;&#19979;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#35780;&#20272;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#30340;&#27867;&#21270;&#35823;&#24046;&#65292;&#36890;&#36807;&#25512;&#23548;&#20986;&#25910;&#25947;&#36895;&#24230;&#20026;$O(1/n)$&#30340;&#19978;&#30028;&#65292;&#20026;&#25105;&#20204;&#23545;&#32593;&#32476;&#22312;&#26410;&#35265;&#25968;&#25454;&#19978;&#30340;&#24615;&#33021;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35813;&#24037;&#20316;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#29992;&#20110;&#35780;&#20272;&#22312;&#36807;&#21442;&#25968;&#21270;&#30340;&#24773;&#20917;&#19979;&#36890;&#36807;&#22270;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#22270;&#20998;&#31867;&#20219;&#21153;&#30340;&#27867;&#21270;&#35823;&#24046;&#65292;&#21363;&#21442;&#25968;&#25968;&#37327;&#36229;&#36807;&#25968;&#25454;&#28857;&#25968;&#37327;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#31867;&#22411;&#65306;&#22270;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#21644;&#28040;&#24687;&#20256;&#36882;&#22270;&#31070;&#32463;&#32593;&#32476;&#12290;&#22312;&#26412;&#30740;&#31350;&#20043;&#21069;&#65292;&#20851;&#20110;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#27867;&#21270;&#35823;&#24046;&#30340;&#29616;&#26377;&#30028;&#38480;&#32570;&#20047;&#20449;&#24687;&#65292;&#38480;&#21046;&#20102;&#25105;&#20204;&#23545;&#36807;&#21442;&#25968;&#21270;&#32593;&#32476;&#24615;&#33021;&#30340;&#29702;&#35299;&#12290;&#25105;&#20204;&#30340;&#21019;&#26032;&#26041;&#27861;&#26159;&#22312;&#22343;&#22330;&#26497;&#38480;&#19979;&#25512;&#23548;&#20986;&#19978;&#30028;&#65292;&#20197;&#35780;&#20272;&#36825;&#20123;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#35823;&#24046;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#20197;$O(1/n)$&#25910;&#25947;&#36895;&#24230;&#30340;&#19978;&#30028;&#65292;&#20854;&#20013;$n$&#26159;&#22270;&#26679;&#26412;&#30340;&#25968;&#37327;&#12290;&#36825;&#20123;&#19978;&#30028;&#20026;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#32593;&#32476;&#22312;&#26410;&#35265;&#25968;&#25454;&#19978;&#30340;&#24615;&#33021;&#25552;&#20379;&#20102;&#29702;&#35770;&#19978;&#30340;&#20445;&#35777;&#65292;&#20174;&#32780;&#23545;&#25105;&#20204;&#30340;&#29702;&#35299;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work provides a theoretical framework for assessing the generalization error of graph classification tasks via graph neural networks in the over-parameterized regime, where the number of parameters surpasses the quantity of data points. We explore two widely utilized types of graph neural networks: graph convolutional neural networks and message passing graph neural networks. Prior to this study, existing bounds on the generalization error in the over-parametrized regime were uninformative, limiting our understanding of over-parameterized network performance. Our novel approach involves deriving upper bounds within the mean-field regime for evaluating the generalization error of these graph neural networks. We establish upper bounds with a convergence rate of $O(1/n)$, where $n$ is the number of graph samples. These upper bounds offer a theoretical assurance of the networks' performance on unseen data in the challenging over-parameterized regime and overall contribute to our under
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#24191;&#20041;&#26631;&#31614;&#36716;&#31227;&#21644;&#24178;&#25200;&#21442;&#25968;&#19979;&#36827;&#34892;&#20998;&#31867;&#30340;&#26032;&#26041;&#27861;&#12290;&#36890;&#36807;&#23558;&#20998;&#31867;&#38382;&#39064;&#35270;&#20026;&#24102;&#26377;&#24178;&#25200;&#21442;&#25968;&#30340;&#20551;&#35774;&#26816;&#39564;&#38382;&#39064;&#65292;&#25105;&#20204;&#33021;&#22815;&#26377;&#25928;&#22320;&#20272;&#35745;&#20998;&#31867;&#22120;&#22312;&#25972;&#20010;&#24178;&#25200;&#21442;&#25968;&#31354;&#38388;&#20013;&#30340;&#25509;&#25910;&#32773;&#25805;&#20316;&#29305;&#24615;&#65292;&#24182;&#35774;&#35745;&#20986;&#22312;&#24191;&#20041;&#26631;&#31614;&#36716;&#31227;&#19979;&#19981;&#21464;&#30340;&#25130;&#26029;&#28857;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#23545;&#20107;&#20214;&#30340;&#21487;&#38752;&#20998;&#31867;&#21644;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#12290;</title><link>https://arxiv.org/abs/2402.05330</link><description>&lt;p&gt;
&#22312;&#26080;&#25311;&#26679;&#20284;&#25512;&#26029;&#30340;&#24178;&#25200;&#21442;&#25968;&#21644;&#24191;&#20041;&#26631;&#31614;&#36716;&#31227;&#19979;&#30340;&#20998;&#31867;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Classification under Nuisance Parameters and Generalized Label Shift in Likelihood-Free Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05330
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#24191;&#20041;&#26631;&#31614;&#36716;&#31227;&#21644;&#24178;&#25200;&#21442;&#25968;&#19979;&#36827;&#34892;&#20998;&#31867;&#30340;&#26032;&#26041;&#27861;&#12290;&#36890;&#36807;&#23558;&#20998;&#31867;&#38382;&#39064;&#35270;&#20026;&#24102;&#26377;&#24178;&#25200;&#21442;&#25968;&#30340;&#20551;&#35774;&#26816;&#39564;&#38382;&#39064;&#65292;&#25105;&#20204;&#33021;&#22815;&#26377;&#25928;&#22320;&#20272;&#35745;&#20998;&#31867;&#22120;&#22312;&#25972;&#20010;&#24178;&#25200;&#21442;&#25968;&#31354;&#38388;&#20013;&#30340;&#25509;&#25910;&#32773;&#25805;&#20316;&#29305;&#24615;&#65292;&#24182;&#35774;&#35745;&#20986;&#22312;&#24191;&#20041;&#26631;&#31614;&#36716;&#31227;&#19979;&#19981;&#21464;&#30340;&#25130;&#26029;&#28857;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#23545;&#20107;&#20214;&#30340;&#21487;&#38752;&#20998;&#31867;&#21644;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25105;&#20204;&#30340;&#35757;&#32451;&#25968;&#25454;&#21644;&#30446;&#26631;&#25968;&#25454;&#20043;&#38388;&#65292;&#26631;&#31614;&#21644;&#28508;&#22312;&#24178;&#25200;&#21442;&#25968;&#30340;&#20998;&#24067;&#19981;&#21516;&#30340;&#24773;&#20917;&#19979;&#65292;&#22914;&#20309;&#20197;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#23545;&#20107;&#20214;&#36827;&#34892;&#20998;&#31867;&#26159;&#19968;&#20010;&#31185;&#23398;&#25361;&#25112;&#12290;&#25105;&#20204;&#23558;&#36825;&#31181;&#20998;&#24067;&#36716;&#31227;&#31216;&#20026;&#24191;&#20041;&#26631;&#31614;&#36716;&#31227; (GLS)&#12290;&#30452;&#25509;&#20351;&#29992;&#35266;&#27979;&#25968;&#25454; $\mathbf{X}$ &#36827;&#34892;&#20998;&#31867;&#20250;&#23548;&#33268;&#39044;&#27979;&#32467;&#26524;&#20559;&#24046;&#21644;&#26631;&#31614; $Y$ &#30340;&#26080;&#25928;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#20998;&#31867;&#38382;&#39064;&#35270;&#20026;&#24102;&#26377;&#24178;&#25200;&#21442;&#25968;&#30340;&#20551;&#35774;&#26816;&#39564;&#38382;&#39064;&#26469;&#20811;&#26381;&#36825;&#20123;&#20559;&#24046;&#12290;&#20851;&#38190;&#24605;&#24819;&#26159;&#22312;&#25972;&#20010;&#24178;&#25200;&#21442;&#25968;&#31354;&#38388;&#20013;&#20272;&#35745;&#20998;&#31867;&#22120;&#30340;&#25509;&#25910;&#32773;&#25805;&#20316;&#29305;&#24615; (ROC)&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#35774;&#35745;&#22312; GLS &#19979;&#19981;&#21464;&#30340;&#25130;&#26029;&#28857;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26377;&#25928;&#22320;&#36171;&#20104;&#39044;&#35757;&#32451;&#30340;&#20998;&#31867;&#22120;&#39046;&#22495;&#36866;&#24212;&#33021;&#21147;&#65292;&#24182;&#36820;&#22238;&#26377;&#25928;&#30340;&#39044;&#27979;&#38598;&#21512;&#65292;&#21516;&#26102;&#20445;&#25345;&#26377;&#25928;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
An open scientific challenge is how to classify events with reliable measures of uncertainty, when we have a mechanistic model of the data-generating process but the distribution over both labels and latent nuisance parameters is different between train and target data. We refer to this type of distributional shift as generalized label shift (GLS). Direct classification using observed data $\mathbf{X}$ as covariates leads to biased predictions and invalid uncertainty estimates of labels $Y$. We overcome these biases by proposing a new method for robust uncertainty quantification that casts classification as a hypothesis testing problem under nuisance parameters. The key idea is to estimate the classifier's receiver operating characteristic (ROC) across the entire nuisance parameter space, which allows us to devise cutoffs that are invariant under GLS. Our method effectively endows a pre-trained classifier with domain adaptation capabilities and returns valid prediction sets while maint
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#23398;&#20064;&#22810;&#25351;&#25968;&#30446;&#26631;&#20989;&#25968;&#26102;&#65292;&#37325;&#22797;&#20351;&#29992;&#25209;&#27425;&#30340;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#30340;&#35757;&#32451;&#21160;&#24577;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#19982;&#21333;&#27425;GD&#30456;&#27604;&#65292;&#22810;&#27425;GD&#33021;&#22815;&#20811;&#26381;&#30446;&#26631;&#20989;&#25968;&#30340;&#38480;&#21046;&#65292;&#20165;&#38656;&#20004;&#20010;&#26102;&#38388;&#27493;&#39588;&#23601;&#33021;&#23454;&#29616;&#32593;&#32476;&#19982;&#30446;&#26631;&#23376;&#31354;&#38388;&#30340;&#37325;&#21472;&#65292;&#23637;&#31034;&#20102;&#22312;&#26377;&#38480;&#26102;&#38388;&#20869;&#26377;&#25928;&#23398;&#20064;&#30340;&#24191;&#27867;&#20989;&#25968;&#31867;&#12290;&#36825;&#20123;&#32467;&#26524;&#22522;&#20110;&#21160;&#21147;&#24179;&#22343;&#22330;&#29702;&#35770;&#65288;DMFT&#65289;&#30340;&#20998;&#26512;&#12290;</title><link>https://arxiv.org/abs/2402.03220</link><description>&lt;p&gt;
&#37325;&#22797;&#20351;&#29992;&#25209;&#27425;&#22312;&#20004;&#23618;&#32593;&#32476;&#30340;&#26799;&#24230;&#19979;&#38477;&#20013;&#30340;&#22909;&#22788;&#65306;&#25171;&#30772;&#20449;&#24687;&#21644;&#36339;&#36291;&#25351;&#25968;&#30340;&#35781;&#21650;
&lt;/p&gt;
&lt;p&gt;
The Benefits of Reusing Batches for Gradient Descent in Two-Layer Networks: Breaking the Curse of Information and Leap Exponents
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03220
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#23398;&#20064;&#22810;&#25351;&#25968;&#30446;&#26631;&#20989;&#25968;&#26102;&#65292;&#37325;&#22797;&#20351;&#29992;&#25209;&#27425;&#30340;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#30340;&#35757;&#32451;&#21160;&#24577;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#19982;&#21333;&#27425;GD&#30456;&#27604;&#65292;&#22810;&#27425;GD&#33021;&#22815;&#20811;&#26381;&#30446;&#26631;&#20989;&#25968;&#30340;&#38480;&#21046;&#65292;&#20165;&#38656;&#20004;&#20010;&#26102;&#38388;&#27493;&#39588;&#23601;&#33021;&#23454;&#29616;&#32593;&#32476;&#19982;&#30446;&#26631;&#23376;&#31354;&#38388;&#30340;&#37325;&#21472;&#65292;&#23637;&#31034;&#20102;&#22312;&#26377;&#38480;&#26102;&#38388;&#20869;&#26377;&#25928;&#23398;&#20064;&#30340;&#24191;&#27867;&#20989;&#25968;&#31867;&#12290;&#36825;&#20123;&#32467;&#26524;&#22522;&#20110;&#21160;&#21147;&#24179;&#22343;&#22330;&#29702;&#35770;&#65288;DMFT&#65289;&#30340;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#23398;&#20064;&#22810;&#25351;&#25968;&#30446;&#26631;&#20989;&#25968;&#26102;&#65292;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#21160;&#24577;&#12290;&#25105;&#20204;&#20851;&#27880;&#37325;&#22797;&#22810;&#27425;&#20351;&#29992;&#25209;&#27425;&#30340;&#22810;&#27425;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#65292;&#24182;&#23637;&#31034;&#23427;&#19982;&#21333;&#27425;&#26799;&#24230;&#19979;&#38477;&#30456;&#27604;&#65292;&#26174;&#33879;&#25913;&#21464;&#20102;&#23545;&#20110;&#21738;&#20123;&#20989;&#25968;&#26159;&#21487;&#23398;&#20064;&#30340;&#30340;&#32467;&#35770;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#21457;&#29616;&#20855;&#26377;&#26377;&#38480;&#27493;&#38271;&#30340;&#22810;&#27425;GD&#33021;&#22815;&#20811;&#26381;&#30446;&#26631;&#20989;&#25968;&#30340;&#20449;&#24687;&#25351;&#25968;&#65288;Ben Arous&#31561;&#20154;&#65292;2021&#65289;&#21644;&#36339;&#36291;&#25351;&#25968;&#65288;Abbe&#31561;&#20154;&#65292;2023&#65289;&#25152;&#32473;&#20986;&#30340;&#26799;&#24230;&#27969;&#21644;&#21333;&#27425;GD&#30340;&#38480;&#21046;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#36890;&#36807;&#37325;&#22797;&#20351;&#29992;&#25209;&#27425;&#65292;&#32593;&#32476;&#20165;&#38656;&#20004;&#20010;&#26102;&#38388;&#27493;&#39588;&#23601;&#33021;&#19982;&#30446;&#26631;&#23376;&#31354;&#38388;&#36798;&#25104;&#37325;&#21472;&#65292;&#21363;&#20351;&#20989;&#25968;&#19981;&#28385;&#36275;&#38454;&#26799;&#24615;&#36136;&#65288;Abbe&#31561;&#20154;&#65292;2021&#65289;&#12290;&#25105;&#20204;&#23545;&#33021;&#22815;&#22312;&#26377;&#38480;&#26102;&#38388;&#20869;&#26377;&#25928;&#23398;&#20064;&#30340;&#65288;&#24191;&#27867;&#30340;&#65289;&#20989;&#25968;&#31867;&#36827;&#34892;&#20102;&#34920;&#24449;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#35777;&#26126;&#22522;&#20110;&#21160;&#21147;&#24179;&#22343;&#22330;&#29702;&#35770;&#65288;DMFT&#65289;&#30340;&#20998;&#26512;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20379;&#20102;&#21160;&#24577;&#30340;&#38381;&#24335;&#25551;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the training dynamics of two-layer neural networks when learning multi-index target functions. We focus on multi-pass gradient descent (GD) that reuses the batches multiple times and show that it significantly changes the conclusion about which functions are learnable compared to single-pass gradient descent. In particular, multi-pass GD with finite stepsize is found to overcome the limitations of gradient flow and single-pass GD given by the information exponent (Ben Arous et al., 2021) and leap exponent (Abbe et al., 2023) of the target function. We show that upon re-using batches, the network achieves in just two time steps an overlap with the target subspace even for functions not satisfying the staircase property (Abbe et al., 2021). We characterize the (broad) class of functions efficiently learned in finite time. The proof of our results is based on the analysis of the Dynamical Mean-Field Theory (DMFT). We further provide a closed-form description of the dynamica
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#28789;&#27963;&#30340;&#36125;&#21494;&#26031;g&#24418;&#24335;&#20272;&#35745;&#22120;&#65292;&#29992;&#20110;&#20855;&#26377;&#26102;&#21464;&#28151;&#26434;&#30340;&#22240;&#26524;&#29983;&#23384;&#20998;&#26512;&#12290;&#23427;&#37319;&#29992;&#36125;&#21494;&#26031;&#38468;&#21152;&#22238;&#24402;&#26641;&#26469;&#27169;&#25311;&#26102;&#21464;&#29983;&#25104;&#32452;&#20214;&#65292;&#24182;&#24341;&#20837;&#20102;&#32437;&#21521;&#24179;&#34913;&#20998;&#25968;&#20197;&#38477;&#20302;&#27169;&#22411;&#38169;&#35823;&#35268;&#33539;&#24341;&#36215;&#30340;&#20559;&#24046;&#12290;</title><link>https://arxiv.org/abs/2402.02306</link><description>&lt;p&gt;
&#24377;&#24615;&#36125;&#21494;&#26031;g&#24418;&#24335;&#22312;&#20855;&#26377;&#26102;&#21464;&#28151;&#26434;&#30340;&#22240;&#26524;&#29983;&#23384;&#20998;&#26512;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
A flexible Bayesian g-formula for causal survival analyses with time-dependent confounding
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02306
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#28789;&#27963;&#30340;&#36125;&#21494;&#26031;g&#24418;&#24335;&#20272;&#35745;&#22120;&#65292;&#29992;&#20110;&#20855;&#26377;&#26102;&#21464;&#28151;&#26434;&#30340;&#22240;&#26524;&#29983;&#23384;&#20998;&#26512;&#12290;&#23427;&#37319;&#29992;&#36125;&#21494;&#26031;&#38468;&#21152;&#22238;&#24402;&#26641;&#26469;&#27169;&#25311;&#26102;&#21464;&#29983;&#25104;&#32452;&#20214;&#65292;&#24182;&#24341;&#20837;&#20102;&#32437;&#21521;&#24179;&#34913;&#20998;&#25968;&#20197;&#38477;&#20302;&#27169;&#22411;&#38169;&#35823;&#35268;&#33539;&#24341;&#36215;&#30340;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20855;&#26377;&#26102;&#38388;&#33267;&#20107;&#20214;&#32467;&#26524;&#30340;&#32437;&#21521;&#35266;&#23519;&#24615;&#30740;&#31350;&#20013;&#65292;&#22240;&#26524;&#20998;&#26512;&#30340;&#24120;&#35265;&#30446;&#26631;&#26159;&#22312;&#30740;&#31350;&#32676;&#20307;&#20013;&#20272;&#35745;&#22312;&#20551;&#35774;&#24178;&#39044;&#24773;&#26223;&#19979;&#30340;&#22240;&#26524;&#29983;&#23384;&#26354;&#32447;&#12290;g&#24418;&#24335;&#26159;&#36825;&#31181;&#20998;&#26512;&#30340;&#19968;&#20010;&#29305;&#21035;&#26377;&#29992;&#30340;&#24037;&#20855;&#12290;&#20026;&#20102;&#22686;&#24378;&#20256;&#32479;&#30340;&#21442;&#25968;&#21270;g&#24418;&#24335;&#26041;&#27861;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26356;&#28789;&#27963;&#30340;&#36125;&#21494;&#26031;g&#24418;&#24335;&#20272;&#35745;&#22120;&#12290;&#35813;&#20272;&#35745;&#22120;&#21516;&#26102;&#25903;&#25345;&#32437;&#21521;&#39044;&#27979;&#21644;&#22240;&#26524;&#25512;&#26029;&#12290;&#23427;&#22312;&#27169;&#25311;&#26102;&#21464;&#29983;&#25104;&#32452;&#20214;&#30340;&#24314;&#27169;&#20013;&#24341;&#20837;&#20102;&#36125;&#21494;&#26031;&#38468;&#21152;&#22238;&#24402;&#26641;&#65292;&#26088;&#22312;&#20943;&#36731;&#30001;&#20110;&#27169;&#22411;&#38169;&#35823;&#35268;&#33539;&#36896;&#25104;&#30340;&#20559;&#24046;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31867;&#26356;&#36890;&#29992;&#30340;&#31163;&#25955;&#29983;&#23384;&#25968;&#25454;g&#24418;&#24335;&#12290;&#36825;&#20123;&#20844;&#24335;&#21487;&#20197;&#24341;&#20837;&#32437;&#21521;&#24179;&#34913;&#20998;&#25968;&#65292;&#36825;&#22312;&#22788;&#29702;&#36234;&#26469;&#36234;&#22810;&#30340;&#26102;&#21464;&#28151;&#26434;&#22240;&#32032;&#26102;&#26159;&#19968;&#31181;&#26377;&#25928;&#30340;&#38477;&#32500;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In longitudinal observational studies with a time-to-event outcome, a common objective in causal analysis is to estimate the causal survival curve under hypothetical intervention scenarios within the study cohort. The g-formula is a particularly useful tool for this analysis. To enhance the traditional parametric g-formula approach, we developed a more adaptable Bayesian g-formula estimator. This estimator facilitates both longitudinal predictive and causal inference. It incorporates Bayesian additive regression trees in the modeling of the time-evolving generative components, aiming to mitigate bias due to model misspecification. Specifically, we introduce a more general class of g-formulas for discrete survival data. These formulas can incorporate the longitudinal balancing scores, which serve as an effective method for dimension reduction and are vital when dealing with an expanding array of time-varying confounders. The minimum sufficient formulation of these longitudinal balancing
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#38754;&#26495;&#25968;&#25454;&#20013;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#30340;&#31616;&#21333;&#19988;&#26368;&#20339;&#21270;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#31616;&#21333;&#30340;&#30697;&#38453;&#20195;&#25968;&#21644;&#22855;&#24322;&#20540;&#20998;&#35299;&#26469;&#23454;&#29616;&#39640;&#25928;&#35745;&#31639;&#12290;&#36890;&#36807;&#23548;&#20986;&#38750;&#28176;&#36817;&#30028;&#38480;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36880;&#39033;&#35823;&#24046;&#19982;&#39640;&#26031;&#21464;&#37327;&#30340;&#36866;&#24403;&#32553;&#25918;&#20855;&#26377;&#25509;&#36817;&#24615;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#20010;&#25968;&#25454;&#39537;&#21160;&#31243;&#24207;&#65292;&#29992;&#20110;&#26500;&#24314;&#20855;&#26377;&#39044;&#20808;&#25351;&#23450;&#35206;&#30422;&#20445;&#35777;&#30340;&#36880;&#39033;&#32622;&#20449;&#21306;&#38388;&#12290;</title><link>http://arxiv.org/abs/2401.13665</link><description>&lt;p&gt;
&#12298;&#38754;&#26495;&#25968;&#25454;&#22240;&#26524;&#25512;&#26029;&#30340;&#36880;&#39033;&#25512;&#29702;&#26041;&#27861;&#65306;&#19968;&#31181;&#31616;&#21333;&#19988;&#26368;&#20339;&#21270;&#30340;&#26041;&#27861;&#12299;
&lt;/p&gt;
&lt;p&gt;
Entrywise Inference for Causal Panel Data: A Simple and Instance-Optimal Approach. (arXiv:2401.13665v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13665
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#38754;&#26495;&#25968;&#25454;&#20013;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#30340;&#31616;&#21333;&#19988;&#26368;&#20339;&#21270;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#31616;&#21333;&#30340;&#30697;&#38453;&#20195;&#25968;&#21644;&#22855;&#24322;&#20540;&#20998;&#35299;&#26469;&#23454;&#29616;&#39640;&#25928;&#35745;&#31639;&#12290;&#36890;&#36807;&#23548;&#20986;&#38750;&#28176;&#36817;&#30028;&#38480;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36880;&#39033;&#35823;&#24046;&#19982;&#39640;&#26031;&#21464;&#37327;&#30340;&#36866;&#24403;&#32553;&#25918;&#20855;&#26377;&#25509;&#36817;&#24615;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#20010;&#25968;&#25454;&#39537;&#21160;&#31243;&#24207;&#65292;&#29992;&#20110;&#26500;&#24314;&#20855;&#26377;&#39044;&#20808;&#25351;&#23450;&#35206;&#30422;&#20445;&#35777;&#30340;&#36880;&#39033;&#32622;&#20449;&#21306;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20998;&#38454;&#27573;&#37319;&#29992;&#30340;&#38754;&#26495;&#25968;&#25454;&#20013;&#30340;&#22240;&#26524;&#25512;&#26029;&#20013;&#65292;&#30446;&#26631;&#26159;&#20272;&#35745;&#21644;&#25512;&#23548;&#20986;&#28508;&#22312;&#32467;&#26524;&#21644;&#22788;&#29702;&#25928;&#24212;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#31243;&#24207;&#65292;&#20165;&#28041;&#21450;&#31616;&#21333;&#30340;&#30697;&#38453;&#20195;&#25968;&#21644;&#22855;&#24322;&#20540;&#20998;&#35299;&#12290;&#25105;&#20204;&#23548;&#20986;&#20102;&#36880;&#39033;&#35823;&#24046;&#30340;&#38750;&#28176;&#36817;&#30028;&#38480;&#65292;&#35777;&#26126;&#20854;&#25509;&#36817;&#20110;&#36866;&#24403;&#32553;&#25918;&#30340;&#39640;&#26031;&#21464;&#37327;&#12290;&#23613;&#31649;&#25105;&#20204;&#30340;&#31243;&#24207;&#31616;&#21333;&#65292;&#20294;&#21364;&#26159;&#23616;&#37096;&#26368;&#20339;&#21270;&#30340;&#65292;&#22240;&#20026;&#25105;&#20204;&#30340;&#29702;&#35770;&#32553;&#25918;&#19982;&#36890;&#36807;&#36125;&#21494;&#26031;Cram\'{e}r-Rao&#35770;&#35777;&#24471;&#20986;&#30340;&#23616;&#37096;&#23454;&#20363;&#19979;&#30028;&#30456;&#21305;&#37197;&#12290;&#21033;&#29992;&#25105;&#20204;&#30340;&#35265;&#35299;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#31243;&#24207;&#65292;&#29992;&#20110;&#26500;&#24314;&#20855;&#26377;&#39044;&#20808;&#25351;&#23450;&#35206;&#30422;&#20445;&#35777;&#30340;&#36880;&#39033;&#32622;&#20449;&#21306;&#38388;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#22522;&#20110;&#23545;&#30697;&#38453;&#21435;&#22122;&#27169;&#22411;&#24212;&#29992;SVD&#31639;&#27861;&#30340;&#19968;&#33324;&#25512;&#29702;&#24037;&#20855;&#31665;&#65292;&#36825;&#21487;&#33021;&#20855;&#26377;&#29420;&#31435;&#30340;&#20852;&#36259;&#12290;
&lt;/p&gt;
&lt;p&gt;
In causal inference with panel data under staggered adoption, the goal is to estimate and derive confidence intervals for potential outcomes and treatment effects. We propose a computationally efficient procedure, involving only simple matrix algebra and singular value decomposition. We derive non-asymptotic bounds on the entrywise error, establishing its proximity to a suitably scaled Gaussian variable. Despite its simplicity, our procedure turns out to be instance-optimal, in that our theoretical scaling matches a local instance-wise lower bound derived via a Bayesian Cram\'{e}r-Rao argument. Using our insights, we develop a data-driven procedure for constructing entrywise confidence intervals with pre-specified coverage guarantees. Our analysis is based on a general inferential toolbox for the SVD algorithm applied to the matrix denoising model, which might be of independent interest.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#32858;&#31867;&#21487;&#20998;&#31163;&#24615;&#24230;&#37327;&#26041;&#27861;&#65292;&#26088;&#22312;&#37327;&#21270;&#31867;&#38388;&#20998;&#31163;&#21644;&#31867;&#20869;&#36830;&#36890;&#24615;&#65292;&#23545;&#20110;&#23494;&#24230;&#32858;&#31867;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2310.12806</link><description>&lt;p&gt;
DCSI -- &#22522;&#20110;&#20998;&#31163;&#21644;&#36830;&#36890;&#24615;&#30340;&#25913;&#36827;&#30340;&#32858;&#31867;&#21487;&#20998;&#31163;&#24615;&#24230;&#37327;
&lt;/p&gt;
&lt;p&gt;
DCSI -- An improved measure of cluster separability based on separation and connectedness. (arXiv:2310.12806v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12806
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#32858;&#31867;&#21487;&#20998;&#31163;&#24615;&#24230;&#37327;&#26041;&#27861;&#65292;&#26088;&#22312;&#37327;&#21270;&#31867;&#38388;&#20998;&#31163;&#21644;&#31867;&#20869;&#36830;&#36890;&#24615;&#65292;&#23545;&#20110;&#23494;&#24230;&#32858;&#31867;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30830;&#23450;&#32473;&#23450;&#25968;&#25454;&#38598;&#20013;&#30340;&#31867;&#21035;&#26631;&#31614;&#26159;&#21542;&#23545;&#24212;&#20110;&#26377;&#24847;&#20041;&#30340;&#32858;&#31867;&#23545;&#20110;&#20351;&#29992;&#30495;&#23454;&#25968;&#25454;&#38598;&#35780;&#20272;&#32858;&#31867;&#31639;&#27861;&#33267;&#20851;&#37325;&#35201;&#12290;&#36825;&#20010;&#29305;&#24615;&#21487;&#20197;&#36890;&#36807;&#21487;&#20998;&#31163;&#24615;&#24230;&#37327;&#26469;&#37327;&#21270;&#12290;&#29616;&#26377;&#25991;&#29486;&#30340;&#32508;&#36848;&#26174;&#31034;&#65292;&#26082;&#26377;&#30340;&#22522;&#20110;&#20998;&#31867;&#30340;&#22797;&#26434;&#24615;&#24230;&#37327;&#26041;&#27861;&#21644;&#32858;&#31867;&#26377;&#25928;&#24615;&#25351;&#26631; (CVIs) &#37117;&#27809;&#26377;&#20805;&#20998;&#34701;&#20837;&#22522;&#20110;&#23494;&#24230;&#30340;&#32858;&#31867;&#30340;&#26680;&#24515;&#29305;&#24449;&#65306;&#31867;&#38388;&#20998;&#31163;&#21644;&#31867;&#20869;&#36830;&#36890;&#24615;&#12290;&#19968;&#31181;&#26032;&#24320;&#21457;&#30340;&#24230;&#37327;&#26041;&#27861; (&#23494;&#24230;&#32858;&#31867;&#21487;&#20998;&#31163;&#24615;&#25351;&#25968;, DCSI) &#26088;&#22312;&#37327;&#21270;&#36825;&#20004;&#20010;&#29305;&#24449;&#65292;&#24182;&#19988;&#20063;&#21487;&#29992;&#20316; CVI&#12290;&#23545;&#21512;&#25104;&#25968;&#25454;&#30340;&#24191;&#27867;&#23454;&#39564;&#34920;&#26126;&#65292;DCSI &#19982;&#36890;&#36807;&#35843;&#25972;&#20848;&#24503;&#25351;&#25968; (ARI) &#27979;&#37327;&#30340;DBSCAN&#30340;&#24615;&#33021;&#20043;&#38388;&#26377;&#24456;&#24378;&#30340;&#30456;&#20851;&#24615;&#65292;&#20294;&#22312;&#23545;&#22810;&#31867;&#25968;&#25454;&#38598;&#36827;&#34892;&#23494;&#24230;&#32858;&#31867;&#19981;&#36866;&#24403;&#30340;&#37325;&#21472;&#31867;&#21035;&#26102;&#32570;&#20047;&#40065;&#26834;&#24615;&#12290;&#23545;&#32463;&#24120;&#20351;&#29992;&#30340;&#30495;&#23454;&#25968;&#25454;&#38598;&#36827;&#34892;&#35814;&#32454;&#35780;&#20272;&#26174;&#31034;&#65292;DCSI &#33021;&#22815;&#26356;&#22909;&#22320;&#21306;&#20998;&#23494;&#24230;&#32858;&#31867;&#30340;&#21487;&#20998;&#31163;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Whether class labels in a given data set correspond to meaningful clusters is crucial for the evaluation of clustering algorithms using real-world data sets. This property can be quantified by separability measures. A review of the existing literature shows that neither classification-based complexity measures nor cluster validity indices (CVIs) adequately incorporate the central aspects of separability for density-based clustering: between-class separation and within-class connectedness. A newly developed measure (density cluster separability index, DCSI) aims to quantify these two characteristics and can also be used as a CVI. Extensive experiments on synthetic data indicate that DCSI correlates strongly with the performance of DBSCAN measured via the adjusted rand index (ARI) but lacks robustness when it comes to multi-class data sets with overlapping classes that are ill-suited for density-based hard clustering. Detailed evaluation on frequently used real-world data sets shows that
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#19978;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#20146;&#21644;&#24230;&#35780;&#20998;&#36861;&#36394;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#38750;&#32447;&#24615;&#20256;&#25773;&#65292;&#23588;&#20854;&#20851;&#27880;&#35745;&#31639;&#26426;&#35270;&#35273;&#24212;&#29992;&#12290;&#23454;&#39564;&#35777;&#23454;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#21644;&#23545;&#24191;&#27867;&#24212;&#29992;&#30340;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.11439</link><description>&lt;p&gt;
&#36890;&#36807;&#38750;&#32447;&#24615;&#30740;&#31350;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Understanding deep neural networks through the lens of their non-linearity. (arXiv:2310.11439v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11439
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#19978;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#20146;&#21644;&#24230;&#35780;&#20998;&#36861;&#36394;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#38750;&#32447;&#24615;&#20256;&#25773;&#65292;&#23588;&#20854;&#20851;&#27880;&#35745;&#31639;&#26426;&#35270;&#35273;&#24212;&#29992;&#12290;&#23454;&#39564;&#35777;&#23454;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#21644;&#23545;&#24191;&#27867;&#24212;&#29992;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNN)&#30340;&#26174;&#33879;&#25104;&#21151;&#24120;&#24120;&#24402;&#22240;&#20110;&#23427;&#20204;&#30340;&#39640;&#34920;&#36798;&#33021;&#21147;&#21644;&#36817;&#20284;&#20219;&#24847;&#22797;&#26434;&#20989;&#25968;&#30340;&#33021;&#21147;&#12290;&#20107;&#23454;&#19978;&#65292;DNN&#26159;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#27169;&#22411;&#65292;&#20854;&#20013;&#24341;&#20837;&#30340;&#28608;&#27963;&#20989;&#25968;&#22312;&#20854;&#20013;&#36215;&#21040;&#20102;&#37325;&#35201;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#35768;&#22810;&#30740;&#31350;&#36890;&#36807;&#36817;&#20284;&#33021;&#21147;&#30340;&#35270;&#35282;&#30740;&#31350;&#20102;DNN&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#20294;&#37327;&#21270;DNN&#25110;&#20010;&#21035;&#28608;&#27963;&#20989;&#25968;&#30340;&#38750;&#32447;&#24615;&#20173;&#28982;&#26159;&#19968;&#20010;&#24320;&#25918;&#24615;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#22312;&#20855;&#20307;&#20851;&#27880;&#35745;&#31639;&#26426;&#35270;&#35273;&#24212;&#29992;&#20013;&#36861;&#36394;&#38750;&#32447;&#24615;&#20256;&#25773;&#30340;&#29702;&#35770;&#26377;&#25928;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#20146;&#21644;&#24230;&#35780;&#20998;&#20801;&#35768;&#25105;&#20204;&#28145;&#20837;&#20102;&#35299;&#21508;&#31181;&#19981;&#21516;&#20307;&#31995;&#32467;&#26500;&#21644;&#23398;&#20064;&#33539;&#24335;&#30340;&#20869;&#37096;&#24037;&#20316;&#21407;&#29702;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#22823;&#37327;&#30340;&#23454;&#39564;&#32467;&#26524;&#65292;&#31361;&#20986;&#20102;&#25152;&#25552;&#20986;&#30340;&#20146;&#21644;&#24230;&#35780;&#20998;&#30340;&#23454;&#38469;&#25928;&#29992;&#21644;&#28508;&#22312;&#24212;&#29992;&#30340;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The remarkable success of deep neural networks (DNN) is often attributed to their high expressive power and their ability to approximate functions of arbitrary complexity. Indeed, DNNs are highly non-linear models, and activation functions introduced into them are largely responsible for this. While many works studied the expressive power of DNNs through the lens of their approximation capabilities, quantifying the non-linearity of DNNs or of individual activation functions remains an open problem. In this paper, we propose the first theoretically sound solution to track non-linearity propagation in deep neural networks with a specific focus on computer vision applications. Our proposed affinity score allows us to gain insights into the inner workings of a wide range of different architectures and learning paradigms. We provide extensive experimental results that highlight the practical utility of the proposed affinity score and its potential for long-reaching applications.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20223;&#23556;&#19981;&#21464;&#38598;&#25104;&#21464;&#25442;&#26041;&#27861;&#65292;&#21487;&#20197;&#25913;&#21892;&#22312;ReLU&#32593;&#32476;&#20013;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#12290;&#36890;&#36807;&#22522;&#20110;&#38598;&#21512;&#21345;&#23572;&#26364;&#28388;&#27874;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;&#30456;&#20114;&#20316;&#29992;&#30340;&#31890;&#23376;&#31995;&#32479;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#25910;&#25947;&#24615;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#25506;&#35752;&#20102;&#36825;&#20123;&#26041;&#27861;&#29992;&#20110;&#37327;&#21270;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.04742</link><description>&lt;p&gt;
&#25913;&#36827;ReLU&#32593;&#32476;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#20223;&#23556;&#19981;&#21464;&#38598;&#25104;&#21464;&#25442;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Affine Invariant Ensemble Transform Methods to Improve Predictive Uncertainty in ReLU Networks. (arXiv:2309.04742v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.04742
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20223;&#23556;&#19981;&#21464;&#38598;&#25104;&#21464;&#25442;&#26041;&#27861;&#65292;&#21487;&#20197;&#25913;&#21892;&#22312;ReLU&#32593;&#32476;&#20013;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#12290;&#36890;&#36807;&#22522;&#20110;&#38598;&#21512;&#21345;&#23572;&#26364;&#28388;&#27874;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;&#30456;&#20114;&#20316;&#29992;&#30340;&#31890;&#23376;&#31995;&#32479;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#25910;&#25947;&#24615;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#25506;&#35752;&#20102;&#36825;&#20123;&#26041;&#27861;&#29992;&#20110;&#37327;&#21270;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#21512;&#36866;&#30340;&#38598;&#21512;&#21345;&#23572;&#26364;&#28388;&#27874;&#30340;&#25193;&#23637;&#36827;&#34892;&#36923;&#36753;&#22238;&#24402;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;&#30456;&#20114;&#20316;&#29992;&#30340;&#31890;&#23376;&#31995;&#32479;&#65292;&#20174;&#36817;&#20284;&#21518;&#39564;&#20998;&#24067;&#20013;&#37319;&#26679;&#65292;&#24182;&#35777;&#26126;&#24403;&#31890;&#23376;&#25968;&#37327;&#36235;&#20110;&#26080;&#31351;&#26102;&#65292;&#36825;&#20123;&#30456;&#20114;&#20316;&#29992;&#31890;&#23376;&#31995;&#32479;&#25910;&#25947;&#21040;&#22343;&#22330;&#26497;&#38480;&#30340;&#37327;&#21270;&#25910;&#25947;&#36895;&#29575;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24212;&#29992;&#36825;&#20123;&#25216;&#26415;&#24182;&#32771;&#23519;&#23427;&#20204;&#20316;&#20026;&#36125;&#21494;&#26031;&#36817;&#20284;&#26041;&#27861;&#22312;ReLU&#32593;&#32476;&#20013;&#37327;&#21270;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of performing Bayesian inference for logistic regression using appropriate extensions of the ensemble Kalman filter. Two interacting particle systems are proposed that sample from an approximate posterior and prove quantitative convergence rates of these interacting particle systems to their mean-field limit as the number of particles tends to infinity. Furthermore, we apply these techniques and examine their effectiveness as methods of Bayesian approximation for quantifying predictive uncertainty in ReLU networks.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20004;&#37096;&#20998;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35782;&#21035;&#21644;&#25551;&#36848;A/B&#27979;&#35797;&#20013;&#30340;&#32593;&#32476;&#24178;&#25200;&#12290;&#36890;&#36807;&#32771;&#34385;&#28508;&#22312;&#30340;&#22797;&#26434;&#32593;&#32476;&#32467;&#26500;&#21644;&#24314;&#31435;&#36866;&#21512;&#30340;&#26333;&#20809;&#26144;&#23556;&#65292;&#35813;&#26041;&#27861;&#22312;&#21512;&#25104;&#23454;&#39564;&#21644;&#30495;&#23454;&#22823;&#35268;&#27169;&#27979;&#35797;&#20013;&#30340;&#27169;&#25311;&#20013;&#34920;&#29616;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2308.09790</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#25551;&#36848;A/B&#27979;&#35797;&#20013;&#32593;&#32476;&#24178;&#25200;&#30340;&#20004;&#37096;&#20998;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Two-Part Machine Learning Approach to Characterizing Network Interference in A/B Testing. (arXiv:2308.09790v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09790
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20004;&#37096;&#20998;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35782;&#21035;&#21644;&#25551;&#36848;A/B&#27979;&#35797;&#20013;&#30340;&#32593;&#32476;&#24178;&#25200;&#12290;&#36890;&#36807;&#32771;&#34385;&#28508;&#22312;&#30340;&#22797;&#26434;&#32593;&#32476;&#32467;&#26500;&#21644;&#24314;&#31435;&#36866;&#21512;&#30340;&#26333;&#20809;&#26144;&#23556;&#65292;&#35813;&#26041;&#27861;&#22312;&#21512;&#25104;&#23454;&#39564;&#21644;&#30495;&#23454;&#22823;&#35268;&#27169;&#27979;&#35797;&#20013;&#30340;&#27169;&#25311;&#20013;&#34920;&#29616;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#32593;&#32476;&#24178;&#25200;&#29616;&#35937;&#30340;&#24433;&#21709;&#65292;&#25511;&#21046;&#23454;&#39564;&#25110;"A/B&#27979;&#35797;"&#30340;&#21487;&#38752;&#24615;&#36890;&#24120;&#20250;&#21463;&#21040;&#25439;&#23475;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#26041;&#27861;&#26469;&#35782;&#21035;&#21644;&#25551;&#36848;&#24322;&#36136;&#32593;&#32476;&#24178;&#25200;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#32771;&#34385;&#20102;&#28508;&#22312;&#30340;&#22797;&#26434;&#32593;&#32476;&#32467;&#26500;&#65292;&#24182;&#33258;&#21160;&#21270;&#20102;"&#26333;&#20809;&#26144;&#23556;"&#30830;&#23450;&#30340;&#20219;&#21153;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#29616;&#26377;&#25991;&#29486;&#20013;&#30340;&#20004;&#20010;&#20027;&#35201;&#38480;&#21046;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;"&#22240;&#26524;&#32593;&#32476;&#27169;&#24335;"&#65292;&#24182;&#37319;&#29992;&#36879;&#26126;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26469;&#24314;&#31435;&#26368;&#36866;&#21512;&#21453;&#26144;&#28508;&#22312;&#32593;&#32476;&#24178;&#25200;&#27169;&#24335;&#30340;&#26333;&#20809;&#26144;&#23556;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#22312;&#20004;&#20010;&#21512;&#25104;&#23454;&#39564;&#21644;&#19968;&#20010;&#28041;&#21450;100-200&#19975;Instagram&#29992;&#25143;&#30340;&#30495;&#23454;&#22823;&#35268;&#27169;&#27979;&#35797;&#20013;&#30340;&#27169;&#25311;&#24471;&#21040;&#20102;&#39564;&#35777;&#65292;&#34920;&#29616;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#65292;&#22914;&#22522;&#20110;&#35774;&#35745;&#30340;&#38598;&#32676;&#38543;&#26426;&#21270;&#21644;&#22522;&#20110;&#20998;&#26512;&#30340;&#37051;&#22495;&#26333;&#20809;&#26144;&#23556;&#12290;
&lt;/p&gt;
&lt;p&gt;
The reliability of controlled experiments, or "A/B tests," can often be compromised due to the phenomenon of network interference, wherein the outcome for one unit is influenced by other units. To tackle this challenge, we propose a machine learning-based method to identify and characterize heterogeneous network interference. Our approach accounts for latent complex network structures and automates the task of "exposure mapping'' determination, which addresses the two major limitations in the existing literature. We introduce "causal network motifs'' and employ transparent machine learning models to establish the most suitable exposure mapping that reflects underlying network interference patterns. Our method's efficacy has been validated through simulations on two synthetic experiments and a real-world, large-scale test involving 1-2 million Instagram users, outperforming conventional methods such as design-based cluster randomization and analysis-based neighborhood exposure mapping. 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#20840;&#23616;&#25928;&#24212;&#24191;&#20041;&#21487;&#21152;&#20998;&#35299;&#65288;GADGET&#65289;&#26694;&#26550;&#65292;&#33021;&#22815;&#26368;&#23567;&#21270;&#29305;&#24449;&#20132;&#20114;&#20316;&#29992;&#30340;&#26412;&#22320;&#29305;&#24449;&#25928;&#24212;&#30340;&#20132;&#20114;&#24322;&#36136;&#24615;&#12290;&#21516;&#26102;&#36866;&#29992;&#20110;&#20559;&#20381;&#36182;&#12289;&#31215;&#32047;&#23616;&#37096;&#25928;&#24212;&#21644;Shapley&#21487;&#21152;&#35299;&#37322;&#65288;SHAP&#65289;&#20381;&#36182;&#30340;&#36793;&#38469;&#29305;&#24449;&#25928;&#24212;&#21487;&#35270;&#21270;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#32622;&#25442;&#30340;&#20132;&#20114;&#27979;&#35797;&#26469;&#26816;&#27979;&#26174;&#30528;&#30340;&#29305;&#24449;&#20132;&#20114;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2306.00541</link><description>&lt;p&gt;
&#22522;&#20110;&#29305;&#24449;&#20132;&#20114;&#20316;&#29992;&#36827;&#34892;&#20840;&#23616;&#29305;&#24449;&#25928;&#24212;&#20998;&#35299;
&lt;/p&gt;
&lt;p&gt;
Decomposing Global Feature Effects Based on Feature Interactions. (arXiv:2306.00541v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00541
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#20840;&#23616;&#25928;&#24212;&#24191;&#20041;&#21487;&#21152;&#20998;&#35299;&#65288;GADGET&#65289;&#26694;&#26550;&#65292;&#33021;&#22815;&#26368;&#23567;&#21270;&#29305;&#24449;&#20132;&#20114;&#20316;&#29992;&#30340;&#26412;&#22320;&#29305;&#24449;&#25928;&#24212;&#30340;&#20132;&#20114;&#24322;&#36136;&#24615;&#12290;&#21516;&#26102;&#36866;&#29992;&#20110;&#20559;&#20381;&#36182;&#12289;&#31215;&#32047;&#23616;&#37096;&#25928;&#24212;&#21644;Shapley&#21487;&#21152;&#35299;&#37322;&#65288;SHAP&#65289;&#20381;&#36182;&#30340;&#36793;&#38469;&#29305;&#24449;&#25928;&#24212;&#21487;&#35270;&#21270;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#32622;&#25442;&#30340;&#20132;&#20114;&#27979;&#35797;&#26469;&#26816;&#27979;&#26174;&#30528;&#30340;&#29305;&#24449;&#20132;&#20114;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20840;&#23616;&#29305;&#24449;&#25928;&#24212;&#26041;&#27861;&#65292;&#22914;&#20559;&#20381;&#36182;&#22270;&#65292;&#25552;&#20379;&#20102;&#39044;&#26399;&#36793;&#38469;&#29305;&#24449;&#25928;&#24212;&#30340;&#21487;&#29702;&#35299;&#30340;&#21487;&#35270;&#21270;&#12290;&#20294;&#26159;&#65292;&#24403;&#23384;&#22312;&#29305;&#24449;&#20132;&#20114;&#20316;&#29992;&#26102;&#65292;&#36825;&#31181;&#20840;&#23616;&#29305;&#24449;&#25928;&#24212;&#26041;&#27861;&#21487;&#33021;&#20250;&#35823;&#23548;&#65292;&#22240;&#20026;&#23427;&#20204;&#19981;&#33021;&#24456;&#22909;&#22320;&#34920;&#31034;&#21333;&#20010;&#35266;&#27979;&#30340;&#23616;&#37096;&#29305;&#24449;&#25928;&#24212;&#12290;&#25105;&#20204;&#27491;&#24335;&#20171;&#32461;&#20102;&#22522;&#20110;&#36882;&#24402;&#20998;&#21306;&#30340;&#20840;&#23616;&#25928;&#24212;&#24191;&#20041;&#21487;&#21152;&#20998;&#35299;&#65288;GADGET&#65289;&#26694;&#26550;&#65292;&#20197;&#25214;&#21040;&#35299;&#37322;&#24615;&#29305;&#24449;&#31354;&#38388;&#20013;&#30340;&#21487;&#35299;&#37322;&#21306;&#22495;&#65292;&#20174;&#32780;&#26368;&#23567;&#21270;&#26412;&#22320;&#29305;&#24449;&#25928;&#24212;&#30340;&#20132;&#20114;&#24322;&#36136;&#24615;&#12290;&#25105;&#20204;&#20026;&#35813;&#26694;&#26550;&#25552;&#20379;&#20102;&#25968;&#23398;&#22522;&#30784;&#65292;&#24182;&#23637;&#31034;&#23427;&#36866;&#29992;&#20110;&#26368;&#27969;&#34892;&#30340;&#26041;&#27861;&#26469;&#21487;&#35270;&#21270;&#36793;&#38469;&#29305;&#24449;&#25928;&#24212;&#65292;&#21363;&#20559;&#20381;&#36182;&#65292;&#31215;&#32047;&#23616;&#37096;&#25928;&#24212;&#21644;Shapley&#21487;&#21152;&#35299;&#37322;&#65288;SHAP&#65289;&#20381;&#36182;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#32622;&#25442;&#30340;&#20132;&#20114;&#27979;&#35797;&#26469;&#26816;&#27979;&#26174;&#30528;&#30340;&#29305;&#24449;&#20132;&#20114;&#20316;&#29992;&#65292;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#20219;&#20309;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Global feature effect methods, such as partial dependence plots, provide an intelligible visualization of the expected marginal feature effect. However, such global feature effect methods can be misleading, as they do not represent local feature effects of single observations well when feature interactions are present. We formally introduce generalized additive decomposition of global effects (GADGET), which is a new framework based on recursive partitioning to find interpretable regions in the feature space such that the interaction-related heterogeneity of local feature effects is minimized. We provide a mathematical foundation of the framework and show that it is applicable to the most popular methods to visualize marginal feature effects, namely partial dependence, accumulated local effects, and Shapley additive explanations (SHAP) dependence. Furthermore, we introduce a new permutation-based interaction test to detect significant feature interactions that is applicable to any feat
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24320;&#21457;&#20102;&#26500;&#24314;&#38750;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#19978;&#38745;&#27490;&#39640;&#26031;&#36807;&#31243;&#30340;&#23454;&#29992;&#25216;&#26415;&#65292;&#33021;&#22815;&#23545;&#23450;&#20041;&#22312;&#36825;&#20123;&#31354;&#38388;&#19978;&#30340;&#20808;&#39564;&#21644;&#21518;&#39564;&#39640;&#26031;&#36807;&#31243;&#36827;&#34892;&#23454;&#38469;&#37319;&#26679;&#21644;&#35745;&#31639;&#21327;&#26041;&#24046;&#26680;&#12290;</title><link>http://arxiv.org/abs/2301.13088</link><description>&lt;p&gt;
Lie &#32676;&#21644;&#23427;&#20204;&#30340;&#40784;&#27425;&#31354;&#38388;&#19978;&#30340;&#38745;&#27490;&#26680;&#21644;&#39640;&#26031;&#36807;&#31243; II&#65306;&#38750;&#32039;&#23545;&#31216;&#31354;&#38388;
&lt;/p&gt;
&lt;p&gt;
Stationary Kernels and Gaussian Processes on Lie Groups and their Homogeneous Spaces II: non-compact symmetric spaces. (arXiv:2301.13088v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.13088
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21457;&#20102;&#26500;&#24314;&#38750;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#19978;&#38745;&#27490;&#39640;&#26031;&#36807;&#31243;&#30340;&#23454;&#29992;&#25216;&#26415;&#65292;&#33021;&#22815;&#23545;&#23450;&#20041;&#22312;&#36825;&#20123;&#31354;&#38388;&#19978;&#30340;&#20808;&#39564;&#21644;&#21518;&#39564;&#39640;&#26031;&#36807;&#31243;&#36827;&#34892;&#23454;&#38469;&#37319;&#26679;&#21644;&#35745;&#31639;&#21327;&#26041;&#24046;&#26680;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#37325;&#35201;&#30340;&#26102;&#31354;&#27169;&#22411;&#20043;&#19968;&#65292;&#23427;&#21487;&#20197;&#32534;&#30721;&#26377;&#20851;&#24314;&#27169;&#20989;&#25968;&#30340;&#20808;&#39564;&#20449;&#24687;&#65292;&#24182;&#21487;&#29992;&#20110;&#31934;&#30830;&#25110;&#36817;&#20284;&#36125;&#21494;&#26031;&#23398;&#20064;&#12290;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#65292;&#29305;&#21035;&#26159;&#22312;&#29289;&#29702;&#31185;&#23398;&#21644;&#24037;&#31243;&#39046;&#22495;&#65292;&#20197;&#21450;&#22320;&#36136;&#32479;&#35745;&#23398;&#21644;&#31070;&#32463;&#31185;&#23398;&#31561;&#39046;&#22495;&#65292;&#23545;&#23545;&#31216;&#24615;&#30340;&#19981;&#21464;&#24615;&#26159;&#21487;&#20197;&#32771;&#34385;&#30340;&#26368;&#22522;&#26412;&#24418;&#24335;&#20043;&#19968;&#12290;&#39640;&#26031;&#36807;&#31243;&#21327;&#26041;&#24046;&#23545;&#36825;&#20123;&#23545;&#31216;&#24615;&#30340;&#19981;&#21464;&#24615;&#24341;&#21457;&#20102;&#23545;&#36825;&#20123;&#31354;&#38388;&#30340;&#24179;&#31283;&#24615;&#27010;&#24565;&#30340;&#26368;&#33258;&#28982;&#30340;&#25512;&#24191;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#24314;&#31435;&#38745;&#27490;&#39640;&#26031;&#36807;&#31243;&#30340;&#26500;&#36896;&#24615;&#21644;&#23454;&#29992;&#25216;&#26415;&#65292;&#29992;&#20110;&#22312;&#23545;&#31216;&#24615;&#32972;&#26223;&#19979;&#20986;&#29616;&#30340;&#38750;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#30340;&#38750;&#24120;&#22823;&#30340;&#31867;&#12290;&#25105;&#20204;&#30340;&#25216;&#26415;&#20351;&#24471;&#33021;&#22815;&#65288;i&#65289;&#35745;&#31639;&#21327;&#26041;&#24046;&#26680;&#21644;&#65288;ii&#65289;&#20174;&#36825;&#20123;&#31354;&#38388;&#19978;&#23450;&#20041;&#30340;&#20808;&#39564;&#21644;&#21518;&#39564;&#39640;&#26031;&#36807;&#31243;&#20013;&#23454;&#38469;&#22320;&#36827;&#34892;&#37319;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian processes are arguably the most important class of spatiotemporal models within machine learning. They encode prior information about the modeled function and can be used for exact or approximate Bayesian learning. In many applications, particularly in physical sciences and engineering, but also in areas such as geostatistics and neuroscience, invariance to symmetries is one of the most fundamental forms of prior information one can consider. The invariance of a Gaussian process' covariance to such symmetries gives rise to the most natural generalization of the concept of stationarity to such spaces. In this work, we develop constructive and practical techniques for building stationary Gaussian processes on a very large class of non-Euclidean spaces arising in the context of symmetries. Our techniques make it possible to (i) calculate covariance kernels and (ii) sample from prior and posterior Gaussian processes defined on such spaces, both in a practical manner. This work is 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26377;&#25928;&#30340;&#32437;&#21521;&#32593;&#32476;&#20272;&#35745;&#26694;&#26550;&#65292;&#21033;&#29992;&#33258;&#36866;&#24212;&#21512;&#24182;&#12289;&#24352;&#37327;&#20998;&#35299;&#21644;&#28857;&#36807;&#31243;&#31561;&#26041;&#27861;&#26469;&#20943;&#23569;&#20272;&#35745;&#20559;&#24046;&#21644;&#26041;&#24046;&#12290;</title><link>http://arxiv.org/abs/2211.07866</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#21512;&#24182;&#19979;&#30340;&#32437;&#21521;&#32593;&#32476;&#26377;&#25928;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Efficient Estimation for Longitudinal Network via Adaptive Merging. (arXiv:2211.07866v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.07866
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26377;&#25928;&#30340;&#32437;&#21521;&#32593;&#32476;&#20272;&#35745;&#26694;&#26550;&#65292;&#21033;&#29992;&#33258;&#36866;&#24212;&#21512;&#24182;&#12289;&#24352;&#37327;&#20998;&#35299;&#21644;&#28857;&#36807;&#31243;&#31561;&#26041;&#27861;&#26469;&#20943;&#23569;&#20272;&#35745;&#20559;&#24046;&#21644;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32437;&#21521;&#32593;&#32476;&#30001;&#22810;&#20010;&#33410;&#28857;&#20043;&#38388;&#30340;&#26102;&#38388;&#36793;&#24207;&#21015;&#32452;&#25104;&#65292;&#20854;&#20013;&#26102;&#38388;&#36793;&#22312;&#23454;&#26102;&#20013;&#34987;&#35266;&#23519;&#21040;&#12290;&#38543;&#30528;&#22312;&#32447;&#31038;&#20132;&#24179;&#21488;&#21644;&#30005;&#23376;&#21830;&#21153;&#30340;&#20852;&#36215;&#65292;&#23427;&#24050;&#32463;&#21464;&#24471;&#26222;&#36941;&#65292;&#20294;&#22312;&#25991;&#29486;&#20013;&#24448;&#24448;&#34987;&#24573;&#30053;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26377;&#25928;&#30340;&#32437;&#21521;&#32593;&#32476;&#20272;&#35745;&#26694;&#26550;&#65292;&#21033;&#29992;&#33258;&#36866;&#24212;&#32593;&#32476;&#21512;&#24182;&#12289;&#24352;&#37327;&#20998;&#35299;&#21644;&#28857;&#36807;&#31243;&#30340;&#20248;&#21183;&#12290;&#23427;&#21512;&#24182;&#30456;&#37051;&#30340;&#31232;&#30095;&#32593;&#32476;&#65292;&#20197;&#25193;&#22823;&#35266;&#27979;&#36793;&#30340;&#25968;&#37327;&#24182;&#20943;&#23569;&#20272;&#35745;&#26041;&#24046;&#65292;&#21516;&#26102;&#36890;&#36807;&#21033;&#29992;&#26412;&#22320;&#26102;&#38388;&#32467;&#26500;&#36827;&#34892;&#33258;&#36866;&#24212;&#32593;&#32476;&#37051;&#22495;&#25511;&#21046;&#24341;&#20837;&#30340;&#20272;&#35745;&#20559;&#24046;&#12290;&#25552;&#20986;&#20102;&#19968;&#20010;&#25237;&#24433;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#26469;&#20419;&#36827;&#20272;&#35745;&#65292;&#20854;&#20013;&#27599;&#27425;&#36845;&#20195;&#30340;&#20272;&#35745;&#38169;&#35823;&#19978;&#30028;&#34987;&#24314;&#31435;&#12290;&#36827;&#34892;&#20102;&#24443;&#24213;&#30340;&#20998;&#26512;&#65292;&#20197;&#37327;&#21270;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#28176;&#36817;&#34892;&#20026;&#65292;&#32467;&#26524;&#34920;&#26126;&#23427;&#21487;&#20197;&#26174;&#30528;&#20943;&#23569;&#20272;&#35745;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Longitudinal network consists of a sequence of temporal edges among multiple nodes, where the temporal edges are observed in real time. It has become ubiquitous with the rise of online social platform and e-commerce, but largely under-investigated in literature. In this paper, we propose an efficient estimation framework for longitudinal network, leveraging strengths of adaptive network merging, tensor decomposition and point process. It merges neighboring sparse networks so as to enlarge the number of observed edges and reduce estimation variance, whereas the estimation bias introduced by network merging is controlled by exploiting local temporal structures for adaptive network neighborhood. A projected gradient descent algorithm is proposed to facilitate estimation, where the upper bound of the estimation error in each iteration is established. A thorough analysis is conducted to quantify the asymptotic behavior of the proposed method, which shows that it can significantly reduce the
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#24102;&#26377;&#36164;&#28304;&#32447;&#24615;&#32422;&#26463;&#30340;&#19978;&#19979;&#25991;&#24184;&#23384;&#32773;&#38382;&#39064;&#30340;&#21464;&#31181;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#31616;&#21333;&#12289;&#35745;&#31639;&#25928;&#29575;&#39640;&#65292;&#21516;&#26102;&#33021;&#22815;&#23454;&#29616;&#36739;&#20302;&#30340;&#21518;&#24724;&#12290;&#27492;&#22806;&#65292;&#24403;&#26576;&#20123;&#32422;&#26463;&#34987;&#36829;&#21453;&#26102;&#65292;&#31639;&#27861;&#22312;&#32479;&#35745;&#19978;&#26159;&#26368;&#20248;&#30340;&#12290;</title><link>http://arxiv.org/abs/2211.07484</link><description>&lt;p&gt;
&#24102;&#35013;&#36733;&#21644;&#35206;&#30422;&#32422;&#26463;&#30340;&#19978;&#19979;&#25991;&#24184;&#23384;&#32773;&#38382;&#39064;&#65306;&#22522;&#20110;&#22238;&#24402;&#30340;&#27169;&#22359;&#21270;Lagrangian&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Contextual Bandits with Packing and Covering Constraints: A Modular Lagrangian Approach via Regression. (arXiv:2211.07484v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.07484
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#24102;&#26377;&#36164;&#28304;&#32447;&#24615;&#32422;&#26463;&#30340;&#19978;&#19979;&#25991;&#24184;&#23384;&#32773;&#38382;&#39064;&#30340;&#21464;&#31181;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#31616;&#21333;&#12289;&#35745;&#31639;&#25928;&#29575;&#39640;&#65292;&#21516;&#26102;&#33021;&#22815;&#23454;&#29616;&#36739;&#20302;&#30340;&#21518;&#24724;&#12290;&#27492;&#22806;&#65292;&#24403;&#26576;&#20123;&#32422;&#26463;&#34987;&#36829;&#21453;&#26102;&#65292;&#31639;&#27861;&#22312;&#32479;&#35745;&#19978;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#19968;&#31181;&#19978;&#19979;&#25991;&#24184;&#23384;&#32773;&#38382;&#39064;&#30340;&#21464;&#31181;&#65292;&#20854;&#20013;&#31639;&#27861;&#22312;&#24635;&#28040;&#36153;&#30340;&#32447;&#24615;&#32422;&#26463;&#19979;&#20351;&#29992;&#22810;&#20010;&#36164;&#28304;&#12290;&#36825;&#20010;&#38382;&#39064;&#25512;&#24191;&#20102;&#24102;&#32972;&#21253;&#30340;&#19978;&#19979;&#25991;&#24184;&#23384;&#32773;&#38382;&#39064;(CBwK)&#65292;&#20801;&#35768;&#35013;&#36733;&#21644;&#35206;&#30422;&#32422;&#26463;&#65292;&#20197;&#21450;&#27491;&#36127;&#36164;&#28304;&#28040;&#32791;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;&#31616;&#21333;&#12289;&#35745;&#31639;&#25928;&#29575;&#39640;&#65292;&#33021;&#22815;&#23454;&#29616;&#36864;&#21270;&#30340;&#21518;&#24724;&#12290;&#24403;&#26576;&#20123;&#32422;&#26463;&#34987;&#36829;&#21453;&#26102;&#65292;&#23545;&#20110;CBwK&#65292;&#23427;&#22312;&#32479;&#35745;&#19978;&#26159;&#26368;&#20248;&#30340;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22522;&#20110;LagrangianBwK(Immorlica&#31561;&#20154;&#65292;FOCS 2019)&#65292;&#36825;&#26159;&#19968;&#31181;&#38754;&#21521;CBwK&#30340;Lagrangian&#25216;&#26415;&#65292;&#20197;&#21450;SquareCB(Foster&#21644;Rakhlin&#65292;ICML 2020)&#65292;&#36825;&#26159;&#19968;&#31181;&#38754;&#21521;&#19978;&#19979;&#25991;&#24184;&#23384;&#32773;&#30340;&#22238;&#24402;&#25216;&#26415;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#21033;&#29992;&#20102;&#20004;&#31181;&#25216;&#26415;&#26412;&#36136;&#19978;&#30340;&#27169;&#22359;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a variant of contextual bandits in which the algorithm consumes multiple resources subject to linear constraints on total consumption. This problem generalizes contextual bandits with knapsacks (CBwK), allowing for packing and covering constraints, as well as positive and negative resource consumption. We present a new algorithm that is simple, computationally efficient, and admits vanishing regret. It is statistically optimal for CBwK when an algorithm must stop once some constraint is violated. Our algorithm builds on LagrangeBwK (Immorlica et al., FOCS 2019) , a Lagrangian-based technique for CBwK, and SquareCB (Foster and Rakhlin, ICML 2020), a regression-based technique for contextual bandits. Our analysis leverages the inherent modularity of both techniques.
&lt;/p&gt;</description></item></channel></rss>