<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#39640;&#32500;&#28857;&#36807;&#31243;&#30340;&#24102;&#26377;&#32467;&#26500;&#32570;&#22833;&#30340;&#28789;&#27963;&#39640;&#25928;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#25429;&#33719;&#26102;&#38388;&#30456;&#20851;&#24615;&#65292;&#24182;&#24320;&#21457;&#20102;&#21487;&#25193;&#23637;&#30340;&#21464;&#20998;&#25512;&#29702;&#26041;&#27861;&#36827;&#34892;&#35757;&#32451;&#12290;</title><link>https://arxiv.org/abs/2402.05758</link><description>&lt;p&gt;
&#39640;&#32500;&#28857;&#36807;&#31243;&#30340;&#24102;&#32467;&#26500;&#32570;&#22833;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Latent variable model for high-dimensional point process with structured missingness
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05758
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#39640;&#32500;&#28857;&#36807;&#31243;&#30340;&#24102;&#26377;&#32467;&#26500;&#32570;&#22833;&#30340;&#28789;&#27963;&#39640;&#25928;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#25429;&#33719;&#26102;&#38388;&#30456;&#20851;&#24615;&#65292;&#24182;&#24320;&#21457;&#20102;&#21487;&#25193;&#23637;&#30340;&#21464;&#20998;&#25512;&#29702;&#26041;&#27861;&#36827;&#34892;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32437;&#21521;&#25968;&#25454;&#22312;&#21307;&#30103;&#20445;&#20581;&#12289;&#31038;&#20250;&#23398;&#21644;&#22320;&#38663;&#23398;&#31561;&#35768;&#22810;&#39046;&#22495;&#20013;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#65292;&#20294;&#26159;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#23545;&#20174;&#19994;&#20154;&#21592;&#26469;&#35828;&#23384;&#22312;&#26126;&#26174;&#30340;&#25361;&#25112;&#65292;&#22240;&#20026;&#23427;&#20204;&#21487;&#33021;&#26159;&#39640;&#32500;&#30340;&#65292;&#21253;&#21547;&#26377;&#32467;&#26500;&#21270;&#30340;&#32570;&#22833;&#27169;&#24335;&#65292;&#24182;&#19988;&#27979;&#37327;&#26102;&#38388;&#28857;&#21487;&#33021;&#21463;&#21040;&#26410;&#30693;&#38543;&#26426;&#36807;&#31243;&#30340;&#25511;&#21046;&#12290;&#23613;&#31649;&#24050;&#32463;&#25552;&#20986;&#20102;&#21508;&#31181;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#20854;&#20013;&#22823;&#22810;&#25968;&#20165;&#32771;&#34385;&#20102;&#36825;&#20123;&#25361;&#25112;&#20013;&#30340;&#19968;&#20010;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#28789;&#27963;&#39640;&#25928;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#33021;&#22815;&#24212;&#23545;&#25152;&#26377;&#36825;&#20123;&#38480;&#21046;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#26469;&#25429;&#33719;&#26679;&#26412;&#19982;&#20854;&#20851;&#32852;&#30340;&#32570;&#22833;&#27169;&#24335;&#20043;&#38388;&#30340;&#26102;&#38388;&#30456;&#20851;&#24615;&#65292;&#21516;&#26102;&#20063;&#29992;&#20110;&#24314;&#27169;&#24213;&#23618;&#30340;&#28857;&#36807;&#31243;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#27169;&#22411;&#26500;&#24314;&#20026;&#19968;&#20010;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65292;&#21516;&#26102;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#30340;&#32534;&#30721;&#22120;&#21644;&#35299;&#30721;&#22120;&#27169;&#22411;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#21464;&#20998;&#25512;&#29702;&#26041;&#27861;&#26469;&#36827;&#34892;&#39640;&#25928;&#30340;&#27169;&#22411;&#35757;&#32451;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20010;&#27169;&#22411;&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#31454;&#20105;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Longitudinal data are important in numerous fields, such as healthcare, sociology and seismology, but real-world datasets present notable challenges for practitioners because they can be high-dimensional, contain structured missingness patterns, and measurement time points can be governed by an unknown stochastic process. While various solutions have been suggested, the majority of them have been designed to account for only one of these challenges. In this work, we propose a flexible and efficient latent-variable model that is capable of addressing all these limitations. Our approach utilizes Gaussian processes to capture temporal correlations between samples and their associated missingness masks as well as to model the underlying point process. We construct our model as a variational autoencoder together with deep neural network parameterised encoder and decoder models, and develop a scalable amortised variational inference approach for efficient model training. We demonstrate compe
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#23558;&#26367;&#20195;&#25968;&#25454;&#19982;&#30495;&#23454;&#25968;&#25454;&#25972;&#21512;&#20197;&#36827;&#34892;&#35757;&#32451;&#30340;&#26041;&#26696;&#65292;&#21457;&#29616;&#25972;&#21512;&#26367;&#20195;&#25968;&#25454;&#33021;&#22815;&#26174;&#33879;&#38477;&#20302;&#27979;&#35797;&#35823;&#24046;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#25193;&#23637;&#35268;&#24459;&#26469;&#25551;&#36848;&#28151;&#21512;&#27169;&#22411;&#30340;&#27979;&#35797;&#35823;&#24046;&#65292;&#21487;&#20197;&#29992;&#20110;&#39044;&#27979;&#26368;&#20248;&#21152;&#26435;&#21644;&#25910;&#30410;&#12290;</title><link>https://arxiv.org/abs/2402.04376</link><description>&lt;p&gt;
&#20351;&#29992;&#30495;&#23454;&#25968;&#25454;&#21644;&#26367;&#20195;&#25968;&#25454;&#36827;&#34892;&#23398;&#20064;&#30340;&#25193;&#23637;&#35268;&#24459;
&lt;/p&gt;
&lt;p&gt;
Scaling laws for learning with real and surrogate data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04376
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#23558;&#26367;&#20195;&#25968;&#25454;&#19982;&#30495;&#23454;&#25968;&#25454;&#25972;&#21512;&#20197;&#36827;&#34892;&#35757;&#32451;&#30340;&#26041;&#26696;&#65292;&#21457;&#29616;&#25972;&#21512;&#26367;&#20195;&#25968;&#25454;&#33021;&#22815;&#26174;&#33879;&#38477;&#20302;&#27979;&#35797;&#35823;&#24046;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#25193;&#23637;&#35268;&#24459;&#26469;&#25551;&#36848;&#28151;&#21512;&#27169;&#22411;&#30340;&#27979;&#35797;&#35823;&#24046;&#65292;&#21487;&#20197;&#29992;&#20110;&#39044;&#27979;&#26368;&#20248;&#21152;&#26435;&#21644;&#25910;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25910;&#38598;&#22823;&#37327;&#39640;&#36136;&#37327;&#30340;&#25968;&#25454;&#36890;&#24120;&#34987;&#38480;&#21046;&#22312;&#25104;&#26412;&#26114;&#36149;&#25110;&#19981;&#20999;&#23454;&#38469;&#30340;&#33539;&#22260;&#20869;, &#36825;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#29942;&#39048;&#12290;&#30456;&#21453;&#22320;, &#21487;&#20197;&#23558;&#26469;&#33258;&#30446;&#26631;&#20998;&#24067;&#30340;&#23567;&#35268;&#27169;&#25968;&#25454;&#38598;&#19982;&#26469;&#33258;&#20844;&#20849;&#25968;&#25454;&#38598;&#12289;&#19981;&#21516;&#24773;&#20917;&#19979;&#25910;&#38598;&#30340;&#25968;&#25454;&#25110;&#30001;&#29983;&#25104;&#27169;&#22411;&#21512;&#25104;&#30340;&#25968;&#25454;&#30456;&#32467;&#21512;, &#20316;&#20026;&#26367;&#20195;&#25968;&#25454;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#26696;&#26469;&#23558;&#26367;&#20195;&#25968;&#25454;&#25972;&#21512;&#21040;&#35757;&#32451;&#20013;, &#24182;&#20351;&#29992;&#29702;&#35770;&#27169;&#22411;&#21644;&#23454;&#35777;&#30740;&#31350;&#25506;&#32034;&#20854;&#34892;&#20026;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#21457;&#29616;&#26159;&#65306;(i) &#25972;&#21512;&#26367;&#20195;&#25968;&#25454;&#21487;&#20197;&#26174;&#33879;&#38477;&#20302;&#21407;&#22987;&#20998;&#24067;&#30340;&#27979;&#35797;&#35823;&#24046;&#65307;(ii) &#20026;&#20102;&#33719;&#24471;&#36825;&#31181;&#25928;&#30410;, &#20351;&#29992;&#26368;&#20248;&#21152;&#26435;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#38750;&#24120;&#20851;&#38190;&#65307;(iii) &#22312;&#28151;&#21512;&#20351;&#29992;&#30495;&#23454;&#25968;&#25454;&#21644;&#26367;&#20195;&#25968;&#25454;&#35757;&#32451;&#30340;&#27169;&#22411;&#30340;&#27979;&#35797;&#35823;&#24046;&#21487;&#20197;&#24456;&#22909;&#22320;&#29992;&#19968;&#20010;&#25193;&#23637;&#35268;&#24459;&#26469;&#25551;&#36848;&#12290;&#36825;&#21487;&#20197;&#29992;&#26469;&#39044;&#27979;&#26368;&#20248;&#21152;&#26435;&#21644;&#25910;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
Collecting large quantities of high-quality data is often prohibitively expensive or impractical, and a crucial bottleneck in machine learning. One may instead augment a small set of $n$ data points from the target distribution with data from more accessible sources like public datasets, data collected under different circumstances, or synthesized by generative models. Blurring distinctions, we refer to such data as `surrogate data'.   We define a simple scheme for integrating surrogate data into training and use both theoretical models and empirical studies to explore its behavior. Our main findings are: $(i)$ Integrating surrogate data can significantly reduce the test error on the original distribution; $(ii)$ In order to reap this benefit, it is crucial to use optimally weighted empirical risk minimization; $(iii)$ The test error of models trained on mixtures of real and surrogate data is well described by a scaling law. This can be used to predict the optimal weighting and the gai
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20048;&#39640;&#31215;&#26408;&#65292;&#36890;&#36807;&#38598;&#25104;&#23616;&#37096;&#29305;&#24449;&#20016;&#23500;&#21644;&#20840;&#23616;&#20869;&#23481;&#21327;&#35843;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#19988;&#21487;&#33258;&#36866;&#24212;&#30340;&#36845;&#20195;&#32454;&#21270;&#25193;&#25955;&#24314;&#27169;&#12290;&#36825;&#20123;&#31215;&#26408;&#21487;&#20197;&#22534;&#21472;&#22312;&#19968;&#36215;&#65292;&#29992;&#20110;&#22312;&#27979;&#35797;&#26102;&#26681;&#25454;&#38656;&#35201;&#36827;&#34892;&#37325;&#26500;&#65292;&#20174;&#32780;&#20943;&#23569;&#37319;&#26679;&#25104;&#26412;&#24182;&#29983;&#25104;&#39640;&#20998;&#36776;&#29575;&#22270;&#20687;&#12290;</title><link>http://arxiv.org/abs/2310.06389</link><description>&lt;p&gt;
&#23398;&#20064;&#21487;&#22534;&#21472;&#21644;&#21487;&#36339;&#36807;&#30340;&#20048;&#39640;&#31215;&#26408;&#20197;&#23454;&#29616;&#39640;&#25928;&#12289;&#21487;&#37325;&#26500;&#21644;&#21487;&#21464;&#20998;&#36776;&#29575;&#30340;&#25193;&#25955;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Learning Stackable and Skippable LEGO Bricks for Efficient, Reconfigurable, and Variable-Resolution Diffusion Modeling. (arXiv:2310.06389v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06389
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20048;&#39640;&#31215;&#26408;&#65292;&#36890;&#36807;&#38598;&#25104;&#23616;&#37096;&#29305;&#24449;&#20016;&#23500;&#21644;&#20840;&#23616;&#20869;&#23481;&#21327;&#35843;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#19988;&#21487;&#33258;&#36866;&#24212;&#30340;&#36845;&#20195;&#32454;&#21270;&#25193;&#25955;&#24314;&#27169;&#12290;&#36825;&#20123;&#31215;&#26408;&#21487;&#20197;&#22534;&#21472;&#22312;&#19968;&#36215;&#65292;&#29992;&#20110;&#22312;&#27979;&#35797;&#26102;&#26681;&#25454;&#38656;&#35201;&#36827;&#34892;&#37325;&#26500;&#65292;&#20174;&#32780;&#20943;&#23569;&#37319;&#26679;&#25104;&#26412;&#24182;&#29983;&#25104;&#39640;&#20998;&#36776;&#29575;&#22270;&#20687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#22312;&#29983;&#25104;&#30495;&#23454;&#24863;&#22270;&#20687;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#22312;&#35757;&#32451;&#21644;&#37319;&#26679;&#26041;&#38754;&#20855;&#26377;&#26174;&#33879;&#30340;&#35745;&#31639;&#25104;&#26412;&#12290;&#23613;&#31649;&#26377;&#21508;&#31181;&#25216;&#26415;&#26469;&#35299;&#20915;&#36825;&#20123;&#35745;&#31639;&#25361;&#25112;&#65292;&#20294;&#19968;&#20010;&#36739;&#23569;&#25506;&#32034;&#30340;&#38382;&#39064;&#26159;&#35774;&#35745;&#19968;&#20010;&#39640;&#25928;&#19988;&#36866;&#24212;&#24615;&#24378;&#30340;&#32593;&#32476;&#39592;&#24178;&#65292;&#29992;&#20110;&#36845;&#20195;&#32454;&#21270;&#12290;&#24403;&#21069;&#30340;&#36873;&#39033;&#22914;U-Net&#21644;Vision Transformer&#36890;&#24120;&#20381;&#36182;&#20110;&#36164;&#28304;&#23494;&#38598;&#22411;&#30340;&#28145;&#24230;&#32593;&#32476;&#65292;&#32570;&#20047;&#22312;&#21464;&#37327;&#20998;&#36776;&#29575;&#19979;&#29983;&#25104;&#22270;&#20687;&#25110;&#20351;&#29992;&#27604;&#35757;&#32451;&#20013;&#26356;&#23567;&#30340;&#32593;&#32476;&#25152;&#38656;&#30340;&#28789;&#27963;&#24615;&#12290;&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#20048;&#39640;&#31215;&#26408;&#65292;&#23427;&#20204;&#26080;&#32541;&#38598;&#25104;&#20102;&#23616;&#37096;&#29305;&#24449;&#20016;&#23500;&#21644;&#20840;&#23616;&#20869;&#23481;&#21327;&#35843;&#12290;&#36825;&#20123;&#31215;&#26408;&#21487;&#20197;&#22534;&#21472;&#22312;&#19968;&#36215;&#65292;&#21019;&#24314;&#19968;&#20010;&#27979;&#35797;&#26102;&#21487;&#37325;&#26500;&#30340;&#25193;&#25955;&#39592;&#24178;&#65292;&#20801;&#35768;&#36873;&#25321;&#24615;&#36339;&#36807;&#31215;&#26408;&#20197;&#20943;&#23569;&#37319;&#26679;&#25104;&#26412;&#65292;&#24182;&#29983;&#25104;&#27604;&#35757;&#32451;&#25968;&#25454;&#26356;&#39640;&#20998;&#36776;&#29575;&#30340;&#22270;&#20687;&#12290;&#20048;&#39640;&#31215;&#26408;&#36890;&#36807;MLP&#23545;&#23616;&#37096;&#21306;&#22495;&#36827;&#34892;&#20016;&#23500;&#65292;&#24182;&#20351;&#29992;Transformer&#22359;&#36827;&#34892;&#21464;&#25442;&#65292;&#21516;&#26102;&#20445;&#25345;&#19968;&#33268;&#30340;&#20840;&#20998;&#36776;&#29575;
&lt;/p&gt;
&lt;p&gt;
Diffusion models excel at generating photo-realistic images but come with significant computational costs in both training and sampling. While various techniques address these computational challenges, a less-explored issue is designing an efficient and adaptable network backbone for iterative refinement. Current options like U-Net and Vision Transformer often rely on resource-intensive deep networks and lack the flexibility needed for generating images at variable resolutions or with a smaller network than used in training. This study introduces LEGO bricks, which seamlessly integrate Local-feature Enrichment and Global-content Orchestration. These bricks can be stacked to create a test-time reconfigurable diffusion backbone, allowing selective skipping of bricks to reduce sampling costs and generate higher-resolution images than the training data. LEGO bricks enrich local regions with an MLP and transform them using a Transformer block while maintaining a consistent full-resolution i
&lt;/p&gt;</description></item><item><title>Fishnets&#26159;&#19968;&#31181;&#29992;&#20110;&#23398;&#20064;&#20449;&#24687;&#26368;&#20248;&#30340;&#38598;&#21512;&#21644;&#22270;&#32858;&#21512;&#30340;&#26041;&#27861;&#65292;&#22312;&#35268;&#27169;&#19978;&#21487;&#20197;&#20248;&#21270;&#21040;&#20219;&#24847;&#25968;&#37327;&#30340;&#25968;&#25454;&#23545;&#35937;&#65292;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#33021;&#22815;&#39281;&#21644;&#36125;&#21494;&#26031;&#20449;&#24687;&#20869;&#23481;&#65292;&#24182;&#21487;&#29992;&#20110;GNNs&#20013;&#30340;&#28040;&#24687;&#20256;&#36882;&#12290;</title><link>http://arxiv.org/abs/2310.03812</link><description>&lt;p&gt;
&#40060;&#32593;&#65306;&#20449;&#24687;&#26368;&#20248;&#65292;&#21487;&#25193;&#23637;&#30340;&#38598;&#21512;&#21644;&#22270;&#32858;&#21512;
&lt;/p&gt;
&lt;p&gt;
Fishnets: Information-Optimal, Scalable Aggregation for Sets and Graphs. (arXiv:2310.03812v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03812
&lt;/p&gt;
&lt;p&gt;
Fishnets&#26159;&#19968;&#31181;&#29992;&#20110;&#23398;&#20064;&#20449;&#24687;&#26368;&#20248;&#30340;&#38598;&#21512;&#21644;&#22270;&#32858;&#21512;&#30340;&#26041;&#27861;&#65292;&#22312;&#35268;&#27169;&#19978;&#21487;&#20197;&#20248;&#21270;&#21040;&#20219;&#24847;&#25968;&#37327;&#30340;&#25968;&#25454;&#23545;&#35937;&#65292;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#33021;&#22815;&#39281;&#21644;&#36125;&#21494;&#26031;&#20449;&#24687;&#20869;&#23481;&#65292;&#24182;&#21487;&#29992;&#20110;GNNs&#20013;&#30340;&#28040;&#24687;&#20256;&#36882;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#38598;&#21512;&#30340;&#23398;&#20064;&#26159;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#21644;&#32593;&#32476;&#31185;&#23398;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#21450;&#20854;&#19981;&#21547;&#36793;&#30340;&#23545;&#24212;&#29289;Deepsets&#22312;&#19981;&#35268;&#21017;&#21644;&#25299;&#25169;&#22797;&#26434;&#30340;&#25968;&#25454;&#38598;&#19978;&#34987;&#35777;&#26126;&#38750;&#24120;&#26377;&#29992;&#12290;&#20026;&#20102;&#23398;&#20064;&#38598;&#21512;&#25104;&#21592;&#30340;&#20449;&#24687;&#20016;&#23500;&#30340;&#23884;&#20837;&#65292;&#20851;&#38190;&#26159;&#25351;&#23450;&#19968;&#20010;&#32858;&#21512;&#20989;&#25968;&#65292;&#36890;&#24120;&#26159;&#27714;&#21644;&#12289;&#26368;&#22823;&#20540;&#25110;&#22343;&#20540;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;Fishnets&#65292;&#19968;&#31181;&#29992;&#20110;&#23398;&#20064;&#38598;&#21512;&#25968;&#25454;&#21644;&#22270;&#32858;&#21512;&#30340;&#20449;&#24687;&#26368;&#20248;&#23884;&#20837;&#31574;&#30053;&#65292;&#36866;&#29992;&#20110;&#36125;&#21494;&#26031;&#25512;&#29702;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#65306;i&#65289;Fishnets&#31070;&#32463;&#25688;&#35201;&#21487;&#20197;&#26368;&#20248;&#22320;&#25193;&#23637;&#21040;&#20219;&#24847;&#25968;&#37327;&#30340;&#25968;&#25454;&#23545;&#35937;&#65307;ii&#65289;Fishnets&#32858;&#21512;&#23545;&#25968;&#25454;&#20998;&#24067;&#30340;&#25913;&#21464;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#32780;&#26631;&#20934;&#30340;Deepsets&#19981;&#20855;&#22791;&#36825;&#31181;&#29305;&#24615;&#65307;iii&#65289;Fishnets&#39281;&#21644;&#36125;&#21494;&#26031;&#20449;&#24687;&#20869;&#23481;&#65292;&#24182;&#25193;&#23637;&#21040;MCMC&#25216;&#26415;&#22833;&#36133;&#30340;&#39046;&#22495;&#65307;iv&#65289;Fishnets&#21487;&#20197;&#20316;&#20026;GNN&#20013;&#30340;&#19968;&#20010;&#25554;&#20837;&#24335;&#32858;&#21512;&#26041;&#26696;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#37319;&#29992;Fishnets&#32858;&#21512;&#26041;&#26696;&#36827;&#34892;&#28040;&#24687;&#20256;&#36882;&#65292;GNNs&#21487;&#20197;&#23454;&#29616; &#36798;&#21040;
&lt;/p&gt;
&lt;p&gt;
Set-based learning is an essential component of modern deep learning and network science. Graph Neural Networks (GNNs) and their edge-free counterparts Deepsets have proven remarkably useful on ragged and topologically challenging datasets. The key to learning informative embeddings for set members is a specified aggregation function, usually a sum, max, or mean. We propose Fishnets, an aggregation strategy for learning information-optimal embeddings for sets of data for both Bayesian inference and graph aggregation. We demonstrate that i) Fishnets neural summaries can be scaled optimally to an arbitrary number of data objects, ii) Fishnets aggregations are robust to changes in data distribution, unlike standard deepsets, iii) Fishnets saturate Bayesian information content and extend to regimes where MCMC techniques fail and iv) Fishnets can be used as a drop-in aggregation scheme within GNNs. We show that by adopting a Fishnets aggregation scheme for message passing, GNNs can achieve 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#22823;&#32500;&#24230;&#25968;&#25454;&#30340;&#26680;&#22238;&#24402;&#30340;&#26368;&#20248;&#27604;&#29575;&#65292;&#36890;&#36807;&#20351;&#29992;Mendelson&#22797;&#26434;&#24615;&#21644;&#24230;&#37327;&#29109;&#26469;&#21051;&#30011;&#20854;&#19978;&#30028;&#21644;&#26368;&#23567;&#21270;&#19979;&#30028;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#36824;&#21457;&#29616;&#26368;&#20248;&#27604;&#29575;&#38543;&#30528;&#32500;&#24230;&#19982;&#26679;&#26412;&#22823;&#23567;&#20851;&#31995;&#30340;&#21464;&#21270;&#21576;&#29616;&#20986;&#22810;&#27425;&#19979;&#38477;&#30340;&#34892;&#20026;&#12290;</title><link>http://arxiv.org/abs/2309.04268</link><description>&lt;p&gt;
&#22823;&#32500;&#24230;&#24773;&#20917;&#19979;&#26680;&#22238;&#24402;&#30340;&#26368;&#20248;&#27604;&#29575;
&lt;/p&gt;
&lt;p&gt;
Optimal Rate of Kernel Regression in Large Dimensions. (arXiv:2309.04268v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.04268
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#22823;&#32500;&#24230;&#25968;&#25454;&#30340;&#26680;&#22238;&#24402;&#30340;&#26368;&#20248;&#27604;&#29575;&#65292;&#36890;&#36807;&#20351;&#29992;Mendelson&#22797;&#26434;&#24615;&#21644;&#24230;&#37327;&#29109;&#26469;&#21051;&#30011;&#20854;&#19978;&#30028;&#21644;&#26368;&#23567;&#21270;&#19979;&#30028;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#36824;&#21457;&#29616;&#26368;&#20248;&#27604;&#29575;&#38543;&#30528;&#32500;&#24230;&#19982;&#26679;&#26412;&#22823;&#23567;&#20851;&#31995;&#30340;&#21464;&#21270;&#21576;&#29616;&#20986;&#22810;&#27425;&#19979;&#38477;&#30340;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23545;&#22823;&#32500;&#24230;&#25968;&#25454;&#65288;&#26679;&#26412;&#22823;&#23567;$n$&#19982;&#26679;&#26412;&#32500;&#24230;$d$&#30340;&#20851;&#31995;&#20026;&#22810;&#39033;&#24335;&#65292;&#21363;$n\asymp d^{\gamma}$&#65292;&#20854;&#20013;$\gamma&gt;0$&#65289;&#30340;&#26680;&#22238;&#24402;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#25105;&#20204;&#39318;&#20808;&#36890;&#36807;Mendelson&#22797;&#26434;&#24615;$\varepsilon_{n}^{2}$&#21644;&#24230;&#37327;&#29109;$\bar{\varepsilon}_{n}^{2}$&#26469;&#24314;&#31435;&#19968;&#20010;&#36890;&#29992;&#24037;&#20855;&#65292;&#29992;&#20110;&#21051;&#30011;&#22823;&#32500;&#24230;&#25968;&#25454;&#30340;&#26680;&#22238;&#24402;&#30340;&#19978;&#30028;&#21644;&#26368;&#23567;&#21270;&#19979;&#30028;&#12290;&#24403;&#30446;&#26631;&#20989;&#25968;&#23646;&#20110;&#19982;$\mathbb{S}^{d}$&#19978;&#23450;&#20041;&#30340;&#65288;&#19968;&#33324;&#65289;&#20869;&#31215;&#27169;&#22411;&#30456;&#20851;&#32852;&#30340;RKHS&#26102;&#65292;&#25105;&#20204;&#21033;&#29992;&#36825;&#20010;&#26032;&#24037;&#20855;&#26469;&#23637;&#31034;&#26680;&#22238;&#24402;&#30340;&#36807;&#37327;&#39118;&#38505;&#30340;&#26368;&#23567;&#21270;&#29575;&#26159;$n^{-1/2}$&#65292;&#24403;$n\asymp d^{\gamma}$&#65292;&#20854;&#20013;$\gamma=2, 4, 6, 8, \cdots$&#12290;&#28982;&#21518;&#25105;&#20204;&#36827;&#19968;&#27493;&#30830;&#23450;&#20102;&#23545;&#20110;&#25152;&#26377;$\gamma&gt;0$&#65292;&#26680;&#22238;&#24402;&#36807;&#37327;&#39118;&#38505;&#30340;&#26368;&#20248;&#27604;&#29575;&#65292;&#24182;&#21457;&#29616;&#38543;&#30528;$\gamma$&#30340;&#21464;&#21270;&#65292;&#26368;&#20248;&#27604;&#29575;&#30340;&#26354;&#32447;&#23637;&#29616;&#20986;&#20960;&#20010;&#26032;&#29616;&#35937;&#65292;&#21253;&#25324;&#22810;&#27425;&#19979;&#38477;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
We perform a study on kernel regression for large-dimensional data (where the sample size $n$ is polynomially depending on the dimension $d$ of the samples, i.e., $n\asymp d^{\gamma}$ for some $\gamma &gt;0$ ). We first build a general tool to characterize the upper bound and the minimax lower bound of kernel regression for large dimensional data through the Mendelson complexity $\varepsilon_{n}^{2}$ and the metric entropy $\bar{\varepsilon}_{n}^{2}$ respectively. When the target function falls into the RKHS associated with a (general) inner product model defined on $\mathbb{S}^{d}$, we utilize the new tool to show that the minimax rate of the excess risk of kernel regression is $n^{-1/2}$ when $n\asymp d^{\gamma}$ for $\gamma =2, 4, 6, 8, \cdots$. We then further determine the optimal rate of the excess risk of kernel regression for all the $\gamma&gt;0$ and find that the curve of optimal rate varying along $\gamma$ exhibits several new phenomena including the {\it multiple descent behavior
&lt;/p&gt;</description></item><item><title>MALIBO&#26159;&#19968;&#31181;&#20803;&#23398;&#20064;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#30452;&#25509;&#23398;&#20064;&#36328;&#20219;&#21153;&#30340;&#26597;&#35810;&#25928;&#29992;&#65292;&#24182;&#24341;&#20837;&#36741;&#21161;&#27169;&#22411;&#20197;&#23454;&#29616;&#23545;&#26032;&#20219;&#21153;&#30340;&#31283;&#20581;&#36866;&#24212;&#65292;&#20811;&#26381;&#20102;&#29616;&#26377;&#26041;&#27861;&#30340;&#21487;&#20280;&#32553;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2307.03565</link><description>&lt;p&gt;
MALIBO: &#20803;&#23398;&#20064;&#24212;&#29992;&#20110;&#26080;&#20284;&#28982;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
MALIBO: Meta-learning for Likelihood-free Bayesian Optimization. (arXiv:2307.03565v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03565
&lt;/p&gt;
&lt;p&gt;
MALIBO&#26159;&#19968;&#31181;&#20803;&#23398;&#20064;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#30452;&#25509;&#23398;&#20064;&#36328;&#20219;&#21153;&#30340;&#26597;&#35810;&#25928;&#29992;&#65292;&#24182;&#24341;&#20837;&#36741;&#21161;&#27169;&#22411;&#20197;&#23454;&#29616;&#23545;&#26032;&#20219;&#21153;&#30340;&#31283;&#20581;&#36866;&#24212;&#65292;&#20811;&#26381;&#20102;&#29616;&#26377;&#26041;&#27861;&#30340;&#21487;&#20280;&#32553;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#26159;&#19968;&#31181;&#20248;&#21270;&#26114;&#36149;&#40657;&#30418;&#20989;&#25968;&#30340;&#27969;&#34892;&#26041;&#27861;&#12290;&#20256;&#32479;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#20250;&#20174;&#22836;&#24320;&#22987;&#20248;&#21270;&#27599;&#20010;&#26032;&#30340;&#30446;&#26631;&#20219;&#21153;&#65292;&#32780;&#20803;&#23398;&#20064;&#21017;&#26159;&#21033;&#29992;&#30456;&#20851;&#20219;&#21153;&#30340;&#30693;&#35782;&#26469;&#26356;&#24555;&#22320;&#20248;&#21270;&#26032;&#20219;&#21153;&#30340;&#19968;&#31181;&#26041;&#24335;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#20803;&#23398;&#20064;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#20381;&#36182;&#20110;&#26631;&#20934;&#27169;&#22411;&#65292;&#36825;&#20123;&#27169;&#22411;&#23384;&#22312;&#21487;&#20280;&#32553;&#24615;&#38382;&#39064;&#65292;&#24182;&#19988;&#23545;&#19981;&#21516;&#20219;&#21153;&#20043;&#38388;&#35266;&#23519;&#25968;&#25454;&#30340;&#23610;&#24230;&#21644;&#22122;&#22768;&#31867;&#22411;&#38750;&#24120;&#25935;&#24863;&#12290;&#27492;&#22806;&#65292;&#23427;&#20204;&#24120;&#24120;&#24573;&#35270;&#19982;&#20219;&#21153;&#30456;&#20284;&#24615;&#30456;&#20851;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#36825;&#23548;&#33268;&#22312;&#20165;&#26377;&#26377;&#38480;&#35266;&#23519;&#25968;&#25454;&#25110;&#26032;&#20219;&#21153;&#19982;&#30456;&#20851;&#20219;&#21153;&#24046;&#24322;&#26174;&#33879;&#26102;&#65292;&#20219;&#21153;&#36866;&#24212;&#24615;&#19981;&#21487;&#38752;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20803;&#23398;&#20064;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#26088;&#22312;&#32469;&#24320;&#26631;&#20934;&#27169;&#22411;&#65292;&#30452;&#25509;&#23398;&#20064;&#36328;&#20219;&#21153;&#30340;&#26597;&#35810;&#25928;&#29992;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26126;&#30830;&#24314;&#27169;&#20219;&#21153;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#36741;&#21161;&#27169;&#22411;&#65292;&#20351;&#20854;&#33021;&#22815;&#23545;&#26032;&#20219;&#21153;&#36827;&#34892;&#31283;&#20581;&#36866;&#24212;&#12290;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimization (BO) is a popular method to optimize costly black-box functions. While traditional BO optimizes each new target task from scratch, meta-learning has emerged as a way to leverage knowledge from related tasks to optimize new tasks faster. However, existing meta-learning BO methods rely on surrogate models that suffer from scalability issues and are sensitive to observations with different scales and noise types across tasks. Moreover, they often overlook the uncertainty associated with task similarity. This leads to unreliable task adaptation when only limited observations are obtained or when the new tasks differ significantly from the related tasks. To address these limitations, we propose a novel meta-learning BO approach that bypasses the surrogate model and directly learns the utility of queries across tasks. Our method explicitly models task uncertainty and includes an auxiliary model to enable robust adaptation to new tasks. Extensive experiments show that ou
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#32034;&#20351;&#29992;GPT-4&#35299;&#20915;&#26356;&#22797;&#26434;&#21644;&#26377;&#25361;&#25112;&#24615;&#30340;&#25968;&#23398;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;MathChat&#30340;&#23545;&#35805;&#24335;&#38382;&#39064;&#27714;&#35299;&#26694;&#26550;&#65292;&#24182;&#22312;&#22256;&#38590;&#39640;&#20013;&#31454;&#36187;&#38382;&#39064;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2306.01337</link><description>&lt;p&gt;
&#22522;&#20110;GPT-4&#30340;&#22797;&#26434;&#25968;&#23398;&#38382;&#39064;&#27714;&#35299;&#30340;&#23454;&#35777;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
An Empirical Study on Challenging Math Problem Solving with GPT-4. (arXiv:2306.01337v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01337
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#20351;&#29992;GPT-4&#35299;&#20915;&#26356;&#22797;&#26434;&#21644;&#26377;&#25361;&#25112;&#24615;&#30340;&#25968;&#23398;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;MathChat&#30340;&#23545;&#35805;&#24335;&#38382;&#39064;&#27714;&#35299;&#26694;&#26550;&#65292;&#24182;&#22312;&#22256;&#38590;&#39640;&#20013;&#31454;&#36187;&#38382;&#39064;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#26469;&#35299;&#20915;&#25968;&#23398;&#38382;&#39064;&#26159;&#19968;&#39033;&#26377;&#36259;&#30340;&#30740;&#31350;&#65292;&#32771;&#34385;&#21040;&#22312;&#21508;&#31181;&#31185;&#23398;&#21644;&#24037;&#31243;&#39046;&#22495;&#20013;&#29992;&#33258;&#28982;&#35821;&#35328;&#34920;&#36798;&#30340;&#25968;&#23398;&#38382;&#39064;&#30340;&#20016;&#23500;&#24615;&#12290;&#34429;&#28982;&#20043;&#21069;&#26377;&#20960;&#39033;&#24037;&#20316;&#30740;&#31350;&#20102;&#20351;&#29992;LLM&#35299;&#20915;&#21021;&#31561;&#25968;&#23398;&#38382;&#39064;&#65292;&#20294;&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#20351;&#29992;GPT-4&#35299;&#20915;&#26356;&#22797;&#26434;&#21644;&#26377;&#25361;&#25112;&#24615;&#30340;&#25968;&#23398;&#38382;&#39064;&#30340;&#21069;&#27839;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#20351;&#29992;GPT-4&#30340;&#21508;&#31181;&#26041;&#27861;&#12290;&#20854;&#20013;&#19968;&#20123;&#26159;&#20174;&#29616;&#26377;&#24037;&#20316;&#20013;&#25913;&#32534;&#32780;&#26469;&#30340;&#65292;&#20854;&#20013;&#19968;&#20010;&#26159;MathChat&#65292;&#36825;&#26159;&#26412;&#30740;&#31350;&#26032;&#25552;&#20986;&#30340;&#19968;&#31181;&#23545;&#35805;&#24335;&#38382;&#39064;&#27714;&#35299;&#26694;&#26550;&#12290;&#25105;&#20204;&#22312;&#26469;&#33258;MATH&#25968;&#25454;&#38598;&#30340;&#22256;&#38590;&#39640;&#20013;&#31454;&#36187;&#38382;&#39064;&#19978;&#36827;&#34892;&#35780;&#20272;&#65292;&#34920;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#23545;&#35805;&#24335;&#26041;&#27861;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Employing Large Language Models (LLMs) to address mathematical problems is an intriguing research endeavor, considering the abundance of math problems expressed in natural language across numerous science and engineering fields. While several prior works have investigated solving elementary mathematics using LLMs, this work explores the frontier of using GPT-4 for solving more complex and challenging math problems. We evaluate various ways of using GPT-4. Some of them are adapted from existing work, and one is \MathChat, a conversational problem-solving framework newly proposed in this work. We perform the evaluation on difficult high school competition problems from the MATH dataset, which shows the advantage of the proposed conversational approach.
&lt;/p&gt;</description></item></channel></rss>