<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#20855;&#26377;&#20219;&#24847;&#31867;&#22411;&#26410;&#30693;&#36229;&#21442;&#25968;&#30340;&#24773;&#20917;&#65292;&#24182;&#20855;&#26377;&#26080;&#36951;&#25022;&#29305;&#24615;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01632</link><description>&lt;p&gt;
&#36229;&#36234;&#23610;&#24230;&#65306;&#20855;&#26377;&#20219;&#24847;&#31867;&#22411;&#26410;&#30693;&#36229;&#21442;&#25968;&#30340;&#26080;&#36951;&#25022;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Beyond Lengthscales: No-regret Bayesian Optimisation With Unknown Hyperparameters Of Any Type
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01632
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#20855;&#26377;&#20219;&#24847;&#31867;&#22411;&#26410;&#30693;&#36229;&#21442;&#25968;&#30340;&#24773;&#20917;&#65292;&#24182;&#20855;&#26377;&#26080;&#36951;&#25022;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#38656;&#35201;&#25311;&#21512;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65292;&#32780;&#25311;&#21512;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#38656;&#35201;&#25351;&#23450;&#36229;&#21442;&#25968; - &#22823;&#37096;&#20998;&#29702;&#35770;&#25991;&#29486;&#20551;&#35774;&#36825;&#20123;&#36229;&#21442;&#25968;&#26159;&#24050;&#30693;&#30340;&#12290;&#20043;&#21069;&#30340;&#29702;&#35770;&#30740;&#31350;&#36890;&#24120;&#20551;&#35774;&#25968;&#25454;&#22312;&#31354;&#38388;&#20013;&#22343;&#21248;&#22635;&#20805;&#65292;&#32780;&#24120;&#29992;&#30340;&#39640;&#26031;&#36807;&#31243;&#36229;&#21442;&#25968;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#21482;&#26377;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#25165;&#26159;&#19968;&#33268;&#30340;&#12290;&#28982;&#32780;&#65292;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#65292;&#25968;&#25454;&#19981;&#19968;&#23450;&#28385;&#36275;&#36825;&#31181;&#22343;&#21248;&#22635;&#20805;&#30340;&#26465;&#20214;&#12290;&#30001;&#20110;&#26080;&#27861;&#20445;&#35777;&#36229;&#21442;&#25968;&#20272;&#35745;&#30340;&#27491;&#30830;&#24615;&#65292;&#24182;&#19988;&#36825;&#20123;&#36229;&#21442;&#25968;&#21487;&#20197;&#26174;&#33879;&#24433;&#21709;&#39640;&#26031;&#36807;&#31243;&#25311;&#21512;&#65292;&#22240;&#27492;&#23545;&#20855;&#26377;&#26410;&#30693;&#36229;&#21442;&#25968;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#36827;&#34892;&#29702;&#35770;&#20998;&#26512;&#38750;&#24120;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20043;&#21069;&#25552;&#20986;&#30340;&#20855;&#26377;&#26080;&#36951;&#25022;&#29305;&#24615;&#30340;&#31639;&#27861;&#20165;&#33021;&#22788;&#29702;&#29305;&#27530;&#24773;&#20917;&#19979;&#30340;&#26410;&#30693;&#38271;&#24230;&#23610;&#24230;&#12289;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#33539;&#25968;&#65292;&#24182;&#19988;&#20165;&#36866;&#29992;&#20110;&#39057;&#29575;&#27966;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#21629;&#21517;&#20026;HE-GP-UCB&#65292;&#23427;&#26159;&#31532;&#19968;&#20010;&#20855;&#26377;&#26080;&#36951;&#25022;&#29305;&#24615;&#30340;&#31639;&#27861;&#65292;&#22312;&#20855;&#26377;&#26410;&#30693;&#36229;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#36125;&#21494;&#26031;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimisation requires fitting a Gaussian process model, which in turn requires specifying hyperparameters - most of the theoretical literature assumes those hyperparameters are known. The commonly used maximum likelihood estimator for hyperparameters of the Gaussian process is consistent only if the data fills the space uniformly, which does not have to be the case in Bayesian optimisation. Since no guarantees exist regarding the correctness of hyperparameter estimation, and those hyperparameters can significantly affect the Gaussian process fit, theoretical analysis of Bayesian optimisation with unknown hyperparameters is very challenging. Previously proposed algorithms with the no-regret property were only able to handle the special case of unknown lengthscales, reproducing kernel Hilbert space norm and applied only to the frequentist case. We propose a novel algorithm, HE-GP-UCB, which is the first algorithm enjoying the no-regret property in the case of unknown hyperparame
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#31070;&#32463;&#32593;&#32476;&#21644;Transformer&#22312;&#25968;&#23398;&#25512;&#29702;&#21644;&#27169;&#36816;&#31639;&#20013;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#21644;&#21333;&#23618;Transformer&#22312;&#35299;&#20915;&#22797;&#26434;&#20195;&#25968;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#29305;&#24449;&#12290;&#38416;&#26126;&#20102;&#36793;&#32536;&#26368;&#22823;&#21270;&#21407;&#21017;&#23545;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2402.09469</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#20613;&#31435;&#21494;&#30005;&#36335;&#65306;&#35299;&#38145;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#22312;&#25968;&#23398;&#25512;&#29702;&#21644;&#27169;&#36816;&#31639;&#20013;&#30340;&#28508;&#21147;
&lt;/p&gt;
&lt;p&gt;
Fourier Circuits in Neural Networks: Unlocking the Potential of Large Language Models in Mathematical Reasoning and Modular Arithmetic
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09469
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#31070;&#32463;&#32593;&#32476;&#21644;Transformer&#22312;&#25968;&#23398;&#25512;&#29702;&#21644;&#27169;&#36816;&#31639;&#20013;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#21644;&#21333;&#23618;Transformer&#22312;&#35299;&#20915;&#22797;&#26434;&#20195;&#25968;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#29305;&#24449;&#12290;&#38416;&#26126;&#20102;&#36793;&#32536;&#26368;&#22823;&#21270;&#21407;&#21017;&#23545;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#19981;&#26029;&#21457;&#23637;&#30340;&#32972;&#26223;&#19979;&#65292;&#29702;&#35299;&#31070;&#32463;&#32593;&#32476;&#21644;Transformer&#25152;&#21033;&#29992;&#30340;&#20869;&#37096;&#34920;&#31034;&#26159;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#12290;&#26412;&#30740;&#31350;&#22312;&#36817;&#26399;&#30340;&#30740;&#31350;&#22522;&#30784;&#19978;&#65292;&#23545;&#32593;&#32476;&#37319;&#29992;&#29305;&#23450;&#35745;&#31639;&#31574;&#30053;&#32972;&#21518;&#30340;&#21407;&#22240;&#36827;&#34892;&#20102;&#25506;&#32034;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32858;&#28966;&#20110;&#28041;&#21450;k&#20010;&#36755;&#20837;&#30340;&#22797;&#26434;&#20195;&#25968;&#23398;&#20064;&#20219;&#21153;&#65292;&#21363;&#27169;&#36816;&#31639;&#30340;&#21152;&#27861;&#12290;&#25105;&#20204;&#23545;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#21644;&#21333;&#23618;Transformer&#22312;&#35299;&#20915;&#36825;&#19968;&#20219;&#21153;&#20013;&#23398;&#21040;&#30340;&#29305;&#24449;&#36827;&#34892;&#20102;&#28145;&#20837;&#30340;&#20998;&#26512;&#12290;&#25105;&#20204;&#29702;&#35770;&#26694;&#26550;&#30340;&#19968;&#20010;&#20851;&#38190;&#26159;&#38416;&#26126;&#36793;&#32536;&#26368;&#22823;&#21270;&#21407;&#21017;&#23545;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#37319;&#29992;&#30340;&#29305;&#24449;&#30340;&#24433;&#21709;&#12290;&#20854;&#20013;&#65292;p&#34920;&#31034;&#27169;&#25968;&#65292;Dp&#34920;&#31034;k&#20010;&#36755;&#20837;&#30340;&#27169;&#36816;&#31639;&#25968;&#25454;&#38598;&#65292;m&#34920;&#31034;&#32593;&#32476;&#36755;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09469v1 Announce Type: new  Abstract: In the evolving landscape of machine learning, a pivotal challenge lies in deciphering the internal representations harnessed by neural networks and Transformers. Building on recent progress toward comprehending how networks execute distinct target functions, our study embarks on an exploration of the underlying reasons behind networks adopting specific computational strategies. We direct our focus to the complex algebraic learning task of modular addition involving $k$ inputs. Our research presents a thorough analytical characterization of the features learned by stylized one-hidden layer neural networks and one-layer Transformers in addressing this task.   A cornerstone of our theoretical framework is the elucidation of how the principle of margin maximization shapes the features adopted by one-hidden layer neural networks. Let $p$ denote the modulus, $D_p$ denote the dataset of modular arithmetic with $k$ inputs and $m$ denote the net
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#28151;&#21512;&#31639;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#29305;&#23450;&#32972;&#26223;&#27169;&#22411;&#65292;&#36890;&#36807;&#32467;&#21512;&#22522;&#20110;&#39034;&#24207;&#30340;MCMC&#31639;&#27861;&#21644;&#31232;&#30095;&#24615;&#20551;&#35774;&#23454;&#29616;&#21487;&#25193;&#23637;&#23398;&#20064;&#65292;&#35813;&#26041;&#27861;&#22312;&#20934;&#30830;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#26041;&#38754;&#34920;&#29616;&#33391;&#22909;&#12290;</title><link>https://arxiv.org/abs/2402.07762</link><description>&lt;p&gt;
&#21487;&#25193;&#23637;&#30340;&#31232;&#30095;&#29305;&#23450;&#32972;&#26223;&#19979;&#22240;&#26524;&#31995;&#32479;&#30340;&#32467;&#26500;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Scalable Structure Learning for Sparse Context-Specific Causal Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07762
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#28151;&#21512;&#31639;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#29305;&#23450;&#32972;&#26223;&#27169;&#22411;&#65292;&#36890;&#36807;&#32467;&#21512;&#22522;&#20110;&#39034;&#24207;&#30340;MCMC&#31639;&#27861;&#21644;&#31232;&#30095;&#24615;&#20551;&#35774;&#23454;&#29616;&#21487;&#25193;&#23637;&#23398;&#20064;&#65292;&#35813;&#26041;&#27861;&#22312;&#20934;&#30830;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#26041;&#38754;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24050;&#32463;&#25552;&#20986;&#20102;&#20960;&#31181;&#34920;&#31034;&#20849;&#21516;&#20998;&#24067;&#20998;&#31867;&#21464;&#37327;&#20043;&#38388;&#29305;&#23450;&#32972;&#26223;&#19979;&#20851;&#31995;&#30340;&#26041;&#27861;&#65292;&#24182;&#19988;&#25552;&#20986;&#20102;&#32467;&#26500;&#23398;&#20064;&#31639;&#27861;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#22823;&#37327;&#29305;&#23450;&#32972;&#26223;&#27169;&#22411;&#30340;&#23384;&#22312;&#65292;&#29616;&#26377;&#30340;&#22522;&#20110;&#20248;&#21270;&#30340;&#26041;&#27861;&#22312;&#21487;&#25193;&#23637;&#24615;&#26041;&#38754;&#21463;&#21040;&#38480;&#21046;&#65292;&#32780;&#22522;&#20110;&#32422;&#26463;&#30340;&#26041;&#27861;&#27604;&#32422;&#26463;DAG&#23398;&#20064;&#31639;&#27861;&#26356;&#23481;&#26131;&#20986;&#38169;&#65292;&#22240;&#20026;&#24517;&#39035;&#27979;&#35797;&#26356;&#22810;&#20851;&#31995;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#31639;&#27861;&#26469;&#23398;&#20064;&#29305;&#23450;&#32972;&#26223;&#27169;&#22411;&#65292;&#33021;&#22815;&#25193;&#23637;&#21040;&#25968;&#30334;&#20010;&#21464;&#37327;&#65292;&#24182;&#19988;&#27979;&#35797;&#30340;&#32422;&#26463;&#19981;&#22810;&#20110;&#26631;&#20934;DAG&#23398;&#20064;&#31639;&#27861;&#12290;&#36890;&#36807;&#32467;&#21512;&#22522;&#20110;&#39034;&#24207;&#30340;MCMC&#31639;&#27861;&#21644;&#31867;&#20284;&#20110;DAG&#27169;&#22411;&#24120;&#29992;&#30340;&#31232;&#30095;&#24615;&#20551;&#35774;&#65292;&#23454;&#29616;&#20102;&#21487;&#25193;&#23637;&#30340;&#23398;&#20064;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#31181;&#26041;&#27861;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;Alon&#21644;Balogh&#26368;&#36817;&#25552;&#20986;&#30340;&#19968;&#20010;&#24320;&#25918;&#38382;&#39064;&#30340;&#29305;&#27530;&#24773;&#20917;&#12290;&#32463;&#36807;&#22312;&#21512;&#25104;&#25968;&#25454;&#21644;&#30495;&#23454;&#19990;&#30028;&#31034;&#20363;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#20934;&#30830;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#26041;&#38754;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Several approaches to graphically representing context-specific relations among jointly distributed categorical variables have been proposed, along with structure learning algorithms. While existing optimization-based methods have limited scalability due to the large number of context-specific models, the constraint-based methods are more prone to error than even constraint-based DAG learning algorithms since more relations must be tested. We present a hybrid algorithm for learning context-specific models that scales to hundreds of variables while testing no more constraints than standard DAG learning algorithms. Scalable learning is achieved through a combination of an order-based MCMC algorithm and sparsity assumptions analogous to those typically invoked for DAG models. To implement the method, we solve a special case of an open problem recently posed by Alon and Balogh. The method is shown to perform well on synthetic data and real world examples, in terms of both accuracy and scal
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#35777;&#30740;&#31350;&#65292;&#25581;&#31034;&#20102;&#22312;&#27979;&#35797;&#29615;&#22659;&#20855;&#26377;&#24178;&#25200;&#22240;&#32032;&#26102;&#24433;&#21709;&#35270;&#35273;&#24378;&#21270;&#23398;&#20064;&#20013;&#27867;&#21270;&#24046;&#36317;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#26368;&#23567;&#21270;&#35757;&#32451;&#21644;&#27979;&#35797;&#29615;&#22659;&#20043;&#38388;&#30340;&#34920;&#31034;&#36317;&#31163;&#26159;&#20943;&#23569;&#27867;&#21270;&#24046;&#36317;&#26368;&#20851;&#38190;&#30340;&#22240;&#32032;&#12290;</title><link>https://arxiv.org/abs/2402.02701</link><description>&lt;p&gt;
&#29702;&#35299;&#24433;&#21709;&#35270;&#35273;&#24378;&#21270;&#23398;&#20064;&#20013;&#27867;&#21270;&#24046;&#36317;&#30340;&#22240;&#32032;&#65306;&#29702;&#35770;&#21644;&#23454;&#35777;&#35777;&#25454;
&lt;/p&gt;
&lt;p&gt;
Understanding What Affects Generalization Gap in Visual Reinforcement Learning: Theory and Empirical Evidence
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02701
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#35777;&#30740;&#31350;&#65292;&#25581;&#31034;&#20102;&#22312;&#27979;&#35797;&#29615;&#22659;&#20855;&#26377;&#24178;&#25200;&#22240;&#32032;&#26102;&#24433;&#21709;&#35270;&#35273;&#24378;&#21270;&#23398;&#20064;&#20013;&#27867;&#21270;&#24046;&#36317;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#26368;&#23567;&#21270;&#35757;&#32451;&#21644;&#27979;&#35797;&#29615;&#22659;&#20043;&#38388;&#30340;&#34920;&#31034;&#36317;&#31163;&#26159;&#20943;&#23569;&#27867;&#21270;&#24046;&#36317;&#26368;&#20851;&#38190;&#30340;&#22240;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#26377;&#35768;&#22810;&#21162;&#21147;&#33268;&#21147;&#20110;&#22312;&#35270;&#35273;&#24378;&#21270;&#23398;&#20064;&#20013;&#23398;&#20064;&#23545;&#36830;&#32493;&#25511;&#21046;&#26377;&#29992;&#30340;&#31574;&#30053;&#12290;&#22312;&#36825;&#31181;&#22330;&#26223;&#19979;&#65292;&#23398;&#20064;&#19968;&#20010;&#20855;&#26377;&#27867;&#21270;&#33021;&#21147;&#30340;&#31574;&#30053;&#38750;&#24120;&#37325;&#35201;&#65292;&#22240;&#20026;&#27979;&#35797;&#29615;&#22659;&#21487;&#33021;&#19982;&#35757;&#32451;&#29615;&#22659;&#19981;&#21516;&#65292;&#20363;&#22914;&#22312;&#37096;&#32626;&#36807;&#31243;&#20013;&#23384;&#22312;&#24178;&#25200;&#22240;&#32032;&#12290;&#35768;&#22810;&#23454;&#38469;&#31639;&#27861;&#34987;&#25552;&#20986;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#23427;&#20204;&#20013;&#27809;&#26377;&#19968;&#31181;&#31639;&#27861;&#33021;&#22815;&#20174;&#29702;&#35770;&#19978;&#35299;&#37322;&#27867;&#21270;&#24046;&#36317;&#30340;&#24433;&#21709;&#22240;&#32032;&#20197;&#21450;&#20026;&#20160;&#20040;&#20182;&#20204;&#30340;&#26041;&#27861;&#26377;&#25928;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;&#27979;&#35797;&#29615;&#22659;&#20855;&#26377;&#24178;&#25200;&#22240;&#32032;&#26102;&#29702;&#35770;&#19978;&#22238;&#31572;&#24433;&#21709;&#27867;&#21270;&#24046;&#36317;&#30340;&#20851;&#38190;&#22240;&#32032;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#34920;&#26126;&#65292;&#26368;&#23567;&#21270;&#35757;&#32451;&#21644;&#27979;&#35797;&#29615;&#22659;&#20043;&#38388;&#30340;&#34920;&#31034;&#36317;&#31163;&#65288;&#19982;&#20154;&#31867;&#30452;&#35273;&#19968;&#33268;&#65289;&#23545;&#20110;&#20943;&#23569;&#27867;&#21270;&#24046;&#36317;&#30340;&#25928;&#30410;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#24471;&#21040;&#20102;DM&#25968;&#25454;&#30340;&#23454;&#35777;&#35777;&#25454;&#30340;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, there are many efforts attempting to learn useful policies for continuous control in visual reinforcement learning (RL). In this scenario, it is important to learn a generalizable policy, as the testing environment may differ from the training environment, e.g., there exist distractors during deployment. Many practical algorithms are proposed to handle this problem. However, to the best of our knowledge, none of them provide a theoretical understanding of what affects the generalization gap and why their proposed methods work. In this paper, we bridge this issue by theoretically answering the key factors that contribute to the generalization gap when the testing environment has distractors. Our theories indicate that minimizing the representation distance between training and testing environments, which aligns with human intuition, is the most critical for the benefit of reducing the generalization gap. Our theoretical results are supported by the empirical evidence in the DM
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;NLP&#27169;&#22411;&#30340;&#23884;&#20837;&#23618;&#32423;&#36827;&#34892;&#25805;&#20316;&#65292;&#20511;&#37492;&#20102;&#26368;&#26032;&#30340;&#35299;&#37322;&#24615;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#65292;&#36890;&#36807;&#23884;&#20837;&#36716;&#25442;&#26469;&#28040;&#38500;&#38544;&#21547;&#30340;&#25935;&#24863;&#20449;&#24687;&#65292;&#20174;&#32780;&#23454;&#29616;&#27169;&#22411;&#30340;&#20844;&#24179;&#24615;&#12290;</title><link>http://arxiv.org/abs/2312.06499</link><description>&lt;p&gt;
TaCo&#65306;&#36890;&#36807;&#20449;&#24687;&#35770;&#21644;&#21487;&#35299;&#37322;&#24615;&#22312;NLP&#20013;&#30340;&#36755;&#20986;&#23884;&#20837;&#20013;&#23454;&#29616;&#26377;&#38024;&#23545;&#24615;&#30340;&#27010;&#24565;&#21435;&#38500;
&lt;/p&gt;
&lt;p&gt;
TaCo: Targeted Concept Removal in Output Embeddings for NLP via Information Theory and Explainability. (arXiv:2312.06499v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.06499
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;NLP&#27169;&#22411;&#30340;&#23884;&#20837;&#23618;&#32423;&#36827;&#34892;&#25805;&#20316;&#65292;&#20511;&#37492;&#20102;&#26368;&#26032;&#30340;&#35299;&#37322;&#24615;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#65292;&#36890;&#36807;&#23884;&#20837;&#36716;&#25442;&#26469;&#28040;&#38500;&#38544;&#21547;&#30340;&#25935;&#24863;&#20449;&#24687;&#65292;&#20174;&#32780;&#23454;&#29616;&#27169;&#22411;&#30340;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#27169;&#22411;&#30340;&#20844;&#24179;&#24615;&#24050;&#25104;&#20026;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#12290;&#20449;&#24687;&#35770;&#34920;&#26126;&#65292;&#20026;&#20102;&#23454;&#29616;&#20844;&#24179;&#24615;&#65292;&#27169;&#22411;&#19981;&#24212;&#33021;&#22815;&#39044;&#27979;&#25935;&#24863;&#21464;&#37327;&#65292;&#22914;&#24615;&#21035;&#12289;&#31181;&#26063;&#21644;&#24180;&#40836;&#12290;&#28982;&#32780;&#65292;&#19982;&#36825;&#20123;&#21464;&#37327;&#30456;&#20851;&#30340;&#20449;&#24687;&#36890;&#24120;&#20197;&#38544;&#24335;&#30340;&#26041;&#24335;&#20986;&#29616;&#22312;&#35821;&#35328;&#20013;&#65292;&#36825;&#32473;&#35782;&#21035;&#21644;&#20943;&#23569;&#20559;&#35265;&#24102;&#26469;&#20102;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#22312;NLP&#27169;&#22411;&#30340;&#23884;&#20837;&#23618;&#32423;&#19978;&#25805;&#20316;&#65292;&#29420;&#31435;&#20110;&#20855;&#20307;&#30340;&#26550;&#26500;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20511;&#37492;&#20102;&#26368;&#36817;&#35299;&#37322;&#24615;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#30340;&#36827;&#23637;&#65292;&#24182;&#37319;&#29992;&#23884;&#20837;&#36716;&#25442;&#26469;&#28040;&#38500;&#36873;&#23450;&#21464;&#37327;&#20013;&#30340;&#38544;&#24335;&#20449;&#24687;&#12290;&#36890;&#36807;&#30452;&#25509;&#25805;&#32437;&#26368;&#21518;&#19968;&#23618;&#30340;&#23884;&#20837;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#26080;&#32541;&#38598;&#25104;&#21040;&#29616;&#26377;&#27169;&#22411;&#20013;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#37325;&#22823;&#20462;&#25913;&#25110;&#37325;&#35757;&#32451;&#12290;&#22312;&#35780;&#20272;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#21518;&#22788;&#29702;&#26041;&#27861;&#26174;&#33879;&#38477;&#20302;&#20102;&#19982;&#24615;&#21035;&#30456;&#20851;&#30340;&#20851;&#32852;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The fairness of Natural Language Processing (NLP) models has emerged as a crucial concern. Information theory indicates that to achieve fairness, a model should not be able to predict sensitive variables, such as gender, ethnicity, and age. However, information related to these variables often appears implicitly in language, posing a challenge in identifying and mitigating biases effectively. To tackle this issue, we present a novel approach that operates at the embedding level of an NLP model, independent of the specific architecture. Our method leverages insights from recent advances in XAI techniques and employs an embedding transformation to eliminate implicit information from a selected variable. By directly manipulating the embeddings in the final layer, our approach enables a seamless integration into existing models without requiring significant modifications or retraining. In evaluation, we show that the proposed post-hoc approach significantly reduces gender-related associati
&lt;/p&gt;</description></item></channel></rss>