<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#20171;&#32461;&#20102;&#22312;&#37327;&#23376;&#20648;&#22791;&#35745;&#31639;&#20013;&#22238;&#22768;&#24577;&#24615;&#36136;&#30340;&#19981;&#21516;&#23618;&#27425;&#65292;&#21253;&#25324;&#38750;&#24179;&#31283;&#24615;ESP&#21644;&#23376;&#31995;&#32479;&#20855;&#26377;ESP&#30340;&#23376;&#31354;&#38388;/&#23376;&#38598;ESP&#12290;&#36827;&#34892;&#20102;&#25968;&#20540;&#28436;&#31034;&#21644;&#35760;&#24518;&#23481;&#37327;&#35745;&#31639;&#20197;&#39564;&#35777;&#36825;&#20123;&#23450;&#20041;&#12290;</title><link>https://arxiv.org/abs/2403.02686</link><description>&lt;p&gt;
&#37327;&#23376;&#20648;&#22791;&#35745;&#31639;&#20013;&#30340;&#22238;&#22768;&#24577;&#24615;&#36136;&#31561;&#32423;
&lt;/p&gt;
&lt;p&gt;
Hierarchy of the echo state property in quantum reservoir computing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02686
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#22312;&#37327;&#23376;&#20648;&#22791;&#35745;&#31639;&#20013;&#22238;&#22768;&#24577;&#24615;&#36136;&#30340;&#19981;&#21516;&#23618;&#27425;&#65292;&#21253;&#25324;&#38750;&#24179;&#31283;&#24615;ESP&#21644;&#23376;&#31995;&#32479;&#20855;&#26377;ESP&#30340;&#23376;&#31354;&#38388;/&#23376;&#38598;ESP&#12290;&#36827;&#34892;&#20102;&#25968;&#20540;&#28436;&#31034;&#21644;&#35760;&#24518;&#23481;&#37327;&#35745;&#31639;&#20197;&#39564;&#35777;&#36825;&#20123;&#23450;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22238;&#22768;&#24577;&#24615;&#36136;&#65288;ESP&#65289;&#20195;&#34920;&#20102;&#20648;&#22791;&#35745;&#31639;&#65288;RC&#65289;&#26694;&#26550;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#27010;&#24565;&#65292;&#36890;&#36807;&#23545;&#21021;&#22987;&#29366;&#24577;&#21644;&#36828;&#26399;&#36755;&#20837;&#19981;&#21152;&#27495;&#35270;&#26469;&#30830;&#20445;&#20648;&#33988;&#32593;&#32476;&#30340;&#20165;&#36755;&#20986;&#35757;&#32451;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30340;ESP&#23450;&#20041;&#24182;&#26410;&#25551;&#36848;&#21487;&#33021;&#28436;&#21464;&#32479;&#35745;&#23646;&#24615;&#30340;&#38750;&#24179;&#31283;&#31995;&#32479;&#12290;&#20026;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#31867;&#26032;&#30340;ESP&#65306;\textit{&#38750;&#24179;&#31283;ESP}&#65292;&#29992;&#20110;&#28508;&#22312;&#38750;&#24179;&#31283;&#31995;&#32479;&#65292;&#21644;\textit{&#23376;&#31354;&#38388;/&#23376;&#38598;ESP}&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;ESP&#30340;&#23376;&#31995;&#32479;&#30340;&#31995;&#32479;&#12290;&#26681;&#25454;&#36825;&#20123;&#23450;&#20041;&#65292;&#25105;&#20204;&#22312;&#37327;&#23376;&#20648;&#22791;&#35745;&#31639;&#65288;QRC&#65289;&#26694;&#26550;&#20013;&#25968;&#20540;&#28436;&#31034;&#20102;&#38750;&#24179;&#31283;ESP&#19982;&#20856;&#22411;&#21704;&#23494;&#39039;&#21160;&#21147;&#23398;&#21644;&#20351;&#29992;&#38750;&#32447;&#24615;&#33258;&#22238;&#24402;&#31227;&#21160;&#24179;&#22343;&#65288;NARMA&#65289;&#20219;&#21153;&#30340;&#36755;&#20837;&#32534;&#30721;&#26041;&#27861;&#20043;&#38388;&#30340;&#23545;&#24212;&#20851;&#31995;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#35745;&#31639;&#32447;&#24615;/&#38750;&#32447;&#24615;&#35760;&#24518;&#23481;&#37327;&#26469;&#30830;&#35748;&#36825;&#31181;&#23545;&#24212;&#20851;&#31995;&#65292;&#20197;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02686v1 Announce Type: cross  Abstract: The echo state property (ESP) represents a fundamental concept in the reservoir computing (RC) framework that ensures output-only training of reservoir networks by being agnostic to the initial states and far past inputs. However, the traditional definition of ESP does not describe possible non-stationary systems in which statistical properties evolve. To address this issue, we introduce two new categories of ESP: \textit{non-stationary ESP}, designed for potentially non-stationary systems, and \textit{subspace/subset ESP}, designed for systems whose subsystems have ESP. Following the definitions, we numerically demonstrate the correspondence between non-stationary ESP in the quantum reservoir computer (QRC) framework with typical Hamiltonian dynamics and input encoding methods using non-linear autoregressive moving-average (NARMA) tasks. We also confirm the correspondence by computing linear/non-linear memory capacities that quantify 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#35299;&#20915;&#20302;&#31209;&#29615;&#22659;&#20013;&#20855;&#26377;&#19978;&#19979;&#25991;&#20449;&#24687;&#30340;&#36172;&#24466;&#38382;&#39064;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#20854;&#20013;&#21253;&#25324;&#31574;&#30053;&#35780;&#20272;&#12289;&#26368;&#20339;&#31574;&#30053;&#35782;&#21035;&#21644;&#36951;&#25022;&#26368;&#23567;&#21270;&#65292;&#24182;&#19988;&#22312;&#26368;&#20339;&#31574;&#30053;&#35782;&#21035;&#21644;&#31574;&#30053;&#35780;&#20272;&#26041;&#38754;&#30340;&#31639;&#27861;&#20960;&#20046;&#26159;&#26497;&#23567;&#26497;&#22823;&#26368;&#20248;&#30340;&#12290;</title><link>https://arxiv.org/abs/2402.15739</link><description>&lt;p&gt;
&#20302;&#31209;&#36172;&#24466;&#36890;&#36807;&#32039;&#32477;&#23545;&#21040;&#26080;&#31351;&#22855;&#24322;&#23376;&#31354;&#38388;&#24674;&#22797;
&lt;/p&gt;
&lt;p&gt;
Low-Rank Bandits via Tight Two-to-Infinity Singular Subspace Recovery
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15739
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#35299;&#20915;&#20302;&#31209;&#29615;&#22659;&#20013;&#20855;&#26377;&#19978;&#19979;&#25991;&#20449;&#24687;&#30340;&#36172;&#24466;&#38382;&#39064;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#20854;&#20013;&#21253;&#25324;&#31574;&#30053;&#35780;&#20272;&#12289;&#26368;&#20339;&#31574;&#30053;&#35782;&#21035;&#21644;&#36951;&#25022;&#26368;&#23567;&#21270;&#65292;&#24182;&#19988;&#22312;&#26368;&#20339;&#31574;&#30053;&#35782;&#21035;&#21644;&#31574;&#30053;&#35780;&#20272;&#26041;&#38754;&#30340;&#31639;&#27861;&#20960;&#20046;&#26159;&#26497;&#23567;&#26497;&#22823;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#20302;&#31209;&#32467;&#26500;&#30340;&#24773;&#22659;&#36172;&#24466;&#38382;&#39064;&#65292;&#22312;&#27599;&#19968;&#36718;&#20013;&#65292;&#22914;&#26524;&#36873;&#25321;&#20102;(&#24773;&#22659;&#65292;&#21160;&#20316;)&#23545;$(i,j)\in [m]\times [n]$&#65292;&#23398;&#20064;&#32773;&#20250;&#35266;&#23519;&#19968;&#20010;&#26410;&#30693;&#20302;&#31209;&#22870;&#21169;&#30697;&#38453;&#30340;$(i,j)$-th&#20837;&#21475;&#30340;&#22024;&#26434;&#26679;&#26412;&#12290;&#36830;&#32493;&#30340;&#24773;&#22659;&#20197;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#26041;&#24335;&#38543;&#26426;&#29983;&#25104;&#24182;&#36879;&#38706;&#32473;&#23398;&#20064;&#32773;&#12290;&#23545;&#20110;&#36825;&#26679;&#30340;&#36172;&#24466;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#39640;&#25928;&#30340;&#31639;&#27861;&#29992;&#20110;&#31574;&#30053;&#35780;&#20272;&#12289;&#26368;&#20339;&#31574;&#30053;&#35782;&#21035;&#21644;&#36951;&#25022;&#26368;&#23567;&#21270;&#12290;&#23545;&#20110;&#31574;&#30053;&#35780;&#20272;&#21644;&#26368;&#20339;&#31574;&#30053;&#35782;&#21035;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#20960;&#20046;&#26159;&#26497;&#23567;&#26497;&#22823;&#26368;&#20248;&#30340;&#12290;&#20363;&#22914;&#65292;&#20026;&#20102;&#20197;&#33267;&#23569;$1-\delta$&#30340;&#27010;&#29575;&#36820;&#22238;&#19968;&#20010;$\varepsilon$-&#26368;&#20339;&#31574;&#30053;&#65292;&#36890;&#24120;&#38656;&#35201;&#30340;&#26679;&#26412;&#25968;&#22823;&#33268;&#25353;&#29031;${m+n\over \varepsilon^2}\log(1/\delta)$&#26469;&#34913;&#37327;&#12290;&#25105;&#20204;&#30340;&#36951;&#25022;&#26368;&#23567;&#21270;&#31639;&#27861;&#20139;&#26377;&#30340;&#26497;&#23567;&#26497;&#22823;&#20445;&#35777;&#25353;&#29031;$r^{7/4}(m+n)^{3/4}\sqrt{T}$&#32553;&#25918;&#65292;&#36825;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#12290;&#25152;&#26377;&#25552;&#20986;&#30340;&#31639;&#27861;&#21253;&#25324;&#20004;&#20010;&#38454;&#27573;&#65306;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15739v1 Announce Type: new  Abstract: We study contextual bandits with low-rank structure where, in each round, if the (context, arm) pair $(i,j)\in [m]\times [n]$ is selected, the learner observes a noisy sample of the $(i,j)$-th entry of an unknown low-rank reward matrix. Successive contexts are generated randomly in an i.i.d. manner and are revealed to the learner. For such bandits, we present efficient algorithms for policy evaluation, best policy identification and regret minimization. For policy evaluation and best policy identification, we show that our algorithms are nearly minimax optimal. For instance, the number of samples required to return an $\varepsilon$-optimal policy with probability at least $1-\delta$ typically scales as ${m+n\over \varepsilon^2}\log(1/\delta)$. Our regret minimization algorithm enjoys minimax guarantees scaling as $r^{7/4}(m+n)^{3/4}\sqrt{T}$, which improves over existing algorithms. All the proposed algorithms consist of two phases: they
&lt;/p&gt;</description></item><item><title>LoRA+&#36890;&#36807;&#35774;&#32622;&#19981;&#21516;&#30340;&#23398;&#20064;&#29575;&#26469;&#25913;&#36827;&#21407;&#22987;LoRA&#30340;&#20302;&#25928;&#29575;&#38382;&#39064;&#65292;&#22312;&#20445;&#25345;&#35745;&#31639;&#25104;&#26412;&#19981;&#21464;&#30340;&#24773;&#20917;&#19979;&#25552;&#39640;&#20102;&#27169;&#22411;&#24615;&#33021;&#21644;&#24494;&#35843;&#36895;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.12354</link><description>&lt;p&gt;
LoRA+: &#22823;&#35268;&#27169;&#27169;&#22411;&#30340;&#39640;&#25928;&#20302;&#31209;&#36866;&#24212;&#24615;
&lt;/p&gt;
&lt;p&gt;
LoRA+: Efficient Low Rank Adaptation of Large Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12354
&lt;/p&gt;
&lt;p&gt;
LoRA+&#36890;&#36807;&#35774;&#32622;&#19981;&#21516;&#30340;&#23398;&#20064;&#29575;&#26469;&#25913;&#36827;&#21407;&#22987;LoRA&#30340;&#20302;&#25928;&#29575;&#38382;&#39064;&#65292;&#22312;&#20445;&#25345;&#35745;&#31639;&#25104;&#26412;&#19981;&#21464;&#30340;&#24773;&#20917;&#19979;&#25552;&#39640;&#20102;&#27169;&#22411;&#24615;&#33021;&#21644;&#24494;&#35843;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20302;&#31209;&#36866;&#24212;&#65288;LoRA&#65289;&#26368;&#21021;&#30001;&#32993;&#31561;&#20154;&#65288;2021&#24180;&#65289;&#24341;&#20837;&#65292;&#23548;&#33268;&#23545;&#20855;&#26377;&#22823;&#23485;&#24230;&#65288;&#23884;&#20837;&#32500;&#24230;&#65289;&#30340;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#26102;&#34920;&#29616;&#20122;&#20248;&#12290;&#36825;&#26159;&#22240;&#20026;LoRA&#20013;&#30340;&#36866;&#37197;&#22120;&#30697;&#38453;A&#21644;B&#20351;&#29992;&#30456;&#21516;&#30340;&#23398;&#20064;&#29575;&#36827;&#34892;&#26356;&#26032;&#12290;&#36890;&#36807;&#23545;&#22823;&#23485;&#24230;&#32593;&#32476;&#36827;&#34892;&#32553;&#25918;&#21442;&#25968;&#30340;&#35770;&#35777;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23545;&#36866;&#37197;&#22120;&#30697;&#38453;A&#21644;B&#20351;&#29992;&#30456;&#21516;&#30340;&#23398;&#20064;&#29575;&#19981;&#21033;&#20110;&#26377;&#25928;&#30340;&#29305;&#24449;&#23398;&#20064;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#34920;&#26126;LoRA&#30340;&#36825;&#31181;&#27425;&#20248;&#24615;&#21487;&#20197;&#31616;&#21333;&#22320;&#36890;&#36807;&#20026;LoRA&#36866;&#37197;&#22120;&#30697;&#38453;A&#21644;B&#35774;&#32622;&#19981;&#21516;&#30340;&#23398;&#20064;&#29575;&#20197;&#21450;&#19968;&#20010;&#31934;&#24515;&#36873;&#25321;&#30340;&#27604;&#29575;&#26469;&#36827;&#34892;&#26657;&#27491;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#25552;&#20986;&#30340;&#31639;&#27861;&#31216;&#20026;LoRA$+$&#12290;&#22312;&#25105;&#20204;&#24191;&#27867;&#30340;&#23454;&#39564;&#35777;&#26126;&#20013;&#65292;LoRA$+$&#22312;&#30456;&#21516;&#35745;&#31639;&#25104;&#26412;&#19979;&#25552;&#39640;&#20102;&#24615;&#33021;&#65288;1-2&#65285;&#30340;&#25913;&#36827;&#65289;&#21644;&#24494;&#35843;&#36895;&#24230;&#65288;&#26368;&#22810;&#25552;&#36895;&#32422;2&#20493;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12354v1 Announce Type: cross  Abstract: In this paper, we show that Low Rank Adaptation (LoRA) as originally introduced in Hu et al. (2021) leads to suboptimal finetuning of models with large width (embedding dimension). This is due to the fact that adapter matrices A and B in LoRA are updated with the same learning rate. Using scaling arguments for large width networks, we demonstrate that using the same learning rate for A and B does not allow efficient feature learning. We then show that this suboptimality of LoRA can be corrected simply by setting different learning rates for the LoRA adapter matrices A and B with a well-chosen ratio. We call this proposed algorithm LoRA$+$. In our extensive experiments, LoRA$+$ improves performance (1-2 $\%$ improvements) and finetuning speed (up to $\sim$ 2X SpeedUp), at the same computational cost as LoRA.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#22343;&#22330;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243; (SDE) &#30340;&#31283;&#24577;&#20998;&#24067;&#20013;&#37319;&#26679;&#30340;&#22797;&#26434;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#32806;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#22312;&#22810;&#31181;&#24773;&#20917;&#19979;&#25552;&#20379;&#25913;&#36827;&#30340;&#20445;&#35777;&#65292;&#21253;&#25324;&#22312;&#22343;&#22330;&#21306;&#22495;&#20248;&#21270;&#26576;&#20123;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#26356;&#22909;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2402.07355</link><description>&lt;p&gt;
&#20174;&#22343;&#22330;&#31283;&#24577;&#20998;&#24067;&#20013;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Sampling from the Mean-Field Stationary Distribution
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07355
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#22343;&#22330;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243; (SDE) &#30340;&#31283;&#24577;&#20998;&#24067;&#20013;&#37319;&#26679;&#30340;&#22797;&#26434;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#32806;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#22312;&#22810;&#31181;&#24773;&#20917;&#19979;&#25552;&#20379;&#25913;&#36827;&#30340;&#20445;&#35777;&#65292;&#21253;&#25324;&#22312;&#22343;&#22330;&#21306;&#22495;&#20248;&#21270;&#26576;&#20123;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#26356;&#22909;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20174;&#22343;&#22330;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243; (SDE) &#30340;&#31283;&#24577;&#20998;&#24067;&#20013;&#37319;&#26679;&#30340;&#22797;&#26434;&#24615;&#65292;&#25110;&#32773;&#31561;&#20215;&#22320;&#65292;&#21363;&#21253;&#21547;&#20132;&#20114;&#39033;&#30340;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#19978;&#30340;&#26368;&#23567;&#21270;&#20989;&#25968;&#30340;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#27934;&#23519;&#26159;&#23558;&#36825;&#20010;&#38382;&#39064;&#30340;&#20004;&#20010;&#20851;&#38190;&#26041;&#38754;&#35299;&#32806;&#65306;(1) &#36890;&#36807;&#26377;&#38480;&#31890;&#23376;&#31995;&#32479;&#36924;&#36817;&#22343;&#22330;SDE&#65292;&#36890;&#36807;&#26102;&#38388;&#22343;&#21248;&#20256;&#25773;&#28151;&#27788;&#65292;&#21644;(2) &#36890;&#36807;&#26631;&#20934;&#23545;&#25968;&#20985;&#25277;&#26679;&#22120;&#20174;&#26377;&#38480;&#31890;&#23376;&#31283;&#24577;&#20998;&#24067;&#20013;&#37319;&#26679;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#27010;&#24565;&#19978;&#26356;&#31616;&#21333;&#65292;&#20854;&#28789;&#27963;&#24615;&#20801;&#35768;&#32467;&#21512;&#29992;&#20110;&#31639;&#27861;&#21644;&#29702;&#35770;&#30340;&#26368;&#26032;&#25216;&#26415;&#12290;&#36825;&#23548;&#33268;&#22312;&#35768;&#22810;&#35774;&#32622;&#20013;&#25552;&#20379;&#20102;&#25913;&#36827;&#30340;&#20445;&#35777;&#65292;&#21253;&#25324;&#22312;&#22343;&#22330;&#21306;&#22495;&#20248;&#21270;&#26576;&#20123;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#26356;&#22909;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the complexity of sampling from the stationary distribution of a mean-field SDE, or equivalently, the complexity of minimizing a functional over the space of probability measures which includes an interaction term.   Our main insight is to decouple the two key aspects of this problem: (1) approximation of the mean-field SDE via a finite-particle system, via uniform-in-time propagation of chaos, and (2) sampling from the finite-particle stationary distribution, via standard log-concave samplers. Our approach is conceptually simpler and its flexibility allows for incorporating the state-of-the-art for both algorithms and theory. This leads to improved guarantees in numerous settings, including better guarantees for optimizing certain two-layer neural networks in the mean-field regime.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28201;&#24230;&#32553;&#25918;&#23545;&#31526;&#21512;&#39044;&#27979;&#26041;&#27861;&#30340;&#24433;&#21709;&#65292;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#21457;&#29616;&#65292;&#26657;&#20934;&#23545;&#33258;&#36866;&#24212;C&#26041;&#27861;&#20135;&#29983;&#20102;&#26377;&#23475;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2402.05806</link><description>&lt;p&gt;
&#20851;&#20110;&#28145;&#24230;&#20998;&#31867;&#22120;&#30340;&#26657;&#20934;&#21644;&#31526;&#21512;&#39044;&#27979;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Calibration and Conformal Prediction of Deep Classifiers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05806
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28201;&#24230;&#32553;&#25918;&#23545;&#31526;&#21512;&#39044;&#27979;&#26041;&#27861;&#30340;&#24433;&#21709;&#65292;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#21457;&#29616;&#65292;&#26657;&#20934;&#23545;&#33258;&#36866;&#24212;C&#26041;&#27861;&#20135;&#29983;&#20102;&#26377;&#23475;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#20998;&#31867;&#24212;&#29992;&#20013;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#22522;&#20110;&#20998;&#31867;&#22120;&#30340;&#39044;&#27979;&#38656;&#35201;&#20276;&#38543;&#19968;&#20123;&#32622;&#20449;&#24230;&#25351;&#31034;&#12290;&#38024;&#23545;&#36825;&#20010;&#30446;&#26631;&#65292;&#26377;&#20004;&#31181;&#27969;&#34892;&#30340;&#21518;&#22788;&#29702;&#26041;&#27861;&#65306;1&#65289;&#26657;&#20934;&#65306;&#20462;&#25913;&#20998;&#31867;&#22120;&#30340;softmax&#20540;&#65292;&#20351;&#20854;&#26368;&#22823;&#20540;&#65288;&#19982;&#39044;&#27979;&#30456;&#20851;&#65289;&#26356;&#22909;&#22320;&#20272;&#35745;&#27491;&#30830;&#27010;&#29575;&#65307;&#21644;2&#65289;&#31526;&#21512;&#39044;&#27979;&#65288;CP&#65289;&#65306;&#35774;&#35745;&#19968;&#20010;&#22522;&#20110;softmax&#20540;&#30340;&#20998;&#25968;&#65292;&#20174;&#20013;&#20135;&#29983;&#19968;&#32452;&#39044;&#27979;&#65292;&#20855;&#26377;&#29702;&#35770;&#19978;&#20445;&#35777;&#27491;&#30830;&#31867;&#21035;&#36793;&#38469;&#35206;&#30422;&#30340;&#29305;&#24615;&#12290;&#23613;&#31649;&#22312;&#23454;&#36341;&#20013;&#20004;&#31181;&#25351;&#31034;&#37117;&#21487;&#33021;&#26159;&#38656;&#35201;&#30340;&#65292;&#20294;&#21040;&#30446;&#21069;&#20026;&#27490;&#23427;&#20204;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#23578;&#26410;&#24471;&#21040;&#30740;&#31350;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#28201;&#24230;&#32553;&#25918;&#65292;&#36825;&#26159;&#26368;&#24120;&#35265;&#30340;&#26657;&#20934;&#25216;&#26415;&#65292;&#23545;&#37325;&#35201;&#30340;CP&#26041;&#27861;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#39318;&#20808;&#36827;&#34892;&#20102;&#19968;&#39033;&#24191;&#27867;&#30340;&#23454;&#35777;&#30740;&#31350;&#65292;&#20854;&#20013;&#26174;&#31034;&#20102;&#19968;&#20123;&#37325;&#35201;&#30340;&#27934;&#23519;&#65292;&#20854;&#20013;&#21253;&#25324;&#20196;&#20154;&#24778;&#35766;&#30340;&#21457;&#29616;&#65292;&#21363;&#26657;&#20934;&#23545;&#27969;&#34892;&#30340;&#33258;&#36866;&#24212;C&#26041;&#27861;&#20135;&#29983;&#20102;&#26377;&#23475;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many classification applications, the prediction of a deep neural network (DNN) based classifier needs to be accompanied with some confidence indication. Two popular post-processing approaches for that aim are: 1) calibration: modifying the classifier's softmax values such that their maximum (associated with the prediction) better estimates the correctness probability; and 2) conformal prediction (CP): devising a score (based on the softmax values) from which a set of predictions with theoretically guaranteed marginal coverage of the correct class is produced. While in practice both types of indications can be desired, so far the interplay between them has not been investigated. Toward filling this gap, in this paper we study the effect of temperature scaling, arguably the most common calibration technique, on prominent CP methods. We start with an extensive empirical study that among other insights shows that, surprisingly, calibration has a detrimental effect on popular adaptive C
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#20272;&#35745;Hessian&#30697;&#38453;&#36870;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;Robbins-Monro&#36807;&#31243;&#65292;&#33021;&#22815; drastical reducescomputational complexity,&#24182;&#21457;&#23637;&#20102;&#36890;&#29992;&#30340;&#38543;&#26426;&#29275;&#39039;&#31639;&#27861;&#65292;&#30740;&#31350;&#20102;&#25152;&#25552;&#26041;&#27861;&#30340;&#28176;&#36827;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2401.10923</link><description>&lt;p&gt;
&#22312;&#20855;&#26377;&#36890;&#29992;&#38543;&#26426;&#29275;&#39039;&#31639;&#27861;&#24212;&#29992;&#20110;&#38543;&#26426;&#20248;&#21270;&#30340;&#24773;&#20917;&#19979;&#65292;&#20851;&#20110;Hessian&#30697;&#38453;&#30340;&#36870;&#30340;&#22312;&#32447;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Online estimation of the inverse of the Hessian for stochastic optimization with application to universal stochastic Newton algorithms. (arXiv:2401.10923v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10923
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#20272;&#35745;Hessian&#30697;&#38453;&#36870;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;Robbins-Monro&#36807;&#31243;&#65292;&#33021;&#22815; drastical reducescomputational complexity,&#24182;&#21457;&#23637;&#20102;&#36890;&#29992;&#30340;&#38543;&#26426;&#29275;&#39039;&#31639;&#27861;&#65292;&#30740;&#31350;&#20102;&#25152;&#25552;&#26041;&#27861;&#30340;&#28176;&#36827;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#20197;&#26399;&#26395;&#24418;&#24335;&#34920;&#31034;&#30340;&#20984;&#20989;&#25968;&#30340;&#27425;&#20248;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#30452;&#25509;&#36882;&#24402;&#20272;&#35745;&#36870;Hessian&#30697;&#38453;&#30340;&#25216;&#26415;&#65292;&#37319;&#29992;&#20102;Robbins-Monro&#36807;&#31243;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#22823;&#24133;&#38477;&#20302;&#35745;&#31639;&#22797;&#26434;&#24615;&#65292;&#24182;&#19988;&#20801;&#35768;&#24320;&#21457;&#36890;&#29992;&#30340;&#38543;&#26426;&#29275;&#39039;&#26041;&#27861;&#65292;&#24182;&#30740;&#31350;&#25152;&#25552;&#26041;&#27861;&#30340;&#28176;&#36817;&#25928;&#29575;&#12290;&#36825;&#39033;&#24037;&#20316;&#25193;&#23637;&#20102;&#22312;&#38543;&#26426;&#20248;&#21270;&#20013;&#20108;&#38454;&#31639;&#27861;&#30340;&#24212;&#29992;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper addresses second-order stochastic optimization for estimating the minimizer of a convex function written as an expectation. A direct recursive estimation technique for the inverse Hessian matrix using a Robbins-Monro procedure is introduced. This approach enables to drastically reduces computational complexity. Above all, it allows to develop universal stochastic Newton methods and investigate the asymptotic efficiency of the proposed approach. This work so expands the application scope of secondorder algorithms in stochastic optimization.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#32508;&#36848;&#20102;&#28145;&#24230;&#23398;&#20064;&#30340;&#32479;&#35745;&#29702;&#35770;&#65292;&#21253;&#25324;&#36817;&#20284;&#26041;&#27861;&#12289;&#35757;&#32451;&#21160;&#24577;&#21644;&#29983;&#25104;&#27169;&#22411;&#12290;&#22312;&#38750;&#21442;&#25968;&#26694;&#26550;&#20013;&#65292;&#32467;&#26524;&#25581;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#36807;&#24230;&#39118;&#38505;&#30340;&#24555;&#36895;&#25910;&#25947;&#36895;&#29575;&#65292;&#20197;&#21450;&#22914;&#20309;&#36890;&#36807;&#26799;&#24230;&#26041;&#27861;&#35757;&#32451;&#32593;&#32476;&#20197;&#25214;&#21040;&#33391;&#22909;&#30340;&#27867;&#21270;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2401.07187</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#30340;&#32479;&#35745;&#29702;&#35770;&#32508;&#36848;&#65306;&#36817;&#20284;&#65292;&#35757;&#32451;&#21160;&#24577;&#21644;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Survey on Statistical Theory of Deep Learning: Approximation, Training Dynamics, and Generative Models. (arXiv:2401.07187v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.07187
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#32508;&#36848;&#20102;&#28145;&#24230;&#23398;&#20064;&#30340;&#32479;&#35745;&#29702;&#35770;&#65292;&#21253;&#25324;&#36817;&#20284;&#26041;&#27861;&#12289;&#35757;&#32451;&#21160;&#24577;&#21644;&#29983;&#25104;&#27169;&#22411;&#12290;&#22312;&#38750;&#21442;&#25968;&#26694;&#26550;&#20013;&#65292;&#32467;&#26524;&#25581;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#36807;&#24230;&#39118;&#38505;&#30340;&#24555;&#36895;&#25910;&#25947;&#36895;&#29575;&#65292;&#20197;&#21450;&#22914;&#20309;&#36890;&#36807;&#26799;&#24230;&#26041;&#27861;&#35757;&#32451;&#32593;&#32476;&#20197;&#25214;&#21040;&#33391;&#22909;&#30340;&#27867;&#21270;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#25991;&#31456;&#20013;&#65292;&#25105;&#20204;&#20174;&#19977;&#20010;&#35282;&#24230;&#22238;&#39038;&#20102;&#20851;&#20110;&#31070;&#32463;&#32593;&#32476;&#32479;&#35745;&#29702;&#35770;&#30340;&#25991;&#29486;&#12290;&#31532;&#19968;&#37096;&#20998;&#22238;&#39038;&#20102;&#22312;&#22238;&#24402;&#25110;&#20998;&#31867;&#30340;&#38750;&#21442;&#25968;&#26694;&#26550;&#19979;&#20851;&#20110;&#31070;&#32463;&#32593;&#32476;&#36807;&#24230;&#39118;&#38505;&#30340;&#32467;&#26524;&#12290;&#36825;&#20123;&#32467;&#26524;&#20381;&#36182;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26174;&#24335;&#26500;&#36896;&#65292;&#20197;&#21450;&#37319;&#29992;&#20102;&#36817;&#20284;&#29702;&#35770;&#30340;&#24037;&#20855;&#65292;&#23548;&#33268;&#36807;&#24230;&#39118;&#38505;&#30340;&#24555;&#36895;&#25910;&#25947;&#36895;&#29575;&#12290;&#36890;&#36807;&#36825;&#20123;&#26500;&#36896;&#65292;&#21487;&#20197;&#29992;&#26679;&#26412;&#22823;&#23567;&#12289;&#25968;&#25454;&#32500;&#24230;&#21644;&#20989;&#25968;&#24179;&#28369;&#24615;&#26469;&#34920;&#36798;&#32593;&#32476;&#30340;&#23485;&#24230;&#21644;&#28145;&#24230;&#12290;&#28982;&#32780;&#65292;&#20182;&#20204;&#30340;&#22522;&#26412;&#20998;&#26512;&#20165;&#36866;&#29992;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#39640;&#24230;&#38750;&#20984;&#30340;&#20840;&#23616;&#26497;&#23567;&#20540;&#28857;&#12290;&#36825;&#20419;&#20351;&#25105;&#20204;&#22312;&#31532;&#20108;&#37096;&#20998;&#22238;&#39038;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#21160;&#24577;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#22238;&#39038;&#20102;&#37027;&#20123;&#35797;&#22270;&#22238;&#31572;&#8220;&#22522;&#20110;&#26799;&#24230;&#26041;&#27861;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#22914;&#20309;&#25214;&#21040;&#33021;&#22815;&#22312;&#26410;&#35265;&#25968;&#25454;&#19978;&#26377;&#33391;&#22909;&#27867;&#21270;&#24615;&#33021;&#30340;&#35299;&#8221;&#30340;&#35770;&#25991;&#12290;&#23588;&#20854;&#26159;&#20004;&#20010;&#30693;&#21517;&#30340;
&lt;/p&gt;
&lt;p&gt;
In this article, we review the literature on statistical theories of neural networks from three perspectives. In the first part, results on excess risks for neural networks are reviewed in the nonparametric framework of regression or classification. These results rely on explicit constructions of neural networks, leading to fast convergence rates of excess risks, in that tools from the approximation theory are adopted. Through these constructions, the width and depth of the networks can be expressed in terms of sample size, data dimension, and function smoothness. Nonetheless, their underlying analysis only applies to the global minimizer in the highly non-convex landscape of deep neural networks. This motivates us to review the training dynamics of neural networks in the second part. Specifically, we review papers that attempt to answer ``how the neural network trained via gradient-based methods finds the solution that can generalize well on unseen data.'' In particular, two well-know
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#22312;Wasserstein&#31354;&#38388;&#20013;&#24212;&#29992;&#36817;&#31471;&#26799;&#24230;&#19979;&#38477;&#65292;&#35777;&#26126;&#20102;&#22522;&#20110;&#27969;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#29983;&#25104;&#25968;&#25454;&#20998;&#24067;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2310.17582</link><description>&lt;p&gt;
&#22312;Wasserstein&#31354;&#38388;&#20013;&#36890;&#36807;&#36817;&#31471;&#26799;&#24230;&#19979;&#38477;&#23454;&#29616;&#22522;&#20110;&#27969;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Convergence of flow-based generative models via proximal gradient descent in Wasserstein space. (arXiv:2310.17582v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17582
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#22312;Wasserstein&#31354;&#38388;&#20013;&#24212;&#29992;&#36817;&#31471;&#26799;&#24230;&#19979;&#38477;&#65292;&#35777;&#26126;&#20102;&#22522;&#20110;&#27969;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#29983;&#25104;&#25968;&#25454;&#20998;&#24067;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#27969;&#30340;&#29983;&#25104;&#27169;&#22411;&#22312;&#35745;&#31639;&#25968;&#25454;&#29983;&#25104;&#21644;&#20284;&#28982;&#20989;&#25968;&#26041;&#38754;&#20855;&#26377;&#19968;&#23450;&#30340;&#20248;&#21183;&#65292;&#24182;&#19988;&#26368;&#36817;&#22312;&#23454;&#35777;&#34920;&#29616;&#19978;&#26174;&#31034;&#20986;&#31454;&#20105;&#21147;&#12290;&#19982;&#30456;&#20851;&#22522;&#20110;&#20998;&#25968;&#25193;&#25955;&#27169;&#22411;&#30340;&#31215;&#32047;&#29702;&#35770;&#30740;&#31350;&#30456;&#27604;&#65292;&#23545;&#20110;&#22312;&#27491;&#21521;&#65288;&#25968;&#25454;&#21040;&#22122;&#22768;&#65289;&#21644;&#21453;&#21521;&#65288;&#22122;&#22768;&#21040;&#25968;&#25454;&#65289;&#26041;&#21521;&#19978;&#37117;&#26159;&#30830;&#23450;&#24615;&#30340;&#27969;&#27169;&#22411;&#30340;&#20998;&#26512;&#36824;&#24456;&#23569;&#12290;&#26412;&#25991;&#36890;&#36807;&#22312;&#24402;&#19968;&#21270;&#27969;&#32593;&#32476;&#20013;&#23454;&#26045;Jordan-Kinderleherer-Otto&#65288;JKO&#65289;&#26041;&#26696;&#30340;&#25152;&#35859;JKO&#27969;&#27169;&#22411;&#65292;&#25552;&#20379;&#20102;&#36890;&#36807;&#28176;&#36827;&#27969;&#27169;&#22411;&#29983;&#25104;&#25968;&#25454;&#20998;&#24067;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#21033;&#29992;Wasserstein&#31354;&#38388;&#20013;&#36817;&#31471;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#30340;&#25351;&#25968;&#25910;&#25947;&#24615;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36890;&#36807;JKO&#27969;&#27169;&#22411;&#29983;&#25104;&#25968;&#25454;&#30340;Kullback-Leibler&#65288;KL&#65289;&#20445;&#35777;&#20026;$O(\varepsilon^2)$&#65292;&#20854;&#20013;&#20351;&#29992;$N \lesssim \log (1/\varepsilon)$&#20010;JKO&#27493;&#39588;&#65288;&#27969;&#20013;&#30340;$N$&#20010;&#27531;&#24046;&#22359;&#65289;&#65292;&#20854;&#20013;$\varepsilon$&#26159;&#27599;&#27493;&#19968;&#38454;&#26465;&#20214;&#30340;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Flow-based generative models enjoy certain advantages in computing the data generation and the likelihood, and have recently shown competitive empirical performance. Compared to the accumulating theoretical studies on related score-based diffusion models, analysis of flow-based models, which are deterministic in both forward (data-to-noise) and reverse (noise-to-data) directions, remain sparse. In this paper, we provide a theoretical guarantee of generating data distribution by a progressive flow model, the so-called JKO flow model, which implements the Jordan-Kinderleherer-Otto (JKO) scheme in a normalizing flow network. Leveraging the exponential convergence of the proximal gradient descent (GD) in Wasserstein space, we prove the Kullback-Leibler (KL) guarantee of data generation by a JKO flow model to be $O(\varepsilon^2)$ when using $N \lesssim \log (1/\varepsilon)$ many JKO steps ($N$ Residual Blocks in the flow) where $\varepsilon $ is the error in the per-step first-order condit
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24314;&#31435;&#20102;&#28145;&#24230;&#27531;&#24046;&#32593;&#32476;&#21521;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#65292;&#36890;&#36807;&#23545;&#29992;&#26799;&#24230;&#27969;&#35757;&#32451;&#30340;&#38750;&#32447;&#24615;&#32593;&#32476;&#30340;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#22312;&#32593;&#32476;&#20197;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#30340;&#31163;&#25955;&#21270;&#24418;&#24335;&#21021;&#22987;&#21270;&#21518;&#65292;&#36825;&#31181;&#31163;&#25955;&#21270;&#23558;&#22312;&#25972;&#20010;&#35757;&#32451;&#36807;&#31243;&#20013;&#20445;&#25345;&#19981;&#21464;&#65292;&#24182;&#25552;&#20379;&#20102;&#25910;&#25947;&#24615;&#30340;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2309.01213</link><description>&lt;p&gt;
&#28145;&#24230;&#27531;&#24046;&#32593;&#32476;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#19982;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#30340;&#20851;&#32852;
&lt;/p&gt;
&lt;p&gt;
Implicit regularization of deep residual networks towards neural ODEs. (arXiv:2309.01213v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01213
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24314;&#31435;&#20102;&#28145;&#24230;&#27531;&#24046;&#32593;&#32476;&#21521;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#65292;&#36890;&#36807;&#23545;&#29992;&#26799;&#24230;&#27969;&#35757;&#32451;&#30340;&#38750;&#32447;&#24615;&#32593;&#32476;&#30340;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#22312;&#32593;&#32476;&#20197;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#30340;&#31163;&#25955;&#21270;&#24418;&#24335;&#21021;&#22987;&#21270;&#21518;&#65292;&#36825;&#31181;&#31163;&#25955;&#21270;&#23558;&#22312;&#25972;&#20010;&#35757;&#32451;&#36807;&#31243;&#20013;&#20445;&#25345;&#19981;&#21464;&#65292;&#24182;&#25552;&#20379;&#20102;&#25910;&#25947;&#24615;&#30340;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27531;&#24046;&#31070;&#32463;&#32593;&#32476;&#26159;&#20808;&#36827;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#12290;&#23427;&#20204;&#30340;&#36830;&#32493;&#28145;&#24230;&#27169;&#25311;&#31216;&#20026;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;ODE&#65289;&#65292;&#20063;&#34987;&#24191;&#27867;&#20351;&#29992;&#12290;&#23613;&#31649;&#23427;&#20204;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#31163;&#25955;&#27169;&#22411;&#19982;&#36830;&#32493;&#27169;&#22411;&#20043;&#38388;&#30340;&#32852;&#31995;&#20173;&#32570;&#20047;&#22362;&#23454;&#30340;&#25968;&#23398;&#22522;&#30784;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#24314;&#31435;&#19968;&#20010;&#38024;&#23545;&#29992;&#26799;&#24230;&#27969;&#35757;&#32451;&#30340;&#38750;&#32447;&#24615;&#32593;&#32476;&#30340;&#28145;&#24230;&#27531;&#24046;&#32593;&#32476;&#21521;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#26469;&#26397;&#30528;&#36825;&#20010;&#26041;&#21521;&#36808;&#20986;&#20102;&#19968;&#27493;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22914;&#26524;&#32593;&#32476;&#30340;&#21021;&#22987;&#21270;&#26159;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#30340;&#31163;&#25955;&#21270;&#65292;&#21017;&#36825;&#31181;&#31163;&#25955;&#21270;&#22312;&#25972;&#20010;&#35757;&#32451;&#36807;&#31243;&#20013;&#20445;&#25345;&#19981;&#21464;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#23545;&#20110;&#26377;&#38480;&#30340;&#35757;&#32451;&#26102;&#38388;&#21644;&#35757;&#32451;&#26102;&#38388;&#36235;&#20110;&#26080;&#31351;&#22823;&#37117;&#25104;&#31435;&#65292;&#21482;&#35201;&#32593;&#32476;&#28385;&#36275;Polyak-Lojasiewicz&#26465;&#20214;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#36825;&#20010;&#26465;&#20214;&#36866;&#29992;&#20110;&#19968;&#20010;&#27531;&#24046;&#32593;&#32476;&#23478;&#26063;&#65292;&#20854;&#20013;&#27531;&#24046;&#26159;&#20004;&#23618;&#24863;&#30693;&#26426;&#65292;&#22312;&#23485;&#24230;&#19978;&#21482;&#26159;&#32447;&#24615;&#36229;&#21442;&#25968;&#21270;&#65292;&#24182;&#19988;&#26263;&#31034;&#20102;&#26799;&#24230;&#27969;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Residual neural networks are state-of-the-art deep learning models. Their continuous-depth analog, neural ordinary differential equations (ODEs), are also widely used. Despite their success, the link between the discrete and continuous models still lacks a solid mathematical foundation. In this article, we take a step in this direction by establishing an implicit regularization of deep residual networks towards neural ODEs, for nonlinear networks trained with gradient flow. We prove that if the network is initialized as a discretization of a neural ODE, then such a discretization holds throughout training. Our results are valid for a finite training time, and also as the training time tends to infinity provided that the network satisfies a Polyak-Lojasiewicz condition. Importantly, this condition holds for a family of residual networks where the residuals are two-layer perceptrons with an overparameterization in width that is only linear, and implies the convergence of gradient flow to
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22823;&#35268;&#27169;&#32972;&#26223;&#22270;&#20013;&#26597;&#25214;&#22810;&#20010;&#23884;&#20837;&#30340;&#27169;&#26495;&#22270;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#36845;&#20195;&#24809;&#32602;&#30456;&#20284;&#24230;&#30697;&#38453;&#26469;&#23454;&#29616;&#22810;&#26679;&#21270;&#21305;&#37197;&#30340;&#21457;&#29616;&#65292;&#24182;&#25552;&#20986;&#20102;&#31639;&#27861;&#21152;&#36895;&#25514;&#26045;&#12290;&#22312;&#29702;&#35770;&#39564;&#35777;&#21644;&#23454;&#39564;&#35777;&#26126;&#20013;&#65292;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#21487;&#34892;&#24615;&#21644;&#23454;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.13451</link><description>&lt;p&gt;
&#25235;&#20303;&#23427;&#20204;&#65306;&#22270;&#21305;&#37197;&#21305;&#37197;&#28388;&#27874;&#20013;&#30340;&#35299;&#20915;&#26041;&#26696;&#22810;&#26679;&#21270;
&lt;/p&gt;
&lt;p&gt;
Gotta match 'em all: Solution diversification in graph matching matched filters. (arXiv:2308.13451v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13451
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22823;&#35268;&#27169;&#32972;&#26223;&#22270;&#20013;&#26597;&#25214;&#22810;&#20010;&#23884;&#20837;&#30340;&#27169;&#26495;&#22270;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#36845;&#20195;&#24809;&#32602;&#30456;&#20284;&#24230;&#30697;&#38453;&#26469;&#23454;&#29616;&#22810;&#26679;&#21270;&#21305;&#37197;&#30340;&#21457;&#29616;&#65292;&#24182;&#25552;&#20986;&#20102;&#31639;&#27861;&#21152;&#36895;&#25514;&#26045;&#12290;&#22312;&#29702;&#35770;&#39564;&#35777;&#21644;&#23454;&#39564;&#35777;&#26126;&#20013;&#65292;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#21487;&#34892;&#24615;&#21644;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#38750;&#24120;&#22823;&#30340;&#32972;&#26223;&#22270;&#20013;&#26597;&#25214;&#22810;&#20010;&#23884;&#20837;&#22312;&#20854;&#20013;&#30340;&#27169;&#26495;&#22270;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;Sussman&#31561;&#20154;&#25552;&#20986;&#30340;&#22270;&#21305;&#37197;&#21305;&#37197;&#28388;&#27874;&#25216;&#26415;&#65292;&#36890;&#36807;&#22312;&#21305;&#37197;&#28388;&#27874;&#31639;&#27861;&#20013;&#36845;&#20195;&#22320;&#24809;&#32602;&#21512;&#36866;&#30340;&#33410;&#28857;&#23545;&#30456;&#20284;&#24230;&#30697;&#38453;&#26469;&#23454;&#29616;&#22810;&#26679;&#21270;&#21305;&#37197;&#30340;&#21457;&#29616;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31639;&#27861;&#21152;&#36895;&#65292;&#26497;&#22823;&#22320;&#25552;&#39640;&#20102;&#25105;&#20204;&#30340;&#21305;&#37197;&#28388;&#27874;&#26041;&#27861;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;&#25105;&#20204;&#22312;&#30456;&#20851;&#30340;Erdos-Renyi&#22270;&#35774;&#32622;&#20013;&#23545;&#25105;&#20204;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#29702;&#35770;&#19978;&#30340;&#39564;&#35777;&#65292;&#26174;&#31034;&#20854;&#22312;&#28201;&#21644;&#30340;&#27169;&#22411;&#26465;&#20214;&#19979;&#33021;&#22815;&#39034;&#24207;&#22320;&#21457;&#29616;&#22810;&#20010;&#27169;&#26495;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#20351;&#29992;&#27169;&#25311;&#27169;&#22411;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#65288;&#21253;&#25324;&#20154;&#33041;&#36830;&#25509;&#32452;&#21644;&#22823;&#22411;&#20132;&#26131;&#30693;&#35782;&#24211;&#65289;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a novel approach for finding multiple noisily embedded template graphs in a very large background graph. Our method builds upon the graph-matching-matched-filter technique proposed in Sussman et al., with the discovery of multiple diverse matchings being achieved by iteratively penalizing a suitable node-pair similarity matrix in the matched filter algorithm. In addition, we propose algorithmic speed-ups that greatly enhance the scalability of our matched-filter approach. We present theoretical justification of our methodology in the setting of correlated Erdos-Renyi graphs, showing its ability to sequentially discover multiple templates under mild model conditions. We additionally demonstrate our method's utility via extensive experiments both using simulated models and real-world dataset, include human brain connectomes and a large transactional knowledge base.
&lt;/p&gt;</description></item><item><title>Engression&#26159;&#19968;&#31181;&#38750;&#32447;&#24615;&#22238;&#24402;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#20998;&#24067;&#22238;&#24402;&#25216;&#26415;&#21644;&#39044;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#65292;&#22312;&#35757;&#32451;&#26679;&#26412;&#33539;&#22260;&#36793;&#30028;&#22806;&#20063;&#33021;&#21487;&#38752;&#22320;&#36827;&#34892;&#22806;&#25512;&#12290;</title><link>http://arxiv.org/abs/2307.00835</link><description>&lt;p&gt;
Engression: &#38750;&#32447;&#24615;&#22238;&#24402;&#30340;&#22806;&#25512;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Engression: Extrapolation for Nonlinear Regression?. (arXiv:2307.00835v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00835
&lt;/p&gt;
&lt;p&gt;
Engression&#26159;&#19968;&#31181;&#38750;&#32447;&#24615;&#22238;&#24402;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#20998;&#24067;&#22238;&#24402;&#25216;&#26415;&#21644;&#39044;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#65292;&#22312;&#35757;&#32451;&#26679;&#26412;&#33539;&#22260;&#36793;&#30028;&#22806;&#20063;&#33021;&#21487;&#38752;&#22320;&#36827;&#34892;&#22806;&#25512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22806;&#25512;&#23545;&#20110;&#35768;&#22810;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#65292;&#22240;&#20026;&#24120;&#24120;&#20250;&#36935;&#21040;&#36229;&#20986;&#35757;&#32451;&#26679;&#26412;&#33539;&#22260;&#30340;&#27979;&#35797;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#38750;&#32447;&#24615;&#27169;&#22411;&#26469;&#35828;&#65292;&#22806;&#25512;&#26159;&#19968;&#20010;&#24040;&#22823;&#30340;&#25361;&#25112;&#12290;&#20256;&#32479;&#27169;&#22411;&#22312;&#36825;&#26041;&#38754;&#36890;&#24120;&#36935;&#21040;&#22256;&#38590;&#65306;&#26641;&#38598;&#25104;&#27169;&#22411;&#22312;&#25903;&#25345;&#33539;&#22260;&#22806;&#25552;&#20379;&#36830;&#32493;&#30340;&#39044;&#27979;&#65292;&#32780;&#31070;&#32463;&#32593;&#32476;&#30340;&#39044;&#27979;&#24448;&#24448;&#21464;&#24471;&#19981;&#21487;&#25511;&#12290;&#36825;&#39033;&#24037;&#20316;&#26088;&#22312;&#25552;&#20379;&#19968;&#31181;&#38750;&#32447;&#24615;&#22238;&#24402;&#26041;&#27861;&#65292;&#20854;&#21487;&#38752;&#24615;&#22312;&#35757;&#32451;&#26679;&#26412;&#33539;&#22260;&#36793;&#30028;&#19981;&#20250;&#31435;&#21363;&#23849;&#28291;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#19968;&#31181;&#21517;&#20026;&#8220;engression&#8221;&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#26159;&#19968;&#31181;&#39044;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#30340;&#20998;&#24067;&#22238;&#24402;&#25216;&#26415;&#65292;&#20854;&#20013;&#22122;&#22768;&#28155;&#21152;&#21040;&#21327;&#21464;&#37327;&#19978;&#24182;&#24212;&#29992;&#38750;&#32447;&#24615;&#36716;&#25442;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#27169;&#22411;&#36890;&#24120;&#36866;&#29992;&#20110;&#35768;&#22810;&#30495;&#23454;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#23637;&#31034;engression&#21487;&#20197;&#22312;&#19968;&#20123;&#20551;&#35774;&#19979;&#25104;&#21151;&#36827;&#34892;&#22806;&#25512;&#65292;&#20363;&#22914;&#20005;&#26684;&#38480;&#21046;&#22122;&#22768;&#22823;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;
Extrapolation is crucial in many statistical and machine learning applications, as it is common to encounter test data outside the training support. However, extrapolation is a considerable challenge for nonlinear models. Conventional models typically struggle in this regard: while tree ensembles provide a constant prediction beyond the support, neural network predictions tend to become uncontrollable. This work aims at providing a nonlinear regression methodology whose reliability does not break down immediately at the boundary of the training support. Our primary contribution is a new method called `engression' which, at its core, is a distributional regression technique for pre-additive noise models, where the noise is added to the covariates before applying a nonlinear transformation. Our experimental results indicate that this model is typically suitable for many real data sets. We show that engression can successfully perform extrapolation under some assumptions such as a strictl
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20122;&#28176;&#36817;&#26497;&#22823;&#20540;&#30340;&#39640;&#32500;&#21464;&#37327;&#32858;&#31867;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21033;&#29992;&#32676;&#38598;&#38388;&#22810;&#21464;&#37327;&#38543;&#26426;&#36807;&#31243;&#30340;&#26497;&#22823;&#20540;&#30340;&#29420;&#31435;&#24615;&#23450;&#20041;&#31181;&#32676;&#27700;&#24179;&#30340;&#32676;&#38598;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#26080;&#38656;&#39044;&#20808;&#25351;&#23450;&#32676;&#38598;&#25968;&#37327;&#30340;&#31639;&#27861;&#26469;&#24674;&#22797;&#21464;&#37327;&#30340;&#32676;&#38598;&#12290;&#35813;&#31639;&#27861;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#33021;&#22815;&#26377;&#25928;&#22320;&#35782;&#21035;&#25968;&#25454;&#20013;&#30340;&#32676;&#38598;&#65292;&#24182;&#33021;&#22815;&#20197;&#22810;&#39033;&#24335;&#22797;&#26434;&#24230;&#36827;&#34892;&#35745;&#31639;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#23545;&#20110;&#29702;&#35299;&#20381;&#36182;&#36807;&#31243;&#30340;&#22359;&#26368;&#22823;&#20540;&#30340;&#38750;&#21442;&#25968;&#23398;&#20064;&#26377;&#37325;&#35201;&#24847;&#20041;&#65292;&#24182;&#19988;&#22312;&#31070;&#32463;&#31185;&#23398;&#39046;&#22495;&#26377;&#30528;&#24212;&#29992;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2302.00934</link><description>&lt;p&gt;
&#22522;&#20110;&#24369;&#30456;&#20851;&#38543;&#26426;&#36807;&#31243;&#30340;&#20122;&#28176;&#36817;&#26497;&#22823;&#20540;&#30340;&#39640;&#32500;&#21464;&#37327;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
High-dimensional variable clustering based on sub-asymptotic maxima of a weakly dependent random process. (arXiv:2302.00934v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.00934
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20122;&#28176;&#36817;&#26497;&#22823;&#20540;&#30340;&#39640;&#32500;&#21464;&#37327;&#32858;&#31867;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21033;&#29992;&#32676;&#38598;&#38388;&#22810;&#21464;&#37327;&#38543;&#26426;&#36807;&#31243;&#30340;&#26497;&#22823;&#20540;&#30340;&#29420;&#31435;&#24615;&#23450;&#20041;&#31181;&#32676;&#27700;&#24179;&#30340;&#32676;&#38598;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#26080;&#38656;&#39044;&#20808;&#25351;&#23450;&#32676;&#38598;&#25968;&#37327;&#30340;&#31639;&#27861;&#26469;&#24674;&#22797;&#21464;&#37327;&#30340;&#32676;&#38598;&#12290;&#35813;&#31639;&#27861;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#33021;&#22815;&#26377;&#25928;&#22320;&#35782;&#21035;&#25968;&#25454;&#20013;&#30340;&#32676;&#38598;&#65292;&#24182;&#33021;&#22815;&#20197;&#22810;&#39033;&#24335;&#22797;&#26434;&#24230;&#36827;&#34892;&#35745;&#31639;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#23545;&#20110;&#29702;&#35299;&#20381;&#36182;&#36807;&#31243;&#30340;&#22359;&#26368;&#22823;&#20540;&#30340;&#38750;&#21442;&#25968;&#23398;&#20064;&#26377;&#37325;&#35201;&#24847;&#20041;&#65292;&#24182;&#19988;&#22312;&#31070;&#32463;&#31185;&#23398;&#39046;&#22495;&#26377;&#30528;&#24212;&#29992;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21464;&#37327;&#32858;&#31867;&#27169;&#22411;&#65292;&#31216;&#20026;&#28176;&#36817;&#29420;&#31435;&#22359; (AI-block) &#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22522;&#20110;&#32676;&#38598;&#38388;&#22810;&#21464;&#37327;&#24179;&#31283;&#28151;&#21512;&#38543;&#26426;&#36807;&#31243;&#30340;&#26497;&#22823;&#20540;&#30340;&#29420;&#31435;&#24615;&#26469;&#23450;&#20041;&#31181;&#32676;&#27700;&#24179;&#30340;&#32676;&#38598;&#12290;&#35813;&#27169;&#22411;&#31867;&#26159;&#21487;&#35782;&#21035;&#30340;&#65292;&#24847;&#21619;&#30528;&#23384;&#22312;&#19968;&#31181;&#20559;&#24207;&#20851;&#31995;&#65292;&#20801;&#35768;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#26080;&#38656;&#20107;&#20808;&#25351;&#23450;&#32676;&#38598;&#30340;&#25968;&#37327;&#21363;&#21487;&#24674;&#22797;&#21464;&#37327;&#30340;&#32676;&#38598;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#25552;&#20379;&#20102;&#19968;&#20123;&#29702;&#35770;&#27934;&#23519;&#65292;&#35777;&#26126;&#20102;&#22312;&#26576;&#20123;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#33021;&#22815;&#22312;&#35745;&#31639;&#22797;&#26434;&#24615;&#22312;&#32500;&#24230;&#20013;&#26159;&#22810;&#39033;&#24335;&#30340;&#24773;&#20917;&#19979;&#26377;&#25928;&#22320;&#35782;&#21035;&#25968;&#25454;&#20013;&#30340;&#32676;&#38598;&#12290;&#36825;&#24847;&#21619;&#30528;&#21487;&#20197;&#38750;&#21442;&#25968;&#22320;&#23398;&#20064;&#20986;&#20165;&#20165;&#26159;&#20122;&#28176;&#36817;&#30340;&#20381;&#36182;&#36807;&#31243;&#30340;&#22359;&#26368;&#22823;&#20540;&#30340;&#32676;&#32452;&#12290;&#20026;&#20102;&#36827;&#19968;&#27493;&#35828;&#26126;&#25105;&#20204;&#30340;&#24037;&#20316;&#30340;&#37325;&#35201;&#24615;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#31070;&#32463;&#31185;&#23398;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new class of models for variable clustering called Asymptotic Independent block (AI-block) models, which defines population-level clusters based on the independence of the maxima of a multivariate stationary mixing random process among clusters. This class of models is identifiable, meaning that there exists a maximal element with a partial order between partitions, allowing for statistical inference. We also present an algorithm for recovering the clusters of variables without specifying the number of clusters \emph{a priori}. Our work provides some theoretical insights into the consistency of our algorithm, demonstrating that under certain conditions it can effectively identify clusters in the data with a computational complexity that is polynomial in the dimension. This implies that groups can be learned nonparametrically in which block maxima of a dependent process are only sub-asymptotic. To further illustrate the significance of our work, we applied our method to neu
&lt;/p&gt;</description></item></channel></rss>