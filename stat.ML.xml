<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25506;&#32034;&#20102;&#22312;&#26080;&#31351;&#32500;&#31354;&#38388;&#20013;&#23545;&#38750;&#32447;&#24615;&#36807;&#31243;&#36827;&#34892;&#26465;&#20214;&#32422;&#26463;&#30340;&#26041;&#27861;&#65292;&#24182;&#24212;&#29992;&#20110;&#36827;&#21270;&#29983;&#29289;&#23398;&#20013;&#30340;&#29983;&#29289;&#24418;&#24577;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01434</link><description>&lt;p&gt;
&#38543;&#26426;&#38750;&#32447;&#24615;&#19982;&#26080;&#31351;&#32500;&#25193;&#25955;&#36807;&#31243;&#30340;&#26465;&#20214;&#32422;&#26463;
&lt;/p&gt;
&lt;p&gt;
Conditioning non-linear and infinite-dimensional diffusion processes
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01434
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#32034;&#20102;&#22312;&#26080;&#31351;&#32500;&#31354;&#38388;&#20013;&#23545;&#38750;&#32447;&#24615;&#36807;&#31243;&#36827;&#34892;&#26465;&#20214;&#32422;&#26463;&#30340;&#26041;&#27861;&#65292;&#24182;&#24212;&#29992;&#20110;&#36827;&#21270;&#29983;&#29289;&#23398;&#20013;&#30340;&#29983;&#29289;&#24418;&#24577;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24615;&#25193;&#25955;&#27169;&#22411;&#21644;&#35768;&#22810;&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#30340;&#38543;&#26426;&#27169;&#22411;&#22312;&#31163;&#25955;&#21270;&#20043;&#21069;&#33258;&#28982;&#22320;&#23384;&#22312;&#20110;&#26080;&#31351;&#32500;&#31354;&#38388;&#20013;&#12290;&#20026;&#20102;&#23558;&#35266;&#27979;&#25968;&#25454;&#32435;&#20837;&#32479;&#35745;&#21644;&#23398;&#20064;&#20219;&#21153;&#20013;&#65292;&#38656;&#35201;&#23545;&#35266;&#27979;&#20540;&#36827;&#34892;&#26465;&#20214;&#32422;&#26463;&#12290;&#36817;&#26399;&#30340;&#30740;&#31350;&#24050;&#32463;&#22788;&#29702;&#20102;&#22312;&#26080;&#31351;&#32500;&#31354;&#38388;&#20013;&#23545;&#32447;&#24615;&#36807;&#31243;&#36827;&#34892;&#26465;&#20214;&#32422;&#26463;&#30340;&#38382;&#39064;&#65292;&#20294;&#23578;&#26410;&#25506;&#32034;&#22312;&#26080;&#31351;&#32500;&#31354;&#38388;&#20013;&#23545;&#38750;&#32447;&#24615;&#36807;&#31243;&#36827;&#34892;&#26465;&#20214;&#32422;&#26463;&#30340;&#26041;&#27861;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#26080;&#20808;&#39564;&#31163;&#25955;&#21270;&#30340;&#24773;&#20917;&#19979;&#23545;&#20989;&#25968;&#20540;&#38543;&#26426;&#36807;&#31243;&#36827;&#34892;&#26465;&#20214;&#32422;&#26463;&#30340;&#26041;&#27861;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;Girsanov&#23450;&#29702;&#30340;&#26080;&#31351;&#32500;&#29256;&#26412;&#26469;&#23545;&#20989;&#25968;&#20540;&#38543;&#26426;&#36807;&#31243;&#36827;&#34892;&#26465;&#20214;&#32422;&#26463;&#65292;&#20174;&#32780;&#24471;&#21040;&#20102;&#28041;&#21450;&#24471;&#20998;&#30340;&#26465;&#20214;&#36807;&#31243;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;(SDE)&#12290;&#25105;&#20204;&#23558;&#36825;&#31181;&#25216;&#26415;&#24212;&#29992;&#20110;&#36827;&#21270;&#29983;&#29289;&#23398;&#20013;&#30340;&#29983;&#29289;&#24418;&#24577;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#20013;&#65292;&#36890;&#36807;Fourier&#22522;&#20989;&#25968;&#31163;&#25955;&#21270;&#65292;&#28982;&#21518;&#21033;&#29992;&#24471;&#20998;&#21305;&#37197;&#26041;&#27861;&#23398;&#20064;&#24471;&#20998;&#20989;&#25968;&#30340;&#31995;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative diffusion models and many stochastic models in science and engineering naturally live in infinite dimensions before discretisation. To incorporate observed data for statistical and learning tasks, one needs to condition on observations. While recent work has treated conditioning linear processes in infinite dimensions, conditioning non-linear processes in infinite dimensions has not been explored. This paper conditions function valued stochastic processes without prior discretisation. To do so, we use an infinite-dimensional version of Girsanov's theorem to condition a function-valued stochastic process, leading to a stochastic differential equation (SDE) for the conditioned process involving the score. We apply this technique to do time series analysis for shapes of organisms in evolutionary biology, where we discretise via the Fourier basis and then learn the coefficients of the score function with score matching methods.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20351;&#29992;&#38789;&#23614;&#24052;&#30028;&#38480;&#21644;&#26080;&#38480;&#32500;&#20984;&#35268;&#21010;&#30340;&#26377;&#38480;&#32500;&#37325;&#26500;&#65292;&#24314;&#31435;&#20102;&#24207;&#36143;&#26680;&#22238;&#24402;&#30340;&#26032;&#32622;&#20449;&#21306;&#38388;&#65292;&#35777;&#26126;&#20854;&#22987;&#32456;&#27604;&#29616;&#26377;&#30340;&#32622;&#20449;&#21306;&#38388;&#26356;&#32039;&#20945;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#26680;&#36172;&#21338;&#38382;&#39064;&#65292;&#25552;&#39640;&#20102;&#31639;&#27861;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;</title><link>https://arxiv.org/abs/2403.12732</link><description>&lt;p&gt;
&#23545;&#20110;&#24207;&#36143;&#26680;&#22238;&#24402;&#30340;&#26356;&#32039;&#20945;&#32622;&#20449;&#21306;&#38388;
&lt;/p&gt;
&lt;p&gt;
Tighter Confidence Bounds for Sequential Kernel Regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12732
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#38789;&#23614;&#24052;&#30028;&#38480;&#21644;&#26080;&#38480;&#32500;&#20984;&#35268;&#21010;&#30340;&#26377;&#38480;&#32500;&#37325;&#26500;&#65292;&#24314;&#31435;&#20102;&#24207;&#36143;&#26680;&#22238;&#24402;&#30340;&#26032;&#32622;&#20449;&#21306;&#38388;&#65292;&#35777;&#26126;&#20854;&#22987;&#32456;&#27604;&#29616;&#26377;&#30340;&#32622;&#20449;&#21306;&#38388;&#26356;&#32039;&#20945;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#26680;&#36172;&#21338;&#38382;&#39064;&#65292;&#25552;&#39640;&#20102;&#31639;&#27861;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32622;&#20449;&#21306;&#38388;&#26159;&#20005;&#26684;&#37327;&#21270;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#37325;&#35201;&#24037;&#20855;&#12290;&#23427;&#20204;&#21487;&#20197;&#25351;&#23548;&#25506;&#32034;&#19982;&#24320;&#21457;&#30340;&#26435;&#34913;&#65292;&#24182;&#26500;&#25104;&#35768;&#22810;&#24207;&#36143;&#23398;&#20064;&#21644;&#20915;&#31574;&#31639;&#27861;&#30340;&#26680;&#24515;&#32452;&#25104;&#37096;&#20998;&#12290;&#26356;&#32039;&#20945;&#30340;&#32622;&#20449;&#21306;&#38388;&#24102;&#26469;&#20102;&#20855;&#26377;&#26356;&#22909;&#32463;&#39564;&#24615;&#33021;&#21644;&#26356;&#22909;&#24615;&#33021;&#20445;&#35777;&#30340;&#31639;&#27861;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#38789;&#23614;&#24052;&#30028;&#38480;&#21644;&#26080;&#38480;&#32500;&#20984;&#35268;&#21010;&#30340;&#26377;&#38480;&#32500;&#37325;&#26500;&#26469;&#24314;&#31435;&#24207;&#36143;&#26680;&#22238;&#24402;&#30340;&#26032;&#32622;&#20449;&#21306;&#38388;&#12290;&#25105;&#20204;&#35777;&#26126;&#22312;&#36825;&#19968;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#30340;&#26032;&#32622;&#20449;&#21306;&#38388;&#22987;&#32456;&#27604;&#29616;&#26377;&#30340;&#26356;&#32039;&#20945;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#32622;&#20449;&#21306;&#38388;&#24212;&#29992;&#20110;&#26680;&#36172;&#21338;&#38382;&#39064;&#65292;&#20854;&#20013;&#26410;&#26469;&#30340;&#34892;&#21160;&#21462;&#20915;&#20110;&#20808;&#21069;&#30340;&#21382;&#21490;&#12290;&#24403;&#25105;&#20204;&#30340;&#32622;&#20449;&#21306;&#38388;&#21462;&#20195;&#29616;&#26377;&#30340;&#32622;&#20449;&#21306;&#38388;&#26102;&#65292;KernelUCB&#65288;GP-UCB&#65289;&#31639;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#32463;&#39564;&#24615;&#33021;&#65292;&#21305;&#37197;&#30340;&#26368;&#22351;&#24773;&#20917;&#24615;&#33021;&#20445;&#35777;&#21644;&#21487;&#27604;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12732v1 Announce Type: cross  Abstract: Confidence bounds are an essential tool for rigorously quantifying the uncertainty of predictions. In this capacity, they can inform the exploration-exploitation trade-off and form a core component in many sequential learning and decision-making algorithms. Tighter confidence bounds give rise to algorithms with better empirical performance and better performance guarantees. In this work, we use martingale tail bounds and finite-dimensional reformulations of infinite-dimensional convex programs to establish new confidence bounds for sequential kernel regression. We prove that our new confidence bounds are always tighter than existing ones in this setting. We apply our confidence bounds to the kernel bandit problem, where future actions depend on the previous history. When our confidence bounds replace existing ones, the KernelUCB (GP-UCB) algorithm has better empirical performance, a matching worst-case performance guarantee and compara
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#38543;&#26426;Halpern&#36845;&#20195;&#22312;&#36171;&#33539;&#31354;&#38388;&#20013;&#30340;Oracle&#22797;&#26434;&#24230;&#65292;&#25552;&#20986;&#20102;&#25913;&#36827;&#30340;&#31639;&#27861;&#22797;&#26434;&#24230;&#65292;&#36827;&#32780;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#25552;&#20986;&#20102;&#26032;&#30340;&#21516;&#27493;&#31639;&#27861;&#24212;&#29992;&#12290;</title><link>https://arxiv.org/abs/2403.12338</link><description>&lt;p&gt;
&#38543;&#26426;Halpern&#36845;&#20195;&#22312;&#36171;&#33539;&#31354;&#38388;&#20013;&#30340;&#24212;&#29992;&#21450;&#20854;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Stochastic Halpern iteration in normed spaces and applications to reinforcement learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12338
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#38543;&#26426;Halpern&#36845;&#20195;&#22312;&#36171;&#33539;&#31354;&#38388;&#20013;&#30340;Oracle&#22797;&#26434;&#24230;&#65292;&#25552;&#20986;&#20102;&#25913;&#36827;&#30340;&#31639;&#27861;&#22797;&#26434;&#24230;&#65292;&#36827;&#32780;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#25552;&#20986;&#20102;&#26032;&#30340;&#21516;&#27493;&#31639;&#27861;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20998;&#26512;&#20102;&#20855;&#26377;&#26041;&#24046;&#20943;&#23569;&#30340;&#38543;&#26426;Halpern&#36845;&#20195;&#30340;Oracle&#22797;&#26434;&#24230;&#65292;&#26088;&#22312;&#36817;&#20284;&#26377;&#30028;&#21644;&#25910;&#32553;&#31639;&#23376;&#30340;&#19981;&#21160;&#28857;&#22312;&#19968;&#20010;&#26377;&#38480;&#32500;&#36171;&#33539;&#31354;&#38388;&#20013;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#22914;&#26524;&#24213;&#23618;&#30340;&#38543;&#26426;Oracle&#20855;&#26377;&#19968;&#33268;&#26377;&#30028;&#30340;&#26041;&#24046;&#65292;&#21017;&#25105;&#20204;&#30340;&#26041;&#27861;&#23637;&#29616;&#20986;&#24635;&#30340;Oracle&#22797;&#26434;&#24230;&#20026;$ \tilde{O} (\varepsilon^{-5})$&#65292;&#25913;&#36827;&#20102;&#26368;&#36817;&#20026;&#38543;&#26426;Krasnoselskii-Mann&#36845;&#20195;&#24314;&#31435;&#30340;&#36895;&#29575;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102; $\Omega (\varepsilon^{-3})$&#30340;&#19979;&#30028;&#65292;&#36866;&#29992;&#20110;&#24191;&#27867;&#33539;&#22260;&#30340;&#31639;&#27861;&#65292;&#21253;&#25324;&#25152;&#26377;&#24102;&#26377;&#23567;&#25209;&#22788;&#29702;&#30340;&#24179;&#22343;&#36845;&#20195;&#12290;&#36890;&#36807;&#36866;&#24403;&#20462;&#25913;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#22312;&#31639;&#23376;&#20026; $\gamma$-&#25910;&#32553;&#30340;&#24773;&#20917;&#19979;&#19968;&#20010; $O(\varepsilon^{-2}(1-\gamma)^{-3})$&#22797;&#26434;&#24230;&#19978;&#30028;&#12290;&#20316;&#20026;&#19968;&#20010;&#24212;&#29992;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26032;&#30340;&#29992;&#20110;&#24179;&#22343;&#22870;&#21169;&#21644;&#25240;&#25187;&#22870;&#21169;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#21516;&#27493;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12338v1 Announce Type: cross  Abstract: We analyze the oracle complexity of the stochastic Halpern iteration with variance reduction, where we aim to approximate fixed-points of nonexpansive and contractive operators in a normed finite-dimensional space. We show that if the underlying stochastic oracle is with uniformly bounded variance, our method exhibits an overall oracle complexity of $\tilde{O}(\varepsilon^{-5})$, improving recent rates established for the stochastic Krasnoselskii-Mann iteration. Also, we establish a lower bound of $\Omega(\varepsilon^{-3})$, which applies to a wide range of algorithms, including all averaged iterations even with minibatching. Using a suitable modification of our approach, we derive a $O(\varepsilon^{-2}(1-\gamma)^{-3})$ complexity bound in the case in which the operator is a $\gamma$-contraction. As an application, we propose new synchronous algorithms for average reward and discounted reward Markov decision processes. In particular, f
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#21033;&#29992;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#20808;&#39564;&#32467;&#26500;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#24067;&#24335;&#20998;&#38548;&#21518;&#39564;&#37319;&#26679;&#26041;&#27861;&#65292;&#30456;&#27604;&#20808;&#21069;&#30340;&#26041;&#27861;&#20855;&#26377;&#26356;&#20302;&#30340;&#36924;&#36817;&#35823;&#24046;&#12290;</title><link>https://arxiv.org/abs/2403.11407</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#20998;&#38548;&#21518;&#39564;&#37319;&#26679;&#29992;&#20110;&#21435;&#22122;&#25193;&#25955;&#20808;&#39564;
&lt;/p&gt;
&lt;p&gt;
Divide-and-Conquer Posterior Sampling for Denoising Diffusion Priors
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11407
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#21033;&#29992;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#20808;&#39564;&#32467;&#26500;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#24067;&#24335;&#20998;&#38548;&#21518;&#39564;&#37319;&#26679;&#26041;&#27861;&#65292;&#30456;&#27604;&#20808;&#21069;&#30340;&#26041;&#27861;&#20855;&#26377;&#26356;&#20302;&#30340;&#36924;&#36817;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#23545;&#20110;&#20351;&#29992;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#65288;DDM&#65289;&#20316;&#20026;&#36870;&#36125;&#21494;&#26031;&#38382;&#39064;&#27714;&#35299;&#30340;&#20808;&#39564;&#24341;&#36215;&#20102;&#26497;&#22823;&#30340;&#20852;&#36259;&#12290;&#28982;&#32780;&#65292;&#20174;&#32467;&#26524;&#21518;&#39564;&#20998;&#24067;&#20013;&#25277;&#26679;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#25552;&#20986;&#20102;&#36817;&#20284;&#26041;&#27861;&#26469;&#20559;&#32622;&#25193;&#25955;&#30340;&#28418;&#31227;&#39033;&#12290;&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#37319;&#21462;&#20102;&#19968;&#31181;&#19981;&#21516;&#30340;&#26041;&#27861;&#65292;&#24182;&#21033;&#29992;DDM&#20808;&#39564;&#30340;&#29305;&#23450;&#32467;&#26500;&#26469;&#23450;&#20041;&#19968;&#32452;&#20013;&#38388;&#21644;&#26356;&#31616;&#21333;&#30340;&#21518;&#39564;&#25277;&#26679;&#38382;&#39064;&#65292;&#30456;&#27604;&#20808;&#21069;&#30340;&#26041;&#27861;&#65292;&#36825;&#20123;&#26041;&#27861;&#20855;&#26377;&#26356;&#20302;&#30340;&#36924;&#36817;&#35823;&#24046;&#12290;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#21512;&#25104;&#20363;&#23376;&#21644;&#21508;&#31181;&#22270;&#20687;&#24674;&#22797;&#20219;&#21153;&#26469;&#23454;&#35777;&#22320;&#23637;&#31034;&#25105;&#20204;&#26041;&#27861;&#23545;&#20110;&#19968;&#33324;&#32447;&#24615;&#36870;&#38382;&#39064;&#30340;&#37325;&#26500;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11407v1 Announce Type: cross  Abstract: Interest in the use of Denoising Diffusion Models (DDM) as priors for solving inverse Bayesian problems has recently increased significantly. However, sampling from the resulting posterior distribution poses a challenge. To solve this problem, previous works have proposed approximations to bias the drift term of the diffusion. In this work, we take a different approach and utilize the specific structure of the DDM prior to define a set of intermediate and simpler posterior sampling problems, resulting in a lower approximation error compared to previous methods. We empirically demonstrate the reconstruction capability of our method for general linear inverse problems using synthetic examples and various image restoration tasks.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#25968;&#25454;&#38598;&#29305;&#24615;&#37327;&#36523;&#23450;&#21046;&#30340;&#36817;&#20284;&#20844;&#24179;&#24615;-&#20934;&#30830;&#24615;&#26435;&#34913;&#26354;&#32447;&#35745;&#31639;&#26041;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#20943;&#36731;&#35757;&#32451;&#22810;&#20010;&#27169;&#22411;&#30340;&#35745;&#31639;&#36127;&#25285;&#24182;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#32479;&#35745;&#20445;&#35777;</title><link>https://arxiv.org/abs/2402.17106</link><description>&lt;p&gt;
&#25968;&#25454;&#38598;&#20844;&#24179;&#24615;&#65306;&#22312;&#24744;&#30340;&#25968;&#25454;&#19978;&#23454;&#29616;&#20855;&#26377;&#25928;&#29992;&#20445;&#35777;&#30340;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Dataset Fairness: Achievable Fairness on Your Data With Utility Guarantees
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17106
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#25968;&#25454;&#38598;&#29305;&#24615;&#37327;&#36523;&#23450;&#21046;&#30340;&#36817;&#20284;&#20844;&#24179;&#24615;-&#20934;&#30830;&#24615;&#26435;&#34913;&#26354;&#32447;&#35745;&#31639;&#26041;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#20943;&#36731;&#35757;&#32451;&#22810;&#20010;&#27169;&#22411;&#30340;&#35745;&#31639;&#36127;&#25285;&#24182;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#32479;&#35745;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#20844;&#24179;&#24615;&#20013;&#65292;&#35757;&#32451;&#33021;&#22815;&#26368;&#23567;&#21270;&#19981;&#21516;&#25935;&#24863;&#32676;&#20307;&#20043;&#38388;&#24046;&#24322;&#30340;&#27169;&#22411;&#36890;&#24120;&#20250;&#23548;&#33268;&#20934;&#30830;&#24615;&#19979;&#38477;&#65292;&#36825;&#31181;&#29616;&#35937;&#34987;&#31216;&#20026;&#20844;&#24179;&#24615;-&#20934;&#30830;&#24615;&#26435;&#34913;&#12290;&#36825;&#31181;&#26435;&#34913;&#30340;&#20005;&#37325;&#31243;&#24230;&#22522;&#26412;&#21462;&#20915;&#20110;&#25968;&#25454;&#38598;&#30340;&#29305;&#24615;&#65292;&#22914;&#25968;&#25454;&#38598;&#30340;&#19981;&#22343;&#34913;&#25110;&#20559;&#35265;&#12290;&#22240;&#27492;&#65292;&#22312;&#25968;&#25454;&#38598;&#20043;&#38388;&#20351;&#29992;&#32479;&#19968;&#30340;&#20844;&#24179;&#24615;&#35201;&#27714;&#20173;&#28982;&#20540;&#24471;&#24576;&#30097;&#65292;&#24182;&#19988;&#24448;&#24448;&#20250;&#23548;&#33268;&#25928;&#29992;&#26497;&#20302;&#30340;&#27169;&#22411;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#21333;&#20010;&#25968;&#25454;&#38598;&#37327;&#36523;&#23450;&#21046;&#30340;&#36817;&#20284;&#20844;&#24179;&#24615;-&#20934;&#30830;&#24615;&#26435;&#34913;&#26354;&#32447;&#30340;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#25903;&#25345;&#20005;&#26684;&#30340;&#32479;&#35745;&#20445;&#35777;&#12290;&#36890;&#36807;&#21033;&#29992;You-Only-Train-Once&#65288;YOTO&#65289;&#26694;&#26550;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20943;&#36731;&#20102;&#22312;&#36924;&#36817;&#26435;&#34913;&#26354;&#32447;&#26102;&#38656;&#35201;&#35757;&#32451;&#22810;&#20010;&#27169;&#22411;&#30340;&#35745;&#31639;&#36127;&#25285;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;&#35813;&#26354;&#32447;&#21608;&#22260;&#24341;&#20837;&#32622;&#20449;&#21306;&#38388;&#26469;&#37327;&#21270;&#25105;&#20204;&#36817;&#20284;&#20540;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17106v1 Announce Type: cross  Abstract: In machine learning fairness, training models which minimize disparity across different sensitive groups often leads to diminished accuracy, a phenomenon known as the fairness-accuracy trade-off. The severity of this trade-off fundamentally depends on dataset characteristics such as dataset imbalances or biases. Therefore using a uniform fairness requirement across datasets remains questionable and can often lead to models with substantially low utility. To address this, we present a computationally efficient approach to approximate the fairness-accuracy trade-off curve tailored to individual datasets, backed by rigorous statistical guarantees. By utilizing the You-Only-Train-Once (YOTO) framework, our approach mitigates the computational burden of having to train multiple models when approximating the trade-off curve. Moreover, we quantify the uncertainty in our approximation by introducing confidence intervals around this curve, offe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#32479;&#35745;&#26080;&#20851;&#22320;&#35780;&#20272;&#20102;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#65292;&#24182;&#35780;&#20272;&#20102;ML&#20272;&#35745;&#22312;&#26816;&#27979;&#26041;&#38754;&#30340;&#34920;&#29616;&#12290;</title><link>https://arxiv.org/abs/2402.15213</link><description>&lt;p&gt;
&#32479;&#35745;&#26080;&#20559;&#22238;&#24402;&#65306;&#19968;&#31181;&#29992;&#20110;&#39564;&#35777;&#22238;&#24402;&#27169;&#22411;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Statistical Agnostic Regression: a machine learning method to validate regression models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15213
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#32479;&#35745;&#26080;&#20851;&#22320;&#35780;&#20272;&#20102;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#65292;&#24182;&#35780;&#20272;&#20102;ML&#20272;&#35745;&#22312;&#26816;&#27979;&#26041;&#38754;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22238;&#24402;&#20998;&#26512;&#26159;&#32479;&#35745;&#24314;&#27169;&#20013;&#30340;&#19968;&#20010;&#26680;&#24515;&#20027;&#39064;&#65292;&#26088;&#22312;&#20272;&#35745;&#22240;&#21464;&#37327;&#65288;&#36890;&#24120;&#31216;&#20026;&#21709;&#24212;&#21464;&#37327;&#65289;&#19982;&#19968;&#20010;&#25110;&#22810;&#20010;&#33258;&#21464;&#37327;&#65288;&#21363;&#35299;&#37322;&#21464;&#37327;&#65289;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#32447;&#24615;&#22238;&#24402;&#26159;&#36804;&#20170;&#20026;&#27490;&#22312;&#39044;&#27979;&#12289;&#39044;&#27979;&#25110;&#22240;&#26524;&#25512;&#26029;&#31561;&#22810;&#20010;&#30740;&#31350;&#39046;&#22495;&#25191;&#34892;&#27492;&#20219;&#21153;&#30340;&#26368;&#27969;&#34892;&#26041;&#27861;&#12290;&#38500;&#20102;&#35299;&#20915;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#30340;&#21508;&#31181;&#20256;&#32479;&#26041;&#27861;&#22806;&#65292;&#22914;&#26222;&#36890;&#26368;&#23567;&#20108;&#20056;&#27861;&#12289;&#23725;&#22238;&#24402;&#25110;&#22871;&#32034;&#22238;&#24402;&#8212;&#8212;&#36825;&#20123;&#26041;&#27861;&#24448;&#24448;&#26159;&#26356;&#39640;&#32423;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#25216;&#26415;&#30340;&#22522;&#30784;&#8212;&#8212;&#21518;&#32773;&#24050;&#25104;&#21151;&#22320;&#24212;&#29992;&#22312;&#36825;&#31181;&#22330;&#26223;&#20013;&#65292;&#20294;&#27809;&#26377;&#23545;&#32479;&#35745;&#26174;&#33879;&#24615;&#36827;&#34892;&#27491;&#24335;&#23450;&#20041;&#12290;&#26368;&#22810;&#65292;&#22522;&#20110;&#32463;&#39564;&#27979;&#37327;&#65288;&#22914;&#27531;&#24046;&#25110;&#20934;&#30830;&#24230;&#65289;&#36827;&#34892;&#32622;&#25442;&#25110;&#22522;&#20110;&#32463;&#20856;&#20998;&#26512;&#65292;&#20197;&#21453;&#26144;ML&#20272;&#35745;&#23545;&#26816;&#27979;&#30340;&#26356;&#39640;&#33021;&#21147;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#32479;&#35745;&#26080;&#20851;&#22320;&#35780;&#20272;&#20102;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#65292;&#24182;&#23545;ML&#20272;&#35745;&#22312;&#26816;&#27979;&#26041;&#38754;&#30340;&#34920;&#29616;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15213v1 Announce Type: cross  Abstract: Regression analysis is a central topic in statistical modeling, aiming to estimate the relationships between a dependent variable, commonly referred to as the response variable, and one or more independent variables, i.e., explanatory variables. Linear regression is by far the most popular method for performing this task in several fields of research, such as prediction, forecasting, or causal inference. Beyond various classical methods to solve linear regression problems, such as Ordinary Least Squares, Ridge, or Lasso regressions - which are often the foundation for more advanced machine learning (ML) techniques - the latter have been successfully applied in this scenario without a formal definition of statistical significance. At most, permutation or classical analyses based on empirical measures (e.g., residuals or accuracy) have been conducted to reflect the greater ability of ML estimations for detection. In this paper, we introd
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21327;&#26041;&#24046;&#33258;&#36866;&#24212;&#30340;&#26368;&#23567;&#20108;&#20056;&#31639;&#27861;&#65292;&#21033;&#29992;&#22312;&#32447;&#20272;&#35745;&#21327;&#26041;&#24046;&#32467;&#26500;&#65292;&#30456;&#23545;&#20110;&#22522;&#20110;&#20195;&#29702;&#26041;&#24046;&#30340;&#31639;&#27861;&#33719;&#24471;&#25913;&#36827;&#30340;&#36951;&#25022;&#19978;&#30028;&#65292;&#29305;&#21035;&#22312;&#21327;&#26041;&#24046;&#31995;&#25968;&#20840;&#20026;&#38750;&#36127;&#26102;&#65292;&#33021;&#26377;&#25928;&#22320;&#21033;&#29992;&#21322;&#33218;&#21453;&#39304;&#65292;&#24182;&#22312;&#21508;&#31181;&#21442;&#25968;&#35774;&#32622;&#19979;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>https://arxiv.org/abs/2402.15171</link><description>&lt;p&gt;
&#29992;&#20110;&#38543;&#26426;&#32452;&#21512;&#21322;&#33218;&#32769;&#34382;&#26426;&#30340;&#21327;&#26041;&#24046;&#33258;&#36866;&#24212;&#26368;&#23567;&#20108;&#20056;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Covariance-Adaptive Least-Squares Algorithm for Stochastic Combinatorial Semi-Bandits
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15171
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21327;&#26041;&#24046;&#33258;&#36866;&#24212;&#30340;&#26368;&#23567;&#20108;&#20056;&#31639;&#27861;&#65292;&#21033;&#29992;&#22312;&#32447;&#20272;&#35745;&#21327;&#26041;&#24046;&#32467;&#26500;&#65292;&#30456;&#23545;&#20110;&#22522;&#20110;&#20195;&#29702;&#26041;&#24046;&#30340;&#31639;&#27861;&#33719;&#24471;&#25913;&#36827;&#30340;&#36951;&#25022;&#19978;&#30028;&#65292;&#29305;&#21035;&#22312;&#21327;&#26041;&#24046;&#31995;&#25968;&#20840;&#20026;&#38750;&#36127;&#26102;&#65292;&#33021;&#26377;&#25928;&#22320;&#21033;&#29992;&#21322;&#33218;&#21453;&#39304;&#65292;&#24182;&#22312;&#21508;&#31181;&#21442;&#25968;&#35774;&#32622;&#19979;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35299;&#20915;&#20102;&#38543;&#26426;&#32452;&#21512;&#21322;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#65292;&#20854;&#20013;&#29609;&#23478;&#21487;&#20197;&#20174;&#21253;&#21547;d&#20010;&#22522;&#26412;&#39033;&#30340;P&#20010;&#23376;&#38598;&#20013;&#36827;&#34892;&#36873;&#25321;&#12290;&#22823;&#22810;&#25968;&#29616;&#26377;&#31639;&#27861;&#65288;&#22914;CUCB&#12289;ESCB&#12289;OLS-UCB&#65289;&#38656;&#35201;&#23545;&#22870;&#21169;&#20998;&#24067;&#26377;&#20808;&#39564;&#30693;&#35782;&#65292;&#27604;&#22914;&#23376;&#39640;&#26031;&#20195;&#29702;-&#26041;&#24046;&#30340;&#19978;&#30028;&#65292;&#36825;&#24456;&#38590;&#20934;&#30830;&#20272;&#35745;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;OLS-UCB&#30340;&#26041;&#24046;&#33258;&#36866;&#24212;&#29256;&#26412;&#65292;&#20381;&#36182;&#20110;&#21327;&#26041;&#24046;&#32467;&#26500;&#30340;&#22312;&#32447;&#20272;&#35745;&#12290;&#22312;&#23454;&#38469;&#35774;&#32622;&#20013;&#65292;&#20272;&#35745;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#31995;&#25968;&#35201;&#23481;&#26131;&#24471;&#22810;&#65292;&#24182;&#19988;&#30456;&#23545;&#20110;&#22522;&#20110;&#20195;&#29702;&#26041;&#24046;&#30340;&#31639;&#27861;&#65292;&#23548;&#33268;&#25913;&#36827;&#30340;&#36951;&#25022;&#19978;&#30028;&#12290;&#24403;&#21327;&#26041;&#24046;&#31995;&#25968;&#20840;&#20026;&#38750;&#36127;&#26102;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#26377;&#25928;&#22320;&#21033;&#29992;&#20102;&#21322;&#33218;&#21453;&#39304;&#65292;&#24182;&#19988;&#21487;&#20197;&#26126;&#26174;&#20248;&#20110;&#32769;&#34382;&#26426;&#21453;&#39304;&#26041;&#27861;&#65292;&#22312;&#25351;&#25968;&#32423;&#21035;P&#8811;d&#20197;&#21450;P&#8804;d&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#19968;&#28857;&#24182;&#19981;&#26469;&#33258;&#22823;&#22810;&#25968;&#29616;&#26377;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15171v1 Announce Type: new  Abstract: We address the problem of stochastic combinatorial semi-bandits, where a player can select from P subsets of a set containing d base items. Most existing algorithms (e.g. CUCB, ESCB, OLS-UCB) require prior knowledge on the reward distribution, like an upper bound on a sub-Gaussian proxy-variance, which is hard to estimate tightly. In this work, we design a variance-adaptive version of OLS-UCB, relying on an online estimation of the covariance structure. Estimating the coefficients of a covariance matrix is much more manageable in practical settings and results in improved regret upper bounds compared to proxy variance-based algorithms. When covariance coefficients are all non-negative, we show that our approach efficiently leverages the semi-bandit feedback and provably outperforms bandit feedback approaches, not only in exponential regimes where P $\gg$ d but also when P $\le$ d, which is not straightforward from most existing analyses.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#26088;&#22312;&#29702;&#35299;&#39640;&#25928;Transformer&#65288;&#20363;&#22914;&#31232;&#30095;Transformer&#21644;&#32447;&#24615;Transformer&#65289;&#30340;&#33021;&#21147;&#21644;&#38480;&#21046;&#65292;&#21457;&#29616;&#23427;&#20204;&#36866;&#21512;&#35299;&#20915;&#19968;&#33324;DP&#20219;&#21153;&#65292;&#20294;&#19981;&#21516;&#20110;&#26631;&#20934;Transformer&#12290;</title><link>https://arxiv.org/abs/2402.13934</link><description>&lt;p&gt;
&#30830;&#23454;&#39640;&#25928;&#30340;Transformer&#33021;&#22815;&#33410;&#32422;&#35745;&#31639;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Do Efficient Transformers Really Save Computation?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13934
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#26088;&#22312;&#29702;&#35299;&#39640;&#25928;Transformer&#65288;&#20363;&#22914;&#31232;&#30095;Transformer&#21644;&#32447;&#24615;Transformer&#65289;&#30340;&#33021;&#21147;&#21644;&#38480;&#21046;&#65292;&#21457;&#29616;&#23427;&#20204;&#36866;&#21512;&#35299;&#20915;&#19968;&#33324;DP&#20219;&#21153;&#65292;&#20294;&#19981;&#21516;&#20110;&#26631;&#20934;Transformer&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22522;&#20110;Transformer&#30340;&#35821;&#35328;&#27169;&#22411;&#22312;&#36234;&#26469;&#36234;&#22823;&#30340;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#65292;&#24182;&#25317;&#26377;&#22823;&#37327;&#21442;&#25968;&#65292;&#25214;&#21040;&#26356;&#39640;&#25928;&#30340;&#26367;&#20195;&#26631;&#20934;Transformer&#21464;&#24471;&#38750;&#24120;&#26377;&#20215;&#20540;&#12290;&#34429;&#28982;&#24050;&#32463;&#25552;&#20986;&#20102;&#35768;&#22810;&#39640;&#25928;&#30340;Transformer&#21644;Transformer&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#20294;&#27809;&#26377;&#19968;&#20010;&#33021;&#22815;&#25552;&#20379;&#23427;&#20204;&#36866;&#21512;&#26367;&#20195;&#26631;&#20934;Transformer&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#36825;&#20351;&#24471;&#24456;&#38590;&#30830;&#23450;&#20309;&#26102;&#20351;&#29992;&#29305;&#23450;&#27169;&#22411;&#20197;&#21450;&#36827;&#19968;&#27493;&#30740;&#31350;&#30340;&#37325;&#28857;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#29702;&#35299;&#39640;&#25928;Transformer&#30340;&#33021;&#21147;&#21644;&#23616;&#38480;&#24615;&#65292;&#29305;&#21035;&#26159;&#31232;&#30095;Transformer&#21644;&#32447;&#24615;Transformer&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#23427;&#20204;&#22312;Chain-of-Thought (CoT)&#25552;&#31034;&#20013;&#23637;&#31034;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#24182;&#36981;&#24490;&#20808;&#21069;&#30340;&#30740;&#31350;&#23558;&#23427;&#20204;&#24314;&#27169;&#20026;&#21160;&#24577;&#35268;&#21010;&#65288;DP&#65289;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#34429;&#28982;&#36825;&#20123;&#27169;&#22411;&#36275;&#22815;&#34920;&#36798;&#35299;&#20915;&#19968;&#33324;DP&#20219;&#21153;&#30340;&#33021;&#21147;&#65292;&#20294;&#19982;&#26631;&#20934;Transformer&#19981;&#21516;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13934v1 Announce Type: cross  Abstract: As transformer-based language models are trained on increasingly large datasets and with vast numbers of parameters, finding more efficient alternatives to the standard Transformer has become very valuable. While many efficient Transformers and Transformer alternatives have been proposed, none provide theoretical guarantees that they are a suitable replacement for the standard Transformer. This makes it challenging to identify when to use a specific model and what directions to prioritize for further investigation. In this paper, we aim to understand the capabilities and limitations of efficient Transformers, specifically the Sparse Transformer and the Linear Transformer. We focus on their reasoning capability as exhibited by Chain-of-Thought (CoT) prompts and follow previous works to model them as Dynamic Programming (DP) problems. Our results show that while these models are expressive enough to solve general DP tasks, contrary to ex
&lt;/p&gt;</description></item><item><title>&#38408;&#20540;&#21644;&#37325;&#26032;&#24402;&#19968;&#21270;Oja&#31639;&#27861;&#30340;&#36755;&#20986;&#21487;&#33719;&#24471;&#19968;&#20010;&#25509;&#36817;&#26368;&#20248;&#30340;&#38169;&#35823;&#29575;&#65292;&#19982;&#26410;&#32463;&#38408;&#20540;&#22788;&#29702;&#30340;Oja&#21521;&#37327;&#30456;&#27604;&#65292;&#36825;&#22823;&#22823;&#20943;&#23567;&#20102;&#35823;&#24046;&#12290;</title><link>https://arxiv.org/abs/2402.07240</link><description>&lt;p&gt;
&#38408;&#20540;Oja&#26159;&#21542;&#36866;&#29992;&#20110;&#31232;&#30095;PCA&#65311;
&lt;/p&gt;
&lt;p&gt;
Thresholded Oja does Sparse PCA?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07240
&lt;/p&gt;
&lt;p&gt;
&#38408;&#20540;&#21644;&#37325;&#26032;&#24402;&#19968;&#21270;Oja&#31639;&#27861;&#30340;&#36755;&#20986;&#21487;&#33719;&#24471;&#19968;&#20010;&#25509;&#36817;&#26368;&#20248;&#30340;&#38169;&#35823;&#29575;&#65292;&#19982;&#26410;&#32463;&#38408;&#20540;&#22788;&#29702;&#30340;Oja&#21521;&#37327;&#30456;&#27604;&#65292;&#36825;&#22823;&#22823;&#20943;&#23567;&#20102;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#24403;&#27604;&#20540;$d/n \rightarrow c &gt; 0$&#26102;&#31232;&#30095;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#30340;&#38382;&#39064;&#12290;&#22312;&#31163;&#32447;&#35774;&#32622;&#19979;&#65292;&#20851;&#20110;&#31232;&#30095;PCA&#30340;&#26368;&#20248;&#29575;&#24050;&#32463;&#26377;&#24456;&#22810;&#30740;&#31350;&#65292;&#20854;&#20013;&#25152;&#26377;&#25968;&#25454;&#37117;&#21487;&#20197;&#29992;&#20110;&#22810;&#27425;&#20256;&#36882;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#24403;&#20154;&#21475;&#29305;&#24449;&#21521;&#37327;&#26159;$s$-&#31232;&#30095;&#26102;&#65292;&#20855;&#26377;$O(d)$&#23384;&#20648;&#21644;$O(nd)$&#26102;&#38388;&#22797;&#26434;&#24230;&#30340;&#27969;&#31639;&#27861;&#36890;&#24120;&#35201;&#27714;&#24378;&#21021;&#22987;&#21270;&#26465;&#20214;&#65292;&#21542;&#21017;&#20250;&#26377;&#27425;&#20248;&#38169;&#35823;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#31639;&#27861;&#65292;&#23545;Oja&#31639;&#27861;&#30340;&#36755;&#20986;&#65288;Oja&#21521;&#37327;&#65289;&#36827;&#34892;&#38408;&#20540;&#21644;&#37325;&#26032;&#24402;&#19968;&#21270;&#65292;&#20174;&#32780;&#33719;&#24471;&#25509;&#36817;&#26368;&#20248;&#30340;&#38169;&#35823;&#29575;&#12290;&#36825;&#38750;&#24120;&#20196;&#20154;&#24778;&#35766;&#65292;&#22240;&#20026;&#27809;&#26377;&#38408;&#20540;&#65292;Oja&#21521;&#37327;&#30340;&#35823;&#24046;&#24456;&#22823;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#38598;&#20013;&#22312;&#38480;&#21046;&#26410;&#24402;&#19968;&#21270;&#30340;Oja&#21521;&#37327;&#30340;&#39033;&#19978;&#65292;&#36825;&#28041;&#21450;&#23558;&#19968;&#32452;&#29420;&#31435;&#38543;&#26426;&#30697;&#38453;&#30340;&#20056;&#31215;&#22312;&#38543;&#26426;&#21021;&#22987;&#21521;&#37327;&#19978;&#30340;&#25237;&#24433;&#12290; &#36825;&#26159;&#38750;&#24179;&#20961;&#19988;&#26032;&#39062;&#30340;&#65292;&#22240;&#20026;&#20197;&#21069;&#30340;Oja&#31639;&#27861;&#20998;&#26512;&#27809;&#26377;&#32771;&#34385;&#36825;&#19968;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.07240v2 Announce Type: cross  Abstract: We consider the problem of Sparse Principal Component Analysis (PCA) when the ratio $d/n \rightarrow c &gt; 0$. There has been a lot of work on optimal rates on sparse PCA in the offline setting, where all the data is available for multiple passes. In contrast, when the population eigenvector is $s$-sparse, streaming algorithms that have $O(d)$ storage and $O(nd)$ time complexity either typically require strong initialization conditions or have a suboptimal error. We show that a simple algorithm that thresholds and renormalizes the output of Oja's algorithm (the Oja vector) obtains a near-optimal error rate. This is very surprising because, without thresholding, the Oja vector has a large error. Our analysis centers around bounding the entries of the unnormalized Oja vector, which involves the projection of a product of independent random matrices on a random initial vector. This is nontrivial and novel since previous analyses of Oja's al
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#21253;&#25324;&#28145;&#24230;&#38598;&#21512;&#12289;&#21464;&#21387;&#22120;&#12289;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#21644;&#31616;&#21333;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#31561;&#22810;&#31181;&#26550;&#26500;&#65292;&#25506;&#32034;&#20102;&#21487;&#35777;&#26126;&#30340;&#38271;&#24230;&#21644;&#32452;&#21512;&#27867;&#21270;&#65292;&#35748;&#20026;&#23545;&#20110;&#38271;&#24230;&#21644;&#32452;&#21512;&#27867;&#21270;&#65292;&#19981;&#21516;&#26550;&#26500;&#38656;&#35201;&#19981;&#21516;&#31243;&#24230;&#30340;&#34920;&#31034;&#35782;&#21035;&#12290;</title><link>https://arxiv.org/abs/2402.04875</link><description>&lt;p&gt;
&#20851;&#20110;&#21487;&#35777;&#26126;&#30340;&#38271;&#24230;&#21644;&#32452;&#21512;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
On Provable Length and Compositional Generalization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04875
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#21253;&#25324;&#28145;&#24230;&#38598;&#21512;&#12289;&#21464;&#21387;&#22120;&#12289;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#21644;&#31616;&#21333;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#31561;&#22810;&#31181;&#26550;&#26500;&#65292;&#25506;&#32034;&#20102;&#21487;&#35777;&#26126;&#30340;&#38271;&#24230;&#21644;&#32452;&#21512;&#27867;&#21270;&#65292;&#35748;&#20026;&#23545;&#20110;&#38271;&#24230;&#21644;&#32452;&#21512;&#27867;&#21270;&#65292;&#19981;&#21516;&#26550;&#26500;&#38656;&#35201;&#19981;&#21516;&#31243;&#24230;&#30340;&#34920;&#31034;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38271;&#24230;&#27867;&#21270;&#8212;&#8212;&#23545;&#35757;&#32451;&#26102;&#26410;&#35265;&#21040;&#30340;&#26356;&#38271;&#24207;&#21015;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#20197;&#21450;&#32452;&#21512;&#27867;&#21270;&#8212;&#8212;&#23545;&#35757;&#32451;&#26102;&#26410;&#35265;&#21040;&#30340;&#20196;&#29260;&#32452;&#21512;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#22312;&#24207;&#21015;&#21040;&#24207;&#21015;&#27169;&#22411;&#20013;&#26159;&#37325;&#35201;&#30340;&#38750;&#20998;&#24067;&#21270;&#27867;&#21270;&#24418;&#24335;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#22312;&#21253;&#25324;&#28145;&#24230;&#38598;&#21512;&#12289;&#21464;&#21387;&#22120;&#12289;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#21644;&#31616;&#21333;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#22312;&#20869;&#30340;&#19968;&#31995;&#21015;&#26550;&#26500;&#20013;&#65292;&#26397;&#30528;&#21487;&#35777;&#26126;&#30340;&#38271;&#24230;&#21644;&#32452;&#21512;&#27867;&#21270;&#36808;&#20986;&#20102;&#31532;&#19968;&#27493;&#12290;&#26681;&#25454;&#26550;&#26500;&#30340;&#19981;&#21516;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19981;&#21516;&#31243;&#24230;&#30340;&#34920;&#31034;&#35782;&#21035;&#30340;&#24517;&#35201;&#24615;&#65292;&#20363;&#22914;&#19982;&#30495;&#23454;&#34920;&#31034;&#20855;&#26377;&#32447;&#24615;&#25110;&#25490;&#21015;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Length generalization -- the ability to generalize to longer sequences than ones seen during training, and compositional generalization -- the ability to generalize to token combinations not seen during training, are crucial forms of out-of-distribution generalization in sequence-to-sequence models. In this work, we take the first steps towards provable length and compositional generalization for a range of architectures, including deep sets, transformers, state space models, and simple recurrent neural nets. Depending on the architecture, we prove different degrees of representation identification, e.g., a linear or a permutation relation with ground truth representation, is necessary for length and compositional generalization.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;RLHF&#30340;&#26694;&#26550;&#65292;&#22312;&#20854;&#20013;&#32771;&#34385;&#20102;&#37096;&#20998;&#35266;&#23519;&#21040;&#30340;&#22870;&#21169;&#29366;&#24577;&#65292;&#24182;&#36890;&#36807;&#23558;&#22522;&#25968;&#21453;&#39304;&#21644;&#20915;&#26007;&#21453;&#39304;&#32553;&#20943;&#20026;PORRL&#24418;&#24335;&#36827;&#34892;&#20102;&#24314;&#27169;&#21644;&#31639;&#27861;&#24320;&#21457;&#12290;</title><link>https://arxiv.org/abs/2402.03282</link><description>&lt;p&gt;
&#19968;&#20010;&#37096;&#20998;&#35266;&#23519;&#21040;&#30340;&#22870;&#21169;&#29366;&#24577;&#22312;RLHF&#20013;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Framework for Partially Observed Reward-States in RLHF
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03282
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;RLHF&#30340;&#26694;&#26550;&#65292;&#22312;&#20854;&#20013;&#32771;&#34385;&#20102;&#37096;&#20998;&#35266;&#23519;&#21040;&#30340;&#22870;&#21169;&#29366;&#24577;&#65292;&#24182;&#36890;&#36807;&#23558;&#22522;&#25968;&#21453;&#39304;&#21644;&#20915;&#26007;&#21453;&#39304;&#32553;&#20943;&#20026;PORRL&#24418;&#24335;&#36827;&#34892;&#20102;&#24314;&#27169;&#21644;&#31639;&#27861;&#24320;&#21457;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#20960;&#24180;&#26469;&#65292;&#24378;&#21270;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#65288;RLHF&#65289;&#30340;&#30740;&#31350;&#22240;&#20854;&#22312;LLMs&#30340;&#21457;&#23637;&#20013;&#36215;&#21040;&#30340;&#20316;&#29992;&#32780;&#21464;&#24471;&#37325;&#35201;&#12290;&#31070;&#32463;&#31185;&#23398;&#30740;&#31350;&#34920;&#26126;&#65292;&#20154;&#31867;&#23545;&#21050;&#28608;&#30340;&#21453;&#24212;&#24050;&#30693;&#20381;&#36182;&#20110;&#37096;&#20998;&#35266;&#23519;&#21040;&#30340;&#8220;&#20869;&#37096;&#29366;&#24577;&#8221;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#24403;&#21069;&#30340;RLHF&#27169;&#22411;&#27809;&#26377;&#32771;&#34385;&#21040;&#36825;&#19968;&#28857;&#12290;&#27492;&#22806;&#65292;&#22823;&#22810;&#25968;RLHF&#27169;&#22411;&#27809;&#26377;&#32771;&#34385;&#21040;&#20013;&#38388;&#21453;&#39304;&#65292;&#22312;&#23454;&#35777;&#30740;&#31350;&#20013;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#65292;&#21487;&#20197;&#24110;&#21161;&#25552;&#39640;&#26679;&#26412;&#22797;&#26434;&#24615;&#21644;&#23545;&#40784;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#23616;&#38480;&#24615;&#65292;&#25105;&#20204;&#23558;RLHF&#24314;&#27169;&#20026;&#37096;&#20998;&#35266;&#23519;&#21040;&#30340;&#22870;&#21169;&#29366;&#24577;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288;PORRL&#65289;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20174;RLHF&#20013;&#20004;&#31181;&#20027;&#35201;&#24418;&#24335;&#30340;&#20154;&#31867;&#21453;&#39304; - &#22522;&#25968;&#21453;&#39304;&#21644;&#20915;&#26007;&#21453;&#39304;&#21040;PORRL&#30340;&#32553;&#20943;&#12290;&#23545;&#20110;&#22522;&#25968;&#21453;&#39304;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#36890;&#29992;&#30340;&#32479;&#35745;&#39640;&#25928;&#31639;&#27861;&#65292;&#24182;&#23558;&#23427;&#20204;&#23454;&#20363;&#21270;&#20026;POR-UCRL&#21644;POR-UCBVI&#12290;&#23545;&#20110;&#20915;&#26007;&#21453;&#39304;&#65292;&#25105;&#20204;&#34920;&#26126;&#65292;&#31616;&#21333;&#30340;&#22522;&#25968;&#21453;&#39304;&#32553;&#20943;&#19981;&#33021;&#36798;&#21040;&#20122;&#32447;&#24615;&#30340;&#20915;&#26007;&#22238;&#24402;&#12290;
&lt;/p&gt;
&lt;p&gt;
The study of reinforcement learning from human feedback (RLHF) has gained prominence in recent years due to its role in the development of LLMs. Neuroscience research shows that human responses to stimuli are known to depend on partially-observed "internal states." Unfortunately current models of RLHF do not take take this into consideration. Moreover most RLHF models do not account for intermediate feedback, which is gaining importance in empirical work and can help improve both sample complexity and alignment. To address these limitations, we model RLHF as reinforcement learning with partially observed reward-states (PORRL). We show reductions from the the two dominant forms of human feedback in RLHF - cardinal and dueling feedback to PORRL. For cardinal feedback, we develop generic statistically efficient algorithms and instantiate them to present POR-UCRL and POR-UCBVI. For dueling feedback, we show that a naive reduction to cardinal feedback fails to achieve sublinear dueling regr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#27861;&#35299;&#20915;&#38750;&#24120;&#25968;&#26680;&#30340;&#26680;&#23725;&#22238;&#24402;&#12290;&#36890;&#36807;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#36880;&#28176;&#20943;&#23567;&#24102;&#23485;&#65292;&#36991;&#20813;&#20102;&#36229;&#21442;&#25968;&#36873;&#25321;&#30340;&#38656;&#27714;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#23485;&#26356;&#26032;&#26041;&#26696;&#65292;&#35777;&#26126;&#20102;&#20854;&#20248;&#20110;&#20351;&#29992;&#24120;&#25968;&#24102;&#23485;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2311.01762</link><description>&lt;p&gt;
&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#27861;&#35299;&#20915;&#38750;&#24120;&#25968;&#26680;&#30340;&#26680;&#23725;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Solving Kernel Ridge Regression with Gradient Descent for a Non-Constant Kernel. (arXiv:2311.01762v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01762
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#27861;&#35299;&#20915;&#38750;&#24120;&#25968;&#26680;&#30340;&#26680;&#23725;&#22238;&#24402;&#12290;&#36890;&#36807;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#36880;&#28176;&#20943;&#23567;&#24102;&#23485;&#65292;&#36991;&#20813;&#20102;&#36229;&#21442;&#25968;&#36873;&#25321;&#30340;&#38656;&#27714;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#23485;&#26356;&#26032;&#26041;&#26696;&#65292;&#35777;&#26126;&#20102;&#20854;&#20248;&#20110;&#20351;&#29992;&#24120;&#25968;&#24102;&#23485;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26680;&#23725;&#22238;&#24402;&#65288;KRR&#65289;&#26159;&#32447;&#24615;&#23725;&#22238;&#24402;&#30340;&#25512;&#24191;&#65292;&#23427;&#22312;&#25968;&#25454;&#20013;&#26159;&#38750;&#32447;&#24615;&#30340;&#65292;&#20294;&#22312;&#21442;&#25968;&#20013;&#26159;&#32447;&#24615;&#30340;&#12290;&#35299;&#20915;&#26041;&#26696;&#21487;&#20197;&#36890;&#36807;&#38381;&#24335;&#35299;&#33719;&#24471;&#65292;&#20854;&#20013;&#21253;&#25324;&#30697;&#38453;&#27714;&#36870;&#65292;&#20063;&#21487;&#20197;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#36845;&#20195;&#33719;&#24471;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#25913;&#21464;&#26680;&#20989;&#25968;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#20174;&#29702;&#35770;&#19978;&#25506;&#35752;&#20102;&#36825;&#23545;&#27169;&#22411;&#22797;&#26434;&#24615;&#21644;&#27867;&#21270;&#24615;&#33021;&#30340;&#24433;&#21709;&#12290;&#22522;&#20110;&#25105;&#20204;&#30340;&#21457;&#29616;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#24179;&#31227;&#19981;&#21464;&#26680;&#30340;&#24102;&#23485;&#26356;&#26032;&#26041;&#26696;&#65292;&#20854;&#20013;&#24102;&#23485;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#36880;&#28176;&#20943;&#23567;&#33267;&#38646;&#65292;&#20174;&#32780;&#36991;&#20813;&#20102;&#36229;&#21442;&#25968;&#36873;&#25321;&#30340;&#38656;&#35201;&#12290;&#25105;&#20204;&#22312;&#30495;&#23454;&#21644;&#21512;&#25104;&#25968;&#25454;&#19978;&#23637;&#31034;&#20102;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#36880;&#28176;&#20943;&#23567;&#24102;&#23485;&#30340;&#20248;&#20110;&#20351;&#29992;&#24120;&#25968;&#24102;&#23485;&#65292;&#36890;&#36807;&#20132;&#21449;&#39564;&#35777;&#21644;&#36793;&#32536;&#20284;&#28982;&#26368;&#22823;&#21270;&#36873;&#25321;&#30340;&#24102;&#23485;&#12290;&#25105;&#20204;&#36824;&#20174;&#29702;&#35770;&#21644;&#23454;&#35777;&#19978;&#35777;&#26126;&#20102;&#20351;&#29992;&#36880;&#28176;&#20943;&#23567;&#30340;&#24102;&#23485;&#26102;&#65292;&#25105;&#20204;&#33021;&#22815;...
&lt;/p&gt;
&lt;p&gt;
Kernel ridge regression, KRR, is a generalization of linear ridge regression that is non-linear in the data, but linear in the parameters. The solution can be obtained either as a closed-form solution, which includes a matrix inversion, or iteratively through gradient descent. Using the iterative approach opens up for changing the kernel during training, something that is investigated in this paper. We theoretically address the effects this has on model complexity and generalization. Based on our findings, we propose an update scheme for the bandwidth of translational-invariant kernels, where we let the bandwidth decrease to zero during training, thus circumventing the need for hyper-parameter selection. We demonstrate on real and synthetic data how decreasing the bandwidth during training outperforms using a constant bandwidth, selected by cross-validation and marginal likelihood maximization. We also show theoretically and empirically that using a decreasing bandwidth, we are able to
&lt;/p&gt;</description></item><item><title>&#20998;&#23618;&#38543;&#26426;&#24179;&#28369;&#26159;&#19968;&#31181;&#22312;&#22797;&#26434;&#25968;&#25454;&#19978;&#36827;&#34892;&#40065;&#26834;&#24615;&#35748;&#35777;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#21482;&#22312;&#19968;&#20010;&#23545;&#35937;&#30340;&#23376;&#38598;&#19978;&#28155;&#21152;&#38543;&#26426;&#22122;&#22768;&#65292;&#20197;&#26356;&#26377;&#38024;&#23545;&#24615;&#30340;&#26041;&#24335;&#25552;&#20379;&#20102;&#26356;&#24378;&#30340;&#40065;&#26834;&#24615;&#20445;&#35777;&#21644;&#39640;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.16221</link><description>&lt;p&gt;
&#20998;&#23618;&#38543;&#26426;&#24179;&#28369;
&lt;/p&gt;
&lt;p&gt;
Hierarchical Randomized Smoothing. (arXiv:2310.16221v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16221
&lt;/p&gt;
&lt;p&gt;
&#20998;&#23618;&#38543;&#26426;&#24179;&#28369;&#26159;&#19968;&#31181;&#22312;&#22797;&#26434;&#25968;&#25454;&#19978;&#36827;&#34892;&#40065;&#26834;&#24615;&#35748;&#35777;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#21482;&#22312;&#19968;&#20010;&#23545;&#35937;&#30340;&#23376;&#38598;&#19978;&#28155;&#21152;&#38543;&#26426;&#22122;&#22768;&#65292;&#20197;&#26356;&#26377;&#38024;&#23545;&#24615;&#30340;&#26041;&#24335;&#25552;&#20379;&#20102;&#26356;&#24378;&#30340;&#40065;&#26834;&#24615;&#20445;&#35777;&#21644;&#39640;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#26159;&#22797;&#26434;&#30340;&#65292;&#36890;&#24120;&#30001;&#21487;&#20998;&#35299;&#20026;&#22810;&#20010;&#23454;&#20307;&#30340;&#23545;&#35937;&#32452;&#25104;&#65288;&#20363;&#22914;&#65292;&#23558;&#22270;&#20687;&#20998;&#35299;&#20026;&#20687;&#32032;&#65292;&#23558;&#22270;&#24418;&#20998;&#35299;&#20026;&#30456;&#20114;&#36830;&#25509;&#30340;&#33410;&#28857;&#65289;&#12290;&#38543;&#26426;&#24179;&#28369;&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#20351;&#27169;&#22411;&#22312;&#20854;&#36755;&#20837;&#30340;&#24494;&#23567;&#21464;&#21270;&#19978;&#20855;&#26377;&#35777;&#26126;&#30340;&#40065;&#26834;&#24615;-&#36890;&#36807;&#22312;&#20998;&#31867;&#20043;&#21069;&#38543;&#26426;&#28155;&#21152;&#22122;&#22768;&#26469;&#20445;&#35777;&#22810;&#25968;&#25237;&#31080;&#30340;&#40065;&#26834;&#24615;&#12290;&#28982;&#32780;&#65292;&#24403;&#23545;&#25163;&#19981;&#26159;&#20219;&#24847;&#24178;&#25200;&#25972;&#20010;&#23545;&#35937;&#65288;&#20363;&#22914;&#22270;&#20687;&#65289;&#65292;&#32780;&#26159;&#23545;&#35937;&#30340;&#26576;&#20010;&#23454;&#20307;&#30340;&#23376;&#38598;&#65288;&#20363;&#22914;&#20687;&#32032;&#65289;&#26102;&#65292;&#36890;&#36807;&#38543;&#26426;&#24179;&#28369;&#23545;&#36825;&#31181;&#22797;&#26434;&#25968;&#25454;&#36827;&#34892;&#40065;&#26834;&#24615;&#35748;&#35777;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#20316;&#20026;&#35299;&#20915;&#26041;&#26696;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20998;&#23618;&#38543;&#26426;&#24179;&#28369;&#65306;&#25105;&#20204;&#36890;&#36807;&#20165;&#22312;&#38543;&#26426;&#36873;&#25321;&#30340;&#23454;&#20307;&#23376;&#38598;&#19978;&#28155;&#21152;&#38543;&#26426;&#22122;&#22768;&#26469;&#37096;&#20998;&#24179;&#28369;&#23545;&#35937;&#12290;&#36890;&#36807;&#20197;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#26377;&#38024;&#23545;&#24615;&#30340;&#26041;&#24335;&#28155;&#21152;&#22122;&#22768;&#65292;&#25105;&#20204;&#33719;&#24471;&#26356;&#24378;&#30340;&#40065;&#26834;&#24615;&#20445;&#35777;&#65292;&#21516;&#26102;&#20445;&#25345;&#39640;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#20351;&#29992;&#19981;&#21516;&#30340;&#22122;&#22768;&#20998;&#24067;&#21021;&#22987;&#21270;&#20998;&#23618;&#24179;&#28369;&#65292;&#24471;&#21040;&#20102;&#26032;&#30340;&#40065;&#26834;&#24615;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Real-world data is complex and often consists of objects that can be decomposed into multiple entities (e.g. images into pixels, graphs into interconnected nodes). Randomized smoothing is a powerful framework for making models provably robust against small changes to their inputs - by guaranteeing robustness of the majority vote when randomly adding noise before classification. Yet, certifying robustness on such complex data via randomized smoothing is challenging when adversaries do not arbitrarily perturb entire objects (e.g. images) but only a subset of their entities (e.g. pixels). As a solution, we introduce hierarchical randomized smoothing: We partially smooth objects by adding random noise only on a randomly selected subset of their entities. By adding noise in a more targeted manner than existing methods we obtain stronger robustness guarantees while maintaining high accuracy. We initialize hierarchical smoothing using different noising distributions, yielding novel robustness
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#21327;&#21516;&#25193;&#25955;&#24674;&#22797;&#20284;&#28982;&#65288;CDRL&#65289;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#21644;&#37319;&#26679;&#19968;&#31995;&#21015;&#22522;&#20110;&#33021;&#37327;&#30340;&#27169;&#22411;&#65288;EBMs&#65289;&#65292;&#36890;&#36807;&#22312;&#19981;&#26029;&#22024;&#26434;&#21270;&#30340;&#25968;&#25454;&#38598;&#29256;&#26412;&#19978;&#23450;&#20041;&#19981;&#21516;&#22122;&#22768;&#27700;&#24179;&#30340;EBMs&#65292;&#24182;&#19982;&#21021;&#22987;&#21270;&#27169;&#22411;&#37197;&#23545;&#21327;&#21516;&#35757;&#32451;&#12290;&#36825;&#31181;&#26041;&#27861;&#26088;&#22312;&#20851;&#38381;EBMs&#21644;&#20854;&#20182;&#29983;&#25104;&#26694;&#26550;&#20043;&#38388;&#30340;&#26679;&#26412;&#36136;&#37327;&#24046;&#36317;&#12290;</title><link>http://arxiv.org/abs/2309.05153</link><description>&lt;p&gt;
&#36890;&#36807;&#21327;&#21516;&#25193;&#25955;&#24674;&#22797;&#20284;&#28982;&#23398;&#20064;&#22522;&#20110;&#33021;&#37327;&#30340;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Learning Energy-Based Models by Cooperative Diffusion Recovery Likelihood. (arXiv:2309.05153v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05153
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#21327;&#21516;&#25193;&#25955;&#24674;&#22797;&#20284;&#28982;&#65288;CDRL&#65289;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#21644;&#37319;&#26679;&#19968;&#31995;&#21015;&#22522;&#20110;&#33021;&#37327;&#30340;&#27169;&#22411;&#65288;EBMs&#65289;&#65292;&#36890;&#36807;&#22312;&#19981;&#26029;&#22024;&#26434;&#21270;&#30340;&#25968;&#25454;&#38598;&#29256;&#26412;&#19978;&#23450;&#20041;&#19981;&#21516;&#22122;&#22768;&#27700;&#24179;&#30340;EBMs&#65292;&#24182;&#19982;&#21021;&#22987;&#21270;&#27169;&#22411;&#37197;&#23545;&#21327;&#21516;&#35757;&#32451;&#12290;&#36825;&#31181;&#26041;&#27861;&#26088;&#22312;&#20851;&#38381;EBMs&#21644;&#20854;&#20182;&#29983;&#25104;&#26694;&#26550;&#20043;&#38388;&#30340;&#26679;&#26412;&#36136;&#37327;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39640;&#32500;&#25968;&#25454;&#19978;&#20351;&#29992;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#35757;&#32451;&#33021;&#37327;&#22522;&#20934;&#27169;&#22411;&#65288;EBMs&#65289;&#21487;&#33021;&#20855;&#26377;&#25361;&#25112;&#24615;&#19988;&#32791;&#26102;&#36739;&#38271;&#12290;&#22240;&#27492;&#65292;EBMs&#21644;&#20854;&#20182;&#29983;&#25104;&#26694;&#26550;&#65288;&#22914;GANs&#21644;&#25193;&#25955;&#27169;&#22411;&#65289;&#20043;&#38388;&#23384;&#22312;&#26126;&#26174;&#30340;&#26679;&#26412;&#36136;&#37327;&#24046;&#36317;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#21463;&#26368;&#36817;&#36890;&#36807;&#26368;&#22823;&#21270;&#25193;&#25955;&#24674;&#22797;&#20284;&#28982;&#65288;DRL&#65289;&#26469;&#23398;&#20064;EBMs&#30340;&#21162;&#21147;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21327;&#21516;&#25193;&#25955;&#24674;&#22797;&#20284;&#28982;&#65288;CDRL&#65289;&#65292;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#26469;&#21487;&#34892;&#22320;&#23398;&#20064;&#21644;&#20174;&#19968;&#31995;&#21015;EBMs&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#36825;&#20123;EBMs&#23450;&#20041;&#22312;&#36234;&#26469;&#36234;&#22024;&#26434;&#30340;&#25968;&#25454;&#38598;&#29256;&#26412;&#19978;&#65292;&#24182;&#19982;&#27599;&#20010;EBM&#30340;&#21021;&#22987;&#21270;&#27169;&#22411;&#37197;&#23545;&#12290;&#22312;&#27599;&#20010;&#22122;&#22768;&#27700;&#24179;&#19978;&#65292;&#21021;&#22987;&#21270;&#27169;&#22411;&#23398;&#20064;&#22312;EBM&#30340;&#37319;&#26679;&#36807;&#31243;&#20013;&#20998;&#25674;&#65292;&#32780;&#20004;&#20010;&#27169;&#22411;&#22312;&#21327;&#21516;&#35757;&#32451;&#26694;&#26550;&#20869;&#20849;&#21516;&#20272;&#35745;&#12290;&#21021;&#22987;&#21270;&#27169;&#22411;&#29983;&#25104;&#30340;&#26679;&#26412;&#20316;&#20026;&#36215;&#22987;&#28857;&#65292;&#32463;&#36807;EBM&#30340;&#20960;&#20010;&#37319;&#26679;&#27493;&#39588;&#36827;&#34892;&#25913;&#36827;&#12290;&#36890;&#36807;&#25913;&#36827;&#21518;&#30340;&#26679;&#26412;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;&#24674;&#22797;&#20284;&#28982;&#26469;&#20248;&#21270;EBM&#12290;
&lt;/p&gt;
&lt;p&gt;
Training energy-based models (EBMs) with maximum likelihood estimation on high-dimensional data can be both challenging and time-consuming. As a result, there a noticeable gap in sample quality between EBMs and other generative frameworks like GANs and diffusion models. To close this gap, inspired by the recent efforts of learning EBMs by maximimizing diffusion recovery likelihood (DRL), we propose cooperative diffusion recovery likelihood (CDRL), an effective approach to tractably learn and sample from a series of EBMs defined on increasingly noisy versons of a dataset, paired with an initializer model for each EBM. At each noise level, the initializer model learns to amortize the sampling process of the EBM, and the two models are jointly estimated within a cooperative training framework. Samples from the initializer serve as starting points that are refined by a few sampling steps from the EBM. With the refined samples, the EBM is optimized by maximizing recovery likelihood, while t
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#21442;&#25968;&#30340;&#20108;&#20301;&#21327;&#26041;&#24046;&#20272;&#35745;&#22120;&#65292;&#36890;&#36807;&#20351;&#29992;&#21464;&#21270;&#30340;&#25238;&#21160;&#23610;&#24230;&#65292;&#35299;&#20915;&#20102;&#22312;&#21327;&#26041;&#24046;&#30697;&#38453;&#23545;&#35282;&#32447;&#20027;&#23548;&#24773;&#20917;&#19979;&#20272;&#35745;&#22120;&#19982;&#26679;&#26412;&#21327;&#26041;&#24046;&#20043;&#38388;&#30340;&#31639;&#23376;&#33539;&#25968;&#35823;&#24046;&#24046;&#36317;&#20197;&#21450;&#20381;&#36182;&#26410;&#30693;&#21442;&#25968;&#30340;&#25238;&#21160;&#23610;&#24230;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.16059</link><description>&lt;p&gt;
&#19968;&#31181;&#26080;&#38656;&#21442;&#25968;&#30340;&#25913;&#36827;&#20108;&#20301;&#21327;&#26041;&#24046;&#20272;&#35745;&#22120;
&lt;/p&gt;
&lt;p&gt;
A Parameter-Free Two-Bit Covariance Estimator with Improved Operator Norm Error Rate. (arXiv:2308.16059v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16059
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#21442;&#25968;&#30340;&#20108;&#20301;&#21327;&#26041;&#24046;&#20272;&#35745;&#22120;&#65292;&#36890;&#36807;&#20351;&#29992;&#21464;&#21270;&#30340;&#25238;&#21160;&#23610;&#24230;&#65292;&#35299;&#20915;&#20102;&#22312;&#21327;&#26041;&#24046;&#30697;&#38453;&#23545;&#35282;&#32447;&#20027;&#23548;&#24773;&#20917;&#19979;&#20272;&#35745;&#22120;&#19982;&#26679;&#26412;&#21327;&#26041;&#24046;&#20043;&#38388;&#30340;&#31639;&#23376;&#33539;&#25968;&#35823;&#24046;&#24046;&#36317;&#20197;&#21450;&#20381;&#36182;&#26410;&#30693;&#21442;&#25968;&#30340;&#25238;&#21160;&#23610;&#24230;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;Dirksen, Maly and Rauhut&#22312;&#12298;Annals of Statistics&#12299;&#19978;&#24320;&#21457;&#20102;&#19968;&#31181;&#20351;&#29992;&#27599;&#20010;&#26465;&#30446;&#20004;&#20301;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#22120;&#12290;&#35813;&#20272;&#35745;&#22120;&#22312;&#19968;&#33324;&#20122;&#39640;&#26031;&#20998;&#24067;&#19979;&#36798;&#21040;&#20102;&#36817;&#20284;&#26497;&#23567;&#21270;&#36895;&#29575;&#65292;&#20294;&#20063;&#23384;&#22312;&#20004;&#20010;&#38382;&#39064;&#65306;&#29702;&#35770;&#19978;&#65292;&#22312;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#23545;&#35282;&#32447;&#30001;&#23569;&#25968;&#26465;&#30446;&#20027;&#23548;&#26102;&#65292;&#20854;&#20272;&#35745;&#22120;&#19982;&#26679;&#26412;&#21327;&#26041;&#24046;&#20043;&#38388;&#23384;&#22312;&#26412;&#36136;&#19978;&#30340;&#31639;&#23376;&#33539;&#25968;&#35823;&#24046;&#24046;&#36317;&#65307;&#23454;&#38469;&#19978;&#65292;&#20854;&#24615;&#33021;&#20005;&#37325;&#20381;&#36182;&#20110;&#38656;&#35201;&#26681;&#25454;&#19968;&#20123;&#26410;&#30693;&#21442;&#25968;&#36827;&#34892;&#35843;&#25972;&#30340;&#25238;&#21160;&#23610;&#24230;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21516;&#26102;&#35299;&#20915;&#36825;&#20004;&#20010;&#38382;&#39064;&#30340;&#26032;&#22411;&#20108;&#20301;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#22120;&#12290;&#19982;Dirksen&#31561;&#20154;&#37319;&#29992;&#30340;&#22343;&#21248;&#25238;&#21160;&#30456;&#20851;&#30340;&#31526;&#21495;&#37327;&#21270;&#22120;&#19981;&#21516;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#21463;&#22810;&#20301;&#22343;&#21248;&#37327;&#21270;&#22120;&#21551;&#21457;&#30340;&#19977;&#35282;&#25238;&#21160;&#22120;&#20043;&#21518;&#20877;&#36827;&#34892;&#20108;&#20301;&#37327;&#21270;&#12290;&#36890;&#36807;&#20351;&#29992;&#21508;&#20010;&#26465;&#30446;&#20043;&#38388;&#21464;&#21270;&#30340;&#25238;&#21160;&#23610;&#24230;&#65292;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#33719;&#24471;&#20102;&#25913;&#36827;&#30340;&#31639;&#23376;&#33539;&#25968;&#35823;&#24046;&#29575;&#65292;&#35813;&#35823;&#24046;&#29575;&#21462;&#20915;&#20110;...
&lt;/p&gt;
&lt;p&gt;
A covariance matrix estimator using two bits per entry was recently developed by Dirksen, Maly and Rauhut [Annals of Statistics, 50(6), pp. 3538-3562]. The estimator achieves near minimax rate for general sub-Gaussian distributions, but also suffers from two downsides: theoretically, there is an essential gap on operator norm error between their estimator and sample covariance when the diagonal of the covariance matrix is dominated by only a few entries; practically, its performance heavily relies on the dithering scale, which needs to be tuned according to some unknown parameters. In this work, we propose a new 2-bit covariance matrix estimator that simultaneously addresses both issues. Unlike the sign quantizer associated with uniform dither in Dirksen et al., we adopt a triangular dither prior to a 2-bit quantizer inspired by the multi-bit uniform quantizer. By employing dithering scales varying across entries, our estimator enjoys an improved operator norm error rate that depends o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#22312;&#22270;&#25299;&#25169;&#30340;&#22270;&#28857;&#36807;&#31243;&#26041;&#27861;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28145;&#24230;&#22270;&#26680;&#26469;&#25551;&#36848;&#20107;&#20214;&#20043;&#38388;&#30340;&#35302;&#21457;&#21644;&#25233;&#21046;&#25928;&#24212;&#65292;&#35813;&#26041;&#27861;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#20855;&#26377;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.11313</link><description>&lt;p&gt;
&#28145;&#24230;&#22270;&#26680;&#28857;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Deep graph kernel point processes. (arXiv:2306.11313v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11313
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#22312;&#22270;&#25299;&#25169;&#30340;&#22270;&#28857;&#36807;&#31243;&#26041;&#27861;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28145;&#24230;&#22270;&#26680;&#26469;&#25551;&#36848;&#20107;&#20214;&#20043;&#38388;&#30340;&#35302;&#21457;&#21644;&#25233;&#21046;&#25928;&#24212;&#65292;&#35813;&#26041;&#27861;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#20855;&#26377;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28857;&#36807;&#31243;&#27169;&#22411;&#24191;&#27867;&#29992;&#20110;&#20998;&#26512;&#22270;&#20013;&#24322;&#27493;&#20107;&#20214;&#65292;&#21453;&#26144;&#19981;&#21516;&#31867;&#22411;&#20107;&#20214;&#20043;&#38388;&#30340;&#30456;&#20114;&#24433;&#21709;&#12290;&#39044;&#27979;&#26410;&#26469;&#20107;&#20214;&#30340;&#26102;&#38388;&#21644;&#31867;&#22411;&#26159;&#19968;&#39033;&#20851;&#38190;&#20219;&#21153;&#65292;&#24182;&#19988;&#22270;&#30340;&#22823;&#23567;&#21644;&#25299;&#25169;&#32467;&#26500;&#22686;&#21152;&#20102;&#38382;&#39064;&#30340;&#38590;&#24230;&#12290;&#26368;&#36817;&#30340;&#31070;&#32463;&#28857;&#36807;&#31243;&#27169;&#22411;&#25581;&#31034;&#20102;&#25429;&#25417;&#22797;&#26434;&#30340;&#20107;&#20214;&#31867;&#21035;&#20043;&#38388;&#20381;&#36182;&#20851;&#31995;&#30340;&#21487;&#33021;&#24615;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#27599;&#20010;&#30446;&#26631;&#20107;&#20214;&#31867;&#22411;&#30340;&#24378;&#24230;&#35745;&#31639;&#20013;&#20351;&#29992;&#20102;&#21253;&#25324;&#25152;&#26377;&#20107;&#20214;&#31867;&#21035;&#22312;&#20869;&#30340;&#26410;&#32463;&#28388;&#27874;&#30340;&#20107;&#20214;&#35760;&#24405;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#22312;&#22270;&#25299;&#25169;&#30340;&#22270;&#28857;&#36807;&#31243;&#26041;&#27861;&#12290;&#23545;&#24212;&#30340;&#26080;&#21521;&#22270;&#20855;&#26377;&#20195;&#34920;&#20107;&#20214;&#31867;&#21035;&#30340;&#33410;&#28857;&#21644;&#34920;&#31034;&#28508;&#22312;&#36129;&#29486;&#20851;&#31995;&#30340;&#36793;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28145;&#24230;&#22270;&#26680;&#26469;&#25551;&#36848;&#20107;&#20214;&#20043;&#38388;&#30340;&#35302;&#21457;&#21644;&#25233;&#21046;&#25928;&#24212;&#12290;&#26412;&#36136;&#24433;&#21709;&#32467;&#26500;&#36890;&#36807;&#22270;&#31070;&#32463;&#32593;&#32476;-based&#30340;&#23616;&#37096;&#37051;&#22495;&#20449;&#24687;&#32858;&#21512;&#36827;&#34892;&#20102;&#34701;&#21512;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#27604;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#26356;&#20855;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Point process models are widely used to analyze asynchronous events occurring within a graph that reflect how different types of events influence one another. Predicting future events' times and types is a crucial task, and the size and topology of the graph add to the challenge of the problem. Recent neural point process models unveil the possibility of capturing intricate inter-event-category dependencies. However, such methods utilize an unfiltered history of events, including all event categories in the intensity computation for each target event type. In this work, we propose a graph point process method where event interactions occur based on a latent graph topology. The corresponding undirected graph has nodes representing event categories and edges indicating potential contribution relationships. We then develop a novel deep graph kernel to characterize the triggering and inhibiting effects between events. The intrinsic influence structures are incorporated via the graph neural
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#19982;&#31070;&#32463;&#32593;&#32476;&#23436;&#20840;&#23545;&#24212;&#30340;&#26080;&#38480;&#26641;&#29366;PGMs&#26469;&#35299;&#20915;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#32570;&#20047;PGMs&#30340;&#31934;&#30830;&#35821;&#20041;&#21644;&#26126;&#30830;&#23450;&#20041;&#30340;&#27010;&#29575;&#35299;&#37322;&#30340;&#38382;&#39064;&#12290;&#30740;&#31350;&#21457;&#29616;DNNs&#22312;&#21069;&#21521;&#20256;&#25773;&#26102;&#30830;&#23454;&#25191;&#34892;PGM&#25512;&#26029;&#30340;&#36817;&#20284;&#65292;&#36825;&#19982;&#29616;&#26377;&#30740;&#31350;&#19981;&#21516;&#65292;&#23427;&#38416;&#26126;&#20102;DNNs&#23545;PGMs&#20013;&#30340;&#31934;&#30830;&#25512;&#29702;&#30340;&#26356;&#30452;&#25509;&#36817;&#20284;&#65292;&#28508;&#22312;&#30340;&#22909;&#22788;&#21253;&#25324;&#25913;&#36827;DNNs&#30340;&#25945;&#23398;&#21644;&#35299;&#37322;&#65292;&#20197;&#21450;&#33021;&#22815;&#21512;&#24182;PGMs&#21644;DNNs&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.17583</link><description>&lt;p&gt;
&#20851;&#20110;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#26080;&#38480;&#26641;&#29366;&#27010;&#29575;&#22270;&#27169;&#22411;&#30340;&#35770;&#25991;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Neural Networks as Infinite Tree-Structured Probabilistic Graphical Models. (arXiv:2305.17583v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17583
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#19982;&#31070;&#32463;&#32593;&#32476;&#23436;&#20840;&#23545;&#24212;&#30340;&#26080;&#38480;&#26641;&#29366;PGMs&#26469;&#35299;&#20915;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#32570;&#20047;PGMs&#30340;&#31934;&#30830;&#35821;&#20041;&#21644;&#26126;&#30830;&#23450;&#20041;&#30340;&#27010;&#29575;&#35299;&#37322;&#30340;&#38382;&#39064;&#12290;&#30740;&#31350;&#21457;&#29616;DNNs&#22312;&#21069;&#21521;&#20256;&#25773;&#26102;&#30830;&#23454;&#25191;&#34892;PGM&#25512;&#26029;&#30340;&#36817;&#20284;&#65292;&#36825;&#19982;&#29616;&#26377;&#30740;&#31350;&#19981;&#21516;&#65292;&#23427;&#38416;&#26126;&#20102;DNNs&#23545;PGMs&#20013;&#30340;&#31934;&#30830;&#25512;&#29702;&#30340;&#26356;&#30452;&#25509;&#36817;&#20284;&#65292;&#28508;&#22312;&#30340;&#22909;&#22788;&#21253;&#25324;&#25913;&#36827;DNNs&#30340;&#25945;&#23398;&#21644;&#35299;&#37322;&#65292;&#20197;&#21450;&#33021;&#22815;&#21512;&#24182;PGMs&#21644;DNNs&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#32570;&#20047;&#27010;&#29575;&#22270;&#27169;&#22411;(PGMs)&#30340;&#31934;&#30830;&#35821;&#20041;&#21644;&#26126;&#30830;&#23450;&#20041;&#30340;&#27010;&#29575;&#35299;&#37322;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#19982;&#31070;&#32463;&#32593;&#32476;&#23436;&#20840;&#23545;&#24212;&#30340;&#26080;&#38480;&#26641;&#29366;PGMs&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;DNNs&#22312;&#21069;&#21521;&#20256;&#25773;&#26399;&#38388;&#30830;&#23454;&#25191;&#34892;PGM&#25512;&#26029;&#30340;&#36817;&#20284;&#65292;&#36825;&#19982;&#26366;&#32463;&#30340;&#31070;&#32463;&#32593;&#32476;&#25551;&#36848;&#20026;&#26680;&#26426;&#22120;&#25110;&#26080;&#38480;&#22823;&#23567;&#30340;&#39640;&#26031;&#36807;&#31243;&#30340;&#29616;&#26377;&#30740;&#31350;&#19981;&#21516;&#65292;&#23427;&#38416;&#26126;&#20102;DNNs&#23545;PGMs&#20013;&#30340;&#31934;&#30830;&#25512;&#29702;&#30340;&#26356;&#30452;&#25509;&#36817;&#20284;&#12290;&#28508;&#22312;&#30340;&#22909;&#22788;&#21253;&#25324;&#25913;&#36827;DNNs&#30340;&#25945;&#23398;&#21644;&#35299;&#37322;&#65292;&#20197;&#21450;&#33021;&#22815;&#21512;&#24182;PGMs&#21644;DNNs&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep neural networks (DNNs) lack the precise semantics and definitive probabilistic interpretation of probabilistic graphical models (PGMs). In this paper, we propose an innovative solution by constructing infinite tree-structured PGMs that correspond exactly to neural networks. Our research reveals that DNNs, during forward propagation, indeed perform approximations of PGM inference that are precise in this alternative PGM structure. Not only does our research complement existing studies that describe neural networks as kernel machines or infinite-sized Gaussian processes, it also elucidates a more direct approximation that DNNs make to exact inference in PGMs. Potential benefits include improved pedagogy and interpretation of DNNs, and algorithms that can merge the strengths of PGMs and DNNs.
&lt;/p&gt;</description></item></channel></rss>