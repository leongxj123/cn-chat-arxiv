<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#23558;Koopman&#31639;&#23376;&#26694;&#26550;&#19982;&#26680;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#36890;&#36807;Nystro&#776;m&#36924;&#36817;&#23454;&#29616;&#20102;&#23545;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#30340;&#26377;&#25928;&#25511;&#21046;&#65292;&#20854;&#29702;&#35770;&#36129;&#29486;&#22312;&#20110;&#25512;&#23548;&#20986;Nystro&#776;m&#36924;&#36817;&#25928;&#26524;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2403.02811</link><description>&lt;p&gt;
&#20855;&#26377;Koopman&#31639;&#23376;&#23398;&#20064;&#21644;Nystro&#776;m&#26041;&#27861;&#30340;&#38750;&#32447;&#24615;&#31995;&#32479;&#30340;&#32447;&#24615;&#20108;&#27425;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Linear quadratic control of nonlinear systems with Koopman operator learning and the Nystr\"om method
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02811
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;Koopman&#31639;&#23376;&#26694;&#26550;&#19982;&#26680;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#36890;&#36807;Nystro&#776;m&#36924;&#36817;&#23454;&#29616;&#20102;&#23545;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#30340;&#26377;&#25928;&#25511;&#21046;&#65292;&#20854;&#29702;&#35770;&#36129;&#29486;&#22312;&#20110;&#25512;&#23548;&#20986;Nystro&#776;m&#36924;&#36817;&#25928;&#26524;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;Koopman&#31639;&#23376;&#26694;&#26550;&#22914;&#20309;&#19982;&#26680;&#26041;&#27861;&#30456;&#32467;&#21512;&#20197;&#26377;&#25928;&#25511;&#21046;&#38750;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#12290;&#34429;&#28982;&#26680;&#26041;&#27861;&#36890;&#24120;&#20855;&#26377;&#24456;&#22823;&#30340;&#35745;&#31639;&#38656;&#27714;&#65292;&#20294;&#25105;&#20204;&#23637;&#31034;&#20102;&#38543;&#26426;&#23376;&#31354;&#38388;&#65288;Nystro&#776;m&#36924;&#36817;&#65289;&#22914;&#20309;&#23454;&#29616;&#24040;&#22823;&#30340;&#35745;&#31639;&#33410;&#32422;&#65292;&#21516;&#26102;&#20445;&#25345;&#31934;&#24230;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#25216;&#26415;&#36129;&#29486;&#22312;&#20110;&#25512;&#23548;&#20986;&#20851;&#20110;Nystro&#776;m&#36924;&#36817;&#25928;&#26524;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#32447;&#24615;&#20108;&#27425;&#35843;&#33410;&#22120;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#23545;&#20110;&#26368;&#20248;&#25511;&#21046;&#38382;&#39064;&#30340;&#30456;&#20851;&#35299;&#30340;&#36817;&#20284;Riccati&#31639;&#23376;&#21644;&#35843;&#33410;&#22120;&#30446;&#26631;&#37117;&#20197;$ m^{-1/2} $&#30340;&#36895;&#29575;&#25910;&#25947;&#65292;&#20854;&#20013;$ m $&#26159;&#38543;&#26426;&#23376;&#31354;&#38388;&#22823;&#23567;&#12290;&#29702;&#35770;&#21457;&#29616;&#24471;&#21040;&#20102;&#25968;&#20540;&#23454;&#39564;&#30340;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02811v1 Announce Type: cross  Abstract: In this paper, we study how the Koopman operator framework can be combined with kernel methods to effectively control nonlinear dynamical systems. While kernel methods have typically large computational requirements, we show how random subspaces (Nystr\"om approximation) can be used to achieve huge computational savings while preserving accuracy. Our main technical contribution is deriving theoretical guarantees on the effect of the Nystr\"om approximation. More precisely, we study the linear quadratic regulator problem, showing that both the approximated Riccati operator and the regulator objective, for the associated solution of the optimal control problem, converge at the rate $m^{-1/2}$, where $m$ is the random subspace size. Theoretical findings are complemented by numerical experiments corroborating our results.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#21305;&#37197;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#21333;&#20301;&#21333;&#32431;&#24418;&#36827;&#34892;&#20984;&#26494;&#24347;&#65292;&#24182;&#24320;&#21457;&#20102;&#39640;&#25928;&#30340;&#38236;&#20687;&#19979;&#38477;&#26041;&#26696;&#26469;&#35299;&#20915;&#35813;&#38382;&#39064;&#12290;&#22312;&#30456;&#20851;&#39640;&#26031;Wigner&#27169;&#22411;&#19979;&#65292;&#21333;&#32431;&#24418;&#26494;&#24347;&#27861;&#20855;&#26377;&#21807;&#19968;&#35299;&#65292;&#24182;&#19988;&#33021;&#22815;&#31934;&#30830;&#24674;&#22797;&#22320;&#38754;&#30495;&#23454;&#25490;&#21015;&#12290;</title><link>http://arxiv.org/abs/2310.20609</link><description>&lt;p&gt;
&#36890;&#36807;&#23545;&#21333;&#32431;&#24418;&#36827;&#34892;&#20984;&#26494;&#24347;&#35299;&#20915;&#22270;&#21305;&#37197;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Graph Matching via convex relaxation to the simplex. (arXiv:2310.20609v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20609
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#21305;&#37197;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#21333;&#20301;&#21333;&#32431;&#24418;&#36827;&#34892;&#20984;&#26494;&#24347;&#65292;&#24182;&#24320;&#21457;&#20102;&#39640;&#25928;&#30340;&#38236;&#20687;&#19979;&#38477;&#26041;&#26696;&#26469;&#35299;&#20915;&#35813;&#38382;&#39064;&#12290;&#22312;&#30456;&#20851;&#39640;&#26031;Wigner&#27169;&#22411;&#19979;&#65292;&#21333;&#32431;&#24418;&#26494;&#24347;&#27861;&#20855;&#26377;&#21807;&#19968;&#35299;&#65292;&#24182;&#19988;&#33021;&#22815;&#31934;&#30830;&#24674;&#22797;&#22320;&#38754;&#30495;&#23454;&#25490;&#21015;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#22270;&#21305;&#37197;&#38382;&#39064;&#36827;&#34892;&#30740;&#31350;&#65292;&#35813;&#38382;&#39064;&#21253;&#25324;&#22312;&#20004;&#20010;&#36755;&#20837;&#22270;&#20043;&#38388;&#25214;&#21040;&#26368;&#20339;&#23545;&#40784;&#65292;&#24182;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#32593;&#32476;&#21435;&#21311;&#21517;&#21270;&#21644;&#34507;&#30333;&#36136;&#23545;&#40784;&#31561;&#39046;&#22495;&#26377;&#35768;&#22810;&#24212;&#29992;&#12290;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#24120;&#35265;&#26041;&#27861;&#26159;&#36890;&#36807;&#23545;NP&#38590;&#38382;&#39064;&#8220;&#20108;&#27425;&#20998;&#37197;&#38382;&#39064;&#8221;&#65288;QAP&#65289;&#36827;&#34892;&#20984;&#26494;&#24347;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#20984;&#26494;&#24347;&#26041;&#27861;&#65292;&#21363;&#23545;&#21333;&#20301;&#21333;&#32431;&#24418;&#36827;&#34892;&#26494;&#24347;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#20855;&#26377;&#38381;&#21512;&#36845;&#20195;&#24418;&#24335;&#30340;&#39640;&#25928;&#38236;&#20687;&#19979;&#38477;&#26041;&#26696;&#26469;&#35299;&#20915;&#35813;&#38382;&#39064;&#12290;&#22312;&#30456;&#20851;&#39640;&#26031;Wigner&#27169;&#22411;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21333;&#32431;&#24418;&#26494;&#24347;&#27861;&#22312;&#39640;&#27010;&#29575;&#19979;&#20855;&#26377;&#21807;&#19968;&#35299;&#12290;&#22312;&#26080;&#22122;&#22768;&#24773;&#20917;&#19979;&#65292;&#36825;&#34987;&#35777;&#26126;&#21487;&#20197;&#31934;&#30830;&#24674;&#22797;&#22320;&#38754;&#30495;&#23454;&#25490;&#21015;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#31181;&#26032;&#30340;&#36755;&#20837;&#30697;&#38453;&#20551;&#35774;&#26465;&#20214;&#65292;&#29992;&#20110;&#26631;&#20934;&#36138;&#24515;&#21462;&#25972;&#26041;&#27861;&#65292;&#24182;&#19988;&#36825;&#20010;&#26465;&#20214;&#27604;&#24120;&#29992;&#30340;&#8220;&#23545;&#35282;&#32447;&#20248;&#21183;&#8221;&#26465;&#20214;&#26356;&#23485;&#26494;&#12290;&#25105;&#20204;&#20351;&#29992;&#36825;&#20010;&#26465;&#20214;&#35777;&#26126;&#20102;&#22320;&#38754;&#30495;&#23454;&#25490;&#21015;&#30340;&#31934;&#30830;&#19968;&#27493;&#24674;&#22797;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper addresses the Graph Matching problem, which consists of finding the best possible alignment between two input graphs, and has many applications in computer vision, network deanonymization and protein alignment. A common approach to tackle this problem is through convex relaxations of the NP-hard \emph{Quadratic Assignment Problem} (QAP).  Here, we introduce a new convex relaxation onto the unit simplex and develop an efficient mirror descent scheme with closed-form iterations for solving this problem. Under the correlated Gaussian Wigner model, we show that the simplex relaxation admits a unique solution with high probability. In the noiseless case, this is shown to imply exact recovery of the ground truth permutation. Additionally, we establish a novel sufficiency condition for the input matrix in standard greedy rounding methods, which is less restrictive than the commonly used `diagonal dominance' condition. We use this condition to show exact one-step recovery of the gro
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#20010;&#25308;&#21344;&#24237;&#40065;&#26834;&#12289;&#36890;&#20449;&#39640;&#25928;&#21644;&#31169;&#23494;&#30340;&#31639;&#27861;(Subspace-Median)&#26469;&#35299;&#20915;&#22312;&#32852;&#37030;&#29615;&#22659;&#20013;&#20272;&#35745;&#23545;&#31216;&#30697;&#38453;&#20027;&#23376;&#31354;&#38388;&#30340;&#38382;&#39064;&#65292;&#21516;&#26102;&#36824;&#30740;&#31350;&#20102;&#32852;&#37030;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#21644;&#27700;&#24179;&#32852;&#37030;&#20302;&#31209;&#21015;&#24863;&#30693;&#65288;LRCCS&#65289;&#30340;&#29305;&#27530;&#24773;&#20917;&#65292;&#24182;&#23637;&#31034;&#20102;Subspace-Median&#31639;&#27861;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2309.14512</link><description>&lt;p&gt;
&#25308;&#21344;&#24237;&#40065;&#26834;&#30340;&#32852;&#37030;PCA&#21644;&#20302;&#31209;&#30697;&#38453;&#24674;&#22797;
&lt;/p&gt;
&lt;p&gt;
Byzantine-Resilient Federated PCA and Low Rank Matrix Recovery. (arXiv:2309.14512v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14512
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#20010;&#25308;&#21344;&#24237;&#40065;&#26834;&#12289;&#36890;&#20449;&#39640;&#25928;&#21644;&#31169;&#23494;&#30340;&#31639;&#27861;(Subspace-Median)&#26469;&#35299;&#20915;&#22312;&#32852;&#37030;&#29615;&#22659;&#20013;&#20272;&#35745;&#23545;&#31216;&#30697;&#38453;&#20027;&#23376;&#31354;&#38388;&#30340;&#38382;&#39064;&#65292;&#21516;&#26102;&#36824;&#30740;&#31350;&#20102;&#32852;&#37030;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#21644;&#27700;&#24179;&#32852;&#37030;&#20302;&#31209;&#21015;&#24863;&#30693;&#65288;LRCCS&#65289;&#30340;&#29305;&#27530;&#24773;&#20917;&#65292;&#24182;&#23637;&#31034;&#20102;Subspace-Median&#31639;&#27861;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#22312;&#32852;&#37030;&#29615;&#22659;&#20013;&#20272;&#35745;&#23545;&#31216;&#30697;&#38453;&#30340;&#20027;&#23376;&#31354;&#38388;&#65288;&#21069;r&#20010;&#22855;&#24322;&#21521;&#37327;&#30340;&#24352;&#25104;&#65289;&#30340;&#38382;&#39064;&#65292;&#24403;&#27599;&#20010;&#33410;&#28857;&#37117;&#21487;&#20197;&#35775;&#38382;&#23545;&#36825;&#20010;&#30697;&#38453;&#30340;&#20272;&#35745;&#26102;&#12290;&#25105;&#20204;&#30740;&#31350;&#22914;&#20309;&#20351;&#36825;&#20010;&#38382;&#39064;&#20855;&#26377;&#25308;&#21344;&#24237;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21487;&#35777;&#26126;&#30340;&#25308;&#21344;&#24237;&#40065;&#26834;&#12289;&#36890;&#20449;&#39640;&#25928;&#21644;&#31169;&#23494;&#30340;&#31639;&#27861;&#65292;&#31216;&#20026;&#23376;&#31354;&#38388;&#20013;&#20540;&#31639;&#27861;&#65288;Subspace-Median&#65289;&#65292;&#29992;&#20110;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#36825;&#20010;&#38382;&#39064;&#30340;&#26368;&#33258;&#28982;&#30340;&#35299;&#27861;&#65292;&#22522;&#20110;&#20960;&#20309;&#20013;&#20540;&#30340;&#20462;&#25913;&#30340;&#32852;&#37030;&#24130;&#26041;&#27861;&#65292;&#24182;&#35299;&#37322;&#20026;&#20160;&#20040;&#23427;&#26159;&#26080;&#29992;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#40065;&#26834;&#23376;&#31354;&#38388;&#20272;&#35745;&#20803;&#38382;&#39064;&#30340;&#20004;&#20010;&#29305;&#27530;&#24773;&#20917; - &#32852;&#37030;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#21644;&#27700;&#24179;&#32852;&#37030;&#20302;&#31209;&#21015;&#24863;&#30693;&#65288;LRCCS&#65289;&#30340;&#35889;&#21021;&#22987;&#21270;&#27493;&#39588;&#12290;&#23545;&#20110;&#36825;&#20004;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23376;&#31354;&#38388;&#20013;&#20540;&#31639;&#27861;&#25552;&#20379;&#20102;&#26082;&#20855;&#26377;&#40065;&#26834;&#24615;&#21448;&#20855;&#26377;&#39640;&#36890;&#20449;&#25928;&#29575;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#22343;&#20540;&#30340;&#20013;&#20301;&#25968;&#25193;&#23637;&#20063;&#34987;&#24320;&#21457;&#20986;&#26469;&#20102;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work we consider the problem of estimating the principal subspace (span of the top r singular vectors) of a symmetric matrix in a federated setting, when each node has access to estimates of this matrix. We study how to make this problem Byzantine resilient. We introduce a novel provably Byzantine-resilient, communication-efficient, and private algorithm, called Subspace-Median, to solve it. We also study the most natural solution for this problem, a geometric median based modification of the federated power method, and explain why it is not useful. We consider two special cases of the resilient subspace estimation meta-problem - federated principal components analysis (PCA) and the spectral initialization step of horizontally federated low rank column-wise sensing (LRCCS) in this work. For both these problems we show how Subspace Median provides a resilient solution that is also communication-efficient. Median of Means extensions are developed for both problems. Extensive simu
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#21160;&#36873;&#25321;&#26368;&#20339;&#30340;&#20301;&#23485;&#21644;&#23618;&#23485;&#26469;&#25552;&#39640;&#32593;&#32476;&#25928;&#29575;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#21098;&#26525;&#21644;&#32858;&#31867;&#25216;&#26415;&#65292;&#20248;&#21270;&#20102;&#25628;&#32034;&#36807;&#31243;&#65292;&#24182;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#20005;&#26684;&#27979;&#35797;&#65292;&#32467;&#26524;&#26174;&#31034;&#35813;&#26041;&#27861;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2308.06422</link><description>&lt;p&gt;
&#20351;&#29992;&#22522;&#20110;&#32858;&#31867;&#30340;&#26641;&#29366;Parzen&#20272;&#35745;&#30340;&#25935;&#24863;&#24615;&#24863;&#30693;&#28151;&#21512;&#31934;&#24230;&#37327;&#21270;&#21644;&#23485;&#24230;&#20248;&#21270;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Sensitivity-Aware Mixed-Precision Quantization and Width Optimization of Deep Neural Networks Through Cluster-Based Tree-Structured Parzen Estimation. (arXiv:2308.06422v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06422
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#21160;&#36873;&#25321;&#26368;&#20339;&#30340;&#20301;&#23485;&#21644;&#23618;&#23485;&#26469;&#25552;&#39640;&#32593;&#32476;&#25928;&#29575;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#21098;&#26525;&#21644;&#32858;&#31867;&#25216;&#26415;&#65292;&#20248;&#21270;&#20102;&#25628;&#32034;&#36807;&#31243;&#65292;&#24182;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#20005;&#26684;&#27979;&#35797;&#65292;&#32467;&#26524;&#26174;&#31034;&#35813;&#26041;&#27861;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#22797;&#26434;&#24615;&#21644;&#35745;&#31639;&#38656;&#27714;&#30340;&#25552;&#39640;&#65292;&#23545;&#31070;&#32463;&#32593;&#32476;&#35774;&#35745;&#30340;&#26377;&#25928;&#20248;&#21270;&#26041;&#27861;&#30340;&#38656;&#27714;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#25628;&#32034;&#26426;&#21046;&#65292;&#29992;&#20110;&#33258;&#21160;&#36873;&#25321;&#21333;&#20010;&#31070;&#32463;&#32593;&#32476;&#23618;&#30340;&#26368;&#20339;&#20301;&#23485;&#21644;&#23618;&#23485;&#12290;&#36825;&#23548;&#33268;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#25928;&#29575;&#30340;&#26126;&#26174;&#25552;&#39640;&#12290;&#36890;&#36807;&#21033;&#29992;&#22522;&#20110;Hessian&#30340;&#21098;&#26525;&#31574;&#30053;&#65292;&#26377;&#36873;&#25321;&#22320;&#20943;&#23569;&#25628;&#32034;&#22495;&#65292;&#30830;&#20445;&#31227;&#38500;&#38750;&#20851;&#38190;&#21442;&#25968;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#22522;&#20110;&#32858;&#31867;&#30340;&#26641;&#29366;Parzen&#20272;&#35745;&#22120;&#24320;&#21457;&#26377;&#21033;&#21644;&#19981;&#21033;&#32467;&#26524;&#30340;&#26367;&#20195;&#27169;&#22411;&#12290;&#36825;&#31181;&#31574;&#30053;&#20801;&#35768;&#23545;&#26550;&#26500;&#21487;&#33021;&#24615;&#36827;&#34892;&#31616;&#21270;&#30340;&#25506;&#32034;&#65292;&#24182;&#36805;&#36895;&#30830;&#23450;&#34920;&#29616;&#26368;&#22909;&#30340;&#35774;&#35745;&#12290;&#36890;&#36807;&#23545;&#30693;&#21517;&#25968;&#25454;&#38598;&#36827;&#34892;&#20005;&#26684;&#27979;&#35797;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#35777;&#26126;&#20102;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#30340;&#26126;&#26174;&#20248;&#21183;&#12290;&#19982;&#39046;&#20808;&#30340;&#21387;&#32553;&#31574;&#30053;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21462;&#24471;&#20102;&#20196;&#20154;&#30633;&#30446;&#30340;&#25104;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
As the complexity and computational demands of deep learning models rise, the need for effective optimization methods for neural network designs becomes paramount. This work introduces an innovative search mechanism for automatically selecting the best bit-width and layer-width for individual neural network layers. This leads to a marked enhancement in deep neural network efficiency. The search domain is strategically reduced by leveraging Hessian-based pruning, ensuring the removal of non-crucial parameters. Subsequently, we detail the development of surrogate models for favorable and unfavorable outcomes by employing a cluster-based tree-structured Parzen estimator. This strategy allows for a streamlined exploration of architectural possibilities and swift pinpointing of top-performing designs. Through rigorous testing on well-known datasets, our method proves its distinct advantage over existing methods. Compared to leading compression strategies, our approach records an impressive 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#40065;&#26834;&#30340;&#33258;&#36866;&#24212; $\tau$-Lasso &#20272;&#35745;&#22120;&#65292;&#21516;&#26102;&#37319;&#29992;&#33258;&#36866;&#24212; $\ell_1$-&#33539;&#25968;&#24809;&#32602;&#39033;&#20197;&#38477;&#20302;&#30495;&#23454;&#22238;&#24402;&#31995;&#25968;&#30340;&#20559;&#24046;&#12290;&#23427;&#20855;&#26377;&#21464;&#37327;&#36873;&#25321;&#19968;&#33268;&#24615;&#21644;&#30495;&#23454;&#25903;&#25345;&#19979;&#22238;&#24402;&#21521;&#37327;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#30340;&#26368;&#20248;&#24615;&#36136;&#65292;&#20551;&#23450;&#24050;&#30693;&#30495;&#23454;&#22238;&#24402;&#21521;&#37327;&#30340;&#25903;&#25345;&#12290;</title><link>http://arxiv.org/abs/2304.09310</link><description>&lt;p&gt;
&#33258;&#36866;&#24212; $\tau$-Lasso&#65306;&#20854;&#20581;&#22766;&#24615;&#21644;&#26368;&#20248;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Adaptive $\tau$-Lasso: Its Robustness and Oracle Properties. (arXiv:2304.09310v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09310
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#40065;&#26834;&#30340;&#33258;&#36866;&#24212; $\tau$-Lasso &#20272;&#35745;&#22120;&#65292;&#21516;&#26102;&#37319;&#29992;&#33258;&#36866;&#24212; $\ell_1$-&#33539;&#25968;&#24809;&#32602;&#39033;&#20197;&#38477;&#20302;&#30495;&#23454;&#22238;&#24402;&#31995;&#25968;&#30340;&#20559;&#24046;&#12290;&#23427;&#20855;&#26377;&#21464;&#37327;&#36873;&#25321;&#19968;&#33268;&#24615;&#21644;&#30495;&#23454;&#25903;&#25345;&#19979;&#22238;&#24402;&#21521;&#37327;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#30340;&#26368;&#20248;&#24615;&#36136;&#65292;&#20551;&#23450;&#24050;&#30693;&#30495;&#23454;&#22238;&#24402;&#21521;&#37327;&#30340;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#20998;&#26512;&#39640;&#32500;&#25968;&#25454;&#38598;&#30340;&#26032;&#22411;&#27491;&#21017;&#21270;&#40065;&#26834; $\tau$-&#22238;&#24402;&#20272;&#35745;&#22120;&#65292;&#20197;&#24212;&#23545;&#21709;&#24212;&#21464;&#37327;&#21644;&#21327;&#21464;&#37327;&#30340;&#20005;&#37325;&#27745;&#26579;&#12290;&#25105;&#20204;&#31216;&#36825;&#31181;&#20272;&#35745;&#22120;&#20026;&#33258;&#36866;&#24212; $\tau$-Lasso&#65292;&#23427;&#23545;&#24322;&#24120;&#20540;&#21644;&#39640;&#26464;&#26438;&#28857;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#21516;&#26102;&#37319;&#29992;&#33258;&#36866;&#24212; $\ell_1$-&#33539;&#25968;&#24809;&#32602;&#39033;&#26469;&#20943;&#23569;&#30495;&#23454;&#22238;&#24402;&#31995;&#25968;&#30340;&#20559;&#24046;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#35813;&#33258;&#36866;&#24212; $\ell_1$-&#33539;&#25968;&#24809;&#32602;&#39033;&#20026;&#27599;&#20010;&#22238;&#24402;&#31995;&#25968;&#20998;&#37197;&#19968;&#20010;&#26435;&#37325;&#12290;&#23545;&#20110;&#22266;&#23450;&#25968;&#37327;&#30340;&#39044;&#27979;&#21464;&#37327; $p$&#65292;&#25105;&#20204;&#26174;&#31034;&#20986;&#33258;&#36866;&#24212; $\tau$-Lasso &#20855;&#26377;&#21464;&#37327;&#36873;&#25321;&#19968;&#33268;&#24615;&#21644;&#30495;&#23454;&#25903;&#25345;&#19979;&#22238;&#24402;&#21521;&#37327;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#30340;&#26368;&#20248;&#24615;&#36136;&#65292;&#20551;&#23450;&#24050;&#30693;&#30495;&#23454;&#22238;&#24402;&#21521;&#37327;&#30340;&#25903;&#25345;&#12290;&#28982;&#21518;&#25105;&#20204;&#36890;&#36807;&#26377;&#38480;&#26679;&#26412;&#26029;&#28857;&#21644;&#24433;&#21709;&#20989;&#25968;&#26469;&#34920;&#24449;&#20854;&#20581;&#22766;&#24615;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#27169;&#25311;&#26469;&#27604;&#36739;&#19981;&#21516;&#30340;&#20272;&#35745;&#22120;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a new regularized version of the robust $\tau$-regression estimator for analyzing high-dimensional data sets subject to gross contamination in the response variables and covariates. We call the resulting estimator adaptive $\tau$-Lasso that is robust to outliers and high-leverage points and simultaneously employs adaptive $\ell_1$-norm penalty term to reduce the bias associated with large true regression coefficients. More specifically, this adaptive $\ell_1$-norm penalty term assigns a weight to each regression coefficient. For a fixed number of predictors $p$, we show that the adaptive $\tau$-Lasso has the oracle property with respect to variable-selection consistency and asymptotic normality for the regression vector corresponding to the true support, assuming knowledge of the true regression vector support. We then characterize its robustness via the finite-sample breakdown point and the influence function. We carry-out extensive simulations to compare the per
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#31639;&#27861;&#65292;&#36866;&#24212;&#30456;&#20284;&#24615;&#32467;&#26500;&#24182;&#23545;&#24322;&#24120;&#20540;&#20219;&#21153;&#20855;&#26377;&#31283;&#20581;&#24615;&#65292;&#36866;&#29992;&#20110;&#34920;&#31034;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#36801;&#31227;&#23398;&#20064;&#35774;&#32622;&#12290;</title><link>http://arxiv.org/abs/2303.17765</link><description>&lt;p&gt;
&#23398;&#20064;&#30456;&#20284;&#30340;&#32447;&#24615;&#34920;&#31034;&#65306;&#36866;&#24212;&#24615;&#12289;&#26497;&#23567;&#21270;&#12289;&#20197;&#21450;&#31283;&#20581;&#24615;
&lt;/p&gt;
&lt;p&gt;
Learning from Similar Linear Representations: Adaptivity, Minimaxity, and Robustness. (arXiv:2303.17765v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.17765
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#31639;&#27861;&#65292;&#36866;&#24212;&#30456;&#20284;&#24615;&#32467;&#26500;&#24182;&#23545;&#24322;&#24120;&#20540;&#20219;&#21153;&#20855;&#26377;&#31283;&#20581;&#24615;&#65292;&#36866;&#29992;&#20110;&#34920;&#31034;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#36801;&#31227;&#23398;&#20064;&#35774;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34920;&#31034;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#36801;&#31227;&#23398;&#20064;&#22312;&#23454;&#36341;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#25104;&#21151;&#65292;&#28982;&#32780;&#23545;&#36825;&#20123;&#26041;&#27861;&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#27424;&#32570;&#12290;&#26412;&#25991;&#26088;&#22312;&#29702;&#35299;&#20174;&#20855;&#26377;&#30456;&#20284;&#20294;&#24182;&#38750;&#23436;&#20840;&#30456;&#21516;&#30340;&#32447;&#24615;&#34920;&#31034;&#30340;&#20219;&#21153;&#20013;&#23398;&#20064;&#65292;&#21516;&#26102;&#22788;&#29702;&#24322;&#24120;&#20540;&#20219;&#21153;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#31639;&#27861;&#65292;&#36866;&#24212;&#30456;&#20284;&#24615;&#32467;&#26500;&#24182;&#23545;&#24322;&#24120;&#20540;&#20219;&#21153;&#20855;&#26377;&#31283;&#20581;&#24615;&#65292;&#36866;&#29992;&#20110;&#34920;&#31034;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#36801;&#31227;&#23398;&#20064;&#35774;&#32622;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#21333;&#20219;&#21153;&#25110;&#20165;&#30446;&#26631;&#23398;&#20064;&#26102;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Representation multi-task learning (MTL) and transfer learning (TL) have achieved tremendous success in practice. However, the theoretical understanding of these methods is still lacking. Most existing theoretical works focus on cases where all tasks share the same representation, and claim that MTL and TL almost always improve performance. However, as the number of tasks grow, assuming all tasks share the same representation is unrealistic. Also, this does not always match empirical findings, which suggest that a shared representation may not necessarily improve single-task or target-only learning performance. In this paper, we aim to understand how to learn from tasks with \textit{similar but not exactly the same} linear representations, while dealing with outlier tasks. We propose two algorithms that are \textit{adaptive} to the similarity structure and \textit{robust} to outlier tasks under both MTL and TL settings. Our algorithms outperform single-task or target-only learning when
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#21152;&#26435;&#32452;&#31232;&#30095;&#21253;&#32476;&#27491;&#21017;&#21270;&#26041;&#27861;&#23398;&#20064;k&#32423;&#31232;&#30095;&#31070;&#32463;&#32593;&#32476;&#30340;&#39640;&#25928;&#26041;&#27861;&#65292;&#21516;&#26102;&#20445;&#35777;&#32593;&#32476;&#30340;&#30828;&#20214;&#21451;&#22909;&#30340;&#32467;&#26500;&#21270;&#31232;&#30095;&#24615;&#65292;&#21152;&#24555;&#32593;&#32476;&#35780;&#20272;&#36895;&#24230;&#65292;&#32780;&#19988;&#33021;&#22815;&#22312;&#35757;&#32451;&#20013;&#39044;&#23450;&#20041;&#31232;&#30095;&#24230;&#27700;&#24179;&#65292;&#21516;&#26102;&#20960;&#20046;&#19981;&#38477;&#20302;&#32593;&#32476;&#20934;&#30830;&#24230;&#29978;&#33267;&#26377;&#21487;&#33021;&#25552;&#39640;&#12290;</title><link>http://arxiv.org/abs/2212.12921</link><description>&lt;p&gt;
&#20351;&#29992;&#26032;&#30340;&#24191;&#20041;&#21152;&#26435;&#32452;&#31232;&#30095;&#21253;&#32476;&#27491;&#21017;&#21270;&#23398;&#20064;k&#32423;&#31232;&#30095;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Learning k-Level Sparse Neural Networks Using a New Generalized Weighted Group Sparse Envelope Regularization. (arXiv:2212.12921v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.12921
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#21152;&#26435;&#32452;&#31232;&#30095;&#21253;&#32476;&#27491;&#21017;&#21270;&#26041;&#27861;&#23398;&#20064;k&#32423;&#31232;&#30095;&#31070;&#32463;&#32593;&#32476;&#30340;&#39640;&#25928;&#26041;&#27861;&#65292;&#21516;&#26102;&#20445;&#35777;&#32593;&#32476;&#30340;&#30828;&#20214;&#21451;&#22909;&#30340;&#32467;&#26500;&#21270;&#31232;&#30095;&#24615;&#65292;&#21152;&#24555;&#32593;&#32476;&#35780;&#20272;&#36895;&#24230;&#65292;&#32780;&#19988;&#33021;&#22815;&#22312;&#35757;&#32451;&#20013;&#39044;&#23450;&#20041;&#31232;&#30095;&#24230;&#27700;&#24179;&#65292;&#21516;&#26102;&#20960;&#20046;&#19981;&#38477;&#20302;&#32593;&#32476;&#20934;&#30830;&#24230;&#29978;&#33267;&#26377;&#21487;&#33021;&#25552;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#26041;&#27861;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#23398;&#20064;&#26080;&#32467;&#26500;&#21644;&#26377;&#32467;&#26500;&#31232;&#30095;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#21033;&#29992;&#19968;&#31181;&#31216;&#20026;"&#21152;&#26435;&#32452;&#31232;&#30095;&#21253;&#32476;&#20989;&#25968;" (WGSEF) &#30340;&#31232;&#30095;&#21253;&#32476;&#20989;&#25968;&#30340;&#26032;&#24191;&#20041;&#12290;WGSEF&#20316;&#20026;&#19968;&#20010;&#31070;&#32463;&#20803;&#32452;&#36873;&#25321;&#22120;&#65292;&#29992;&#20110;&#24341;&#23548;&#32467;&#26500;&#21270;&#31232;&#30095;&#24615;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#30830;&#20445;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476; (DNN) &#30340;&#30828;&#20214;&#21451;&#22909;&#30340;&#32467;&#26500;&#21270;&#31232;&#30095;&#24615;&#65292;&#20197;&#26377;&#25928;&#21152;&#36895;DNN&#30340;&#35780;&#20272;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#35813;&#26041;&#27861;&#26159;&#21487;&#36866;&#24212;&#30340;&#65292;&#20801;&#35768;&#20219;&#20309;&#30828;&#20214;&#25351;&#23450;&#32452;&#23450;&#20041;&#65292;&#22914;&#28388;&#27874;&#22120;&#12289;&#36890;&#36947;&#12289;&#28388;&#27874;&#22120;&#24418;&#29366;&#12289;&#23618;&#28145;&#24230;&#12289;&#21333;&#20010;&#21442;&#25968; (&#26080;&#32467;&#26500;)&#31561;&#12290;&#30001;&#20110;WGSEF&#30340;&#29305;&#24615;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#22312;&#35757;&#32451;&#25910;&#25947;&#26102;&#39044;&#23450;&#20041;&#31232;&#30095;&#24230;&#27700;&#24179;&#65292;&#21516;&#26102;&#20445;&#25345;&#32593;&#32476;&#20934;&#30830;&#24230;&#30340;&#26497;&#23567;&#38477;&#20302;&#29978;&#33267;&#25913;&#21892;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#25216;&#26415;&#26469;&#35745;&#31639;&#31934;&#30830;&#30340;...
&lt;/p&gt;
&lt;p&gt;
We propose an efficient method to learn both unstructured and structured sparse neural networks during training, utilizing a novel generalization of the sparse envelope function (SEF) used as a regularizer, termed {\itshape{weighted group sparse envelope function}} (WGSEF). The WGSEF acts as a neuron group selector, which is leveraged to induce structured sparsity. The method ensures a hardware-friendly structured sparsity of a deep neural network (DNN) to efficiently accelerate the DNN's evaluation. Notably, the method is adaptable, letting any hardware specify group definitions, such as filters, channels, filter shapes, layer depths, a single parameter (unstructured), etc. Owing to the WGSEF's properties, the proposed method allows to a pre-define sparsity level that would be achieved at the training convergence, while maintaining negligible network accuracy degradation or even improvement in the case of redundant parameters. We introduce an efficient technique to calculate the exact
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#25552;&#20986;&#22270;&#24418;&#26631;&#20934;&#21644;&#27169;&#22411;&#26080;&#20851;&#26694;&#26550;CIP&#65292;&#25105;&#20204;&#33021;&#22815;&#23398;&#20064;&#21453;&#20107;&#23454;&#19981;&#21464;&#30340;&#39044;&#27979;&#22120;&#65292;&#20197;&#23454;&#29616;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#20844;&#24179;&#24615;&#12289;&#24378;&#20581;&#24615;&#21644;&#26222;&#36866;&#24615;&#12290;</title><link>http://arxiv.org/abs/2207.09768</link><description>&lt;p&gt;
&#23398;&#20064;&#21453;&#20107;&#23454;&#19981;&#21464;&#30340;&#39044;&#27979;&#22120;
&lt;/p&gt;
&lt;p&gt;
Learning Counterfactually Invariant Predictors. (arXiv:2207.09768v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.09768
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25552;&#20986;&#22270;&#24418;&#26631;&#20934;&#21644;&#27169;&#22411;&#26080;&#20851;&#26694;&#26550;CIP&#65292;&#25105;&#20204;&#33021;&#22815;&#23398;&#20064;&#21453;&#20107;&#23454;&#19981;&#21464;&#30340;&#39044;&#27979;&#22120;&#65292;&#20197;&#23454;&#29616;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#20844;&#24179;&#24615;&#12289;&#24378;&#20581;&#24615;&#21644;&#26222;&#36866;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21453;&#20107;&#23454;&#19981;&#21464;&#24615;&#65288;CI&#65289;&#30340;&#27010;&#24565;&#23545;&#20110;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#20844;&#24179;&#12289;&#24378;&#20581;&#21644;&#20855;&#26377;&#26222;&#36866;&#24615;&#30340;&#39044;&#27979;&#22120;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22270;&#24418;&#26631;&#20934;&#65292;&#23427;&#20197;&#35266;&#27979;&#20998;&#24067;&#30340;&#26465;&#20214;&#29420;&#31435;&#24615;&#20316;&#20026;&#39044;&#27979;&#22120;&#21453;&#20107;&#23454;&#19981;&#21464;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#20026;&#20102;&#23398;&#20064;&#36825;&#26679;&#30340;&#39044;&#27979;&#22120;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31216;&#20026;Counterfactually Invariant Prediction&#65288;CIP&#65289;&#30340;&#27169;&#22411;&#26080;&#20851;&#26694;&#26550;&#65292;&#22522;&#20110;Hilbert-Schmidt&#26465;&#20214;&#29420;&#31435;&#20934;&#21017;&#65288;HSCIC&#65289;&#65292;&#19968;&#31181;&#22522;&#20110;&#26680;&#30340;&#26465;&#20214;&#20381;&#36182;&#24230;&#37327;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#22312;&#21253;&#25324;&#26631;&#37327;&#21644;&#22810;&#21464;&#37327;&#35774;&#32622;&#22312;&#20869;&#30340;&#21508;&#31181;&#27169;&#25311;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#35777;&#26126;&#20102;CIP&#22312;&#24378;&#21046;&#21453;&#20107;&#23454;&#19981;&#21464;&#24615;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Notions of counterfactual invariance (CI) have proven essential for predictors that are fair, robust, and generalizable in the real world. We propose graphical criteria that yield a sufficient condition for a predictor to be counterfactually invariant in terms of a conditional independence in the observational distribution. In order to learn such predictors, we propose a model-agnostic framework, called Counterfactually Invariant Prediction (CIP), building on the Hilbert-Schmidt Conditional Independence Criterion (HSCIC), a kernel-based conditional dependence measure. Our experimental results demonstrate the effectiveness of CIP in enforcing counterfactual invariance across various simulated and real-world datasets including scalar and multi-variate settings.
&lt;/p&gt;</description></item></channel></rss>