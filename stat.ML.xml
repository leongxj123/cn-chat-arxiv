<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#35774;&#35745;&#20102;&#19968;&#31181;&#21033;&#29992;&#39044;&#35757;&#32451;&#25193;&#25955;&#27169;&#22411;&#30340;&#25193;&#25955;&#27748;&#26222;&#26862;&#37319;&#26679;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#22823;&#21160;&#20316;&#31354;&#38388;&#19979;&#36827;&#34892;&#39640;&#25928;&#30340;&#24773;&#22659;&#24378;&#21270;&#23398;&#20064;&#25506;&#32034;&#12290;&#23454;&#35777;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.10028</link><description>&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#19982;&#22823;&#21160;&#20316;&#31354;&#38388;&#24773;&#22659;&#24378;&#21270;&#23398;&#20064;&#30340;&#32467;&#21512;
&lt;/p&gt;
&lt;p&gt;
Diffusion Models Meet Contextual Bandits with Large Action Spaces
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10028
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35774;&#35745;&#20102;&#19968;&#31181;&#21033;&#29992;&#39044;&#35757;&#32451;&#25193;&#25955;&#27169;&#22411;&#30340;&#25193;&#25955;&#27748;&#26222;&#26862;&#37319;&#26679;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#22823;&#21160;&#20316;&#31354;&#38388;&#19979;&#36827;&#34892;&#39640;&#25928;&#30340;&#24773;&#22659;&#24378;&#21270;&#23398;&#20064;&#25506;&#32034;&#12290;&#23454;&#35777;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#21160;&#20316;&#31354;&#38388;&#36739;&#22823;&#65292;&#26377;&#25928;&#30340;&#25506;&#32034;&#26159;&#24773;&#22659;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#12290;&#26412;&#25991;&#36890;&#36807;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#26469;&#25429;&#25417;&#21160;&#20316;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#35774;&#35745;&#20102;&#25193;&#25955;&#27748;&#26222;&#26862;&#37319;&#26679;&#65288;dTS&#65289;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#25506;&#32034;&#12290;&#25105;&#20204;&#20026;dTS&#26041;&#27861;&#25552;&#20379;&#20102;&#29702;&#35770;&#21644;&#31639;&#27861;&#22522;&#30784;&#65292;&#24182;&#36890;&#36807;&#23454;&#35777;&#35780;&#20272;&#23637;&#31034;&#20102;&#23427;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10028v1 Announce Type: cross  Abstract: Efficient exploration is a key challenge in contextual bandits due to the large size of their action space, where uninformed exploration can result in computational and statistical inefficiencies. Fortunately, the rewards of actions are often correlated and this can be leveraged to explore them efficiently. In this work, we capture such correlations using pre-trained diffusion models; upon which we design diffusion Thompson sampling (dTS). Both theoretical and algorithmic foundations are developed for dTS, and empirical evaluation also shows its favorable performance.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20048;&#35266;&#35843;&#33410;&#30340;&#22312;&#32447;&#23398;&#20064;&#26694;&#26550;&#21644;&#36866;&#24212;&#31639;&#27861;&#65292;&#25361;&#25112;&#20102;&#23545;&#19987;&#23478;&#30340;&#20449;&#24515;&#20551;&#35774;&#65292;&#24182;&#36890;&#36807;&#21160;&#24577;&#36951;&#25022;&#30028;&#38480;&#30340;&#29702;&#35770;&#20445;&#35777;&#21644;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2301.07530</link><description>&lt;p&gt;
&#20048;&#35266;&#35843;&#33410;&#30340;&#22312;&#32447;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Optimistically Tempered Online Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2301.07530
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20048;&#35266;&#35843;&#33410;&#30340;&#22312;&#32447;&#23398;&#20064;&#26694;&#26550;&#21644;&#36866;&#24212;&#31639;&#27861;&#65292;&#25361;&#25112;&#20102;&#23545;&#19987;&#23478;&#30340;&#20449;&#24515;&#20551;&#35774;&#65292;&#24182;&#36890;&#36807;&#21160;&#24577;&#36951;&#25022;&#30028;&#38480;&#30340;&#29702;&#35770;&#20445;&#35777;&#21644;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20048;&#35266;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#24050;&#32463;&#34987;&#24320;&#21457;&#20986;&#26469;&#65292;&#20197;&#21033;&#29992;&#19987;&#23478;&#24847;&#35265;&#65292;&#20551;&#35774;&#19987;&#23478;&#24847;&#35265;&#24635;&#26159;&#26377;&#29992;&#30340;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#21487;&#20197;&#21512;&#29702;&#22320;&#23545;&#36825;&#20123;&#24847;&#35265;&#19982;&#22522;&#20110;&#26799;&#24230;&#30340;&#22312;&#32447;&#31639;&#27861;&#25552;&#20379;&#30340;&#23398;&#20064;&#20449;&#24687;&#30340;&#30456;&#20851;&#24615;&#25552;&#20986;&#36136;&#30097;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36136;&#30097;&#23545;&#19987;&#23478;&#30340;&#20449;&#24515;&#20551;&#35774;&#65292;&#24182;&#24320;&#21457;&#20102;&#20048;&#35266;&#35843;&#33410;&#65288;OT&#65289;&#22312;&#32447;&#23398;&#20064;&#26694;&#26550;&#20197;&#21450;&#22312;&#32447;&#31639;&#27861;&#30340;OT&#36866;&#24212;&#24615;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20855;&#26377;&#21160;&#24577;&#36951;&#25022;&#30028;&#38480;&#30340;&#31283;&#22266;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#26368;&#32456;&#39564;&#35777;&#20102;OT&#26041;&#27861;&#30340;&#26377;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2301.07530v2 Announce Type: replace Abstract: Optimistic Online Learning algorithms have been developed to exploit expert advices, assumed optimistically to be always useful. However, it is legitimate to question the relevance of such advices \emph{w.r.t.} the learning information provided by gradient-based online algorithms. In this work, we challenge the confidence assumption on the expert and develop the \emph{optimistically tempered} (OT) online learning framework as well as OT adaptations of online algorithms. Our algorithms come with sound theoretical guarantees in the form of dynamic regret bounds, and we eventually provide experimental validation of the usefulness of the OT approach.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#20102;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#30340;&#20256;&#36882;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#24773;&#20917;&#19979;&#30340;&#35299;&#20915;&#26041;&#27861;&#65292;&#24182;&#20998;&#21035;&#32473;&#20986;&#20102;&#32479;&#35745;&#24615;&#36136;&#21644;&#26368;&#20248;&#24615;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.13966</link><description>&lt;p&gt;
&#22522;&#20110;&#26680;&#38750;&#21442;&#25968;&#22238;&#24402;&#30340;&#26368;&#20248;&#26497;&#23567;&#21270;&#20256;&#36882;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Minimax Optimal Transfer Learning for Kernel-based Nonparametric Regression. (arXiv:2310.13966v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13966
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#20102;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#30340;&#20256;&#36882;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#24773;&#20917;&#19979;&#30340;&#35299;&#20915;&#26041;&#27861;&#65292;&#24182;&#20998;&#21035;&#32473;&#20986;&#20102;&#32479;&#35745;&#24615;&#36136;&#21644;&#26368;&#20248;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#20256;&#36882;&#23398;&#20064;&#22312;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#20013;&#21463;&#21040;&#20102;&#24456;&#22823;&#20851;&#27880;&#12290;&#23427;&#33021;&#22815;&#21033;&#29992;&#30456;&#20851;&#30740;&#31350;&#30340;&#30693;&#35782;&#26469;&#25552;&#39640;&#30446;&#26631;&#30740;&#31350;&#30340;&#27867;&#21270;&#24615;&#33021;&#65292;&#20351;&#20854;&#20855;&#26377;&#24456;&#39640;&#30340;&#21560;&#24341;&#21147;&#12290;&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#30340;&#20256;&#36882;&#23398;&#20064;&#38382;&#39064;&#65292;&#30446;&#30340;&#26159;&#32553;&#23567;&#23454;&#38469;&#25928;&#26524;&#19982;&#29702;&#35770;&#20445;&#35777;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#20855;&#20307;&#32771;&#34385;&#20102;&#20004;&#31181;&#24773;&#20917;&#65306;&#24050;&#30693;&#21487;&#20256;&#36882;&#30340;&#26469;&#28304;&#21644;&#26410;&#30693;&#30340;&#24773;&#20917;&#12290;&#23545;&#20110;&#24050;&#30693;&#21487;&#20256;&#36882;&#30340;&#26469;&#28304;&#24773;&#20917;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#27493;&#26680;&#20272;&#35745;&#22120;&#65292;&#20165;&#20351;&#29992;&#26680;&#23725;&#22238;&#24402;&#12290;&#23545;&#20110;&#26410;&#30693;&#30340;&#24773;&#20917;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#25928;&#32858;&#21512;&#31639;&#27861;&#30340;&#26032;&#26041;&#27861;&#65292;&#21487;&#20197;&#33258;&#21160;&#26816;&#27979;&#24182;&#20943;&#36731;&#36127;&#38754;&#26469;&#28304;&#30340;&#24433;&#21709;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#25152;&#38656;&#20272;&#35745;&#22120;&#30340;&#32479;&#35745;&#24615;&#36136;&#65292;&#24182;&#24314;&#31435;&#20102;&#35813;&#26041;&#27861;&#30340;&#26368;&#20248;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, transfer learning has garnered significant attention in the machine learning community. Its ability to leverage knowledge from related studies to improve generalization performance in a target study has made it highly appealing. This paper focuses on investigating the transfer learning problem within the context of nonparametric regression over a reproducing kernel Hilbert space. The aim is to bridge the gap between practical effectiveness and theoretical guarantees. We specifically consider two scenarios: one where the transferable sources are known and another where they are unknown. For the known transferable source case, we propose a two-step kernel-based estimator by solely using kernel ridge regression. For the unknown case, we develop a novel method based on an efficient aggregation algorithm, which can automatically detect and alleviate the effects of negative sources. This paper provides the statistical properties of the desired estimators and establishes the 
&lt;/p&gt;</description></item></channel></rss>