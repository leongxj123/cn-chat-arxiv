<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21151;&#33021;&#36793;&#32536;&#32593;&#32476;&#27169;&#22411;&#65292;&#36890;&#36807;&#23558;&#36793;&#35270;&#20026;&#21151;&#33021;&#25968;&#25454;&#65292;&#24182;&#24341;&#20837;&#39069;&#22806;&#32500;&#24230;&#26469;&#34920;&#31034;&#20989;&#25968;&#65292;&#20351;&#29992;Tucker&#21151;&#33021;&#20998;&#35299;&#22788;&#29702;&#21151;&#33021;&#37051;&#25509;&#24352;&#37327;&#65292;&#36827;&#34892;&#27169;&#22411;&#25512;&#26029;&#20197;&#35299;&#20915;&#19981;&#35268;&#21017;&#35266;&#27979;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#27491;&#21017;&#21270;&#20351;&#22522;&#30784;&#30697;&#38453;&#23545;&#31216;&#21270;&#65292;&#26368;&#32456;&#23637;&#31034;&#20102;&#27169;&#22411;&#30340;&#29702;&#24819;&#23646;&#24615;&#12290;</title><link>https://arxiv.org/abs/2404.00218</link><description>&lt;p&gt;
&#21151;&#33021;&#36793;&#32536;&#32593;&#32476;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Functional-Edged Network Modeling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00218
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21151;&#33021;&#36793;&#32536;&#32593;&#32476;&#27169;&#22411;&#65292;&#36890;&#36807;&#23558;&#36793;&#35270;&#20026;&#21151;&#33021;&#25968;&#25454;&#65292;&#24182;&#24341;&#20837;&#39069;&#22806;&#32500;&#24230;&#26469;&#34920;&#31034;&#20989;&#25968;&#65292;&#20351;&#29992;Tucker&#21151;&#33021;&#20998;&#35299;&#22788;&#29702;&#21151;&#33021;&#37051;&#25509;&#24352;&#37327;&#65292;&#36827;&#34892;&#27169;&#22411;&#25512;&#26029;&#20197;&#35299;&#20915;&#19981;&#35268;&#21017;&#35266;&#27979;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#27491;&#21017;&#21270;&#20351;&#22522;&#30784;&#30697;&#38453;&#23545;&#31216;&#21270;&#65292;&#26368;&#32456;&#23637;&#31034;&#20102;&#27169;&#22411;&#30340;&#29702;&#24819;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19982;&#29616;&#26377;&#20316;&#21697;&#24418;&#25104;&#23545;&#27604;&#65292;&#29616;&#26377;&#20316;&#21697;&#37117;&#23558;&#33410;&#28857;&#35270;&#20026;&#20989;&#25968;&#65292;&#24182;&#20351;&#29992;&#36793;&#26469;&#34920;&#31034;&#19981;&#21516;&#20989;&#25968;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#32593;&#32476;&#24314;&#27169;&#65292;&#20854;&#20013;&#36793;&#26159;&#21151;&#33021;&#25968;&#25454;&#65292;&#24182;&#23558;&#37051;&#25509;&#30697;&#38453;&#36716;&#25442;&#20026;&#21151;&#33021;&#37051;&#25509;&#24352;&#37327;&#65292;&#24341;&#20837;&#19968;&#20010;&#39069;&#22806;&#30340;&#32500;&#24230;&#19987;&#38376;&#29992;&#20110;&#20989;&#25968;&#34920;&#31034;&#12290;&#25105;&#20204;&#20351;&#29992;Tucker&#21151;&#33021;&#20998;&#35299;&#26469;&#22788;&#29702;&#21151;&#33021;&#37051;&#25509;&#24352;&#37327;&#65292;&#20026;&#36827;&#19968;&#27493;&#32771;&#34385;&#33410;&#28857;&#20043;&#38388;&#30340;&#31038;&#21306;&#65292;&#23545;&#22522;&#30784;&#30697;&#38453;&#36827;&#34892;&#27491;&#21017;&#21270;&#20351;&#20854;&#23545;&#31216;&#21270;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#22788;&#29702;&#21151;&#33021;&#36793;&#30340;&#19981;&#35268;&#21017;&#35266;&#27979;&#65292;&#25105;&#20204;&#36827;&#34892;&#27169;&#22411;&#25512;&#26029;&#20197;&#35299;&#20915;&#24352;&#37327;&#23436;&#25104;&#38382;&#39064;&#65292;&#36890;&#36807;Riemann&#20849;&#36717;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#36827;&#34892;&#20248;&#21270;&#12290;&#38500;&#27492;&#20043;&#22806;&#65292;&#25105;&#20204;&#36824;&#25512;&#23548;&#20986;&#20960;&#20010;&#23450;&#29702;&#26469;&#23637;&#31034;&#21151;&#33021;&#36793;&#32536;&#32593;&#32476;&#27169;&#22411;&#30340;&#29702;&#24819;&#23646;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#27169;&#25311;&#25968;&#25454;&#21644;&#30495;&#23454;&#22320;&#38081;&#31995;&#32479;&#25968;&#25454;&#35780;&#20272;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#27169;&#22411;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00218v1 Announce Type: cross  Abstract: Contrasts with existing works which all consider nodes as functions and use edges to represent the relationships between different functions. We target at network modeling whose edges are functional data and transform the adjacency matrix into a functional adjacency tensor, introducing an additional dimension dedicated to function representation. Tucker functional decomposition is used for the functional adjacency tensor, and to further consider the community between nodes, we regularize the basis matrices to be symmetrical. Furthermore, to deal with irregular observations of the functional edges, we conduct model inference to solve a tensor completion problem. It is optimized by a Riemann conjugate gradient descent method. Besides these, we also derive several theorems to show the desirable properties of the functional edged network model. Finally, we evaluate the efficacy of our proposed model using simulation data and real metro sys
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21463;&#26368;&#36817;&#27169;&#20223;&#23398;&#20064;&#21644;&#20445;&#23432;RL&#31639;&#27861;&#36827;&#23637;&#21551;&#21457;&#30340;&#21019;&#26032;&#26041;&#27861;&#65292;&#22312;&#31163;&#32447;&#21160;&#21147;&#23398;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#23569;&#26679;&#26412;&#36716;&#31227;&#36807;&#31243;&#20013;&#24341;&#20837;&#24809;&#32602;&#26469;&#35843;&#33410;&#28304;&#35757;&#32451;&#31574;&#30053;&#29983;&#25104;&#30340;&#36712;&#36857;&#12290;</title><link>https://arxiv.org/abs/2312.15474</link><description>&lt;p&gt;
&#22312;&#31163;&#32447;&#21160;&#21147;&#23398;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#23569;&#26679;&#26412;&#36716;&#31227;&#30340;&#20445;&#23432;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Conservative Approach for Few-Shot Transfer in Off-Dynamics Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.15474
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21463;&#26368;&#36817;&#27169;&#20223;&#23398;&#20064;&#21644;&#20445;&#23432;RL&#31639;&#27861;&#36827;&#23637;&#21551;&#21457;&#30340;&#21019;&#26032;&#26041;&#27861;&#65292;&#22312;&#31163;&#32447;&#21160;&#21147;&#23398;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#23569;&#26679;&#26412;&#36716;&#31227;&#36807;&#31243;&#20013;&#24341;&#20837;&#24809;&#32602;&#26469;&#35843;&#33410;&#28304;&#35757;&#32451;&#31574;&#30053;&#29983;&#25104;&#30340;&#36712;&#36857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#32447;&#21160;&#21147;&#23398;&#24378;&#21270;&#23398;&#20064;&#65288;ODRL&#65289;&#26088;&#22312;&#23558;&#31574;&#30053;&#20174;&#28304;&#29615;&#22659;&#36716;&#31227;&#21040;&#20855;&#26377;&#19981;&#21516;&#20294;&#30456;&#20284;&#21160;&#21147;&#23398;&#29305;&#24449;&#30340;&#30446;&#26631;&#29615;&#22659;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#20256;&#32479;RL&#20195;&#29702;&#36807;&#24230;&#20381;&#36182;&#28304;&#29615;&#22659;&#30340;&#21160;&#21147;&#23398;&#65292;&#23548;&#33268;&#21457;&#29616;&#22312;&#35813;&#29615;&#22659;&#20013;&#34920;&#29616;&#21331;&#36234;&#30340;&#31574;&#30053;&#65292;&#20294;&#22312;&#30446;&#26631;&#29615;&#22659;&#20013;&#34920;&#29616;&#19981;&#20339;&#12290;&#22312;&#23569;&#26679;&#26412;&#26694;&#26550;&#20013;&#65292;&#24341;&#20837;&#20102;&#26469;&#33258;&#30446;&#26631;&#29615;&#22659;&#30340;&#26377;&#38480;&#25968;&#37327;&#36716;&#25442;&#20197;&#20419;&#36827;&#26356;&#26377;&#25928;&#30340;&#36716;&#31227;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21463;&#26368;&#36817;&#27169;&#20223;&#23398;&#20064;&#21644;&#20445;&#23432;RL&#31639;&#27861;&#36827;&#23637;&#21551;&#21457;&#30340;&#21019;&#26032;&#26041;&#27861;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#24341;&#20837;&#20102;&#19968;&#20010;&#24809;&#32602;&#26469;&#35843;&#33410;&#28304;&#35757;&#32451;&#31574;&#30053;&#29983;&#25104;&#30340;&#36712;&#36857;&#12290;&#25105;&#20204;&#22312;&#20195;&#34920;&#19981;&#21516;&#31163;&#32447;&#21160;&#21147;&#23398;&#26465;&#20214;&#30340;&#21508;&#31181;&#29615;&#22659;&#20013;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#22312;&#36825;&#20123;&#29615;&#22659;&#20013;&#35775;&#38382;&#30446;&#26631;&#29615;&#22659;&#26159;&#26497;&#31471;&#22256;&#38590;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.15474v2 Announce Type: replace  Abstract: Off-dynamics Reinforcement Learning (ODRL) seeks to transfer a policy from a source environment to a target environment characterized by distinct yet similar dynamics. In this context, traditional RL agents depend excessively on the dynamics of the source environment, resulting in the discovery of policies that excel in this environment but fail to provide reasonable performance in the target one. In the few-shot framework, a limited number of transitions from the target environment are introduced to facilitate a more effective transfer. Addressing this challenge, we propose an innovative approach inspired by recent advancements in Imitation Learning and conservative RL algorithms. The proposed method introduces a penalty to regulate the trajectories generated by the source-trained policy. We evaluate our method across various environments representing diverse off-dynamics conditions, where access to the target environment is extreme
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#20855;&#26377;&#21487;&#23398;&#20064;&#24352;&#37327;&#26680;&#33539;&#25968;&#30340;&#26032;&#22411;&#24352;&#37327;&#24674;&#22797;&#27169;&#22411;&#65292;&#24341;&#20837;&#20132;&#26367;&#36817;&#31471;&#20056;&#23376;&#26041;&#27861;&#65288;APMM&#65289;&#20248;&#21270;&#31639;&#27861;&#65292;&#35299;&#20915;&#22788;&#29702;&#38750;&#20809;&#28369;&#21464;&#21270;&#30340;&#24352;&#37327;&#25968;&#25454;&#25361;&#25112;</title><link>https://arxiv.org/abs/2311.13958</link><description>&lt;p&gt;
&#22788;&#29702;&#24352;&#37327;&#22855;&#24322;&#20540;&#20998;&#35299;&#20013;&#30340;&#38750;&#20809;&#28369;&#25361;&#25112;&#65306;&#22810;&#30446;&#26631;&#24352;&#37327;&#24674;&#22797;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Handling The Non-Smooth Challenge in Tensor SVD: A Multi-Objective Tensor Recovery Framework
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.13958
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#20855;&#26377;&#21487;&#23398;&#20064;&#24352;&#37327;&#26680;&#33539;&#25968;&#30340;&#26032;&#22411;&#24352;&#37327;&#24674;&#22797;&#27169;&#22411;&#65292;&#24341;&#20837;&#20132;&#26367;&#36817;&#31471;&#20056;&#23376;&#26041;&#27861;&#65288;APMM&#65289;&#20248;&#21270;&#31639;&#27861;&#65292;&#35299;&#20915;&#22788;&#29702;&#38750;&#20809;&#28369;&#21464;&#21270;&#30340;&#24352;&#37327;&#25968;&#25454;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#35768;&#22810;&#22522;&#20110;&#24352;&#37327;&#22855;&#24322;&#20540;&#20998;&#35299;&#65288;t-SVD&#65289;&#30340;&#24352;&#37327;&#24674;&#22797;&#26041;&#27861;&#22312;&#22788;&#29702;&#35270;&#35273;&#25968;&#25454;&#65288;&#22914;&#24425;&#33394;&#22270;&#20687;&#21644;&#35270;&#39057;&#65289;&#26041;&#38754;&#34920;&#29616;&#20986;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#24403;&#38754;&#23545;&#26174;&#31034;&#20986;&#38750;&#20809;&#28369;&#21464;&#21270;&#30340;&#24352;&#37327;&#25968;&#25454;&#26102;&#65292;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#20250;&#36973;&#21463;&#20005;&#37325;&#30340;&#24615;&#33021;&#36864;&#21270;&#12290;&#34429;&#28982;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#32463;&#24120;&#35266;&#23519;&#21040;&#36825;&#31181;&#24773;&#20917;&#65292;&#20294;&#20256;&#32479;&#30340;&#22522;&#20110;t-SVD&#30340;&#26041;&#27861;&#21364;&#24573;&#35270;&#20102;&#36825;&#19968;&#28857;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24352;&#37327;&#24674;&#22797;&#27169;&#22411;&#65292;&#20854;&#20013;&#21253;&#25324;&#21487;&#23398;&#20064;&#30340;&#24352;&#37327;&#26680;&#33539;&#25968;&#65292;&#20197;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#21517;&#20026;&#20132;&#26367;&#36817;&#31471;&#20056;&#23376;&#26041;&#27861;&#65288;APMM&#65289;&#30340;&#26032;&#20248;&#21270;&#31639;&#27861;&#65292;&#20197;&#36845;&#20195;&#22320;&#35299;&#20915;&#25552;&#20986;&#30340;&#24352;&#37327;&#34917;&#20840;&#27169;&#22411;&#12290;&#29702;&#35770;&#20998;&#26512;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;APMM&#25910;&#25947;&#21040;&#20248;&#21270;&#38382;&#39064;&#30340;Karush-Kuhn-Tucker&#65288;KKT&#65289;&#28857;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22522;&#20110;APMM&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#30446;&#26631;&#24352;&#37327;&#24674;&#22797;&#26694;&#26550;&#65292;&#20197;&#26377;&#25928;&#25506;&#32034;&#21327;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.13958v2 Announce Type: replace-cross  Abstract: Recently, numerous tensor singular value decomposition (t-SVD)-based tensor recovery methods have shown promise in processing visual data, such as color images and videos. However, these methods often suffer from severe performance degradation when confronted with tensor data exhibiting non-smooth changes. It has been commonly observed in real-world scenarios but ignored by the traditional t-SVD-based methods. In this work, we introduce a novel tensor recovery model with a learnable tensor nuclear norm to address such a challenge. We develop a new optimization algorithm named the Alternating Proximal Multiplier Method (APMM) to iteratively solve the proposed tensor completion model. Theoretical analysis demonstrates the convergence of the proposed APMM to the Karush-Kuhn-Tucker (KKT) point of the optimization problem. In addition, we propose a multi-objective tensor recovery framework based on APMM to efficiently explore the co
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23545;&#28145;&#24230;&#23398;&#20064;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#36827;&#34892;&#20102;&#35843;&#26597;&#65292;&#20174;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#30340;&#35282;&#24230;&#20998;&#26512;&#19981;&#21516;&#26041;&#27861;&#65292;&#20197;&#35780;&#20272;DNN&#39044;&#27979;&#30340;&#32622;&#20449;&#24230;&#12290;</title><link>https://arxiv.org/abs/2302.13425</link><description>&lt;p&gt;
&#23545;&#28145;&#24230;&#23398;&#20064;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#36827;&#34892;&#35843;&#26597;&#65306;&#20174;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#30340;&#35282;&#24230;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
A Survey on Uncertainty Quantification for Deep Learning: An Uncertainty Source Perspective
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2302.13425
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23545;&#28145;&#24230;&#23398;&#20064;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#36827;&#34892;&#20102;&#35843;&#26597;&#65292;&#20174;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#30340;&#35282;&#24230;&#20998;&#26512;&#19981;&#21516;&#26041;&#27861;&#65292;&#20197;&#35780;&#20272;DNN&#39044;&#27979;&#30340;&#32622;&#20449;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20197;&#21450;&#31185;&#23398;&#19982;&#24037;&#31243;&#39046;&#22495;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#20154;&#20204;&#20063;&#35748;&#35782;&#21040;DNNs&#26377;&#26102;&#20250;&#20570;&#20986;&#24847;&#22806;&#12289;&#38169;&#35823;&#20294;&#36807;&#20110;&#33258;&#20449;&#30340;&#39044;&#27979;&#12290;&#36825;&#21487;&#33021;&#23548;&#33268;&#22312;&#33258;&#21160;&#39550;&#39542;&#12289;&#21307;&#23398;&#35786;&#26029;&#21644;&#28798;&#38590;&#21709;&#24212;&#31561;&#39640;&#39118;&#38505;&#24212;&#29992;&#20013;&#20986;&#29616;&#20005;&#37325;&#21518;&#26524;&#12290;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65288;UQ&#65289;&#26088;&#22312;&#20272;&#35745;DNN&#39044;&#27979;&#30340;&#32622;&#20449;&#24230;&#65292;&#36229;&#36234;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#36817;&#24180;&#26469;&#65292;&#24050;&#32463;&#24320;&#21457;&#20102;&#35768;&#22810;&#38024;&#23545;DNNs&#30340;UQ&#26041;&#27861;&#12290;&#31995;&#32479;&#22320;&#23545;&#36825;&#20123;UQ&#26041;&#27861;&#36827;&#34892;&#20998;&#31867;&#24182;&#27604;&#36739;&#23427;&#20204;&#30340;&#20248;&#21183;&#21644;&#21155;&#21183;&#20855;&#26377;&#26497;&#22823;&#30340;&#23454;&#38469;&#20215;&#20540;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#35843;&#26597;&#22823;&#22810;&#38598;&#20013;&#22312;&#20174;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#35282;&#24230;&#25110;&#36125;&#21494;&#26031;&#35282;&#24230;&#23545;UQ&#26041;&#27861;&#36827;&#34892;&#20998;&#31867;&#65292;&#24573;&#30053;&#20102;&#27599;&#31181;&#26041;&#27861;&#21487;&#33021;&#24341;&#20837;&#30340;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2302.13425v3 Announce Type: replace  Abstract: Deep neural networks (DNNs) have achieved tremendous success in making accurate predictions for computer vision, natural language processing, as well as science and engineering domains. However, it is also well-recognized that DNNs sometimes make unexpected, incorrect, but overconfident predictions. This can cause serious consequences in high-stake applications, such as autonomous driving, medical diagnosis, and disaster response. Uncertainty quantification (UQ) aims to estimate the confidence of DNN predictions beyond prediction accuracy. In recent years, many UQ methods have been developed for DNNs. It is of great practical value to systematically categorize these UQ methods and compare their advantages and disadvantages. However, existing surveys mostly focus on categorizing UQ methodologies from a neural network architecture perspective or a Bayesian perspective and ignore the source of uncertainty that each methodology can incor
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31283;&#23450;&#30340;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#25193;&#25955;&#26144;&#23556;&#19982;&#26391;&#20043;&#19975;&#21160;&#21147;&#23398;&#30456;&#32467;&#21512;&#65292;&#22312;&#20165;&#26377;&#26377;&#38480;&#25968;&#37327;&#30340;&#35757;&#32451;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#29983;&#25104;&#26032;&#26679;&#26412;&#65292;&#24182;&#35299;&#20915;&#20102;&#26102;&#38388;&#27493;&#38271;&#20725;&#30828;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#20013;&#30340;&#31283;&#23450;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.04372</link><description>&lt;p&gt;
&#20351;&#29992;&#25193;&#25955;&#26144;&#23556;&#36827;&#34892;&#31283;&#23450;&#30340;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Stable generative modeling using diffusion maps. (arXiv:2401.04372v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04372
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31283;&#23450;&#30340;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#25193;&#25955;&#26144;&#23556;&#19982;&#26391;&#20043;&#19975;&#21160;&#21147;&#23398;&#30456;&#32467;&#21512;&#65292;&#22312;&#20165;&#26377;&#26377;&#38480;&#25968;&#37327;&#30340;&#35757;&#32451;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#29983;&#25104;&#26032;&#26679;&#26412;&#65292;&#24182;&#35299;&#20915;&#20102;&#26102;&#38388;&#27493;&#38271;&#20725;&#30828;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#20013;&#30340;&#31283;&#23450;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20174;&#20165;&#26377;&#36275;&#22815;&#25968;&#37327;&#30340;&#35757;&#32451;&#26679;&#26412;&#21487;&#24471;&#21040;&#30340;&#26410;&#30693;&#20998;&#24067;&#20013;&#25277;&#26679;&#30340;&#38382;&#39064;&#12290;&#22312;&#29983;&#25104;&#24314;&#27169;&#30340;&#32972;&#26223;&#19979;&#65292;&#36825;&#26679;&#30340;&#35774;&#32622;&#26368;&#36817;&#24341;&#36215;&#20102;&#30456;&#24403;&#22823;&#30340;&#20851;&#27880;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#25193;&#25955;&#26144;&#23556;&#21644;&#26391;&#20043;&#19975;&#21160;&#21147;&#23398;&#30456;&#32467;&#21512;&#30340;&#29983;&#25104;&#27169;&#22411;&#12290;&#25193;&#25955;&#26144;&#23556;&#29992;&#20110;&#20174;&#21487;&#29992;&#30340;&#35757;&#32451;&#26679;&#26412;&#20013;&#36817;&#20284;&#24471;&#21040;&#28418;&#31227;&#39033;&#65292;&#28982;&#21518;&#22312;&#31163;&#25955;&#26102;&#38388;&#30340;&#26391;&#20043;&#19975;&#37319;&#26679;&#22120;&#20013;&#23454;&#29616;&#29983;&#25104;&#26032;&#26679;&#26412;&#12290;&#36890;&#36807;&#23558;&#26680;&#24102;&#23485;&#35774;&#32622;&#20026;&#19982;&#26410;&#35843;&#25972;&#30340;&#26391;&#20043;&#19975;&#31639;&#27861;&#20013;&#20351;&#29992;&#30340;&#26102;&#38388;&#27493;&#38271;&#21305;&#37197;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#22320;&#36991;&#20813;&#36890;&#24120;&#19982;&#26102;&#38388;&#27493;&#38271;&#20725;&#30828;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30456;&#20851;&#30340;&#31283;&#23450;&#24615;&#38382;&#39064;&#12290;&#26356;&#20934;&#30830;&#22320;&#35828;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#35010;&#27493;&#39588;&#26041;&#26696;&#65292;&#30830;&#20445;&#29983;&#25104;&#30340;&#26679;&#26412;&#20445;&#25345;&#22312;&#35757;&#32451;&#26679;&#26412;&#30340;&#20984;&#21253;&#20869;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#33258;&#28982;&#22320;&#25193;&#23637;&#20026;&#29983;&#25104;&#26465;&#20214;&#26679;&#26412;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of sampling from an unknown distribution for which only a sufficiently large number of training samples are available. Such settings have recently drawn considerable interest in the context of generative modelling. In this paper, we propose a generative model combining diffusion maps and Langevin dynamics. Diffusion maps are used to approximate the drift term from the available training samples, which is then implemented in a discrete-time Langevin sampler to generate new samples. By setting the kernel bandwidth to match the time step size used in the unadjusted Langevin algorithm, our method effectively circumvents any stability issues typically associated with time-stepping stiff stochastic differential equations. More precisely, we introduce a novel split-step scheme, ensuring that the generated samples remain within the convex hull of the training samples. Our framework can be naturally extended to generate conditional samples. We demonstrate the performance
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#20302;&#31934;&#24230;&#21644;&#20840;&#31934;&#24230;&#26799;&#24230;&#32047;&#21152;&#22120;&#30340;&#38543;&#26426;&#26799;&#24230;Hamiltonian Monte Carlo (SGHMC)&#22312;&#20302;&#31934;&#24230;&#37319;&#26679;&#20013;&#30340;&#24212;&#29992;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#38750;&#23545;&#25968;&#20985;&#20998;&#24067;&#19979;&#65292;&#20302;&#31934;&#24230;SGHMC&#30456;&#23545;&#20110;&#20302;&#31934;&#24230;&#37319;&#26679;&#22120;&#65288;SGLD&#65289;&#23454;&#29616;&#20102;&#20108;&#27425;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2310.16320</link><description>&lt;p&gt;
&#22686;&#24378;&#20302;&#31934;&#24230;&#37319;&#26679;&#65306;&#38543;&#26426;&#26799;&#24230;Hamiltonian Monte Carlo
&lt;/p&gt;
&lt;p&gt;
Enhancing Low-Precision Sampling via Stochastic Gradient Hamiltonian Monte Carlo. (arXiv:2310.16320v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16320
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#20302;&#31934;&#24230;&#21644;&#20840;&#31934;&#24230;&#26799;&#24230;&#32047;&#21152;&#22120;&#30340;&#38543;&#26426;&#26799;&#24230;Hamiltonian Monte Carlo (SGHMC)&#22312;&#20302;&#31934;&#24230;&#37319;&#26679;&#20013;&#30340;&#24212;&#29992;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#38750;&#23545;&#25968;&#20985;&#20998;&#24067;&#19979;&#65292;&#20302;&#31934;&#24230;SGHMC&#30456;&#23545;&#20110;&#20302;&#31934;&#24230;&#37319;&#26679;&#22120;&#65288;SGLD&#65289;&#23454;&#29616;&#20102;&#20108;&#27425;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20302;&#31934;&#24230;&#35757;&#32451;&#24050;&#32463;&#25104;&#20026;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#20302;&#25104;&#26412;&#25216;&#26415;&#65292;&#21487;&#20197;&#22312;&#19981;&#29306;&#29298;&#22826;&#22810;&#20934;&#30830;&#24615;&#30340;&#24773;&#20917;&#19979;&#25552;&#39640;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#25928;&#29575;&#12290;&#20854;&#36125;&#21494;&#26031;&#23545;&#24212;&#29289;&#21487;&#20197;&#36827;&#19968;&#27493;&#25552;&#20379;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#25913;&#36827;&#30340;&#27867;&#21270;&#20934;&#30830;&#24615;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#24378;&#23545;&#25968;&#20985;&#21644;&#38750;&#23545;&#25968;&#20985;&#20998;&#24067;&#19979;&#65292;&#20351;&#29992;&#20302;&#31934;&#24230;&#21644;&#20840;&#31934;&#24230;&#26799;&#24230;&#32047;&#21152;&#22120;&#30340;&#38543;&#26426;&#26799;&#24230;Hamiltonian Monte Carlo (SGHMC)&#12290;&#20174;&#29702;&#35770;&#19978;&#35762;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#20026;&#20102;&#22312;&#38750;&#23545;&#25968;&#20985;&#20998;&#24067;&#19979;&#23454;&#29616;2-Wasserstein&#36317;&#31163;&#30340;&#949;&#35823;&#24046;&#65292;&#20302;&#31934;&#24230;SGHMC&#30456;&#23545;&#20110;&#20302;&#31934;&#24230;&#37319;&#26679;&#22120;&#65288;&#38543;&#26426;&#26799;&#24230;Langevin&#21160;&#21147;&#23398;&#65292;SGLD&#65289;&#23454;&#29616;&#20102;&#20108;&#27425;&#25913;&#36827;&#65288;$\widetilde{\mathbf{O}}\left({\epsilon^{-2}{\mu^*}^{-2}\log^2\left({\epsilon^{-1}}\right)}\right)$ vs $\widetilde{\mathbf{O}}\left({{\epsilon}^{-4}{\lambda^{*}}^{-1}\log^5\left({\epsilon^{-1}}\right)}\right)$&#65289;&#12290;&#21478;&#22806;&#65292;&#22522;&#20110;&#30495;&#23454;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#20302;&#31934;&#24230;SGHMC&#30456;&#23545;&#20110;SGLD&#22312;&#38750;&#23545;&#25968;&#20985;&#20998;&#24067;&#19979;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Low-precision training has emerged as a promising low-cost technique to enhance the training efficiency of deep neural networks without sacrificing much accuracy. Its Bayesian counterpart can further provide uncertainty quantification and improved generalization accuracy. This paper investigates low-precision sampling via Stochastic Gradient Hamiltonian Monte Carlo (SGHMC) with low-precision and full-precision gradient accumulators for both strongly log-concave and non-log-concave distributions. Theoretically, our results show that, to achieve $\epsilon$-error in the 2-Wasserstein distance for non-log-concave distributions, low-precision SGHMC achieves quadratic improvement ($\widetilde{\mathbf{O}}\left({\epsilon^{-2}{\mu^*}^{-2}\log^2\left({\epsilon^{-1}}\right)}\right)$) compared to the state-of-the-art low-precision sampler, Stochastic Gradient Langevin Dynamics (SGLD) ($\widetilde{\mathbf{O}}\left({{\epsilon}^{-4}{\lambda^{*}}^{-1}\log^5\left({\epsilon^{-1}}\right)}\right)$). Moreo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#39640;&#32500;&#24230;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#20013;&#24322;&#26041;&#24046;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22522;&#20110;&#20998;&#21306;&#32463;&#39564;&#36125;&#21494;&#26031;ECM&#31639;&#27861;&#30340;&#24322;&#26041;&#24046;&#39640;&#32500;&#24230;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#26469;&#23454;&#29616;&#12290;&#36825;&#20010;&#27169;&#22411;&#21487;&#20197;&#22788;&#29702;&#27531;&#24046;&#26041;&#24046;&#19981;&#24658;&#23450;&#30340;&#24773;&#20917;&#65292;&#24182;&#19988;&#21487;&#20197;&#20351;&#29992;&#25554;&#20540;&#30340;&#32463;&#39564;&#36125;&#21494;&#26031;&#20272;&#35745;&#36229;&#21442;&#25968;&#26469;&#28789;&#27963;&#22320;&#35843;&#25972;&#26041;&#24046;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2309.08783</link><description>&lt;p&gt;
&#39640;&#32500;&#24230;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#24322;&#26041;&#24046;&#38382;&#39064;&#21450;&#22522;&#20110;&#20998;&#21306;&#32463;&#39564;&#36125;&#21494;&#26031;ECM&#31639;&#27861;&#30340;&#35299;&#20915;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Heteroscedastic sparse high-dimensional linear regression with a partitioned empirical Bayes ECM algorithm. (arXiv:2309.08783v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08783
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#39640;&#32500;&#24230;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#20013;&#24322;&#26041;&#24046;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22522;&#20110;&#20998;&#21306;&#32463;&#39564;&#36125;&#21494;&#26031;ECM&#31639;&#27861;&#30340;&#24322;&#26041;&#24046;&#39640;&#32500;&#24230;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#26469;&#23454;&#29616;&#12290;&#36825;&#20010;&#27169;&#22411;&#21487;&#20197;&#22788;&#29702;&#27531;&#24046;&#26041;&#24046;&#19981;&#24658;&#23450;&#30340;&#24773;&#20917;&#65292;&#24182;&#19988;&#21487;&#20197;&#20351;&#29992;&#25554;&#20540;&#30340;&#32463;&#39564;&#36125;&#21494;&#26031;&#20272;&#35745;&#36229;&#21442;&#25968;&#26469;&#28789;&#27963;&#22320;&#35843;&#25972;&#26041;&#24046;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#32500;&#24230;&#25968;&#25454;&#30340;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#26041;&#27861;&#36890;&#24120;&#20551;&#35774;&#27531;&#24046;&#20855;&#26377;&#24120;&#25968;&#26041;&#24046;&#12290;&#24403;&#36825;&#19968;&#20551;&#35774;&#34987;&#36829;&#32972;&#26102;&#65292;&#20250;&#23548;&#33268;&#20272;&#35745;&#31995;&#25968;&#30340;&#20559;&#24046;&#65292;&#39044;&#27979;&#21306;&#38388;&#38271;&#24230;&#19981;&#21512;&#36866;&#20197;&#21450;&#22686;&#21152;I&#22411;&#38169;&#35823;&#12290;&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20998;&#21306;&#32463;&#39564;&#36125;&#21494;&#26031;&#26399;&#26395;&#26465;&#20214;&#26368;&#22823;&#21270;(H-PROBE)&#31639;&#27861;&#30340;&#24322;&#26041;&#24046;&#39640;&#32500;&#24230;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#12290;H-PROBE&#26159;&#19968;&#31181;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#26368;&#22823;&#21518;&#39564;&#20272;&#35745;&#26041;&#27861;&#65292;&#22522;&#20110;&#21442;&#25968;&#25193;&#23637;&#30340;&#26399;&#26395;&#26465;&#20214;&#26368;&#22823;&#21270;(PX-ECM)&#31639;&#27861;&#12290;&#23427;&#36890;&#36807;&#25554;&#20540;&#30340;&#32463;&#39564;&#36125;&#21494;&#26031;&#20272;&#35745;&#36229;&#21442;&#25968;&#65292;&#22312;&#22238;&#24402;&#21442;&#25968;&#19978;&#20551;&#35774;&#26368;&#23567;&#12290;&#26041;&#24046;&#27169;&#22411;&#20351;&#29992;&#20102;&#22810;&#20803;&#23545;&#25968;&#20285;&#39532;&#20998;&#24067;&#29702;&#35770;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#24182;&#21487;&#20197;&#21253;&#21547;&#20551;&#35774;&#20250;&#24433;&#21709;&#24322;&#36136;&#24615;&#30340;&#21327;&#21464;&#37327;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#21160;&#26426;&#26159;&#36890;&#36807;T2&#39640;&#20998;&#36776;&#29575;&#31070;&#32463;&#24433;&#20687;&#30740;&#31350;&#19982;&#22833;&#35821;&#25351;&#25968;(AQ)&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sparse linear regression methods for high-dimensional data often assume that residuals have constant variance. When this assumption is violated, it can lead to bias in estimated coefficients, prediction intervals with improper length, and increased type I errors. This paper proposes a heteroscedastic (H) high-dimensional linear regression model through a partitioned empirical Bayes Expectation Conditional Maximization (H-PROBE) algorithm. H-PROBE is a computationally efficient maximum a posteriori (MAP) estimation approach based on a Parameter-Expanded Expectation-Conditional-Maximization (PX-ECM) algorithm. It requires minimal prior assumptions on the regression parameters through plug-in empirical Bayes estimates of hyperparameters. The variance model uses recent advances in multivariate log-Gamma distribution theory and can include covariates hypothesized to impact heterogeneity. The motivation of our approach is a study relating Aphasia Quotient (AQ) to high-resolution T2 neuroimag
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25216;&#26415;&#65292;&#31216;&#20026;UTOPIA&#65292;&#29992;&#20110;&#32858;&#21512;&#22810;&#20010;&#39044;&#27979;&#21306;&#38388;&#20197;&#20943;&#23567;&#20854;&#23485;&#24230;&#24182;&#20445;&#35777;&#35206;&#30422;&#29575;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#32447;&#24615;&#25110;&#20984;&#35268;&#21010;&#65292;&#26131;&#20110;&#23454;&#29616;&#65292;&#36866;&#29992;&#33539;&#22260;&#24191;&#27867;&#12290;</title><link>http://arxiv.org/abs/2306.16549</link><description>&lt;p&gt;
UTOPIA&#65306;&#36890;&#29992;&#21487;&#35757;&#32451;&#30340;&#26368;&#20248;&#39044;&#27979;&#21306;&#38388;&#32858;&#21512;
&lt;/p&gt;
&lt;p&gt;
UTOPIA: Universally Trainable Optimal Prediction Intervals Aggregation. (arXiv:2306.16549v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16549
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25216;&#26415;&#65292;&#31216;&#20026;UTOPIA&#65292;&#29992;&#20110;&#32858;&#21512;&#22810;&#20010;&#39044;&#27979;&#21306;&#38388;&#20197;&#20943;&#23567;&#20854;&#23485;&#24230;&#24182;&#20445;&#35777;&#35206;&#30422;&#29575;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#32447;&#24615;&#25110;&#20984;&#35268;&#21010;&#65292;&#26131;&#20110;&#23454;&#29616;&#65292;&#36866;&#29992;&#33539;&#22260;&#24191;&#27867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26159;&#19968;&#20010;&#26377;&#36259;&#30340;&#38382;&#39064;&#65292;&#22312;&#29983;&#29289;&#21307;&#23398;&#31185;&#23398;&#12289;&#32463;&#27982;&#30740;&#31350;&#21644;&#22825;&#27668;&#39044;&#25253;&#31561;&#21508;&#20010;&#39046;&#22495;&#26377;&#37325;&#35201;&#30340;&#24212;&#29992;&#12290;&#26500;&#24314;&#39044;&#27979;&#21306;&#38388;&#30340;&#26041;&#27861;&#26377;&#24456;&#22810;&#65292;&#22914;&#20998;&#20301;&#25968;&#22238;&#24402;&#21644;&#19968;&#33268;&#24615;&#39044;&#27979;&#31561;&#12290;&#28982;&#32780;&#65292;&#27169;&#22411;&#38169;&#35823;&#35268;&#23450;&#65288;&#23588;&#20854;&#26159;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#65289;&#25110;&#27425;&#20248;&#30340;&#26500;&#36896;&#36890;&#24120;&#20250;&#23548;&#33268;&#26377;&#20559;&#25110;&#36807;&#23485;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#19988;&#24191;&#27867;&#36866;&#29992;&#30340;&#25216;&#26415;&#65292;&#29992;&#20110;&#32858;&#21512;&#22810;&#20010;&#39044;&#27979;&#21306;&#38388;&#20197;&#26368;&#23567;&#21270;&#39044;&#27979;&#24102;&#30340;&#24179;&#22343;&#23485;&#24230;&#21644;&#35206;&#30422;&#20445;&#35777;&#65292;&#31216;&#20026;&#36890;&#29992;&#21487;&#35757;&#32451;&#30340;&#26368;&#20248;&#39044;&#27979;&#21306;&#38388;&#32858;&#21512;&#65288;UTOPIA&#65289;&#12290;&#35813;&#26041;&#27861;&#36824;&#20801;&#35768;&#25105;&#20204;&#26681;&#25454;&#22522;&#26412;&#30340;&#22522;&#20989;&#25968;&#30452;&#25509;&#26500;&#24314;&#39044;&#27979;&#24102;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#32447;&#24615;&#25110;&#20984;&#35268;&#21010;&#65292;&#26131;&#20110;&#23454;&#29616;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#25152;&#26377;&#26041;&#27861;&#37117;&#24471;&#21040;&#20102;&#23454;&#39564;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
Uncertainty quantification for prediction is an intriguing problem with significant applications in various fields, such as biomedical science, economic studies, and weather forecasts. Numerous methods are available for constructing prediction intervals, such as quantile regression and conformal predictions, among others. Nevertheless, model misspecification (especially in high-dimension) or sub-optimal constructions can frequently result in biased or unnecessarily-wide prediction intervals. In this paper, we propose a novel and widely applicable technique for aggregating multiple prediction intervals to minimize the average width of the prediction band along with coverage guarantee, called Universally Trainable Optimal Predictive Intervals Aggregation (UTOPIA). The method also allows us to directly construct predictive bands based on elementary basis functions. Our approach is based on linear or convex programming which is easy to implement. All of our proposed methodologies are suppo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26102;&#38388;&#21464;&#37327;&#22788;&#29702;&#24773;&#20917;&#19979;&#30340;&#21453;&#20107;&#23454;&#29983;&#25104;&#27169;&#22411;&#65292;&#33021;&#22815;&#25429;&#25417;&#25972;&#20010;&#21453;&#20107;&#23454;&#20998;&#24067;&#65292;&#24182;&#19988;&#33021;&#22815;&#26377;&#25928;&#25512;&#26029;&#21453;&#20107;&#23454;&#20998;&#24067;&#30340;&#26576;&#20123;&#32479;&#35745;&#37327;&#65292;&#36866;&#29992;&#20110;&#21307;&#30103;&#20445;&#20581;&#21644;&#20844;&#20849;&#25919;&#31574;&#21046;&#23450;&#39046;&#22495;&#12290;</title><link>http://arxiv.org/abs/2305.15742</link><description>&lt;p&gt;
&#26102;&#38388;&#21464;&#21270;&#22788;&#29702;&#30340;&#21453;&#20107;&#23454;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Counterfactual Generative Models for Time-Varying Treatments. (arXiv:2305.15742v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15742
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26102;&#38388;&#21464;&#37327;&#22788;&#29702;&#24773;&#20917;&#19979;&#30340;&#21453;&#20107;&#23454;&#29983;&#25104;&#27169;&#22411;&#65292;&#33021;&#22815;&#25429;&#25417;&#25972;&#20010;&#21453;&#20107;&#23454;&#20998;&#24067;&#65292;&#24182;&#19988;&#33021;&#22815;&#26377;&#25928;&#25512;&#26029;&#21453;&#20107;&#23454;&#20998;&#24067;&#30340;&#26576;&#20123;&#32479;&#35745;&#37327;&#65292;&#36866;&#29992;&#20110;&#21307;&#30103;&#20445;&#20581;&#21644;&#20844;&#20849;&#25919;&#31574;&#21046;&#23450;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20272;&#35745;&#24179;&#22343;&#22240;&#26524;&#25928;&#24212;&#26159;&#27979;&#35797;&#26032;&#30103;&#27861;&#30340;&#24120;&#29992;&#20570;&#27861;&#12290;&#28982;&#32780;&#65292;&#24179;&#22343;&#25928;&#24212;&#20250;&#25513;&#30422;&#21453;&#20107;&#23454;&#20998;&#24067;&#20013;&#37325;&#35201;&#30340;&#20010;&#20307;&#29305;&#24449;&#65292;&#21487;&#33021;&#20250;&#24341;&#36215;&#23433;&#20840;&#12289;&#20844;&#24179;&#21644;&#36947;&#24503;&#26041;&#38754;&#30340;&#25285;&#24551;&#12290;&#36825;&#20010;&#38382;&#39064;&#22312;&#26102;&#38388;&#35774;&#32622;&#20013;&#26356;&#21152;&#20005;&#37325;&#65292;&#22240;&#20026;&#22788;&#29702;&#26159;&#26102;&#24207;&#30340;&#21644;&#26102;&#21464;&#30340;&#65292;&#23545;&#21453;&#20107;&#23454;&#20998;&#24067;&#20135;&#29983;&#20102;&#38169;&#32508;&#22797;&#26434;&#30340;&#24433;&#21709;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26465;&#20214;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#65292;&#20197;&#25429;&#33719;&#25972;&#20010;&#21453;&#20107;&#23454;&#20998;&#24067;&#65292;&#20801;&#35768;&#23545;&#21453;&#20107;&#23454;&#20998;&#24067;&#30340;&#26576;&#20123;&#32479;&#35745;&#37327;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#12290;&#36825;&#20351;&#24471;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#23588;&#20854;&#36866;&#29992;&#20110;&#21307;&#30103;&#20445;&#20581;&#21644;&#20844;&#20849;&#25919;&#31574;&#21046;&#23450;&#39046;&#22495;&#12290;&#25105;&#20204;&#30340;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#36890;&#36807;&#36793;&#38469;&#32467;&#26500;&#27169;&#22411;&#35880;&#24910;&#22320;&#35299;&#20915;&#20102;&#35266;&#23519;&#25968;&#25454;&#21644;&#30446;&#26631;&#21453;&#20107;&#23454;&#20998;&#24067;&#20043;&#38388;&#30340;&#20998;&#24067;&#19981;&#21305;&#37197;&#12290;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#19978;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#30340;&#22522;&#32447;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating average causal effects is a common practice to test new treatments. However, the average effect ''masks'' important individual characteristics in the counterfactual distribution, which may lead to safety, fairness, and ethical concerns. This issue is exacerbated in the temporal setting, where the treatment is sequential and time-varying, leading to an intricate influence on the counterfactual distribution. In this paper, we propose a novel conditional generative modeling approach to capture the whole counterfactual distribution, allowing efficient inference on certain statistics of the counterfactual distribution. This makes the proposed approach particularly suitable for healthcare and public policy making. Our generative modeling approach carefully tackles the distribution mismatch in the observed data and the targeted counterfactual distribution via a marginal structural model. Our method outperforms state-of-the-art baselines on both synthetic and real data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21160;&#24577;&#20851;&#31995;&#25968;&#25454;&#30340;&#20998;&#35299;&#34701;&#21512;&#21387;&#32553;&#27169;&#22411;&#65292;&#36890;&#36807;&#23545;&#20998;&#35299;&#30697;&#38453;&#30340;&#34892;&#21521;&#37327;&#30340;&#36880;&#27425;&#24046;&#20540;&#26045;&#21152;&#20840;&#23616;-&#23616;&#37096;&#21387;&#32553;&#20808;&#39564;&#33719;&#24471;&#25910;&#32553;&#65292;&#24182;&#20855;&#26377;&#35768;&#22810;&#26377;&#21033;&#30340;&#24615;&#36136;&#12290;</title><link>http://arxiv.org/abs/2210.00091</link><description>&lt;p&gt;
&#21160;&#24577;&#20851;&#31995;&#25968;&#25454;&#30340;&#20998;&#35299;&#34701;&#21512;&#21387;&#32553;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Factorized Fusion Shrinkage for Dynamic Relational Data. (arXiv:2210.00091v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.00091
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21160;&#24577;&#20851;&#31995;&#25968;&#25454;&#30340;&#20998;&#35299;&#34701;&#21512;&#21387;&#32553;&#27169;&#22411;&#65292;&#36890;&#36807;&#23545;&#20998;&#35299;&#30697;&#38453;&#30340;&#34892;&#21521;&#37327;&#30340;&#36880;&#27425;&#24046;&#20540;&#26045;&#21152;&#20840;&#23616;-&#23616;&#37096;&#21387;&#32553;&#20808;&#39564;&#33719;&#24471;&#25910;&#32553;&#65292;&#24182;&#20855;&#26377;&#35768;&#22810;&#26377;&#21033;&#30340;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#25968;&#25454;&#31185;&#23398;&#24212;&#29992;&#32463;&#24120;&#28041;&#21450;&#20855;&#26377;&#21160;&#24577;&#32467;&#26500;&#30340;&#22797;&#26434;&#20851;&#31995;&#25968;&#25454;&#12290;&#27492;&#31867;&#21160;&#24577;&#20851;&#31995;&#25968;&#25454;&#30340;&#31361;&#21464;&#36890;&#24120;&#20986;&#29616;&#22312;&#30001;&#20110;&#24178;&#39044;&#32780;&#32463;&#21382;&#21046;&#24230;&#21464;&#21270;&#30340;&#31995;&#32479;&#20013;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#32771;&#34385;&#19968;&#31181;&#20998;&#35299;&#34701;&#21512;&#21387;&#32553;&#27169;&#22411;&#65292;&#20854;&#20013;&#25152;&#26377;&#20998;&#35299;&#22240;&#23376;&#37117;&#34987;&#21160;&#24577;&#22320;&#25910;&#32553;&#21040;&#32452;&#20869;&#34701;&#21512;&#32467;&#26500;&#65292;&#25910;&#32553;&#36890;&#36807;&#23545;&#20998;&#35299;&#30697;&#38453;&#30340;&#34892;&#21521;&#37327;&#30340;&#36880;&#27425;&#24046;&#20540;&#26045;&#21152;&#20840;&#23616;-&#23616;&#37096;&#21387;&#32553;&#20808;&#39564;&#26469;&#33719;&#24471;&#12290;&#25152;&#25552;&#20986;&#30340;&#20808;&#39564;&#22312;&#20272;&#35745;&#30340;&#21160;&#24577;&#28508;&#22312;&#22240;&#23376;&#30340;&#27604;&#36739;&#21644;&#32858;&#31867;&#26041;&#38754;&#20855;&#26377;&#35768;&#22810;&#26377;&#21033;&#30340;&#24615;&#36136;&#12290;&#27604;&#36739;&#20272;&#35745;&#30340;&#28508;&#22312;&#22240;&#23376;&#28041;&#21450;&#30456;&#37051;&#21644;&#38271;&#26399;&#27604;&#36739;&#65292;&#32771;&#34385;&#21040;&#27604;&#36739;&#30340;&#26102;&#38388;&#33539;&#22260;&#20316;&#20026;&#21464;&#37327;&#12290;&#22312;&#26576;&#20123;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#21518;&#39564;&#20998;&#24067;&#36798;&#21040;&#26368;&#23567;&#21270;&#26368;&#22823;&#39118;&#38505;&#65292;&#30452;&#21040;&#23545;&#25968;&#22240;&#23376;&#12290;&#22312;&#35745;&#31639;&#26041;&#38754;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32467;&#26500;&#21270;&#30340;&#22343;&#20540;&#22330;&#21464;&#20998;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern data science applications often involve complex relational data with dynamic structures. An abrupt change in such dynamic relational data is typically observed in systems that undergo regime changes due to interventions. In such a case, we consider a factorized fusion shrinkage model in which all decomposed factors are dynamically shrunk towards group-wise fusion structures, where the shrinkage is obtained by applying global-local shrinkage priors to the successive differences of the row vectors of the factorized matrices. The proposed priors enjoy many favorable properties in comparison and clustering of the estimated dynamic latent factors. Comparing estimated latent factors involves both adjacent and long-term comparisons, with the time range of comparison considered as a variable. Under certain conditions, we demonstrate that the posterior distribution attains the minimax optimal rate up to logarithmic factors. In terms of computation, we present a structured mean-field vari
&lt;/p&gt;</description></item></channel></rss>