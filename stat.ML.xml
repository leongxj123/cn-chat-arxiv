<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#22522;&#20110;&#20302;&#31209;&#21152;&#23545;&#35282;&#32447;&#21442;&#25968;&#21270;&#21327;&#26041;&#24046;&#30697;&#38453;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#21051;&#30011;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#35823;&#24046;&#30340;&#33258;&#30456;&#20851;&#24615;&#65292;&#24182;&#20855;&#26377;&#22797;&#26434;&#24230;&#20302;&#12289;&#26657;&#20934;&#39044;&#27979;&#20934;&#30830;&#24615;&#39640;&#31561;&#20248;&#28857;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01000</link><description>&lt;p&gt;
&#22810;&#20803;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#19982;&#30456;&#20851;&#35823;&#24046;
&lt;/p&gt;
&lt;p&gt;
Multivariate Probabilistic Time Series Forecasting with Correlated Errors
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01000
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#22522;&#20110;&#20302;&#31209;&#21152;&#23545;&#35282;&#32447;&#21442;&#25968;&#21270;&#21327;&#26041;&#24046;&#30697;&#38453;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#21051;&#30011;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#35823;&#24046;&#30340;&#33258;&#30456;&#20851;&#24615;&#65292;&#24182;&#20855;&#26377;&#22797;&#26434;&#24230;&#20302;&#12289;&#26657;&#20934;&#39044;&#27979;&#20934;&#30830;&#24615;&#39640;&#31561;&#20248;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24314;&#27169;&#35823;&#24046;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#19982;&#27169;&#22411;&#33021;&#22815;&#20934;&#30830;&#37327;&#21270;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#23494;&#20999;&#30456;&#20851;&#12290;&#26368;&#36817;&#30340;&#22810;&#20803;&#27169;&#22411;&#22312;&#32771;&#34385;&#35823;&#24046;&#20043;&#38388;&#30340;&#21516;&#26102;&#30456;&#20851;&#24615;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#28982;&#32780;&#65292;&#23545;&#20110;&#32479;&#35745;&#31616;&#21270;&#30340;&#30446;&#30340;&#65292;&#23545;&#36825;&#20123;&#35823;&#24046;&#30340;&#24120;&#35265;&#20551;&#35774;&#26159;&#23427;&#20204;&#22312;&#26102;&#38388;&#19978;&#26159;&#29420;&#31435;&#30340;&#12290;&#28982;&#32780;&#65292;&#23454;&#38469;&#35266;&#27979;&#24448;&#24448;&#20559;&#31163;&#20102;&#36825;&#20010;&#20551;&#35774;&#65292;&#22240;&#20026;&#35823;&#24046;&#36890;&#24120;&#30001;&#20110;&#21508;&#31181;&#22240;&#32032;&#65288;&#22914;&#25490;&#38500;&#26102;&#38388;&#30456;&#20851;&#30340;&#21327;&#21464;&#37327;&#65289;&#32780;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#33258;&#30456;&#20851;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20302;&#31209;&#21152;&#23545;&#35282;&#32447;&#21442;&#25968;&#21270;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#39640;&#25928;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#21051;&#30011;&#35823;&#24046;&#30340;&#33258;&#30456;&#20851;&#24615;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20855;&#26377;&#20960;&#20010;&#21487;&#21462;&#30340;&#29305;&#24615;&#65306;&#22797;&#26434;&#24230;&#19981;&#38543;&#26102;&#38388;&#24207;&#21015;&#25968;&#30446;&#22686;&#21152;&#65292;&#24471;&#21040;&#30340;&#21327;&#26041;&#24046;&#21487;&#20197;&#29992;&#20110;&#26657;&#20934;&#39044;&#27979;&#65292;&#19988;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modeling the correlations among errors is closely associated with how accurately the model can quantify predictive uncertainty in probabilistic time series forecasting. Recent multivariate models have made significant progress in accounting for contemporaneous correlations among errors, while a common assumption on these errors is that they are temporally independent for the sake of statistical simplicity. However, real-world observations often deviate from this assumption, since errors usually exhibit substantial autocorrelation due to various factors such as the exclusion of temporally correlated covariates. In this work, we propose an efficient method, based on a low-rank-plus-diagonal parameterization of the covariance matrix, which can effectively characterize the autocorrelation of errors. The proposed method possesses several desirable properties: the complexity does not scale with the number of time series, the resulting covariance can be used for calibrating predictions, and i
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26368;&#20248;&#27969;&#21305;&#37197;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#19968;&#27493;&#20013;&#23398;&#20064;&#23454;&#29616;&#20108;&#27425;&#25104;&#26412;&#19979;&#30340;&#30452;&#32447; OT &#20301;&#31227;&#12290;</title><link>https://arxiv.org/abs/2403.13117</link><description>&lt;p&gt;
&#26368;&#20248;&#27969;&#21305;&#37197;&#65306;&#22312;&#19968;&#27493;&#20013;&#23398;&#20064;&#30452;&#32447;&#36712;&#36857;
&lt;/p&gt;
&lt;p&gt;
Optimal Flow Matching: Learning Straight Trajectories in Just One Step
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13117
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26368;&#20248;&#27969;&#21305;&#37197;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#19968;&#27493;&#20013;&#23398;&#20064;&#23454;&#29616;&#20108;&#27425;&#25104;&#26412;&#19979;&#30340;&#30452;&#32447; OT &#20301;&#31227;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#20960;&#24180;&#20013;&#65292;&#27969;&#21305;&#37197;&#26041;&#27861;&#22312;&#29983;&#25104;&#24314;&#27169;&#20013;&#24471;&#21040;&#20102;&#34028;&#21187;&#21457;&#23637;&#12290;&#31038;&#21306;&#36861;&#27714;&#30340;&#19968;&#20010;&#24341;&#20154;&#27880;&#30446;&#30340;&#23646;&#24615;&#26159;&#33021;&#22815;&#23398;&#20064;&#20855;&#26377;&#30452;&#32447;&#36712;&#36857;&#30340;&#27969;&#65292;&#36825;&#20123;&#36712;&#36857;&#23454;&#29616;&#20102;&#26368;&#20248;&#36755;&#36816;&#65288;OT&#65289;&#32622;&#25442;&#12290;&#30452;&#32447;&#24615;&#23545;&#20110;&#24555;&#36895;&#38598;&#25104;&#23398;&#20064;&#27969;&#30340;&#36335;&#24452;&#33267;&#20851;&#37325;&#35201;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#27969;&#30452;&#32447;&#21270;&#26041;&#27861;&#37117;&#22522;&#20110;&#38750;&#24179;&#20961;&#30340;&#36845;&#20195;&#36807;&#31243;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#31215;&#32047;&#35823;&#24046;&#25110;&#21033;&#29992;&#21551;&#21457;&#24335;&#23567;&#25209;&#37327;OT&#36817;&#20284;&#12290;&#20026;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26368;&#20248;&#27969;&#21305;&#37197;&#26041;&#27861;&#65292;&#20165;&#36890;&#36807;&#19968;&#27425;&#27969;&#21305;&#37197;&#27493;&#39588;&#21363;&#21487;&#20026;&#20108;&#27425;&#25104;&#26412;&#24674;&#22797;&#30452;&#32447;OT&#32622;&#25442;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13117v1 Announce Type: cross  Abstract: Over the several recent years, there has been a boom in development of flow matching methods for generative modeling. One intriguing property pursued by the community is the ability to learn flows with straight trajectories which realize the optimal transport (OT) displacements. Straightness is crucial for fast integration of the learned flow's paths. Unfortunately, most existing flow straightening methods are based on non-trivial iterative procedures which accumulate the error during training or exploit heuristic minibatch OT approximations. To address this issue, we develop a novel optimal flow matching approach which recovers the straight OT displacement for the quadratic cost in just one flow matching step.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#25552;&#20986;&#20004;&#21442;&#25968;&#27169;&#22411;&#21644;&#26799;&#24230;&#27969;&#23398;&#20064;&#39640;&#32500;&#30446;&#26631;&#30340;&#29702;&#35770;&#21487;&#33021;&#24615;&#65292;&#30740;&#31350;&#21457;&#29616;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#23384;&#22312;&#22823;&#37327;&#19981;&#21487;&#23398;&#20064;&#30446;&#26631;&#65292;&#24182;&#19988;&#36825;&#20123;&#30446;&#26631;&#30340;&#38598;&#21512;&#19981;&#23494;&#38598;&#65292;&#20855;&#26377;&#19968;&#23450;&#25299;&#25169;&#24615;&#36136;&#30340;&#23376;&#38598;&#20013;&#20063;&#23384;&#22312;&#19981;&#21487;&#23398;&#20064;&#30446;&#26631;&#12290;&#26368;&#32456;&#65292;&#21457;&#29616;&#20351;&#29992;&#23618;&#27425;&#36807;&#31243;&#26500;&#24314;&#30340;&#20027;&#35201;&#23450;&#29702;&#27169;&#22411;&#22312;&#25968;&#23398;&#34920;&#36798;&#19978;&#24182;&#38750;&#30001;&#21333;&#19968;&#21021;&#31561;&#20989;&#25968;&#34920;&#31034;&#12290;</title><link>https://arxiv.org/abs/2402.17089</link><description>&lt;p&gt;
&#36890;&#36807;&#20004;&#21442;&#25968;&#27169;&#22411;&#21644;&#26799;&#24230;&#27969;&#23398;&#20064;&#39640;&#32500;&#30446;&#26631;
&lt;/p&gt;
&lt;p&gt;
Learning high-dimensional targets by two-parameter models and gradient flow
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17089
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25552;&#20986;&#20004;&#21442;&#25968;&#27169;&#22411;&#21644;&#26799;&#24230;&#27969;&#23398;&#20064;&#39640;&#32500;&#30446;&#26631;&#30340;&#29702;&#35770;&#21487;&#33021;&#24615;&#65292;&#30740;&#31350;&#21457;&#29616;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#23384;&#22312;&#22823;&#37327;&#19981;&#21487;&#23398;&#20064;&#30446;&#26631;&#65292;&#24182;&#19988;&#36825;&#20123;&#30446;&#26631;&#30340;&#38598;&#21512;&#19981;&#23494;&#38598;&#65292;&#20855;&#26377;&#19968;&#23450;&#25299;&#25169;&#24615;&#36136;&#30340;&#23376;&#38598;&#20013;&#20063;&#23384;&#22312;&#19981;&#21487;&#23398;&#20064;&#30446;&#26631;&#12290;&#26368;&#32456;&#65292;&#21457;&#29616;&#20351;&#29992;&#23618;&#27425;&#36807;&#31243;&#26500;&#24314;&#30340;&#20027;&#35201;&#23450;&#29702;&#27169;&#22411;&#22312;&#25968;&#23398;&#34920;&#36798;&#19978;&#24182;&#38750;&#30001;&#21333;&#19968;&#21021;&#31561;&#20989;&#25968;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25506;&#35752;&#20102;&#24403;$W&lt;d$&#26102;&#65292;&#36890;&#36807;&#26799;&#24230;&#27969;&#65288;GF&#65289;&#20197;$W$&#21442;&#25968;&#27169;&#22411;&#23398;&#20064;$d$&#32500;&#30446;&#26631;&#30340;&#29702;&#35770;&#21487;&#33021;&#24615;&#65292;&#24517;&#28982;&#23384;&#22312;GF-&#19981;&#21487;&#23398;&#20064;&#30446;&#26631;&#30340;&#22823;&#23376;&#38598;&#12290;&#29305;&#21035;&#26159;&#65292;&#21487;&#23398;&#20064;&#30446;&#26631;&#30340;&#38598;&#21512;&#22312;$\mathbb R^d$&#20013;&#19981;&#26159;&#23494;&#38598;&#30340;&#65292;&#20219;&#20309;&#24418;&#21516;$W$&#32500;&#29699;&#38754;&#30340;$\mathbb R^d$&#23376;&#38598;&#21253;&#21547;&#19981;&#21487;&#23398;&#20064;&#30446;&#26631;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#22312;&#20960;&#20046;&#20445;&#35777;&#20108;&#21442;&#25968;&#23398;&#20064;&#30340;&#20027;&#35201;&#23450;&#29702;&#20013;&#65292;&#25152;&#36848;&#27169;&#22411;&#26159;&#36890;&#36807;&#23618;&#27425;&#36807;&#31243;&#26500;&#24314;&#30340;&#65292;&#22240;&#27492;&#19981;&#33021;&#29992;&#21333;&#20010;&#21021;&#31561;&#20989;&#25968;&#34920;&#36798;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#38480;&#21046;&#22312;&#26412;&#36136;&#19978;&#26159;&#24517;&#35201;&#30340;&#65292;&#22240;&#20026;&#36825;&#31181;&#21487;&#23398;&#20064;&#24615;&#23545;&#20110;&#35768;&#22810;&#21021;&#31561;&#20989;&#25968;&#31867;&#30340;&#21487;&#23398;&#20064;&#24615;&#26159;&#34987;&#25490;&#38500;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17089v1 Announce Type: cross  Abstract: We explore the theoretical possibility of learning $d$-dimensional targets with $W$-parameter models by gradient flow (GF) when $W&lt;d$ there is necessarily a large subset of GF-non-learnable targets. In particular, the set of learnable targets is not dense in $\mathbb R^d$, and any subset of $\mathbb R^d$ homeomorphic to the $W$-dimensional sphere contains non-learnable targets. Finally, we observe that the model in our main theorem on almost guaranteed two-parameter learning is constructed using a hierarchical procedure and as a result is not expressible by a single elementary function. We show that this limitation is essential in the sense that such learnability can be ruled out for a large class of elementary functions.
&lt;/p&gt;</description></item><item><title>K&#25240;&#20132;&#21449;&#39564;&#35777;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#26159;&#24120;&#29992;&#30340;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#20294;&#22312;&#22788;&#29702;&#23567;&#26679;&#26412;&#25968;&#25454;&#38598;&#21644;&#24322;&#36136;&#25968;&#25454;&#28304;&#26102;&#23384;&#22312;&#22256;&#38590;&#12290;</title><link>http://arxiv.org/abs/2401.16407</link><description>&lt;p&gt;
K&#25240;&#20132;&#21449;&#39564;&#35777;&#26159;&#21542;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#22909;&#30340;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65311;
&lt;/p&gt;
&lt;p&gt;
Is K-fold cross validation the best model selection method for Machine Learning?. (arXiv:2401.16407v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16407
&lt;/p&gt;
&lt;p&gt;
K&#25240;&#20132;&#21449;&#39564;&#35777;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#26159;&#24120;&#29992;&#30340;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#20294;&#22312;&#22788;&#29702;&#23567;&#26679;&#26412;&#25968;&#25454;&#38598;&#21644;&#24322;&#36136;&#25968;&#25454;&#28304;&#26102;&#23384;&#22312;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20316;&#20026;&#19968;&#31181;&#33021;&#22815;&#32039;&#20945;&#34920;&#31034;&#22797;&#26434;&#27169;&#24335;&#30340;&#25216;&#26415;&#65292;&#20855;&#26377;&#26174;&#33879;&#30340;&#39044;&#27979;&#25512;&#29702;&#28508;&#21147;&#12290;K&#25240;&#20132;&#21449;&#39564;&#35777;&#65288;CV&#65289;&#26159;&#30830;&#23450;&#26426;&#22120;&#23398;&#20064;&#32467;&#26524;&#26159;&#21542;&#26159;&#38543;&#26426;&#29983;&#25104;&#30340;&#26368;&#24120;&#29992;&#26041;&#27861;&#65292;&#24182;&#32463;&#24120;&#20248;&#20110;&#20256;&#32479;&#30340;&#20551;&#35774;&#26816;&#39564;&#12290;&#36825;&#31181;&#25913;&#36827;&#21033;&#29992;&#20102;&#30452;&#25509;&#20174;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#20013;&#33719;&#24471;&#30340;&#24230;&#37327;&#65292;&#27604;&#22914;&#20934;&#30830;&#24615;&#65292;&#36825;&#20123;&#24230;&#37327;&#27809;&#26377;&#21442;&#25968;&#25551;&#36848;&#12290;&#20026;&#20102;&#22312;&#26426;&#22120;&#23398;&#20064;&#27969;&#31243;&#20013;&#36827;&#34892;&#39057;&#29575;&#20998;&#26512;&#65292;&#21487;&#20197;&#28155;&#21152;&#25490;&#21015;&#27979;&#35797;&#25110;&#26469;&#33258;&#25968;&#25454;&#20998;&#21306;&#65288;&#21363;&#25240;&#21472;&#65289;&#30340;&#31616;&#21333;&#32479;&#35745;&#37327;&#26469;&#20272;&#35745;&#32622;&#20449;&#21306;&#38388;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#26080;&#35770;&#26159;&#21442;&#25968;&#21270;&#36824;&#26159;&#38750;&#21442;&#25968;&#21270;&#27979;&#35797;&#37117;&#26080;&#27861;&#35299;&#20915;&#22260;&#32469;&#20998;&#21106;&#23567;&#26679;&#26412;&#25968;&#25454;&#38598;&#21644;&#26469;&#33258;&#24322;&#36136;&#25968;&#25454;&#28304;&#30340;&#23398;&#20064;&#22266;&#26377;&#38382;&#39064;&#12290;&#26426;&#22120;&#23398;&#20064;&#20005;&#37325;&#20381;&#36182;&#23398;&#20064;&#21442;&#25968;&#21644;&#25968;&#25454;&#22312;&#25240;&#21472;&#20013;&#30340;&#20998;&#24067;&#65292;&#36825;&#37325;&#26032;&#27010;&#25324;&#20102;&#29087;&#24713;&#30340;&#22256;&#38590;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
As a technique that can compactly represent complex patterns, machine learning has significant potential for predictive inference. K-fold cross-validation (CV) is the most common approach to ascertaining the likelihood that a machine learning outcome is generated by chance and frequently outperforms conventional hypothesis testing. This improvement uses measures directly obtained from machine learning classifications, such as accuracy, that do not have a parametric description. To approach a frequentist analysis within machine learning pipelines, a permutation test or simple statistics from data partitions (i.e. folds) can be added to estimate confidence intervals. Unfortunately, neither parametric nor non-parametric tests solve the inherent problems around partitioning small sample-size datasets and learning from heterogeneous data sources. The fact that machine learning strongly depends on the learning parameters and the distribution of data across folds recapitulates familiar diffic
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#19982;&#26368;&#26032;&#30340;&#20915;&#31574;&#29702;&#35770;&#27169;&#22411;&#30456;&#32467;&#21512;&#30340;&#40065;&#26834;&#20248;&#21270;&#20934;&#21017;&#65292;&#36890;&#36807;&#36825;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#20013;&#33719;&#24471;&#26377;&#31283;&#23450;&#24615;&#21644;&#20248;&#36234;&#24615;&#33021;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2401.15771</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#19982;&#25968;&#25454;&#39537;&#21160;&#40065;&#26834;&#20248;&#21270;&#30340;&#32467;&#21512;
&lt;/p&gt;
&lt;p&gt;
Bayesian Nonparametrics meets Data-Driven Robust Optimization. (arXiv:2401.15771v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15771
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#19982;&#26368;&#26032;&#30340;&#20915;&#31574;&#29702;&#35770;&#27169;&#22411;&#30456;&#32467;&#21512;&#30340;&#40065;&#26834;&#20248;&#21270;&#20934;&#21017;&#65292;&#36890;&#36807;&#36825;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#20013;&#33719;&#24471;&#26377;&#31283;&#23450;&#24615;&#21644;&#20248;&#36234;&#24615;&#33021;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#27169;&#22411;&#36890;&#24120;&#28041;&#21450;&#20248;&#21270;&#25968;&#25454;&#39537;&#21160;&#30340;&#39118;&#38505;&#20934;&#21017;&#12290;&#39118;&#38505;&#36890;&#24120;&#26159;&#26681;&#25454;&#32463;&#39564;&#25968;&#25454;&#20998;&#24067;&#35745;&#31639;&#30340;&#65292;&#20294;&#30001;&#20110;&#20998;&#24067;&#19981;&#30830;&#23450;&#24615;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#24615;&#33021;&#19981;&#31283;&#23450;&#21644;&#19981;&#22909;&#30340;&#26679;&#26412;&#22806;&#34920;&#29616;&#12290;&#22312;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#30340;&#31934;&#31070;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#40065;&#26834;&#20934;&#21017;&#65292;&#23558;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#65288;&#21363;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#65289;&#29702;&#35770;&#21644;&#26368;&#36817;&#30340;&#24179;&#28369;&#27169;&#31946;&#35268;&#36991;&#20559;&#22909;&#30340;&#20915;&#31574;&#29702;&#35770;&#27169;&#22411;&#30340;&#35265;&#35299;&#30456;&#32467;&#21512;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#24378;&#35843;&#20102;&#19982;&#26631;&#20934;&#27491;&#21017;&#21270;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#25216;&#26415;&#30340;&#26032;&#36830;&#25509;&#65292;&#20854;&#20013;&#21253;&#25324;&#23725;&#22238;&#24402;&#21644;&#22871;&#32034;&#22238;&#24402;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20174;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#40065;&#26834;&#20248;&#21270;&#36807;&#31243;&#22312;&#26377;&#38480;&#26679;&#26412;&#21644;&#28176;&#36817;&#32479;&#35745;&#20445;&#35777;&#26041;&#38754;&#30340;&#26377;&#21033;&#24615;&#23384;&#22312;&#12290;&#23545;&#20110;&#23454;&#38469;&#23454;&#26045;&#65292;&#25105;&#20204;&#25552;&#20986;&#24182;&#30740;&#31350;&#20102;&#22522;&#20110;&#20247;&#25152;&#21608;&#30693;&#30340;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#34920;&#31034;&#30340;&#21487;&#34892;&#36817;&#20284;&#20934;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;
Training machine learning and statistical models often involves optimizing a data-driven risk criterion. The risk is usually computed with respect to the empirical data distribution, but this may result in poor and unstable out-of-sample performance due to distributional uncertainty. In the spirit of distributionally robust optimization, we propose a novel robust criterion by combining insights from Bayesian nonparametric (i.e., Dirichlet Process) theory and recent decision-theoretic models of smooth ambiguity-averse preferences. First, we highlight novel connections with standard regularized empirical risk minimization techniques, among which Ridge and LASSO regressions. Then, we theoretically demonstrate the existence of favorable finite-sample and asymptotic statistical guarantees on the performance of the robust optimization procedure. For practical implementation, we propose and study tractable approximations of the criterion based on well-known Dirichlet Process representations. 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22235;&#20010;&#26032;&#30340;&#20960;&#20309;&#24230;&#37327;&#65292;&#21487;&#20197;&#27604;&#36739;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#22312;&#32771;&#34385;&#26597;&#35810;&#28857;&#21644;&#20840;&#23616;&#26368;&#20248;&#35299;&#30340;&#20960;&#20309;&#29305;&#24615;&#26102;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.01981</link><description>&lt;p&gt;
&#36229;&#36234;&#36951;&#25022;&#65306;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#20960;&#20309;&#24230;&#37327;
&lt;/p&gt;
&lt;p&gt;
Beyond Regrets: Geometric Metrics for Bayesian Optimization. (arXiv:2401.01981v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01981
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22235;&#20010;&#26032;&#30340;&#20960;&#20309;&#24230;&#37327;&#65292;&#21487;&#20197;&#27604;&#36739;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#22312;&#32771;&#34385;&#26597;&#35810;&#28857;&#21644;&#20840;&#23616;&#26368;&#20248;&#35299;&#30340;&#20960;&#20309;&#29305;&#24615;&#26102;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#26159;&#19968;&#31181;&#38024;&#23545;&#40657;&#30418;&#23376;&#30446;&#26631;&#20989;&#25968;&#30340;&#21407;&#21017;&#24615;&#20248;&#21270;&#31574;&#30053;&#12290;&#23427;&#22312;&#31185;&#23398;&#21457;&#29616;&#21644;&#23454;&#39564;&#35774;&#35745;&#31561;&#21508;&#31181;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#25928;&#26524;&#24471;&#21040;&#20102;&#35777;&#26126;&#12290;&#36890;&#24120;&#65292;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#24615;&#33021;&#26159;&#36890;&#36807;&#22522;&#20110;&#36951;&#25022;&#30340;&#24230;&#37327;&#26469;&#35780;&#20272;&#30340;&#65292;&#22914;&#30636;&#26102;&#36951;&#25022;&#12289;&#31616;&#21333;&#36951;&#25022;&#21644;&#32047;&#31215;&#36951;&#25022;&#12290;&#36825;&#20123;&#24230;&#37327;&#20165;&#20381;&#36182;&#20110;&#20989;&#25968;&#35780;&#20272;&#65292;&#22240;&#27492;&#23427;&#20204;&#19981;&#32771;&#34385;&#26597;&#35810;&#28857;&#21644;&#20840;&#23616;&#35299;&#20043;&#38388;&#30340;&#20960;&#20309;&#20851;&#31995;&#65292;&#20063;&#19981;&#32771;&#34385;&#26597;&#35810;&#28857;&#26412;&#36523;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#23427;&#20204;&#19981;&#33021;&#21306;&#20998;&#26159;&#21542;&#25104;&#21151;&#25214;&#21040;&#20102;&#22810;&#20010;&#20840;&#23616;&#35299;&#12290;&#27492;&#22806;&#65292;&#23427;&#20204;&#20063;&#19981;&#33021;&#35780;&#20272;&#36125;&#21494;&#26031;&#20248;&#21270;&#22312;&#32473;&#23450;&#25628;&#32034;&#31354;&#38388;&#20013;&#21033;&#29992;&#21644;&#25506;&#32034;&#30340;&#33021;&#21147;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22235;&#20010;&#26032;&#30340;&#20960;&#20309;&#24230;&#37327;&#65292;&#21363;&#31934;&#30830;&#24230;&#12289;&#21484;&#22238;&#29575;&#12289;&#24179;&#22343;&#24230;&#21644;&#24179;&#22343;&#36317;&#31163;&#12290;&#36825;&#20123;&#24230;&#37327;&#20351;&#25105;&#20204;&#33021;&#22815;&#27604;&#36739;&#32771;&#34385;&#26597;&#35810;&#28857;&#21644;&#20840;&#23616;&#26368;&#20248;&#35299;&#30340;&#20960;&#20309;&#29305;&#24615;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimization is a principled optimization strategy for a black-box objective function. It shows its effectiveness in a wide variety of real-world applications such as scientific discovery and experimental design. In general, the performance of Bayesian optimization is assessed by regret-based metrics such as instantaneous, simple, and cumulative regrets. These metrics only rely on function evaluations, so that they do not consider geometric relationships between query points and global solutions, or query points themselves. Notably, they cannot discriminate if multiple global solutions are successfully found. Moreover, they do not evaluate Bayesian optimization's abilities to exploit and explore a search space given. To tackle these issues, we propose four new geometric metrics, i.e., precision, recall, average degree, and average distance. These metrics allow us to compare Bayesian optimization algorithms considering the geometry of both query points and global optima, or que
&lt;/p&gt;</description></item><item><title>TomOpt&#26159;&#19968;&#20010;&#36719;&#20214;&#21253;&#65292;&#29992;&#20110;&#20248;&#21270;&#23431;&#23449;&#23556;&#32447;&#956;&#23376;&#26029;&#23618;&#25195;&#25551;&#35774;&#35745;&#20013;&#30340;&#24494;&#31890;&#25506;&#27979;&#22120;&#30340;&#20960;&#20309;&#24067;&#23616;&#21644;&#35268;&#26684;&#12290;&#23427;&#21033;&#29992;&#21487;&#24494;&#20998;&#32534;&#31243;&#27169;&#25311;&#956;&#23376;&#19982;&#25506;&#27979;&#22120;&#21644;&#25195;&#25551;&#20307;&#31215;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#24182;&#36890;&#36807;&#25439;&#22833;&#26368;&#23567;&#21270;&#30340;&#20248;&#21270;&#24490;&#29615;&#36827;&#34892;&#25512;&#26029;&#24863;&#30693;&#20248;&#21270;&#12290;</title><link>http://arxiv.org/abs/2309.14027</link><description>&lt;p&gt;
TomOpt&#65306;&#22312;&#23431;&#23449;&#23556;&#32447;&#956;&#23376;&#26029;&#23618;&#25195;&#25551;&#20013;&#38754;&#21521;&#20219;&#21153;&#21644;&#32422;&#26463;&#24863;&#30693;&#35774;&#35745;&#30340;&#24494;&#31890;&#25506;&#27979;&#22120;&#30340;&#24046;&#20998;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
TomOpt: Differential optimisation for task- and constraint-aware design of particle detectors in the context of muon tomography. (arXiv:2309.14027v1 [physics.ins-det])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14027
&lt;/p&gt;
&lt;p&gt;
TomOpt&#26159;&#19968;&#20010;&#36719;&#20214;&#21253;&#65292;&#29992;&#20110;&#20248;&#21270;&#23431;&#23449;&#23556;&#32447;&#956;&#23376;&#26029;&#23618;&#25195;&#25551;&#35774;&#35745;&#20013;&#30340;&#24494;&#31890;&#25506;&#27979;&#22120;&#30340;&#20960;&#20309;&#24067;&#23616;&#21644;&#35268;&#26684;&#12290;&#23427;&#21033;&#29992;&#21487;&#24494;&#20998;&#32534;&#31243;&#27169;&#25311;&#956;&#23376;&#19982;&#25506;&#27979;&#22120;&#21644;&#25195;&#25551;&#20307;&#31215;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#24182;&#36890;&#36807;&#25439;&#22833;&#26368;&#23567;&#21270;&#30340;&#20248;&#21270;&#24490;&#29615;&#36827;&#34892;&#25512;&#26029;&#24863;&#30693;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#20010;&#21517;&#20026;TomOpt&#30340;&#36719;&#20214;&#21253;&#65292;&#29992;&#20110;&#20248;&#21270;&#20960;&#20309;&#24067;&#23616;&#21644;&#25506;&#27979;&#22120;&#35268;&#26684;&#65292;&#20197;&#36827;&#34892;&#23431;&#23449;&#23556;&#32447;&#956;&#23376;&#30340;&#25955;&#23556;&#26029;&#23618;&#25195;&#25551;&#35774;&#35745;&#12290;&#35813;&#36719;&#20214;&#21033;&#29992;&#21487;&#24494;&#20998;&#32534;&#31243;&#26469;&#27169;&#25311;&#956;&#23376;&#19982;&#25506;&#27979;&#22120;&#21644;&#25195;&#25551;&#20307;&#31215;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#25512;&#26029;&#20307;&#31215;&#23646;&#24615;&#65292;&#24182;&#36827;&#34892;&#25439;&#22833;&#26368;&#23567;&#21270;&#30340;&#20248;&#21270;&#24490;&#29615;&#12290;&#36890;&#36807;&#36825;&#26679;&#20570;&#65292;&#25105;&#20204;&#39318;&#27425;&#28436;&#31034;&#20102;&#31890;&#23376;&#29289;&#29702;&#20202;&#22120;&#30340;&#31471;&#21040;&#31471;&#21487;&#24494;&#20998;&#21644;&#25512;&#26029;&#24863;&#30693;&#20248;&#21270;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#35813;&#36719;&#20214;&#22312;&#30456;&#20851;&#22522;&#20934;&#22330;&#26223;&#19978;&#30340;&#24615;&#33021;&#65292;&#24182;&#35752;&#35770;&#20102;&#20854;&#28508;&#22312;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We describe a software package, TomOpt, developed to optimise the geometrical layout and specifications of detectors designed for tomography by scattering of cosmic-ray muons. The software exploits differentiable programming for the modeling of muon interactions with detectors and scanned volumes, the inference of volume properties, and the optimisation cycle performing the loss minimisation. In doing so, we provide the first demonstration of end-to-end-differentiable and inference-aware optimisation of particle physics instruments. We study the performance of the software on a relevant benchmark scenarios and discuss its potential applications.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#37327;&#21270;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;PAC&#31070;&#32463;&#39044;&#27979;&#38598;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#22810;&#31181;&#35821;&#35328;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#30456;&#27604;&#20110;&#26631;&#20934;&#22522;&#20934;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24179;&#22343;&#25552;&#39640;&#20102;63&#65285;&#30340;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.09254</link><description>&lt;p&gt;
&#29992;&#20110;&#37327;&#21270;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;PAC&#31070;&#32463;&#39044;&#27979;&#38598;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
PAC Neural Prediction Set Learning to Quantify the Uncertainty of Generative Language Models. (arXiv:2307.09254v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09254
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#37327;&#21270;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;PAC&#31070;&#32463;&#39044;&#27979;&#38598;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#22810;&#31181;&#35821;&#35328;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#30456;&#27604;&#20110;&#26631;&#20934;&#22522;&#20934;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24179;&#22343;&#25552;&#39640;&#20102;63&#65285;&#30340;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#21644;&#37327;&#21270;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#26159;&#22686;&#24378;&#27169;&#22411;&#21487;&#20449;&#24230;&#30340;&#20851;&#38190;&#20219;&#21153;&#12290;&#30001;&#20110;&#23545;&#29983;&#25104;&#34394;&#26500;&#20107;&#23454;&#30340;&#25285;&#24551;&#65292;&#26368;&#36817;&#20852;&#36215;&#30340;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#65288;GLM&#65289;&#29305;&#21035;&#24378;&#35843;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#38656;&#27714;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#31070;&#32463;&#39044;&#27979;&#38598;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#20197;&#21487;&#33021;&#36817;&#20284;&#27491;&#30830;&#65288;PAC&#65289;&#30340;&#26041;&#24335;&#37327;&#21270;GLM&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#19982;&#29616;&#26377;&#30340;&#39044;&#27979;&#38598;&#27169;&#22411;&#36890;&#36807;&#26631;&#37327;&#20540;&#21442;&#25968;&#21270;&#19981;&#21516;&#65292;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#39044;&#27979;&#38598;&#65292;&#23454;&#29616;&#26356;&#31934;&#30830;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#20294;&#20173;&#28385;&#36275;PAC&#20445;&#35777;&#12290;&#36890;&#36807;&#22312;&#22235;&#31181;&#31867;&#22411;&#30340;&#35821;&#35328;&#25968;&#25454;&#38598;&#21644;&#20845;&#31181;&#31867;&#22411;&#30340;&#27169;&#22411;&#19978;&#23637;&#31034;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#30456;&#27604;&#26631;&#20934;&#22522;&#20934;&#26041;&#27861;&#24179;&#22343;&#25552;&#39640;&#20102;63&#65285;&#30340;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Uncertainty learning and quantification of models are crucial tasks to enhance the trustworthiness of the models. Importantly, the recent surge of generative language models (GLMs) emphasizes the need for reliable uncertainty quantification due to the concerns on generating hallucinated facts. In this paper, we propose to learn neural prediction set models that comes with the probably approximately correct (PAC) guarantee for quantifying the uncertainty of GLMs. Unlike existing prediction set models, which are parameterized by a scalar value, we propose to parameterize prediction sets via neural networks, which achieves more precise uncertainty quantification but still satisfies the PAC guarantee. We demonstrate the efficacy of our method on four types of language datasets and six types of models by showing that our method improves the quantified uncertainty by $63\%$ on average, compared to a standard baseline method.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#22810;&#32423;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#23558;&#32676;&#20307;&#25968;&#25454;&#35270;&#20026;&#25972;&#20307;&#26469;&#32771;&#34385;&#65292;&#24182;&#23558;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#21644;&#29289;&#29702;&#30693;&#35782;&#32534;&#30721;&#21040;&#27169;&#22411;&#20013;&#65292;&#20197;&#23454;&#29616;&#28304;&#20301;&#32622;&#30340;&#23450;&#20301;&#12290;</title><link>http://arxiv.org/abs/2305.08657</link><description>&lt;p&gt;
&#23558;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#32534;&#30721;&#21040;&#22810;&#32423;&#27169;&#22411;&#20013;&#29992;&#20110;&#28304;&#20301;&#32622;&#30340;&#23450;&#20301;&#12290;
&lt;/p&gt;
&lt;p&gt;
Encoding Domain Expertise into Multilevel Models for Source Location. (arXiv:2305.08657v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08657
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#22810;&#32423;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#23558;&#32676;&#20307;&#25968;&#25454;&#35270;&#20026;&#25972;&#20307;&#26469;&#32771;&#34385;&#65292;&#24182;&#23558;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#21644;&#29289;&#29702;&#30693;&#35782;&#32534;&#30721;&#21040;&#27169;&#22411;&#20013;&#65292;&#20197;&#23454;&#29616;&#28304;&#20301;&#32622;&#30340;&#23450;&#20301;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#24037;&#19994;&#24212;&#29992;&#20013;&#65292;&#32676;&#20307;&#25968;&#25454;&#26159;&#26222;&#36941;&#23384;&#22312;&#30340;&#12290;&#26426;&#22120;&#21644;&#22522;&#30784;&#35774;&#26045;&#36234;&#26469;&#36234;&#22810;&#22320;&#37197;&#22791;&#20102;&#20256;&#24863;&#31995;&#32479;&#65292;&#21457;&#20986;&#20855;&#26377;&#22797;&#26434;&#30456;&#20114;&#20381;&#36182;&#20851;&#31995;&#30340;&#36965;&#27979;&#25968;&#25454;&#27969;&#12290;&#23454;&#38469;&#19978;&#65292;&#25968;&#25454;&#20013;&#24515;&#30340;&#30417;&#27979;&#31243;&#24207;&#20542;&#21521;&#20110;&#23558;&#36825;&#20123;&#36164;&#20135;&#65288;&#20197;&#21450;&#21508;&#33258;&#30340;&#27169;&#22411;&#65289;&#35270;&#20026;&#19981;&#21516;&#30340;&#23454;&#20307; - &#29420;&#31435;&#36816;&#34892;&#24182;&#19982;&#29420;&#31435;&#25968;&#25454;&#30456;&#20851;&#32852;&#12290;&#30456;&#21453;&#65292;&#36825;&#39033;&#24037;&#20316;&#25429;&#25417;&#20102;&#19968;&#32452;&#31995;&#32479;&#27169;&#22411;&#20043;&#38388;&#30340;&#32479;&#35745;&#30456;&#20851;&#24615;&#21644;&#30456;&#20114;&#20381;&#36182;&#20851;&#31995;&#12290;&#21033;&#29992;&#36125;&#21494;&#26031;&#22810;&#32423;&#26041;&#27861;&#65292;&#25968;&#25454;&#30340;&#20215;&#20540;&#21487;&#20197;&#24471;&#21040;&#25193;&#23637;&#65292;&#22240;&#20026;&#21487;&#20197;&#23558;&#20154;&#32676;&#20316;&#20026;&#19968;&#20010;&#25972;&#20307;&#26469;&#32771;&#34385;&#65292;&#32780;&#19981;&#26159;&#20316;&#20026;&#32452;&#25104;&#37096;&#20998;&#12290;&#26368;&#26377;&#36259;&#30340;&#26159;&#65292;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#21644;&#22522;&#30784;&#29289;&#29702;&#30693;&#35782;&#21487;&#20197;&#22312;&#31995;&#32479;&#12289;&#23376;&#32452;&#25110;&#20154;&#32676;&#27700;&#24179;&#19978;&#32534;&#30721;&#21040;&#27169;&#22411;&#20013;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#22768;&#21457;&#23556;&#65288;&#21040;&#36798;&#26102;&#38388;&#65289;&#26144;&#23556;&#28304;&#20301;&#32622;&#30340;&#31034;&#20363;&#65292;&#20197;&#35828;&#26126;&#22810;&#32423;&#27169;&#22411;&#22914;&#20309;&#33258;&#28982;&#22320;&#36866;&#29992;&#20110;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data from populations of systems are prevalent in many industrial applications. Machines and infrastructure are increasingly instrumented with sensing systems, emitting streams of telemetry data with complex interdependencies. In practice, data-centric monitoring procedures tend to consider these assets (and respective models) as distinct -- operating in isolation and associated with independent data. In contrast, this work captures the statistical correlations and interdependencies between models of a group of systems. Utilising a Bayesian multilevel approach, the value of data can be extended, since the population can be considered as a whole, rather than constituent parts. Most interestingly, domain expertise and knowledge of the underlying physics can be encoded in the model at the system, subgroup, or population level. We present an example of acoustic emission (time-of-arrival) mapping for source location, to illustrate how multilevel models naturally lend themselves to represent
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20851;&#20110;&#26680;&#23725;&#22238;&#24402;&#30340;&#21327;&#21464;&#37327;&#36716;&#31227;&#31574;&#30053;&#65292;&#36890;&#36807;&#20351;&#29992;&#20266;&#26631;&#31614;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#65292;&#33021;&#22815;&#36866;&#24212;&#19981;&#21516;&#29305;&#24449;&#20998;&#24067;&#19979;&#30340;&#23398;&#20064;&#65292;&#23454;&#29616;&#22343;&#26041;&#35823;&#24046;&#26368;&#23567;&#21270;&#12290;</title><link>http://arxiv.org/abs/2302.10160</link><description>&lt;p&gt;
&#26680;&#23725;&#22238;&#24402;&#19979;&#20266;&#26631;&#31614;&#30340;&#21327;&#21464;&#37327;&#36716;&#31227;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Pseudo-Labeling for Kernel Ridge Regression under Covariate Shift. (arXiv:2302.10160v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.10160
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20851;&#20110;&#26680;&#23725;&#22238;&#24402;&#30340;&#21327;&#21464;&#37327;&#36716;&#31227;&#31574;&#30053;&#65292;&#36890;&#36807;&#20351;&#29992;&#20266;&#26631;&#31614;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#65292;&#33021;&#22815;&#36866;&#24212;&#19981;&#21516;&#29305;&#24449;&#20998;&#24067;&#19979;&#30340;&#23398;&#20064;&#65292;&#23454;&#29616;&#22343;&#26041;&#35823;&#24046;&#26368;&#23567;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#24182;&#20998;&#26512;&#20102;&#19968;&#31181;&#22522;&#20110;&#21327;&#21464;&#37327;&#36716;&#31227;&#30340;&#26680;&#23725;&#22238;&#24402;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#22312;&#30446;&#26631;&#20998;&#24067;&#19978;&#23398;&#20064;&#19968;&#20010;&#22343;&#26041;&#35823;&#24046;&#26368;&#23567;&#30340;&#22238;&#24402;&#20989;&#25968;&#65292;&#22522;&#20110;&#20174;&#30446;&#26631;&#20998;&#24067;&#37319;&#26679;&#30340;&#26410;&#26631;&#35760;&#25968;&#25454;&#21644;&#21487;&#33021;&#20855;&#26377;&#19981;&#21516;&#29305;&#24449;&#20998;&#24067;&#30340;&#24050;&#26631;&#35760;&#25968;&#25454;&#12290;&#25105;&#20204;&#23558;&#24050;&#26631;&#35760;&#25968;&#25454;&#20998;&#25104;&#20004;&#20010;&#23376;&#38598;&#65292;&#24182;&#20998;&#21035;&#36827;&#34892;&#26680;&#23725;&#22238;&#24402;&#65292;&#20197;&#33719;&#24471;&#20505;&#36873;&#27169;&#22411;&#38598;&#21512;&#21644;&#19968;&#20010;&#22635;&#20805;&#27169;&#22411;&#12290;&#25105;&#20204;&#20351;&#29992;&#21518;&#32773;&#22635;&#20805;&#32570;&#22833;&#30340;&#26631;&#31614;&#65292;&#28982;&#21518;&#30456;&#24212;&#22320;&#36873;&#25321;&#26368;&#20339;&#30340;&#20505;&#36873;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#38750;&#28176;&#36817;&#24615;&#36807;&#37327;&#39118;&#38505;&#30028;&#34920;&#26126;&#65292;&#22312;&#30456;&#24403;&#19968;&#33324;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#33021;&#22815;&#36866;&#24212;&#30446;&#26631;&#20998;&#24067;&#20197;&#21450;&#21327;&#21464;&#37327;&#36716;&#31227;&#30340;&#32467;&#26500;&#12290;&#23427;&#33021;&#22815;&#23454;&#29616;&#28176;&#36817;&#27491;&#24577;&#35823;&#24046;&#29575;&#30452;&#21040;&#23545;&#25968;&#22240;&#23376;&#30340;&#26368;&#23567;&#26497;&#38480;&#20248;&#21270;&#12290;&#22312;&#27169;&#22411;&#36873;&#25321;&#20013;&#20351;&#29992;&#20266;&#26631;&#31614;&#19981;&#20250;&#20135;&#29983;&#20027;&#35201;&#36127;&#38754;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop and analyze a principled approach to kernel ridge regression under covariate shift. The goal is to learn a regression function with small mean squared error over a target distribution, based on unlabeled data from there and labeled data that may have a different feature distribution. We propose to split the labeled data into two subsets and conduct kernel ridge regression on them separately to obtain a collection of candidate models and an imputation model. We use the latter to fill the missing labels and then select the best candidate model accordingly. Our non-asymptotic excess risk bounds show that in quite general scenarios, our estimator adapts to the structure of the target distribution as well as the covariate shift. It achieves the minimax optimal error rate up to a logarithmic factor. The use of pseudo-labels in model selection does not have major negative impacts.
&lt;/p&gt;</description></item></channel></rss>