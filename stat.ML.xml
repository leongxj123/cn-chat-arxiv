<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#23558;&#25299;&#25169;&#29305;&#24449;&#24341;&#20837;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#21487;&#20316;&#20026;&#22270;&#34920;&#31034;&#23398;&#20064;&#21644;&#20960;&#20309;&#28145;&#24230;&#23398;&#20064;&#30340;&#34917;&#20805;&#65292;&#32473;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#29615;&#22659;&#25552;&#20379;&#20102;&#33258;&#28982;&#36873;&#25321;&#12290;&#26412;&#25991;&#35752;&#35770;&#20102;&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#24320;&#25918;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#26410;&#26469;&#30340;&#30740;&#31350;&#26426;&#20250;&#12290;</title><link>https://arxiv.org/abs/2402.08871</link><description>&lt;p&gt;
&#20301;&#32622;&#35770;&#25991;&#65306;&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#25361;&#25112;&#19982;&#26426;&#36935;
&lt;/p&gt;
&lt;p&gt;
Position Paper: Challenges and Opportunities in Topological Deep Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08871
&lt;/p&gt;
&lt;p&gt;
&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#23558;&#25299;&#25169;&#29305;&#24449;&#24341;&#20837;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#21487;&#20316;&#20026;&#22270;&#34920;&#31034;&#23398;&#20064;&#21644;&#20960;&#20309;&#28145;&#24230;&#23398;&#20064;&#30340;&#34917;&#20805;&#65292;&#32473;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#29615;&#22659;&#25552;&#20379;&#20102;&#33258;&#28982;&#36873;&#25321;&#12290;&#26412;&#25991;&#35752;&#35770;&#20102;&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#24320;&#25918;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#26410;&#26469;&#30340;&#30740;&#31350;&#26426;&#20250;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#26159;&#19968;&#20010;&#24555;&#36895;&#21457;&#23637;&#30340;&#39046;&#22495;&#65292;&#23427;&#21033;&#29992;&#25299;&#25169;&#29305;&#24449;&#26469;&#29702;&#35299;&#21644;&#35774;&#35745;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#12290;&#26412;&#25991;&#35748;&#20026;&#65292;&#36890;&#36807;&#34701;&#20837;&#25299;&#25169;&#27010;&#24565;&#65292;&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#21487;&#20197;&#34917;&#20805;&#22270;&#34920;&#31034;&#23398;&#20064;&#21644;&#20960;&#20309;&#28145;&#24230;&#23398;&#20064;&#65292;&#24182;&#25104;&#20026;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#29615;&#22659;&#19979;&#30340;&#33258;&#28982;&#36873;&#25321;&#12290;&#20026;&#27492;&#65292;&#26412;&#25991;&#35752;&#35770;&#20102;&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#24320;&#25918;&#38382;&#39064;&#65292;&#28085;&#30422;&#20102;&#20174;&#23454;&#29992;&#30410;&#22788;&#21040;&#29702;&#35770;&#22522;&#30784;&#30340;&#21508;&#20010;&#26041;&#38754;&#12290;&#38024;&#23545;&#27599;&#20010;&#38382;&#39064;&#65292;&#23427;&#27010;&#36848;&#20102;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#26696;&#21644;&#26410;&#26469;&#30340;&#30740;&#31350;&#26426;&#20250;&#12290;&#21516;&#26102;&#65292;&#26412;&#25991;&#20063;&#26159;&#23545;&#31185;&#23398;&#30028;&#30340;&#36992;&#35831;&#65292;&#24076;&#26395;&#31215;&#26497;&#21442;&#19982;&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#30740;&#31350;&#65292;&#24320;&#21457;&#36825;&#20010;&#26032;&#20852;&#39046;&#22495;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08871v1 Announce Type: new Abstract: Topological deep learning (TDL) is a rapidly evolving field that uses topological features to understand and design deep learning models. This paper posits that TDL may complement graph representation learning and geometric deep learning by incorporating topological concepts, and can thus provide a natural choice for various machine learning settings. To this end, this paper discusses open problems in TDL, ranging from practical benefits to theoretical foundations. For each problem, it outlines potential solutions and future research opportunities. At the same time, this paper serves as an invitation to the scientific community to actively participate in TDL research to unlock the potential of this emerging field.
&lt;/p&gt;</description></item><item><title>&#12298;&#22312;&#22823;&#35268;&#27169;&#20154;&#24037;&#26234;&#33021;&#26102;&#20195;&#30340;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#12299;&#36825;&#31687;&#31435;&#22330;&#35770;&#25991;&#25506;&#35752;&#20102;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#22312;&#21508;&#31181;&#19981;&#21516;&#35774;&#32622;&#19979;&#30340;&#20248;&#21183;&#65292;&#24182;&#25351;&#20986;&#20102;&#19982;&#20043;&#30456;&#20851;&#30340;&#25361;&#25112;&#21644;&#26377;&#36259;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;&#26410;&#26469;&#30340;&#30740;&#31350;&#37325;&#28857;&#23558;&#25918;&#22312;&#22914;&#20309;&#23558;&#22823;&#35268;&#27169;&#22522;&#30784;&#27169;&#22411;&#19982;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#30456;&#32467;&#21512;&#65292;&#20197;&#21457;&#25381;&#23427;&#20204;&#30340;&#20840;&#37096;&#28508;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.00809</link><description>&lt;p&gt;
&#12298;&#22312;&#22823;&#35268;&#27169;&#20154;&#24037;&#26234;&#33021;&#26102;&#20195;&#30340;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#12299;&#30340;&#31435;&#22330;&#35770;&#25991;
&lt;/p&gt;
&lt;p&gt;
Position Paper: Bayesian Deep Learning in the Age of Large-Scale AI
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00809
&lt;/p&gt;
&lt;p&gt;
&#12298;&#22312;&#22823;&#35268;&#27169;&#20154;&#24037;&#26234;&#33021;&#26102;&#20195;&#30340;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#12299;&#36825;&#31687;&#31435;&#22330;&#35770;&#25991;&#25506;&#35752;&#20102;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#22312;&#21508;&#31181;&#19981;&#21516;&#35774;&#32622;&#19979;&#30340;&#20248;&#21183;&#65292;&#24182;&#25351;&#20986;&#20102;&#19982;&#20043;&#30456;&#20851;&#30340;&#25361;&#25112;&#21644;&#26377;&#36259;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;&#26410;&#26469;&#30340;&#30740;&#31350;&#37325;&#28857;&#23558;&#25918;&#22312;&#22914;&#20309;&#23558;&#22823;&#35268;&#27169;&#22522;&#30784;&#27169;&#22411;&#19982;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#30456;&#32467;&#21512;&#65292;&#20197;&#21457;&#25381;&#23427;&#20204;&#30340;&#20840;&#37096;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24403;&#21069;&#30340;&#28145;&#24230;&#23398;&#20064;&#30740;&#31350;&#39046;&#22495;&#20013;&#65292;&#20154;&#20204;&#20027;&#35201;&#20851;&#27880;&#22312;&#28041;&#21450;&#22823;&#35268;&#27169;&#22270;&#20687;&#21644;&#35821;&#35328;&#25968;&#25454;&#38598;&#30340;&#30417;&#30563;&#20219;&#21153;&#20013;&#23454;&#29616;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#28982;&#32780;&#65292;&#26356;&#24191;&#27867;&#30340;&#35270;&#35282;&#25581;&#31034;&#20102;&#35768;&#22810;&#34987;&#24573;&#35270;&#30340;&#24230;&#37327;&#26631;&#20934;&#12289;&#20219;&#21153;&#21644;&#25968;&#25454;&#31867;&#22411;&#65292;&#22914;&#19981;&#30830;&#23450;&#24615;&#12289;&#20027;&#21160;&#21644;&#25345;&#32493;&#23398;&#20064;&#20197;&#21450;&#31185;&#23398;&#25968;&#25454;&#65292;&#36825;&#20123;&#26041;&#38754;&#38656;&#35201;&#20851;&#27880;&#12290;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#65288;BDL&#65289;&#26159;&#19968;&#26465;&#26377;&#21069;&#26223;&#30340;&#36947;&#36335;&#65292;&#21487;&#20197;&#22312;&#36825;&#20123;&#19981;&#21516;&#30340;&#35774;&#32622;&#20013;&#25552;&#20379;&#20248;&#21183;&#12290;&#26412;&#25991;&#35748;&#20026;BDL&#21487;&#20197;&#25552;&#21319;&#28145;&#24230;&#23398;&#20064;&#30340;&#33021;&#21147;&#12290;&#23427;&#37325;&#26032;&#23457;&#35270;&#20102;BDL&#30340;&#20248;&#21183;&#12289;&#25215;&#35748;&#20102;&#29616;&#26377;&#30340;&#25361;&#25112;&#65292;&#24182;&#37325;&#28857;&#20171;&#32461;&#20102;&#19968;&#20123;&#26088;&#22312;&#35299;&#20915;&#36825;&#20123;&#38556;&#30861;&#30340;&#26377;&#36259;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;&#23637;&#26395;&#26410;&#26469;&#65292;&#35752;&#35770;&#38598;&#20013;&#22312;&#21487;&#33021;&#30340;&#26041;&#24335;&#19978;&#65292;&#23558;&#22823;&#35268;&#27169;&#22522;&#30784;&#27169;&#22411;&#19982;BDL&#30456;&#32467;&#21512;&#65292;&#20197;&#20805;&#20998;&#21457;&#25381;&#23427;&#20204;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the current landscape of deep learning research, there is a predominant emphasis on achieving high predictive accuracy in supervised tasks involving large image and language datasets. However, a broader perspective reveals a multitude of overlooked metrics, tasks, and data types, such as uncertainty, active and continual learning, and scientific data, that demand attention. Bayesian deep learning (BDL) constitutes a promising avenue, offering advantages across these diverse settings. This paper posits that BDL can elevate the capabilities of deep learning. It revisits the strengths of BDL, acknowledges existing challenges, and highlights some exciting research avenues aimed at addressing these obstacles. Looking ahead, the discussion focuses on possible ways to combine large-scale foundation models with BDL to unlock their full potential.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#38543;&#26426;&#26862;&#26519;&#27169;&#22411;&#30340;&#29305;&#24449;&#31354;&#38388;&#20013;&#30340;&#37051;&#36817;&#24615;&#26469;&#35299;&#37322;&#27169;&#22411;&#39044;&#27979;&#30340;&#26041;&#27861;&#65292;&#20026;&#27169;&#22411;&#39044;&#27979;&#25552;&#20379;&#20102;&#23616;&#37096;&#30340;&#35299;&#37322;&#24615;&#65292;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#36741;&#30456;&#25104;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#22312;&#20538;&#21048;&#23450;&#20215;&#27169;&#22411;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.12428</link><description>&lt;p&gt;
&#23454;&#29616;&#38543;&#26426;&#26862;&#26519;&#30340;&#23616;&#37096;&#21487;&#35299;&#37322;&#24615;&#22686;&#24378;&#65306;&#22522;&#20110;&#37051;&#36817;&#24615;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Towards Enhanced Local Explainability of Random Forests: a Proximity-Based Approach. (arXiv:2310.12428v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12428
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#38543;&#26426;&#26862;&#26519;&#27169;&#22411;&#30340;&#29305;&#24449;&#31354;&#38388;&#20013;&#30340;&#37051;&#36817;&#24615;&#26469;&#35299;&#37322;&#27169;&#22411;&#39044;&#27979;&#30340;&#26041;&#27861;&#65292;&#20026;&#27169;&#22411;&#39044;&#27979;&#25552;&#20379;&#20102;&#23616;&#37096;&#30340;&#35299;&#37322;&#24615;&#65292;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#36741;&#30456;&#25104;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#22312;&#20538;&#21048;&#23450;&#20215;&#27169;&#22411;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#35299;&#37322;&#38543;&#26426;&#26862;&#26519;&#65288;RF&#65289;&#27169;&#22411;&#30340;&#26679;&#26412;&#22806;&#24615;&#33021;&#65292;&#21033;&#29992;&#20102;&#20219;&#20309;RF&#37117;&#21487;&#20197;&#34987;&#34920;&#36848;&#20026;&#33258;&#36866;&#24212;&#21152;&#26435;K&#26368;&#36817;&#37051;&#65288;KNN&#65289;&#27169;&#22411;&#30340;&#20107;&#23454;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#21033;&#29992;RF&#22312;&#29305;&#24449;&#31354;&#38388;&#20013;&#23398;&#21040;&#30340;&#28857;&#20043;&#38388;&#30340;&#37051;&#36817;&#24615;&#65292;&#23558;&#38543;&#26426;&#26862;&#26519;&#30340;&#39044;&#27979;&#37325;&#20889;&#20026;&#35757;&#32451;&#25968;&#25454;&#28857;&#30446;&#26631;&#26631;&#31614;&#30340;&#21152;&#26435;&#24179;&#22343;&#20540;&#12290;&#36825;&#31181;&#32447;&#24615;&#24615;&#36136;&#26377;&#21161;&#20110;&#22312;&#35757;&#32451;&#38598;&#35266;&#27979;&#20013;&#20026;&#20219;&#20309;&#27169;&#22411;&#39044;&#27979;&#29983;&#25104;&#23646;&#24615;&#65292;&#20174;&#32780;&#20026;RF&#39044;&#27979;&#25552;&#20379;&#20102;&#23616;&#37096;&#30340;&#35299;&#37322;&#24615;&#65292;&#34917;&#20805;&#20102;SHAP&#31561;&#24050;&#26377;&#26041;&#27861;&#65292;&#36825;&#20123;&#26041;&#27861;&#21017;&#20026;&#29305;&#24449;&#31354;&#38388;&#32500;&#24230;&#19978;&#30340;&#27169;&#22411;&#39044;&#27979;&#29983;&#25104;&#23646;&#24615;&#12290;&#25105;&#20204;&#22312;&#35757;&#32451;&#20110;&#32654;&#22269;&#20844;&#21496;&#20538;&#21048;&#20132;&#26131;&#25968;&#25454;&#30340;&#20538;&#21048;&#23450;&#20215;&#27169;&#22411;&#20013;&#28436;&#31034;&#20102;&#36825;&#31181;&#26041;&#27861;&#65292;&#24182;&#23558;&#20854;&#19982;&#21508;&#31181;&#29616;&#26377;&#30340;&#27169;&#22411;&#35299;&#37322;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
We initiate a novel approach to explain the out of sample performance of random forest (RF) models by exploiting the fact that any RF can be formulated as an adaptive weighted K nearest-neighbors model. Specifically, we use the proximity between points in the feature space learned by the RF to re-write random forest predictions exactly as a weighted average of the target labels of training data points. This linearity facilitates a local notion of explainability of RF predictions that generates attributions for any model prediction across observations in the training set, and thereby complements established methods like SHAP, which instead generates attributions for a model prediction across dimensions of the feature space. We demonstrate this approach in the context of a bond pricing model trained on US corporate bond trades, and compare our approach to various existing approaches to model explainability.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#26410;&#30693;&#20855;&#26377;&#28508;&#22312;&#29366;&#24577;&#31995;&#32479;&#30340;&#23398;&#20064;&#20248;&#21270;&#25511;&#21046;&#26041;&#27861;&#65292;&#24182;&#32473;&#20986;&#20102;&#27010;&#29575;&#24615;&#33021;&#20445;&#35777;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#39564;&#35777;&#20219;&#24847;&#25511;&#21046;&#24459;&#24615;&#33021;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2303.17963</link><description>&lt;p&gt;
&#38754;&#21521;&#26410;&#30693;&#20855;&#26377;&#28508;&#22312;&#29366;&#24577;&#31995;&#32479;&#30340;&#23398;&#20064;&#20248;&#21270;&#25511;&#21046;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Learning-Based Optimal Control with Performance Guarantees for Unknown Systems with Latent States. (arXiv:2303.17963v1 [eess.SY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.17963
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#26410;&#30693;&#20855;&#26377;&#28508;&#22312;&#29366;&#24577;&#31995;&#32479;&#30340;&#23398;&#20064;&#20248;&#21270;&#25511;&#21046;&#26041;&#27861;&#65292;&#24182;&#32473;&#20986;&#20102;&#27010;&#29575;&#24615;&#33021;&#20445;&#35777;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#39564;&#35777;&#20219;&#24847;&#25511;&#21046;&#24459;&#24615;&#33021;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#25511;&#21046;&#24037;&#31243;&#26041;&#27861;&#24212;&#29992;&#20110;&#36234;&#26469;&#36234;&#22797;&#26434;&#30340;&#31995;&#32479;&#65292;&#25968;&#25454;&#39537;&#21160;&#30340;&#31995;&#32479;&#36776;&#35782;&#26041;&#27861;&#25104;&#20026;&#29289;&#29702;&#24314;&#27169;&#30340;&#26377;&#24076;&#26395;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#36825;&#20123;&#26041;&#27861;&#20381;&#36182;&#20110;&#29366;&#24577;&#27979;&#37327;&#30340;&#21487;&#29992;&#24615;&#65292;&#32780;&#22797;&#26434;&#31995;&#32479;&#30340;&#29366;&#24577;&#36890;&#24120;&#19981;&#26159;&#30452;&#25509;&#21487;&#27979;&#37327;&#30340;&#12290;&#22240;&#27492;&#65292;&#21487;&#33021;&#38656;&#35201;&#21516;&#26102;&#20272;&#35745;&#21160;&#21147;&#23398;&#21644;&#28508;&#22312;&#29366;&#24577;&#65292;&#20174;&#32780;&#26356;&#21152;&#20855;&#26377;&#25361;&#25112;&#24615;&#22320;&#35774;&#35745;&#20855;&#26377;&#24615;&#33021;&#20445;&#35777;&#30340;&#25511;&#21046;&#22120;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#35745;&#31639;&#20855;&#26377;&#28508;&#22312;&#29366;&#24577;&#30340;&#26410;&#30693;&#38750;&#32447;&#24615;&#31995;&#32479;&#30340;&#26368;&#20248;&#36755;&#20837;&#36712;&#36857;&#12290;&#23545;&#32467;&#26524;&#36755;&#20837;&#36712;&#36857;&#36827;&#34892;&#20102;&#27010;&#29575;&#24615;&#33021;&#20445;&#35777;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#39564;&#35777;&#20219;&#24847;&#25511;&#21046;&#24459;&#24615;&#33021;&#30340;&#26041;&#27861;&#12290;&#26412;&#25991;&#22312;&#25968;&#20540;&#27169;&#25311;&#20013;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
As control engineering methods are applied to increasingly complex systems, data-driven approaches for system identification appear as a promising alternative to physics-based modeling. While many of these approaches rely on the availability of state measurements, the states of a complex system are often not directly measurable. It may then be necessary to jointly estimate the dynamics and a latent state, making it considerably more challenging to design controllers with performance guarantees. This paper proposes a novel method for the computation of an optimal input trajectory for unknown nonlinear systems with latent states. Probabilistic performance guarantees are derived for the resulting input trajectory, and an approach to validate the performance of arbitrary control laws is presented. The effectiveness of the proposed method is demonstrated in a numerical simulation.
&lt;/p&gt;</description></item></channel></rss>