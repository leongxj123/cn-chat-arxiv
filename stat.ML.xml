<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#36125;&#21494;&#26031;&#32852;&#21512;&#25512;&#26029;&#26041;&#27861;&#65292;&#22312;&#19981;&#21516;&#20013;&#24515;&#20998;&#21035;&#20998;&#26512;&#26412;&#22320;&#25968;&#25454;&#65292;&#24182;&#23558;&#32479;&#35745;&#25512;&#26029;&#32467;&#26524;&#32452;&#21512;&#36215;&#26469;&#65292;&#20197;&#35299;&#20915;&#26679;&#26412;&#37327;&#19981;&#36275;&#30340;&#38382;&#39064;&#65292;&#24182;&#20934;&#30830;&#20272;&#35745;&#22238;&#24402;&#27169;&#22411;&#30340;&#21442;&#25968;&#12290;</title><link>https://arxiv.org/abs/2402.02898</link><description>&lt;p&gt;
&#20855;&#26377;&#24322;&#36136;&#22810;&#20013;&#24515;&#20154;&#32676;&#30340;&#22238;&#24402;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#32852;&#21512;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Bayesian Federated Inference for regression models with heterogeneous multi-center populations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02898
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#36125;&#21494;&#26031;&#32852;&#21512;&#25512;&#26029;&#26041;&#27861;&#65292;&#22312;&#19981;&#21516;&#20013;&#24515;&#20998;&#21035;&#20998;&#26512;&#26412;&#22320;&#25968;&#25454;&#65292;&#24182;&#23558;&#32479;&#35745;&#25512;&#26029;&#32467;&#26524;&#32452;&#21512;&#36215;&#26469;&#65292;&#20197;&#35299;&#20915;&#26679;&#26412;&#37327;&#19981;&#36275;&#30340;&#38382;&#39064;&#65292;&#24182;&#20934;&#30830;&#20272;&#35745;&#22238;&#24402;&#27169;&#22411;&#30340;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#20934;&#30830;&#20272;&#35745;&#22238;&#24402;&#27169;&#22411;&#30340;&#21442;&#25968;&#65292;&#26679;&#26412;&#37327;&#24517;&#39035;&#30456;&#23545;&#20110;&#21487;&#33021;&#30340;&#39044;&#27979;&#21464;&#37327;&#20010;&#25968;&#36275;&#22815;&#22823;&#12290;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#36890;&#24120;&#32570;&#20047;&#36275;&#22815;&#30340;&#25968;&#25454;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#27169;&#22411;&#36807;&#25311;&#21512;&#65292;&#24182;&#22240;&#27492;&#26080;&#27861;&#23545;&#26032;&#24739;&#32773;&#30340;&#32467;&#26524;&#36827;&#34892;&#21487;&#38752;&#39044;&#27979;&#12290;&#21512;&#24182;&#26469;&#33258;&#19981;&#21516;&#65288;&#21307;&#30103;&#65289;&#20013;&#24515;&#25910;&#38598;&#30340;&#25968;&#25454;&#21487;&#20197;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#65292;&#20294;&#36890;&#24120;&#30001;&#20110;&#38544;&#31169;&#27861;&#35268;&#25110;&#29289;&#27969;&#38382;&#39064;&#32780;&#19981;&#21487;&#34892;&#12290;&#21478;&#19968;&#31181;&#26041;&#27861;&#26159;&#20998;&#26512;&#21508;&#20010;&#20013;&#24515;&#30340;&#26412;&#22320;&#25968;&#25454;&#65292;&#28982;&#21518;&#20351;&#29992;&#36125;&#21494;&#26031;&#32852;&#21512;&#25512;&#26029;&#65288;BFI&#65289;&#26041;&#27861;&#23558;&#32479;&#35745;&#25512;&#26029;&#32467;&#26524;&#36827;&#34892;&#32452;&#21512;&#12290;&#36825;&#31181;&#26041;&#27861;&#30340;&#30446;&#26631;&#26159;&#20174;&#21508;&#20010;&#20013;&#24515;&#30340;&#25512;&#26029;&#32467;&#26524;&#20013;&#35745;&#31639;&#20986;&#22914;&#26524;&#23545;&#32452;&#21512;&#25968;&#25454;&#36827;&#34892;&#20102;&#32479;&#35745;&#20998;&#26512;&#21518;&#20250;&#24471;&#21040;&#20160;&#20040;&#32467;&#26524;&#12290;&#25105;&#20204;&#35299;&#37322;&#20102;&#21516;&#36136;&#21644;&#24322;&#36136;&#20013;&#24515;&#20154;&#32676;&#19979;&#30340;&#26041;&#27861;&#65292;&#24182;&#32473;&#20986;&#20102;&#30495;&#23454;&#30340;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
To estimate accurately the parameters of a regression model, the sample size must be large enough relative to the number of possible predictors for the model. In practice, sufficient data is often lacking, which can lead to overfitting of the model and, as a consequence, unreliable predictions of the outcome of new patients. Pooling data from different data sets collected in different (medical) centers would alleviate this problem, but is often not feasible due to privacy regulation or logistic problems. An alternative route would be to analyze the local data in the centers separately and combine the statistical inference results with the Bayesian Federated Inference (BFI) methodology. The aim of this approach is to compute from the inference results in separate centers what would have been found if the statistical analysis was performed on the combined data. We explain the methodology under homogeneity and heterogeneity across the populations in the separate centers, and give real lif
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#25991;&#31456;&#20171;&#32461;&#20102;&#29992;&#20110;&#28508;&#22312;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#20013;&#30340;Vecchia-Laplace&#36817;&#20284;&#27861;&#30340;&#36845;&#20195;&#26041;&#27861;&#65292;&#30456;&#27604;&#20110;&#20256;&#32479;&#30340;Cholesky&#20998;&#35299;&#26041;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#21152;&#24555;&#35745;&#31639;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.12000</link><description>&lt;p&gt;
Vecchia-Laplace&#36817;&#20284;&#27861;&#22312;&#28508;&#22312;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#20013;&#30340;&#36845;&#20195;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Iterative Methods for Vecchia-Laplace Approximations for Latent Gaussian Process Models. (arXiv:2310.12000v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12000
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#25991;&#31456;&#20171;&#32461;&#20102;&#29992;&#20110;&#28508;&#22312;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#20013;&#30340;Vecchia-Laplace&#36817;&#20284;&#27861;&#30340;&#36845;&#20195;&#26041;&#27861;&#65292;&#30456;&#27604;&#20110;&#20256;&#32479;&#30340;Cholesky&#20998;&#35299;&#26041;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#21152;&#24555;&#35745;&#31639;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28508;&#22312;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#27169;&#22411;&#26159;&#28789;&#27963;&#30340;&#27010;&#29575;&#38750;&#21442;&#25968;&#20989;&#25968;&#27169;&#22411;&#12290;Vecchia&#36817;&#20284;&#26159;&#29992;&#20110;&#20811;&#26381;&#22823;&#25968;&#25454;&#35745;&#31639;&#29942;&#39048;&#30340;&#20934;&#30830;&#36817;&#20284;&#26041;&#27861;&#65292;Laplace&#36817;&#20284;&#26159;&#19968;&#31181;&#24555;&#36895;&#26041;&#27861;&#65292;&#21487;&#20197;&#36817;&#20284;&#38750;&#39640;&#26031;&#20284;&#28982;&#20989;&#25968;&#30340;&#36793;&#32536;&#20284;&#28982;&#21644;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;&#65292;&#24182;&#20855;&#26377;&#28176;&#36817;&#25910;&#25947;&#20445;&#35777;&#12290;&#28982;&#32780;&#65292;&#24403;&#19982;&#30452;&#25509;&#27714;&#35299;&#26041;&#27861;&#65288;&#22914;Cholesky&#20998;&#35299;&#65289;&#32467;&#21512;&#20351;&#29992;&#26102;&#65292;Vecchia-Laplace&#36817;&#20284;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#22686;&#38271;&#36229;&#32447;&#24615;&#22320;&#38543;&#26679;&#26412;&#22823;&#23567;&#22686;&#21152;&#12290;&#22240;&#27492;&#65292;&#19982;Vecchia-Laplace&#36817;&#20284;&#35745;&#31639;&#30456;&#20851;&#30340;&#36816;&#31639;&#22312;&#36890;&#24120;&#24773;&#20917;&#19979;&#26159;&#26368;&#20934;&#30830;&#30340;&#22823;&#22411;&#25968;&#25454;&#38598;&#26102;&#20250;&#21464;&#24471;&#38750;&#24120;&#32531;&#24930;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20960;&#31181;&#29992;&#20110;Vecchia-Laplace&#36817;&#20284;&#25512;&#26029;&#30340;&#36845;&#20195;&#26041;&#27861;&#65292;&#30456;&#27604;&#20110;&#22522;&#20110;Cholesky&#30340;&#35745;&#31639;&#65292;&#21487;&#20197;&#22823;&#22823;&#21152;&#24555;&#35745;&#31639;&#36895;&#24230;&#12290;&#25105;&#20204;&#23545;&#25105;&#20204;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Latent Gaussian process (GP) models are flexible probabilistic non-parametric function models. Vecchia approximations are accurate approximations for GPs to overcome computational bottlenecks for large data, and the Laplace approximation is a fast method with asymptotic convergence guarantees to approximate marginal likelihoods and posterior predictive distributions for non-Gaussian likelihoods. Unfortunately, the computational complexity of combined Vecchia-Laplace approximations grows faster than linearly in the sample size when used in combination with direct solver methods such as the Cholesky decomposition. Computations with Vecchia-Laplace approximations thus become prohibitively slow precisely when the approximations are usually the most accurate, i.e., on large data sets. In this article, we present several iterative methods for inference with Vecchia-Laplace approximations which make computations considerably faster compared to Cholesky-based calculations. We analyze our propo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22810;&#27169;&#24577;&#25968;&#25454;&#30340;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#24182;&#24320;&#21457;&#20102;&#26356;&#28789;&#27963;&#30340;&#32534;&#30721;&#29305;&#24449;&#32858;&#21512;&#26041;&#26696;&#65292;&#33021;&#22815;&#32039;&#23494;&#22320;&#19979;&#30028;&#25968;&#25454;&#23545;&#25968;&#20284;&#28982;&#12290;</title><link>http://arxiv.org/abs/2309.00380</link><description>&lt;p&gt;
&#29992;&#25490;&#24207;&#19981;&#21464;&#30340;&#32534;&#30721;&#22120;&#21644;&#26356;&#32039;&#30340;&#21464;&#20998;&#36793;&#30028;&#23398;&#20064;&#22810;&#27169;&#24577;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Learning multi-modal generative models with permutation-invariant encoders and tighter variational bounds. (arXiv:2309.00380v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00380
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22810;&#27169;&#24577;&#25968;&#25454;&#30340;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#24182;&#24320;&#21457;&#20102;&#26356;&#28789;&#27963;&#30340;&#32534;&#30721;&#29305;&#24449;&#32858;&#21512;&#26041;&#26696;&#65292;&#33021;&#22815;&#32039;&#23494;&#22320;&#19979;&#30028;&#25968;&#25454;&#23545;&#25968;&#20284;&#28982;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35774;&#35745;&#29992;&#20110;&#22810;&#27169;&#24577;&#25968;&#25454;&#30340;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#19968;&#30452;&#26159;&#26426;&#22120;&#23398;&#20064;&#30740;&#31350;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#20027;&#39064;&#12290;&#22810;&#27169;&#24577;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120; (VAE) &#26159;&#19968;&#31181;&#24120;&#29992;&#30340;&#29983;&#25104;&#27169;&#22411;&#31867;&#21035;&#65292;&#23427;&#23398;&#20064;&#33021;&#22815;&#20849;&#21516;&#35299;&#37322;&#22810;&#31181;&#27169;&#24577;&#30340;&#28508;&#22312;&#34920;&#31034;&#12290;&#21508;&#31181;&#23458;&#35266;&#20989;&#25968;&#24050;&#34987;&#25552;&#20986;&#29992;&#20110;&#36825;&#26679;&#30340;&#27169;&#22411;&#65292;&#24448;&#24448;&#20197;&#22810;&#27169;&#24577;&#25968;&#25454;&#23545;&#25968;&#20284;&#28982;&#30340;&#19979;&#30028;&#20197;&#21450;&#20449;&#24687;&#35770;&#26041;&#38754;&#30340;&#32771;&#34385;&#20026;&#21160;&#26426;&#12290;&#20026;&#20102;&#23545;&#19981;&#21516;&#27169;&#24577;&#23376;&#38598;&#36827;&#34892;&#32534;&#30721;&#65292;&#25105;&#20204;&#32463;&#24120;&#20351;&#29992;&#24182;&#23637;&#31034;&#20102;&#20135;&#21697;&#22411;&#19987;&#23478; (PoE) &#25110;&#32773;&#28151;&#21512;&#22411;&#19987;&#23478; (MoE) &#32858;&#21512;&#26041;&#26696;&#65292;&#36825;&#20123;&#26041;&#26696;&#22312;&#29983;&#25104;&#36136;&#37327;&#25110;&#32773;&#22810;&#27169;&#24577;&#19968;&#33268;&#24615;&#31561;&#26041;&#38754;&#20855;&#26377;&#19981;&#21516;&#30340;&#26435;&#34913;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#33021;&#22815;&#32039;&#23494;&#22320;&#19979;&#30028;&#25968;&#25454;&#23545;&#25968;&#20284;&#28982;&#30340;&#21464;&#20998;&#36793;&#30028;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#19981;&#21516;&#27169;&#24577;&#30340;&#32534;&#30721;&#29305;&#24449;&#32452;&#21512;&#36215;&#26469;&#65292;&#24320;&#21457;&#20102;&#26356;&#28789;&#27963;&#30340;&#32858;&#21512;&#26041;&#26696;&#65292;&#36825;&#20123;&#26041;&#26696;&#25512;&#24191;&#20102; PoE &#25110;&#32773; MoE &#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Devising deep latent variable models for multi-modal data has been a long-standing theme in machine learning research. Multi-modal Variational Autoencoders (VAEs) have been a popular generative model class that learns latent representations which jointly explain multiple modalities. Various objective functions for such models have been suggested, often motivated as lower bounds on the multi-modal data log-likelihood or from information-theoretic considerations. In order to encode latent variables from different modality subsets, Product-of-Experts (PoE) or Mixture-of-Experts (MoE) aggregation schemes have been routinely used and shown to yield different trade-offs, for instance, regarding their generative quality or consistency across multiple modalities. In this work, we consider a variational bound that can tightly lower bound the data log-likelihood. We develop more flexible aggregation schemes that generalise PoE or MoE approaches by combining encoded features from different modali
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20027;&#23548;-&#26368;&#23567;&#21270;&#21407;&#21017;&#65292;&#36890;&#36807;&#20302;&#31209;&#30697;&#38453;&#34917;&#20840;&#35299;&#20915;1&#27604;&#29305;&#30697;&#38453;&#34917;&#20840;&#38382;&#39064;&#30340;&#26032;&#26041;&#27861;&#65292;&#31216;&#20026;MMGN&#12290;&#36890;&#36807;&#24212;&#29992;&#39640;&#26031;-&#29275;&#39039;&#26041;&#27861;&#65292;MMGN&#20855;&#26377;&#26356;&#24555;&#30340;&#36895;&#24230;&#21644;&#26356;&#20934;&#30830;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#36824;&#19981;&#22826;&#21463;&#21040;&#28508;&#22312;&#30697;&#38453;&#23574;&#38160;&#24230;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2304.13940</link><description>&lt;p&gt;
1&#27604;&#29305;&#30697;&#38453;&#34917;&#20840;&#30340;&#20027;&#23548;-&#26368;&#23567;&#21270;&#39640;&#26031;&#29275;&#39039;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Majorization-Minimization Gauss-Newton Method for 1-Bit Matrix Completion. (arXiv:2304.13940v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13940
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20027;&#23548;-&#26368;&#23567;&#21270;&#21407;&#21017;&#65292;&#36890;&#36807;&#20302;&#31209;&#30697;&#38453;&#34917;&#20840;&#35299;&#20915;1&#27604;&#29305;&#30697;&#38453;&#34917;&#20840;&#38382;&#39064;&#30340;&#26032;&#26041;&#27861;&#65292;&#31216;&#20026;MMGN&#12290;&#36890;&#36807;&#24212;&#29992;&#39640;&#26031;-&#29275;&#39039;&#26041;&#27861;&#65292;MMGN&#20855;&#26377;&#26356;&#24555;&#30340;&#36895;&#24230;&#21644;&#26356;&#20934;&#30830;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#36824;&#19981;&#22826;&#21463;&#21040;&#28508;&#22312;&#30697;&#38453;&#23574;&#38160;&#24230;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;1&#27604;&#29305;&#30697;&#38453;&#34917;&#20840;&#20013;&#65292;&#26088;&#22312;&#20174;&#37096;&#20998;&#20108;&#36827;&#21046;&#35266;&#27979;&#20540;&#20013;&#20272;&#35745;&#28508;&#22312;&#30340;&#20302;&#31209;&#30697;&#38453;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;MMGN&#30340;1&#27604;&#29305;&#30697;&#38453;&#34917;&#20840;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#20027;&#23548;-&#26368;&#23567;&#21270;&#65288;MM&#65289;&#21407;&#21017;&#65292;&#22312;&#25105;&#20204;&#30340;&#35774;&#32622;&#20013;&#20135;&#29983;&#19968;&#31995;&#21015;&#26631;&#20934;&#20302;&#31209;&#30697;&#38453;&#34917;&#20840;&#38382;&#39064;&#12290;&#25105;&#20204;&#36890;&#36807;&#26126;&#30830;&#24378;&#21046;&#20551;&#23450;&#30340;&#20302;&#31209;&#32467;&#26500;&#30340;&#20998;&#35299;&#26041;&#27861;&#35299;&#20915;&#36825;&#20123;&#23376;&#38382;&#39064;&#65292;&#28982;&#21518;&#24212;&#29992;&#39640;&#26031;-&#29275;&#39039;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#25968;&#20540;&#30740;&#31350;&#21644;&#23545;&#23454;&#38469;&#25968;&#25454;&#30340;&#24212;&#29992;&#34920;&#26126;&#65292;MMGN&#36755;&#20986;&#30340;&#20272;&#35745;&#32467;&#26524;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#36739;&#20855;&#26377;&#21487;&#27604;&#24615;&#19988;&#26356;&#20934;&#30830;&#12289;&#36895;&#24230;&#36890;&#24120;&#26356;&#24555;&#65292;&#24182;&#19988;&#23545;&#28508;&#22312;&#30697;&#38453;&#30340;&#23574;&#38160;&#24230;&#19981;&#22826;&#25935;&#24863;&#12290;
&lt;/p&gt;
&lt;p&gt;
In 1-bit matrix completion, the aim is to estimate an underlying low-rank matrix from a partial set of binary observations. We propose a novel method for 1-bit matrix completion called MMGN. Our method is based on the majorization-minimization (MM) principle, which yields a sequence of standard low-rank matrix completion problems in our setting. We solve each of these sub-problems by a factorization approach that explicitly enforces the assumed low-rank structure and then apply a Gauss-Newton method. Our numerical studies and application to a real-data example illustrate that MMGN outputs comparable if not more accurate estimates, is often significantly faster, and is less sensitive to the spikiness of the underlying matrix than existing methods.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#32852;&#21512;&#20998;&#24067;&#23398;&#20064;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#20174;&#22823;&#37327;&#25968;&#25454;&#28857;&#20013;&#20272;&#35745;&#20302;&#32500;&#12289;&#24402;&#19968;&#21270;&#21644;&#27491;&#30340;Radon-Nikodym&#23548;&#25968;&#27169;&#22411;&#65292;&#24182;&#22312;&#19981;&#21516;&#23398;&#20064;&#38382;&#39064;&#19978;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2110.04829</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#32852;&#21512;&#20998;&#24067;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Adaptive joint distribution learning. (arXiv:2110.04829v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.04829
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#32852;&#21512;&#20998;&#24067;&#23398;&#20064;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#20174;&#22823;&#37327;&#25968;&#25454;&#28857;&#20013;&#20272;&#35745;&#20302;&#32500;&#12289;&#24402;&#19968;&#21270;&#21644;&#27491;&#30340;Radon-Nikodym&#23548;&#25968;&#27169;&#22411;&#65292;&#24182;&#22312;&#19981;&#21516;&#23398;&#20064;&#38382;&#39064;&#19978;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#23558;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#23884;&#20837;&#24352;&#37327;&#31215;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#20013;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#23481;&#32435;&#19968;&#20010;&#20302;&#32500;&#12289;&#24402;&#19968;&#21270;&#21644;&#27491;&#30340;Radon-Nikodym&#23548;&#25968;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#20174;&#22810;&#36798;&#25968;&#30334;&#19975;&#20010;&#25968;&#25454;&#28857;&#30340;&#26679;&#26412;&#22823;&#23567;&#20013;&#36827;&#34892;&#20272;&#35745;&#65292;&#20943;&#36731;&#20102;RKHS&#24314;&#27169;&#30340;&#22266;&#26377;&#38480;&#21046;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#33258;&#28982;&#20135;&#29983;&#20102;&#23450;&#20041;&#33391;&#22909;&#30340;&#24402;&#19968;&#21270;&#21644;&#27491;&#30340;&#26465;&#20214;&#20998;&#24067;&#12290;&#23884;&#20837;&#35745;&#31639;&#36895;&#24230;&#24555;&#19988;&#36866;&#29992;&#20110;&#20174;&#39044;&#27979;&#21040;&#20998;&#31867;&#30340;&#21508;&#31181;&#23398;&#20064;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#24471;&#21040;&#20102;&#26377;&#30410;&#30340;&#25968;&#20540;&#32467;&#26524;&#30340;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a new framework for embedding joint probability distributions in tensor product reproducing kernel Hilbert spaces (RKHS). Our framework accommodates a low-dimensional, normalized and positive model of a Radon-Nikodym derivative, which we estimate from sample sizes of up to several million data points, alleviating the inherent limitations of RKHS modeling. Well-defined normalized and positive conditional distributions are natural by-products to our approach. The embedding is fast to compute and accommodates learning problems ranging from prediction to classification. Our theoretical findings are supplemented by favorable numerical results.
&lt;/p&gt;</description></item></channel></rss>