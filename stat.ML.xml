<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22810;&#20449;&#24230;&#35757;&#32451;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#31185;&#23398;&#26426;&#22120;&#23398;&#20064;&#20013;&#31232;&#32570;&#32780;&#26114;&#36149;&#30340;&#39640;&#20445;&#30495;&#25968;&#25454;&#65292;&#20197;&#25552;&#39640;&#27169;&#22411;&#30340;&#31283;&#20581;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2403.08627</link><description>&lt;p&gt;
&#22810;&#20449;&#24230;&#32447;&#24615;&#22238;&#24402;&#29992;&#20110;&#31185;&#23398;&#26426;&#22120;&#23398;&#20064;&#20013;&#31232;&#32570;&#25968;&#25454;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Multifidelity linear regression for scientific machine learning from scarce data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08627
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22810;&#20449;&#24230;&#35757;&#32451;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#31185;&#23398;&#26426;&#22120;&#23398;&#20064;&#20013;&#31232;&#32570;&#32780;&#26114;&#36149;&#30340;&#39640;&#20445;&#30495;&#25968;&#25454;&#65292;&#20197;&#25552;&#39640;&#27169;&#22411;&#30340;&#31283;&#20581;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#25311;&#21512;&#32473;&#23450;&#21442;&#25968;&#21270;&#27169;&#22411;&#31867;&#30340;&#21442;&#25968;&#26469;&#36866;&#24212;&#25968;&#25454;&#65292;&#20316;&#20026;&#23398;&#20064;&#22797;&#26434;&#24037;&#31243;&#31995;&#32479;&#30340;&#20195;&#29702;&#27169;&#22411;&#30340;&#28508;&#22312;&#26041;&#27861;&#24050;&#32463;&#24341;&#36215;&#20102;&#26497;&#22823;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#31185;&#23398;&#21644;&#24037;&#31243;&#29615;&#22659;&#20013;&#65292;&#29983;&#25104;&#29992;&#20110;&#35757;&#32451;ML&#27169;&#22411;&#30340;&#39640;&#20445;&#30495;&#25968;&#25454;&#26159;&#26114;&#36149;&#30340;&#65292;&#24182;&#19988;&#29992;&#20110;&#29983;&#25104;&#35757;&#32451;&#25968;&#25454;&#30340;&#39044;&#31639;&#26377;&#38480;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31185;&#23398;&#26426;&#22120;&#23398;&#20064;&#22810;&#20449;&#24230;&#35757;&#32451;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#20102;&#25968;&#25454;&#30340;&#21508;&#31181;&#20445;&#30495;&#24230;&#21644;&#25104;&#26412;&#21487;&#29992;&#30340;&#31185;&#23398;&#32972;&#26223;&#65307;&#20363;&#22914;&#65292;&#39640;&#20445;&#30495;&#25968;&#25454;&#21487;&#33021;&#30001;&#26114;&#36149;&#30340;&#20840;&#38754;&#35299;&#26512;&#30340;&#29289;&#29702;&#27169;&#25311;&#29983;&#25104;&#65292;&#32780;&#20302;&#20445;&#30495;&#25968;&#25454;&#21487;&#33021;&#26469;&#33258;&#22522;&#20110;&#31616;&#21270;&#30340;&#26356;&#20415;&#23452;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08627v1 Announce Type: cross  Abstract: Machine learning (ML) methods, which fit to data the parameters of a given parameterized model class, have garnered significant interest as potential methods for learning surrogate models for complex engineering systems for which traditional simulation is expensive. However, in many scientific and engineering settings, generating high-fidelity data on which to train ML models is expensive, and the available budget for generating training data is limited. ML models trained on the resulting scarce high-fidelity data have high variance and are sensitive to vagaries of the training data set. We propose a new multifidelity training approach for scientific machine learning that exploits the scientific context where data of varying fidelities and costs are available; for example high-fidelity data may be generated by an expensive fully resolved physics simulation whereas lower-fidelity data may arise from a cheaper model based on simplifying 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;(XAI)&#26041;&#27861;&#22312;&#24515;&#30005;&#22270;(ECG)&#20998;&#26512;&#20013;&#30340;&#24212;&#29992;&#65292;&#25552;&#20986;&#20102;&#19968;&#22871;&#26816;&#26597;&#25514;&#26045;&#20197;&#30830;&#23450;&#21512;&#29702;&#30340;&#24402;&#22240;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#23545;&#24739;&#32773;&#20122;&#32452;&#30340;&#25968;&#25454;&#20998;&#26512;&#65292;&#23637;&#31034;&#20102;&#36825;&#20123;XAI&#25216;&#26415;&#22914;&#20309;&#34987;&#29992;&#20110;&#30693;&#35782;&#21457;&#29616;&#65292;&#22914;&#35782;&#21035;&#24515;&#32908;&#26775;&#27515;&#20122;&#22411;&#12290;</title><link>http://arxiv.org/abs/2305.17043</link><description>&lt;p&gt;
&#35299;&#26512;&#24515;&#30005;&#22270;&#20998;&#26512;&#30340;&#28145;&#24230;&#23398;&#20064;&#65306;&#23457;&#35745;&#21644;&#30693;&#35782;&#21457;&#29616;&#30340;&#22522;&#30707;
&lt;/p&gt;
&lt;p&gt;
Explaining Deep Learning for ECG Analysis: Building Blocks for Auditing and Knowledge Discovery. (arXiv:2305.17043v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17043
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;(XAI)&#26041;&#27861;&#22312;&#24515;&#30005;&#22270;(ECG)&#20998;&#26512;&#20013;&#30340;&#24212;&#29992;&#65292;&#25552;&#20986;&#20102;&#19968;&#22871;&#26816;&#26597;&#25514;&#26045;&#20197;&#30830;&#23450;&#21512;&#29702;&#30340;&#24402;&#22240;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#23545;&#24739;&#32773;&#20122;&#32452;&#30340;&#25968;&#25454;&#20998;&#26512;&#65292;&#23637;&#31034;&#20102;&#36825;&#20123;XAI&#25216;&#26415;&#22914;&#20309;&#34987;&#29992;&#20110;&#30693;&#35782;&#21457;&#29616;&#65292;&#22914;&#35782;&#21035;&#24515;&#32908;&#26775;&#27515;&#20122;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#33021;&#22815;&#20934;&#30830;&#35782;&#21035;&#24515;&#33039;&#30142;&#30149;&#21644;&#38544;&#34255;&#30340;&#20020;&#24202;&#22240;&#32032;&#65292;&#22240;&#27492;&#23427;&#20204;&#24050;&#32463;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#22320;&#29992;&#20110;&#20998;&#26512;&#24515;&#30005;&#22270;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#30340;&#40657;&#21283;&#23376;&#29305;&#24615;&#32570;&#20047;&#36879;&#26126;&#24230;&#65292;&#26159;&#19968;&#20010;&#24120;&#35265;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#21487;&#20197;&#20351;&#29992;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#26041;&#27861;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31181;&#21518;&#20107;&#35299;&#37322;(XAI)&#26041;&#27861;&#30340;&#20840;&#38754;&#20998;&#26512;&#65292;&#30740;&#31350;&#20102;&#23616;&#37096;(&#27599;&#20010;&#26679;&#26412;&#30340;&#36129;&#29486;&#20540;)&#21644;&#20840;&#23616;(&#22522;&#20110;&#39046;&#22495;&#19987;&#23478;&#27010;&#24565;)&#30340;&#35270;&#35282;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#22871;&#26816;&#26597;&#25514;&#26045;&#65292;&#20197;&#30830;&#23450;&#21512;&#29702;&#30340;&#24402;&#22240;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#31526;&#21512;&#19987;&#23478;&#35268;&#21017;&#30340;&#23450;&#37327;&#35777;&#25454;&#12290;&#36825;&#31181;&#25968;&#25454;&#38598;&#33539;&#22260;&#30340;&#20998;&#26512;&#36229;&#20986;&#20102;&#20010;&#26696;&#32463;&#39564;&#35777;&#25454;&#65292;&#36890;&#36807;&#27719;&#24635;&#24739;&#32773;&#20122;&#32452;&#30340;&#25968;&#25454;&#26469;&#23454;&#29616;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20123;XAI&#25216;&#26415;&#22914;&#20309;&#34987;&#29992;&#20110;&#30693;&#35782;&#21457;&#29616;&#65292;&#22914;&#35782;&#21035;&#24515;&#32908;&#26775;&#27515;&#30340;&#20122;&#22411;&#12290;&#25105;&#20204;&#30456;&#20449;&#65292;&#36825;&#20123;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#20316;&#20026;&#23457;&#35745;&#21644;&#30693;&#35782;&#21457;&#29616;&#30340;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep neural networks have become increasingly popular for analyzing ECG data because of their ability to accurately identify cardiac conditions and hidden clinical factors. However, the lack of transparency due to the black box nature of these models is a common concern. To address this issue, explainable AI (XAI) methods can be employed. In this study, we present a comprehensive analysis of post-hoc XAI methods, investigating the local (attributions per sample) and global (based on domain expert concepts) perspectives. We have established a set of sanity checks to identify sensible attribution methods, and we provide quantitative evidence in accordance with expert rules. This dataset-wide analysis goes beyond anecdotal evidence by aggregating data across patient subgroups. Furthermore, we demonstrate how these XAI techniques can be utilized for knowledge discovery, such as identifying subtypes of myocardial infarction. We believe that these proposed methods can serve as building block
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#31070;&#32463;&#25511;&#21046;&#24494;&#20998;&#26041;&#31243;&#36827;&#34892;&#30417;&#30563;&#23398;&#20064;&#30340;&#27867;&#21270;&#33021;&#21147;&#38382;&#39064;&#65292;&#36890;&#36807;&#37327;&#21270;&#31163;&#25955;&#21270;&#20559;&#24046;&#21644;&#21033;&#26222;&#24076;&#33576;&#20989;&#25968;&#36924;&#36817;&#35823;&#24046;&#65292;&#24471;&#21040;&#20102;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#22120;&#19982;&#36125;&#21494;&#26031;&#26368;&#20248;&#39118;&#38505;&#30340;&#27867;&#21270;&#24046;&#36317;&#19978;&#30028;&#12290;</title><link>http://arxiv.org/abs/2305.16791</link><description>&lt;p&gt;
&#31070;&#32463;&#25511;&#21046;&#24494;&#20998;&#26041;&#31243;&#30340;&#27867;&#21270;&#33021;&#21147;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Generalization Capacities of Neural Controlled Differential Equations. (arXiv:2305.16791v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16791
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#31070;&#32463;&#25511;&#21046;&#24494;&#20998;&#26041;&#31243;&#36827;&#34892;&#30417;&#30563;&#23398;&#20064;&#30340;&#27867;&#21270;&#33021;&#21147;&#38382;&#39064;&#65292;&#36890;&#36807;&#37327;&#21270;&#31163;&#25955;&#21270;&#20559;&#24046;&#21644;&#21033;&#26222;&#24076;&#33576;&#20989;&#25968;&#36924;&#36817;&#35823;&#24046;&#65292;&#24471;&#21040;&#20102;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#22120;&#19982;&#36125;&#21494;&#26031;&#26368;&#20248;&#39118;&#38505;&#30340;&#27867;&#21270;&#24046;&#36317;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#31070;&#32463;&#25511;&#21046;&#24494;&#20998;&#26041;&#31243;&#65288;Kidger&#65292;Morrill&#31561;&#65292;2020&#65289;&#20174;&#19981;&#35268;&#21017;&#37319;&#26679;&#30340;&#26102;&#38388;&#24207;&#21015;&#26679;&#26412;&#20013;&#39044;&#27979;&#32467;&#26524;&#30340;&#30417;&#30563;&#23398;&#20064;&#35774;&#32622;&#12290;&#22312;&#25105;&#20204;&#30340;&#26694;&#26550;&#20013;&#65292;&#26102;&#38388;&#24207;&#21015;&#26159;&#19968;&#20010;&#26410;&#35266;&#23519;&#21040;&#30340;&#36830;&#32493;&#36335;&#24452;&#30340;&#31163;&#25955;&#21270;&#65292;&#32467;&#26524;&#36890;&#36807;&#19968;&#20010;&#20855;&#26377;&#26410;&#30693;&#21521;&#37327;&#22330;&#30340;&#25511;&#21046;&#24494;&#20998;&#26041;&#31243;&#20381;&#36182;&#20110;&#36825;&#20010;&#36335;&#24452;&#12290;&#20351;&#29992;&#31163;&#25955;&#25968;&#25454;&#36827;&#34892;&#23398;&#20064;&#20250;&#24341;&#20837;&#31163;&#25955;&#20559;&#24046;&#65292;&#25105;&#20204;&#31934;&#30830;&#22320;&#37327;&#21270;&#20102;&#36825;&#31181;&#20559;&#24046;&#12290;&#36890;&#36807;&#20351;&#29992;&#20851;&#20110;&#25511;&#21046;&#24494;&#20998;&#26041;&#31243;&#27969;&#30340;&#36830;&#32493;&#24615;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36924;&#36817;&#20559;&#24046;&#30452;&#25509;&#19982;&#30001;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#23450;&#20041;&#29983;&#25104;&#27169;&#22411;&#30340;&#21033;&#26222;&#24076;&#33576;&#20989;&#25968;&#30340;&#36924;&#36817;&#35823;&#24046;&#30456;&#20851;&#12290;&#36890;&#36807;&#32467;&#21512;&#26368;&#36817;&#30340;&#24037;&#20316;&#23558;&#31070;&#32463;&#32593;&#32476;&#30340;&#21033;&#26222;&#24076;&#33576;&#24120;&#25968;&#19982;&#20854;&#27867;&#21270;&#33021;&#21147;&#32852;&#31995;&#36215;&#26469;&#65292;&#25105;&#20204;&#19978;&#30028;&#20102;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#22120;&#36798;&#21040;&#30340;&#26399;&#26395;&#25439;&#22833;&#19982;&#36125;&#21494;&#26031;&#26368;&#20248;&#39118;&#38505;&#20043;&#38388;&#30340;&#27867;&#21270;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a supervised learning setup in which the goal is to predicts an outcome from a sample of irregularly sampled time series using Neural Controlled Differential Equations (Kidger, Morrill, et al. 2020). In our framework, the time series is a discretization of an unobserved continuous path, and the outcome depends on this path through a controlled differential equation with unknown vector field. Learning with discrete data thus induces a discretization bias, which we precisely quantify. Using theoretical results on the continuity of the flow of controlled differential equations, we show that the approximation bias is directly related to the approximation error of a Lipschitz function defining the generative model by a shallow neural network. By combining these result with recent work linking the Lipschitz constant of neural networks to their generalization capacities, we upper bound the generalization gap between the expected loss attained by the empirical risk minimizer and th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21516;&#24577;&#33258;&#32534;&#30721;&#22120;&#26041;&#27861;&#65292;&#20351;&#26426;&#22120;&#33021;&#22815;&#22312;&#34892;&#21160;&#20013;&#23398;&#20064;&#21040;&#19982;&#20854;&#34892;&#20026;&#30456;&#19968;&#33268;&#30340;&#24863;&#30693;&#20449;&#24687;&#30340;&#20869;&#37096;&#34920;&#31034;&#65292;&#24182;&#25429;&#33719;&#29615;&#22659;&#20013;&#30340;&#36716;&#25442;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2207.12067</link><description>&lt;p&gt;
&#21516;&#24577;&#33258;&#32534;&#30721;&#22120; - &#20174;&#35266;&#23519;&#21040;&#36716;&#21270;&#23398;&#20064;&#32676;&#32452;&#32467;&#26500;&#34920;&#29616;
&lt;/p&gt;
&lt;p&gt;
Homomorphism Autoencoder -- Learning Group Structured Representations from Observed Transitions. (arXiv:2207.12067v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.12067
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21516;&#24577;&#33258;&#32534;&#30721;&#22120;&#26041;&#27861;&#65292;&#20351;&#26426;&#22120;&#33021;&#22815;&#22312;&#34892;&#21160;&#20013;&#23398;&#20064;&#21040;&#19982;&#20854;&#34892;&#20026;&#30456;&#19968;&#33268;&#30340;&#24863;&#30693;&#20449;&#24687;&#30340;&#20869;&#37096;&#34920;&#31034;&#65292;&#24182;&#25429;&#33719;&#29615;&#22659;&#20013;&#30340;&#36716;&#25442;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#20309;&#35753;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#23398;&#20064;&#21040;&#20934;&#30830;&#34920;&#31034;&#20854;&#19982;&#30495;&#23454;&#19990;&#30028;&#20132;&#20114;&#30340;&#20869;&#22312;&#27169;&#22411;&#26159;&#19968;&#20010;&#23578;&#24453;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#26500;&#24314;&#19981;&#20165;&#21253;&#21547;&#35266;&#23519;&#24615;&#30693;&#35782;&#65292;&#20063;&#21253;&#21547;&#24178;&#39044;&#24615;&#30693;&#35782;&#30340;&#34920;&#29616;&#23398;&#20064;&#26694;&#26550;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#34920;&#31034;&#23398;&#20064;&#21644;&#32676;&#35770;&#30340;&#26041;&#27861;&#26469;&#30740;&#31350;&#35813;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#26041;&#27861;&#65292;&#20351;&#26426;&#22120;&#33021;&#22815;&#22312;&#34892;&#21160;&#36807;&#31243;&#20013;&#23398;&#20064;&#21040;&#19982;&#20043;&#30456;&#19968;&#33268;&#30340;&#24863;&#30693;&#20449;&#24687;&#30340;&#20869;&#37096;&#34920;&#31034;&#65292;&#32780;&#36825;&#20123;&#34892;&#21160;&#23454;&#38469;&#19978;&#26159;&#21464;&#25442;&#36825;&#20123;&#20449;&#24687;&#30340;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#33258;&#32534;&#30721;&#22120;&#24182;&#22312;&#20854;&#28508;&#22312;&#31354;&#38388;&#19978;&#24212;&#29992;&#32676;&#32452;&#34920;&#31034;&#65292;&#36890;&#36807;&#21033;&#29992;&#31561;&#21464;&#25439;&#22833;&#24378;&#21046;&#23454;&#26045;&#36866;&#24403;&#30340;&#21516;&#24577;&#24615;&#36136;&#20197;&#23436;&#25104;&#35757;&#32451;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#38656;&#35201;&#20808;&#39564;&#32676;&#32452;&#30693;&#35782;&#65292;&#24182;&#19988;&#19981;&#38480;&#21046;&#20195;&#29702;&#21487;&#25191;&#34892;&#30340;&#34892;&#21160;&#38598;&#21512;&#12290;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#33021;&#22815;&#23398;&#20064;&#21040;&#34892;&#21160;&#30340;&#32676;&#32452;&#34920;&#31034;&#65292;&#20174;&#32780;&#25429;&#33719;&#20102;&#29615;&#22659;&#20013;&#30340;&#36716;&#25442;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
How can agents learn internal models that veridically represent interactions with the real world is a largely open question. As machine learning is moving towards representations containing not just observational but also interventional knowledge, we study this problem using tools from representation learning and group theory. We propose methods enabling an agent acting upon the world to learn internal representations of sensory information that are consistent with actions that modify it. We use an autoencoder equipped with a group representation acting on its latent space, trained using an equivariance-derived loss in order to enforce a suitable homomorphism property on the group representation. In contrast to existing work, our approach does not require prior knowledge of the group and does not restrict the set of actions the agent can perform. We motivate our method theoretically, and show empirically that it can learn a group representation of the actions, thereby capturing the str
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#32771;&#34385;&#20102;&#36830;&#32493;&#26102;&#38388;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDPs&#65289;&#30340;&#24179;&#22343;&#22870;&#21169;&#35774;&#32622;&#19979;&#30340;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#25214;&#21040;&#20102;&#23454;&#20363;&#30456;&#20851;&#30340;&#23545;&#25968;&#36951;&#25022;&#19979;&#30028;&#65292;&#24182;&#35774;&#35745;&#20986;&#20102;&#19968;&#20010;&#33021;&#22815;&#23454;&#29616;&#23545;&#25968;&#22686;&#38271;&#36895;&#29575;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2205.11168</link><description>&lt;p&gt;
&#36830;&#32493;&#26102;&#38388;&#24179;&#22343;&#22870;&#21169;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#23545;&#25968;&#36951;&#25022;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Logarithmic regret bounds for continuous-time average-reward Markov decision processes. (arXiv:2205.11168v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.11168
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#32771;&#34385;&#20102;&#36830;&#32493;&#26102;&#38388;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDPs&#65289;&#30340;&#24179;&#22343;&#22870;&#21169;&#35774;&#32622;&#19979;&#30340;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#25214;&#21040;&#20102;&#23454;&#20363;&#30456;&#20851;&#30340;&#23545;&#25968;&#36951;&#25022;&#19979;&#30028;&#65292;&#24182;&#35774;&#35745;&#20986;&#20102;&#19968;&#20010;&#33021;&#22815;&#23454;&#29616;&#23545;&#25968;&#22686;&#38271;&#36895;&#29575;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#22312;&#26080;&#38480;&#26102;&#38388;&#36328;&#24230;&#12289;&#24179;&#22343;&#22870;&#21169;&#35774;&#23450;&#19979;&#30340;&#36830;&#32493;&#26102;&#38388;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDPs&#65289;&#30340;&#24378;&#21270;&#23398;&#20064;&#12290;&#19982;&#31163;&#25955;&#26102;&#38388;MDPs&#19981;&#21516;&#65292;&#36830;&#32493;&#26102;&#38388;&#36807;&#31243;&#22312;&#37319;&#21462;&#34892;&#21160;&#21518;&#20250;&#31227;&#21160;&#21040;&#19968;&#20010;&#29366;&#24577;&#24182;&#22312;&#27492;&#20572;&#30041;&#19968;&#20010;&#38543;&#26426;&#25345;&#32493;&#26102;&#38388;&#12290;&#22312;&#26410;&#30693;&#30340;&#36716;&#31227;&#27010;&#29575;&#21644;&#25351;&#25968;&#25345;&#32493;&#26102;&#38388;&#21464;&#21270;&#29575;&#19979;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#19968;&#20010;&#19982;&#26102;&#38388;&#36328;&#24230;&#23545;&#25968;&#30456;&#20851;&#30340;&#23454;&#20363;&#30456;&#20851;&#36951;&#25022;&#19979;&#30028;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#19968;&#20010;&#26377;&#38480;&#26102;&#38388;&#30340;&#36951;&#25022;&#30028;&#38480;&#65292;&#33021;&#22815;&#23454;&#29616;&#23545;&#25968;&#22686;&#38271;&#36895;&#29575;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#24314;&#31435;&#22312;&#19978;&#38480;&#32622;&#20449;&#22686;&#24378;&#23398;&#20064;&#12289;&#22343;&#20540;&#25345;&#32493;&#26102;&#38388;&#30340;&#31934;&#32454;&#20272;&#35745;&#20197;&#21450;&#28857;&#36807;&#31243;&#30340;&#38543;&#26426;&#27604;&#36739;&#20043;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider reinforcement learning for continuous-time Markov decision processes (MDPs) in the infinite-horizon, average-reward setting. In contrast to discrete-time MDPs, a continuous-time process moves to a state and stays there for a random holding time after an action is taken. With unknown transition probabilities and rates of exponential holding times, we derive instance-dependent regret lower bounds that are logarithmic in the time horizon. Moreover, we design a learning algorithm and establish a finite-time regret bound that achieves the logarithmic growth rate. Our analysis builds upon upper confidence reinforcement learning, a delicate estimation of the mean holding times, and stochastic comparison of point processes.
&lt;/p&gt;</description></item></channel></rss>