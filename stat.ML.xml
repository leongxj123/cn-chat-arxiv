<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20302;&#26597;&#35810;&#25104;&#26412;&#30340;&#32858;&#31867;&#26041;&#27861;&#65292;&#21033;&#29992;&#32431;&#22312;&#32452;&#21512;&#22810;&#33218;&#36172;&#21338;&#26426;&#25506;&#32034;&#33539;&#24335;&#23454;&#29616;&#22312;&#32447;&#23398;&#20064;&#65292;&#24182;&#35774;&#35745;&#20102;&#33021;&#22312;NP-hard&#24773;&#20917;&#19979;&#36816;&#34892;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01400</link><description>&lt;p&gt;
&#20302;&#26597;&#35810;&#25104;&#26412;&#24102;&#22122;&#22768;or&#21516;&#26102;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Query-Efficient Correlation Clustering with Noisy Oracle
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01400
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20302;&#26597;&#35810;&#25104;&#26412;&#30340;&#32858;&#31867;&#26041;&#27861;&#65292;&#21033;&#29992;&#32431;&#22312;&#32452;&#21512;&#22810;&#33218;&#36172;&#21338;&#26426;&#25506;&#32034;&#33539;&#24335;&#23454;&#29616;&#22312;&#32447;&#23398;&#20064;&#65292;&#24182;&#35774;&#35745;&#20102;&#33021;&#22312;NP-hard&#24773;&#20917;&#19979;&#36816;&#34892;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#24120;&#35265;&#30340;&#32858;&#31867;&#35774;&#32622;&#65292;&#20854;&#20013;&#25105;&#20204;&#38656;&#35201;&#23545;n&#20010;&#20803;&#32032;&#36827;&#34892;&#32858;&#31867;&#65292;&#24182;&#19988;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#23613;&#21487;&#33021;&#23569;&#22320;&#21521;&#36820;&#22238;&#20004;&#20010;&#20803;&#32032;&#30456;&#20284;&#24615;&#30340;&#26377;&#22122;&#22768;&#30340;oracle&#26597;&#35810;&#12290;&#25105;&#20204;&#30340;&#35774;&#32622;&#28085;&#30422;&#20102;&#35768;&#22810;&#24212;&#29992;&#39046;&#22495;&#65292;&#22312;&#36825;&#20123;&#39046;&#22495;&#20013;&#65292;&#30456;&#20284;&#24615;&#20989;&#25968;&#35745;&#31639;&#36215;&#26469;&#25104;&#26412;&#39640;&#24182;&#19988; inherently noisy&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;&#32431;&#22312;&#32452;&#21512;&#22810;&#33218;&#36172;&#21338;&#26426;&#25506;&#32034;&#33539;&#24335;(PE-CMAB)&#30340;&#22312;&#32447;&#23398;&#20064;&#38382;&#39064;&#30340;&#26032;&#39062;&#34920;&#36798;&#26041;&#27861;&#22266;&#23450;&#32622;&#20449;&#24230;&#21644;&#22266;&#23450;&#39044;&#31639;&#35774;&#32622;&#12290;&#23545;&#20110;&#36825;&#20004;&#31181;&#35774;&#32622;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#23558;&#25277;&#26679;&#31574;&#30053;&#19982;&#32463;&#20856;&#30340;&#30456;&#20851;&#32858;&#31867;&#36817;&#20284;&#31639;&#27861;&#30456;&#32467;&#21512;&#30340;&#31639;&#27861;&#65292;&#24182;&#30740;&#31350;&#20102;&#23427;&#20204;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26159;&#36825;&#26679;&#30340;&#65306;&#36825;&#20123;&#31639;&#27861;&#26159;&#31532;&#19968;&#20010;&#22312;&#24213;&#23618;&#31163;&#32447;&#20248;&#21270;&#38382;&#39064;&#20026;NP-hard&#30340;&#24773;&#20917;&#19979;&#36816;&#34892;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#30340;&#20363;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study a general clustering setting in which we have $n$ elements to be clustered, and we aim to perform as few queries as possible to an oracle that returns a noisy sample of the similarity between two elements. Our setting encompasses many application domains in which the similarity function is costly to compute and inherently noisy. We propose two novel formulations of online learning problems rooted in the paradigm of Pure Exploration in Combinatorial Multi-Armed Bandits (PE-CMAB): fixed confidence and fixed budget settings. For both settings, we design algorithms that combine a sampling strategy with a classic approximation algorithm for correlation clustering and study their theoretical guarantees. Our results are the first examples of polynomial-time algorithms that work for the case of PE-CMAB in which the underlying offline optimization problem is NP-hard.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#20195;&#25968;&#20960;&#20309;&#24037;&#20855;&#30740;&#31350;&#20102;&#20855;&#26377;&#21333;&#39033;&#24335;&#28608;&#27963;&#20989;&#25968;&#30340;&#22810;&#39033;&#24335;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#24615;&#21644;&#23398;&#20064;&#36807;&#31243;&#65292;&#36890;&#36807;&#23545;&#31070;&#32463;&#27969;&#24418;&#30340;&#32500;&#24230;&#21644;&#23398;&#20064;&#24230;&#30340;&#30740;&#31350;&#65292;&#25552;&#20379;&#20102;&#32593;&#32476;&#34920;&#36798;&#33021;&#21147;&#21644;&#35757;&#32451;&#22797;&#26434;&#24230;&#30340;&#24230;&#37327;&#65292;&#24182;&#32473;&#20986;&#20102;&#21487;&#23398;&#20989;&#25968;&#25968;&#37327;&#30340;&#19978;&#30028;&#12290;</title><link>https://rss.arxiv.org/abs/2402.00949</link><description>&lt;p&gt;
&#22810;&#39033;&#24335;&#31070;&#32463;&#32593;&#32476;&#30340;&#20960;&#20309;&#24615;&#36136;
&lt;/p&gt;
&lt;p&gt;
Geometry of Polynomial Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.00949
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#20195;&#25968;&#20960;&#20309;&#24037;&#20855;&#30740;&#31350;&#20102;&#20855;&#26377;&#21333;&#39033;&#24335;&#28608;&#27963;&#20989;&#25968;&#30340;&#22810;&#39033;&#24335;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#24615;&#21644;&#23398;&#20064;&#36807;&#31243;&#65292;&#36890;&#36807;&#23545;&#31070;&#32463;&#27969;&#24418;&#30340;&#32500;&#24230;&#21644;&#23398;&#20064;&#24230;&#30340;&#30740;&#31350;&#65292;&#25552;&#20379;&#20102;&#32593;&#32476;&#34920;&#36798;&#33021;&#21147;&#21644;&#35757;&#32451;&#22797;&#26434;&#24230;&#30340;&#24230;&#37327;&#65292;&#24182;&#32473;&#20986;&#20102;&#21487;&#23398;&#20989;&#25968;&#25968;&#37327;&#30340;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#21333;&#39033;&#24335;&#28608;&#27963;&#20989;&#25968;&#30340;&#22810;&#39033;&#24335;&#31070;&#32463;&#32593;&#32476;&#65288;PNN&#65289;&#30340;&#34920;&#36798;&#24615;&#21644;&#23398;&#20064;&#36807;&#31243;&#12290;&#32593;&#32476;&#30340;&#26435;&#37325;&#21442;&#25968;&#21270;&#20102;&#31070;&#32463;&#27969;&#24418;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#20195;&#25968;&#20960;&#20309;&#24037;&#20855;&#30740;&#31350;&#20102;&#26576;&#20123;&#31070;&#32463;&#27969;&#24418;&#65306;&#25105;&#20204;&#32473;&#20986;&#20102;&#21322;&#20195;&#25968;&#38598;&#30340;&#26126;&#30830;&#25551;&#36848;&#24182;&#29305;&#24449;&#21270;&#20102;&#23427;&#20204;&#30340;Zariski&#38381;&#21253;&#65292;&#31216;&#20026;&#31070;&#32463;&#22810;&#26679;&#24615;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#23427;&#20204;&#30340;&#32500;&#24230;&#24182;&#23558;&#19968;&#20010;&#20195;&#25968;&#24230;&#37327;&#65292;&#23398;&#20064;&#24230;&#65292;&#19982;&#31070;&#32463;&#22810;&#26679;&#24615;&#30456;&#20851;&#32852;&#12290;&#32500;&#24230;&#20316;&#20026;&#32593;&#32476;&#34920;&#36798;&#33021;&#21147;&#30340;&#20960;&#20309;&#24230;&#37327;&#65292;&#23398;&#20064;&#24230;&#26159;&#35757;&#32451;&#32593;&#32476;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#65292;&#24182;&#25552;&#20379;&#21487;&#23398;&#20989;&#25968;&#25968;&#37327;&#30340;&#19978;&#30028;&#12290;&#36825;&#20123;&#29702;&#35770;&#32467;&#26524;&#36824;&#20276;&#38543;&#30528;&#23454;&#39564;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the expressivity and learning process for polynomial neural networks (PNNs) with monomial activation functions. The weights of the network parametrize the neuromanifold. In this paper, we study certain neuromanifolds using tools from algebraic geometry: we give explicit descriptions as semialgebraic sets and characterize their Zariski closures, called neurovarieties. We study their dimension and associate an algebraic degree, the learning degree, to the neurovariety. The dimension serves as a geometric measure for the expressivity of the network, the learning degree is a measure for the complexity of training the network and provides upper bounds on the number of learnable functions. These theoretical results are accompanied with experiments.
&lt;/p&gt;</description></item><item><title>&#22312;&#23545;&#25239;&#24615;&#29615;&#22659;&#20013;&#65292;&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20462;&#25913;&#36716;&#31227;&#26680;&#23494;&#24230;&#30340;&#25200;&#21160;&#27169;&#22411;&#65292;&#25299;&#23637;&#20102;&#20256;&#32479;&#30340;&#36793;&#32536;&#25935;&#24863;&#24615;&#27169;&#22411;&#65292;&#23545;&#26080;&#38480;&#26102;&#38388;RL&#20013;&#31574;&#30053;&#20215;&#20540;&#36827;&#34892;&#20102;&#23574;&#38160;&#36793;&#30028;&#30340;&#21051;&#30011;&#21644;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2404.00099</link><description>&lt;p&gt;
&#22312;&#24378;&#20581;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#39640;&#25928;&#32780;&#23574;&#38160;&#30340;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Efficient and Sharp Off-Policy Evaluation in Robust Markov Decision Processes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00099
&lt;/p&gt;
&lt;p&gt;
&#22312;&#23545;&#25239;&#24615;&#29615;&#22659;&#20013;&#65292;&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20462;&#25913;&#36716;&#31227;&#26680;&#23494;&#24230;&#30340;&#25200;&#21160;&#27169;&#22411;&#65292;&#25299;&#23637;&#20102;&#20256;&#32479;&#30340;&#36793;&#32536;&#25935;&#24863;&#24615;&#27169;&#22411;&#65292;&#23545;&#26080;&#38480;&#26102;&#38388;RL&#20013;&#31574;&#30053;&#20215;&#20540;&#36827;&#34892;&#20102;&#23574;&#38160;&#36793;&#30028;&#30340;&#21051;&#30011;&#21644;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDP&#65289;&#20013;&#32473;&#23450;&#26469;&#33258;&#21407;&#22987;MDP&#30340;&#36716;&#31227;&#35266;&#23519;&#26102;&#65292;&#22312;&#26368;&#20339;&#21644;&#26368;&#22351;&#24773;&#20917;&#19979;&#35780;&#20272;&#31574;&#30053;&#65292;&#26080;&#35770;&#26159;&#22312;&#30456;&#21516;&#31574;&#30053;&#36824;&#26159;&#19981;&#21516;&#31574;&#30053;&#19979;&#12290;&#24403;&#23384;&#22312;&#21382;&#21490;&#21644;&#26410;&#26469;&#29615;&#22659;&#20043;&#38388;&#21487;&#33021;&#21457;&#29983;&#36716;&#21464;&#30340;&#21487;&#33021;&#24615;&#26102;&#65292;&#27604;&#22914;&#30001;&#20110;&#26410;&#27979;&#37327;&#30340;&#28151;&#26434;&#12289;&#20998;&#24067;&#36716;&#31227;&#25110;&#23545;&#25239;&#24615;&#29615;&#22659;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#25200;&#21160;&#27169;&#22411;&#65292;&#21487;&#20197;&#23558;&#36716;&#31227;&#26680;&#23494;&#24230;&#20462;&#25913;&#33267;&#32473;&#23450;&#20056;&#27861;&#22240;&#23376;&#25110;&#20854;&#20498;&#25968;&#65292;&#36825;&#23558;&#32463;&#20856;&#30340;&#36793;&#38469;&#25935;&#24863;&#24615;&#27169;&#22411;&#65288;MSM&#65289;&#25193;&#23637;&#21040;&#26080;&#38480;&#26102;&#38388; RL&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#22312;&#36825;&#20010;&#27169;&#22411;&#19979;&#30340;&#31574;&#30053;&#20215;&#20540;&#30340;&#23574;&#38160;&#36793;&#30028;&#65292;&#21363;&#22312;&#32473;&#23450;&#26469;&#33258;&#21407;&#22987;MDP&#30340;&#36716;&#31227;&#35266;&#27979;&#26102;&#21487;&#33021;&#30340;&#26368;&#20005;&#26684;&#36793;&#30028;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20174;&#36825;&#20123;&#36716;&#31227;&#35266;&#23519;&#20013;&#20272;&#35745;&#36825;&#20123;&#36793;&#30028;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#20272;&#35745;&#22120;&#65292;&#20855;&#26377;&#20960;&#20010;&#21560;&#24341;&#20154;&#30340;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00099v1 Announce Type: new  Abstract: We study evaluating a policy under best- and worst-case perturbations to a Markov decision process (MDP), given transition observations from the original MDP, whether under the same or different policy. This is an important problem when there is the possibility of a shift between historical and future environments, due to e.g. unmeasured confounding, distributional shift, or an adversarial environment. We propose a perturbation model that can modify transition kernel densities up to a given multiplicative factor or its reciprocal, which extends the classic marginal sensitivity model (MSM) for single time step decision making to infinite-horizon RL. We characterize the sharp bounds on policy value under this model, that is, the tightest possible bounds given by the transition observations from the original MDP, and we study the estimation of these bounds from such transition observations. We develop an estimator with several appealing gua
&lt;/p&gt;</description></item><item><title>CLIP&#27169;&#22411;&#22312;&#38754;&#23545;&#20998;&#24067;&#36716;&#31227;&#26102;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#20316;&#32773;&#35774;&#35745;&#20102;CounterAnimal&#25968;&#25454;&#38598;&#26469;&#25506;&#31350;&#27169;&#22411;&#23545;&#34394;&#20551;&#29305;&#24449;&#30340;&#20381;&#36182;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.11497</link><description>&lt;p&gt;
CLIP&#24635;&#26159;&#27604;ImageNet&#27169;&#22411;&#27867;&#21270;&#26356;&#22909;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Do CLIPs Always Generalize Better than ImageNet Models?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11497
&lt;/p&gt;
&lt;p&gt;
CLIP&#27169;&#22411;&#22312;&#38754;&#23545;&#20998;&#24067;&#36716;&#31227;&#26102;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#20316;&#32773;&#35774;&#35745;&#20102;CounterAnimal&#25968;&#25454;&#38598;&#26469;&#25506;&#31350;&#27169;&#22411;&#23545;&#34394;&#20551;&#29305;&#24449;&#30340;&#20381;&#36182;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#65292;&#20363;&#22914;CLIP&#65292;&#24050;&#32463;&#24443;&#24213;&#25913;&#21464;&#20102;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#12290;CLIP&#23637;&#31034;&#20102;&#22312;&#20998;&#24067;&#36716;&#31227;&#19979;&#30340;&#33391;&#22909;&#27867;&#21270;&#33021;&#21147;&#65292;&#24471;&#21040;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#25991;&#29486;&#25903;&#25345;&#12290;&#28982;&#32780;&#65292;CLIP&#30340;&#35780;&#20272;&#25968;&#25454;&#38598;&#20027;&#35201;&#26159;&#20026;ImageNet&#22522;&#20934;&#32780;&#35774;&#35745;&#30340;&#21464;&#31181;&#65292;&#21487;&#33021;&#19981;&#33021;&#23436;&#20840;&#21453;&#26144;CLIP&#22312;LAION&#31561;&#19978;&#36827;&#34892;&#39044;&#35757;&#32451;&#26102;&#23545;&#34394;&#20551;&#30456;&#20851;&#24615;&#30340;&#31283;&#20581;&#24615;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#25910;&#38598;&#20102;&#19968;&#20010;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#65292;&#21517;&#20026;CounterAnimal&#65292;&#20854;&#20013;&#21253;&#21547;&#21160;&#29289;&#29031;&#29255;&#20013;&#21457;&#29616;&#30340;&#29616;&#23454;&#34394;&#20551;&#29305;&#24449;&#12290;CounterAnimal&#21253;&#25324;a&#65289;&#24120;&#35265;&#32452;&#65306;&#21253;&#25324;&#24120;&#35265;&#32972;&#26223;&#30340;&#21160;&#29289;&#65292;&#24182;&#19988; b) &#23545;&#29031;&#32452;&#65306;&#21253;&#25324;&#22312;&#19981;&#23547;&#24120;&#32972;&#26223;&#19979;&#30340;&#21160;&#29289;&#12290;&#20174;&#24120;&#35265;&#32452;&#21040;&#23545;&#29031;&#32452;&#30340;&#24615;&#33021;&#19979;&#38477;&#37327;&#21270;&#20102;&#27169;&#22411;&#23545;&#34394;&#20551;&#29305;&#24449;&#65288;&#21363;&#32972;&#26223;&#65289;&#39044;&#27979;&#21160;&#29289;&#30340;&#20381;&#36182;&#24615;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;LAION&#25110;OpenAI&#25968;&#25454;&#19978;&#36827;&#34892;&#35757;&#32451;&#30340;CLIP&#21363;&#27809;&#26377;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11497v1 Announce Type: cross  Abstract: Large vision language models, such as CLIPs, have revolutionized modern machine learning. CLIPs have demonstrated great generalizability under distribution shifts, supported by an increasing body of literature. However, the evaluation datasets for CLIPs are variations primarily designed for ImageNet benchmarks, which may not fully reflect the extent to which CLIPs, e.g., pre-trained on LAION, robust to spurious correlations. To bridge the gap, we collect a real-world dataset called CounterAnimal that contains realistic spurious features found in animal photos. CounterAnimal consists of a) the common group: comprising animals on common backgrounds, and b) the counter group: including animals on unusual backgrounds. The performance drops from the common to counter groups quantify the reliance of models on spurious features (i.e., backgrounds) to predict the animals. We find that CLIPs trained on either LAION or the OpenAI data exhibit no
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;SDP&#30340;&#20998;&#25903;&#23450;&#30028;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;$k$-&#26368;&#23494;&#19981;&#30456;&#20132;&#21452;&#22242;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.11351</link><description>&lt;p&gt;
&#22522;&#20110;SDP&#30340;&#20108;&#20998;&#22270;&#32858;&#31867;&#20998;&#25903;&#23450;&#30028;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
An SDP-based Branch-and-Cut Algorithm for Biclustering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11351
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;SDP&#30340;&#20998;&#25903;&#23450;&#30028;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;$k$-&#26368;&#23494;&#19981;&#30456;&#20132;&#21452;&#22242;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20108;&#20998;&#22270;&#32858;&#31867;&#65292;&#20063;&#31216;&#20026;&#20849;&#32858;&#31867;&#12289;&#22359;&#32858;&#31867;&#25110;&#21452;&#21521;&#32858;&#31867;&#65292;&#28041;&#21450;&#23558;&#25968;&#25454;&#30697;&#38453;&#30340;&#34892;&#21644;&#21015;&#21516;&#26102;&#32858;&#31867;&#25104;&#19981;&#21516;&#30340;&#32452;&#65292;&#20351;&#24471;&#21516;&#19968;&#32452;&#20869;&#30340;&#34892;&#21644;&#21015;&#26174;&#31034;&#20986;&#30456;&#20284;&#30340;&#27169;&#24335;&#12290;&#20316;&#20026;&#20108;&#20998;&#22270;&#32858;&#31867;&#30340;&#27169;&#22411;&#38382;&#39064;&#65292;&#25105;&#20204;&#32771;&#34385;$k$-&#26368;&#23494;&#19981;&#30456;&#20132;&#21452;&#22242;&#38382;&#39064;&#65292;&#20854;&#30446;&#26631;&#26159;&#22312;&#32473;&#23450;&#21152;&#26435;&#23436;&#20840;&#20108;&#20998;&#22270;&#20013;&#35782;&#21035; $k$ &#20010;&#19981;&#30456;&#20132;&#30340;&#23436;&#20840;&#20108;&#37096;&#23376;&#22270;&#65288;&#31216;&#20026;&#21452;&#22242;&#65289;&#65292;&#20351;&#23427;&#20204;&#30340;&#23494;&#24230;&#20043;&#21644;&#26368;&#22823;&#21270;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23450;&#21046;&#30340;&#20998;&#25903;&#23450;&#30028;&#31639;&#27861;&#12290;&#23545;&#20110;&#19978;&#30028;&#20363;&#31243;&#65292;&#25105;&#20204;&#32771;&#34385;&#21322;&#23450;&#35268;&#21010;&#25918;&#26494;&#24182;&#25552;&#20986;&#20102;&#29992;&#20110;&#21152;&#24378;&#30028;&#38480;&#30340;&#26377;&#25928;&#19981;&#31561;&#24335;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#31181;&#19968;&#38454;&#26041;&#27861;&#20197;&#20999;&#24179;&#38754;&#26041;&#24335;&#35299;&#20915;&#36825;&#20010;&#25918;&#26494;&#38382;&#39064;&#12290;&#23545;&#20110;&#19979;&#30028;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#21033;&#29992;&#35299;&#20915;&#26041;&#26696;&#30340;&#26368;&#22823;&#26435;&#21305;&#37197;&#33293;&#20837;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11351v1 Announce Type: cross  Abstract: Biclustering, also called co-clustering, block clustering, or two-way clustering, involves the simultaneous clustering of both the rows and columns of a data matrix into distinct groups, such that the rows and columns within a group display similar patterns. As a model problem for biclustering, we consider the $k$-densest-disjoint biclique problem, whose goal is to identify $k$ disjoint complete bipartite subgraphs (called bicliques) of a given weighted complete bipartite graph such that the sum of their densities is maximized. To address this problem, we present a tailored branch-and-cut algorithm. For the upper bound routine, we consider a semidefinite programming relaxation and propose valid inequalities to strengthen the bound. We solve this relaxation in a cutting-plane fashion using a first-order method. For the lower bound, we design a maximum weight matching rounding procedure that exploits the solution of the relaxation solved
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#20855;&#26377;&#39640;&#26031;&#22122;&#22768;&#39537;&#21160;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#30340;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#22823;&#35268;&#27169;&#21464;&#20998;&#31639;&#27861;&#21644;&#32467;&#26500;&#21270;&#36924;&#36817;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#35780;&#20272;ELBO&#21644;&#33719;&#21462;&#20302;&#26041;&#24046;&#30340;&#38543;&#26426;&#26799;&#24230;&#20272;&#35745;&#65292;&#36890;&#36807;&#21033;&#29992;&#20302;&#31209;&#33945;&#29305;&#21345;&#32599;&#36924;&#36817;&#21644;&#25512;&#26029;&#32593;&#32476;&#30340;&#31934;&#24230;&#30697;&#38453;&#26356;&#26032;&#65292;&#23558;&#36817;&#20284;&#24179;&#28369;&#38382;&#39064;&#36716;&#21270;&#20026;&#36817;&#20284;&#28388;&#27874;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.01371</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#21464;&#20998;&#39640;&#26031;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Large-scale variational Gaussian state-space models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01371
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#20855;&#26377;&#39640;&#26031;&#22122;&#22768;&#39537;&#21160;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#30340;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#22823;&#35268;&#27169;&#21464;&#20998;&#31639;&#27861;&#21644;&#32467;&#26500;&#21270;&#36924;&#36817;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#35780;&#20272;ELBO&#21644;&#33719;&#21462;&#20302;&#26041;&#24046;&#30340;&#38543;&#26426;&#26799;&#24230;&#20272;&#35745;&#65292;&#36890;&#36807;&#21033;&#29992;&#20302;&#31209;&#33945;&#29305;&#21345;&#32599;&#36924;&#36817;&#21644;&#25512;&#26029;&#32593;&#32476;&#30340;&#31934;&#24230;&#30697;&#38453;&#26356;&#26032;&#65292;&#23558;&#36817;&#20284;&#24179;&#28369;&#38382;&#39064;&#36716;&#21270;&#20026;&#36817;&#20284;&#28388;&#27874;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#23884;&#22871;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#21644;&#32467;&#26500;&#21270;&#21464;&#20998;&#36924;&#36817;&#26041;&#27861;&#65292;&#20854;&#20013;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#30001;&#39640;&#26031;&#22122;&#22768;&#39537;&#21160;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#20801;&#35768;&#22312;&#27809;&#26377;&#37319;&#29992;&#23545;&#35282;&#39640;&#26031;&#36924;&#36817;&#30340;&#24773;&#20917;&#19979;&#26377;&#25928;&#22320;&#35780;&#20272;ELBO&#21644;&#20302;&#26041;&#24046;&#38543;&#26426;&#26799;&#24230;&#20272;&#35745;&#65292;&#36890;&#36807;&#21033;&#29992;&#65288;i&#65289;&#36890;&#36807;&#21160;&#21147;&#23398;&#23545;&#38544;&#29366;&#24577;&#36827;&#34892;&#36793;&#32536;&#21270;&#30340;&#33945;&#29305;&#21345;&#32599;&#36924;&#36817;&#30340;&#20302;&#31209;&#32467;&#26500;&#65292;&#65288;ii&#65289;&#19968;&#20010;&#25512;&#26029;&#32593;&#32476;&#65292;&#35813;&#32593;&#32476;&#36890;&#36807;&#20302;&#31209;&#31934;&#24230;&#30697;&#38453;&#26356;&#26032;&#26469;&#36817;&#20284;&#26356;&#26032;&#27493;&#39588;&#65292;&#65288;iii&#65289;&#23558;&#24403;&#21069;&#21644;&#26410;&#26469;&#35266;&#27979;&#32534;&#30721;&#20026;&#20266;&#35266;&#27979;--&#23558;&#36817;&#20284;&#24179;&#28369;&#38382;&#39064;&#36716;&#25442;&#20026;&#65288;&#26356;&#31616;&#21333;&#30340;&#65289;&#36817;&#20284;&#28388;&#27874;&#38382;&#39064;&#12290;&#25972;&#20307;&#32780;&#35328;&#65292;&#24517;&#35201;&#30340;&#32479;&#35745;&#20449;&#24687;&#21644;ELBO&#21487;&#20197;&#22312;$O&#65288;TL&#65288;Sr+S^2+r^2&#65289;&#65289;$&#26102;&#38388;&#20869;&#35745;&#31639;&#65292;&#20854;&#20013;$T$&#26159;&#31995;&#21015;&#38271;&#24230;&#65292;$L$&#26159;&#29366;&#24577;&#31354;&#38388;&#32500;&#25968;&#65292;$S$&#26159;&#29992;&#20110;&#36924;&#36817;&#30340;&#26679;&#26412;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01371v1 Announce Type: cross  Abstract: We introduce an amortized variational inference algorithm and structured variational approximation for state-space models with nonlinear dynamics driven by Gaussian noise. Importantly, the proposed framework allows for efficient evaluation of the ELBO and low-variance stochastic gradient estimates without resorting to diagonal Gaussian approximations by exploiting (i) the low-rank structure of Monte-Carlo approximations to marginalize the latent state through the dynamics (ii) an inference network that approximates the update step with low-rank precision matrix updates (iii) encoding current and future observations into pseudo observations -- transforming the approximate smoothing problem into an (easier) approximate filtering problem. Overall, the necessary statistics and ELBO can be computed in $O(TL(Sr + S^2 + r^2))$ time where $T$ is the series length, $L$ is the state-space dimensionality, $S$ are the number of samples used to app
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29983;&#25104;&#27169;&#22411;&#30340;&#36817;&#26368;&#23567;&#26497;&#22823;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#20351;&#29992;&#29983;&#25104;&#27169;&#22411;&#36817;&#20284;&#22238;&#25253;&#20998;&#24067;&#26041;&#38754;&#20855;&#26377;&#26497;&#23567;&#26497;&#22823;&#20248;&#21183;&#65292;&#35299;&#20915;&#20102;&#19968;&#20010;&#24320;&#25918;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#23454;&#39564;&#30740;&#31350;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.07598</link><description>&lt;p&gt;
&#22522;&#20110;&#29983;&#25104;&#27169;&#22411;&#30340;&#36817;&#26368;&#23567;&#26497;&#22823;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Near-Minimax-Optimal Distributional Reinforcement Learning with a Generative Model
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07598
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29983;&#25104;&#27169;&#22411;&#30340;&#36817;&#26368;&#23567;&#26497;&#22823;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#20351;&#29992;&#29983;&#25104;&#27169;&#22411;&#36817;&#20284;&#22238;&#25253;&#20998;&#24067;&#26041;&#38754;&#20855;&#26377;&#26497;&#23567;&#26497;&#22823;&#20248;&#21183;&#65292;&#35299;&#20915;&#20102;&#19968;&#20010;&#24320;&#25918;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#23454;&#39564;&#30740;&#31350;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#20351;&#29992;&#29983;&#25104;&#27169;&#22411;&#36817;&#20284;&#22238;&#25253;&#20998;&#24067;&#26041;&#38754;&#65292;&#23427;&#26159;&#36817;&#20284;&#26368;&#23567;&#26497;&#22823;&#30340;&#65288;&#22312;&#23545;&#25968;&#22240;&#23376;&#19978;&#65289;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;Zhang&#31561;&#20154;&#65288;2023&#65289;&#30340;&#19968;&#20010;&#24320;&#25918;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#20026;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20998;&#31867;&#26041;&#27861;&#25552;&#20379;&#20102;&#26032;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#24067;&#24335;Bellman&#26041;&#31243;&#65292;&#21363;&#38543;&#26426;&#20998;&#31867;&#32047;&#31215;&#20998;&#24067;&#20989;&#25968;Bellman&#26041;&#31243;&#65292;&#25105;&#20204;&#35748;&#20026;&#36825;&#20010;&#26041;&#31243;&#20063;&#20855;&#26377;&#29420;&#31435;&#30340;&#30740;&#31350;&#24847;&#20041;&#12290;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#23454;&#39564;&#30740;&#31350;&#65292;&#27604;&#36739;&#20102;&#20960;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#24471;&#20986;&#20102;&#23545;&#23454;&#36341;&#32773;&#26377;&#24847;&#20041;&#30340;&#20960;&#20010;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new algorithm for model-based distributional reinforcement learning (RL), and prove that it is minimax-optimal for approximating return distributions with a generative model (up to logarithmic factors), resolving an open question of Zhang et al. (2023). Our analysis provides new theoretical results on categorical approaches to distributional RL, and also introduces a new distributional Bellman equation, the stochastic categorical CDF Bellman equation, which we expect to be of independent interest. We also provide an experimental study comparing several model-based distributional RL algorithms, with several takeaways for practitioners.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;MARINA-P&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#31995;&#21015;&#30456;&#20851;&#21387;&#32553;&#22120;&#65292;&#20248;&#21270;&#20102;&#26381;&#21153;&#22120;&#21040;&#24037;&#20316;&#33410;&#28857;&#30340;&#36890;&#20449;&#22797;&#26434;&#24230;&#12290;&#29702;&#35770;&#20998;&#26512;&#35777;&#26126;&#65292;MARINA-P&#22312;&#31639;&#27861;&#19978;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#24182;&#21487;&#20197;&#20316;&#20026;&#25903;&#25345;&#21452;&#21521;&#21387;&#32553;&#30340;&#36215;&#28857;&#12290;&#36890;&#36807;&#19982;&#19978;&#34892;&#21387;&#32553;&#21644;&#21160;&#37327;&#27493;&#39588;&#30340;&#32467;&#21512;&#65292;M3&#26041;&#27861;&#23454;&#29616;&#20102;&#21452;&#21521;&#21387;&#32553;&#65292;&#24182;&#22312;&#24635;&#36890;&#20449;&#22797;&#26434;&#24230;&#19978;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2402.06412</link><description>&lt;p&gt;
&#25552;&#39640;&#38750;&#20984;&#20998;&#24067;&#24335;&#20248;&#21270;&#22312;&#20989;&#25968;&#30456;&#20284;&#24615;&#19979;&#30340;&#26368;&#22351;&#24773;&#20917;&#21452;&#21521;&#36890;&#20449;&#22797;&#26434;&#24615;
&lt;/p&gt;
&lt;p&gt;
Improving the Worst-Case Bidirectional Communication Complexity for Nonconvex Distributed Optimization under Function Similarity
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06412
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;MARINA-P&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#31995;&#21015;&#30456;&#20851;&#21387;&#32553;&#22120;&#65292;&#20248;&#21270;&#20102;&#26381;&#21153;&#22120;&#21040;&#24037;&#20316;&#33410;&#28857;&#30340;&#36890;&#20449;&#22797;&#26434;&#24230;&#12290;&#29702;&#35770;&#20998;&#26512;&#35777;&#26126;&#65292;MARINA-P&#22312;&#31639;&#27861;&#19978;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#24182;&#21487;&#20197;&#20316;&#20026;&#25903;&#25345;&#21452;&#21521;&#21387;&#32553;&#30340;&#36215;&#28857;&#12290;&#36890;&#36807;&#19982;&#19978;&#34892;&#21387;&#32553;&#21644;&#21160;&#37327;&#27493;&#39588;&#30340;&#32467;&#21512;&#65292;M3&#26041;&#27861;&#23454;&#29616;&#20102;&#21452;&#21521;&#21387;&#32553;&#65292;&#24182;&#22312;&#24635;&#36890;&#20449;&#22797;&#26434;&#24230;&#19978;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26381;&#21153;&#22120;&#21644;&#24037;&#20316;&#33410;&#28857;&#20043;&#38388;&#30340;&#26377;&#25928;&#36890;&#20449;&#22312;&#20998;&#24067;&#24335;&#20248;&#21270;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#26412;&#25991;&#20027;&#35201;&#20851;&#27880;&#20248;&#21270;&#26381;&#21153;&#22120;&#21040;&#24037;&#20316;&#33410;&#28857;&#30340;&#36890;&#20449;&#65292;&#24182;&#25581;&#31034;&#20102;&#24403;&#21069;&#27969;&#34892;&#30340;&#19979;&#34892;&#21387;&#32553;&#26041;&#27861;&#20013;&#30340;&#20302;&#25928;&#24615;&#12290;&#39318;&#20808;&#32771;&#34385;&#19978;&#34892;&#36890;&#20449;&#25104;&#26412;&#21487;&#24573;&#30053;&#30340;&#32431;&#31929;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#24341;&#20837;MARINA-P&#65292;&#19968;&#31181;&#20351;&#29992;&#19968;&#31995;&#21015;&#30456;&#20851;&#21387;&#32553;&#22120;&#30340;&#26032;&#22411;&#19979;&#34892;&#21387;&#32553;&#26041;&#27861;&#12290;&#29702;&#35770;&#20998;&#26512;&#35777;&#26126;&#65292;&#20351;&#29992;&#25490;&#21015;&#21387;&#32553;&#22120;&#30340;MARINA-P&#21487;&#20197;&#23454;&#29616;&#26381;&#21153;&#22120;&#21040;&#24037;&#20316;&#33410;&#28857;&#30340;&#36890;&#20449;&#22797;&#26434;&#24230;&#38543;&#24037;&#20316;&#33410;&#28857;&#25968;&#37327;&#25552;&#39640;&#65292;&#22240;&#27492;&#22312;&#31639;&#27861;&#19978;&#21487;&#35777;&#26126;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23637;&#31034;&#20102;MARINA-P&#21487;&#20197;&#20316;&#20026;&#25903;&#25345;&#21452;&#21521;&#21387;&#32553;&#30340;&#26041;&#27861;&#30340;&#36215;&#28857;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;M3&#65292;&#36825;&#26159;&#19968;&#31181;&#23558;MARINA-P&#19982;&#19978;&#34892;&#21387;&#32553;&#21644;&#21160;&#37327;&#27493;&#39588;&#32452;&#21512;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#23454;&#29616;&#21452;&#21521;&#21387;&#32553;&#65292;&#24182;&#22312;&#24635;&#36890;&#20449;&#22797;&#26434;&#24230;&#19978;&#35777;&#26126;&#20102;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Effective communication between the server and workers plays a key role in distributed optimization. In this paper, we focus on optimizing the server-to-worker communication, uncovering inefficiencies in prevalent downlink compression approaches. Considering first the pure setup where the uplink communication costs are negligible, we introduce MARINA-P, a novel method for downlink compression, employing a collection of correlated compressors. Theoretical analyses demonstrates that MARINA-P with permutation compressors can achieve a server-to-worker communication complexity improving with the number of workers, thus being provably superior to existing algorithms. We further show that MARINA-P can serve as a starting point for extensions such as methods supporting bidirectional compression. We introduce M3, a method combining MARINA-P with uplink compression and a momentum step, achieving bidirectional compression with provable improvements in total communication complexity as the number
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#40654;&#26364;&#27969;&#24418;&#19978;&#35299;&#20915;&#32422;&#26463;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#30340;&#26694;&#26550;&#65292;&#24182;&#25552;&#20379;&#20102;&#22810;&#31181;&#36229;&#26799;&#24230;&#20272;&#35745;&#31574;&#30053;&#65292;&#24182;&#23545;&#20854;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#35813;&#26694;&#26550;&#19981;&#20165;&#36866;&#29992;&#20110;&#30830;&#23450;&#24615;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#36824;&#36866;&#29992;&#20110;&#38543;&#26426;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#19988;&#21487;&#20197;&#20351;&#29992;&#19968;&#33324;&#30340;&#22238;&#36864;&#12290;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#65292;&#35813;&#26694;&#26550;&#37117;&#20855;&#26377;&#24456;&#39640;&#30340;&#23454;&#29992;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.03883</link><description>&lt;p&gt;
&#22312;&#40654;&#26364;&#27969;&#24418;&#19978;&#36827;&#34892;&#21452;&#23618;&#20248;&#21270;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Framework for Bilevel Optimization on Riemannian Manifolds
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03883
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#40654;&#26364;&#27969;&#24418;&#19978;&#35299;&#20915;&#32422;&#26463;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#30340;&#26694;&#26550;&#65292;&#24182;&#25552;&#20379;&#20102;&#22810;&#31181;&#36229;&#26799;&#24230;&#20272;&#35745;&#31574;&#30053;&#65292;&#24182;&#23545;&#20854;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#35813;&#26694;&#26550;&#19981;&#20165;&#36866;&#29992;&#20110;&#30830;&#23450;&#24615;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#36824;&#36866;&#29992;&#20110;&#38543;&#26426;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#19988;&#21487;&#20197;&#20351;&#29992;&#19968;&#33324;&#30340;&#22238;&#36864;&#12290;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#65292;&#35813;&#26694;&#26550;&#37117;&#20855;&#26377;&#24456;&#39640;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21452;&#23618;&#20248;&#21270;&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#24212;&#29992;&#20013;&#36234;&#26469;&#36234;&#24120;&#35265;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#40654;&#26364;&#27969;&#24418;&#19978;&#32422;&#26463;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#21464;&#37327;&#30340;&#26694;&#26550;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20960;&#31181;&#22312;&#27969;&#24418;&#19978;&#30340;&#36229;&#26799;&#24230;&#20272;&#35745;&#31574;&#30053;&#65292;&#24182;&#30740;&#31350;&#20102;&#23427;&#20204;&#30340;&#20272;&#35745;&#35823;&#24046;&#12290;&#25105;&#20204;&#23545;&#27969;&#24418;&#19978;&#30340;&#36229;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#25552;&#20379;&#20102;&#25910;&#25947;&#24615;&#21644;&#22797;&#26434;&#24615;&#20998;&#26512;&#12290;&#25105;&#20204;&#36824;&#23558;&#36825;&#20123;&#30740;&#31350;&#25193;&#23637;&#21040;&#38543;&#26426;&#21452;&#23618;&#20248;&#21270;&#21644;&#20351;&#29992;&#19968;&#33324;&#30340;&#22238;&#36864;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26694;&#26550;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bilevel optimization has seen an increasing presence in various domains of applications. In this work, we propose a framework for solving bilevel optimization problems where variables of both lower and upper level problems are constrained on Riemannian manifolds. We provide several hypergradient estimation strategies on manifolds and study their estimation error. We provide convergence and complexity analysis for the proposed hypergradient descent algorithm on manifolds. We also extend the developments to stochastic bilevel optimization and to the use of general retraction. We showcase the utility of the proposed framework on various applications.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31070;&#32463;&#21518;&#39564;&#20272;&#35745;&#30340;&#19968;&#33268;&#24615;&#27169;&#22411;&#65292;&#32467;&#21512;&#20102;&#26631;&#20934;&#21270;&#27969;&#21644;&#27969;&#21305;&#37197;&#26041;&#27861;&#30340;&#20248;&#28857;&#65292;&#29992;&#20110;&#21487;&#25193;&#23637;&#12289;&#24555;&#36895;&#21644;&#25674;&#38144;&#25512;&#26029;&#65292;&#22312;&#22810;&#20010;&#23454;&#39564;&#20013;&#23637;&#31034;&#20986;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2312.05440</link><description>&lt;p&gt;
&#21487;&#25193;&#23637;&#21644;&#24555;&#36895;&#27169;&#25311;&#25512;&#26029;&#30340;&#19968;&#33268;&#24615;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Consistency Models for Scalable and Fast Simulation-Based Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.05440
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31070;&#32463;&#21518;&#39564;&#20272;&#35745;&#30340;&#19968;&#33268;&#24615;&#27169;&#22411;&#65292;&#32467;&#21512;&#20102;&#26631;&#20934;&#21270;&#27969;&#21644;&#27969;&#21305;&#37197;&#26041;&#27861;&#30340;&#20248;&#28857;&#65292;&#29992;&#20110;&#21487;&#25193;&#23637;&#12289;&#24555;&#36895;&#21644;&#25674;&#38144;&#25512;&#26029;&#65292;&#22312;&#22810;&#20010;&#23454;&#39564;&#20013;&#23637;&#31034;&#20986;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20223;&#30495;&#25512;&#26029;&#65288;SBI&#65289;&#19981;&#26029;&#23547;&#25214;&#26356;&#20855;&#34920;&#29616;&#21147;&#30340;&#31639;&#27861;&#65292;&#20197;&#20934;&#30830;&#25512;&#26029;&#22797;&#26434;&#27169;&#22411;&#30340;&#21442;&#25968;&#20174;&#22024;&#26434;&#25968;&#25454;&#20013;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#31070;&#32463;&#21518;&#39564;&#20272;&#35745;&#30340;&#19968;&#33268;&#24615;&#27169;&#22411;&#65288;CMPE&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#21487;&#25193;&#23637;&#12289;&#24555;&#36895;&#21644;&#25674;&#38144;&#25512;&#26029;&#30340;&#26032;&#33258;&#30001;&#24418;&#24335;&#26465;&#20214;&#37319;&#26679;&#22120;&#65292;&#21033;&#29992;&#29983;&#25104;&#24615;&#31070;&#32463;&#32593;&#32476;&#12290;CMPE&#23558;&#26631;&#20934;&#21270;&#27969;&#21644;&#27969;&#21305;&#37197;&#26041;&#27861;&#30340;&#20248;&#28857;&#32467;&#21512;&#21040;&#21333;&#20010;&#29983;&#25104;&#26550;&#26500;&#20013;&#65306;&#23427;&#26412;&#36136;&#19978;&#25552;&#28860;&#20102;&#36830;&#32493;&#27010;&#29575;&#27969;&#65292;&#24182;&#33021;&#22815;&#21033;&#29992;&#26080;&#32422;&#26463;&#30340;&#32467;&#26500;&#24555;&#36895;&#36827;&#34892;&#23569;&#23556;&#25512;&#26029;&#65292;&#35813;&#32467;&#26500;&#21487;&#20197;&#23450;&#21046;&#21040;&#20272;&#35745;&#38382;&#39064;&#30340;&#32467;&#26500;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#35780;&#20272;&#34920;&#26126;&#65292;CMPE&#19981;&#20165;&#22312;&#19977;&#20010;&#22256;&#38590;&#30340;&#20302;&#32500;&#38382;&#39064;&#19978;&#20248;&#20110;&#24403;&#21069;&#30340;&#26368;&#20808;&#36827;&#31639;&#27861;&#65292;&#32780;&#19988;&#22312;&#39640;&#32500;&#36125;&#21494;&#26031;&#21435;&#22122;&#23454;&#39564;&#21644;&#20272;&#35745;&#35745;&#31639;&#23494;&#38598;&#22411;&#22810;&#23610;&#24230;&#20013;&#34920;&#29616;&#20986;&#26377;&#31454;&#20105;&#21147;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.05440v2 Announce Type: replace-cross  Abstract: Simulation-based inference (SBI) is constantly in search of more expressive algorithms for accurately inferring the parameters of complex models from noisy data. We present consistency models for neural posterior estimation (CMPE), a new free-form conditional sampler for scalable, fast, and amortized SBI with generative neural networks. CMPE combines the advantages of normalizing flows and flow matching methods into a single generative architecture: It essentially distills a continuous probability flow and enables rapid few-shot inference with an unconstrained architecture that can be tailored to the structure of the estimation problem. Our empirical evaluation demonstrates that CMPE not only outperforms current state-of-the-art algorithms on three hard low-dimensional problems but also achieves competitive performance in a high-dimensional Bayesian denoising experiment and in estimating a computationally demanding multi-scale 
&lt;/p&gt;</description></item><item><title>SASSL&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#39118;&#26684;&#36801;&#31227;&#30340;&#22686;&#24378;&#25216;&#26415;&#65292;&#36890;&#36807;&#35299;&#32806;&#35821;&#20041;&#21644;&#39118;&#26684;&#23646;&#24615;&#65292;&#22312;&#33258;&#30417;&#30563;&#23398;&#20064;&#20013;&#29983;&#25104;&#22810;&#26679;&#21270;&#30340;&#22686;&#24378;&#26679;&#26412;&#65292;&#20174;&#32780;&#25552;&#21319;&#20102;&#22270;&#20687;&#20998;&#31867;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2312.01187</link><description>&lt;p&gt;
SASSL:&#36890;&#36807;&#31070;&#32463;&#39118;&#26684;&#36801;&#31227;&#22686;&#24378;&#33258;&#30417;&#30563;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
SASSL: Enhancing Self-Supervised Learning via Neural Style Transfer. (arXiv:2312.01187v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.01187
&lt;/p&gt;
&lt;p&gt;
SASSL&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#39118;&#26684;&#36801;&#31227;&#30340;&#22686;&#24378;&#25216;&#26415;&#65292;&#36890;&#36807;&#35299;&#32806;&#35821;&#20041;&#21644;&#39118;&#26684;&#23646;&#24615;&#65292;&#22312;&#33258;&#30417;&#30563;&#23398;&#20064;&#20013;&#29983;&#25104;&#22810;&#26679;&#21270;&#30340;&#22686;&#24378;&#26679;&#26412;&#65292;&#20174;&#32780;&#25552;&#21319;&#20102;&#22270;&#20687;&#20998;&#31867;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#30417;&#30563;&#23398;&#20064;&#20381;&#36182;&#20110;&#25968;&#25454;&#22686;&#24378;&#26469;&#20174;&#26080;&#26631;&#31614;&#22270;&#20687;&#20013;&#25552;&#21462;&#26377;&#24847;&#20041;&#30340;&#34920;&#24449;&#12290;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#30340;&#22686;&#24378;&#27969;&#27700;&#32447;&#21253;&#25324;&#20102;&#21508;&#31181;&#21407;&#22987;&#30340;&#36716;&#25442;&#65292;&#20294;&#36890;&#24120;&#24573;&#30053;&#20102;&#33258;&#28982;&#22270;&#20687;&#30340;&#32467;&#26500;&#12290;&#22240;&#27492;&#65292;&#22686;&#24378;&#26679;&#26412;&#21487;&#33021;&#26174;&#31034;&#20986;&#36864;&#21270;&#30340;&#35821;&#20041;&#20449;&#24687;&#21644;&#20302;&#39118;&#26684;&#22810;&#26679;&#24615;&#65292;&#20174;&#32780;&#24433;&#21709;&#21040;&#33258;&#30417;&#30563;&#34920;&#24449;&#30340;&#19979;&#28216;&#24615;&#33021;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SASSL&#30340;&#26032;&#22411;&#22686;&#24378;&#25216;&#26415;&#65292;&#23427;&#22522;&#20110;&#31070;&#32463;&#39118;&#26684;&#36801;&#31227;&#12290;&#35813;&#26041;&#27861;&#23558;&#22270;&#20687;&#20013;&#30340;&#35821;&#20041;&#21644;&#39118;&#26684;&#23646;&#24615;&#35299;&#32806;&#65292;&#24182;&#20165;&#23545;&#39118;&#26684;&#24212;&#29992;&#36716;&#25442;&#65292;&#20445;&#25345;&#20869;&#23481;&#65292;&#29983;&#25104;&#22810;&#26679;&#21270;&#30340;&#22686;&#24378;&#26679;&#26412;&#65292;&#26356;&#22909;&#22320;&#20445;&#30041;&#23427;&#20204;&#30340;&#35821;&#20041;&#23646;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#19982;&#24191;&#20026;&#25509;&#21463;&#30340;MoCo v2&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#25216;&#26415;&#22312;ImageNet&#19978;&#30340;top-1&#20998;&#31867;&#24615;&#33021;&#25552;&#21319;&#36229;&#36807;2%&#12290;
&lt;/p&gt;
&lt;p&gt;
Self-supervised learning relies heavily on data augmentation to extract meaningful representations from unlabeled images. While existing state-of-the-art augmentation pipelines incorporate a wide range of primitive transformations, these often disregard natural image structure. Thus, augmented samples can exhibit degraded semantic information and low stylistic diversity, affecting downstream performance of self-supervised representations. To overcome this, we propose SASSL: Style Augmentations for Self Supervised Learning, a novel augmentation technique based on Neural Style Transfer. The method decouples semantic and stylistic attributes in images and applies transformations exclusively to the style while preserving content, generating diverse augmented samples that better retain their semantic properties. Experimental results show our technique achieves a top-1 classification performance improvement of more than 2% on ImageNet compared to the well-established MoCo v2. We also measure
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#36125;&#21494;&#26031;EM&#31639;&#27861;&#65292;&#29992;&#20110;&#20174;&#20108;&#20803;&#21644;&#26377;&#24207;&#39033;&#30446;&#21709;&#24212;&#20013;&#20272;&#35745;&#31232;&#30095;&#22240;&#23376;&#36733;&#33655;&#65292;&#24182;&#36890;&#36807;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#35299;&#20915;&#20102;&#26410;&#30693;&#28508;&#22312;&#22240;&#23376;&#32500;&#24230;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.17820</link><description>&lt;p&gt;
&#31232;&#30095;&#36125;&#21494;&#26031;&#22810;&#32500;&#39033;&#30446;&#21453;&#24212;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Sparse Bayesian Multidimensional Item Response Theory. (arXiv:2310.17820v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17820
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#36125;&#21494;&#26031;EM&#31639;&#27861;&#65292;&#29992;&#20110;&#20174;&#20108;&#20803;&#21644;&#26377;&#24207;&#39033;&#30446;&#21709;&#24212;&#20013;&#20272;&#35745;&#31232;&#30095;&#22240;&#23376;&#36733;&#33655;&#65292;&#24182;&#36890;&#36807;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#35299;&#20915;&#20102;&#26410;&#30693;&#28508;&#22312;&#22240;&#23376;&#32500;&#24230;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#21464;&#37327;&#39033;&#30446;&#21453;&#24212;&#29702;&#35770;&#65288;MIRT&#65289;&#34987;&#24212;&#29992;&#30740;&#31350;&#20154;&#21592;&#24191;&#27867;&#20351;&#29992;&#65292;&#20197;&#23547;&#25214;&#38382;&#21367;&#25968;&#25454;&#20013;&#21709;&#24212;&#27169;&#24335;&#32972;&#21518;&#30340;&#21487;&#35299;&#37322;&#65288;&#31232;&#30095;&#65289;&#35299;&#37322;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#23545;&#20110;&#36825;&#31181;&#31232;&#30095;&#24615;&#21457;&#29616;&#24037;&#20855;&#30340;&#38656;&#27714;&#23578;&#26410;&#24471;&#21040;&#28385;&#36275;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20108;&#20803;&#21644;&#26377;&#24207;&#39033;&#30446;MIRT&#30340;&#36125;&#21494;&#26031;&#24179;&#21488;&#65292;&#20854;&#38656;&#35201;&#26368;&#23569;&#30340;&#35843;&#25972;&#65292;&#24182;&#19988;&#30001;&#20110;&#20854;&#21487;&#24182;&#34892;&#21270;&#30340;&#29305;&#24615;&#65292;&#22312;&#30456;&#23545;&#36739;&#22823;&#30340;&#25968;&#25454;&#38598;&#19978;&#20855;&#26377;&#33391;&#22909;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;MIRT&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#20256;&#32479;&#19978;&#20381;&#36182;&#20110;MCMC&#27169;&#25311;&#65292;&#22312;&#23454;&#36341;&#20013;&#21487;&#33021;&#26082;&#36153;&#26102;&#21448;&#38590;&#20197;&#36890;&#36807;&#39069;&#22806;&#30340;&#38408;&#20540;&#35774;&#23450;&#23454;&#29616;&#31934;&#30830;&#30340;&#31232;&#30095;&#24674;&#22797;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#36125;&#21494;&#26031;EM&#31639;&#27861;&#65292;&#29992;&#20110;&#20174;&#20108;&#20803;&#21644;&#26377;&#24207;&#39033;&#30446;&#21709;&#24212;&#20013;&#20272;&#35745;&#31232;&#30095;&#22240;&#23376;&#36733;&#33655;&#12290;&#25105;&#20204;&#21033;&#29992;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#35299;&#20915;&#20102;&#26410;&#30693;&#28508;&#22312;&#22240;&#23376;&#32500;&#24230;&#30340;&#30475;&#20284;&#19981;&#21487;&#36926;&#36234;&#30340;&#38382;&#39064;&#65292;&#20174;&#32780;&#20351;&#24471;&#21487;&#20197;&#20272;&#35745;&#22240;&#23376;&#30340;&#25968;&#37327;&#12290;&#36890;&#36807;&#26059;&#36716;&#21487;&#20197;&#23454;&#29616;&#31232;&#30095;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multivariate Item Response Theory (MIRT) is sought-after widely by applied researchers looking for interpretable (sparse) explanations underlying response patterns in questionnaire data. There is, however, an unmet demand for such sparsity discovery tools in practice. Our paper develops a Bayesian platform for binary and ordinal item MIRT which requires minimal tuning and scales well on relatively large datasets due to its parallelizable features. Bayesian methodology for MIRT models has traditionally relied on MCMC simulation, which cannot only be slow in practice, but also often renders exact sparsity recovery impossible without additional thresholding. In this work, we develop a scalable Bayesian EM algorithm to estimate sparse factor loadings from binary and ordinal item responses. We address the seemingly insurmountable problem of unknown latent factor dimensionality with tools from Bayesian nonparametrics which enable estimating the number of factors. Rotations to sparsity throug
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;QBSD&#30340;&#23454;&#26102;&#39044;&#27979;&#26041;&#27861;&#65292;&#20197;&#22312;&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#26816;&#27979;&#20013;&#21462;&#24471;&#26368;&#20339;&#24179;&#34913;&#12290;</title><link>http://arxiv.org/abs/2306.05989</link><description>&lt;p&gt;
&#22522;&#20110;&#22235;&#20998;&#20301;&#25968;&#30340;&#23395;&#33410;&#24615;&#20998;&#35299;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#21644;&#24322;&#24120;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Quartile-Based Seasonality Decomposition for Time Series Forecasting and Anomaly Detection. (arXiv:2306.05989v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05989
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;QBSD&#30340;&#23454;&#26102;&#39044;&#27979;&#26041;&#27861;&#65292;&#20197;&#22312;&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#26816;&#27979;&#20013;&#21462;&#24471;&#26368;&#20339;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#30005;&#20449;&#39046;&#22495;&#65292;&#21450;&#26102;&#26816;&#27979;&#24322;&#24120;&#38750;&#24120;&#37325;&#35201;&#65292;&#22240;&#20026;&#36825;&#26377;&#21161;&#20110;&#35782;&#21035;&#21644;&#34920;&#24449;&#19981;&#35268;&#21017;&#27169;&#24335;&#12289;&#24322;&#24120;&#34892;&#20026;&#21644;&#32593;&#32476;&#24322;&#24120;&#65292;&#20174;&#32780;&#25552;&#39640;&#26381;&#21153;&#36136;&#37327;&#21644;&#25805;&#20316;&#25928;&#29575;&#12290;&#31934;&#30830;&#22320;&#39044;&#27979;&#21644;&#28040;&#38500;&#21487;&#39044;&#27979;&#30340;&#26102;&#38388;&#24207;&#21015;&#27169;&#24335;&#26159;&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#26816;&#27979;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22522;&#20110;&#22235;&#20998;&#20301;&#25968;&#30340;&#23395;&#33410;&#24615;&#20998;&#35299;&#65288;QBSD&#65289;&#30340;&#23454;&#26102;&#39044;&#27979;&#26041;&#27861;&#65292;&#20197;&#22312;&#35745;&#31639;&#22797;&#26434;&#24230;&#21644;&#39044;&#27979;&#20934;&#30830;&#29575;&#20043;&#38388;&#21462;&#24471;&#26368;&#20339;&#24179;&#34913;&#12290;&#26412;&#25991;&#27604;&#36739;&#20102;QBSD&#19982;&#29616;&#26377;&#39044;&#27979;&#26041;&#27861;&#30340;&#24615;&#33021;&#21450;&#20854;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The timely detection of anomalies is essential in the telecom domain as it facilitates the identification and characterization of irregular patterns, abnormal behaviors, and network anomalies, contributing to enhanced service quality and operational efficiency. Precisely forecasting and eliminating predictable time series patterns constitutes a vital component of time series anomaly detection. While the state-of-the-art methods aim to maximize forecasting accuracy, the computational performance takes a hit. In a system composed of a large number of time series variables, e.g., cell Key Performance Indicators (KPIs), the time and space complexity of the forecasting employed is of crucial importance. Quartile-Based Seasonality Decomposition (QBSD) is a live forecasting method proposed in this paper to make an optimal trade-off between computational complexity and forecasting accuracy. This paper compares the performance of QBSD to the state-of-the-art forecasting methods and their applic
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#27604;&#36739;&#20102;&#19981;&#21516;&#31867;&#22411;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#22312;&#28082;&#21387;&#29366;&#24577;&#30417;&#27979;&#31995;&#32479;&#20013;&#29992;&#20110;&#24322;&#24120;&#26816;&#27979;&#12290;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#34920;&#29616;&#26368;&#22909;&#65292;&#32780;&#38598;&#25104;&#27169;&#22411;&#21487;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;&#26816;&#27979;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.02709</link><description>&lt;p&gt;
&#29992;&#20110;&#28082;&#21387;&#29366;&#24577;&#30417;&#27979;&#31995;&#32479;&#24322;&#24120;&#26816;&#27979;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#27604;&#36739;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Comparative Study on Semi-supervised Learning Applied for Anomaly Detection in Hydraulic Condition Monitoring System. (arXiv:2306.02709v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02709
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#27604;&#36739;&#20102;&#19981;&#21516;&#31867;&#22411;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#22312;&#28082;&#21387;&#29366;&#24577;&#30417;&#27979;&#31995;&#32479;&#20013;&#29992;&#20110;&#24322;&#24120;&#26816;&#27979;&#12290;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#34920;&#29616;&#26368;&#22909;&#65292;&#32780;&#38598;&#25104;&#27169;&#22411;&#21487;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;&#26816;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#29366;&#24577;&#30340;&#32500;&#25252;&#22312;&#28082;&#21387;&#31995;&#32479;&#20013;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#31995;&#32479;&#30340;&#24322;&#24120;&#26816;&#27979;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#29305;&#21035;&#26159;&#30001;&#20110;&#24322;&#24120;&#25968;&#25454;&#24456;&#23569;&#65292;&#26631;&#35760;&#36825;&#20123;&#25968;&#25454;&#26159;&#36153;&#26102;&#36153;&#21147;&#29978;&#33267;&#21361;&#38505;&#30340;&#12290;&#22240;&#27492;&#65292;&#24314;&#35758;&#20351;&#29992;&#26080;&#30417;&#30563;&#25110;&#21322;&#30417;&#30563;&#26041;&#27861;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#21482;&#26377;&#23569;&#37327;&#26631;&#31614;&#21487;&#29992;&#30340;&#24773;&#20917;&#19979;&#21033;&#29992;&#26080;&#30417;&#30563;&#23398;&#20064;&#20316;&#20026;&#29305;&#24449;&#25552;&#21462;&#26426;&#21046;&#26469;&#36741;&#21161;&#30417;&#30563;&#23398;&#20064;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#12290;&#26412;&#30740;&#31350;&#31995;&#32479;&#22320;&#27604;&#36739;&#20102;&#22312;&#28082;&#21387;&#29366;&#24577;&#30417;&#27979;&#31995;&#32479;&#20013;&#24212;&#29992;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#29992;&#20110;&#24322;&#24120;&#26816;&#27979;&#12290;&#39318;&#20808;&#65292;&#36827;&#34892;&#20102;&#28145;&#20837;&#30340;&#25968;&#25454;&#20998;&#26512;&#21644;&#29305;&#24449;&#23398;&#20064;&#65292;&#20197;&#20102;&#35299;&#24320;&#28304;&#30340;&#28082;&#21387;&#29366;&#24577;&#30417;&#27979;&#25968;&#25454;&#38598;&#12290;&#28982;&#21518;&#65292;&#23454;&#26045;&#21644;&#35780;&#20272;&#20102;&#21508;&#31181;&#26041;&#27861;&#65292;&#21253;&#25324;&#20256;&#32479;&#30340;&#29420;&#31435;&#21322;&#30417;&#30563;&#23398;&#20064;&#27169;&#22411;&#65288;&#20363;&#22914;&#65292;&#19968;&#31867;&#25903;&#25345;&#21521;&#37327;&#26426;&#12289;&#40065;&#26834;&#21327;&#26041;&#24046;&#65289;&#12289;&#38598;&#25104;&#27169;&#22411;&#65288;&#20363;&#22914;&#65292;&#23396;&#31435;&#26862;&#26519;&#65289;&#21644;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#27169;&#22411;&#65288;&#20363;&#22914;&#65292;&#33258;&#21160;&#32534;&#30721;&#22120;&#12289;&#22270;&#21367;&#31215;&#32593;&#32476;&#65289;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#20248;&#20110;&#20256;&#32479;&#27169;&#22411;&#65292;&#32780;&#38598;&#25104;&#27169;&#22411;&#21487;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;&#26816;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Condition-based maintenance is becoming increasingly important in hydraulic systems. However, anomaly detection for these systems remains challenging, especially since that anomalous data is scarce and labeling such data is tedious and even dangerous. Therefore, it is advisable to make use of unsupervised or semi-supervised methods, especially for semi-supervised learning which utilizes unsupervised learning as a feature extraction mechanism to aid the supervised part when only a small number of labels are available. This study systematically compares semi-supervised learning methods applied for anomaly detection in hydraulic condition monitoring systems. Firstly, thorough data analysis and feature learning were carried out to understand the open-sourced hydraulic condition monitoring dataset. Then, various methods were implemented and evaluated including traditional stand-alone semi-supervised learning models (e.g., one-class SVM, Robust Covariance), ensemble models (e.g., Isolation F
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;DU-Shapley&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26356;&#26377;&#25928;&#22320;&#35745;&#31639;Shapley&#20540;&#65292;&#20197;&#23454;&#29616;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#25968;&#25454;&#38598;&#20215;&#20540;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2306.02071</link><description>&lt;p&gt;
DU-Shapley: &#19968;&#31181;&#26377;&#25928;&#30340;&#25968;&#25454;&#38598;&#20215;&#20540;&#35780;&#20272;&#30340;Shapley&#20540;&#20195;&#29702;
&lt;/p&gt;
&lt;p&gt;
DU-Shapley: A Shapley Value Proxy for Efficient Dataset Valuation. (arXiv:2306.02071v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02071
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;DU-Shapley&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26356;&#26377;&#25928;&#22320;&#35745;&#31639;Shapley&#20540;&#65292;&#20197;&#23454;&#29616;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#25968;&#25454;&#38598;&#20215;&#20540;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#38656;&#35201;&#36827;&#34892;&#25968;&#25454;&#38598;&#35780;&#20272;&#65292;&#21363;&#37327;&#21270;&#23558;&#19968;&#20010;&#21333;&#29420;&#30340;&#25968;&#25454;&#38598;&#19982;&#20854;&#20182;&#25968;&#25454;&#38598;&#32858;&#21512;&#30340;&#22686;&#37327;&#25910;&#30410;&#65292;&#20197;&#26576;&#20123;&#30456;&#20851;&#39044;&#23450;&#20041;&#20844;&#29992;&#20107;&#19994;&#20026;&#22522;&#30784;&#12290;&#26368;&#36817;&#65292;Shapley&#20540;&#34987;&#25552;&#20986;&#20316;&#20026;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#30340;&#19968;&#31181;&#22522;&#26412;&#24037;&#20855;&#65292;&#22240;&#20026;&#23427;&#20855;&#26377;&#24418;&#24335;&#20844;&#29702;&#35777;&#26126;&#12290;&#30001;&#20110;&#20854;&#35745;&#31639;&#36890;&#24120;&#38656;&#35201;&#25351;&#25968;&#26102;&#38388;&#65292;&#22240;&#27492;&#32771;&#34385;&#22522;&#20110;Monte Carlo&#31215;&#20998;&#30340;&#26631;&#20934;&#36817;&#20284;&#31574;&#30053;&#12290;&#28982;&#32780;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#36825;&#31181;&#36890;&#29992;&#36817;&#20284;&#26041;&#27861;&#20173;&#28982;&#26114;&#36149;&#12290;&#26412;&#25991;&#21033;&#29992;&#25968;&#25454;&#38598;&#35780;&#20272;&#38382;&#39064;&#30340;&#32467;&#26500;&#30693;&#35782;&#65292;&#35774;&#35745;&#20102;&#26356;&#26377;&#25928;&#30340;Shapley&#20540;&#20272;&#35745;&#22120;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;Shapley&#20540;&#36817;&#20284;&#65292;&#31216;&#20026;&#31163;&#25955;&#22343;&#21248;Shapley (DU-Shapley)&#65292;&#20854;&#34920;&#36798;&#20026;&#26399;&#26395;&#20540;
&lt;/p&gt;
&lt;p&gt;
Many machine learning problems require performing dataset valuation, i.e. to quantify the incremental gain, to some relevant pre-defined utility, of aggregating an individual dataset to others. As seminal examples, dataset valuation has been leveraged in collaborative and federated learning to create incentives for data sharing across several data owners. The Shapley value has recently been proposed as a principled tool to achieve this goal due to formal axiomatic justification. Since its computation often requires exponential time, standard approximation strategies based on Monte Carlo integration have been considered. Such generic approximation methods, however, remain expensive in some cases. In this paper, we exploit the knowledge about the structure of the dataset valuation problem to devise more efficient Shapley value estimators. We propose a novel approximation of the Shapley value, referred to as discrete uniform Shapley (DU-Shapley) which is expressed as an expectation under 
&lt;/p&gt;</description></item></channel></rss>