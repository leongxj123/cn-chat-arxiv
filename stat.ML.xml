<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#22312;&#22810;&#29615;&#22659;&#39044;&#27979;&#38382;&#39064;&#20013;&#26500;&#24314;&#26377;&#25928;&#32622;&#20449;&#21306;&#38388;&#21644;&#32622;&#20449;&#38598;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#19968;&#31181;&#26032;&#30340;&#35843;&#25972;&#26041;&#27861;&#20197;&#36866;&#24212;&#38382;&#39064;&#38590;&#24230;&#65292;&#20174;&#32780;&#20943;&#23569;&#39044;&#27979;&#38598;&#22823;&#23567;&#65292;&#36825;&#22312;&#31070;&#32463;&#24863;&#24212;&#21644;&#29289;&#31181;&#20998;&#31867;&#25968;&#25454;&#38598;&#20013;&#30340;&#23454;&#38469;&#34920;&#29616;&#20013;&#24471;&#21040;&#39564;&#35777;&#12290;</title><link>https://arxiv.org/abs/2403.16336</link><description>&lt;p&gt;
&#22810;&#29615;&#22659;&#22330;&#26223;&#20013;&#30340;&#39044;&#27979;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Predictive Inference in Multi-environment Scenarios
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16336
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#22312;&#22810;&#29615;&#22659;&#39044;&#27979;&#38382;&#39064;&#20013;&#26500;&#24314;&#26377;&#25928;&#32622;&#20449;&#21306;&#38388;&#21644;&#32622;&#20449;&#38598;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#19968;&#31181;&#26032;&#30340;&#35843;&#25972;&#26041;&#27861;&#20197;&#36866;&#24212;&#38382;&#39064;&#38590;&#24230;&#65292;&#20174;&#32780;&#20943;&#23569;&#39044;&#27979;&#38598;&#22823;&#23567;&#65292;&#36825;&#22312;&#31070;&#32463;&#24863;&#24212;&#21644;&#29289;&#31181;&#20998;&#31867;&#25968;&#25454;&#38598;&#20013;&#30340;&#23454;&#38469;&#34920;&#29616;&#20013;&#24471;&#21040;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35299;&#20915;&#20102;&#22312;&#36328;&#22810;&#20010;&#29615;&#22659;&#30340;&#39044;&#27979;&#38382;&#39064;&#20013;&#26500;&#24314;&#26377;&#25928;&#32622;&#20449;&#21306;&#38388;&#21644;&#32622;&#20449;&#38598;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#36866;&#29992;&#20110;&#36825;&#20123;&#38382;&#39064;&#30340;&#20004;&#31181;&#35206;&#30422;&#31867;&#22411;&#65292;&#25193;&#23637;&#20102;Jackknife&#21644;&#20998;&#35010;&#19968;&#33268;&#26041;&#27861;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#22312;&#36825;&#31181;&#38750;&#20256;&#32479;&#30340;&#23618;&#27425;&#25968;&#25454;&#29983;&#25104;&#22330;&#26223;&#20013;&#33719;&#24471;&#26080;&#20998;&#24067;&#35206;&#30422;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#36824;&#21253;&#25324;&#23545;&#38750;&#23454;&#20540;&#21709;&#24212;&#35774;&#32622;&#30340;&#25193;&#23637;&#65292;&#20197;&#21450;&#36825;&#20123;&#19968;&#33324;&#38382;&#39064;&#20013;&#39044;&#27979;&#25512;&#26029;&#30340;&#19968;&#33268;&#24615;&#29702;&#35770;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31181;&#26032;&#30340;&#35843;&#25972;&#26041;&#27861;&#65292;&#20197;&#36866;&#24212;&#38382;&#39064;&#38590;&#24230;&#65292;&#36825;&#36866;&#29992;&#20110;&#20855;&#26377;&#23618;&#27425;&#25968;&#25454;&#30340;&#39044;&#27979;&#25512;&#26029;&#30340;&#29616;&#26377;&#26041;&#27861;&#20197;&#21450;&#25105;&#20204;&#24320;&#21457;&#30340;&#26041;&#27861;&#65307;&#36825;&#36890;&#36807;&#31070;&#32463;&#21270;&#23398;&#24863;&#24212;&#21644;&#29289;&#31181;&#20998;&#31867;&#25968;&#25454;&#38598;&#35780;&#20272;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#23454;&#38469;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16336v1 Announce Type: cross  Abstract: We address the challenge of constructing valid confidence intervals and sets in problems of prediction across multiple environments. We investigate two types of coverage suitable for these problems, extending the jackknife and split-conformal methods to show how to obtain distribution-free coverage in such non-traditional, hierarchical data-generating scenarios. Our contributions also include extensions for settings with non-real-valued responses and a theory of consistency for predictive inference in these general problems. We demonstrate a novel resizing method to adapt to problem difficulty, which applies both to existing approaches for predictive inference with hierarchical data and the methods we develop; this reduces prediction set sizes using limited information from the test environment, a key to the methods' practical performance, which we evaluate through neurochemical sensing and species classification datasets.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#35780;&#20998;&#35268;&#21017;&#35757;&#32451;&#29983;&#23384;&#27169;&#22411;&#30340;&#36890;&#29992;&#26041;&#27861;&#65292;&#23558;&#20854;&#24212;&#29992;&#20110;&#21508;&#31181;&#27169;&#22411;&#31867;&#21035;&#20013;&#24182;&#19982;&#31070;&#32463;&#32593;&#32476;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#21487;&#25193;&#23637;&#30340;&#20248;&#21270;&#20363;&#31243;&#65292;&#24182;&#23637;&#31034;&#20102;&#20248;&#20110;&#22522;&#20110;&#20284;&#28982;&#24615;&#26041;&#27861;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.13150</link><description>&lt;p&gt;
&#20351;&#29992;&#35780;&#20998;&#35268;&#21017;&#35757;&#32451;&#29983;&#23384;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Training Survival Models using Scoring Rules
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13150
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#35780;&#20998;&#35268;&#21017;&#35757;&#32451;&#29983;&#23384;&#27169;&#22411;&#30340;&#36890;&#29992;&#26041;&#27861;&#65292;&#23558;&#20854;&#24212;&#29992;&#20110;&#21508;&#31181;&#27169;&#22411;&#31867;&#21035;&#20013;&#24182;&#19982;&#31070;&#32463;&#32593;&#32476;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#21487;&#25193;&#23637;&#30340;&#20248;&#21270;&#20363;&#31243;&#65292;&#24182;&#23637;&#31034;&#20102;&#20248;&#20110;&#22522;&#20110;&#20284;&#28982;&#24615;&#26041;&#27861;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#23384;&#20998;&#26512;&#20026;&#21508;&#20010;&#39046;&#22495;&#20013;&#37096;&#20998;&#19981;&#23436;&#25972;&#30340;&#20107;&#20214;&#21457;&#29983;&#26102;&#38388;&#25968;&#25454;&#25552;&#20379;&#20102;&#20851;&#38190;&#35265;&#35299;&#12290;&#23427;&#20063;&#26159;&#27010;&#29575;&#26426;&#22120;&#23398;&#20064;&#30340;&#19968;&#20010;&#37325;&#35201;&#31034;&#20363;&#12290;&#25105;&#20204;&#30340;&#25552;&#26696;&#20197;&#19968;&#31181;&#36890;&#29992;&#30340;&#26041;&#24335;&#21033;&#29992;&#20102;&#39044;&#27979;&#30340;&#27010;&#29575;&#24615;&#36136;&#65292;&#36890;&#36807;&#22312;&#27169;&#22411;&#25311;&#21512;&#36807;&#31243;&#20013;&#20351;&#29992;&#65288;&#21512;&#36866;&#30340;&#65289;&#35780;&#20998;&#35268;&#21017;&#32780;&#38750;&#22522;&#20110;&#20284;&#28982;&#24615;&#30340;&#20248;&#21270;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#19981;&#21516;&#30340;&#21442;&#25968;&#21270;&#21644;&#38750;&#21442;&#25968;&#21270;&#23376;&#26694;&#26550;&#65292;&#20801;&#35768;&#19981;&#21516;&#31243;&#24230;&#30340;&#28789;&#27963;&#24615;&#12290;&#23558;&#20854;&#28151;&#20837;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#23548;&#33268;&#20102;&#19968;&#20010;&#35745;&#31639;&#26377;&#25928;&#19988;&#21487;&#25193;&#23637;&#30340;&#20248;&#21270;&#20363;&#31243;&#65292;&#20135;&#29983;&#20102;&#26368;&#20808;&#36827;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20351;&#29992;&#25105;&#20204;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#24674;&#22797;&#21508;&#31181;&#21442;&#25968;&#21270;&#27169;&#22411;&#65292;&#24182;&#35777;&#26126;&#22312;&#19982;&#22522;&#20110;&#20284;&#28982;&#24615;&#26041;&#27861;&#30340;&#27604;&#36739;&#20013;&#65292;&#20248;&#21270;&#25928;&#26524;&#21516;&#26679;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13150v1 Announce Type: new  Abstract: Survival Analysis provides critical insights for partially incomplete time-to-event data in various domains. It is also an important example of probabilistic machine learning. The probabilistic nature of the predictions can be exploited by using (proper) scoring rules in the model fitting process instead of likelihood-based optimization. Our proposal does so in a generic manner and can be used for a variety of model classes. We establish different parametric and non-parametric sub-frameworks that allow different degrees of flexibility. Incorporated into neural networks, it leads to a computationally efficient and scalable optimization routine, yielding state-of-the-art predictive performance. Finally, we show that using our framework, we can recover various parametric models and demonstrate that optimization works equally well when compared to likelihood-based methods.
&lt;/p&gt;</description></item><item><title>&#36825;&#26159;&#19968;&#31687;&#20851;&#20110;&#22312;&#32447;&#20984;&#20248;&#21270;&#30340;&#35770;&#25991;&#65292;&#20316;&#32773;&#20998;&#26512;&#20102;&#19981;&#21516;&#29615;&#22659;&#19979;&#30340;&#38382;&#39064;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#35299;&#20915;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#36716;&#21270;&#20026;&#30456;&#24212;&#30340;&#32447;&#24615;&#20248;&#21270;&#31639;&#27861;&#65292;&#24182;&#21487;&#20197;&#22312;&#38754;&#23545;&#19981;&#21516;&#31867;&#22411;&#23545;&#25163;&#26102;&#33719;&#24471;&#21487;&#27604;&#36739;&#30340;&#36951;&#25022;&#30028;&#38480;&#12290;</title><link>https://arxiv.org/abs/2402.08621</link><description>&lt;p&gt;
&#19968;&#31181;&#24191;&#20041;&#30340;&#22312;&#32447;&#20984;&#20248;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Generalized Approach to Online Convex Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08621
&lt;/p&gt;
&lt;p&gt;
&#36825;&#26159;&#19968;&#31687;&#20851;&#20110;&#22312;&#32447;&#20984;&#20248;&#21270;&#30340;&#35770;&#25991;&#65292;&#20316;&#32773;&#20998;&#26512;&#20102;&#19981;&#21516;&#29615;&#22659;&#19979;&#30340;&#38382;&#39064;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#35299;&#20915;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#36716;&#21270;&#20026;&#30456;&#24212;&#30340;&#32447;&#24615;&#20248;&#21270;&#31639;&#27861;&#65292;&#24182;&#21487;&#20197;&#22312;&#38754;&#23545;&#19981;&#21516;&#31867;&#22411;&#23545;&#25163;&#26102;&#33719;&#24471;&#21487;&#27604;&#36739;&#30340;&#36951;&#25022;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#19981;&#21516;&#29615;&#22659;&#19979;&#30340;&#22312;&#32447;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20219;&#20309;&#29992;&#20110;&#20855;&#26377;&#23436;&#20840;&#33258;&#36866;&#24212;&#23545;&#25163;&#30340;&#22312;&#32447;&#32447;&#24615;&#20248;&#21270;&#30340;&#31639;&#27861;&#37117;&#26159;&#29992;&#20110;&#22312;&#32447;&#20984;&#20248;&#21270;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#20219;&#20309;&#38656;&#35201;&#20840;&#20449;&#24687;&#21453;&#39304;&#30340;&#31639;&#27861;&#37117;&#21487;&#20197;&#36716;&#21270;&#20026;&#20855;&#26377;&#21487;&#27604;&#36739;&#30340;&#36951;&#25022;&#30028;&#38480;&#30340;&#21322;&#21305;&#37197;&#21453;&#39304;&#31639;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#20351;&#29992;&#30830;&#23450;&#24615;&#21322;&#21305;&#37197;&#21453;&#39304;&#30340;&#20840;&#33258;&#36866;&#24212;&#23545;&#25163;&#35774;&#35745;&#30340;&#31639;&#27861;&#22312;&#38754;&#23545;&#26080;&#30693;&#23545;&#25163;&#26102;&#21487;&#20197;&#20351;&#29992;&#21482;&#26377;&#38543;&#26426;&#21322;&#21305;&#37197;&#21453;&#39304;&#30340;&#31639;&#27861;&#33719;&#24471;&#30456;&#20284;&#30340;&#30028;&#38480;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#19968;&#32467;&#26524;&#25551;&#36848;&#20102;&#23558;&#19968;&#38454;&#31639;&#27861;&#36716;&#21270;&#20026;&#38646;&#38454;&#31639;&#27861;&#30340;&#36890;&#29992;&#20803;&#31639;&#27861;&#65292;&#36825;&#20123;&#31639;&#27861;&#20855;&#26377;&#21487;&#27604;&#36739;&#30340;&#36951;&#25022;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#20351;&#25105;&#20204;&#33021;&#22815;&#20998;&#26512;&#21508;&#31181;&#35774;&#32622;&#20013;&#30340;&#22312;&#32447;&#20248;&#21270;&#38382;&#39064;&#65292;&#21253;&#25324;&#20840;&#20449;&#24687;&#21453;&#39304;&#12289;&#21322;&#21305;&#37197;&#21453;&#39304;&#12289;&#38543;&#26426;&#36951;&#25022;&#12289;&#23545;&#25239;&#36951;&#25022;&#21644;&#21508;&#31181;&#24418;&#24335;&#30340;&#38750;&#24179;&#31283;&#36951;&#25022;&#12290;&#21033;&#29992;&#25105;&#20204;&#30340;&#20998;&#26512;&#32467;&#26524;&#65292;
&lt;/p&gt;
&lt;p&gt;
In this paper, we analyze the problem of online convex optimization in different settings. We show that any algorithm for online linear optimization with fully adaptive adversaries is an algorithm for online convex optimization. We also show that any such algorithm that requires full-information feedback may be transformed to an algorithm with semi-bandit feedback with comparable regret bound. We further show that algorithms that are designed for fully adaptive adversaries using deterministic semi-bandit feedback can obtain similar bounds using only stochastic semi-bandit feedback when facing oblivious adversaries. We use this to describe general meta-algorithms to convert first order algorithms to zeroth order algorithms with comparable regret bounds. Our framework allows us to analyze online optimization in various settings, such full-information feedback, bandit feedback, stochastic regret, adversarial regret and various forms of non-stationary regret. Using our analysis, we provide
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22343;&#21248;&#20998;&#24067;&#32593;&#26684;&#19978;&#20351;&#29992;&#20998;&#31867;&#27861;&#39640;&#25928;&#35745;&#31639;&#32622;&#20449;&#21306;&#38388;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#20351;&#29992;&#25903;&#25345;&#21521;&#37327;&#26426;&#20998;&#31867;&#22120;&#65292;&#23558;&#21442;&#25968;&#31354;&#38388;&#21010;&#20998;&#20026;&#20004;&#20010;&#21306;&#22495;&#65292;&#24182;&#36890;&#36807;&#35757;&#32451;&#20998;&#31867;&#22120;&#24555;&#36895;&#30830;&#23450;&#28857;&#26159;&#21542;&#22312;&#32622;&#20449;&#21306;&#38388;&#20869;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#20855;&#26377;&#39640;&#25928;&#21644;&#20934;&#30830;&#30340;&#29305;&#28857;&#12290;</title><link>http://arxiv.org/abs/2401.01804</link><description>&lt;p&gt;
&#22312;&#22343;&#21248;&#20998;&#24067;&#32593;&#26684;&#19978;&#20351;&#29992;&#20998;&#31867;&#27861;&#39640;&#25928;&#35745;&#31639;&#32622;&#20449;&#21306;&#38388;
&lt;/p&gt;
&lt;p&gt;
Efficient Computation of Confidence Sets Using Classification on Equidistributed Grids. (arXiv:2401.01804v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01804
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22343;&#21248;&#20998;&#24067;&#32593;&#26684;&#19978;&#20351;&#29992;&#20998;&#31867;&#27861;&#39640;&#25928;&#35745;&#31639;&#32622;&#20449;&#21306;&#38388;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#20351;&#29992;&#25903;&#25345;&#21521;&#37327;&#26426;&#20998;&#31867;&#22120;&#65292;&#23558;&#21442;&#25968;&#31354;&#38388;&#21010;&#20998;&#20026;&#20004;&#20010;&#21306;&#22495;&#65292;&#24182;&#36890;&#36807;&#35757;&#32451;&#20998;&#31867;&#22120;&#24555;&#36895;&#30830;&#23450;&#28857;&#26159;&#21542;&#22312;&#32622;&#20449;&#21306;&#38388;&#20869;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#20855;&#26377;&#39640;&#25928;&#21644;&#20934;&#30830;&#30340;&#29305;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32463;&#27982;&#27169;&#22411;&#20135;&#29983;&#30340;&#30697;&#19981;&#31561;&#24335;&#21487;&#20197;&#29992;&#26469;&#24418;&#25104;&#23545;&#30495;&#23454;&#21442;&#25968;&#30340;&#26816;&#39564;&#65292;&#36890;&#36807;&#23545;&#36825;&#20123;&#26816;&#39564;&#36827;&#34892;&#21453;&#28436;&#21487;&#20197;&#24471;&#20986;&#30495;&#23454;&#21442;&#25968;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#32622;&#20449;&#21306;&#38388;&#36890;&#24120;&#27809;&#26377;&#35299;&#26512;&#34920;&#36798;&#24335;&#65292;&#38656;&#35201;&#36890;&#36807;&#20445;&#30041;&#36890;&#36807;&#26816;&#39564;&#30340;&#32593;&#26684;&#28857;&#26469;&#25968;&#20540;&#35745;&#31639;&#24471;&#20986;&#32622;&#20449;&#21306;&#38388;&#12290;&#24403;&#32479;&#35745;&#37327;&#19981;&#20855;&#26377;&#28176;&#36817;&#20851;&#38190;&#24615;&#26102;&#65292;&#22312;&#21442;&#25968;&#31354;&#38388;&#30340;&#27599;&#20010;&#32593;&#26684;&#28857;&#19978;&#26500;&#24314;&#20020;&#30028;&#20540;&#22686;&#21152;&#20102;&#35745;&#31639;&#36127;&#25285;&#12290;&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#25903;&#25345;&#21521;&#37327;&#26426;&#65288;SVM&#65289;&#20998;&#31867;&#22120;&#65292;&#23558;&#35745;&#31639;&#38382;&#39064;&#36716;&#21270;&#20026;&#20998;&#31867;&#38382;&#39064;&#12290;&#20854;&#20915;&#31574;&#20989;&#25968;&#20026;&#23558;&#21442;&#25968;&#31354;&#38388;&#21010;&#20998;&#20026;&#20004;&#20010;&#21306;&#22495;&#65288;&#32622;&#20449;&#21306;&#38388;&#20869;&#37096;&#19982;&#22806;&#37096;&#65289;&#25552;&#20379;&#20102;&#26356;&#24555;&#36895;&#21644;&#26356;&#31995;&#32479;&#30340;&#26041;&#24335;&#12290;&#25105;&#20204;&#23558;&#32622;&#20449;&#21306;&#38388;&#20869;&#37096;&#30340;&#28857;&#26631;&#35760;&#20026;1&#65292;&#23558;&#22806;&#37096;&#30340;&#28857;&#26631;&#35760;&#20026;-1&#12290;&#30740;&#31350;&#20154;&#21592;&#21487;&#20197;&#22312;&#21487;&#31649;&#29702;&#30340;&#32593;&#26684;&#19978;&#35757;&#32451;SVM&#20998;&#31867;&#22120;&#65292;&#24182;&#20351;&#29992;&#35813;&#20998;&#31867;&#22120;&#30830;&#23450;&#23494;&#24230;&#26356;&#39640;&#30340;&#32593;&#26684;&#19978;&#30340;&#28857;&#26159;&#21542;&#22312;&#32622;&#20449;&#21306;&#38388;&#20869;&#12290;&#25105;&#20204;&#20570;&#20986;&#20102;&#19968;&#31995;&#21015;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Economic models produce moment inequalities, which can be used to form tests of the true parameters. Confidence sets (CS) of the true parameters are derived by inverting these tests. However, they often lack analytical expressions, necessitating a grid search to obtain the CS numerically by retaining the grid points that pass the test. When the statistic is not asymptotically pivotal, constructing the critical value for each grid point in the parameter space adds to the computational burden. In this paper, we convert the computational issue into a classification problem by using a support vector machine (SVM) classifier. Its decision function provides a faster and more systematic way of dividing the parameter space into two regions: inside vs. outside of the confidence set. We label those points in the CS as 1 and those outside as -1. Researchers can train the SVM classifier on a grid of manageable size and use it to determine whether points on denser grids are in the CS or not. We est
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37319;&#29992;&#36890;&#36135;&#32039;&#32553;&#21464;&#37327;&#26059;&#36716;&#30340;&#25311;&#21512;&#22240;&#23376;&#20998;&#26512;&#26041;&#27861;&#65292;&#22312;&#27599;&#19968;&#34892;&#19978;&#36880;&#27493;&#27714;&#35299;&#27491;&#20132;&#30697;&#38453;&#65292;&#30456;&#27604;&#20110;&#20256;&#32479;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#35745;&#31639;&#24615;&#33021;&#21644;&#28789;&#27963;&#24615;&#65292;&#24182;&#19988;&#22312;&#26356;&#24191;&#27867;&#30340;&#32972;&#26223;&#19979;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2310.10545</link><description>&lt;p&gt;
&#20248;&#21270;&#25311;&#21512;&#22240;&#23376;&#20998;&#26512;&#19982;&#36890;&#36135;&#32039;&#32553;&#21464;&#37327;&#26059;&#36716;
&lt;/p&gt;
&lt;p&gt;
Optimal vintage factor analysis with deflation varimax. (arXiv:2310.10545v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10545
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37319;&#29992;&#36890;&#36135;&#32039;&#32553;&#21464;&#37327;&#26059;&#36716;&#30340;&#25311;&#21512;&#22240;&#23376;&#20998;&#26512;&#26041;&#27861;&#65292;&#22312;&#27599;&#19968;&#34892;&#19978;&#36880;&#27493;&#27714;&#35299;&#27491;&#20132;&#30697;&#38453;&#65292;&#30456;&#27604;&#20110;&#20256;&#32479;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#35745;&#31639;&#24615;&#33021;&#21644;&#28789;&#27963;&#24615;&#65292;&#24182;&#19988;&#22312;&#26356;&#24191;&#27867;&#30340;&#32972;&#26223;&#19979;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36135;&#32039;&#32553;&#21464;&#37327;&#26059;&#36716;&#26159;&#19968;&#31181;&#37325;&#35201;&#30340;&#22240;&#23376;&#20998;&#26512;&#26041;&#27861;&#65292;&#26088;&#22312;&#39318;&#20808;&#25214;&#21040;&#21407;&#22987;&#25968;&#25454;&#30340;&#20302;&#32500;&#34920;&#31034;&#65292;&#28982;&#21518;&#23547;&#27714;&#26059;&#36716;&#65292;&#20351;&#26059;&#36716;&#21518;&#30340;&#20302;&#32500;&#34920;&#31034;&#20855;&#26377;&#31185;&#23398;&#24847;&#20041;&#12290;&#23613;&#31649;Principal Component Analysis (PCA) followed by the varimax rotation&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#25311;&#21512;&#22240;&#23376;&#20998;&#26512;&#65292;&#20294;&#30001;&#20110;varimax rotation&#38656;&#35201;&#22312;&#27491;&#20132;&#30697;&#38453;&#38598;&#21512;&#19978;&#35299;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#22240;&#27492;&#24456;&#38590;&#25552;&#20379;&#29702;&#35770;&#20445;&#35777;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36880;&#34892;&#27714;&#35299;&#27491;&#20132;&#30697;&#38453;&#30340;&#36890;&#36135;&#32039;&#32553;&#21464;&#37327;&#26059;&#36716;&#36807;&#31243;&#12290;&#38500;&#20102;&#22312;&#35745;&#31639;&#19978;&#30340;&#20248;&#21183;&#21644;&#28789;&#27963;&#24615;&#20043;&#22806;&#65292;&#25105;&#20204;&#36824;&#33021;&#22312;&#24191;&#27867;&#30340;&#32972;&#26223;&#19979;&#23545;&#25152;&#25552;&#20986;&#30340;&#36807;&#31243;&#36827;&#34892;&#23436;&#20840;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#22312;PCA&#20043;&#21518;&#37319;&#29992;&#36825;&#31181;&#26032;&#30340;varimax&#26041;&#27861;&#20316;&#20026;&#31532;&#20108;&#27493;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#20998;&#26512;&#20102;&#36825;&#20010;&#20004;&#27493;&#36807;&#31243;&#22312;&#19968;&#20010;&#26356;&#19968;&#33324;&#30340;&#22240;&#23376;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Vintage factor analysis is one important type of factor analysis that aims to first find a low-dimensional representation of the original data, and then to seek a rotation such that the rotated low-dimensional representation is scientifically meaningful. Perhaps the most widely used vintage factor analysis is the Principal Component Analysis (PCA) followed by the varimax rotation. Despite its popularity, little theoretical guarantee can be provided mainly because varimax rotation requires to solve a non-convex optimization over the set of orthogonal matrices.  In this paper, we propose a deflation varimax procedure that solves each row of an orthogonal matrix sequentially. In addition to its net computational gain and flexibility, we are able to fully establish theoretical guarantees for the proposed procedure in a broad context.  Adopting this new varimax approach as the second step after PCA, we further analyze this two step procedure under a general class of factor models. Our resul
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#31070;&#32463;&#32593;&#32476;&#21644;&#26497;&#20540;&#29702;&#35770;&#30340;EQRN&#27169;&#22411;&#65292;&#23427;&#33021;&#22815;&#22312;&#23384;&#22312;&#22797;&#26434;&#39044;&#27979;&#21464;&#37327;&#30456;&#20851;&#24615;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#22806;&#25512;&#65292;&#24182;&#19988;&#33021;&#22815;&#24212;&#29992;&#20110;&#27946;&#27700;&#39118;&#38505;&#39044;&#27979;&#20013;&#65292;&#25552;&#20379;&#19968;&#22825;&#21069;&#22238;&#24402;&#27700;&#24179;&#21644;&#36229;&#20986;&#27010;&#29575;&#30340;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2208.07590</link><description>&lt;p&gt;
&#26497;&#31471;&#20998;&#20301;&#25968;&#22238;&#24402;&#30340;&#31070;&#32463;&#32593;&#32476;&#19982;&#27946;&#27700;&#39118;&#38505;&#39044;&#27979;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Neural Networks for Extreme Quantile Regression with an Application to Forecasting of Flood Risk. (arXiv:2208.07590v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.07590
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#31070;&#32463;&#32593;&#32476;&#21644;&#26497;&#20540;&#29702;&#35770;&#30340;EQRN&#27169;&#22411;&#65292;&#23427;&#33021;&#22815;&#22312;&#23384;&#22312;&#22797;&#26434;&#39044;&#27979;&#21464;&#37327;&#30456;&#20851;&#24615;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#22806;&#25512;&#65292;&#24182;&#19988;&#33021;&#22815;&#24212;&#29992;&#20110;&#27946;&#27700;&#39118;&#38505;&#39044;&#27979;&#20013;&#65292;&#25552;&#20379;&#19968;&#22825;&#21069;&#22238;&#24402;&#27700;&#24179;&#21644;&#36229;&#20986;&#27010;&#29575;&#30340;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#26497;&#31471;&#20107;&#20214;&#30340;&#39118;&#38505;&#35780;&#20272;&#38656;&#35201;&#20934;&#30830;&#20272;&#35745;&#36229;&#20986;&#21382;&#21490;&#35266;&#27979;&#33539;&#22260;&#30340;&#39640;&#20998;&#20301;&#25968;&#12290;&#24403;&#39118;&#38505;&#20381;&#36182;&#20110;&#35266;&#27979;&#39044;&#27979;&#21464;&#37327;&#30340;&#20540;&#26102;&#65292;&#22238;&#24402;&#25216;&#26415;&#29992;&#20110;&#22312;&#39044;&#27979;&#31354;&#38388;&#20013;&#36827;&#34892;&#25554;&#20540;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;EQRN&#27169;&#22411;&#65292;&#23427;&#23558;&#31070;&#32463;&#32593;&#32476;&#21644;&#26497;&#20540;&#29702;&#35770;&#30340;&#24037;&#20855;&#32467;&#21512;&#36215;&#26469;&#65292;&#24418;&#25104;&#19968;&#31181;&#33021;&#22815;&#22312;&#22797;&#26434;&#39044;&#27979;&#21464;&#37327;&#30456;&#20851;&#24615;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#22806;&#25512;&#30340;&#26041;&#27861;&#12290;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#33258;&#28982;&#22320;&#23558;&#25968;&#25454;&#20013;&#30340;&#38468;&#21152;&#32467;&#26500;&#32435;&#20837;&#20854;&#20013;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;EQRN&#30340;&#24490;&#29615;&#29256;&#26412;&#65292;&#33021;&#22815;&#25429;&#25417;&#26102;&#38388;&#24207;&#21015;&#20013;&#22797;&#26434;&#30340;&#39034;&#24207;&#30456;&#20851;&#24615;&#12290;&#25105;&#20204;&#23558;&#36825;&#31181;&#26041;&#27861;&#24212;&#29992;&#20110;&#29790;&#22763;Aare&#27969;&#22495;&#30340;&#27946;&#27700;&#39118;&#38505;&#39044;&#27979;&#12290;&#23427;&#21033;&#29992;&#31354;&#38388;&#21644;&#26102;&#38388;&#19978;&#30340;&#22810;&#20010;&#21327;&#21464;&#37327;&#20449;&#24687;&#65292;&#25552;&#20379;&#19968;&#22825;&#21069;&#22238;&#24402;&#27700;&#24179;&#21644;&#36229;&#20986;&#27010;&#29575;&#30340;&#39044;&#27979;&#12290;&#36825;&#20010;&#36755;&#20986;&#34917;&#20805;&#20102;&#20256;&#32479;&#26497;&#20540;&#20998;&#26512;&#30340;&#38745;&#24577;&#22238;&#24402;&#27700;&#24179;&#65292;&#24182;&#19988;&#39044;&#27979;&#33021;&#22815;&#36866;&#24212;&#20998;&#24067;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Risk assessment for extreme events requires accurate estimation of high quantiles that go beyond the range of historical observations. When the risk depends on the values of observed predictors, regression techniques are used to interpolate in the predictor space. We propose the EQRN model that combines tools from neural networks and extreme value theory into a method capable of extrapolation in the presence of complex predictor dependence. Neural networks can naturally incorporate additional structure in the data. We develop a recurrent version of EQRN that is able to capture complex sequential dependence in time series. We apply this method to forecasting of flood risk in the Swiss Aare catchment. It exploits information from multiple covariates in space and time to provide one-day-ahead predictions of return levels and exceedances probabilities. This output complements the static return level from a traditional extreme value analysis and the predictions are able to adapt to distribu
&lt;/p&gt;</description></item></channel></rss>