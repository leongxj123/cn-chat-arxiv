<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#30340;&#27010;&#29575;&#26694;&#26550;&#65292;&#31216;&#20026;&#36125;&#21494;&#26031;-SINDy&#65292;&#29992;&#20110;&#20174;&#26377;&#38480;&#19988;&#22024;&#26434;&#25968;&#25454;&#20013;&#23398;&#20064;&#27491;&#30830;&#30340;&#27169;&#22411;&#26041;&#31243;&#65292;&#24182;&#19988;&#23545;&#21442;&#25968;&#20272;&#35745;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#37327;&#21270;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#29983;&#29289;&#25968;&#25454;&#21644;&#23454;&#26102;&#31995;&#32479;&#35782;&#21035;&#12290;</title><link>https://arxiv.org/abs/2402.15357</link><description>&lt;p&gt;
&#20174;&#31232;&#30095;&#19988;&#22024;&#26434;&#25968;&#25454;&#20013;&#24555;&#36895;&#35782;&#21035;&#31232;&#30095;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Rapid Bayesian identification of sparse nonlinear dynamics from scarce and noisy data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15357
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#30340;&#27010;&#29575;&#26694;&#26550;&#65292;&#31216;&#20026;&#36125;&#21494;&#26031;-SINDy&#65292;&#29992;&#20110;&#20174;&#26377;&#38480;&#19988;&#22024;&#26434;&#25968;&#25454;&#20013;&#23398;&#20064;&#27491;&#30830;&#30340;&#27169;&#22411;&#26041;&#31243;&#65292;&#24182;&#19988;&#23545;&#21442;&#25968;&#20272;&#35745;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#37327;&#21270;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#29983;&#29289;&#25968;&#25454;&#21644;&#23454;&#26102;&#31995;&#32479;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#24555;&#36895;&#30340;&#27010;&#29575;&#26694;&#26550;&#65292;&#29992;&#20110;&#35782;&#21035;&#25511;&#21046;&#35266;&#27979;&#25968;&#25454;&#21160;&#24577;&#30340;&#24494;&#20998;&#26041;&#31243;&#12290;&#25105;&#20204;&#23558;SINDy&#26041;&#27861;&#37325;&#26032;&#26500;&#24314;&#21040;&#36125;&#21494;&#26031;&#26694;&#26550;&#20013;&#65292;&#24182;&#20351;&#29992;&#39640;&#26031;&#36924;&#36817;&#26469;&#21152;&#36895;&#35745;&#31639;&#12290;&#30001;&#27492;&#20135;&#29983;&#30340;&#26041;&#27861;&#65292;&#36125;&#21494;&#26031;-SINDy&#65292;&#19981;&#20165;&#37327;&#21270;&#20102;&#21442;&#25968;&#20272;&#35745;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#32780;&#19988;&#22312;&#20174;&#26377;&#38480;&#19988;&#22024;&#26434;&#25968;&#25454;&#20013;&#23398;&#20064;&#27491;&#30830;&#27169;&#22411;&#26102;&#26356;&#21152;&#31283;&#20581;&#12290;&#36890;&#36807;&#20351;&#29992;&#21512;&#25104;&#21644;&#30495;&#23454;&#20363;&#23376;&#65292;&#22914;&#29470;&#29441;-&#37326;&#20820;&#31181;&#32676;&#21160;&#24577;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26032;&#26694;&#26550;&#22312;&#23398;&#20064;&#27491;&#30830;&#27169;&#22411;&#26041;&#31243;&#20013;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#27604;&#36739;&#20102;&#20854;&#19982;&#29616;&#26377;&#26041;&#27861;&#30340;&#35745;&#31639;&#21644;&#25968;&#25454;&#25928;&#29575;&#12290;&#30001;&#20110;&#36125;&#21494;&#26031;-SINDy&#21487;&#20197;&#24555;&#36895;&#21560;&#25910;&#25968;&#25454;&#24182;&#23545;&#22122;&#22768;&#20855;&#26377;&#31283;&#20581;&#24615;&#65292;&#22240;&#27492;&#29305;&#21035;&#36866;&#29992;&#20110;&#29983;&#29289;&#25968;&#25454;&#21644;&#25511;&#21046;&#20013;&#30340;&#23454;&#26102;&#31995;&#32479;&#35782;&#21035;&#12290;&#20854;&#27010;&#29575;&#26694;&#26550;&#36824;&#20351;&#24471;&#21487;&#20197;&#35745;&#31639;&#20449;&#24687;&#29109;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15357v1 Announce Type: cross  Abstract: We propose a fast probabilistic framework for identifying differential equations governing the dynamics of observed data. We recast the SINDy method within a Bayesian framework and use Gaussian approximations for the prior and likelihood to speed up computation. The resulting method, Bayesian-SINDy, not only quantifies uncertainty in the parameters estimated but also is more robust when learning the correct model from limited and noisy data. Using both synthetic and real-life examples such as Lynx-Hare population dynamics, we demonstrate the effectiveness of the new framework in learning correct model equations and compare its computational and data efficiency with existing methods. Because Bayesian-SINDy can quickly assimilate data and is robust against noise, it is particularly suitable for biological data and real-time system identification in control. Its probabilistic framework also enables the calculation of information entropy, 
&lt;/p&gt;</description></item><item><title>&#24605;&#32500;&#38142;&#36171;&#20104;&#21464;&#21387;&#22120;&#27169;&#22411;&#25191;&#34892;&#22266;&#26377;&#20018;&#34892;&#35745;&#31639;&#30340;&#33021;&#21147;&#65292;&#25552;&#39640;&#20102;&#21464;&#21387;&#22120;&#22312;&#31639;&#26415;&#21644;&#31526;&#21495;&#25512;&#29702;&#20219;&#21153;&#20013;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.12875</link><description>&lt;p&gt;
&#24605;&#32500;&#38142;&#28608;&#21457;&#21464;&#21387;&#22120;&#35299;&#20915;&#22266;&#26377;&#20018;&#34892;&#38382;&#39064;&#30340;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Chain of Thought Empowers Transformers to Solve Inherently Serial Problems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12875
&lt;/p&gt;
&lt;p&gt;
&#24605;&#32500;&#38142;&#36171;&#20104;&#21464;&#21387;&#22120;&#27169;&#22411;&#25191;&#34892;&#22266;&#26377;&#20018;&#34892;&#35745;&#31639;&#30340;&#33021;&#21147;&#65292;&#25552;&#39640;&#20102;&#21464;&#21387;&#22120;&#22312;&#31639;&#26415;&#21644;&#31526;&#21495;&#25512;&#29702;&#20219;&#21153;&#20013;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25351;&#23548;&#27169;&#22411;&#29983;&#25104;&#19968;&#31995;&#21015;&#20013;&#38388;&#27493;&#39588;&#65292;&#21363;&#24605;&#32500;&#38142;&#65288;CoT&#65289;&#65292;&#26159;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#31639;&#26415;&#21644;&#31526;&#21495;&#25512;&#29702;&#20219;&#21153;&#19978;&#20934;&#30830;&#24615;&#30340;&#39640;&#25928;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;CoT&#32972;&#21518;&#30340;&#26426;&#21046;&#20173;&#19981;&#28165;&#26970;&#12290;&#36825;&#39033;&#24037;&#20316;&#36890;&#36807;&#34920;&#36798;&#24615;&#30340;&#35270;&#35282;&#25552;&#20379;&#20102;&#23545;&#35299;&#30721;&#22120;&#19987;&#29992;&#21464;&#21387;&#22120;&#30340;CoT&#33021;&#21147;&#30340;&#29702;&#35770;&#29702;&#35299;&#12290;&#22312;&#27010;&#24565;&#19978;&#65292;CoT&#36171;&#20104;&#27169;&#22411;&#25191;&#34892;&#22266;&#26377;&#20018;&#34892;&#35745;&#31639;&#30340;&#33021;&#21147;&#65292;&#32780;&#36825;&#31181;&#33021;&#21147;&#22312;&#21464;&#21387;&#22120;&#20013;&#32570;&#20047;&#65292;&#29305;&#21035;&#26159;&#24403;&#28145;&#24230;&#36739;&#20302;&#26102;&#12290;&#20808;&#21069;&#30340;&#20316;&#21697;&#24050;&#32463;&#34920;&#26126;&#65292;&#22312;&#27809;&#26377;CoT&#30340;&#24773;&#20917;&#19979;&#65292;&#20855;&#26377;&#26377;&#38480;&#31934;&#24230;$\mathsf{poly}(n)$&#23884;&#20837;&#23610;&#23544;&#30340;&#24658;&#23450;&#28145;&#24230;&#21464;&#21387;&#22120;&#21482;&#33021;&#22312;$\mathsf{TC}^0$&#20013;&#35299;&#20915;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;&#20855;&#26377;&#24120;&#25968;&#20301;&#31934;&#24230;&#30340;&#24658;&#23450;&#28145;&#24230;&#21464;&#21387;&#22120;&#30340;&#26356;&#32039;&#23494;&#30340;&#34920;&#36798;&#24615;&#19978;&#30028;&#65292;&#23427;&#21482;&#33021;&#35299;&#20915;$\mathsf{AC}^0$&#20013;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12875v1 Announce Type: new  Abstract: Instructing the model to generate a sequence of intermediate steps, a.k.a., a chain of thought (CoT), is a highly effective method to improve the accuracy of large language models (LLMs) on arithmetics and symbolic reasoning tasks. However, the mechanism behind CoT remains unclear. This work provides a theoretical understanding of the power of CoT for decoder-only transformers through the lens of expressiveness. Conceptually, CoT empowers the model with the ability to perform inherently serial computation, which is otherwise lacking in transformers, especially when depth is low. Given input length $n$, previous works have shown that constant-depth transformers with finite precision $\mathsf{poly}(n)$ embedding size can only solve problems in $\mathsf{TC}^0$ without CoT. We first show an even tighter expressiveness upper bound for constant-depth transformers with constant-bit precision, which can only solve problems in $\mathsf{AC}^0$, a 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24320;&#21457;&#20102;&#19968;&#31181;&#20855;&#26377;&#31454;&#20105;&#39044;&#27979;&#21644;&#20998;&#31867;&#33021;&#21147;&#30340;&#28207;&#21475;&#36816;&#33829;&#35299;&#20915;&#26041;&#26696;&#65292;&#29992;&#20110;&#20934;&#30830;&#20272;&#35745;&#33337;&#33334;&#22312;&#28207;&#21475;&#30340;&#24635;&#26102;&#38388;&#21644;&#24310;&#36831;&#26102;&#38388;&#65292;&#22635;&#34917;&#20102;&#28207;&#21475;&#20998;&#26512;&#27169;&#22411;&#22312;&#36825;&#26041;&#38754;&#30340;&#31354;&#30333;&#65292;&#24182;&#20026;&#28023;&#20107;&#29289;&#27969;&#39046;&#22495;&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#36129;&#29486;&#12290;</title><link>http://arxiv.org/abs/2401.14498</link><description>&lt;p&gt;
&#20248;&#21270;&#28207;&#21475;&#36816;&#33829;&#30340;&#39044;&#27979;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Predictive Analysis for Optimizing Port Operations. (arXiv:2401.14498v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14498
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24320;&#21457;&#20102;&#19968;&#31181;&#20855;&#26377;&#31454;&#20105;&#39044;&#27979;&#21644;&#20998;&#31867;&#33021;&#21147;&#30340;&#28207;&#21475;&#36816;&#33829;&#35299;&#20915;&#26041;&#26696;&#65292;&#29992;&#20110;&#20934;&#30830;&#20272;&#35745;&#33337;&#33334;&#22312;&#28207;&#21475;&#30340;&#24635;&#26102;&#38388;&#21644;&#24310;&#36831;&#26102;&#38388;&#65292;&#22635;&#34917;&#20102;&#28207;&#21475;&#20998;&#26512;&#27169;&#22411;&#22312;&#36825;&#26041;&#38754;&#30340;&#31354;&#30333;&#65292;&#24182;&#20026;&#28023;&#20107;&#29289;&#27969;&#39046;&#22495;&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28023;&#36816;&#26159;&#36828;&#36317;&#31163;&#21644;&#22823;&#23447;&#36135;&#29289;&#36816;&#36755;&#30340;&#37325;&#35201;&#29289;&#27969;&#26041;&#24335;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#36816;&#36755;&#27169;&#24335;&#20013;&#22797;&#26434;&#30340;&#35268;&#21010;&#32463;&#24120;&#21463;&#21040;&#19981;&#30830;&#23450;&#24615;&#30340;&#24433;&#21709;&#65292;&#21253;&#25324;&#22825;&#27668;&#26465;&#20214;&#12289;&#36135;&#29289;&#22810;&#26679;&#24615;&#21644;&#28207;&#21475;&#21160;&#24577;&#65292;&#23548;&#33268;&#25104;&#26412;&#22686;&#21152;&#12290;&#22240;&#27492;&#65292;&#20934;&#30830;&#20272;&#35745;&#33337;&#33334;&#22312;&#28207;&#21475;&#20572;&#30041;&#30340;&#24635;&#26102;&#38388;&#21644;&#28508;&#22312;&#24310;&#36831;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#65292;&#20197;&#20415;&#22312;&#28207;&#21475;&#36816;&#33829;&#20013;&#36827;&#34892;&#26377;&#25928;&#30340;&#35268;&#21010;&#21644;&#23433;&#25490;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#24320;&#21457;&#20855;&#26377;&#31454;&#20105;&#39044;&#27979;&#21644;&#20998;&#31867;&#33021;&#21147;&#30340;&#28207;&#21475;&#36816;&#33829;&#35299;&#20915;&#26041;&#26696;&#65292;&#29992;&#20110;&#20272;&#35745;&#33337;&#33334;&#30340;&#24635;&#26102;&#38388;&#21644;&#24310;&#36831;&#26102;&#38388;&#12290;&#35813;&#30740;&#31350;&#22635;&#34917;&#20102;&#28207;&#21475;&#20998;&#26512;&#27169;&#22411;&#22312;&#33337;&#33334;&#20572;&#30041;&#21644;&#24310;&#36831;&#26102;&#38388;&#26041;&#38754;&#30340;&#37325;&#35201;&#31354;&#30333;&#65292;&#20026;&#28023;&#20107;&#29289;&#27969;&#39046;&#22495;&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#36129;&#29486;&#12290;&#25152;&#25552;&#20986;&#30340;&#35299;&#20915;&#26041;&#26696;&#26088;&#22312;&#21327;&#21161;&#28207;&#21475;&#29615;&#22659;&#19979;&#30340;&#20915;&#31574;&#21046;&#23450;&#65292;&#24182;&#39044;&#27979;&#26381;&#21153;&#24310;&#36831;&#12290;&#36890;&#36807;&#23545;&#24052;&#35199;&#28207;&#21475;&#30340;&#26696;&#20363;&#30740;&#31350;&#36827;&#34892;&#39564;&#35777;&#65292;&#21516;&#26102;&#20351;&#29992;&#29305;&#24449;&#20998;&#26512;&#26469;&#29702;&#35299;...
&lt;/p&gt;
&lt;p&gt;
Maritime transport is a pivotal logistics mode for the long-distance and bulk transportation of goods. However, the intricate planning involved in this mode is often hindered by uncertainties, including weather conditions, cargo diversity, and port dynamics, leading to increased costs. Consequently, accurately estimating vessel total (stay) time at port and potential delays becomes imperative for effective planning and scheduling in port operations. This study aims to develop a port operation solution with competitive prediction and classification capabilities for estimating vessel Total and Delay times. This research addresses a significant gap in port analysis models for vessel Stay and Delay times, offering a valuable contribution to the field of maritime logistics. The proposed solution is designed to assist decision-making in port environments and predict service delays. This is demonstrated through a case study on Brazil ports. Additionally, feature analysis is used to understand
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#23618;&#32593;&#32476;&#35757;&#32451;&#20013;&#30340;&#26089;&#26399;&#23545;&#40784;&#29616;&#35937;&#65292;&#21457;&#29616;&#22312;&#23567;&#21021;&#22987;&#21270;&#21644;&#19968;&#20010;&#38544;&#34255;&#30340;ReLU&#23618;&#32593;&#32476;&#20013;&#65292;&#31070;&#32463;&#20803;&#20250;&#22312;&#35757;&#32451;&#30340;&#26089;&#26399;&#38454;&#27573;&#21521;&#20851;&#38190;&#26041;&#21521;&#36827;&#34892;&#23545;&#40784;&#65292;&#23548;&#33268;&#32593;&#32476;&#31232;&#30095;&#34920;&#31034;&#20197;&#21450;&#26799;&#24230;&#27969;&#22312;&#25910;&#25947;&#26102;&#30340;&#38544;&#21547;&#20559;&#22909;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#31232;&#30095;&#35825;&#23548;&#30340;&#23545;&#40784;&#20063;&#20351;&#24471;&#35757;&#32451;&#30446;&#26631;&#30340;&#26368;&#23567;&#21270;&#21464;&#24471;&#22256;&#38590;&#12290;</title><link>http://arxiv.org/abs/2401.10791</link><description>&lt;p&gt;
&#20004;&#23618;&#32593;&#32476;&#35757;&#32451;&#20013;&#30340;&#26089;&#26399;&#23545;&#40784;&#26159;&#19968;&#25226;&#21452;&#20995;&#21073;
&lt;/p&gt;
&lt;p&gt;
Early alignment in two-layer networks training is a two-edged sword. (arXiv:2401.10791v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10791
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#23618;&#32593;&#32476;&#35757;&#32451;&#20013;&#30340;&#26089;&#26399;&#23545;&#40784;&#29616;&#35937;&#65292;&#21457;&#29616;&#22312;&#23567;&#21021;&#22987;&#21270;&#21644;&#19968;&#20010;&#38544;&#34255;&#30340;ReLU&#23618;&#32593;&#32476;&#20013;&#65292;&#31070;&#32463;&#20803;&#20250;&#22312;&#35757;&#32451;&#30340;&#26089;&#26399;&#38454;&#27573;&#21521;&#20851;&#38190;&#26041;&#21521;&#36827;&#34892;&#23545;&#40784;&#65292;&#23548;&#33268;&#32593;&#32476;&#31232;&#30095;&#34920;&#31034;&#20197;&#21450;&#26799;&#24230;&#27969;&#22312;&#25910;&#25947;&#26102;&#30340;&#38544;&#21547;&#20559;&#22909;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#31232;&#30095;&#35825;&#23548;&#30340;&#23545;&#40784;&#20063;&#20351;&#24471;&#35757;&#32451;&#30446;&#26631;&#30340;&#26368;&#23567;&#21270;&#21464;&#24471;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#19968;&#38454;&#20248;&#21270;&#26041;&#27861;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#26159;&#28145;&#24230;&#23398;&#20064;&#25104;&#21151;&#30340;&#26680;&#24515;&#12290;&#21021;&#22987;&#21270;&#30340;&#35268;&#27169;&#26159;&#19968;&#20010;&#20851;&#38190;&#22240;&#32032;&#65292;&#22240;&#20026;&#23567;&#30340;&#21021;&#22987;&#21270;&#36890;&#24120;&#19982;&#29305;&#24449;&#23398;&#20064;&#27169;&#24335;&#30456;&#20851;&#65292;&#22312;&#36825;&#31181;&#27169;&#24335;&#19979;&#65292;&#26799;&#24230;&#19979;&#38477;&#23545;&#31616;&#21333;&#35299;&#38544;&#21547;&#20559;&#22909;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#26089;&#26399;&#23545;&#40784;&#38454;&#27573;&#30340;&#26222;&#36941;&#21644;&#37327;&#21270;&#25551;&#36848;&#65292;&#26368;&#21021;&#30001;Maennel&#31561;&#20154;&#25552;&#20986;&#12290;&#23545;&#20110;&#23567;&#21021;&#22987;&#21270;&#21644;&#19968;&#20010;&#38544;&#34255;&#30340;ReLU&#23618;&#32593;&#32476;&#65292;&#35757;&#32451;&#21160;&#24577;&#30340;&#26089;&#26399;&#38454;&#27573;&#23548;&#33268;&#31070;&#32463;&#20803;&#21521;&#20851;&#38190;&#26041;&#21521;&#36827;&#34892;&#23545;&#40784;&#12290;&#36825;&#31181;&#23545;&#40784;&#24341;&#21457;&#20102;&#32593;&#32476;&#30340;&#31232;&#30095;&#34920;&#31034;&#65292;&#36825;&#19982;&#26799;&#24230;&#27969;&#22312;&#25910;&#25947;&#26102;&#30340;&#38544;&#21547;&#20559;&#22909;&#30452;&#25509;&#30456;&#20851;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#31232;&#30095;&#35825;&#23548;&#30340;&#23545;&#40784;&#26159;&#20197;&#22312;&#26368;&#23567;&#21270;&#35757;&#32451;&#30446;&#26631;&#26041;&#38754;&#36935;&#21040;&#22256;&#38590;&#20026;&#20195;&#20215;&#30340;&#65306;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#25968;&#25454;&#31034;&#20363;&#65292;&#20854;&#20013;&#36229;&#21442;&#25968;&#32593;&#32476;&#26080;&#27861;&#25910;&#25947;&#21040;&#20840;&#23616;&#26368;&#23567;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Training neural networks with first order optimisation methods is at the core of the empirical success of deep learning. The scale of initialisation is a crucial factor, as small initialisations are generally associated to a feature learning regime, for which gradient descent is implicitly biased towards simple solutions. This work provides a general and quantitative description of the early alignment phase, originally introduced by Maennel et al. (2018) . For small initialisation and one hidden ReLU layer networks, the early stage of the training dynamics leads to an alignment of the neurons towards key directions. This alignment induces a sparse representation of the network, which is directly related to the implicit bias of gradient flow at convergence. This sparsity inducing alignment however comes at the expense of difficulties in minimising the training objective: we also provide a simple data example for which overparameterised networks fail to converge towards global minima and
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26862;&#26519;&#20462;&#21098;&#26041;&#27861;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20860;&#39038;&#38543;&#26426;&#26862;&#26519;&#20934;&#30830;&#24615;&#21644;&#20915;&#31574;&#26641;&#21487;&#35299;&#37322;&#24615;&#30340;&#26041;&#27861;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#22823;&#22810;&#25968;&#24773;&#26223;&#19979;&#65292;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#38543;&#26426;&#26862;&#26519;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.05535</link><description>&lt;p&gt;
&#36890;&#36807;&#26862;&#26519;&#20462;&#21098;&#25552;&#39640;&#38543;&#26426;&#26862;&#26519;&#30340;&#20934;&#30830;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;
&lt;/p&gt;
&lt;p&gt;
Improving the Accuracy and Interpretability of Random Forests via Forest Pruning. (arXiv:2401.05535v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05535
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26862;&#26519;&#20462;&#21098;&#26041;&#27861;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20860;&#39038;&#38543;&#26426;&#26862;&#26519;&#20934;&#30830;&#24615;&#21644;&#20915;&#31574;&#26641;&#21487;&#35299;&#37322;&#24615;&#30340;&#26041;&#27861;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#22823;&#22810;&#25968;&#24773;&#26223;&#19979;&#65292;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#38543;&#26426;&#26862;&#26519;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25509;&#36817;&#20960;&#21313;&#24180;&#30340;&#21457;&#23637;&#20043;&#21518;&#65292;&#38543;&#26426;&#26862;&#26519;&#20173;&#28982;&#22312;&#21508;&#31181;&#23398;&#20064;&#38382;&#39064;&#20013;&#25552;&#20379;&#26368;&#20808;&#36827;&#30340;&#20934;&#30830;&#24615;&#65292;&#22312;&#36825;&#26041;&#38754;&#36229;&#36234;&#20102;&#20915;&#31574;&#26641;&#29978;&#33267;&#31070;&#32463;&#32593;&#32476;&#31561;&#26367;&#20195;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#12290;&#28982;&#32780;&#65292;&#20316;&#20026;&#19968;&#31181;&#38598;&#25104;&#26041;&#27861;&#65292;&#38543;&#26426;&#26862;&#26519;&#22312;&#35299;&#37322;&#24615;&#26041;&#38754;&#24448;&#24448;&#27604;&#20915;&#31574;&#26641;&#34920;&#29616;&#19981;&#20339;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20107;&#21518;&#26041;&#27861;&#65292;&#26088;&#22312;&#20860;&#39038;&#38543;&#26426;&#26862;&#26519;&#30340;&#20934;&#30830;&#24615;&#21644;&#20915;&#31574;&#26641;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26862;&#26519;&#20462;&#21098;&#26041;&#27861;&#65292;&#20197;&#22312;&#32473;&#23450;&#30340;&#38543;&#26426;&#26862;&#26519;&#20869;&#25214;&#21040;&#26368;&#20339;&#23376;&#26862;&#26519;&#65292;&#28982;&#21518;&#22312;&#36866;&#29992;&#30340;&#24773;&#20917;&#19979;&#23558;&#36873;&#23450;&#30340;&#26641;&#21512;&#24182;&#20026;&#19968;&#26869;&#12290;&#25105;&#20204;&#30340;&#31532;&#19968;&#31181;&#26041;&#27861;&#20381;&#36182;&#20110;&#32422;&#26463;&#31351;&#20030;&#25628;&#32034;&#65292;&#32780;&#31532;&#20108;&#31181;&#26041;&#27861;&#22522;&#20110;LASSO&#26041;&#27861;&#30340;&#25913;&#36827;&#12290;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#22823;&#22810;&#25968;&#24773;&#26223;&#19979;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#20013;&#33267;&#23569;&#26377;&#19968;&#31181;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#38543;&#26426;&#26862;&#26519;&#30340;&#20934;&#30830;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Decades after their inception, random forests continue to provide state-of-the-art accuracy in a variety of learning problems, outperforming in this respect alternative machine learning algorithms such as decision trees or even neural networks. However, being an ensemble method, the one aspect where random forests tend to severely underperform decision trees is interpretability. In the present work, we propose a post-hoc approach that aims to have the best of both worlds: the accuracy of random forests and the interpretability of decision trees. To this end, we present two forest-pruning methods to find an optimal sub-forest within a given random forest, and then, when applicable, combine the selected trees into one. Our first method relies on constrained exhaustive search, while our second method is based on an adaptation of the LASSO methodology. Extensive experiments over synthetic and real world datasets show that, in the majority of scenarios, at least one of the two methods propo
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#24102;&#26377;&#26080;&#30028;&#26041;&#24046;&#30340;&#26377;&#20559;&#22122;&#22768;&#23545;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#30340;&#24433;&#21709;&#65292;&#24182;&#20171;&#32461;&#20102;&#35813;&#31639;&#27861;&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2312.02828</link><description>&lt;p&gt;
&#38543;&#26426;&#36924;&#36817;&#30340;&#25910;&#25947;&#36895;&#24230;&#65306;&#24102;&#26377;&#26080;&#30028;&#26041;&#24046;&#30340;&#26377;&#20559;&#22122;&#22768;&#21644;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Convergence Rates for Stochastic Approximation: Biased Noise with Unbounded Variance, and Applications. (arXiv:2312.02828v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.02828
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#24102;&#26377;&#26080;&#30028;&#26041;&#24046;&#30340;&#26377;&#20559;&#22122;&#22768;&#23545;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#30340;&#24433;&#21709;&#65292;&#24182;&#20171;&#32461;&#20102;&#35813;&#31639;&#27861;&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
1951&#24180;&#32599;&#23486;&#26031;&#21644;&#33707;&#27931;&#24341;&#20837;&#30340;&#38543;&#26426;&#36924;&#36817;&#65288;SA&#65289;&#31639;&#27861;&#24050;&#32463;&#25104;&#20026;&#35299;&#26041;&#31243;$\mathbf{f}({\boldsymbol{\theta}}) = \mathbf{0}$&#30340;&#26631;&#20934;&#26041;&#27861;&#65292;&#24403;&#21482;&#26377;$\mathbf{f}(\cdot)$&#30340;&#24102;&#22122;&#22768;&#27979;&#37327;&#21487;&#29992;&#26102;&#12290;&#22914;&#26524;&#23545;&#20110;&#26576;&#20010;&#20989;&#25968;$J(\cdot)$&#65292;$\mathbf{f}({\boldsymbol{\theta}}) = \nabla J({\boldsymbol{\theta}})$&#65292;&#37027;&#20040;SA&#20063;&#21487;&#20197;&#29992;&#26469;&#23547;&#25214;$J(\cdot)$&#30340;&#19968;&#20010;&#31283;&#23450;&#28857;&#12290;&#22312;&#27599;&#20010;&#26102;&#38388;$t$&#65292;&#24403;&#21069;&#30340;&#29468;&#27979;${\boldsymbol{\theta}}_t$&#36890;&#36807;&#24418;&#24335;&#20026;$\mathbf{f}({\boldsymbol{\theta}}_t) + {\boldsymbol{\xi}}_{t+1}$&#30340;&#24102;&#22122;&#22768;&#27979;&#37327;&#26356;&#26032;&#20026;${\boldsymbol{\theta}}_{t+1}$&#12290;&#22312;&#35768;&#22810;&#25991;&#29486;&#20013;&#65292;&#20551;&#35774;&#35823;&#24046;&#39033;${\boldsymbol{\xi}}_{t+1}$&#30340;&#26465;&#20214;&#22343;&#20540;&#20026;&#38646;&#65292;&#21644;/&#25110;&#32773;&#23427;&#30340;&#26465;&#20214;&#26041;&#24046;&#38543;$t$&#65288;&#32780;&#19981;&#26159;${\boldsymbol{\theta}}_t$&#65289;&#34987;&#38480;&#21046;&#12290;&#22810;&#24180;&#26469;&#65292;SA&#24050;&#32463;&#24212;&#29992;&#20110;&#21508;&#31181;&#39046;&#22495;&#65292;&#26412;&#25991;&#37325;&#28857;&#30740;&#31350;&#20854;&#20013;&#19968;&#20010;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Stochastic Approximation (SA) algorithm introduced by Robbins and Monro in 1951 has been a standard method for solving equations of the form $\mathbf{f}({\boldsymbol {\theta}}) = \mathbf{0}$, when only noisy measurements of $\mathbf{f}(\cdot)$ are available. If $\mathbf{f}({\boldsymbol {\theta}}) = \nabla J({\boldsymbol {\theta}})$ for some function $J(\cdot)$, then SA can also be used to find a stationary point of $J(\cdot)$. At each time $t$, the current guess ${\boldsymbol {\theta}}_t$ is updated to ${\boldsymbol {\theta}}_{t+1}$ using a noisy measurement of the form $\mathbf{f}({\boldsymbol {\theta}}_t) + {\boldsymbol {\xi}}_{t+1}$. In much of the literature, it is assumed that the error term ${\boldsymbol {\xi}}_{t+1}$ has zero conditional mean, and/or that its conditional variance is bounded as a function of $t$ (though not necessarily with respect to ${\boldsymbol {\theta}}_t$). Over the years, SA has been applied to a variety of areas, out of which the focus in this paper i
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20998;&#37197;&#31119;&#21033;&#30340;&#26368;&#20248;&#27835;&#30103;&#20998;&#37197;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#26681;&#25454;&#20010;&#20307;&#27835;&#30103;&#25928;&#24212;&#30340;&#26465;&#20214;&#20998;&#20301;&#25968;&#26469;&#20915;&#23450;&#27835;&#30103;&#20998;&#37197;&#65292;&#24182;&#24341;&#20837;&#20102;&#40065;&#26834;&#30340;&#26368;&#23567;&#26368;&#22823;&#21270;&#31574;&#30053;&#26469;&#35299;&#20915;&#23545;&#21453;&#20107;&#23454;&#32467;&#26524;&#32852;&#21512;&#20998;&#24067;&#30340;&#24674;&#22797;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2311.15878</link><description>&lt;p&gt;
&#20998;&#37197;&#31119;&#21033;&#30340;&#25919;&#31574;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Policy Learning with Distributional Welfare. (arXiv:2311.15878v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.15878
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20998;&#37197;&#31119;&#21033;&#30340;&#26368;&#20248;&#27835;&#30103;&#20998;&#37197;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#26681;&#25454;&#20010;&#20307;&#27835;&#30103;&#25928;&#24212;&#30340;&#26465;&#20214;&#20998;&#20301;&#25968;&#26469;&#20915;&#23450;&#27835;&#30103;&#20998;&#37197;&#65292;&#24182;&#24341;&#20837;&#20102;&#40065;&#26834;&#30340;&#26368;&#23567;&#26368;&#22823;&#21270;&#31574;&#30053;&#26469;&#35299;&#20915;&#23545;&#21453;&#20107;&#23454;&#32467;&#26524;&#32852;&#21512;&#20998;&#24067;&#30340;&#24674;&#22797;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#38024;&#23545;&#20998;&#37197;&#31119;&#21033;&#30340;&#26368;&#20248;&#27835;&#30103;&#20998;&#37197;&#31574;&#30053;&#12290;&#22823;&#37096;&#20998;&#20851;&#20110;&#27835;&#30103;&#36873;&#25321;&#30340;&#25991;&#29486;&#37117;&#32771;&#34385;&#20102;&#22522;&#20110;&#26465;&#20214;&#24179;&#22343;&#27835;&#30103;&#25928;&#24212;&#65288;ATE&#65289;&#30340;&#21151;&#21033;&#31119;&#21033;&#12290;&#34429;&#28982;&#24179;&#22343;&#31119;&#21033;&#26159;&#30452;&#35266;&#30340;&#65292;&#20294;&#22312;&#20010;&#20307;&#24322;&#36136;&#21270;&#65288;&#20363;&#22914;&#65292;&#23384;&#22312;&#31163;&#32676;&#20540;&#65289;&#24773;&#20917;&#19979;&#21487;&#33021;&#20250;&#20135;&#29983;&#19981;&#29702;&#24819;&#30340;&#20998;&#37197; - &#36825;&#27491;&#26159;&#20010;&#24615;&#21270;&#27835;&#30103;&#24341;&#20837;&#30340;&#21407;&#22240;&#20043;&#19968;&#12290;&#36825;&#20010;&#35266;&#23519;&#35753;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26681;&#25454;&#20010;&#20307;&#27835;&#30103;&#25928;&#24212;&#30340;&#26465;&#20214;&#20998;&#20301;&#25968;&#65288;QoTE&#65289;&#26469;&#20998;&#37197;&#27835;&#30103;&#30340;&#26368;&#20248;&#31574;&#30053;&#12290;&#26681;&#25454;&#20998;&#20301;&#25968;&#27010;&#29575;&#30340;&#36873;&#25321;&#65292;&#36825;&#20010;&#20934;&#21017;&#21487;&#20197;&#36866;&#24212;&#35880;&#24910;&#25110;&#31895;&#24515;&#30340;&#20915;&#31574;&#32773;&#12290;&#30830;&#23450;QoTE&#30340;&#25361;&#25112;&#22312;&#20110;&#20854;&#38656;&#35201;&#23545;&#21453;&#20107;&#23454;&#32467;&#26524;&#30340;&#32852;&#21512;&#20998;&#24067;&#26377;&#25152;&#20102;&#35299;&#65292;&#20294;&#21363;&#20351;&#20351;&#29992;&#23454;&#39564;&#25968;&#25454;&#65292;&#36890;&#24120;&#20063;&#24456;&#38590;&#24674;&#22797;&#20986;&#26469;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#40065;&#26834;&#30340;&#26368;&#23567;&#26368;&#22823;&#21270;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
In this paper, we explore optimal treatment allocation policies that target distributional welfare. Most literature on treatment choice has considered utilitarian welfare based on the conditional average treatment effect (ATE). While average welfare is intuitive, it may yield undesirable allocations especially when individuals are heterogeneous (e.g., with outliers) - the very reason individualized treatments were introduced in the first place. This observation motivates us to propose an optimal policy that allocates the treatment based on the conditional quantile of individual treatment effects (QoTE). Depending on the choice of the quantile probability, this criterion can accommodate a policymaker who is either prudent or negligent. The challenge of identifying the QoTE lies in its requirement for knowledge of the joint distribution of the counterfactual outcomes, which is generally hard to recover even with experimental data. Therefore, we introduce minimax policies that are robust 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;&#21028;&#21035;&#22120;&#24341;&#23548;&#65292;&#29992;&#20110;&#33258;&#22238;&#24402;&#25193;&#25955;&#27169;&#22411;&#30340;&#35757;&#32451;&#65292;&#36890;&#36807;&#20351;&#29992;&#26368;&#20248;&#21028;&#21035;&#22120;&#26469;&#32416;&#27491;&#39044;&#35757;&#32451;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#31639;&#27861;&#26469;&#24212;&#23545;&#20351;&#29992;&#27425;&#20248;&#21028;&#21035;&#22120;&#30340;&#24773;&#20917;&#12290;&#22312;&#29983;&#25104;&#20998;&#23376;&#22270;&#30340;&#20219;&#21153;&#20013;&#65292;&#21028;&#21035;&#22120;&#24341;&#23548;&#26377;&#21161;&#20110;&#25552;&#39640;&#29983;&#25104;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.15817</link><description>&lt;p&gt;
&#21028;&#21035;&#22120;&#24341;&#23548;&#19979;&#30340;&#33258;&#22238;&#24402;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Discriminator Guidance for Autoregressive Diffusion Models. (arXiv:2310.15817v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15817
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#21028;&#21035;&#22120;&#24341;&#23548;&#65292;&#29992;&#20110;&#33258;&#22238;&#24402;&#25193;&#25955;&#27169;&#22411;&#30340;&#35757;&#32451;&#65292;&#36890;&#36807;&#20351;&#29992;&#26368;&#20248;&#21028;&#21035;&#22120;&#26469;&#32416;&#27491;&#39044;&#35757;&#32451;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#31639;&#27861;&#26469;&#24212;&#23545;&#20351;&#29992;&#27425;&#20248;&#21028;&#21035;&#22120;&#30340;&#24773;&#20917;&#12290;&#22312;&#29983;&#25104;&#20998;&#23376;&#22270;&#30340;&#20219;&#21153;&#20013;&#65292;&#21028;&#21035;&#22120;&#24341;&#23548;&#26377;&#21161;&#20110;&#25552;&#39640;&#29983;&#25104;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#33258;&#22238;&#24402;&#25193;&#25955;&#27169;&#22411;&#20013;&#24341;&#20837;&#20102;&#21028;&#21035;&#22120;&#24341;&#23548;&#12290;&#22312;&#36830;&#32493;&#25193;&#25955;&#27169;&#22411;&#20013;&#65292;&#20351;&#29992;&#21028;&#21035;&#22120;&#24341;&#23548;&#25193;&#25955;&#36807;&#31243;&#30340;&#26041;&#27861;&#24050;&#32463;&#34987;&#20351;&#29992;&#36807;&#65292;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#22312;&#31163;&#25955;&#24773;&#20917;&#19979;&#20351;&#29992;&#21028;&#21035;&#22120;&#21644;&#39044;&#35757;&#32451;&#29983;&#25104;&#27169;&#22411;&#30340;&#26041;&#27861;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35777;&#26126;&#20351;&#29992;&#26368;&#20248;&#21028;&#21035;&#22120;&#23558;&#32416;&#27491;&#39044;&#35757;&#32451;&#27169;&#22411;&#65292;&#24182;&#33021;&#22815;&#20174;&#24213;&#23618;&#25968;&#25454;&#20998;&#24067;&#20013;&#31934;&#30830;&#37319;&#26679;&#12290;&#20854;&#27425;&#65292;&#20026;&#20102;&#24212;&#23545;&#20351;&#29992;&#27425;&#20248;&#21028;&#21035;&#22120;&#30340;&#23454;&#38469;&#24773;&#20917;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#19968;&#20010;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#29983;&#25104;&#36807;&#31243;&#20013;&#36845;&#20195;&#22320;&#23558;&#21028;&#21035;&#22120;&#30340;&#39044;&#27979;&#32435;&#20837;&#32771;&#34385;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#26041;&#27861;&#24212;&#29992;&#20110;&#29983;&#25104;&#20998;&#23376;&#22270;&#30340;&#20219;&#21153;&#65292;&#24182;&#23637;&#31034;&#20102;&#21028;&#21035;&#22120;&#30456;&#36739;&#20110;&#20165;&#20351;&#29992;&#39044;&#35757;&#32451;&#27169;&#22411;&#26102;&#30340;&#29983;&#25104;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce discriminator guidance in the setting of Autoregressive Diffusion Models. The use of a discriminator to guide a diffusion process has previously been used for continuous diffusion models, and in this work we derive ways of using a discriminator together with a pretrained generative model in the discrete case. First, we show that using an optimal discriminator will correct the pretrained model and enable exact sampling from the underlying data distribution. Second, to account for the realistic scenario of using a sub-optimal discriminator, we derive a sequential Monte Carlo algorithm which iteratively takes the predictions from the discrimiator into account during the generation process. We test these approaches on the task of generating molecular graphs and show how the discriminator improves the generative performance over using only the pretrained model.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#25968;&#25454;&#20381;&#36182;&#32806;&#21512;&#26469;&#26500;&#24314;&#29983;&#25104;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#36229;&#20998;&#36776;&#29575;&#21644;&#20462;&#22797;&#20219;&#21153;&#20013;&#30340;&#23454;&#39564;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.03725</link><description>&lt;p&gt;
&#20855;&#26377;&#25968;&#25454;&#20381;&#36182;&#32806;&#21512;&#30340;&#38543;&#26426;&#25554;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic interpolants with data-dependent couplings. (arXiv:2310.03725v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03725
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#25968;&#25454;&#20381;&#36182;&#32806;&#21512;&#26469;&#26500;&#24314;&#29983;&#25104;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#36229;&#20998;&#36776;&#29575;&#21644;&#20462;&#22797;&#20219;&#21153;&#20013;&#30340;&#23454;&#39564;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#21160;&#24577;&#27979;&#24230;&#20256;&#36755;&#21551;&#21457;&#30340;&#29983;&#25104;&#27169;&#22411;&#65288;&#22914;&#27969;&#21644;&#25193;&#25955;&#65289;&#26500;&#24314;&#20102;&#20004;&#20010;&#27010;&#29575;&#23494;&#24230;&#20043;&#38388;&#30340;&#36830;&#32493;&#26102;&#38388;&#26144;&#23556;&#12290;&#25353;&#29031;&#20256;&#32479;&#26041;&#27861;&#65292;&#20854;&#20013;&#19968;&#20010;&#26159;&#30446;&#26631;&#23494;&#24230;&#65292;&#21482;&#33021;&#36890;&#36807;&#26679;&#26412;&#35775;&#38382;&#65292;&#32780;&#21478;&#19968;&#20010;&#26159;&#31616;&#21333;&#30340;&#22522;&#30784;&#23494;&#24230;&#65292;&#19982;&#25968;&#25454;&#26080;&#20851;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#38543;&#26426;&#25554;&#20540;&#30340;&#26694;&#26550;&#65292;&#35268;&#33539;&#21270;&#20102;&#22914;&#20309;&#8220;&#32806;&#21512;&#8221;&#22522;&#26412;&#23494;&#24230;&#21644;&#30446;&#26631;&#23494;&#24230;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#23558;&#31867;&#21035;&#26631;&#31614;&#25110;&#36830;&#32493;&#23884;&#20837;&#30340;&#20449;&#24687;&#32435;&#20837;&#21040;&#26500;&#24314;&#21160;&#24577;&#20256;&#36755;&#26144;&#23556;&#30340;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#20013;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#35299;&#20915;&#31867;&#20284;&#20110;&#26631;&#20934;&#29420;&#31435;&#35774;&#32622;&#30340;&#31616;&#21333;&#24179;&#26041;&#25439;&#22833;&#22238;&#24402;&#38382;&#39064;&#26469;&#23398;&#20064;&#36825;&#20123;&#20256;&#36755;&#26144;&#23556;&#12290;&#36890;&#36807;&#36229;&#20998;&#36776;&#29575;&#21644;&#20462;&#22797;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#26500;&#24314;&#20381;&#36182;&#32806;&#21512;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative models inspired by dynamical transport of measure -- such as flows and diffusions -- construct a continuous-time map between two probability densities. Conventionally, one of these is the target density, only accessible through samples, while the other is taken as a simple base density that is data-agnostic. In this work, using the framework of stochastic interpolants, we formalize how to \textit{couple} the base and the target densities. This enables us to incorporate information about class labels or continuous embeddings to construct dynamical transport maps that serve as conditional generative models. We show that these transport maps can be learned by solving a simple square loss regression problem analogous to the standard independent setting. We demonstrate the usefulness of constructing dependent couplings in practice through experiments in super-resolution and in-painting.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#29616;&#26377;&#25216;&#26415;&#23545;&#21327;&#21464;&#37327;&#20998;&#24067;&#30340;&#38480;&#21046;&#38382;&#39064;&#12290;&#30740;&#31350;&#32773;&#20204;&#21457;&#29616;&#65292;&#29616;&#26377;&#26041;&#27861;&#22312;&#22788;&#29702;&#38750;&#39640;&#26031;&#20998;&#24067;&#12289;&#24322;&#36136;&#24615;&#35774;&#35745;&#30697;&#38453;&#21644;&#32570;&#20047;&#21487;&#38752;&#29305;&#24449;&#21327;&#26041;&#24046;&#20272;&#35745;&#26102;&#36935;&#21040;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#20182;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#21033;&#29992;&#32553;&#25918;&#30340;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#36827;&#34892;&#21435;&#20559;&#26657;&#27491;&#12290;</title><link>http://arxiv.org/abs/2309.07810</link><description>&lt;p&gt;
Spectrum-Aware Adjustment: &#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#21450;&#20854;&#22312;&#20027;&#25104;&#20998;&#22238;&#24402;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Spectrum-Aware Adjustment: A New Debiasing Framework with Applications to Principal Components Regression. (arXiv:2309.07810v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07810
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#29616;&#26377;&#25216;&#26415;&#23545;&#21327;&#21464;&#37327;&#20998;&#24067;&#30340;&#38480;&#21046;&#38382;&#39064;&#12290;&#30740;&#31350;&#32773;&#20204;&#21457;&#29616;&#65292;&#29616;&#26377;&#26041;&#27861;&#22312;&#22788;&#29702;&#38750;&#39640;&#26031;&#20998;&#24067;&#12289;&#24322;&#36136;&#24615;&#35774;&#35745;&#30697;&#38453;&#21644;&#32570;&#20047;&#21487;&#38752;&#29305;&#24449;&#21327;&#26041;&#24046;&#20272;&#35745;&#26102;&#36935;&#21040;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#20182;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#21033;&#29992;&#32553;&#25918;&#30340;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#36827;&#34892;&#21435;&#20559;&#26657;&#27491;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#29616;&#20195;&#21435;&#20559;&#25216;&#26415;&#23545;&#21327;&#21464;&#37327;&#20998;&#24067;&#30340;&#32422;&#26463;&#38382;&#39064;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#29305;&#24449;&#25968;&#21644;&#26679;&#26412;&#25968;&#37117;&#24456;&#22823;&#19988;&#30456;&#36817;&#30340;&#26222;&#36941;&#24773;&#20917;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#29616;&#20195;&#21435;&#20559;&#25216;&#26415;&#20351;&#29992;&#33258;&#30001;&#24230;&#26657;&#27491;&#26469;&#38500;&#21435;&#27491;&#21017;&#21270;&#20272;&#35745;&#37327;&#30340;&#25910;&#32553;&#20559;&#24046;&#24182;&#36827;&#34892;&#25512;&#26029;&#12290;&#28982;&#32780;&#65292;&#35813;&#26041;&#27861;&#35201;&#27714;&#35266;&#27979;&#26679;&#26412;&#26159;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#65292;&#21327;&#21464;&#37327;&#36981;&#24490;&#22343;&#20540;&#20026;&#38646;&#30340;&#39640;&#26031;&#20998;&#24067;&#65292;&#24182;&#19988;&#33021;&#22815;&#33719;&#24471;&#21487;&#38752;&#30340;&#29305;&#24449;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#12290;&#24403;&#65288;i&#65289;&#21327;&#21464;&#37327;&#20855;&#26377;&#38750;&#39640;&#26031;&#20998;&#24067;&#12289;&#37325;&#23614;&#25110;&#38750;&#23545;&#31216;&#20998;&#24067;&#65292;&#65288;ii&#65289;&#35774;&#35745;&#30697;&#38453;&#30340;&#34892;&#21576;&#24322;&#36136;&#24615;&#25110;&#23384;&#22312;&#20381;&#36182;&#24615;&#65292;&#20197;&#21450;&#65288;iii&#65289;&#32570;&#20047;&#21487;&#38752;&#30340;&#29305;&#24449;&#21327;&#26041;&#24046;&#20272;&#35745;&#26102;&#65292;&#36825;&#31181;&#26041;&#27861;&#23601;&#20250;&#36935;&#21040;&#22256;&#38590;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#20854;&#20013;&#21435;&#20559;&#26657;&#27491;&#26159;&#19968;&#27493;&#32553;&#25918;&#30340;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#65288;&#36866;&#24403;&#32553;&#25918;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new debiasing framework for high-dimensional linear regression that bypasses the restrictions on covariate distributions imposed by modern debiasing technology. We study the prevalent setting where the number of features and samples are both large and comparable. In this context, state-of-the-art debiasing technology uses a degrees-of-freedom correction to remove shrinkage bias of regularized estimators and conduct inference. However, this method requires that the observed samples are i.i.d., the covariates follow a mean zero Gaussian distribution, and reliable covariance matrix estimates for observed features are available. This approach struggles when (i) covariates are non-Gaussian with heavy tails or asymmetric distributions, (ii) rows of the design exhibit heterogeneity or dependencies, and (iii) reliable feature covariance estimates are lacking.  To address these, we develop a new strategy where the debiasing correction is a rescaled gradient descent step (suitably
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35752;&#35770;&#20102;&#25345;&#32493;&#24615;&#21516;&#35843;&#31209;&#20989;&#25968;&#22312;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#25351;&#20986;&#31209;&#20989;&#25968;&#30456;&#23545;&#20110;&#26465;&#30721;&#30340;&#20248;&#21183;&#22312;&#20110;&#26356;&#26131;&#20110;&#35745;&#31639;&#65292;&#24182;&#19988;&#21487;&#20197;&#30452;&#25509;&#24212;&#29992;&#20989;&#25968;&#25968;&#25454;&#20998;&#26512;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#31209;&#20989;&#25968;&#30340;&#31283;&#23450;&#24615;&#38382;&#39064;&#23578;&#24453;&#35299;&#20915;&#12290;</title><link>http://arxiv.org/abs/2307.02904</link><description>&lt;p&gt;
&#21487;&#35745;&#31639;&#30340;&#31283;&#23450;&#24615;&#23545;&#20110;&#25345;&#32493;&#24615;&#31209;&#20989;&#25968;&#26426;&#22120;&#23398;&#20064;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Computable Stability for Persistence Rank Function Machine Learning. (arXiv:2307.02904v1 [math.AT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02904
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#25345;&#32493;&#24615;&#21516;&#35843;&#31209;&#20989;&#25968;&#22312;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#25351;&#20986;&#31209;&#20989;&#25968;&#30456;&#23545;&#20110;&#26465;&#30721;&#30340;&#20248;&#21183;&#22312;&#20110;&#26356;&#26131;&#20110;&#35745;&#31639;&#65292;&#24182;&#19988;&#21487;&#20197;&#30452;&#25509;&#24212;&#29992;&#20989;&#25968;&#25968;&#25454;&#20998;&#26512;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#31209;&#20989;&#25968;&#30340;&#31283;&#23450;&#24615;&#38382;&#39064;&#23578;&#24453;&#35299;&#20915;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25345;&#32493;&#24615;&#21516;&#35843;&#26465;&#30721;&#21644;&#22270;&#26159;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#30340;&#22522;&#30784;&#12290;&#23427;&#20204;&#22312;&#35768;&#22810;&#30495;&#23454;&#25968;&#25454;&#29615;&#22659;&#20013;&#24471;&#21040;&#24191;&#27867;&#24212;&#29992;&#65292;&#23558;&#25299;&#25169;&#20449;&#24687;&#30340;&#21464;&#21270;&#65288;&#36890;&#36807;&#32454;&#32990;&#21516;&#35843;&#27979;&#37327;&#65289;&#19982;&#25968;&#25454;&#30340;&#21464;&#21270;&#30456;&#20851;&#32852;&#65292;&#28982;&#32780;&#65292;&#30001;&#20110;&#20854;&#22797;&#26434;&#30340;&#20960;&#20309;&#32467;&#26500;&#65292;&#23427;&#20204;&#22312;&#32479;&#35745;&#29615;&#22659;&#20013;&#30340;&#20351;&#29992;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;&#25345;&#32493;&#24615;&#21516;&#35843;&#31209;&#20989;&#25968;&#8212;&#8212;&#19968;&#31181;&#34913;&#37327;&#8220;&#24418;&#29366;&#8221;&#30340;&#19981;&#21464;&#37327;&#65292;&#23427;&#22312;&#26465;&#30721;&#21644;&#25345;&#32493;&#24615;&#22270;&#20043;&#21069;&#34987;&#24341;&#20837;&#65292;&#24182;&#20197;&#26356;&#36866;&#21512;&#25968;&#25454;&#21644;&#35745;&#31639;&#30340;&#24418;&#24335;&#25429;&#25417;&#30456;&#21516;&#30340;&#20449;&#24687;&#12290;&#23588;&#20854;&#26159;&#65292;&#30001;&#20110;&#23427;&#20204;&#26159;&#20989;&#25968;&#65292;&#24403;&#25345;&#32493;&#24615;&#21516;&#35843;&#20197;&#31209;&#20989;&#25968;&#24418;&#24335;&#34920;&#31034;&#26102;&#65292;&#21487;&#20197;&#30452;&#25509;&#24212;&#29992;&#20989;&#25968;&#25968;&#25454;&#20998;&#26512;&#39046;&#22495;&#30340;&#25216;&#26415;&#65292;&#36825;&#26159;&#19968;&#31181;&#36866;&#29992;&#20110;&#20989;&#25968;&#30340;&#32479;&#35745;&#23398;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#19982;&#26465;&#30721;&#30456;&#27604;&#65292;&#31209;&#20989;&#25968;&#30340;&#21463;&#27426;&#36814;&#31243;&#24230;&#36739;&#20302;&#65292;&#22240;&#20026;&#23427;&#20204;&#38754;&#20020;&#30528;&#31283;&#23450;&#24615;&#30340;&#25361;&#25112;&#8212;&#8212;&#36825;&#26159;&#39564;&#35777;&#23427;&#20204;&#22312;&#25968;&#25454;&#20998;&#26512;&#20013;&#20351;&#29992;&#30340;&#20851;&#38190;&#24615;&#36136;&#65292;&#32780;&#36825;&#31181;&#31283;&#23450;&#24615;&#24456;&#38590;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Persistent homology barcodes and diagrams are a cornerstone of topological data analysis. Widely used in many real data settings, they relate variation in topological information (as measured by cellular homology) with variation in data, however, they are challenging to use in statistical settings due to their complex geometric structure. In this paper, we revisit the persistent homology rank function -- an invariant measure of ``shape" that was introduced before barcodes and persistence diagrams and captures the same information in a form that is more amenable to data and computation. In particular, since they are functions, techniques from functional data analysis -- a domain of statistics adapted for functions -- apply directly to persistent homology when represented by rank functions. Rank functions, however, have been less popular than barcodes because they face the challenge that stability -- a property that is crucial to validate their use in data analysis -- is difficult to gua
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;SGD-like&#31639;&#27861;&#65292;&#27880;&#20837;&#38543;&#26426;&#22122;&#22768;&#24182;&#21033;&#29992;&#20998;&#24067;&#23545;&#31216;&#24615;&#26469;&#20943;&#23569;&#26041;&#24046;&#65292;&#20197;&#23547;&#25214;&#20855;&#26377;&#20302;&#28023;&#26862;&#30697;&#38453;&#36857;&#30340;&#24179;&#22374;&#26497;&#23567;&#20540;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#25910;&#25947;&#36895;&#29575;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2306.08553</link><description>&lt;p&gt;
&#22122;&#22768;&#31283;&#23450;&#20248;&#21270;&#23545;&#20110;&#20855;&#26377;&#26368;&#20248;&#25910;&#25947;&#29575;&#30340;&#24179;&#22374;&#26497;&#23567;&#20540;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Noise Stability Optimization for Flat Minima with Optimal Convergence Rates. (arXiv:2306.08553v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08553
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;SGD-like&#31639;&#27861;&#65292;&#27880;&#20837;&#38543;&#26426;&#22122;&#22768;&#24182;&#21033;&#29992;&#20998;&#24067;&#23545;&#31216;&#24615;&#26469;&#20943;&#23569;&#26041;&#24046;&#65292;&#20197;&#23547;&#25214;&#20855;&#26377;&#20302;&#28023;&#26862;&#30697;&#38453;&#36857;&#30340;&#24179;&#22374;&#26497;&#23567;&#20540;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#25910;&#25947;&#36895;&#29575;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#36890;&#36807;&#21152;&#20837;&#21152;&#26435;&#25200;&#21160;&#26469;&#25214;&#21040;&#24179;&#22374;&#30340;&#26497;&#23567;&#20540;&#12290;&#32473;&#23450;&#19968;&#20010;&#38750;&#20984;&#20989;&#25968;$f:\mathbb{R}^d\rightarrow \mathbb{R}$&#21644;&#19968;&#20010;$d$&#32500;&#20998;&#24067;$\mathcal{P}$&#65292;&#25105;&#20204;&#25200;&#21160;$f$&#30340;&#26435;&#37325;&#65292;&#24182;&#23450;&#20041;$F(W)=\mathbb{E}[f({W+U})]$&#65292;&#20854;&#20013;$U$&#26159;&#19968;&#20010;&#20174;$\mathcal{P}$&#20013;&#38543;&#26426;&#25277;&#21462;&#30340;&#26679;&#26412;&#12290;&#36825;&#20010;&#36807;&#31243;&#36890;&#36807;$f$&#30340;&#28023;&#26862;&#30697;&#38453;&#30340;&#36857;&#26469;&#35825;&#23548;&#27491;&#21017;&#21270;&#65292;&#20197;&#36866;&#24212;&#20110;&#23567;&#30340;&#12289;&#21508;&#21521;&#21516;&#24615;&#30340;&#39640;&#26031;&#25200;&#21160;&#12290;&#22240;&#27492;&#65292;&#21152;&#26435;&#25200;&#21160;&#30340;&#20989;&#25968;&#20559;&#21521;&#20110;&#24102;&#26377;&#20302;&#28023;&#26862;&#30697;&#38453;&#36857;&#30340;&#26497;&#23567;&#20540;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31867;&#20284;&#20110;SGD&#30340;&#31639;&#27861;&#65292;&#22312;&#35745;&#31639;&#26799;&#24230;&#20043;&#21069;&#27880;&#20837;&#38543;&#26426;&#22122;&#22768;&#65292;&#21516;&#26102;&#21033;&#29992;$\mathcal{P}$&#30340;&#23545;&#31216;&#24615;&#26469;&#20943;&#23569;&#26041;&#24046;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;...
&lt;/p&gt;
&lt;p&gt;
We consider finding flat, local minimizers by adding average weight perturbations. Given a nonconvex function $f: \mathbb{R}^d \rightarrow \mathbb{R}$ and a $d$-dimensional distribution $\mathcal{P}$ which is symmetric at zero, we perturb the weight of $f$ and define $F(W) = \mathbb{E}[f({W + U})]$, where $U$ is a random sample from $\mathcal{P}$. This injection induces regularization through the Hessian trace of $f$ for small, isotropic Gaussian perturbations. Thus, the weight-perturbed function biases to minimizers with low Hessian trace. Several prior works have studied settings related to this weight-perturbed function by designing algorithms to improve generalization. Still, convergence rates are not known for finding minima under the average perturbations of the function $F$. This paper considers an SGD-like algorithm that injects random noise before computing gradients while leveraging the symmetry of $\mathcal{P}$ to reduce variance. We then provide a rigorous analysis, showing
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#25968;&#25454;&#20998;&#25104;&#25209;&#27425;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#39640;&#32500;&#36229;&#21442;&#25968;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#25552;&#20379;&#20102;&#38544;&#24335;&#27491;&#21017;&#21270;&#65292;&#36890;&#36807;&#36866;&#24403;&#30340;&#25209;&#37327;&#22823;&#23567;&#36873;&#25321;&#65292;&#31283;&#23450;&#20102;&#39118;&#38505;&#34892;&#20026;&#65292;&#28040;&#38500;&#20102;&#25554;&#20540;&#28857;&#22788;&#30340;&#33192;&#32960;&#21644;&#21452;&#23792;&#29616;&#35937;</title><link>http://arxiv.org/abs/2306.08432</link><description>&lt;p&gt;
&#25209;&#27425;&#20351;&#39640;&#32500;&#36229;&#21442;&#25968;&#32447;&#24615;&#22238;&#24402;&#30340;&#26368;&#23567;&#35268;&#33539;&#39118;&#38505;&#31283;&#23450;
&lt;/p&gt;
&lt;p&gt;
Batches Stabilize the Minimum Norm Risk in High Dimensional Overparameterized Linear Regression. (arXiv:2306.08432v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08432
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#25968;&#25454;&#20998;&#25104;&#25209;&#27425;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#39640;&#32500;&#36229;&#21442;&#25968;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#25552;&#20379;&#20102;&#38544;&#24335;&#27491;&#21017;&#21270;&#65292;&#36890;&#36807;&#36866;&#24403;&#30340;&#25209;&#37327;&#22823;&#23567;&#36873;&#25321;&#65292;&#31283;&#23450;&#20102;&#39118;&#38505;&#34892;&#20026;&#65292;&#28040;&#38500;&#20102;&#25554;&#20540;&#28857;&#22788;&#30340;&#33192;&#32960;&#21644;&#21452;&#23792;&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#25968;&#25454;&#20998;&#25104;&#25209;&#27425;&#30340;&#23398;&#20064;&#31639;&#27861;&#22312;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#24456;&#24120;&#35265;&#65292;&#36890;&#24120;&#22312;&#35745;&#31639;&#25928;&#29575;&#21644;&#24615;&#33021;&#20043;&#38388;&#25552;&#20379;&#26377;&#29992;&#30340;&#26435;&#34913;&#12290;&#26412;&#25991;&#36890;&#36807;&#20855;&#26377;&#21508;&#21521;&#21516;&#24615;&#39640;&#26031;&#29305;&#24449;&#30340;&#26368;&#23567;&#35268;&#33539;&#36229;&#21442;&#25968;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#30340;&#35270;&#35282;&#26469;&#30740;&#31350;&#25209;&#37327;&#20998;&#21306;&#30340;&#22909;&#22788;&#12290;&#25105;&#20204;&#24314;&#35758;&#26368;&#23567;&#35268;&#33539;&#20272;&#35745;&#37327;&#30340;&#33258;&#28982;&#23567;&#25209;&#37327;&#29256;&#26412;&#65292;&#24182;&#25512;&#23548;&#20986;&#20854;&#20108;&#27425;&#39118;&#38505;&#30340;&#19978;&#30028;&#65292;&#34920;&#26126;&#20854;&#19982;&#22122;&#22768;&#27700;&#24179;&#20197;&#21450;&#36807;&#24230;&#21442;&#25968;&#21270;&#27604;&#20363;&#25104;&#21453;&#27604;&#65292;&#23545;&#20110;&#26368;&#20339;&#25209;&#37327;&#22823;&#23567;&#30340;&#36873;&#25321;&#12290;&#19982;&#26368;&#23567;&#35268;&#33539;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#20855;&#26377;&#31283;&#23450;&#30340;&#39118;&#38505;&#34892;&#20026;&#65292;&#20854;&#22312;&#36807;&#24230;&#21442;&#25968;&#21270;&#27604;&#20363;&#19978;&#21333;&#35843;&#36882;&#22686;&#65292;&#28040;&#38500;&#20102;&#25554;&#20540;&#28857;&#22788;&#30340;&#33192;&#32960;&#21644;&#21452;&#23792;&#29616;&#35937;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#25209;&#22788;&#29702;&#25152;&#25552;&#20379;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#21487;&#20197;&#36890;&#36807;&#29305;&#24449;&#37325;&#21472;&#26469;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning algorithms that divide the data into batches are prevalent in many machine-learning applications, typically offering useful trade-offs between computational efficiency and performance. In this paper, we examine the benefits of batch-partitioning through the lens of a minimum-norm overparameterized linear regression model with isotropic Gaussian features. We suggest a natural small-batch version of the minimum-norm estimator, and derive an upper bound on its quadratic risk, showing it is inversely proportional to the noise level as well as to the overparameterization ratio, for the optimal choice of batch size. In contrast to minimum-norm, our estimator admits a stable risk behavior that is monotonically increasing in the overparameterization ratio, eliminating both the blowup at the interpolation point and the double-descent phenomenon. Interestingly, we observe that this implicit regularization offered by the batch partition is partially explained by feature overlap between t
&lt;/p&gt;</description></item><item><title>repliclust &#26159;&#19968;&#20010; Python &#21253;&#65292;&#29992;&#20110;&#29983;&#25104;&#20855;&#26377;&#32858;&#31867;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#65292;&#22522;&#20110;&#25968;&#25454;&#38598;&#30340;&#21407;&#22411;&#65292;&#25552;&#20379;&#20102;&#25918;&#32622;&#38598;&#32676;&#20013;&#24515;&#12289;&#37319;&#26679;&#38598;&#32676;&#24418;&#29366;&#12289;&#36873;&#25321;&#27599;&#20010;&#38598;&#32676;&#30340;&#25968;&#25454;&#28857;&#25968;&#37327;&#20197;&#21450;&#20026;&#38598;&#32676;&#20998;&#37197;&#27010;&#29575;&#20998;&#24067;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2303.14301</link><description>&lt;p&gt;
repliclust&#65306;&#32858;&#31867;&#20998;&#26512;&#30340;&#21512;&#25104;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
repliclust: Synthetic Data for Cluster Analysis. (arXiv:2303.14301v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14301
&lt;/p&gt;
&lt;p&gt;
repliclust &#26159;&#19968;&#20010; Python &#21253;&#65292;&#29992;&#20110;&#29983;&#25104;&#20855;&#26377;&#32858;&#31867;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#65292;&#22522;&#20110;&#25968;&#25454;&#38598;&#30340;&#21407;&#22411;&#65292;&#25552;&#20379;&#20102;&#25918;&#32622;&#38598;&#32676;&#20013;&#24515;&#12289;&#37319;&#26679;&#38598;&#32676;&#24418;&#29366;&#12289;&#36873;&#25321;&#27599;&#20010;&#38598;&#32676;&#30340;&#25968;&#25454;&#28857;&#25968;&#37327;&#20197;&#21450;&#20026;&#38598;&#32676;&#20998;&#37197;&#27010;&#29575;&#20998;&#24067;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102; repliclust&#65288;&#26469;&#33258;&#20110; repli-cate &#21644; clust-er&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#29983;&#25104;&#20855;&#26377;&#32858;&#31867;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#30340; Python &#21253;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#25968;&#25454;&#38598;&#30340;&#21407;&#22411;&#65292;&#21363;&#39640;&#32423;&#20960;&#20309;&#25551;&#36848;&#65292;&#29992;&#25143;&#21487;&#20197;&#20174;&#20013;&#21019;&#24314;&#35768;&#22810;&#19981;&#21516;&#30340;&#25968;&#25454;&#38598;&#65292;&#24182;&#20855;&#26377;&#25152;&#38656;&#30340;&#20960;&#20309;&#29305;&#24615;&#12290;&#25105;&#20204;&#36719;&#20214;&#30340;&#26550;&#26500;&#26159;&#27169;&#22359;&#21270;&#21644;&#38754;&#21521;&#23545;&#35937;&#30340;&#65292;&#23558;&#25968;&#25454;&#29983;&#25104;&#20998;&#35299;&#25104;&#25918;&#32622;&#38598;&#32676;&#20013;&#24515;&#30340;&#31639;&#27861;&#12289;&#37319;&#26679;&#38598;&#32676;&#24418;&#29366;&#30340;&#31639;&#27861;&#12289;&#36873;&#25321;&#27599;&#20010;&#38598;&#32676;&#30340;&#25968;&#25454;&#28857;&#25968;&#37327;&#30340;&#31639;&#27861;&#20197;&#21450;&#20026;&#38598;&#32676;&#20998;&#37197;&#27010;&#29575;&#20998;&#24067;&#30340;&#31639;&#27861;&#12290;repliclust.org &#39033;&#30446;&#32593;&#39029;&#25552;&#20379;&#20102;&#31616;&#26126;&#30340;&#29992;&#25143;&#25351;&#21335;&#21644;&#20840;&#38754;&#30340;&#25991;&#26723;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present repliclust (from repli-cate and clust-er), a Python package for generating synthetic data sets with clusters. Our approach is based on data set archetypes, high-level geometric descriptions from which the user can create many different data sets, each possessing the desired geometric characteristics. The architecture of our software is modular and object-oriented, decomposing data generation into algorithms for placing cluster centers, sampling cluster shapes, selecting the number of data points for each cluster, and assigning probability distributions to clusters. The project webpage, repliclust.org, provides a concise user guide and thorough documentation.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#24207;&#21015;&#23454;&#39564;&#30340;&#21453;&#20107;&#23454;&#25512;&#26029;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#28508;&#22312;&#22240;&#23376;&#27169;&#22411;&#65292;&#20351;&#29992;&#38750;&#21442;&#25968;&#26041;&#27861;&#23545;&#21453;&#20107;&#23454;&#22343;&#20540;&#36827;&#34892;&#20272;&#35745;&#65292;&#24182;&#24314;&#31435;&#20102;&#35823;&#24046;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2202.06891</link><description>&lt;p&gt;
&#24207;&#21015;&#23454;&#39564;&#30340;&#21453;&#20107;&#23454;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Counterfactual inference for sequential experiments. (arXiv:2202.06891v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.06891
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#24207;&#21015;&#23454;&#39564;&#30340;&#21453;&#20107;&#23454;&#25512;&#26029;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#28508;&#22312;&#22240;&#23376;&#27169;&#22411;&#65292;&#20351;&#29992;&#38750;&#21442;&#25968;&#26041;&#27861;&#23545;&#21453;&#20107;&#23454;&#22343;&#20540;&#36827;&#34892;&#20272;&#35745;&#65292;&#24182;&#24314;&#31435;&#20102;&#35823;&#24046;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#38024;&#23545;&#36830;&#32493;&#35774;&#35745;&#23454;&#39564;&#36827;&#34892;&#30340;&#20107;&#21518;&#32479;&#35745;&#25512;&#26029;&#65292;&#22312;&#27492;&#23454;&#39564;&#20013;&#65292;&#22810;&#20010;&#21333;&#20301;&#22312;&#22810;&#20010;&#26102;&#38388;&#28857;&#19978;&#20998;&#37197;&#27835;&#30103;&#65292;&#24182;&#20351;&#29992;&#38543;&#26102;&#38388;&#32780;&#36866;&#24212;&#30340;&#27835;&#30103;&#31574;&#30053;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#22312;&#23545;&#36866;&#24212;&#24615;&#27835;&#30103;&#31574;&#30053;&#20570;&#20986;&#26368;&#23569;&#30340;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#20026;&#26368;&#23567;&#21487;&#33021;&#35268;&#27169;&#30340;&#21453;&#20107;&#23454;&#22343;&#20540;&#25552;&#20379;&#25512;&#26029;&#20445;&#35777;&#65292;&#21363;&#22312;&#27599;&#20010;&#21333;&#20301;&#21644;&#27599;&#20010;&#26102;&#38388;&#19979;&#65292;&#38024;&#23545;&#19981;&#21516;&#27835;&#30103;&#30340;&#24179;&#22343;&#32467;&#26524;&#12290;&#22312;&#27809;&#26377;&#23545;&#21453;&#20107;&#23454;&#22343;&#20540;&#36827;&#34892;&#20219;&#20309;&#32467;&#26500;&#24615;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#26159;&#19981;&#21487;&#34892;&#30340;&#65292;&#22240;&#20026;&#26410;&#30693;&#21464;&#37327;&#27604;&#35266;&#23519;&#21040;&#30340;&#25968;&#25454;&#28857;&#36824;&#22810;&#12290;&#20026;&#20102;&#21462;&#24471;&#36827;&#23637;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#28508;&#22312;&#22240;&#23376;&#27169;&#22411;&#29992;&#20110;&#21453;&#20107;&#23454;&#22343;&#20540;&#19978;&#65292;&#35813;&#27169;&#22411;&#20316;&#20026;&#38750;&#21442;&#25968;&#24418;&#24335;&#30340;&#38750;&#32447;&#24615;&#28151;&#21512;&#25928;&#24212;&#27169;&#22411;&#21644;&#20197;&#21069;&#24037;&#20316;&#20013;&#32771;&#34385;&#30340;&#21452;&#32447;&#24615;&#28508;&#22312;&#22240;&#23376;&#27169;&#22411;&#30340;&#25512;&#24191;&#12290;&#25105;&#20204;&#20351;&#29992;&#38750;&#21442;&#25968;&#26041;&#27861;&#36827;&#34892;&#20272;&#35745;&#65292;&#21363;&#26368;&#36817;&#37051;&#30340;&#21464;&#20307;&#65292;&#24182;&#20026;&#27599;&#20010;&#21333;&#20301;&#21644;&#27599;&#20010;&#26102;&#38388;&#30340;&#21453;&#20107;&#23454;&#22343;&#20540;&#24314;&#31435;&#20102;&#38750;&#28176;&#36827;&#39640;&#27010;&#29575;&#35823;&#24046;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider after-study statistical inference for sequentially designed experiments wherein multiple units are assigned treatments for multiple time points using treatment policies that adapt over time. Our goal is to provide inference guarantees for the counterfactual mean at the smallest possible scale -- mean outcome under different treatments for each unit and each time -- with minimal assumptions on the adaptive treatment policy. Without any structural assumptions on the counterfactual means, this challenging task is infeasible due to more unknowns than observed data points. To make progress, we introduce a latent factor model over the counterfactual means that serves as a non-parametric generalization of the non-linear mixed effects model and the bilinear latent factor model considered in prior works. For estimation, we use a non-parametric method, namely a variant of nearest neighbors, and establish a non-asymptotic high probability error bound for the counterfactual mean for ea
&lt;/p&gt;</description></item></channel></rss>