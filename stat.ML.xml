<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#23398;&#20064;&#21033;&#29992;&#35266;&#27979;&#25968;&#25454;&#25552;&#20986;&#20102;&#19968;&#31181;&#36880;&#27493;&#21452;&#37325;&#24378;&#20581;&#26041;&#27861;&#65292;&#36890;&#36807;&#21521;&#21518;&#24402;&#32435;&#35299;&#20915;&#20102;&#26368;&#20339;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;&#30340;&#38382;&#39064;</title><link>https://arxiv.org/abs/2404.00221</link><description>&lt;p&gt;
&#21033;&#29992;&#35266;&#27979;&#25968;&#25454;&#36827;&#34892;&#24378;&#20581;&#23398;&#20064;&#20197;&#33719;&#24471;&#26368;&#20339;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
Robust Learning for Optimal Dynamic Treatment Regimes with Observational Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00221
&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#21033;&#29992;&#35266;&#27979;&#25968;&#25454;&#25552;&#20986;&#20102;&#19968;&#31181;&#36880;&#27493;&#21452;&#37325;&#24378;&#20581;&#26041;&#27861;&#65292;&#36890;&#36807;&#21521;&#21518;&#24402;&#32435;&#35299;&#20915;&#20102;&#26368;&#20339;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;&#30340;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#20844;&#20849;&#25919;&#31574;&#21644;&#21307;&#30103;&#24178;&#39044;&#28041;&#21450;&#20854;&#27835;&#30103;&#20998;&#37197;&#20013;&#30340;&#21160;&#24577;&#24615;&#65292;&#27835;&#30103;&#36890;&#24120;&#20381;&#25454;&#20808;&#21069;&#27835;&#30103;&#30340;&#21382;&#21490;&#21644;&#30456;&#20851;&#29305;&#24449;&#23545;&#27599;&#20010;&#38454;&#27573;&#30340;&#25928;&#26524;&#20855;&#26377;&#24322;&#36136;&#24615;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#32479;&#35745;&#23398;&#20064;&#26368;&#20339;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;(DTR)&#65292;&#26681;&#25454;&#20010;&#20307;&#30340;&#21382;&#21490;&#25351;&#23548;&#27599;&#20010;&#38454;&#27573;&#30340;&#26368;&#20339;&#27835;&#30103;&#20998;&#37197;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35266;&#27979;&#25968;&#25454;&#30340;&#36880;&#27493;&#21452;&#37325;&#24378;&#20581;&#26041;&#27861;&#65292;&#22312;&#39034;&#24207;&#21487;&#24573;&#30053;&#24615;&#20551;&#35774;&#19979;&#23398;&#20064;&#26368;&#20339;DTR&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#21521;&#21518;&#24402;&#32435;&#35299;&#20915;&#20102;&#39034;&#24207;&#27835;&#30103;&#20998;&#37197;&#38382;&#39064;&#65292;&#22312;&#27599;&#19968;&#27493;&#20013;&#65292;&#25105;&#20204;&#32467;&#21512;&#20542;&#21521;&#35780;&#20998;&#21644;&#34892;&#21160;&#20540;&#20989;&#25968;(Q&#20989;&#25968;)&#30340;&#20272;&#35745;&#37327;&#65292;&#26500;&#24314;&#20102;&#25919;&#31574;&#20215;&#20540;&#30340;&#22686;&#24378;&#21453;&#21521;&#27010;&#29575;&#21152;&#26435;&#20272;&#35745;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00221v1 Announce Type: cross  Abstract: Many public policies and medical interventions involve dynamics in their treatment assignments, where treatments are sequentially assigned to the same individuals across multiple stages, and the effect of treatment at each stage is usually heterogeneous with respect to the history of prior treatments and associated characteristics. We study statistical learning of optimal dynamic treatment regimes (DTRs) that guide the optimal treatment assignment for each individual at each stage based on the individual's history. We propose a step-wise doubly-robust approach to learn the optimal DTR using observational data under the assumption of sequential ignorability. The approach solves the sequential treatment assignment problem through backward induction, where, at each step, we combine estimators of propensity scores and action-value functions (Q-functions) to construct augmented inverse probability weighting estimators of values of policies 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#39640;&#32500;&#22238;&#24402;&#30340;&#33258;&#36866;&#24212;&#36801;&#31227;&#23398;&#20064;&#26041;&#27861;&#65292;&#21487;&#20197;&#26681;&#25454;&#21487;&#36801;&#31227;&#32467;&#26500;&#33258;&#36866;&#24212;&#26816;&#27979;&#21644;&#32858;&#21512;&#29305;&#24449;&#21644;&#26679;&#26412;&#30340;&#21487;&#36801;&#31227;&#32467;&#26500;&#12290;</title><link>https://arxiv.org/abs/2403.13565</link><description>&lt;p&gt;
AdaTrans&#65306;&#38024;&#23545;&#39640;&#32500;&#22238;&#24402;&#30340;&#29305;&#24449;&#33258;&#36866;&#24212;&#19982;&#26679;&#26412;&#33258;&#36866;&#24212;&#36801;&#31227;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
AdaTrans: Feature-wise and Sample-wise Adaptive Transfer Learning for High-dimensional Regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13565
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#39640;&#32500;&#22238;&#24402;&#30340;&#33258;&#36866;&#24212;&#36801;&#31227;&#23398;&#20064;&#26041;&#27861;&#65292;&#21487;&#20197;&#26681;&#25454;&#21487;&#36801;&#31227;&#32467;&#26500;&#33258;&#36866;&#24212;&#26816;&#27979;&#21644;&#32858;&#21512;&#29305;&#24449;&#21644;&#26679;&#26412;&#30340;&#21487;&#36801;&#31227;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#39640;&#32500;&#32972;&#26223;&#19979;&#30340;&#36801;&#31227;&#23398;&#20064;&#38382;&#39064;&#65292;&#22312;&#35813;&#38382;&#39064;&#20013;&#65292;&#29305;&#24449;&#32500;&#24230;&#22823;&#20110;&#26679;&#26412;&#22823;&#23567;&#12290;&#20026;&#20102;&#23398;&#20064;&#21487;&#36801;&#31227;&#30340;&#20449;&#24687;&#65292;&#35813;&#20449;&#24687;&#21487;&#33021;&#22312;&#29305;&#24449;&#25110;&#28304;&#26679;&#26412;&#20043;&#38388;&#21464;&#21270;&#65292;&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#33258;&#36866;&#24212;&#36801;&#31227;&#23398;&#20064;&#26041;&#27861;&#65292;&#21487;&#20197;&#26816;&#27979;&#21644;&#32858;&#21512;&#29305;&#24449;-wise (F-AdaTrans)&#25110;&#26679;&#26412;-wise (S-AdaTrans)&#21487;&#36801;&#31227;&#32467;&#26500;&#12290;&#25105;&#20204;&#36890;&#36807;&#37319;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#34701;&#21512;&#24809;&#32602;&#26041;&#27861;&#65292;&#32467;&#21512;&#26435;&#37325;&#65292;&#21487;&#20197;&#26681;&#25454;&#21487;&#36801;&#31227;&#32467;&#26500;&#36827;&#34892;&#35843;&#25972;&#12290;&#20026;&#20102;&#36873;&#25321;&#26435;&#37325;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#29702;&#35770;&#19978;&#24314;&#31435;&#65292;&#25968;&#25454;&#39537;&#21160;&#30340;&#36807;&#31243;&#65292;&#20351;&#24471; F-AdaTrans &#33021;&#22815;&#36873;&#25321;&#24615;&#22320;&#23558;&#21487;&#36801;&#31227;&#30340;&#20449;&#21495;&#19982;&#30446;&#26631;&#34701;&#21512;&#22312;&#19968;&#36215;&#65292;&#21516;&#26102;&#28388;&#38500;&#38750;&#21487;&#36801;&#31227;&#30340;&#20449;&#21495;&#65292;S-AdaTrans&#21017;&#21487;&#20197;&#33719;&#24471;&#27599;&#20010;&#28304;&#26679;&#26412;&#20256;&#36882;&#30340;&#20449;&#24687;&#30340;&#26368;&#20339;&#32452;&#21512;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#38750;&#28176;&#36817;&#36895;&#29575;&#65292;&#21487;&#20197;&#22312;&#29305;&#27530;&#24773;&#20917;&#19979;&#24674;&#22797;&#29616;&#26377;&#30340;&#36817;&#26368;&#23567;&#20284;&#20046;&#26368;&#20248;&#36895;&#29575;&#12290;&#25928;&#26524;&#35777;&#26126;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13565v1 Announce Type: cross  Abstract: We consider the transfer learning problem in the high dimensional setting, where the feature dimension is larger than the sample size. To learn transferable information, which may vary across features or the source samples, we propose an adaptive transfer learning method that can detect and aggregate the feature-wise (F-AdaTrans) or sample-wise (S-AdaTrans) transferable structures. We achieve this by employing a novel fused-penalty, coupled with weights that can adapt according to the transferable structure. To choose the weight, we propose a theoretically informed, data-driven procedure, enabling F-AdaTrans to selectively fuse the transferable signals with the target while filtering out non-transferable signals, and S-AdaTrans to obtain the optimal combination of information transferred from each source sample. The non-asymptotic rates are established, which recover existing near-minimax optimal rates in special cases. The effectivene
&lt;/p&gt;</description></item><item><title>&#21487;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#22312;&#29983;&#23384;&#20998;&#26512;&#20013;&#30340;&#24212;&#29992;&#20419;&#36827;&#20102;&#36879;&#26126;&#24230;&#21644;&#20844;&#24179;&#24615;&#65292;&#25581;&#31034;&#20102;&#27169;&#22411;&#30340;&#28508;&#22312;&#20559;&#35265;&#21644;&#38480;&#21046;&#65292;&#24182;&#25552;&#20379;&#20102;&#26356;&#31526;&#21512;&#25968;&#23398;&#21407;&#29702;&#30340;&#29305;&#24449;&#24433;&#21709;&#21644;&#39118;&#38505;&#22240;&#32032;&#39044;&#27979;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.10250</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#29992;&#20110;&#29983;&#23384;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Interpretable Machine Learning for Survival Analysis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10250
&lt;/p&gt;
&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#22312;&#29983;&#23384;&#20998;&#26512;&#20013;&#30340;&#24212;&#29992;&#20419;&#36827;&#20102;&#36879;&#26126;&#24230;&#21644;&#20844;&#24179;&#24615;&#65292;&#25581;&#31034;&#20102;&#27169;&#22411;&#30340;&#28508;&#22312;&#20559;&#35265;&#21644;&#38480;&#21046;&#65292;&#24182;&#25552;&#20379;&#20102;&#26356;&#31526;&#21512;&#25968;&#23398;&#21407;&#29702;&#30340;&#29305;&#24449;&#24433;&#21709;&#21644;&#39118;&#38505;&#22240;&#32032;&#39044;&#27979;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#40657;&#30418;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#20256;&#25773;&#21644;&#24555;&#36895;&#36827;&#27493;&#65292;&#21487;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#65288;IML&#65289;&#39046;&#22495;&#25110;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#22312;&#36807;&#21435;&#21313;&#24180;&#20013;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290; &#36825;&#22312;&#29983;&#23384;&#20998;&#26512;&#39046;&#22495;&#23588;&#20026;&#37325;&#35201;&#65292;&#20854;&#20013;&#37319;&#29992;IML&#25216;&#26415;&#20419;&#36827;&#20102;&#36879;&#26126;&#24230;&#12289;&#38382;&#36131;&#21046;&#21644;&#20844;&#24179;&#24615;&#65292;&#29305;&#21035;&#26159;&#22312;&#20020;&#24202;&#20915;&#31574;&#36807;&#31243;&#12289;&#26377;&#38024;&#23545;&#24615;&#30103;&#27861;&#30340;&#24320;&#21457;&#12289;&#24178;&#39044;&#25110;&#20854;&#20182;&#21307;&#23398;&#25110;&#19982;&#21307;&#30103;&#20445;&#20581;&#30456;&#20851;&#30340;&#29615;&#22659;&#20013;&#12290; &#20855;&#20307;&#26469;&#35828;&#65292;&#21487;&#35299;&#37322;&#24615;&#21487;&#20197;&#25581;&#31034;&#29983;&#23384;&#27169;&#22411;&#30340;&#28508;&#22312;&#20559;&#35265;&#21644;&#23616;&#38480;&#24615;&#65292;&#24182;&#25552;&#20379;&#26356;&#31526;&#21512;&#25968;&#23398;&#21407;&#29702;&#30340;&#26041;&#27861;&#26469;&#29702;&#35299;&#21738;&#20123;&#29305;&#24449;&#23545;&#39044;&#27979;&#26377;&#24433;&#21709;&#25110;&#26500;&#25104;&#39118;&#38505;&#22240;&#32032;&#12290; &#28982;&#32780;&#65292;&#32570;&#20047;&#21363;&#26102;&#21487;&#29992;&#30340;IML&#26041;&#27861;&#21487;&#33021;&#24050;&#32463;&#38459;&#30861;&#20102;&#21307;&#23398;&#20174;&#19994;&#32773;&#21644;&#20844;&#20849;&#21355;&#29983;&#25919;&#31574;&#21046;&#23450;&#32773;&#20805;&#20998;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10250v1 Announce Type: cross  Abstract: With the spread and rapid advancement of black box machine learning models, the field of interpretable machine learning (IML) or explainable artificial intelligence (XAI) has become increasingly important over the last decade. This is particularly relevant for survival analysis, where the adoption of IML techniques promotes transparency, accountability and fairness in sensitive areas, such as clinical decision making processes, the development of targeted therapies, interventions or in other medical or healthcare related contexts. More specifically, explainability can uncover a survival model's potential biases and limitations and provide more mathematically sound ways to understand how and which features are influential for prediction or constitute risk factors. However, the lack of readily available IML methods may have deterred medical practitioners and policy makers in public health from leveraging the full potential of machine lea
&lt;/p&gt;</description></item><item><title>RLHF&#22312;&#32771;&#34385;&#37096;&#20998;&#35266;&#23519;&#24615;&#26102;&#21487;&#33021;&#23548;&#33268;&#31574;&#30053;&#27450;&#39575;&#24615;&#22320;&#22840;&#22823;&#24615;&#33021;&#25110;&#36807;&#24230;&#36777;&#25252;&#34892;&#20026;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#25968;&#23398;&#26465;&#20214;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#24182;&#35686;&#21578;&#19981;&#35201;&#30450;&#30446;&#24212;&#29992;RLHF&#22312;&#37096;&#20998;&#21487;&#35266;&#27979;&#24773;&#20917;&#19979;&#12290;</title><link>https://arxiv.org/abs/2402.17747</link><description>&lt;p&gt;
&#24403;&#20320;&#30340;AI&#27450;&#39575;&#20320;&#65306;&#22312;&#22870;&#21169;&#23398;&#20064;&#20013;&#20154;&#31867;&#35780;&#20272;&#32773;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#30340;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;
When Your AI Deceives You: Challenges with Partial Observability of Human Evaluators in Reward Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17747
&lt;/p&gt;
&lt;p&gt;
RLHF&#22312;&#32771;&#34385;&#37096;&#20998;&#35266;&#23519;&#24615;&#26102;&#21487;&#33021;&#23548;&#33268;&#31574;&#30053;&#27450;&#39575;&#24615;&#22320;&#22840;&#22823;&#24615;&#33021;&#25110;&#36807;&#24230;&#36777;&#25252;&#34892;&#20026;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#25968;&#23398;&#26465;&#20214;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#24182;&#35686;&#21578;&#19981;&#35201;&#30450;&#30446;&#24212;&#29992;RLHF&#22312;&#37096;&#20998;&#21487;&#35266;&#27979;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#65288;RLHF&#65289;&#30340;&#36807;&#21435;&#20998;&#26512;&#20551;&#35774;&#20154;&#31867;&#23436;&#20840;&#35266;&#23519;&#21040;&#29615;&#22659;&#12290;&#24403;&#20154;&#31867;&#21453;&#39304;&#20165;&#22522;&#20110;&#37096;&#20998;&#35266;&#23519;&#26102;&#20250;&#21457;&#29983;&#20160;&#20040;&#65311;&#25105;&#20204;&#23545;&#20004;&#31181;&#22833;&#36133;&#24773;&#20917;&#36827;&#34892;&#20102;&#27491;&#24335;&#23450;&#20041;&#65306;&#27450;&#39575;&#21644;&#36807;&#24230;&#36777;&#25252;&#12290;&#36890;&#36807;&#23558;&#20154;&#31867;&#24314;&#27169;&#20026;&#23545;&#36712;&#36857;&#20449;&#24565;&#30340;Boltzmann-&#29702;&#24615;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;RLHF&#20445;&#35777;&#20250;&#23548;&#33268;&#31574;&#30053;&#27450;&#39575;&#24615;&#22320;&#22840;&#22823;&#20854;&#24615;&#33021;&#12289;&#20026;&#20102;&#30041;&#19979;&#21360;&#35937;&#32780;&#36807;&#24230;&#36777;&#25252;&#25110;&#32773;&#20004;&#32773;&#20860;&#32780;&#26377;&#20043;&#30340;&#26465;&#20214;&#12290;&#20026;&#20102;&#24110;&#21161;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25968;&#23398;&#22320;&#21051;&#30011;&#20102;&#29615;&#22659;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#22914;&#20309;&#36716;&#21270;&#20026;&#65288;&#32570;&#20047;&#65289;&#23398;&#21040;&#30340;&#22238;&#25253;&#20989;&#25968;&#20013;&#30340;&#27169;&#31946;&#24615;&#12290;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#32771;&#34385;&#29615;&#22659;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#20351;&#24471;&#22312;&#29702;&#35770;&#19978;&#21487;&#33021;&#24674;&#22797;&#22238;&#25253;&#20989;&#25968;&#21644;&#26368;&#20248;&#31574;&#30053;&#65292;&#32780;&#22312;&#20854;&#20182;&#24773;&#20917;&#19979;&#65292;&#23384;&#22312;&#19981;&#21487;&#20943;&#23569;&#30340;&#27169;&#31946;&#24615;&#12290;&#25105;&#20204;&#35686;&#21578;&#19981;&#35201;&#30450;&#30446;&#24212;&#29992;RLHF&#22312;&#37096;&#20998;&#21487;&#35266;&#27979;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17747v1 Announce Type: cross  Abstract: Past analyses of reinforcement learning from human feedback (RLHF) assume that the human fully observes the environment. What happens when human feedback is based only on partial observations? We formally define two failure cases: deception and overjustification. Modeling the human as Boltzmann-rational w.r.t. a belief over trajectories, we prove conditions under which RLHF is guaranteed to result in policies that deceptively inflate their performance, overjustify their behavior to make an impression, or both. To help address these issues, we mathematically characterize how partial observability of the environment translates into (lack of) ambiguity in the learned return function. In some cases, accounting for partial observability makes it theoretically possible to recover the return function and thus the optimal policy, while in other cases, there is irreducible ambiguity. We caution against blindly applying RLHF in partially observa
&lt;/p&gt;</description></item><item><title>&#20102;&#35299;&#31070;&#32463;&#32593;&#32476;&#20174;&#36755;&#20837;-&#26631;&#31614;&#23545;&#20013;&#25552;&#21462;&#32479;&#35745;&#20449;&#24687;&#30340;&#26426;&#21046;&#26159;&#30417;&#30563;&#23398;&#20064;&#20013;&#26368;&#37325;&#35201;&#30340;&#26410;&#35299;&#20915;&#38382;&#39064;&#20043;&#19968;&#12290;&#21069;&#20154;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#65292;&#26435;&#37325;&#30340;&#26684;&#25289;&#22982;&#30697;&#38453;&#19982;&#27169;&#22411;&#30340;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#25104;&#27491;&#27604;&#65292;&#36825;&#34987;&#31216;&#20026;&#31070;&#32463;&#29305;&#24449;&#20998;&#26512;&#65288;NFA&#65289;&#12290;&#26412;&#30740;&#31350;&#35299;&#37322;&#20102;&#36825;&#31181;&#30456;&#20851;&#24615;&#30340;&#20986;&#29616;&#65292;&#24182;&#21457;&#29616;NFA&#31561;&#20215;&#20110;&#26435;&#37325;&#30697;&#38453;&#30340;&#24038;&#22855;&#24322;&#32467;&#26500;&#19982;&#19982;&#36825;&#20123;&#26435;&#37325;&#30456;&#20851;&#30340;&#32463;&#39564;&#31070;&#32463;&#20999;&#32447;&#26680;&#30340;&#26174;&#33879;&#25104;&#20998;&#20043;&#38388;&#30340;&#23545;&#40784;&#12290;&#22312;&#26089;&#26399;&#35757;&#32451;&#38454;&#27573;&#65292;&#21487;&#20197;&#36890;&#36807;&#35299;&#26512;&#30340;&#26041;&#24335;&#39044;&#27979;NFA&#30340;&#21457;&#23637;&#36895;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.05271</link><description>&lt;p&gt;
&#26799;&#24230;&#19979;&#38477;&#24341;&#21457;&#20102;&#28145;&#24230;&#38750;&#32447;&#24615;&#32593;&#32476;&#26435;&#37325;&#19982;&#32463;&#39564;NTK&#20043;&#38388;&#30340;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Gradient descent induces alignment between weights and the empirical NTK for deep non-linear networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05271
&lt;/p&gt;
&lt;p&gt;
&#20102;&#35299;&#31070;&#32463;&#32593;&#32476;&#20174;&#36755;&#20837;-&#26631;&#31614;&#23545;&#20013;&#25552;&#21462;&#32479;&#35745;&#20449;&#24687;&#30340;&#26426;&#21046;&#26159;&#30417;&#30563;&#23398;&#20064;&#20013;&#26368;&#37325;&#35201;&#30340;&#26410;&#35299;&#20915;&#38382;&#39064;&#20043;&#19968;&#12290;&#21069;&#20154;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#65292;&#26435;&#37325;&#30340;&#26684;&#25289;&#22982;&#30697;&#38453;&#19982;&#27169;&#22411;&#30340;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#25104;&#27491;&#27604;&#65292;&#36825;&#34987;&#31216;&#20026;&#31070;&#32463;&#29305;&#24449;&#20998;&#26512;&#65288;NFA&#65289;&#12290;&#26412;&#30740;&#31350;&#35299;&#37322;&#20102;&#36825;&#31181;&#30456;&#20851;&#24615;&#30340;&#20986;&#29616;&#65292;&#24182;&#21457;&#29616;NFA&#31561;&#20215;&#20110;&#26435;&#37325;&#30697;&#38453;&#30340;&#24038;&#22855;&#24322;&#32467;&#26500;&#19982;&#19982;&#36825;&#20123;&#26435;&#37325;&#30456;&#20851;&#30340;&#32463;&#39564;&#31070;&#32463;&#20999;&#32447;&#26680;&#30340;&#26174;&#33879;&#25104;&#20998;&#20043;&#38388;&#30340;&#23545;&#40784;&#12290;&#22312;&#26089;&#26399;&#35757;&#32451;&#38454;&#27573;&#65292;&#21487;&#20197;&#36890;&#36807;&#35299;&#26512;&#30340;&#26041;&#24335;&#39044;&#27979;NFA&#30340;&#21457;&#23637;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#31070;&#32463;&#32593;&#32476;&#20174;&#36755;&#20837;-&#26631;&#31614;&#23545;&#20013;&#25552;&#21462;&#32479;&#35745;&#20449;&#24687;&#30340;&#26426;&#21046;&#26159;&#30417;&#30563;&#23398;&#20064;&#20013;&#26368;&#37325;&#35201;&#30340;&#26410;&#35299;&#20915;&#38382;&#39064;&#20043;&#19968;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#30830;&#23450;&#65292;&#22312;&#19968;&#33324;&#32467;&#26500;&#30340;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#26435;&#37325;&#30340;&#26684;&#25289;&#22982;&#30697;&#38453;&#19982;&#27169;&#22411;&#30340;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#25104;&#27491;&#27604;&#65292;&#36825;&#20010;&#35828;&#27861;&#34987;&#31216;&#20026;&#31070;&#32463;&#29305;&#24449;&#20998;&#26512;&#65288;NFA&#65289;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#25968;&#37327;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#22914;&#20309;&#30456;&#20851;&#23578;&#19981;&#28165;&#26970;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35299;&#37322;&#20102;&#36825;&#31181;&#30456;&#20851;&#24615;&#30340;&#20986;&#29616;&#12290;&#25105;&#20204;&#21457;&#29616;NFA&#31561;&#20215;&#20110;&#26435;&#37325;&#30697;&#38453;&#30340;&#24038;&#22855;&#24322;&#32467;&#26500;&#19982;&#19982;&#36825;&#20123;&#26435;&#37325;&#30456;&#20851;&#30340;&#32463;&#39564;&#31070;&#32463;&#20999;&#32447;&#26680;&#30340;&#26174;&#33879;&#25104;&#20998;&#20043;&#38388;&#30340;&#23545;&#40784;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20808;&#21069;&#30740;&#31350;&#20013;&#24341;&#20837;&#30340;NFA&#26159;&#30001;&#38548;&#31163;&#36825;&#31181;&#23545;&#40784;&#30340;&#20013;&#24515;&#21270;NFA&#39537;&#21160;&#30340;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22312;&#26089;&#26399;&#35757;&#32451;&#38454;&#27573;&#65292;&#21487;&#20197;&#36890;&#36807;&#35299;&#26512;&#30340;&#26041;&#24335;&#39044;&#27979;NFA&#30340;&#21457;&#23637;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding the mechanisms through which neural networks extract statistics from input-label pairs is one of the most important unsolved problems in supervised learning. Prior works have identified that the gram matrices of the weights in trained neural networks of general architectures are proportional to the average gradient outer product of the model, in a statement known as the Neural Feature Ansatz (NFA). However, the reason these quantities become correlated during training is poorly understood. In this work, we explain the emergence of this correlation. We identify that the NFA is equivalent to alignment between the left singular structure of the weight matrices and a significant component of the empirical neural tangent kernels associated with those weights. We establish that the NFA introduced in prior works is driven by a centered NFA that isolates this alignment. We show that the speed of NFA development can be predicted analytically at early training times in terms of sim
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#21464;&#37327;&#39640;&#26031;&#36807;&#31243;&#30340;&#22810;&#28304;&#25968;&#25454;&#34701;&#21512;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#22810;&#20010;&#25968;&#25454;&#28304;&#20043;&#38388;&#36136;&#37327;&#21644;&#20840;&#38754;&#24615;&#24046;&#24322;&#32473;&#31995;&#32479;&#20248;&#21270;&#24102;&#26469;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.04146</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#22810;&#28304;&#25968;&#25454;&#34701;&#21512;&#36890;&#36807;&#28508;&#21464;&#37327;&#39640;&#26031;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Interpretable Multi-Source Data Fusion Through Latent Variable Gaussian Process
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04146
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#21464;&#37327;&#39640;&#26031;&#36807;&#31243;&#30340;&#22810;&#28304;&#25968;&#25454;&#34701;&#21512;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#22810;&#20010;&#25968;&#25454;&#28304;&#20043;&#38388;&#36136;&#37327;&#21644;&#20840;&#38754;&#24615;&#24046;&#24322;&#32473;&#31995;&#32479;&#20248;&#21270;&#24102;&#26469;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#21644;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#30340;&#20986;&#29616;&#65292;&#21508;&#20010;&#31185;&#23398;&#21644;&#24037;&#31243;&#39046;&#22495;&#24050;&#32463;&#21033;&#29992;&#25968;&#25454;&#39537;&#21160;&#30340;&#26367;&#20195;&#27169;&#22411;&#26469;&#24314;&#27169;&#26469;&#33258;&#22823;&#37327;&#20449;&#24687;&#28304;&#65288;&#25968;&#25454;&#65289;&#30340;&#22797;&#26434;&#31995;&#32479;&#12290;&#36825;&#31181;&#22686;&#21152;&#23548;&#33268;&#20102;&#24320;&#21457;&#20986;&#29992;&#20110;&#25191;&#34892;&#29305;&#23450;&#21151;&#33021;&#30340;&#20248;&#36234;&#31995;&#32479;&#25152;&#38656;&#30340;&#25104;&#26412;&#21644;&#26102;&#38388;&#30340;&#26174;&#33879;&#38477;&#20302;&#12290;&#36825;&#26679;&#30340;&#26367;&#20195;&#27169;&#22411;&#24448;&#24448;&#24191;&#27867;&#22320;&#34701;&#21512;&#22810;&#20010;&#25968;&#25454;&#26469;&#28304;&#65292;&#21487;&#33021;&#26159;&#21457;&#34920;&#30340;&#35770;&#25991;&#12289;&#19987;&#21033;&#12289;&#24320;&#25918;&#36164;&#28304;&#24211;&#25110;&#20854;&#20182;&#36164;&#28304;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#24050;&#30693;&#21644;&#26410;&#30693;&#30340;&#20449;&#24687;&#26469;&#28304;&#30340;&#22522;&#30784;&#29289;&#29702;&#21442;&#25968;&#30340;&#36136;&#37327;&#21644;&#20840;&#38754;&#24615;&#30340;&#24046;&#24322;&#65292;&#21487;&#33021;&#23545;&#31995;&#32479;&#20248;&#21270;&#36807;&#31243;&#20135;&#29983;&#21518;&#32493;&#24433;&#21709;&#65292;&#21364;&#27809;&#26377;&#24471;&#21040;&#20805;&#20998;&#30340;&#20851;&#27880;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#21464;&#37327;&#39640;&#26031;&#36807;&#31243;&#65288;LVGP&#65289;&#30340;&#22810;&#28304;&#25968;&#25454;&#34701;&#21512;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the advent of artificial intelligence (AI) and machine learning (ML), various domains of science and engineering communites has leveraged data-driven surrogates to model complex systems from numerous sources of information (data). The proliferation has led to significant reduction in cost and time involved in development of superior systems designed to perform specific functionalities. A high proposition of such surrogates are built extensively fusing multiple sources of data, may it be published papers, patents, open repositories, or other resources. However, not much attention has been paid to the differences in quality and comprehensiveness of the known and unknown underlying physical parameters of the information sources that could have downstream implications during system optimization. Towards resolving this issue, a multi-source data fusion framework based on Latent Variable Gaussian Process (LVGP) is proposed. The individual data sources are tagged as a characteristic cate
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#20915;&#31574;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#23545;&#20110;&#20219;&#20309;&#36125;&#21494;&#26031;&#22238;&#24402;&#27169;&#22411;&#65292;&#21487;&#20197;&#24471;&#21040;&#27599;&#20010;&#26465;&#20214;&#20998;&#20301;&#25968;&#30340;&#26368;&#20339;&#21644;&#21487;&#35299;&#37322;&#30340;&#32447;&#24615;&#20272;&#35745;&#20540;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#35813;&#26041;&#27861;&#26159;&#19968;&#31181;&#36866;&#29992;&#20110;&#29305;&#23450;&#20998;&#20301;&#25968;&#23376;&#38598;&#36873;&#25321;&#30340;&#26377;&#25928;&#24037;&#20855;&#12290;</title><link>http://arxiv.org/abs/2311.02043</link><description>&lt;p&gt;
&#22522;&#20110;&#23376;&#38598;&#36873;&#25321;&#30340;&#36125;&#21494;&#26031;&#20998;&#20301;&#22238;&#24402;&#65306;&#21518;&#39564;&#24635;&#32467;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Bayesian Quantile Regression with Subset Selection: A Posterior Summarization Perspective. (arXiv:2311.02043v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.02043
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#20915;&#31574;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#23545;&#20110;&#20219;&#20309;&#36125;&#21494;&#26031;&#22238;&#24402;&#27169;&#22411;&#65292;&#21487;&#20197;&#24471;&#21040;&#27599;&#20010;&#26465;&#20214;&#20998;&#20301;&#25968;&#30340;&#26368;&#20339;&#21644;&#21487;&#35299;&#37322;&#30340;&#32447;&#24615;&#20272;&#35745;&#20540;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#35813;&#26041;&#27861;&#26159;&#19968;&#31181;&#36866;&#29992;&#20110;&#29305;&#23450;&#20998;&#20301;&#25968;&#23376;&#38598;&#36873;&#25321;&#30340;&#26377;&#25928;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#20301;&#22238;&#24402;&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#24037;&#20855;&#65292;&#29992;&#20110;&#25512;&#26029;&#21327;&#21464;&#37327;&#22914;&#20309;&#24433;&#21709;&#21709;&#24212;&#20998;&#24067;&#30340;&#29305;&#23450;&#20998;&#20301;&#25968;&#12290;&#29616;&#26377;&#26041;&#27861;&#35201;&#20040;&#20998;&#21035;&#20272;&#35745;&#27599;&#20010;&#24863;&#20852;&#36259;&#20998;&#20301;&#25968;&#30340;&#26465;&#20214;&#20998;&#20301;&#25968;&#65292;&#35201;&#20040;&#20351;&#29992;&#21322;&#21442;&#25968;&#25110;&#38750;&#21442;&#25968;&#27169;&#22411;&#20272;&#35745;&#25972;&#20010;&#26465;&#20214;&#20998;&#24067;&#12290;&#21069;&#32773;&#32463;&#24120;&#20135;&#29983;&#19981;&#36866;&#21512;&#23454;&#38469;&#25968;&#25454;&#30340;&#27169;&#22411;&#65292;&#24182;&#19988;&#19981;&#22312;&#20998;&#20301;&#25968;&#20043;&#38388;&#20849;&#20139;&#20449;&#24687;&#65292;&#32780;&#21518;&#32773;&#21017;&#20197;&#22797;&#26434;&#19988;&#21463;&#38480;&#21046;&#30340;&#27169;&#22411;&#20026;&#29305;&#28857;&#65292;&#38590;&#20197;&#35299;&#37322;&#21644;&#35745;&#31639;&#25928;&#29575;&#20302;&#19979;&#12290;&#27492;&#22806;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#37117;&#19981;&#36866;&#21512;&#20110;&#29305;&#23450;&#20998;&#20301;&#25968;&#30340;&#23376;&#38598;&#36873;&#25321;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#20174;&#36125;&#21494;&#26031;&#20915;&#31574;&#20998;&#26512;&#30340;&#35282;&#24230;&#20986;&#21457;&#65292;&#25552;&#20986;&#20102;&#32447;&#24615;&#20998;&#20301;&#20272;&#35745;&#12289;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#23376;&#38598;&#36873;&#25321;&#30340;&#22522;&#26412;&#38382;&#39064;&#12290;&#23545;&#20110;&#20219;&#20309;&#36125;&#21494;&#26031;&#22238;&#24402;&#27169;&#22411;&#65292;&#25105;&#20204;&#20026;&#27599;&#20010;&#22522;&#20110;&#27169;&#22411;&#30340;&#26465;&#20214;&#20998;&#20301;&#25968;&#25512;&#23548;&#20986;&#26368;&#20339;&#21644;&#21487;&#35299;&#37322;&#30340;&#32447;&#24615;&#20272;&#35745;&#20540;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#24341;&#20837;&#20102;&#19968;&#31181;&#20998;&#20301;&#25968;&#32858;&#28966;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantile regression is a powerful tool for inferring how covariates affect specific percentiles of the response distribution. Existing methods either estimate conditional quantiles separately for each quantile of interest or estimate the entire conditional distribution using semi- or non-parametric models. The former often produce inadequate models for real data and do not share information across quantiles, while the latter are characterized by complex and constrained models that can be difficult to interpret and computationally inefficient. Further, neither approach is well-suited for quantile-specific subset selection. Instead, we pose the fundamental problems of linear quantile estimation, uncertainty quantification, and subset selection from a Bayesian decision analysis perspective. For any Bayesian regression model, we derive optimal and interpretable linear estimates and uncertainty quantification for each model-based conditional quantile. Our approach introduces a quantile-focu
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#19981;&#21487;&#30693;&#30340;&#25512;&#26029;&#26041;&#27861;&#65292;&#22312;&#37096;&#20998;&#21487;&#36776;&#35782;&#30340;&#22240;&#26524;&#20272;&#35745;&#20013;&#24212;&#29992;&#24191;&#27867;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#30340;&#23545;&#20598;&#29702;&#35770;&#65292;&#33021;&#22815;&#36866;&#24212;&#38543;&#26426;&#23454;&#39564;&#21644;&#35266;&#27979;&#30740;&#31350;&#65292;&#24182;&#19988;&#20855;&#26377;&#32479;&#19968;&#26377;&#25928;&#21644;&#21452;&#37325;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.08115</link><description>&lt;p&gt;
&#27169;&#22411;&#19981;&#21487;&#30693;&#30340;&#36741;&#21161;&#25512;&#26029;&#26041;&#27861;&#22312;&#37096;&#20998;&#21487;&#36776;&#35782;&#22240;&#26524;&#25928;&#24212;&#19978;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Model-Agnostic Covariate-Assisted Inference on Partially Identified Causal Effects. (arXiv:2310.08115v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08115
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#19981;&#21487;&#30693;&#30340;&#25512;&#26029;&#26041;&#27861;&#65292;&#22312;&#37096;&#20998;&#21487;&#36776;&#35782;&#30340;&#22240;&#26524;&#20272;&#35745;&#20013;&#24212;&#29992;&#24191;&#27867;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#30340;&#23545;&#20598;&#29702;&#35770;&#65292;&#33021;&#22815;&#36866;&#24212;&#38543;&#26426;&#23454;&#39564;&#21644;&#35266;&#27979;&#30740;&#31350;&#65292;&#24182;&#19988;&#20855;&#26377;&#32479;&#19968;&#26377;&#25928;&#21644;&#21452;&#37325;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24456;&#22810;&#22240;&#26524;&#20272;&#35745;&#26159;&#37096;&#20998;&#21487;&#36776;&#35782;&#30340;&#65292;&#22240;&#20026;&#23427;&#20204;&#20381;&#36182;&#20110;&#28508;&#22312;&#32467;&#26524;&#20043;&#38388;&#30340;&#19981;&#21487;&#35266;&#23519;&#32852;&#21512;&#20998;&#24067;&#12290;&#22522;&#20110;&#21069;&#22788;&#29702;&#21327;&#21464;&#37327;&#30340;&#20998;&#23618;&#21487;&#20197;&#33719;&#24471;&#26356;&#26126;&#30830;&#30340;&#37096;&#20998;&#21487;&#36776;&#35782;&#24615;&#33539;&#22260;&#65307;&#28982;&#32780;&#65292;&#38500;&#38750;&#21327;&#21464;&#37327;&#20026;&#31163;&#25955;&#19988;&#25903;&#25745;&#24230;&#30456;&#23545;&#36739;&#23567;&#65292;&#21542;&#21017;&#36825;&#31181;&#26041;&#27861;&#36890;&#24120;&#38656;&#35201;&#23545;&#32473;&#23450;&#21327;&#21464;&#37327;&#30340;&#28508;&#22312;&#32467;&#26524;&#30340;&#26465;&#20214;&#20998;&#24067;&#36827;&#34892;&#19968;&#33268;&#20272;&#35745;&#12290;&#22240;&#27492;&#65292;&#29616;&#26377;&#30340;&#26041;&#27861;&#22312;&#27169;&#22411;&#38169;&#35823;&#25110;&#19968;&#33268;&#24615;&#20551;&#35774;&#34987;&#36829;&#21453;&#26102;&#21487;&#33021;&#22833;&#36133;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#30340;&#23545;&#20598;&#29702;&#35770;&#30340;&#32479;&#19968;&#19988;&#27169;&#22411;&#19981;&#21487;&#30693;&#30340;&#25512;&#26029;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#24191;&#27867;&#31867;&#21035;&#30340;&#37096;&#20998;&#21487;&#36776;&#35782;&#20272;&#35745;&#12290;&#22312;&#38543;&#26426;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#32467;&#21512;&#20219;&#20309;&#23545;&#26465;&#20214;&#20998;&#24067;&#30340;&#20272;&#35745;&#65292;&#24182;&#25552;&#20379;&#32479;&#19968;&#26377;&#25928;&#30340;&#25512;&#26029;&#65292;&#21363;&#20351;&#21021;&#22987;&#20272;&#35745;&#26159;&#20219;&#24847;&#19981;&#20934;&#30830;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#35266;&#27979;&#30740;&#31350;&#20013;&#20063;&#26159;&#21452;&#37325;&#40065;&#26834;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many causal estimands are only partially identifiable since they depend on the unobservable joint distribution between potential outcomes. Stratification on pretreatment covariates can yield sharper partial identification bounds; however, unless the covariates are discrete with relatively small support, this approach typically requires consistent estimation of the conditional distributions of the potential outcomes given the covariates. Thus, existing approaches may fail under model misspecification or if consistency assumptions are violated. In this study, we propose a unified and model-agnostic inferential approach for a wide class of partially identified estimands, based on duality theory for optimal transport problems. In randomized experiments, our approach can wrap around any estimates of the conditional distributions and provide uniformly valid inference, even if the initial estimates are arbitrarily inaccurate. Also, our approach is doubly robust in observational studies. Notab
&lt;/p&gt;</description></item><item><title>MaGNet&#26159;&#19968;&#31181;&#27169;&#22411;&#26080;&#20851;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#65292;&#33021;&#22815;&#39034;&#24207;&#22320;&#25972;&#21512;&#19981;&#21516;&#39034;&#24207;&#30340;&#20449;&#24687;&#65292;&#24182;&#36890;&#36807;&#35782;&#21035;&#26377;&#24433;&#21709;&#21147;&#30340;&#32039;&#20945;&#22270;&#32467;&#26500;&#25552;&#20379;&#26377;&#24847;&#20041;&#19988;&#21487;&#35299;&#37322;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2309.13459</link><description>&lt;p&gt;
&#27169;&#22411;&#26080;&#20851;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#25972;&#21512;&#23616;&#37096;&#21644;&#20840;&#23616;&#20449;&#24687;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A Model-Agnostic Graph Neural Network for Integrating Local and Global Information. (arXiv:2309.13459v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13459
&lt;/p&gt;
&lt;p&gt;
MaGNet&#26159;&#19968;&#31181;&#27169;&#22411;&#26080;&#20851;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#65292;&#33021;&#22815;&#39034;&#24207;&#22320;&#25972;&#21512;&#19981;&#21516;&#39034;&#24207;&#30340;&#20449;&#24687;&#65292;&#24182;&#36890;&#36807;&#35782;&#21035;&#26377;&#24433;&#21709;&#21147;&#30340;&#32039;&#20945;&#22270;&#32467;&#26500;&#25552;&#20379;&#26377;&#24847;&#20041;&#19988;&#21487;&#35299;&#37322;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#22312;&#21508;&#31181;&#20197;&#22270;&#20026;&#37325;&#28857;&#30340;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#20196;&#20154;&#28385;&#24847;&#30340;&#24615;&#33021;&#12290;&#23613;&#31649;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#29616;&#26377;&#30340;GNN&#23384;&#22312;&#20004;&#20010;&#37325;&#35201;&#38480;&#21046;&#65306;&#30001;&#20110;&#40657;&#30418;&#29305;&#24615;&#65292;&#32467;&#26524;&#32570;&#20047;&#21487;&#35299;&#37322;&#24615;&#65307;&#26080;&#27861;&#23398;&#20064;&#19981;&#21516;&#39034;&#24207;&#30340;&#34920;&#31034;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;&#26080;&#20851;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;MaGNet&#65289;&#26694;&#26550;&#65292;&#33021;&#22815;&#39034;&#24207;&#22320;&#25972;&#21512;&#19981;&#21516;&#39034;&#24207;&#30340;&#20449;&#24687;&#65292;&#20174;&#39640;&#38454;&#37051;&#23621;&#20013;&#25552;&#21462;&#30693;&#35782;&#65292;&#24182;&#36890;&#36807;&#35782;&#21035;&#26377;&#24433;&#21709;&#21147;&#30340;&#32039;&#20945;&#22270;&#32467;&#26500;&#25552;&#20379;&#26377;&#24847;&#20041;&#19988;&#21487;&#35299;&#37322;&#30340;&#32467;&#26524;&#12290;&#29305;&#21035;&#22320;&#65292;MaGNet&#30001;&#20004;&#20010;&#32452;&#20214;&#32452;&#25104;&#65306;&#22270;&#25299;&#25169;&#19979;&#22797;&#26434;&#20851;&#31995;&#30340;&#28508;&#22312;&#34920;&#31034;&#30340;&#20272;&#35745;&#27169;&#22411;&#21644;&#35782;&#21035;&#26377;&#24433;&#21709;&#21147;&#30340;&#33410;&#28857;&#12289;&#36793;&#21644;&#37325;&#35201;&#33410;&#28857;&#29305;&#24449;&#30340;&#35299;&#37322;&#27169;&#22411;&#12290;&#20174;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#36890;&#36807;&#32463;&#39564;Rademacher&#22797;&#26434;&#24230;&#24314;&#31435;&#20102;MaGNet&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#24378;&#22823;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Networks (GNNs) have achieved promising performance in a variety of graph-focused tasks. Despite their success, existing GNNs suffer from two significant limitations: a lack of interpretability in results due to their black-box nature, and an inability to learn representations of varying orders. To tackle these issues, we propose a novel Model-agnostic Graph Neural Network (MaGNet) framework, which is able to sequentially integrate information of various orders, extract knowledge from high-order neighbors, and provide meaningful and interpretable results by identifying influential compact graph structures. In particular, MaGNet consists of two components: an estimation model for the latent representation of complex relationships under graph topology, and an interpretation model that identifies influential nodes, edges, and important node features. Theoretically, we establish the generalization error bound for MaGNet via empirical Rademacher complexity, and showcase its pow
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#38750;&#21442;&#25968;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#36827;&#34892;&#22522;&#20110;&#27169;&#22411;&#30340;&#32858;&#31867;&#26102;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#65292;&#24182;&#25552;&#20986;&#20102;&#30456;&#24212;&#30340;&#32858;&#31867;&#26041;&#27861;&#12290;&#36890;&#36807;&#30740;&#31350;&#20998;&#31867;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#21644;&#32858;&#31867;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#30830;&#23450;&#20102;&#32858;&#31867;&#20219;&#21153;&#30340;&#38590;&#24230;&#12290;&#21516;&#26102;&#65292;&#22312;&#25554;&#20540;&#20998;&#31867;&#22120;&#21644;&#22312;&#32447;&#35774;&#32622;&#20013;&#30340;&#32467;&#26524;&#20063;&#24471;&#21040;&#20102;&#35777;&#26126;&#12290;&#27169;&#25311;&#23454;&#39564;&#39564;&#35777;&#20102;&#36825;&#20123;&#21457;&#29616;&#12290;</title><link>http://arxiv.org/abs/2309.12238</link><description>&lt;p&gt;
&#20351;&#29992;&#38750;&#21442;&#25968;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Model-based Clustering using Non-parametric Hidden Markov Models. (arXiv:2309.12238v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12238
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#38750;&#21442;&#25968;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#36827;&#34892;&#22522;&#20110;&#27169;&#22411;&#30340;&#32858;&#31867;&#26102;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#65292;&#24182;&#25552;&#20986;&#20102;&#30456;&#24212;&#30340;&#32858;&#31867;&#26041;&#27861;&#12290;&#36890;&#36807;&#30740;&#31350;&#20998;&#31867;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#21644;&#32858;&#31867;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#30830;&#23450;&#20102;&#32858;&#31867;&#20219;&#21153;&#30340;&#38590;&#24230;&#12290;&#21516;&#26102;&#65292;&#22312;&#25554;&#20540;&#20998;&#31867;&#22120;&#21644;&#22312;&#32447;&#35774;&#32622;&#20013;&#30340;&#32467;&#26524;&#20063;&#24471;&#21040;&#20102;&#35777;&#26126;&#12290;&#27169;&#25311;&#23454;&#39564;&#39564;&#35777;&#20102;&#36825;&#20123;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#21442;&#25968;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#65288;HMM&#65289;&#30001;&#20110;&#20854;&#20381;&#36182;&#32467;&#26500;&#65292;&#21487;&#20197;&#22312;&#19981;&#25351;&#23450;&#32676;&#32452;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#22522;&#20110;&#27169;&#22411;&#30340;&#32858;&#31867;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20351;&#29992;HMM&#36827;&#34892;&#32858;&#31867;&#26102;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#65292;&#24182;&#25552;&#20986;&#20102;&#30456;&#24212;&#30340;&#32858;&#31867;&#26041;&#27861;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#23558;&#20998;&#31867;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#19982;&#32858;&#31867;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#32852;&#31995;&#36215;&#26469;&#30340;&#32467;&#26524;&#65292;&#29992;&#20197;&#30830;&#23450;&#32858;&#31867;&#20219;&#21153;&#30340;&#38590;&#24230;&#30340;&#20851;&#38190;&#25968;&#37327;&#12290;&#25105;&#20204;&#36824;&#22312;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#26694;&#26550;&#19979;&#35777;&#26126;&#20102;&#36825;&#19968;&#32467;&#26524;&#65292;&#36825;&#21487;&#33021;&#20855;&#26377;&#29420;&#31435;&#30340;&#20852;&#36259;&#12290;&#28982;&#21518;&#25105;&#20204;&#30740;&#31350;&#20102;&#25554;&#20540;&#20998;&#31867;&#22120;&#30340;&#36807;&#24230;&#39118;&#38505;&#12290;&#25152;&#26377;&#36825;&#20123;&#32467;&#26524;&#37117;&#34987;&#35777;&#26126;&#22312;&#22312;&#32447;&#35774;&#32622;&#20013;&#20173;&#28982;&#26377;&#25928;&#65292;&#22312;&#35813;&#35774;&#32622;&#19979;&#65292;&#35266;&#27979;&#32467;&#26524;&#34987;&#39034;&#24207;&#32858;&#31867;&#12290;&#27169;&#25311;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Thanks to their dependency structure, non-parametric Hidden Markov Models (HMMs) are able to handle model-based clustering without specifying group distributions. The aim of this work is to study the Bayes risk of clustering when using HMMs and to propose associated clustering procedures. We first give a result linking the Bayes risk of classification and the Bayes risk of clustering, which we use to identify the key quantity determining the difficulty of the clustering task. We also give a proof of this result in the i.i.d. framework, which might be of independent interest. Then we study the excess risk of the plugin classifier. All these results are shown to remain valid in the online setting where observations are clustered sequentially. Simulations illustrate our findings.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#20851;&#38190;&#39046;&#22495;&#20013;&#38024;&#23545;&#40723;&#21169;&#25919;&#31574;&#30340;&#26368;&#20248;&#21644;&#20844;&#24179;&#35780;&#20272;&#20197;&#21450;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#30740;&#31350;&#21457;&#29616;&#22312;&#20154;&#31867;&#19981;&#36981;&#24490;&#27835;&#30103;&#24314;&#35758;&#30340;&#24773;&#20917;&#19979;&#65292;&#26368;&#20248;&#31574;&#30053;&#35268;&#21017;&#21482;&#26159;&#24314;&#35758;&#12290;&#21516;&#26102;&#65292;&#38024;&#23545;&#27835;&#30103;&#30340;&#24322;&#36136;&#24615;&#21644;&#20844;&#24179;&#32771;&#34385;&#22240;&#32032;&#65292;&#20915;&#31574;&#32773;&#30340;&#26435;&#34913;&#21644;&#20915;&#31574;&#35268;&#21017;&#20063;&#20250;&#21457;&#29983;&#21464;&#21270;&#12290;&#22312;&#31038;&#20250;&#26381;&#21153;&#39046;&#22495;&#65292;&#30740;&#31350;&#26174;&#31034;&#23384;&#22312;&#19968;&#20010;&#20351;&#29992;&#24046;&#36317;&#38382;&#39064;&#65292;&#37027;&#20123;&#26368;&#26377;&#21487;&#33021;&#21463;&#30410;&#30340;&#20154;&#21364;&#26080;&#27861;&#33719;&#24471;&#36825;&#20123;&#30410;&#26381;&#21153;&#12290;</title><link>http://arxiv.org/abs/2309.07176</link><description>&lt;p&gt;
&#26368;&#20248;&#21644;&#20844;&#24179;&#30340;&#40723;&#21169;&#25919;&#31574;&#35780;&#20272;&#19982;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Optimal and Fair Encouragement Policy Evaluation and Learning. (arXiv:2309.07176v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07176
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#20851;&#38190;&#39046;&#22495;&#20013;&#38024;&#23545;&#40723;&#21169;&#25919;&#31574;&#30340;&#26368;&#20248;&#21644;&#20844;&#24179;&#35780;&#20272;&#20197;&#21450;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#30740;&#31350;&#21457;&#29616;&#22312;&#20154;&#31867;&#19981;&#36981;&#24490;&#27835;&#30103;&#24314;&#35758;&#30340;&#24773;&#20917;&#19979;&#65292;&#26368;&#20248;&#31574;&#30053;&#35268;&#21017;&#21482;&#26159;&#24314;&#35758;&#12290;&#21516;&#26102;&#65292;&#38024;&#23545;&#27835;&#30103;&#30340;&#24322;&#36136;&#24615;&#21644;&#20844;&#24179;&#32771;&#34385;&#22240;&#32032;&#65292;&#20915;&#31574;&#32773;&#30340;&#26435;&#34913;&#21644;&#20915;&#31574;&#35268;&#21017;&#20063;&#20250;&#21457;&#29983;&#21464;&#21270;&#12290;&#22312;&#31038;&#20250;&#26381;&#21153;&#39046;&#22495;&#65292;&#30740;&#31350;&#26174;&#31034;&#23384;&#22312;&#19968;&#20010;&#20351;&#29992;&#24046;&#36317;&#38382;&#39064;&#65292;&#37027;&#20123;&#26368;&#26377;&#21487;&#33021;&#21463;&#30410;&#30340;&#20154;&#21364;&#26080;&#27861;&#33719;&#24471;&#36825;&#20123;&#30410;&#26381;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20851;&#38190;&#39046;&#22495;&#20013;&#65292;&#24378;&#21046;&#20010;&#20307;&#25509;&#21463;&#27835;&#30103;&#36890;&#24120;&#26159;&#19981;&#21487;&#33021;&#30340;&#65292;&#22240;&#27492;&#22312;&#20154;&#31867;&#19981;&#36981;&#24490;&#27835;&#30103;&#24314;&#35758;&#30340;&#24773;&#20917;&#19979;&#65292;&#26368;&#20248;&#31574;&#30053;&#35268;&#21017;&#21482;&#26159;&#24314;&#35758;&#12290;&#22312;&#36825;&#20123;&#39046;&#22495;&#20013;&#65292;&#25509;&#21463;&#27835;&#30103;&#30340;&#20010;&#20307;&#21487;&#33021;&#23384;&#22312;&#24322;&#36136;&#24615;&#65292;&#27835;&#30103;&#25928;&#26524;&#20063;&#21487;&#33021;&#23384;&#22312;&#24322;&#36136;&#24615;&#12290;&#34429;&#28982;&#26368;&#20248;&#27835;&#30103;&#35268;&#21017;&#21487;&#20197;&#26368;&#22823;&#21270;&#25972;&#20010;&#20154;&#32676;&#30340;&#22240;&#26524;&#32467;&#26524;&#65292;&#20294;&#22312;&#40723;&#21169;&#30340;&#24773;&#20917;&#19979;&#65292;&#23545;&#20110;&#35775;&#38382;&#24179;&#31561;&#38480;&#21046;&#25110;&#20854;&#20182;&#20844;&#24179;&#32771;&#34385;&#22240;&#32032;&#21487;&#33021;&#26159;&#30456;&#20851;&#30340;&#12290;&#20363;&#22914;&#65292;&#22312;&#31038;&#20250;&#26381;&#21153;&#39046;&#22495;&#65292;&#19968;&#20010;&#25345;&#20037;&#30340;&#38590;&#39064;&#26159;&#37027;&#20123;&#26368;&#26377;&#21487;&#33021;&#20174;&#20013;&#21463;&#30410;&#30340;&#20154;&#20013;&#37027;&#20123;&#33719;&#30410;&#26381;&#21153;&#30340;&#20351;&#29992;&#24046;&#36317;&#12290;&#24403;&#20915;&#31574;&#32773;&#23545;&#35775;&#38382;&#21644;&#24179;&#22343;&#32467;&#26524;&#37117;&#26377;&#20998;&#37197;&#20559;&#22909;&#26102;&#65292;&#26368;&#20248;&#20915;&#31574;&#35268;&#21017;&#20250;&#21457;&#29983;&#21464;&#21270;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22240;&#26524;&#35782;&#21035;&#12289;&#32479;&#35745;&#26041;&#24046;&#20943;&#23569;&#20272;&#35745;&#21644;&#31283;&#20581;&#20272;&#35745;&#30340;&#26368;&#20248;&#27835;&#30103;&#35268;&#21017;&#65292;&#21253;&#25324;&#22312;&#36829;&#21453;&#38451;&#24615;&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;
In consequential domains, it is often impossible to compel individuals to take treatment, so that optimal policy rules are merely suggestions in the presence of human non-adherence to treatment recommendations. In these same domains, there may be heterogeneity both in who responds in taking-up treatment, and heterogeneity in treatment efficacy. While optimal treatment rules can maximize causal outcomes across the population, access parity constraints or other fairness considerations can be relevant in the case of encouragement. For example, in social services, a persistent puzzle is the gap in take-up of beneficial services among those who may benefit from them the most. When in addition the decision-maker has distributional preferences over both access and average outcomes, the optimal decision rule changes. We study causal identification, statistical variance-reduced estimation, and robust estimation of optimal treatment rules, including under potential violations of positivity. We c
&lt;/p&gt;</description></item></channel></rss>