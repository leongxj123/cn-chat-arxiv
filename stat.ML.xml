<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#22312;&#22810;&#28304;&#29615;&#22659;&#20013;&#31995;&#32479;&#22320;&#35780;&#20272;&#20102;&#26631;&#20934;K&#25240;&#20132;&#21449;&#39564;&#35777;&#21644;&#30041;&#20986;&#28304;&#20132;&#21449;&#39564;&#35777;&#26041;&#27861;&#65292;&#20026;&#23454;&#29616;&#26356;&#20840;&#38754;&#21644;&#30495;&#23454;&#30340;&#31934;&#30830;&#24230;&#35780;&#20272;&#25552;&#20379;&#20102;&#26032;&#30340;&#26426;&#20250;</title><link>https://arxiv.org/abs/2403.15012</link><description>&lt;p&gt;
&#20020;&#24202;&#26426;&#22120;&#23398;&#20064;&#20013;&#22810;&#28304;&#20132;&#21449;&#39564;&#35777;&#30340;&#23454;&#35777;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Empirical investigation of multi-source cross-validation in clinical machine learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15012
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22312;&#22810;&#28304;&#29615;&#22659;&#20013;&#31995;&#32479;&#22320;&#35780;&#20272;&#20102;&#26631;&#20934;K&#25240;&#20132;&#21449;&#39564;&#35777;&#21644;&#30041;&#20986;&#28304;&#20132;&#21449;&#39564;&#35777;&#26041;&#27861;&#65292;&#20026;&#23454;&#29616;&#26356;&#20840;&#38754;&#21644;&#30495;&#23454;&#30340;&#31934;&#30830;&#24230;&#35780;&#20272;&#25552;&#20379;&#20102;&#26032;&#30340;&#26426;&#20250;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#19978;&#65292;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#20020;&#24202;&#39044;&#27979;&#27169;&#22411;&#26159;&#22312;&#26469;&#33258;&#21333;&#19968;&#26469;&#28304;&#65288;&#22914;&#21307;&#38498;&#65289;&#30340;&#24739;&#32773;&#25968;&#25454;&#19978;&#36827;&#34892;&#35757;&#32451;&#21644;&#35780;&#20272;&#30340;&#12290;&#20132;&#21449;&#39564;&#35777;&#26041;&#27861;&#21487;&#36890;&#36807;&#37325;&#22797;&#38543;&#26426;&#25286;&#20998;&#25968;&#25454;&#26469;&#20272;&#35745;&#36825;&#20123;&#27169;&#22411;&#22312;&#26469;&#33258;&#21516;&#19968;&#26469;&#28304;&#30340;&#26032;&#24739;&#32773;&#19978;&#30340;&#31934;&#30830;&#24230;&#12290;&#28982;&#32780;&#65292;&#19982;&#37096;&#32626;&#27169;&#22411;&#21040;&#25968;&#25454;&#38598;&#20013;&#26410;&#20195;&#34920;&#30340;&#28304;&#22836;&#65288;&#22914;&#26032;&#21307;&#38498;&#65289;&#33719;&#24471;&#30340;&#31934;&#30830;&#24230;&#30456;&#27604;&#65292;&#36825;&#20123;&#20272;&#35745;&#24448;&#24448;&#36807;&#20110;&#20048;&#35266;&#12290;&#22810;&#28304;&#21307;&#30103;&#25968;&#25454;&#38598;&#30340;&#19981;&#26029;&#22686;&#21152;&#20026;&#36890;&#36807;&#22522;&#20110;&#28304;&#22836;&#30340;&#20132;&#21449;&#39564;&#35777;&#35774;&#35745;&#33719;&#24471;&#26356;&#20840;&#38754;&#21644;&#30495;&#23454;&#30340;&#39044;&#26399;&#31934;&#30830;&#24230;&#35780;&#20272;&#25552;&#20379;&#20102;&#26032;&#26426;&#20250;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15012v1 Announce Type: new  Abstract: Traditionally, machine learning-based clinical prediction models have been trained and evaluated on patient data from a single source, such as a hospital. Cross-validation methods can be used to estimate the accuracy of such models on new patients originating from the same source, by repeated random splitting of the data. However, such estimates tend to be highly overoptimistic when compared to accuracy obtained from deploying models to sources not represented in the dataset, such as a new hospital. The increasing availability of multi-source medical datasets provides new opportunities for obtaining more comprehensive and realistic evaluations of expected accuracy through source-level cross-validation designs.   In this study, we present a systematic empirical evaluation of standard K-fold cross-validation and leave-source-out cross-validation methods in a multi-source setting. We consider the task of electrocardiogram based cardiovascul
&lt;/p&gt;</description></item><item><title>CASPER&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#26524;&#20851;&#31995;&#24863;&#30693;&#30340;&#26041;&#27861;&#26469;&#22788;&#29702;&#26102;&#31354;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#25554;&#34917;&#38382;&#39064;&#65292;&#36991;&#20813;&#36807;&#24230;&#21033;&#29992;&#38750;&#22240;&#26524;&#20851;&#31995;&#65292;&#25552;&#39640;&#25968;&#25454;&#20998;&#26512;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.11960</link><description>&lt;p&gt;
CASPER&#65306;&#22240;&#26524;&#20851;&#31995;&#24863;&#30693;&#26102;&#31354;&#22270;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#26102;&#31354;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;
&lt;/p&gt;
&lt;p&gt;
CASPER: Causality-Aware Spatiotemporal Graph Neural Networks for Spatiotemporal Time Series Imputation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11960
&lt;/p&gt;
&lt;p&gt;
CASPER&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#26524;&#20851;&#31995;&#24863;&#30693;&#30340;&#26041;&#27861;&#26469;&#22788;&#29702;&#26102;&#31354;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#25554;&#34917;&#38382;&#39064;&#65292;&#36991;&#20813;&#36807;&#24230;&#21033;&#29992;&#38750;&#22240;&#26524;&#20851;&#31995;&#65292;&#25552;&#39640;&#25968;&#25454;&#20998;&#26512;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11960v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#26032; &#25552;&#35201;&#65306;&#26102;&#31354;&#26102;&#38388;&#24207;&#21015;&#26159;&#29702;&#35299;&#20154;&#31867;&#27963;&#21160;&#21450;&#20854;&#24433;&#21709;&#30340;&#22522;&#30784;&#65292;&#36890;&#24120;&#36890;&#36807;&#25918;&#32622;&#22312;&#19981;&#21516;&#20301;&#32622;&#30340;&#30417;&#27979;&#20256;&#24863;&#22120;&#25910;&#38598;&#12290;&#25910;&#38598;&#21040;&#30340;&#25968;&#25454;&#36890;&#24120;&#21253;&#21547;&#30001;&#20110;&#21508;&#31181;&#25925;&#38556;&#32780;&#23548;&#33268;&#30340;&#32570;&#22833;&#20540;&#65292;&#36825;&#23545;&#25968;&#25454;&#20998;&#26512;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;&#20026;&#20102;&#22635;&#34917;&#32570;&#22833;&#20540;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#35768;&#22810;&#26041;&#27861;&#12290;&#22312;&#24674;&#22797;&#29305;&#23450;&#25968;&#25454;&#28857;&#26102;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#26041;&#27861;&#20542;&#21521;&#20110;&#32771;&#34385;&#19982;&#35813;&#28857;&#30456;&#20851;&#30340;&#25152;&#26377;&#20449;&#24687;&#65292;&#26080;&#35770;&#23427;&#20204;&#26159;&#21542;&#20855;&#26377;&#22240;&#26524;&#20851;&#31995;&#12290;&#22312;&#25968;&#25454;&#25910;&#38598;&#36807;&#31243;&#20013;&#65292;&#21253;&#25324;&#19968;&#20123;&#26410;&#30693;&#28151;&#26434;&#22240;&#32032;&#26159;&#19981;&#21487;&#36991;&#20813;&#30340;&#65292;&#20363;&#22914;&#26102;&#38388;&#24207;&#21015;&#20013;&#30340;&#32972;&#26223;&#22122;&#22768;&#21644;&#26500;&#24314;&#30340;&#20256;&#24863;&#22120;&#32593;&#32476;&#20013;&#30340;&#38750;&#22240;&#26524;&#24555;&#25463;&#36793;&#12290;&#36825;&#20123;&#28151;&#26434;&#22240;&#32032;&#21487;&#33021;&#22312;&#36755;&#20837;&#21644;&#36755;&#20986;&#20043;&#38388;&#24320;&#36767;&#21453;&#21521;&#36335;&#24452;&#65292;&#25442;&#21477;&#35805;&#35828;&#65292;&#23427;&#20204;&#24314;&#31435;&#20102;&#36755;&#20837;&#21644;&#36755;&#20986;&#20043;&#38388;&#30340;&#38750;&#22240;&#26524;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11960v1 Announce Type: new  Abstract: Spatiotemporal time series is the foundation of understanding human activities and their impacts, which is usually collected via monitoring sensors placed at different locations. The collected data usually contains missing values due to various failures, which have significant impact on data analysis. To impute the missing values, a lot of methods have been introduced. When recovering a specific data point, most existing methods tend to take into consideration all the information relevant to that point regardless of whether they have a cause-and-effect relationship. During data collection, it is inevitable that some unknown confounders are included, e.g., background noise in time series and non-causal shortcut edges in the constructed sensor network. These confounders could open backdoor paths between the input and output, in other words, they establish non-causal correlations between the input and output. Over-exploiting these non-causa
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#20998;&#24067;&#24335;&#26102;&#38388;&#24046;&#20998;&#30340;&#32479;&#35745;&#25928;&#29575;&#21644;&#26377;&#38480;&#26679;&#26412;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.05811</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#26102;&#38388;&#24046;&#20998;&#30340;&#32479;&#35745;&#25928;&#29575;
&lt;/p&gt;
&lt;p&gt;
Statistical Efficiency of Distributional Temporal Difference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05811
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#20998;&#24067;&#24335;&#26102;&#38388;&#24046;&#20998;&#30340;&#32479;&#35745;&#25928;&#29575;&#21644;&#26377;&#38480;&#26679;&#26412;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;(DRL)&#20851;&#27880;&#30340;&#26159;&#36820;&#22238;&#30340;&#23436;&#25972;&#20998;&#24067;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#22343;&#20540;&#65292;&#22312;&#21508;&#20010;&#39046;&#22495;&#21462;&#24471;&#20102;&#32463;&#39564;&#25104;&#21151;&#12290;&#39046;&#22495;DRL&#20013;&#30340;&#26680;&#24515;&#20219;&#21153;&#20043;&#19968;&#26159;&#20998;&#24067;&#24335;&#31574;&#30053;&#35780;&#20272;&#65292;&#28041;&#21450;&#20272;&#35745;&#32473;&#23450;&#31574;&#30053;pi&#30340;&#36820;&#22238;&#20998;&#24067;&#951;^pi&#12290;&#30456;&#24212;&#22320;&#25552;&#20986;&#20102;&#20998;&#24067;&#26102;&#38388;&#24046;&#20998;(TD)&#31639;&#27861;&#65292;&#36825;&#26159;&#32463;&#20856;RL&#25991;&#29486;&#20013;&#26102;&#38388;&#24046;&#20998;&#31639;&#27861;&#30340;&#24310;&#20280;&#12290;&#22312;&#34920;&#26684;&#26696;&#20363;&#20013;&#65292;citet{rowland2018analysis}&#21644;citet{rowland2023analysis}&#20998;&#21035;&#35777;&#26126;&#20102;&#20004;&#20010;&#20998;&#24067;&#24335;TD&#23454;&#20363;&#21363;&#20998;&#31867;&#26102;&#38388;&#24046;&#20998;&#31639;&#27861;(CTD)&#21644;&#20998;&#20301;&#25968;&#26102;&#38388;&#24046;&#20998;&#31639;&#27861;(QTD)&#30340;&#28176;&#36817;&#25910;&#25947;&#12290;&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#20998;&#26512;&#20102;&#20998;&#24067;&#24335;TD&#30340;&#26377;&#38480;&#26679;&#26412;&#24615;&#33021;&#12290;&#20026;&#20102;&#20419;&#36827;&#29702;&#35770;&#20998;&#26512;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#38750;&#21442;&#25968;&#30340; dis
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05811v1 Announce Type: cross  Abstract: Distributional reinforcement learning (DRL), which cares about the full distribution of returns instead of just the mean, has achieved empirical success in various domains. One of the core tasks in the field of DRL is distributional policy evaluation, which involves estimating the return distribution $\eta^\pi$ for a given policy $\pi$. A distributional temporal difference (TD) algorithm has been accordingly proposed, which is an extension of the temporal difference algorithm in the classic RL literature. In the tabular case, \citet{rowland2018analysis} and \citet{rowland2023analysis} proved the asymptotic convergence of two instances of distributional TD, namely categorical temporal difference algorithm (CTD) and quantile temporal difference algorithm (QTD), respectively. In this paper, we go a step further and analyze the finite-sample performance of distributional TD. To facilitate theoretical analysis, we propose non-parametric dis
&lt;/p&gt;</description></item><item><title>&#22240;&#26524;&#29305;&#24449;&#19981;&#33021;&#26356;&#22909;&#22320;&#25512;&#24191;&#21040;&#26032;&#39046;&#22495;&#65292;&#39044;&#27979;&#22120;&#20351;&#29992;&#25152;&#26377;&#29305;&#24449;&#30340;&#25928;&#26524;&#26356;&#22909;&#12290;</title><link>https://arxiv.org/abs/2402.09891</link><description>&lt;p&gt;
&#39044;&#27979;&#22240;&#26524;&#29305;&#24449;&#19981;&#33021;&#26356;&#22909;&#22320;&#25512;&#24191;&#21040;&#26032;&#39046;&#22495;
&lt;/p&gt;
&lt;p&gt;
Predictors from causal features do not generalize better to new domains
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09891
&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#29305;&#24449;&#19981;&#33021;&#26356;&#22909;&#22320;&#25512;&#24191;&#21040;&#26032;&#39046;&#22495;&#65292;&#39044;&#27979;&#22120;&#20351;&#29992;&#25152;&#26377;&#29305;&#24449;&#30340;&#25928;&#26524;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#19981;&#21516;&#39046;&#22495;&#20013;&#65292;&#22522;&#20110;&#22240;&#26524;&#29305;&#24449;&#35757;&#32451;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#27867;&#21270;&#25928;&#26524;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#28085;&#30422;&#20581;&#24247;&#12289;&#23601;&#19994;&#12289;&#25945;&#32946;&#12289;&#31038;&#20250;&#31119;&#21033;&#21644;&#25919;&#27835;&#31561;&#24212;&#29992;&#30340;16&#20010;&#34920;&#26684;&#25968;&#25454;&#38598;&#30340;&#39044;&#27979;&#20219;&#21153;&#12290;&#27599;&#20010;&#25968;&#25454;&#38598;&#37117;&#26377;&#22810;&#20010;&#39046;&#22495;&#65292;&#25105;&#20204;&#21487;&#20197;&#27979;&#35797;&#19968;&#20010;&#22312;&#19968;&#20010;&#39046;&#22495;&#35757;&#32451;&#30340;&#27169;&#22411;&#22312;&#21478;&#19968;&#20010;&#39046;&#22495;&#30340;&#34920;&#29616;&#12290;&#23545;&#20110;&#27599;&#20010;&#39044;&#27979;&#20219;&#21153;&#65292;&#25105;&#20204;&#36873;&#25321;&#23545;&#39044;&#27979;&#30446;&#26631;&#26377;&#22240;&#26524;&#24433;&#21709;&#30340;&#29305;&#24449;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#27979;&#35797;&#22522;&#20110;&#22240;&#26524;&#29305;&#24449;&#35757;&#32451;&#30340;&#27169;&#22411;&#26159;&#21542;&#22312;&#19981;&#21516;&#39046;&#22495;&#20013;&#26356;&#22909;&#22320;&#27867;&#21270;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#26080;&#35770;&#26159;&#21542;&#20855;&#26377;&#22240;&#26524;&#20851;&#31995;&#65292;&#20351;&#29992;&#25152;&#26377;&#21487;&#29992;&#29305;&#24449;&#30340;&#39044;&#27979;&#22120;&#37117;&#27604;&#20351;&#29992;&#22240;&#26524;&#29305;&#24449;&#30340;&#39044;&#27979;&#22120;&#22312;&#39046;&#22495;&#20869;&#22806;&#30340;&#20934;&#30830;&#24615;&#26356;&#39640;&#12290;&#32780;&#19988;&#65292;&#21363;&#20351;&#26159;&#20174;&#19968;&#20010;&#39046;&#22495;&#21040;&#21478;&#19968;&#20010;&#39046;&#22495;&#30340;&#20934;&#30830;&#24615;&#32477;&#23545;&#19979;&#38477;&#23545;&#20110;&#22240;&#26524;&#39044;&#27979;&#22120;&#26469;&#35828;&#20063;&#19981;&#27604;&#20351;&#29992;&#25152;&#26377;&#29305;&#24449;&#30340;&#27169;&#22411;&#26356;&#22909;&#12290;&#22914;&#26524;&#30446;&#26631;&#26159;&#22312;&#26032;&#39046;&#22495;&#20013;&#27867;&#21270;&#65292;&#23454;&#36341;&#20013;&#20351;&#29992;&#25152;&#26377;&#29305;&#24449;&#30340;&#39044;&#27979;&#22120;&#25928;&#26524;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09891v1 Announce Type: new  Abstract: We study how well machine learning models trained on causal features generalize across domains. We consider 16 prediction tasks on tabular datasets covering applications in health, employment, education, social benefits, and politics. Each dataset comes with multiple domains, allowing us to test how well a model trained in one domain performs in another. For each prediction task, we select features that have a causal influence on the target of prediction. Our goal is to test the hypothesis that models trained on causal features generalize better across domains. Without exception, we find that predictors using all available features, regardless of causality, have better in-domain and out-of-domain accuracy than predictors using causal features. Moreover, even the absolute drop in accuracy from one domain to the other is no better for causal predictors than for models that use all features. If the goal is to generalize to new domains, prac
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20351;&#29992;&#20462;&#21098;&#22343;&#20540;&#31867;&#22411;&#30340;&#20013;&#24515;&#28857;&#20272;&#35745;&#30340;&#28151;&#21512;&#32858;&#31867;&#25216;&#26415;&#65292;&#29992;&#20110;&#22312;&#23384;&#22312;&#27425;&#39640;&#26031;&#35823;&#24046;&#30340;&#20013;&#24515;&#28857;&#21608;&#22260;&#20998;&#24067;&#30340;&#24369;&#21021;&#22987;&#21270;&#26465;&#20214;&#19979;&#20135;&#29983;&#26368;&#20248;&#38169;&#35823;&#26631;&#35760;&#20445;&#35777;&#65292;&#24182;&#19988;&#22312;&#23384;&#22312;&#25932;&#23545;&#24322;&#24120;&#20540;&#30340;&#24773;&#20917;&#19979;&#20173;&#28982;&#26377;&#25928;&#12290;</title><link>http://arxiv.org/abs/2401.05574</link><description>&lt;p&gt;
&#36890;&#36807;&#20462;&#21098;&#22343;&#20540;&#30340;&#40065;&#26834;&#32858;&#31867;&#30340;&#19968;&#33324;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
A general theory for robust clustering via trimmed mean. (arXiv:2401.05574v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05574
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20351;&#29992;&#20462;&#21098;&#22343;&#20540;&#31867;&#22411;&#30340;&#20013;&#24515;&#28857;&#20272;&#35745;&#30340;&#28151;&#21512;&#32858;&#31867;&#25216;&#26415;&#65292;&#29992;&#20110;&#22312;&#23384;&#22312;&#27425;&#39640;&#26031;&#35823;&#24046;&#30340;&#20013;&#24515;&#28857;&#21608;&#22260;&#20998;&#24067;&#30340;&#24369;&#21021;&#22987;&#21270;&#26465;&#20214;&#19979;&#20135;&#29983;&#26368;&#20248;&#38169;&#35823;&#26631;&#35760;&#20445;&#35777;&#65292;&#24182;&#19988;&#22312;&#23384;&#22312;&#25932;&#23545;&#24322;&#24120;&#20540;&#30340;&#24773;&#20917;&#19979;&#20173;&#28982;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23384;&#22312;&#24322;&#36136;&#25968;&#25454;&#30340;&#32479;&#35745;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#32858;&#31867;&#26159;&#19968;&#31181;&#22522;&#26412;&#24037;&#20855;&#12290;&#35768;&#22810;&#26368;&#36817;&#30340;&#32467;&#26524;&#20027;&#35201;&#20851;&#27880;&#22312;&#25968;&#25454;&#22260;&#32469;&#24102;&#26377;&#27425;&#39640;&#26031;&#35823;&#24046;&#30340;&#20013;&#24515;&#28857;&#20998;&#24067;&#26102;&#30340;&#26368;&#20248;&#38169;&#35823;&#26631;&#35760;&#20445;&#35777;&#12290;&#28982;&#32780;&#65292;&#38480;&#21046;&#24615;&#30340;&#27425;&#39640;&#26031;&#27169;&#22411;&#22312;&#23454;&#36341;&#20013;&#24120;&#24120;&#26080;&#25928;&#65292;&#22240;&#20026;&#21508;&#31181;&#23454;&#38469;&#24212;&#29992;&#23637;&#31034;&#20102;&#22260;&#32469;&#20013;&#24515;&#28857;&#30340;&#37325;&#23614;&#20998;&#24067;&#25110;&#21463;&#21040;&#21487;&#33021;&#30340;&#25932;&#23545;&#25915;&#20987;&#65292;&#38656;&#35201;&#20855;&#26377;&#40065;&#26834;&#25968;&#25454;&#39537;&#21160;&#21021;&#22987;&#21270;&#30340;&#40065;&#26834;&#32858;&#31867;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#19968;&#31181;&#28151;&#21512;&#32858;&#31867;&#25216;&#26415;&#65292;&#21033;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#22810;&#21464;&#37327;&#20462;&#21098;&#22343;&#20540;&#31867;&#22411;&#30340;&#20013;&#24515;&#28857;&#20272;&#35745;&#65292;&#22312;&#20013;&#24515;&#28857;&#21608;&#22260;&#30340;&#35823;&#24046;&#20998;&#24067;&#30340;&#24369;&#21021;&#22987;&#21270;&#26465;&#20214;&#19979;&#20135;&#29983;&#38169;&#35823;&#26631;&#35760;&#20445;&#35777;&#12290;&#25105;&#20204;&#36824;&#32473;&#20986;&#20102;&#19968;&#20010;&#30456;&#21305;&#37197;&#30340;&#19979;&#30028;&#65292;&#19978;&#30028;&#20381;&#36182;&#20110;&#32858;&#31867;&#30340;&#25968;&#37327;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21363;&#20351;&#22312;&#23384;&#22312;&#25932;&#23545;&#24322;&#24120;&#20540;&#30340;&#24773;&#20917;&#19979;&#20063;&#33021;&#20135;&#29983;&#26368;&#20248;&#38169;&#35823;&#26631;&#35760;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#31616;&#21270;&#20026;&#20122;&#39640;&#26031;&#27169;&#22411;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Clustering is a fundamental tool in statistical machine learning in the presence of heterogeneous data. Many recent results focus primarily on optimal mislabeling guarantees, when data are distributed around centroids with sub-Gaussian errors. Yet, the restrictive sub-Gaussian model is often invalid in practice, since various real-world applications exhibit heavy tail distributions around the centroids or suffer from possible adversarial attacks that call for robust clustering with a robust data-driven initialization. In this paper, we introduce a hybrid clustering technique with a novel multivariate trimmed mean type centroid estimate to produce mislabeling guarantees under a weak initialization condition for general error distributions around the centroids. A matching lower bound is derived, up to factors depending on the number of clusters. In addition, our approach also produces the optimal mislabeling even in the presence of adversarial outliers. Our results reduce to the sub-Gaus
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31283;&#23450;&#30340;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#25193;&#25955;&#26144;&#23556;&#19982;&#26391;&#20043;&#19975;&#21160;&#21147;&#23398;&#30456;&#32467;&#21512;&#65292;&#22312;&#20165;&#26377;&#26377;&#38480;&#25968;&#37327;&#30340;&#35757;&#32451;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#29983;&#25104;&#26032;&#26679;&#26412;&#65292;&#24182;&#35299;&#20915;&#20102;&#26102;&#38388;&#27493;&#38271;&#20725;&#30828;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#20013;&#30340;&#31283;&#23450;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.04372</link><description>&lt;p&gt;
&#20351;&#29992;&#25193;&#25955;&#26144;&#23556;&#36827;&#34892;&#31283;&#23450;&#30340;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Stable generative modeling using diffusion maps. (arXiv:2401.04372v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04372
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31283;&#23450;&#30340;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#25193;&#25955;&#26144;&#23556;&#19982;&#26391;&#20043;&#19975;&#21160;&#21147;&#23398;&#30456;&#32467;&#21512;&#65292;&#22312;&#20165;&#26377;&#26377;&#38480;&#25968;&#37327;&#30340;&#35757;&#32451;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#29983;&#25104;&#26032;&#26679;&#26412;&#65292;&#24182;&#35299;&#20915;&#20102;&#26102;&#38388;&#27493;&#38271;&#20725;&#30828;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#20013;&#30340;&#31283;&#23450;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20174;&#20165;&#26377;&#36275;&#22815;&#25968;&#37327;&#30340;&#35757;&#32451;&#26679;&#26412;&#21487;&#24471;&#21040;&#30340;&#26410;&#30693;&#20998;&#24067;&#20013;&#25277;&#26679;&#30340;&#38382;&#39064;&#12290;&#22312;&#29983;&#25104;&#24314;&#27169;&#30340;&#32972;&#26223;&#19979;&#65292;&#36825;&#26679;&#30340;&#35774;&#32622;&#26368;&#36817;&#24341;&#36215;&#20102;&#30456;&#24403;&#22823;&#30340;&#20851;&#27880;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#25193;&#25955;&#26144;&#23556;&#21644;&#26391;&#20043;&#19975;&#21160;&#21147;&#23398;&#30456;&#32467;&#21512;&#30340;&#29983;&#25104;&#27169;&#22411;&#12290;&#25193;&#25955;&#26144;&#23556;&#29992;&#20110;&#20174;&#21487;&#29992;&#30340;&#35757;&#32451;&#26679;&#26412;&#20013;&#36817;&#20284;&#24471;&#21040;&#28418;&#31227;&#39033;&#65292;&#28982;&#21518;&#22312;&#31163;&#25955;&#26102;&#38388;&#30340;&#26391;&#20043;&#19975;&#37319;&#26679;&#22120;&#20013;&#23454;&#29616;&#29983;&#25104;&#26032;&#26679;&#26412;&#12290;&#36890;&#36807;&#23558;&#26680;&#24102;&#23485;&#35774;&#32622;&#20026;&#19982;&#26410;&#35843;&#25972;&#30340;&#26391;&#20043;&#19975;&#31639;&#27861;&#20013;&#20351;&#29992;&#30340;&#26102;&#38388;&#27493;&#38271;&#21305;&#37197;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#22320;&#36991;&#20813;&#36890;&#24120;&#19982;&#26102;&#38388;&#27493;&#38271;&#20725;&#30828;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30456;&#20851;&#30340;&#31283;&#23450;&#24615;&#38382;&#39064;&#12290;&#26356;&#20934;&#30830;&#22320;&#35828;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#35010;&#27493;&#39588;&#26041;&#26696;&#65292;&#30830;&#20445;&#29983;&#25104;&#30340;&#26679;&#26412;&#20445;&#25345;&#22312;&#35757;&#32451;&#26679;&#26412;&#30340;&#20984;&#21253;&#20869;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#33258;&#28982;&#22320;&#25193;&#23637;&#20026;&#29983;&#25104;&#26465;&#20214;&#26679;&#26412;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of sampling from an unknown distribution for which only a sufficiently large number of training samples are available. Such settings have recently drawn considerable interest in the context of generative modelling. In this paper, we propose a generative model combining diffusion maps and Langevin dynamics. Diffusion maps are used to approximate the drift term from the available training samples, which is then implemented in a discrete-time Langevin sampler to generate new samples. By setting the kernel bandwidth to match the time step size used in the unadjusted Langevin algorithm, our method effectively circumvents any stability issues typically associated with time-stepping stiff stochastic differential equations. More precisely, we introduce a novel split-step scheme, ensuring that the generated samples remain within the convex hull of the training samples. Our framework can be naturally extended to generate conditional samples. We demonstrate the performance
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#32452;&#22810;&#20803;&#20989;&#25968;&#22238;&#24402;&#27169;&#22411;&#65292;&#20854;&#20013;&#37319;&#29992;&#20102;&#19968;&#31181;&#26032;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#26469;&#35299;&#20915;&#19981;&#21516;&#20989;&#25968;&#21327;&#21464;&#37327;&#30340;&#28508;&#22312;&#21516;&#36136;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2312.01925</link><description>&lt;p&gt;
&#22312;&#22810;&#20803;&#20989;&#25968;&#22238;&#24402;&#20013;&#30340;&#31995;&#25968;&#24418;&#29366;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Coefficient Shape Alignment in Multivariate Functional Regression. (arXiv:2312.01925v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.01925
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#32452;&#22810;&#20803;&#20989;&#25968;&#22238;&#24402;&#27169;&#22411;&#65292;&#20854;&#20013;&#37319;&#29992;&#20102;&#19968;&#31181;&#26032;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#26469;&#35299;&#20915;&#19981;&#21516;&#20989;&#25968;&#21327;&#21464;&#37327;&#30340;&#28508;&#22312;&#21516;&#36136;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22810;&#20803;&#20989;&#25968;&#25968;&#25454;&#20998;&#26512;&#20013;&#65292;&#19981;&#21516;&#30340;&#20989;&#25968;&#21327;&#21464;&#37327;&#21487;&#33021;&#20855;&#26377;&#21516;&#36136;&#24615;&#12290;&#38544;&#34255;&#30340;&#21516;&#36136;&#24615;&#32467;&#26500;&#23545;&#20110;&#19981;&#21516;&#21327;&#21464;&#37327;&#30340;&#36830;&#25509;&#25110;&#20851;&#32852;&#20855;&#26377;&#20449;&#24687;&#20215;&#20540;&#12290;&#20855;&#26377;&#26126;&#26174;&#21516;&#36136;&#24615;&#30340;&#21327;&#21464;&#37327;&#21487;&#20197;&#22312;&#21516;&#19968;&#32676;&#32452;&#20013;&#36827;&#34892;&#32852;&#21512;&#20998;&#26512;&#65292;&#20174;&#32780;&#20135;&#29983;&#19968;&#31181;&#31616;&#21270;&#24314;&#27169;&#22810;&#20803;&#20989;&#25968;&#25968;&#25454;&#30340;&#26041;&#27861;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#32452;&#22810;&#20803;&#20989;&#25968;&#22238;&#24402;&#27169;&#22411;&#65292;&#37319;&#29992;&#31216;&#20026;&#8220;&#31995;&#25968;&#24418;&#29366;&#23545;&#40784;&#8221;&#30340;&#26032;&#27491;&#21017;&#21270;&#26041;&#27861;&#26469;&#35299;&#20915;&#19981;&#21516;&#20989;&#25968;&#21327;&#21464;&#37327;&#30340;&#28508;&#22312;&#21516;&#36136;&#24615;&#38382;&#39064;&#12290;&#24314;&#27169;&#36807;&#31243;&#21253;&#25324;&#20004;&#20010;&#20027;&#35201;&#27493;&#39588;&#65306;&#39318;&#20808;&#65292;&#20351;&#29992;&#26032;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#26816;&#27979;&#26410;&#30693;&#20998;&#32452;&#32467;&#26500;&#65292;&#23558;&#21327;&#21464;&#37327;&#32858;&#21512;&#21040;&#19981;&#30456;&#20132;&#30340;&#32676;&#32452;&#20013;&#65307;&#28982;&#21518;&#65292;&#22522;&#20110;&#26816;&#27979;&#21040;&#30340;&#20998;&#32452;&#32467;&#26500;&#24314;&#31435;&#20998;&#32452;&#22810;&#20803;&#20989;&#25968;&#22238;&#24402;&#27169;&#22411;&#12290;&#22312;&#36825;&#20010;&#26032;&#30340;&#20998;&#32452;&#27169;&#22411;&#20013;&#65292;&#21516;&#19968;&#21516;&#36136;&#32676;&#32452;&#20013;&#30340;&#31995;&#25968;&#20989;&#25968;&#24212;&#23545;&#40784;&#12290;
&lt;/p&gt;
&lt;p&gt;
In multivariate functional data analysis, different functional covariates can be homogeneous. The hidden homogeneity structure is informative about the connectivity or association of different covariates. The covariates with pronounced homogeneity can be analyzed jointly within the same group, which gives rise to a way of parsimoniously modeling multivariate functional data. In this paper, a novel grouped multivariate functional regression model with a new regularization approach termed "coefficient shape alignment" is developed to tackle the potential homogeneity of different functional covariates. The modeling procedure includes two main steps: first detect the unknown grouping structure with the new regularization approach to aggregate covariates into disjoint groups; and then the grouped multivariate functional regression model is established based on the detected grouping structure. In this new grouped model, the coefficient functions of covariates in the same homogeneous group sh
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#21518;&#39564;&#37319;&#26679;&#23398;&#20064;&#31639;&#27861;&#22312;&#24207;&#21015;&#21270;POMDPs&#20013;&#30340;&#36951;&#25022;&#24615;&#33021;&#65292;&#24182;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#25552;&#20379;&#20102;&#25913;&#36827;&#30340;&#22810;&#39033;&#24335;&#36125;&#21494;&#26031;&#36951;&#25022;&#30028;&#12290;</title><link>http://arxiv.org/abs/2310.10107</link><description>&lt;p&gt;
&#21518;&#39564;&#37319;&#26679;&#23398;&#20064;&#31639;&#27861;&#22312;&#24207;&#21015;&#21270;POMDPs&#20013;&#30340;&#36951;&#25022;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Regret Analysis of the Posterior Sampling-based Learning Algorithm for Episodic POMDPs. (arXiv:2310.10107v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10107
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#21518;&#39564;&#37319;&#26679;&#23398;&#20064;&#31639;&#27861;&#22312;&#24207;&#21015;&#21270;POMDPs&#20013;&#30340;&#36951;&#25022;&#24615;&#33021;&#65292;&#24182;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#25552;&#20379;&#20102;&#25913;&#36827;&#30340;&#22810;&#39033;&#24335;&#36125;&#21494;&#26031;&#36951;&#25022;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30456;&#27604;&#20110;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDPs&#65289;&#65292;&#37096;&#20998;&#21487;&#35266;&#23519;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;POMDPs&#65289;&#30340;&#23398;&#20064;&#30001;&#20110;&#35266;&#23519;&#25968;&#25454;&#38590;&#20197;&#35299;&#35835;&#32780;&#21464;&#24471;&#26356;&#21152;&#22256;&#38590;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#20855;&#26377;&#26410;&#30693;&#36716;&#31227;&#21644;&#35266;&#27979;&#27169;&#22411;&#30340;POMDPs&#20013;&#30340;&#24207;&#21015;&#21270;&#23398;&#20064;&#38382;&#39064;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#22522;&#20110;&#21518;&#39564;&#37319;&#26679;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65288;PSRL&#65289;&#22312;POMDPs&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#35777;&#26126;&#20854;&#36125;&#21494;&#26031;&#36951;&#25022;&#38543;&#30528;&#24207;&#21015;&#30340;&#25968;&#37327;&#30340;&#24179;&#26041;&#26681;&#32780;&#32553;&#23567;&#12290;&#19968;&#33324;&#26469;&#35828;&#65292;&#36951;&#25022;&#38543;&#30528;&#26102;&#38388;&#38271;&#24230;$H$&#21576;&#25351;&#25968;&#32423;&#22686;&#38271;&#65292;&#24182;&#36890;&#36807;&#25552;&#20379;&#19968;&#20010;&#19979;&#30028;&#35777;&#26126;&#20102;&#36825;&#19968;&#28857;&#12290;&#28982;&#32780;&#65292;&#22312;POMDP&#26159;&#27424;&#23436;&#22791;&#19988;&#24369;&#21487;&#35782;&#21035;&#30340;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#22810;&#39033;&#24335;&#36125;&#21494;&#26031;&#36951;&#25022;&#30028;&#65292;&#30456;&#27604;&#20110;arXiv:2204.08967&#30340;&#26368;&#26032;&#32467;&#26524;&#65292;&#25913;&#36827;&#20102;&#36951;&#25022;&#30028;&#32422;$\Omega(H^2\sqrt{SA})$&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;
Compared to Markov Decision Processes (MDPs), learning in Partially Observable Markov Decision Processes (POMDPs) can be significantly harder due to the difficulty of interpreting observations. In this paper, we consider episodic learning problems in POMDPs with unknown transition and observation models. We consider the Posterior Sampling-based Reinforcement Learning (PSRL) algorithm for POMDPs and show that its Bayesian regret scales as the square root of the number of episodes. In general, the regret scales exponentially with the horizon length $H$, and we show that this is inevitable by providing a lower bound. However, under the condition that the POMDP is undercomplete and weakly revealing, we establish a polynomial Bayesian regret bound that improves the regret bound by a factor of $\Omega(H^2\sqrt{SA})$ over the recent result by arXiv:2204.08967.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#39318;&#27425;&#30740;&#31350;&#20102;&#20855;&#26377;&#32593;&#32476;&#36741;&#21161;&#20449;&#24687;&#30340;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#23398;&#20064;&#38382;&#39064;&#65292;&#24341;&#20837;&#20102;Reg-Graph&#27169;&#22411;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;AMP&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#22312;&#23454;&#39564;&#20013;&#20248;&#20110;&#29616;&#26377;&#30340;&#20960;&#31181;&#32593;&#32476;&#36741;&#21161;&#22238;&#24402;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.05679</link><description>&lt;p&gt;
&#20855;&#26377;&#32593;&#32476;&#36741;&#21161;&#20449;&#24687;&#30340;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Bayes optimal learning in high-dimensional linear regression with network side information. (arXiv:2306.05679v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05679
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#27425;&#30740;&#31350;&#20102;&#20855;&#26377;&#32593;&#32476;&#36741;&#21161;&#20449;&#24687;&#30340;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#23398;&#20064;&#38382;&#39064;&#65292;&#24341;&#20837;&#20102;Reg-Graph&#27169;&#22411;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;AMP&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#22312;&#23454;&#39564;&#20013;&#20248;&#20110;&#29616;&#26377;&#30340;&#20960;&#31181;&#32593;&#32476;&#36741;&#21161;&#22238;&#24402;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22522;&#22240;&#32452;&#23398;&#12289;&#34507;&#30333;&#36136;&#32452;&#23398;&#21644;&#31070;&#32463;&#31185;&#23398;&#31561;&#24212;&#29992;&#20013;&#65292;&#20855;&#26377;&#32593;&#32476;&#36741;&#21161;&#20449;&#24687;&#30340;&#30417;&#30563;&#23398;&#20064;&#38382;&#39064;&#32463;&#24120;&#20986;&#29616;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#30740;&#31350;&#20102;&#20855;&#26377;&#32593;&#32476;&#36741;&#21161;&#20449;&#24687;&#30340;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#23398;&#20064;&#38382;&#39064;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#39318;&#20808;&#24341;&#20837;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#29983;&#25104;&#27169;&#22411;&#65288;&#31216;&#20026;Reg-Graph&#27169;&#22411;&#65289;&#65292;&#36890;&#36807;&#19968;&#32452;&#20849;&#21516;&#30340;&#28508;&#22312;&#21442;&#25968;&#20026;&#30417;&#30563;&#25968;&#25454;&#21644;&#35266;&#27979;&#21040;&#30340;&#32593;&#32476;&#35774;&#23450;&#20102;&#19968;&#20010;&#32852;&#21512;&#20998;&#24067;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#36817;&#20284;&#28040;&#24687;&#20256;&#36882;&#65288;AMP&#65289;&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#22312;&#38750;&#24120;&#19968;&#33324;&#30340;&#26465;&#20214;&#19979;&#21487;&#35777;&#26126;&#26159;&#36125;&#21494;&#26031;&#26368;&#20248;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23545;&#28508;&#22312;&#20449;&#21495;&#21644;&#35266;&#27979;&#21040;&#30340;&#25968;&#25454;&#20043;&#38388;&#30340;&#26497;&#38480;&#20114;&#20449;&#24687;&#36827;&#34892;&#20102;&#34920;&#24449;&#65292;&#20174;&#32780;&#31934;&#30830;&#37327;&#21270;&#20102;&#32593;&#32476;&#36741;&#21161;&#20449;&#24687;&#22312;&#22238;&#24402;&#38382;&#39064;&#20013;&#30340;&#32479;&#35745;&#24433;&#21709;&#12290;&#25105;&#20204;&#23545;&#27169;&#25311;&#25968;&#25454;&#21644;&#23454;&#38469;&#25968;&#25454;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#30340;&#20960;&#31181;&#32593;&#32476;&#36741;&#21161;&#22238;&#24402;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Supervised learning problems with side information in the form of a network arise frequently in applications in genomics, proteomics and neuroscience. For example, in genetic applications, the network side information can accurately capture background biological information on the intricate relations among the relevant genes. In this paper, we initiate a study of Bayes optimal learning in high-dimensional linear regression with network side information. To this end, we first introduce a simple generative model (called the Reg-Graph model) which posits a joint distribution for the supervised data and the observed network through a common set of latent parameters. Next, we introduce an iterative algorithm based on Approximate Message Passing (AMP) which is provably Bayes optimal under very general conditions. In addition, we characterize the limiting mutual information between the latent signal and the data observed, and thus precisely quantify the statistical impact of the network side 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20174;&#32479;&#35745;&#23398;&#35282;&#24230;&#24314;&#31435;&#25928;&#29992;&#29702;&#35770;&#65292;&#26088;&#22312;&#22522;&#20110;&#19968;&#33324;&#24615;&#25351;&#26631;&#23450;&#37327;&#35780;&#20272;&#21512;&#25104;&#31639;&#27861;&#30340;&#25928;&#29992;&#65292;&#25928;&#29992;&#25351;&#26631;&#30340;&#20998;&#26512;&#30028;&#38480;&#25581;&#31034;&#20102;&#25351;&#26631;&#25910;&#25947;&#30340;&#20851;&#38190;&#26465;&#20214;&#65292;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#21482;&#35201;&#19979;&#28216;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#27169;&#22411;&#35268;&#33539;&#26159;&#27491;&#30830;&#30340;&#65292;&#21512;&#25104;&#29305;&#24449;&#20998;&#24067;&#19981;&#19968;&#23450;&#19982;&#21407;&#22987;&#29305;&#24449;&#20998;&#24067;&#30456;&#21516;&#65292;&#25928;&#29992;&#25351;&#26631;&#20250;&#25910;&#25947;&#12290;</title><link>http://arxiv.org/abs/2305.10015</link><description>&lt;p&gt;
&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#30340;&#25928;&#29992;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Utility Theory of Synthetic Data Generation. (arXiv:2305.10015v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10015
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#32479;&#35745;&#23398;&#35282;&#24230;&#24314;&#31435;&#25928;&#29992;&#29702;&#35770;&#65292;&#26088;&#22312;&#22522;&#20110;&#19968;&#33324;&#24615;&#25351;&#26631;&#23450;&#37327;&#35780;&#20272;&#21512;&#25104;&#31639;&#27861;&#30340;&#25928;&#29992;&#65292;&#25928;&#29992;&#25351;&#26631;&#30340;&#20998;&#26512;&#30028;&#38480;&#25581;&#31034;&#20102;&#25351;&#26631;&#25910;&#25947;&#30340;&#20851;&#38190;&#26465;&#20214;&#65292;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#21482;&#35201;&#19979;&#28216;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#27169;&#22411;&#35268;&#33539;&#26159;&#27491;&#30830;&#30340;&#65292;&#21512;&#25104;&#29305;&#24449;&#20998;&#24067;&#19981;&#19968;&#23450;&#19982;&#21407;&#22987;&#29305;&#24449;&#20998;&#24067;&#30456;&#21516;&#65292;&#25928;&#29992;&#25351;&#26631;&#20250;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#21512;&#25104;&#25968;&#25454;&#30340;&#25928;&#29992;&#23545;&#20110;&#34913;&#37327;&#21512;&#25104;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#25928;&#29575;&#33267;&#20851;&#37325;&#35201;&#12290;&#29616;&#26377;&#30340;&#32467;&#26524;&#20391;&#37325;&#20110;&#23545;&#21512;&#25104;&#25968;&#25454;&#25928;&#29992;&#30340;&#32463;&#39564;&#35780;&#20272;&#65292;&#32780;&#38024;&#23545;&#21512;&#25104;&#25968;&#25454;&#31639;&#27861;&#22914;&#20309;&#24433;&#21709;&#25928;&#29992;&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#26410;&#34987;&#20805;&#20998;&#25506;&#32034;&#12290;&#26412;&#25991;&#20174;&#32479;&#35745;&#23398;&#35282;&#24230;&#24314;&#31435;&#25928;&#29992;&#29702;&#35770;&#65292;&#26088;&#22312;&#22522;&#20110;&#19968;&#33324;&#24615;&#25351;&#26631;&#23450;&#37327;&#35780;&#20272;&#21512;&#25104;&#31639;&#27861;&#30340;&#25928;&#29992;&#12290;&#35813;&#25351;&#26631;&#23450;&#20041;&#20026;&#22312;&#21512;&#25104;&#21644;&#21407;&#22987;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#20043;&#38388;&#27867;&#21270;&#30340;&#32477;&#23545;&#24046;&#24322;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#35813;&#25928;&#29992;&#25351;&#26631;&#30340;&#20998;&#26512;&#30028;&#38480;&#26469;&#30740;&#31350;&#25351;&#26631;&#25910;&#25947;&#30340;&#20851;&#38190;&#26465;&#20214;&#12290;&#19968;&#20010;&#26377;&#36259;&#30340;&#32467;&#26524;&#26159;&#65292;&#21482;&#35201;&#19979;&#28216;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#27169;&#22411;&#35268;&#33539;&#26159;&#27491;&#30830;&#30340;&#65292;&#21512;&#25104;&#29305;&#24449;&#20998;&#24067;&#19981;&#19968;&#23450;&#19982;&#21407;&#22987;&#29305;&#24449;&#20998;&#24067;&#30456;&#21516;&#65292;&#21017;&#35813;&#25928;&#29992;&#25351;&#26631;&#20250;&#25910;&#25947;&#12290;&#21478;&#19968;&#20010;&#37325;&#35201;&#30340;&#25928;&#29992;&#25351;&#26631;&#22522;&#20110;&#21512;&#25104;&#21644;&#21407;&#22987;&#25968;&#25454;&#20043;&#38388;&#28508;&#22312;&#30340;&#22240;&#26524;&#26426;&#21046;&#19968;&#33268;&#24615;&#12290;&#35813;&#29702;&#35770;&#20351;&#29992;&#20960;&#31181;&#21512;&#25104;&#31639;&#27861;&#36827;&#34892;&#35828;&#26126;&#65292;&#24182;&#20998;&#26512;&#20102;&#23427;&#20204;&#30340;&#25928;&#29992;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Evaluating the utility of synthetic data is critical for measuring the effectiveness and efficiency of synthetic algorithms. Existing results focus on empirical evaluations of the utility of synthetic data, whereas the theoretical understanding of how utility is affected by synthetic data algorithms remains largely unexplored. This paper establishes utility theory from a statistical perspective, aiming to quantitatively assess the utility of synthetic algorithms based on a general metric. The metric is defined as the absolute difference in generalization between models trained on synthetic and original datasets. We establish analytical bounds for this utility metric to investigate critical conditions for the metric to converge. An intriguing result is that the synthetic feature distribution is not necessarily identical to the original one for the convergence of the utility metric as long as the model specification in downstream learning tasks is correct. Another important utility metri
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20132;&#36890;&#22270;&#26410;&#35843;&#25972;&#30340; Langevin &#31639;&#27861; (ULA) &#21644; Riemann &#27969;&#24418; Langevin &#21160;&#21147;&#23398; (RMLD)&#65292;&#36890;&#36807;&#24212;&#29992;&#20132;&#36890;&#22270;&#21487;&#20197;&#21152;&#36895; Langevin &#21160;&#21147;&#23398;&#30340;&#25910;&#25947;&#65292;&#24182;&#25552;&#20379;&#20102;&#23398;&#20064;&#24230;&#37327;&#21644;&#25200;&#21160;&#30340;&#26032;&#24605;&#36335;&#12290;</title><link>http://arxiv.org/abs/2302.07227</link><description>&lt;p&gt;
&#20132;&#36890;&#22270;&#26410;&#35843;&#25972;&#30340; Langevin &#31639;&#27861;&#65306;&#23398;&#20064;&#21644;&#31163;&#25955;&#21270;&#25200;&#21160;&#37319;&#26679;&#22120;
&lt;/p&gt;
&lt;p&gt;
Transport map unadjusted Langevin algorithms: learning and discretizing perturbed samplers. (arXiv:2302.07227v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.07227
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20132;&#36890;&#22270;&#26410;&#35843;&#25972;&#30340; Langevin &#31639;&#27861; (ULA) &#21644; Riemann &#27969;&#24418; Langevin &#21160;&#21147;&#23398; (RMLD)&#65292;&#36890;&#36807;&#24212;&#29992;&#20132;&#36890;&#22270;&#21487;&#20197;&#21152;&#36895; Langevin &#21160;&#21147;&#23398;&#30340;&#25910;&#25947;&#65292;&#24182;&#25552;&#20379;&#20102;&#23398;&#20064;&#24230;&#37327;&#21644;&#25200;&#21160;&#30340;&#26032;&#24605;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Langevin &#21160;&#21147;&#23398;&#34987;&#24191;&#27867;&#29992;&#20110;&#25277;&#26679;&#39640;&#32500;&#12289;&#38750;&#39640;&#26031;&#20998;&#24067;&#65292;&#20854;&#23494;&#24230;&#24050;&#30693;&#20294;&#24120;&#25968;&#26410;&#30693;&#12290;&#29305;&#21035;&#24863;&#20852;&#36259;&#30340;&#26159;&#26410;&#20462;&#27491;&#30340; Langevin &#31639;&#27861; (ULA)&#65292;&#23427;&#30452;&#25509;&#31163;&#25955;&#21270; Langevin &#21160;&#21147;&#23398;&#20197;&#20272;&#35745;&#30446;&#26631;&#20998;&#24067;&#19978;&#30340;&#26399;&#26395;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#20351;&#29992;&#20132;&#36890;&#22270;&#26469;&#36817;&#20284;&#26631;&#20934;&#21270;&#30446;&#26631;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#20197;&#39044;&#22788;&#29702;&#21644;&#21152;&#36895; Langevin &#21160;&#21147;&#23398;&#30340;&#25910;&#25947;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#36830;&#32493;&#26102;&#38388;&#19979;&#65292;&#24403;&#23558;&#20132;&#36890;&#22270;&#24212;&#29992;&#20110; Langevin &#21160;&#21147;&#23398;&#26102;&#65292;&#32467;&#26524;&#26159;&#20855;&#26377;&#30001;&#20132;&#36890;&#22270;&#23450;&#20041;&#30340;&#24230;&#37327;&#30340; Riemann &#27969;&#24418; Langevin &#21160;&#21147;&#23398;&#65288;RMLD&#65289;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#23558;&#20132;&#36890;&#22270;&#24212;&#29992;&#20110;&#19981;&#21487;&#36870;&#25200;&#21160;&#30340; ULA &#20250;&#20135;&#29983;&#21407;&#21160;&#21147;&#23398;&#30340;&#20960;&#20309;&#20449;&#24687;&#19981;&#21487;&#36870;&#25200;&#21160; &#65288;GiIrr&#65289;&#12290;&#36825;&#20123;&#32852;&#31995;&#34920;&#26126;&#20102;&#23398;&#20064;&#24230;&#37327;&#21644;&#25200;&#21160;&#30340;&#26356;&#31995;&#32479;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#25551;&#36848; RMLD &#30340;&#26367;&#20195;&#31163;&#25955;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Langevin dynamics are widely used in sampling high-dimensional, non-Gaussian distributions whose densities are known up to a normalizing constant. In particular, there is strong interest in unadjusted Langevin algorithms (ULA), which directly discretize Langevin dynamics to estimate expectations over the target distribution. We study the use of transport maps that approximately normalize a target distribution as a way to precondition and accelerate the convergence of Langevin dynamics. We show that in continuous time, when a transport map is applied to Langevin dynamics, the result is a Riemannian manifold Langevin dynamics (RMLD) with metric defined by the transport map. We also show that applying a transport map to an irreversibly-perturbed ULA results in a geometry-informed irreversible perturbation (GiIrr) of the original dynamics. These connections suggest more systematic ways of learning metrics and perturbations, and also yield alternative discretizations of the RMLD described b
&lt;/p&gt;</description></item></channel></rss>