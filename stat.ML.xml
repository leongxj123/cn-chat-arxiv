<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#22810;&#27169;&#24577;&#34920;&#31034;&#23398;&#20064;&#20013;&#23545;&#40784;&#19981;&#37197;&#23545;&#26679;&#26412;&#25361;&#25112;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20272;&#35745;&#20542;&#21521;&#24471;&#20998;&#26469;&#23450;&#20041;&#26679;&#26412;&#20043;&#38388;&#30340;&#36317;&#31163;&#12290;</title><link>https://arxiv.org/abs/2404.01595</link><description>&lt;p&gt;
&#22810;&#27169;&#24577;&#25968;&#25454;&#26080;&#37197;&#23545;&#20542;&#21521;&#24471;&#20998;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Propensity Score Alignment of Unpaired Multimodal Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01595
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#22810;&#27169;&#24577;&#34920;&#31034;&#23398;&#20064;&#20013;&#23545;&#40784;&#19981;&#37197;&#23545;&#26679;&#26412;&#25361;&#25112;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20272;&#35745;&#20542;&#21521;&#24471;&#20998;&#26469;&#23450;&#20041;&#26679;&#26412;&#20043;&#38388;&#30340;&#36317;&#31163;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24577;&#34920;&#31034;&#23398;&#20064;&#25216;&#26415;&#36890;&#24120;&#20381;&#36182;&#20110;&#37197;&#23545;&#26679;&#26412;&#26469;&#23398;&#20064;&#20849;&#21516;&#30340;&#34920;&#31034;&#65292;&#20294;&#22312;&#29983;&#29289;&#23398;&#31561;&#39046;&#22495;&#65292;&#24448;&#24448;&#38590;&#20197;&#25910;&#38598;&#37197;&#23545;&#26679;&#26412;&#65292;&#22240;&#20026;&#27979;&#37327;&#35774;&#22791;&#36890;&#24120;&#20250;&#30772;&#22351;&#26679;&#26412;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#35299;&#20915;&#22810;&#27169;&#24577;&#34920;&#31034;&#23398;&#20064;&#20013;&#23545;&#40784;&#19981;&#37197;&#23545;&#26679;&#26412;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#23558;&#22240;&#26524;&#25512;&#26029;&#20013;&#30340;&#28508;&#22312;&#32467;&#26524;&#19982;&#22810;&#27169;&#24577;&#35266;&#23519;&#20013;&#30340;&#28508;&#22312;&#35270;&#22270;&#36827;&#34892;&#31867;&#27604;&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#20351;&#29992;Rubin&#30340;&#26694;&#26550;&#26469;&#20272;&#35745;&#19968;&#20010;&#20849;&#21516;&#30340;&#31354;&#38388;&#65292;&#20197;&#21305;&#37197;&#26679;&#26412;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20551;&#35774;&#25105;&#20204;&#25910;&#38598;&#20102;&#32463;&#36807;&#22788;&#29702;&#23454;&#39564;&#24178;&#25200;&#30340;&#26679;&#26412;&#65292;&#24182;&#21033;&#29992;&#27492;&#26469;&#20174;&#27599;&#31181;&#27169;&#24577;&#20013;&#20272;&#35745;&#20542;&#21521;&#24471;&#20998;&#65292;&#20854;&#20013;&#21253;&#25324;&#28508;&#22312;&#29366;&#24577;&#21644;&#22788;&#29702;&#20043;&#38388;&#30340;&#25152;&#26377;&#20849;&#20139;&#20449;&#24687;&#65292;&#24182;&#21487;&#29992;&#20110;&#23450;&#20041;&#26679;&#26412;&#20043;&#38388;&#30340;&#36317;&#31163;&#12290;&#25105;&#20204;&#23581;&#35797;&#20102;&#20004;&#31181;&#21033;&#29992;&#36825;&#19968;&#26041;&#27861;&#30340;&#23545;&#40784;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01595v1 Announce Type: new  Abstract: Multimodal representation learning techniques typically rely on paired samples to learn common representations, but paired samples are challenging to collect in fields such as biology where measurement devices often destroy the samples. This paper presents an approach to address the challenge of aligning unpaired samples across disparate modalities in multimodal representation learning. We draw an analogy between potential outcomes in causal inference and potential views in multimodal observations, which allows us to use Rubin's framework to estimate a common space in which to match samples. Our approach assumes we collect samples that are experimentally perturbed by treatments, and uses this to estimate a propensity score from each modality, which encapsulates all shared information between a latent state and treatment and can be used to define a distance between samples. We experiment with two alignment techniques that leverage this di
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#31283;&#20581;&#30340;&#20272;&#35745;&#37327;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#29616;&#20195;&#25968;&#25454;&#20016;&#23500;&#30340;&#29615;&#22659;&#20013;&#20272;&#35745;&#23384;&#22312;&#26410;&#35266;&#23519;&#28151;&#26434;&#22240;&#32032;&#19979;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#26377;&#38480;&#26679;&#26412;&#21644;&#28176;&#36817;&#24615;&#36136;&#65292;&#24182;&#22312;&#21442;&#25968;&#36895;&#29575;&#19979;&#23558;&#20854;&#35823;&#24046;&#25910;&#25947;&#20026;&#38646;&#22343;&#20540;&#39640;&#26031;&#20998;&#24067;&#12290;</title><link>https://arxiv.org/abs/2402.11652</link><description>&lt;p&gt;
&#22240;&#26524;&#28508;&#22312;&#22240;&#23376;&#27169;&#22411;&#20013;&#30340;&#21452;&#37325;&#31283;&#20581;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Doubly Robust Inference in Causal Latent Factor Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11652
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#31283;&#20581;&#30340;&#20272;&#35745;&#37327;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#29616;&#20195;&#25968;&#25454;&#20016;&#23500;&#30340;&#29615;&#22659;&#20013;&#20272;&#35745;&#23384;&#22312;&#26410;&#35266;&#23519;&#28151;&#26434;&#22240;&#32032;&#19979;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#26377;&#38480;&#26679;&#26412;&#21644;&#28176;&#36817;&#24615;&#36136;&#65292;&#24182;&#22312;&#21442;&#25968;&#36895;&#29575;&#19979;&#23558;&#20854;&#35823;&#24046;&#25910;&#25947;&#20026;&#38646;&#22343;&#20540;&#39640;&#26031;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#29616;&#20195;&#25968;&#25454;&#20016;&#23500;&#29615;&#22659;&#20013;&#20272;&#35745;&#23384;&#22312;&#26410;&#35266;&#23519;&#28151;&#26434;&#22240;&#32032;&#19979;&#30340;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#30340;&#26032;&#26694;&#26550;&#65292;&#35813;&#29615;&#22659;&#20855;&#26377;&#22823;&#37327;&#21333;&#20301;&#21644;&#32467;&#26524;&#12290;&#25152;&#25552;&#20986;&#30340;&#20272;&#35745;&#37327;&#26159;&#21452;&#37325;&#31283;&#20581;&#30340;&#65292;&#32467;&#21512;&#20102;&#32467;&#26524;&#22635;&#34917;&#12289;&#20498;&#25968;&#27010;&#29575;&#21152;&#26435;&#20197;&#21450;&#19968;&#31181;&#29992;&#20110;&#30697;&#38453;&#34917;&#20840;&#30340;&#26032;&#22411;&#20132;&#21449;&#37197;&#23545;&#31243;&#24207;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#26377;&#38480;&#26679;&#26412;&#21644;&#28176;&#36817;&#20445;&#35777;&#65292;&#24182;&#23637;&#31034;&#20102;&#26032;&#20272;&#35745;&#37327;&#30340;&#35823;&#24046;&#25910;&#25947;&#21040;&#21442;&#25968;&#36895;&#29575;&#19979;&#30340;&#38646;&#22343;&#20540;&#39640;&#26031;&#20998;&#24067;&#12290;&#27169;&#25311;&#32467;&#26524;&#23637;&#31034;&#20102;&#26412;&#25991;&#20998;&#26512;&#30340;&#20272;&#35745;&#37327;&#30340;&#24418;&#24335;&#29305;&#24615;&#30340;&#23454;&#38469;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11652v1 Announce Type: cross  Abstract: This article introduces a new framework for estimating average treatment effects under unobserved confounding in modern data-rich environments featuring large numbers of units and outcomes. The proposed estimator is doubly robust, combining outcome imputation, inverse probability weighting, and a novel cross-fitting procedure for matrix completion. We derive finite-sample and asymptotic guarantees, and show that the error of the new estimator converges to a mean-zero Gaussian distribution at a parametric rate. Simulation results demonstrate the practical relevance of the formal properties of the estimators analyzed in this article.
&lt;/p&gt;</description></item><item><title>OptEx&#26159;&#31532;&#19968;&#20010;&#36890;&#36807;&#21033;&#29992;&#24182;&#34892;&#35745;&#31639;&#26469;&#20943;&#36731;&#19968;&#38454;&#20248;&#21270;&#30340;&#36845;&#20195;&#29942;&#39048;&#24182;&#22686;&#24378;&#25928;&#29575;&#30340;&#26694;&#26550;&#65292;&#20351;&#29992;&#26680;&#21270;&#26799;&#24230;&#20272;&#35745;&#23454;&#29616;&#36845;&#20195;&#30340;&#24182;&#34892;&#21270;&#65292;&#25552;&#20379;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2402.11427</link><description>&lt;p&gt;
OptEx: &#21033;&#29992;&#36817;&#20284;&#24182;&#34892;&#21270;&#36845;&#20195;&#21152;&#36895;&#19968;&#38454;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
OptEx: Expediting First-Order Optimization with Approximately Parallelized Iterations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11427
&lt;/p&gt;
&lt;p&gt;
OptEx&#26159;&#31532;&#19968;&#20010;&#36890;&#36807;&#21033;&#29992;&#24182;&#34892;&#35745;&#31639;&#26469;&#20943;&#36731;&#19968;&#38454;&#20248;&#21270;&#30340;&#36845;&#20195;&#29942;&#39048;&#24182;&#22686;&#24378;&#25928;&#29575;&#30340;&#26694;&#26550;&#65292;&#20351;&#29992;&#26680;&#21270;&#26799;&#24230;&#20272;&#35745;&#23454;&#29616;&#36845;&#20195;&#30340;&#24182;&#34892;&#21270;&#65292;&#25552;&#20379;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31532;&#19968;&#38454;&#20248;&#21270;&#65288;FOO&#65289;&#31639;&#27861;&#22312;&#35832;&#22914;&#26426;&#22120;&#23398;&#20064;&#21644;&#20449;&#21495;&#21435;&#22122;&#31561;&#20247;&#22810;&#35745;&#31639;&#39046;&#22495;&#20013;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#23558;&#23427;&#20204;&#24212;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#31561;&#22797;&#26434;&#20219;&#21153;&#24448;&#24448;&#23548;&#33268;&#26174;&#33879;&#30340;&#20302;&#25928;&#65292;&#22240;&#20026;&#38656;&#35201;&#35768;&#22810;&#39034;&#24207;&#36845;&#20195;&#20197;&#23454;&#29616;&#25910;&#25947;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#31532;&#19968;&#38454;&#20248;&#21270;&#21152;&#36895;&#36817;&#20284;&#24182;&#34892;&#36845;&#20195;&#65288;OptEx&#65289;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#36890;&#36807;&#21033;&#29992;&#24182;&#34892;&#35745;&#31639;&#26469;&#20943;&#36731;&#20854;&#36845;&#20195;&#29942;&#39048;&#32780;&#22686;&#24378;FOO&#25928;&#29575;&#30340;&#26694;&#26550;&#12290;OptEx&#37319;&#29992;&#26680;&#21270;&#26799;&#24230;&#20272;&#35745;&#26469;&#21033;&#29992;&#26799;&#24230;&#21382;&#21490;&#36827;&#34892;&#26410;&#26469;&#26799;&#24230;&#39044;&#27979;&#65292;&#23454;&#29616;&#20102;&#36845;&#20195;&#30340;&#24182;&#34892;&#21270; -- &#36825;&#26159;&#19968;&#31181;&#26366;&#32463;&#34987;&#35748;&#20026;&#30001;&#20110;FOO&#20013;&#22266;&#26377;&#30340;&#36845;&#20195;&#20381;&#36182;&#32780;&#19981;&#20999;&#23454;&#38469;&#30340;&#31574;&#30053;&#12290;&#25105;&#20204;&#20026;&#25105;&#20204;&#30340;&#26680;&#21270;&#26799;&#24230;&#20272;&#35745;&#30340;&#21487;&#38752;&#24615;&#21644;&#22522;&#20110;SGD&#30340;OptEx&#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#25552;&#20379;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#30830;&#35748;&#20102;&#20854;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11427v1 Announce Type: cross  Abstract: First-order optimization (FOO) algorithms are pivotal in numerous computational domains such as machine learning and signal denoising. However, their application to complex tasks like neural network training often entails significant inefficiencies due to the need for many sequential iterations for convergence. In response, we introduce first-order optimization expedited with approximately parallelized iterations (OptEx), the first framework that enhances the efficiency of FOO by leveraging parallel computing to mitigate its iterative bottleneck. OptEx employs kernelized gradient estimation to make use of gradient history for future gradient prediction, enabling parallelization of iterations -- a strategy once considered impractical because of the inherent iterative dependency in FOO. We provide theoretical guarantees for the reliability of our kernelized gradient estimation and the iteration complexity of SGD-based OptEx, confirming t
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#32508;&#21512;&#30340;&#22810;&#20445;&#30495;&#24230;&#20195;&#29702;&#24314;&#27169;&#26694;&#26550;&#65292;&#33021;&#22815;&#23558;&#40657;&#30418;&#27169;&#22411;&#21644;&#30333;&#30418;&#27169;&#22411;&#30340;&#20449;&#24687;&#32467;&#21512;&#36215;&#26469;&#65292;&#24182;&#33021;&#22815;&#22788;&#29702;&#22122;&#22768;&#27745;&#26579;&#30340;&#25968;&#25454;&#65292;&#24182;&#20272;&#35745;&#20986;&#26080;&#22122;&#22768;&#30340;&#39640;&#20445;&#30495;&#24230;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2401.06447</link><description>&lt;p&gt;
&#19968;&#20010;&#32508;&#21512;&#30340;&#22810;&#20445;&#30495;&#24230;&#20195;&#29702;&#24314;&#27169;&#26694;&#26550;&#65292;&#24102;&#26377;&#22122;&#22768;&#25968;&#25454;&#65306;&#20174;&#28784;&#30418;&#30340;&#35282;&#24230;&#26469;&#30475;
&lt;/p&gt;
&lt;p&gt;
A comprehensive framework for multi-fidelity surrogate modeling with noisy data: a gray-box perspective. (arXiv:2401.06447v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06447
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#32508;&#21512;&#30340;&#22810;&#20445;&#30495;&#24230;&#20195;&#29702;&#24314;&#27169;&#26694;&#26550;&#65292;&#33021;&#22815;&#23558;&#40657;&#30418;&#27169;&#22411;&#21644;&#30333;&#30418;&#27169;&#22411;&#30340;&#20449;&#24687;&#32467;&#21512;&#36215;&#26469;&#65292;&#24182;&#33021;&#22815;&#22788;&#29702;&#22122;&#22768;&#27745;&#26579;&#30340;&#25968;&#25454;&#65292;&#24182;&#20272;&#35745;&#20986;&#26080;&#22122;&#22768;&#30340;&#39640;&#20445;&#30495;&#24230;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35745;&#31639;&#26426;&#27169;&#25311;&#65288;&#21363;&#30333;&#30418;&#27169;&#22411;&#65289;&#22312;&#27169;&#25311;&#22797;&#26434;&#24037;&#31243;&#31995;&#32479;&#26041;&#38754;&#27604;&#20197;&#24448;&#20219;&#20309;&#26102;&#20505;&#37117;&#26356;&#21152;&#24517;&#19981;&#21487;&#23569;&#12290;&#28982;&#32780;&#65292;&#20165;&#20973;&#35745;&#31639;&#27169;&#22411;&#24448;&#24448;&#26080;&#27861;&#23436;&#20840;&#25429;&#25417;&#29616;&#23454;&#30340;&#22797;&#26434;&#24615;&#12290;&#24403;&#29289;&#29702;&#23454;&#39564;&#21487;&#34892;&#26102;&#65292;&#22686;&#24378;&#35745;&#31639;&#27169;&#22411;&#25552;&#20379;&#30340;&#19981;&#23436;&#25972;&#20449;&#24687;&#21464;&#24471;&#38750;&#24120;&#37325;&#35201;&#12290;&#28784;&#30418;&#24314;&#27169;&#28041;&#21450;&#21040;&#23558;&#25968;&#25454;&#39537;&#21160;&#27169;&#22411;&#65288;&#21363;&#40657;&#30418;&#27169;&#22411;&#65289;&#21644;&#30333;&#30418;&#27169;&#22411;&#65288;&#21363;&#22522;&#20110;&#29289;&#29702;&#30340;&#27169;&#22411;&#65289;&#30340;&#20449;&#24687;&#34701;&#21512;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#22810;&#20445;&#30495;&#24230;&#20195;&#29702;&#27169;&#22411;&#65288;MFSMs&#65289;&#26469;&#25191;&#34892;&#36825;&#20010;&#20219;&#21153;&#12290;MFSM&#23558;&#19981;&#21516;&#35745;&#31639;&#20445;&#30495;&#24230;&#30340;&#27169;&#22411;&#30340;&#20449;&#24687;&#38598;&#25104;&#21040;&#19968;&#20010;&#26032;&#30340;&#20195;&#29702;&#27169;&#22411;&#20013;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#22810;&#20445;&#30495;&#24230;&#20195;&#29702;&#24314;&#27169;&#26694;&#26550;&#33021;&#22815;&#22788;&#29702;&#34987;&#22122;&#22768;&#27745;&#26579;&#30340;&#25968;&#25454;&#65292;&#24182;&#33021;&#22815;&#20272;&#35745;&#24213;&#23618;&#26080;&#22122;&#22768;&#30340;&#39640;&#20445;&#30495;&#24230;&#20989;&#25968;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#24378;&#35843;&#20197;&#32622;&#20449;&#24230;&#30340;&#24418;&#24335;&#25552;&#20379;&#20854;&#39044;&#27979;&#20013;&#19981;&#30830;&#23450;&#24615;&#30340;&#31934;&#30830;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Computer simulations (a.k.a. white-box models) are more indispensable than ever to model intricate engineering systems. However, computational models alone often fail to fully capture the complexities of reality. When physical experiments are accessible though, it is of interest to enhance the incomplete information offered by computational models. Gray-box modeling is concerned with the problem of merging information from data-driven (a.k.a. black-box) models and white-box (i.e., physics-based) models. In this paper, we propose to perform this task by using multi-fidelity surrogate models (MFSMs). A MFSM integrates information from models with varying computational fidelity into a new surrogate model. The multi-fidelity surrogate modeling framework we propose handles noise-contaminated data and is able to estimate the underlying noise-free high-fidelity function. Our methodology emphasizes on delivering precise estimates of the uncertainty in its predictions in the form of confidence 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#35797;&#39564;&#21644;&#35266;&#23519;&#25968;&#25454;&#30340;&#22806;&#37096;&#26377;&#25928;&#31574;&#30053;&#35780;&#20272;&#26041;&#27861;&#65292;&#21033;&#29992;&#35797;&#39564;&#25968;&#25454;&#23545;&#30446;&#26631;&#20154;&#32676;&#19978;&#30340;&#25919;&#31574;&#32467;&#26524;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#65292;&#24182;&#32473;&#20986;&#20102;&#21487;&#39564;&#35777;&#30340;&#35780;&#20272;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.14763</link><description>&lt;p&gt;
&#22806;&#37096;&#39564;&#35777;&#31574;&#30053;&#35780;&#20272;&#32467;&#21512;&#35797;&#39564;&#21644;&#35266;&#23519;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Externally Valid Policy Evaluation Combining Trial and Observational Data. (arXiv:2310.14763v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14763
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#35797;&#39564;&#21644;&#35266;&#23519;&#25968;&#25454;&#30340;&#22806;&#37096;&#26377;&#25928;&#31574;&#30053;&#35780;&#20272;&#26041;&#27861;&#65292;&#21033;&#29992;&#35797;&#39564;&#25968;&#25454;&#23545;&#30446;&#26631;&#20154;&#32676;&#19978;&#30340;&#25919;&#31574;&#32467;&#26524;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#65292;&#24182;&#32473;&#20986;&#20102;&#21487;&#39564;&#35777;&#30340;&#35780;&#20272;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#35797;&#39564;&#34987;&#24191;&#27867;&#35748;&#20026;&#26159;&#35780;&#20272;&#20915;&#31574;&#31574;&#30053;&#24433;&#21709;&#30340;&#37329; standard&#12290;&#28982;&#32780;&#65292;&#35797;&#39564;&#25968;&#25454;&#26469;&#33258;&#21487;&#33021;&#19982;&#30446;&#26631;&#20154;&#32676;&#19981;&#21516;&#30340;&#20154;&#32676;&#65292;&#36825;&#24341;&#21457;&#20102;&#22806;&#37096;&#25928;&#24230;&#65288;&#20063;&#31216;&#20026;&#27867;&#21270;&#33021;&#21147;&#65289;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35797;&#22270;&#21033;&#29992;&#35797;&#39564;&#25968;&#25454;&#23545;&#30446;&#26631;&#20154;&#32676;&#19978;&#30340;&#25919;&#31574;&#32467;&#26524;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#12290;&#30446;&#26631;&#20154;&#32676;&#30340;&#39069;&#22806;&#21327;&#21464;&#37327;&#25968;&#25454;&#29992;&#20110;&#27169;&#25311;&#35797;&#39564;&#30740;&#31350;&#20013;&#20010;&#20307;&#30340;&#25277;&#26679;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#22312;&#20219;&#20309;&#25351;&#23450;&#30340;&#27169;&#22411;&#26410;&#26657;&#20934;&#33539;&#22260;&#20869;&#20135;&#29983;&#21487;&#39564;&#35777;&#30340;&#22522;&#20110;&#35797;&#39564;&#30340;&#25919;&#31574;&#35780;&#20272;&#12290;&#35813;&#26041;&#27861;&#26159;&#38750;&#21442;&#25968;&#30340;&#65292;&#21363;&#20351;&#26679;&#26412;&#26159;&#26377;&#38480;&#30340;&#65292;&#26377;&#25928;&#24615;&#20063;&#24471;&#21040;&#20445;&#35777;&#12290;&#20351;&#29992;&#27169;&#25311;&#21644;&#23454;&#38469;&#25968;&#25454;&#35828;&#26126;&#20102;&#35748;&#35777;&#30340;&#25919;&#31574;&#35780;&#20272;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Randomized trials are widely considered as the gold standard for evaluating the effects of decision policies. Trial data is, however, drawn from a population which may differ from the intended target population and this raises a problem of external validity (aka. generalizability). In this paper we seek to use trial data to draw valid inferences about the outcome of a policy on the target population. Additional covariate data from the target population is used to model the sampling of individuals in the trial study. We develop a method that yields certifiably valid trial-based policy evaluations under any specified range of model miscalibrations. The method is nonparametric and the validity is assured even with finite samples. The certified policy evaluations are illustrated using both simulated and real data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#39640;&#32500;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#24046;&#20998;&#38544;&#31169;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#25105;&#20204;&#20351;&#29992;&#25351;&#25968;&#26426;&#21046;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#65292;&#24182;&#25552;&#20986;&#20102;Metropolis-Hastings&#31639;&#27861;&#26469;&#20811;&#26381;&#25351;&#25968;&#25628;&#32034;&#31354;&#38388;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#19968;&#23450;&#36793;&#30028;&#26465;&#20214;&#19979;&#33021;&#22815;&#23454;&#29616;&#24378;&#27169;&#22411;&#24674;&#22797;&#24615;&#36136;&#65292;&#24182;&#20855;&#26377;&#22810;&#39033;&#24335;&#28151;&#21512;&#26102;&#38388;&#21644;&#36817;&#20284;&#24046;&#20998;&#38544;&#31169;&#24615;&#36136;&#12290;</title><link>http://arxiv.org/abs/2310.07852</link><description>&lt;p&gt;
&#20851;&#20110;&#36890;&#36807;&#25351;&#25968;&#26426;&#21046;&#36827;&#34892;&#39640;&#32500;&#31169;&#26377;&#27169;&#22411;&#36873;&#25321;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Computational Complexity of Private High-dimensional Model Selection via the Exponential Mechanism. (arXiv:2310.07852v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07852
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#39640;&#32500;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#24046;&#20998;&#38544;&#31169;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#25105;&#20204;&#20351;&#29992;&#25351;&#25968;&#26426;&#21046;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#65292;&#24182;&#25552;&#20986;&#20102;Metropolis-Hastings&#31639;&#27861;&#26469;&#20811;&#26381;&#25351;&#25968;&#25628;&#32034;&#31354;&#38388;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#19968;&#23450;&#36793;&#30028;&#26465;&#20214;&#19979;&#33021;&#22815;&#23454;&#29616;&#24378;&#27169;&#22411;&#24674;&#22797;&#24615;&#36136;&#65292;&#24182;&#20855;&#26377;&#22810;&#39033;&#24335;&#28151;&#21512;&#26102;&#38388;&#21644;&#36817;&#20284;&#24046;&#20998;&#38544;&#31169;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24046;&#20998;&#38544;&#31169;&#26694;&#26550;&#19979;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#39640;&#32500;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#24046;&#20998;&#38544;&#31169;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#30340;&#38382;&#39064;&#65292;&#24182;&#30740;&#31350;&#20102;&#20854;&#25928;&#29992;&#20445;&#35777;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#24191;&#20026;&#20154;&#30693;&#30340;&#25351;&#25968;&#26426;&#21046;&#26469;&#36873;&#25321;&#26368;&#20339;&#27169;&#22411;&#65292;&#24182;&#22312;&#19968;&#23450;&#36793;&#30028;&#26465;&#20214;&#19979;&#65292;&#24314;&#31435;&#20102;&#20854;&#24378;&#27169;&#22411;&#24674;&#22797;&#24615;&#36136;&#12290;&#28982;&#32780;&#65292;&#25351;&#25968;&#26426;&#21046;&#30340;&#25351;&#25968;&#25628;&#32034;&#31354;&#38388;&#23548;&#33268;&#20102;&#20005;&#37325;&#30340;&#35745;&#31639;&#29942;&#39048;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Metropolis-Hastings&#31639;&#27861;&#26469;&#36827;&#34892;&#37319;&#26679;&#27493;&#39588;&#65292;&#24182;&#22312;&#38382;&#39064;&#21442;&#25968;$n$&#12289;$p$&#21644;$s$&#20013;&#24314;&#31435;&#20102;&#20854;&#21040;&#31283;&#24577;&#20998;&#24067;&#30340;&#22810;&#39033;&#24335;&#28151;&#21512;&#26102;&#38388;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#21033;&#29992;&#20854;&#28151;&#21512;&#24615;&#36136;&#24314;&#31435;&#20102;Metropolis-Hastings&#38543;&#26426;&#34892;&#36208;&#30340;&#26368;&#32456;&#20272;&#35745;&#30340;&#36817;&#20284;&#24046;&#20998;&#38544;&#31169;&#24615;&#36136;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#19968;&#20123;&#35828;&#26126;&#24615;&#27169;&#25311;&#65292;&#21360;&#35777;&#20102;&#25105;&#20204;&#20027;&#35201;&#32467;&#26524;&#30340;&#29702;&#35770;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of model selection in a high-dimensional sparse linear regression model under the differential privacy framework. In particular, we consider the problem of differentially private best subset selection and study its utility guarantee. We adopt the well-known exponential mechanism for selecting the best model, and under a certain margin condition, we establish its strong model recovery property. However, the exponential search space of the exponential mechanism poses a serious computational bottleneck. To overcome this challenge, we propose a Metropolis-Hastings algorithm for the sampling step and establish its polynomial mixing time to its stationary distribution in the problem parameters $n,p$, and $s$. Furthermore, we also establish approximate differential privacy for the final estimates of the Metropolis-Hastings random walk using its mixing property. Finally, we also perform some illustrative simulations that echo the theoretical findings of our main results
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#20999;&#21521;&#26680;&#35270;&#35282;&#30340;&#32852;&#37030;&#24179;&#22343;&#26041;&#27861;&#22312;&#28145;&#24230;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#19978;&#30340;&#24212;&#29992;&#65292;&#24182;&#25506;&#35752;&#20102;&#35813;&#26041;&#27861;&#38754;&#20020;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2310.05495</link><description>&lt;p&gt;
&#22522;&#20110;&#31070;&#32463;&#20999;&#21521;&#26680;&#30340;&#32852;&#37030;&#24179;&#22343;&#22312;&#28145;&#24230;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#19978;&#30340;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
A Neural Tangent Kernel View on Federated Averaging for Deep Linear Neural Network. (arXiv:2310.05495v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05495
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#20999;&#21521;&#26680;&#35270;&#35282;&#30340;&#32852;&#37030;&#24179;&#22343;&#26041;&#27861;&#22312;&#28145;&#24230;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#19978;&#30340;&#24212;&#29992;&#65292;&#24182;&#25506;&#35752;&#20102;&#35813;&#26041;&#27861;&#38754;&#20020;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#24179;&#22343;&#65288;FedAvg&#65289;&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#33539;&#24335;&#65292;&#29992;&#20110;&#22312;&#19981;&#20849;&#20139;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#21327;&#21516;&#35757;&#32451;&#26469;&#33258;&#20998;&#24067;&#24335;&#23458;&#25143;&#31471;&#30340;&#27169;&#22411;&#12290;&#22914;&#20170;&#65292;&#30001;&#20110;&#20854;&#21331;&#36234;&#24615;&#33021;&#65292;&#31070;&#32463;&#32593;&#32476;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#65292;&#36825;&#20351;&#24471;&#23427;&#25104;&#20026;FedAvg&#20013;&#30340;&#39318;&#36873;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#31070;&#32463;&#32593;&#32476;&#30340;&#20248;&#21270;&#38382;&#39064;&#36890;&#24120;&#26159;&#38750;&#20984;&#30340;&#29978;&#33267;&#26159;&#38750;&#20809;&#28369;&#30340;&#12290;&#27492;&#22806;&#65292;FedAvg&#24635;&#26159;&#28041;&#21450;&#22810;&#20010;&#23458;&#25143;&#31471;&#21644;&#26412;&#22320;&#26356;&#26032;&#65292;&#23548;&#33268;&#19981;&#20934;&#30830;&#30340;&#26356;&#26032;&#26041;&#21521;&#12290;&#36825;&#20123;&#23646;&#24615;&#32473;&#20998;&#26512;FedAvg&#22312;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#25910;&#25947;&#24615;&#24102;&#26469;&#20102;&#22256;&#38590;&#12290;&#26368;&#36817;&#65292;&#31070;&#32463;&#20999;&#21521;&#26680;&#65288;NTK&#65289;&#29702;&#35770;&#24050;&#34987;&#25552;&#20986;&#65292;&#29992;&#20110;&#29702;&#35299;&#35299;&#20915;&#31070;&#32463;&#32593;&#32476;&#38750;&#20984;&#38382;&#39064;&#20013;&#30340;&#19968;&#38454;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;&#28145;&#24230;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#26159;&#29702;&#35770;&#23398;&#31185;&#20013;&#30340;&#32463;&#20856;&#27169;&#22411;&#65292;&#30001;&#20110;&#20854;&#31616;&#21333;&#30340;&#20844;&#24335;&#12290;&#28982;&#32780;&#65292;&#22312;&#35757;&#32451;&#28145;&#24230;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#19978;&#65292;&#23545;&#20110;FedAvg&#30340;&#25910;&#25947;&#24615;&#30446;&#21069;&#36824;&#27809;&#26377;&#29702;&#35770;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated averaging (FedAvg) is a widely employed paradigm for collaboratively training models from distributed clients without sharing data. Nowadays, the neural network has achieved remarkable success due to its extraordinary performance, which makes it a preferred choice as the model in FedAvg. However, the optimization problem of the neural network is often non-convex even non-smooth. Furthermore, FedAvg always involves multiple clients and local updates, which results in an inaccurate updating direction. These properties bring difficulties in analyzing the convergence of FedAvg in training neural networks. Recently, neural tangent kernel (NTK) theory has been proposed towards understanding the convergence of first-order methods in tackling the non-convex problem of neural networks. The deep linear neural network is a classical model in theoretical subject due to its simple formulation. Nevertheless, there exists no theoretical result for the convergence of FedAvg in training the d
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#26088;&#22312;&#25552;&#20379;IRM&#30340;&#29702;&#35770;&#39564;&#35777;&#65292;&#20005;&#26684;&#35777;&#26126;&#20102;&#35299;&#20915;&#26041;&#26696;&#21487;&#20197;&#26368;&#23567;&#21270;&#21306;&#22806;&#39118;&#38505;&#12290;</title><link>http://arxiv.org/abs/2307.11972</link><description>&lt;p&gt;
&#19981;&#21464;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#21306;&#22806;&#20248;&#21270;&#24615;
&lt;/p&gt;
&lt;p&gt;
Out-of-Distribution Optimality of Invariant Risk Minimization. (arXiv:2307.11972v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11972
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#25552;&#20379;IRM&#30340;&#29702;&#35770;&#39564;&#35777;&#65292;&#20005;&#26684;&#35777;&#26126;&#20102;&#35299;&#20915;&#26041;&#26696;&#21487;&#20197;&#26368;&#23567;&#21270;&#21306;&#22806;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#32463;&#24120;&#32487;&#25215;&#35757;&#32451;&#25968;&#25454;&#20013;&#23884;&#20837;&#30340;&#34394;&#20551;&#30456;&#20851;&#24615;&#65292;&#22240;&#27492;&#21487;&#33021;&#26080;&#27861;&#27867;&#21270;&#21040;&#20855;&#26377;&#19982;&#25552;&#20379;&#35757;&#32451;&#25968;&#25454;&#30340;&#39046;&#22495;&#19981;&#21516;&#30340;&#26410;&#30693;&#22495;&#12290;M. Arjovsky&#31561;&#20154;&#65288;2019&#24180;&#65289;&#24341;&#20837;&#20102;&#21306;&#22806;&#65288;o.o.d.&#65289;&#39118;&#38505;&#30340;&#27010;&#24565;&#65292;&#21363;&#25152;&#26377;&#22495;&#20013;&#30340;&#26368;&#22823;&#39118;&#38505;&#65292;&#24182;&#23558;&#30001;&#34394;&#20551;&#30456;&#20851;&#24615;&#24341;&#36215;&#30340;&#38382;&#39064;&#35268;&#23450;&#20026;&#26368;&#23567;&#21270;&#21306;&#22806;&#39118;&#38505;&#30340;&#38382;&#39064;&#12290;&#19981;&#21464;&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;IRM&#65289;&#34987;&#35748;&#20026;&#26159;&#26368;&#23567;&#21270;&#21306;&#22806;&#39118;&#38505;&#30340;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#26041;&#27861;&#65306;IRM&#36890;&#36807;&#35299;&#20915;&#19968;&#20010;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#26469;&#20272;&#35745;&#26368;&#23567;&#21270;&#30340;&#21306;&#22806;&#39118;&#38505;&#12290;&#23613;&#31649;IRM&#20197;&#23454;&#35777;&#25104;&#21151;&#21560;&#24341;&#20102;&#30456;&#24403;&#22810;&#30340;&#20851;&#27880;&#65292;&#20294;&#23427;&#32570;&#20047;&#19968;&#20123;&#29702;&#35770;&#20445;&#35777;&#12290;&#29305;&#21035;&#26159;&#65292;&#36824;&#27809;&#26377;&#30830;&#31435;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#32473;&#20986;&#26368;&#23567;&#21270;&#21306;&#22806;&#39118;&#38505;&#30340;&#22362;&#23454;&#29702;&#35770;&#20445;&#35777;&#12290;&#26412;&#25991;&#26088;&#22312;&#25552;&#20379;IRM&#30340;&#29702;&#35770;&#39564;&#35777;&#65292;&#20005;&#26684;&#35777;&#26126;&#20102;&#35299;&#20915;&#26041;&#26696;&#21487;&#20197;&#36890;&#36807;&#22312;&#22823;&#20223;&#30495;&#36319;&#36394;&#25968;&#25454;&#24211;&#20013;&#36827;&#34892;&#23454;&#26102;&#20223;&#30495;&#65292;&#20854;&#21253;&#25324;&#23545;&#21608;&#22260;&#29615;&#22659;&#30340;&#30452;&#25509;&#24863;&#30693;&#65292;&#23545;&#28508;&#22312;&#36335;&#32447;&#35268;&#21010;&#30340;&#31574;&#30053;&#35748;&#35782;&#65292;&#21516;&#26102;&#32771;&#34385;&#21040;&#22810;&#36710;&#36742;&#20132;&#20114;&#65292;&#20197;&#23454;&#29616;&#35813;&#38382;&#39064;&#30340;&#20840;&#23616;&#20248;&#21270;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep Neural Networks often inherit spurious correlations embedded in training data and hence may fail to generalize to unseen domains, which have different distributions from the domain to provide training data. M. Arjovsky et al. (2019) introduced the concept out-of-distribution (o.o.d.) risk, which is the maximum risk among all domains, and formulated the issue caused by spurious correlations as a minimization problem of the o.o.d. risk. Invariant Risk Minimization (IRM) is considered to be a promising approach to minimize the o.o.d. risk: IRM estimates a minimum of the o.o.d. risk by solving a bi-level optimization problem. While IRM has attracted considerable attention with empirical success, it comes with few theoretical guarantees. Especially, a solid theoretical guarantee that the bi-level optimization problem gives the minimum of the o.o.d. risk has not yet been established. Aiming at providing a theoretical justification for IRM, this paper rigorously proves that a solution to
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#36866;&#24403;&#21021;&#22987;&#21270;&#30340;&#26377;&#38480;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#21560;&#25910;&#30456;&#21464;&#21450;&#20854;&#26222;&#36866;&#24615;&#65292;&#35777;&#26126;&#20102;&#21363;&#20351;&#22312;&#26377;&#38480;&#32593;&#32476;&#20013;&#20173;&#28982;&#23384;&#22312;&#30528;&#20174;&#26377;&#24207;&#29366;&#24577;&#21040;&#28151;&#27788;&#29366;&#24577;&#30340;&#36807;&#28193;&#65292;&#24182;&#19988;&#19981;&#21516;&#30340;&#32593;&#32476;&#26550;&#26500;&#20250;&#21453;&#26144;&#22312;&#36807;&#28193;&#30340;&#26222;&#36866;&#31867;&#19978;&#12290;</title><link>http://arxiv.org/abs/2307.02284</link><description>&lt;p&gt;
&#20154;&#24037;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#21560;&#25910;&#30456;&#21464;
&lt;/p&gt;
&lt;p&gt;
Absorbing Phase Transitions in Artificial Deep Neural Networks. (arXiv:2307.02284v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02284
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#36866;&#24403;&#21021;&#22987;&#21270;&#30340;&#26377;&#38480;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#21560;&#25910;&#30456;&#21464;&#21450;&#20854;&#26222;&#36866;&#24615;&#65292;&#35777;&#26126;&#20102;&#21363;&#20351;&#22312;&#26377;&#38480;&#32593;&#32476;&#20013;&#20173;&#28982;&#23384;&#22312;&#30528;&#20174;&#26377;&#24207;&#29366;&#24577;&#21040;&#28151;&#27788;&#29366;&#24577;&#30340;&#36807;&#28193;&#65292;&#24182;&#19988;&#19981;&#21516;&#30340;&#32593;&#32476;&#26550;&#26500;&#20250;&#21453;&#26144;&#22312;&#36807;&#28193;&#30340;&#26222;&#36866;&#31867;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#33879;&#21517;&#30340;&#24179;&#22343;&#22330;&#29702;&#35770;&#65292;&#23545;&#20110;&#21508;&#31181;&#20307;&#31995;&#30340;&#26080;&#38480;&#23485;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#34892;&#20026;&#30340;&#29702;&#35770;&#29702;&#35299;&#24050;&#32463;&#36805;&#36895;&#21457;&#23637;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#26356;&#23454;&#38469;&#21644;&#29616;&#23454;&#37325;&#35201;&#24615;&#26356;&#24378;&#30340;&#26377;&#38480;&#32593;&#32476;&#65292;&#32570;&#20047;&#28165;&#26224;&#30452;&#35266;&#30340;&#26694;&#26550;&#26469;&#24310;&#20280;&#25105;&#20204;&#30340;&#29702;&#35299;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36866;&#24403;&#21021;&#22987;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#34892;&#20026;&#21487;&#20197;&#29992;&#21560;&#25910;&#30456;&#21464;&#20013;&#30340;&#26222;&#36941;&#20020;&#30028;&#29616;&#35937;&#26469;&#29702;&#35299;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20840;&#36830;&#25509;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#21644;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#20013;&#20174;&#26377;&#24207;&#29366;&#24577;&#21040;&#28151;&#27788;&#29366;&#24577;&#30340;&#30456;&#21464;&#65292;&#24182;&#24378;&#35843;&#20102;&#20307;&#31995;&#26550;&#26500;&#30340;&#24046;&#24322;&#19982;&#30456;&#21464;&#30340;&#26222;&#36866;&#31867;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#36824;&#25104;&#21151;&#22320;&#24212;&#29992;&#20102;&#26377;&#38480;&#23610;&#24230;&#25193;&#23637;&#30340;&#26041;&#27861;&#65292;&#36825;&#34920;&#26126;&#20102;&#30452;&#35266;&#30340;&#29616;&#35937;&#23398;&#12290;
&lt;/p&gt;
&lt;p&gt;
Theoretical understanding of the behavior of infinitely-wide neural networks has been rapidly developed for various architectures due to the celebrated mean-field theory. However, there is a lack of a clear, intuitive framework for extending our understanding to finite networks that are of more practical and realistic importance. In the present contribution, we demonstrate that the behavior of properly initialized neural networks can be understood in terms of universal critical phenomena in absorbing phase transitions. More specifically, we study the order-to-chaos transition in the fully-connected feedforward neural networks and the convolutional ones to show that (i) there is a well-defined transition from the ordered state to the chaotics state even for the finite networks, and (ii) difference in architecture is reflected in that of the universality class of the transition. Remarkably, the finite-size scaling can also be successfully applied, indicating that intuitive phenomenologic
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;SVD-QCQP&#21407;&#22987;&#23545;&#20598;&#31639;&#27861;&#30340;&#39640;&#25928;&#20869;&#26680;&#23398;&#20064;&#23454;&#29616;&#65292;&#29992;&#20110;&#23398;&#20064;&#21322;&#20998;&#31163;&#26680;&#65292;&#22823;&#22823;&#38477;&#20302;&#20102;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#24182;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#20854;&#20934;&#30830;&#24615;&#21644;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2304.07472</link><description>&lt;p&gt;
&#36890;&#29992;&#26680;&#23398;&#20064;&#30340;&#39640;&#25928;&#20984;&#20248;&#21270;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Efficient Convex Algorithms for Universal Kernel Learning. (arXiv:2304.07472v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07472
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;SVD-QCQP&#21407;&#22987;&#23545;&#20598;&#31639;&#27861;&#30340;&#39640;&#25928;&#20869;&#26680;&#23398;&#20064;&#23454;&#29616;&#65292;&#29992;&#20110;&#23398;&#20064;&#21322;&#20998;&#31163;&#26680;&#65292;&#22823;&#22823;&#38477;&#20302;&#20102;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#24182;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#20854;&#20934;&#30830;&#24615;&#21644;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#26680;&#20248;&#21270;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#20934;&#30830;&#24615;&#21644;&#22797;&#26434;&#24615;&#21462;&#20915;&#20110;&#23427;&#20204;&#33021;&#22815;&#20248;&#21270;&#30340;&#26680;&#38598;&#12290;&#29702;&#24819;&#30340;&#26680;&#38598;&#24212;&#35813;&#65306;&#20855;&#26377;&#32447;&#24615;&#21442;&#25968;&#21270;&#65288;&#20197;&#20415;&#20110;&#21487;&#22788;&#29702;&#24615;&#65289;&#65307;&#22312;&#25152;&#26377;&#26680;&#38598;&#20013;&#23494;&#38598;&#65288;&#20197;&#20415;&#20110;&#40065;&#26834;&#24615;&#65289;&#65307;&#26159;&#36890;&#29992;&#30340;&#65288;&#20197;&#20415;&#20110;&#20934;&#30830;&#24615;&#65289;&#12290;&#26368;&#36817;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26694;&#26550;&#65292;&#20351;&#29992;&#27491;&#23450;&#30697;&#38453;&#26469;&#21442;&#25968;&#21270;&#19968;&#31867;&#27491;&#21322;&#20998;&#31163;&#26680;&#12290;&#23613;&#31649;&#27492;&#31867;&#26680;&#33021;&#22815;&#28385;&#36275;&#25152;&#26377;&#19977;&#20010;&#26631;&#20934;&#65292;&#20294;&#20043;&#21069;&#29992;&#20110;&#20248;&#21270;&#27492;&#31867;&#26680;&#30340;&#31639;&#27861;&#20165;&#38480;&#20110;&#20998;&#31867;&#65292;&#24182;&#19988;&#36824;&#20381;&#36182;&#20110;&#35745;&#31639;&#22797;&#26434;&#30340;&#21322;&#23450;&#35268;&#21010;&#65288;SDP&#65289;&#31639;&#27861;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#23398;&#20064;&#21322;&#20998;&#31163;&#26680;&#30340;&#38382;&#39064;&#20316;&#20026;&#26497;&#23567;&#21270;&#26497;&#22823;&#21270;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;SVD-QCQP&#21407;&#22987;&#23545;&#20598;&#31639;&#27861;&#65292;&#20854;&#19982;&#20043;&#21069;&#22522;&#20110;SDP&#30340;&#26041;&#27861;&#30456;&#27604;&#65292;&#22823;&#22823;&#38477;&#20302;&#20102;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#20869;&#26680;&#23398;&#20064;&#23454;&#29616;&#65292;&#24182;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#20854;&#20934;&#30830;&#24615;&#21644;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
The accuracy and complexity of machine learning algorithms based on kernel optimization are determined by the set of kernels over which they are able to optimize. An ideal set of kernels should: admit a linear parameterization (for tractability); be dense in the set of all kernels (for robustness); be universal (for accuracy). Recently, a framework was proposed for using positive matrices to parameterize a class of positive semi-separable kernels. Although this class can be shown to meet all three criteria, previous algorithms for optimization of such kernels were limited to classification and furthermore relied on computationally complex Semidefinite Programming (SDP) algorithms. In this paper, we pose the problem of learning semiseparable kernels as a minimax optimization problem and propose a SVD-QCQP primal-dual algorithm which dramatically reduces the computational complexity as compared with previous SDP-based approaches. Furthermore, we provide an efficient implementation of thi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#29109;&#27491;&#21017;&#21270;&#20316;&#20026;&#19968;&#31181;&#24179;&#28369;&#26041;&#27861;&#22312;Wasserstein&#20272;&#35745;&#22120;&#20013;&#30340;&#28508;&#22312;&#30410;&#22788;&#65292;&#36890;&#36807;&#26367;&#25442;&#26368;&#20248;&#36755;&#36816;&#25104;&#26412;&#30340;&#27491;&#21017;&#21270;&#29256;&#26412;&#26469;&#23454;&#29616;&#12290;&#20027;&#35201;&#21457;&#29616;&#26159;&#29109;&#27491;&#21017;&#21270;&#21487;&#20197;&#20197;&#36739;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#36798;&#21040;&#19982;&#26410;&#27491;&#21017;&#21270;&#30340;Wasserstein&#20272;&#35745;&#22120;&#30456;&#24403;&#30340;&#32479;&#35745;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2210.06934</link><description>&lt;p&gt;
&#20851;&#20110;&#20351;&#29992;&#29109;&#27491;&#21017;&#21270;&#24179;&#28369;Wasserstein&#20272;&#35745;&#22120;&#30340;&#28508;&#22312;&#30410;&#22788;
&lt;/p&gt;
&lt;p&gt;
On the potential benefits of entropic regularization for smoothing Wasserstein estimators. (arXiv:2210.06934v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.06934
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#29109;&#27491;&#21017;&#21270;&#20316;&#20026;&#19968;&#31181;&#24179;&#28369;&#26041;&#27861;&#22312;Wasserstein&#20272;&#35745;&#22120;&#20013;&#30340;&#28508;&#22312;&#30410;&#22788;&#65292;&#36890;&#36807;&#26367;&#25442;&#26368;&#20248;&#36755;&#36816;&#25104;&#26412;&#30340;&#27491;&#21017;&#21270;&#29256;&#26412;&#26469;&#23454;&#29616;&#12290;&#20027;&#35201;&#21457;&#29616;&#26159;&#29109;&#27491;&#21017;&#21270;&#21487;&#20197;&#20197;&#36739;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#36798;&#21040;&#19982;&#26410;&#27491;&#21017;&#21270;&#30340;Wasserstein&#20272;&#35745;&#22120;&#30456;&#24403;&#30340;&#32479;&#35745;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#19987;&#27880;&#20110;&#30740;&#31350;&#29109;&#27491;&#21017;&#21270;&#22312;&#26368;&#20248;&#36755;&#36816;&#20013;&#20316;&#20026;Wasserstein&#20272;&#35745;&#22120;&#30340;&#24179;&#28369;&#26041;&#27861;&#65292;&#36890;&#36807;&#32479;&#35745;&#23398;&#20013;&#36924;&#36817;&#35823;&#24046;&#21644;&#20272;&#35745;&#35823;&#24046;&#30340;&#32463;&#20856;&#26435;&#34913;&#12290;Wasserstein&#20272;&#35745;&#22120;&#34987;&#23450;&#20041;&#20026;&#35299;&#20915;&#21464;&#20998;&#38382;&#39064;&#30340;&#35299;&#65292;&#20854;&#30446;&#26631;&#20989;&#25968;&#28041;&#21450;&#27010;&#29575;&#27979;&#24230;&#20043;&#38388;&#30340;&#26368;&#20248;&#36755;&#36816;&#25104;&#26412;&#30340;&#20351;&#29992;&#12290;&#36825;&#26679;&#30340;&#20272;&#35745;&#22120;&#21487;&#20197;&#36890;&#36807;&#29992;&#29109;&#24809;&#32602;&#26367;&#25442;&#26368;&#20248;&#36755;&#36816;&#25104;&#26412;&#30340;&#27491;&#21017;&#21270;&#29256;&#26412;&#26469;&#36827;&#34892;&#27491;&#21017;&#21270;&#65292;&#20174;&#32780;&#23545;&#32467;&#26524;&#20272;&#35745;&#22120;&#20135;&#29983;&#28508;&#22312;&#30340;&#24179;&#28369;&#25928;&#26524;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#29109;&#27491;&#21017;&#21270;&#23545;&#27491;&#21017;&#21270;Wasserstein&#20272;&#35745;&#22120;&#30340;&#36924;&#36817;&#21644;&#20272;&#35745;&#24615;&#36136;&#21487;&#33021;&#24102;&#26469;&#30340;&#30410;&#22788;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#35752;&#35770;&#29109;&#27491;&#21017;&#21270;&#22914;&#20309;&#20197;&#26356;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#36798;&#21040;&#19982;&#26410;&#27491;&#21017;&#21270;&#30340;Wasserstein&#20272;&#35745;&#22120;&#30456;&#24403;&#30340;&#32479;&#35745;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper is focused on the study of entropic regularization in optimal transport as a smoothing method for Wasserstein estimators, through the prism of the classical tradeoff between approximation and estimation errors in statistics. Wasserstein estimators are defined as solutions of variational problems whose objective function involves the use of an optimal transport cost between probability measures. Such estimators can be regularized by replacing the optimal transport cost by its regularized version using an entropy penalty on the transport plan. The use of such a regularization has a potentially significant smoothing effect on the resulting estimators. In this work, we investigate its potential benefits on the approximation and estimation properties of regularized Wasserstein estimators. Our main contribution is to discuss how entropic regularization may reach, at a lower computational cost, statistical performances that are comparable to those of un-regularized Wasserstein esti
&lt;/p&gt;</description></item></channel></rss>