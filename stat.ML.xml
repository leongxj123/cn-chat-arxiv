<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36890;&#36807;&#24341;&#20837;&#26032;&#39062;&#30340;&#23450;&#24615;&#21644;&#23450;&#37327;&#27169;&#22411;&#38598;&#25104;&#35780;&#20272;&#26041;&#27861;&#65292;&#20316;&#32773;&#25581;&#31034;&#20102;&#29616;&#26377;&#38598;&#25104;&#26041;&#27861;&#30340;&#20851;&#38190;&#32570;&#38519;&#65292;&#25552;&#20986;&#20102;&#25552;&#39640;&#20256;&#32479;&#27169;&#22411;&#38598;&#25104;&#32500;&#24230;&#30340;&#26041;&#27861;&#65292;&#20197;&#20811;&#26381;&#29305;&#24449;&#34920;&#31034;&#20013;&#30340;&#22810;&#26679;&#24615;&#38480;&#21046;&#12290;</title><link>https://arxiv.org/abs/2403.16260</link><description>&lt;p&gt;
&#36890;&#36807;&#28145;&#24230;&#22810;&#29702;&#35299;&#38598;&#25104;&#23454;&#29616;&#36234;&#30028;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Out-of-Distribution Detection via Deep Multi-Comprehension Ensemble
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16260
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#26032;&#39062;&#30340;&#23450;&#24615;&#21644;&#23450;&#37327;&#27169;&#22411;&#38598;&#25104;&#35780;&#20272;&#26041;&#27861;&#65292;&#20316;&#32773;&#25581;&#31034;&#20102;&#29616;&#26377;&#38598;&#25104;&#26041;&#27861;&#30340;&#20851;&#38190;&#32570;&#38519;&#65292;&#25552;&#20986;&#20102;&#25552;&#39640;&#20256;&#32479;&#27169;&#22411;&#38598;&#25104;&#32500;&#24230;&#30340;&#26041;&#27861;&#65292;&#20197;&#20811;&#26381;&#29305;&#24449;&#34920;&#31034;&#20013;&#30340;&#22810;&#26679;&#24615;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#24378;&#35843;&#20102;&#36234;&#30028;&#65288;OOD&#65289;&#29305;&#24449;&#34920;&#31034;&#39046;&#22495;&#35268;&#27169;&#23545;&#27169;&#22411;&#22312;OOD&#26816;&#27979;&#20013;&#25928;&#26524;&#30340;&#37325;&#35201;&#20316;&#29992;&#12290;&#22240;&#27492;&#65292;&#37319;&#29992;&#27169;&#22411;&#38598;&#25104;&#20316;&#20026;&#22686;&#24378;&#36825;&#19968;&#29305;&#24449;&#34920;&#31034;&#39046;&#22495;&#30340;&#31361;&#20986;&#31574;&#30053;&#24050;&#32463;&#25104;&#20026;&#19968;&#31181;&#31361;&#20986;&#30340;&#31574;&#30053;&#65292;&#21033;&#29992;&#39044;&#26399;&#30340;&#27169;&#22411;&#22810;&#26679;&#24615;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#26032;&#39062;&#30340;&#23450;&#24615;&#21644;&#23450;&#37327;&#27169;&#22411;&#38598;&#25104;&#35780;&#20272;&#26041;&#27861;&#65292;&#29305;&#21035;&#26159;&#25439;&#22833;&#30406;/&#38556;&#30861;&#21487;&#35270;&#21270;&#21644;&#33258;&#32806;&#21512;&#25351;&#25968;&#65292;&#25581;&#31034;&#20102;&#29616;&#26377;&#38598;&#25104;&#26041;&#27861;&#30340;&#19968;&#20010;&#20851;&#38190;&#32570;&#38519;&#12290;&#25105;&#20204;&#21457;&#29616;&#36825;&#20123;&#26041;&#27861;&#21253;&#21547;&#21487;&#36827;&#34892;&#20223;&#23556;&#21464;&#25442;&#30340;&#26435;&#37325;&#65292;&#34920;&#29616;&#20986;&#26377;&#38480;&#30340;&#21487;&#21464;&#24615;&#65292;&#20174;&#32780;&#26410;&#33021;&#23454;&#29616;&#29305;&#24449;&#34920;&#31034;&#20013;&#25152;&#38656;&#30340;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16260v1 Announce Type: cross  Abstract: Recent research underscores the pivotal role of the Out-of-Distribution (OOD) feature representation field scale in determining the efficacy of models in OOD detection. Consequently, the adoption of model ensembles has emerged as a prominent strategy to augment this feature representation field, capitalizing on anticipated model diversity.   However, our introduction of novel qualitative and quantitative model ensemble evaluation methods, specifically Loss Basin/Barrier Visualization and the Self-Coupling Index, reveals a critical drawback in existing ensemble methods. We find that these methods incorporate weights that are affine-transformable, exhibiting limited variability and thus failing to achieve the desired diversity in feature representation.   To address this limitation, we elevate the dimensions of traditional model ensembles, incorporating various factors such as different weight initializations, data holdout, etc., into di
&lt;/p&gt;</description></item><item><title>CASPER&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#26524;&#20851;&#31995;&#24863;&#30693;&#30340;&#26041;&#27861;&#26469;&#22788;&#29702;&#26102;&#31354;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#25554;&#34917;&#38382;&#39064;&#65292;&#36991;&#20813;&#36807;&#24230;&#21033;&#29992;&#38750;&#22240;&#26524;&#20851;&#31995;&#65292;&#25552;&#39640;&#25968;&#25454;&#20998;&#26512;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.11960</link><description>&lt;p&gt;
CASPER&#65306;&#22240;&#26524;&#20851;&#31995;&#24863;&#30693;&#26102;&#31354;&#22270;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#26102;&#31354;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;
&lt;/p&gt;
&lt;p&gt;
CASPER: Causality-Aware Spatiotemporal Graph Neural Networks for Spatiotemporal Time Series Imputation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11960
&lt;/p&gt;
&lt;p&gt;
CASPER&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#26524;&#20851;&#31995;&#24863;&#30693;&#30340;&#26041;&#27861;&#26469;&#22788;&#29702;&#26102;&#31354;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#25554;&#34917;&#38382;&#39064;&#65292;&#36991;&#20813;&#36807;&#24230;&#21033;&#29992;&#38750;&#22240;&#26524;&#20851;&#31995;&#65292;&#25552;&#39640;&#25968;&#25454;&#20998;&#26512;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11960v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#26032; &#25552;&#35201;&#65306;&#26102;&#31354;&#26102;&#38388;&#24207;&#21015;&#26159;&#29702;&#35299;&#20154;&#31867;&#27963;&#21160;&#21450;&#20854;&#24433;&#21709;&#30340;&#22522;&#30784;&#65292;&#36890;&#24120;&#36890;&#36807;&#25918;&#32622;&#22312;&#19981;&#21516;&#20301;&#32622;&#30340;&#30417;&#27979;&#20256;&#24863;&#22120;&#25910;&#38598;&#12290;&#25910;&#38598;&#21040;&#30340;&#25968;&#25454;&#36890;&#24120;&#21253;&#21547;&#30001;&#20110;&#21508;&#31181;&#25925;&#38556;&#32780;&#23548;&#33268;&#30340;&#32570;&#22833;&#20540;&#65292;&#36825;&#23545;&#25968;&#25454;&#20998;&#26512;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;&#20026;&#20102;&#22635;&#34917;&#32570;&#22833;&#20540;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#35768;&#22810;&#26041;&#27861;&#12290;&#22312;&#24674;&#22797;&#29305;&#23450;&#25968;&#25454;&#28857;&#26102;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#26041;&#27861;&#20542;&#21521;&#20110;&#32771;&#34385;&#19982;&#35813;&#28857;&#30456;&#20851;&#30340;&#25152;&#26377;&#20449;&#24687;&#65292;&#26080;&#35770;&#23427;&#20204;&#26159;&#21542;&#20855;&#26377;&#22240;&#26524;&#20851;&#31995;&#12290;&#22312;&#25968;&#25454;&#25910;&#38598;&#36807;&#31243;&#20013;&#65292;&#21253;&#25324;&#19968;&#20123;&#26410;&#30693;&#28151;&#26434;&#22240;&#32032;&#26159;&#19981;&#21487;&#36991;&#20813;&#30340;&#65292;&#20363;&#22914;&#26102;&#38388;&#24207;&#21015;&#20013;&#30340;&#32972;&#26223;&#22122;&#22768;&#21644;&#26500;&#24314;&#30340;&#20256;&#24863;&#22120;&#32593;&#32476;&#20013;&#30340;&#38750;&#22240;&#26524;&#24555;&#25463;&#36793;&#12290;&#36825;&#20123;&#28151;&#26434;&#22240;&#32032;&#21487;&#33021;&#22312;&#36755;&#20837;&#21644;&#36755;&#20986;&#20043;&#38388;&#24320;&#36767;&#21453;&#21521;&#36335;&#24452;&#65292;&#25442;&#21477;&#35805;&#35828;&#65292;&#23427;&#20204;&#24314;&#31435;&#20102;&#36755;&#20837;&#21644;&#36755;&#20986;&#20043;&#38388;&#30340;&#38750;&#22240;&#26524;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11960v1 Announce Type: new  Abstract: Spatiotemporal time series is the foundation of understanding human activities and their impacts, which is usually collected via monitoring sensors placed at different locations. The collected data usually contains missing values due to various failures, which have significant impact on data analysis. To impute the missing values, a lot of methods have been introduced. When recovering a specific data point, most existing methods tend to take into consideration all the information relevant to that point regardless of whether they have a cause-and-effect relationship. During data collection, it is inevitable that some unknown confounders are included, e.g., background noise in time series and non-causal shortcut edges in the constructed sensor network. These confounders could open backdoor paths between the input and output, in other words, they establish non-causal correlations between the input and output. Over-exploiting these non-causa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#38388;&#25509;&#21442;&#25968;&#21270;CAEs&#65288;IP-CAEs&#65289;&#26469;&#35299;&#20915;&#20855;&#20307;&#33258;&#32534;&#30721;&#22120;&#65288;CAEs&#65289;&#22312;&#31283;&#23450;&#32852;&#21512;&#20248;&#21270;&#26041;&#38754;&#30340;&#38382;&#39064;&#65292;IP-CAEs&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#26174;&#33879;&#19988;&#19968;&#33268;&#30340;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2403.00563</link><description>&lt;p&gt;
&#38388;&#25509;&#21442;&#25968;&#21270;&#20855;&#20307;&#33258;&#32534;&#30721;&#22120;
&lt;/p&gt;
&lt;p&gt;
Indirectly Parameterized Concrete Autoencoders
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00563
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#38388;&#25509;&#21442;&#25968;&#21270;CAEs&#65288;IP-CAEs&#65289;&#26469;&#35299;&#20915;&#20855;&#20307;&#33258;&#32534;&#30721;&#22120;&#65288;CAEs&#65289;&#22312;&#31283;&#23450;&#32852;&#21512;&#20248;&#21270;&#26041;&#38754;&#30340;&#38382;&#39064;&#65292;IP-CAEs&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#26174;&#33879;&#19988;&#19968;&#33268;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29305;&#24449;&#36873;&#25321;&#22312;&#25968;&#25454;&#39640;&#32500;&#25110;&#33719;&#21462;&#23436;&#25972;&#29305;&#24449;&#38598;&#25104;&#26412;&#39640;&#26114;&#30340;&#24773;&#20917;&#19979;&#33267;&#20851;&#37325;&#35201;&#12290;&#26368;&#36817;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#23884;&#20837;&#24335;&#29305;&#24449;&#36873;&#25321;&#30340;&#21457;&#23637;&#22312;&#24191;&#27867;&#24212;&#29992;&#20013;&#34920;&#29616;&#20986;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;&#20855;&#20307;&#33258;&#32534;&#30721;&#22120;&#65288;CAEs&#65289;&#34987;&#35748;&#20026;&#26159;&#23884;&#20837;&#24335;&#29305;&#24449;&#36873;&#25321;&#20013;&#30340;&#26368;&#20808;&#36827;&#25216;&#26415;&#65292;&#20294;&#21487;&#33021;&#38590;&#20197;&#23454;&#29616;&#31283;&#23450;&#30340;&#32852;&#21512;&#20248;&#21270;&#65292;&#20174;&#32780;&#24433;&#21709;&#20854;&#35757;&#32451;&#26102;&#38388;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;&#26412;&#25991;&#21457;&#29616;&#36825;&#31181;&#19981;&#31283;&#23450;&#24615;&#19982;CAE&#23398;&#20064;&#37325;&#22797;&#36873;&#25321;&#26377;&#20851;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#26377;&#25928;&#30340;&#25913;&#36827;&#65306;&#38388;&#25509;&#21442;&#25968;&#21270;CAEs&#65288;IP-CAEs&#65289;&#12290;IP-CAEs&#23398;&#20064;&#19968;&#20010;&#23884;&#20837;&#21644;&#20174;&#23427;&#21040;Gumbel-Softmax&#20998;&#24067;&#21442;&#25968;&#30340;&#26144;&#23556;&#12290;&#23613;&#31649;&#23454;&#29616;&#31616;&#21333;&#65292;IP-CAE&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#37325;&#26500;&#21644;&#20998;&#31867;&#20219;&#21153;&#20013;&#22343;&#34920;&#29616;&#20986;&#26174;&#33879;&#19988;&#19968;&#33268;&#30340;&#25913;&#36827;&#65292;&#26080;&#35770;&#26159;&#22312;&#27867;&#21270;&#36824;&#26159;&#35757;&#32451;&#26102;&#38388;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00563v1 Announce Type: new  Abstract: Feature selection is a crucial task in settings where data is high-dimensional or acquiring the full set of features is costly. Recent developments in neural network-based embedded feature selection show promising results across a wide range of applications. Concrete Autoencoders (CAEs), considered state-of-the-art in embedded feature selection, may struggle to achieve stable joint optimization, hurting their training time and generalization. In this work, we identify that this instability is correlated with the CAE learning duplicate selections. To remedy this, we propose a simple and effective improvement: Indirectly Parameterized CAEs (IP-CAEs). IP-CAEs learn an embedding and a mapping from it to the Gumbel-Softmax distributions' parameters. Despite being simple to implement, IP-CAE exhibits significant and consistent improvements over CAE in both generalization and training time across several datasets for reconstruction and classifi
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#23436;&#20840;&#36125;&#21494;&#26031;&#38647;&#36798;&#33258;&#21160;&#30446;&#26631;&#35782;&#21035;&#30340;&#26694;&#26550;&#65292;&#37319;&#29992;&#26368;&#20248;&#36125;&#21494;&#26031;&#34701;&#21512;&#26469;&#26377;&#25928;&#22320;&#27719;&#24635;&#22810;&#20010;&#38647;&#36798;&#30340;&#20998;&#31867;&#27010;&#29575;&#21521;&#37327;&#65292;&#20197;&#25913;&#36827;&#26080;&#20154;&#26426;&#38647;&#36798;&#25130;&#38754;&#35782;&#21035;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.17987</link><description>&lt;p&gt;
&#22810;&#24577;&#38647;&#36798;&#23545;&#31354;&#20013;&#39134;&#34892;&#22120;&#38647;&#36798;&#25130;&#38754;&#35782;&#21035;&#65306;&#19968;&#31181;&#36125;&#21494;&#26031;&#34701;&#21512;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Multistatic-Radar RCS-Signature Recognition of Aerial Vehicles: A Bayesian Fusion Approach
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17987
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#23436;&#20840;&#36125;&#21494;&#26031;&#38647;&#36798;&#33258;&#21160;&#30446;&#26631;&#35782;&#21035;&#30340;&#26694;&#26550;&#65292;&#37319;&#29992;&#26368;&#20248;&#36125;&#21494;&#26031;&#34701;&#21512;&#26469;&#26377;&#25928;&#22320;&#27719;&#24635;&#22810;&#20010;&#38647;&#36798;&#30340;&#20998;&#31867;&#27010;&#29575;&#21521;&#37327;&#65292;&#20197;&#25913;&#36827;&#26080;&#20154;&#26426;&#38647;&#36798;&#25130;&#38754;&#35782;&#21035;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17987v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#36328;&#39046;&#22495; &#25688;&#35201;&#65306;&#26080;&#20154;&#26426;&#30340;&#38647;&#36798;&#33258;&#21160;&#30446;&#26631;&#35782;&#21035;&#65288;RATR&#65289;&#28041;&#21450;&#21457;&#23556;&#30005;&#30913;&#27874;&#24182;&#23545;&#25509;&#25910;&#21040;&#30340;&#38647;&#36798;&#22238;&#27874;&#25191;&#34892;&#30446;&#26631;&#31867;&#22411;&#35782;&#21035;&#65292;&#23545;&#22269;&#38450;&#21644;&#33322;&#31354;&#33322;&#22825;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#31361;&#20986;&#20102;&#22810;&#24577;&#38647;&#36798;&#37197;&#32622;&#22312;RATR&#20013;&#20248;&#20110;&#21333;&#24577;&#38647;&#36798;&#30340;&#20248;&#21183;&#12290;&#28982;&#32780;&#65292;&#22810;&#24577;&#38647;&#36798;&#37197;&#32622;&#20013;&#30340;&#34701;&#21512;&#26041;&#27861;&#36890;&#24120;&#20197;&#27010;&#29575;&#26041;&#24335;&#27425;&#20248;&#22320;&#32452;&#21512;&#26469;&#33258;&#21508;&#20010;&#38647;&#36798;&#30340;&#20998;&#31867;&#21521;&#37327;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23436;&#20840;&#36125;&#21494;&#26031;RATR&#26694;&#26550;&#65292;&#37319;&#29992;&#26368;&#20248;&#36125;&#21494;&#26031;&#34701;&#21512;&#65288;OBF&#65289;&#26469;&#32858;&#21512;&#26469;&#33258;&#22810;&#20010;&#38647;&#36798;&#30340;&#20998;&#31867;&#27010;&#29575;&#21521;&#37327;&#12290;OBF&#22522;&#20110;&#26399;&#26395;0-1&#25439;&#22833;&#65292;&#26681;&#25454;&#22810;&#20010;&#26102;&#38388;&#27493;&#39588;&#30340;&#21382;&#21490;&#35266;&#27979;&#26356;&#26032;&#30446;&#26631;&#26080;&#20154;&#26426;&#31867;&#22411;&#30340;&#36882;&#24402;&#36125;&#21494;&#26031;&#20998;&#31867;&#65288;RBC&#65289;&#21518;&#39564;&#20998;&#24067;&#12290;&#25105;&#20204;&#20351;&#29992;&#27169;&#25311;&#30340;&#38543;&#26426;&#34892;&#36208;&#36712;&#36857;&#35780;&#20272;&#20102;&#36825;&#31181;&#26041;&#27861;&#65292;&#20849;&#28041;&#21450;&#19971;&#31181;&#26426;&#21160;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17987v1 Announce Type: cross  Abstract: Radar Automated Target Recognition (RATR) for Unmanned Aerial Vehicles (UAVs) involves transmitting Electromagnetic Waves (EMWs) and performing target type recognition on the received radar echo, crucial for defense and aerospace applications. Previous studies highlighted the advantages of multistatic radar configurations over monostatic ones in RATR. However, fusion methods in multistatic radar configurations often suboptimally combine classification vectors from individual radars probabilistically. To address this, we propose a fully Bayesian RATR framework employing Optimal Bayesian Fusion (OBF) to aggregate classification probability vectors from multiple radars. OBF, based on expected 0-1 loss, updates a Recursive Bayesian Classification (RBC) posterior distribution for target UAV type, conditioned on historical observations across multiple time steps. We evaluate the approach using simulated random walk trajectories for seven dro
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#19968;&#27425;&#24615;&#20998;&#27835;&#20272;&#35745;&#21644;&#22810;&#36718;&#20272;&#35745;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#20998;&#24067;&#24335;&#29615;&#22659;&#19979;&#23545;&#21322;&#21442;&#25968;&#20108;&#20803;&#36873;&#25321;&#27169;&#22411;&#30340;&#26032;&#20272;&#35745;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#20248;&#21270;&#35823;&#24046;&#30340;&#36229;&#32447;&#24615;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2210.08393</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#20272;&#35745;&#21644;&#25512;&#26029;&#29992;&#20110;&#21322;&#21442;&#25968;&#20108;&#20803;&#21709;&#24212;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Distributed Estimation and Inference for Semi-parametric Binary Response Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2210.08393
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#19968;&#27425;&#24615;&#20998;&#27835;&#20272;&#35745;&#21644;&#22810;&#36718;&#20272;&#35745;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#20998;&#24067;&#24335;&#29615;&#22659;&#19979;&#23545;&#21322;&#21442;&#25968;&#20108;&#20803;&#36873;&#25321;&#27169;&#22411;&#30340;&#26032;&#20272;&#35745;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#20248;&#21270;&#35823;&#24046;&#30340;&#36229;&#32447;&#24615;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#25216;&#26415;&#30340;&#21457;&#23637;&#20351;&#24471;&#25968;&#25454;&#25910;&#38598;&#30340;&#35268;&#27169;&#21069;&#25152;&#26410;&#26377;&#65292;&#36825;&#32473;&#35768;&#22810;&#32479;&#35745;&#20272;&#35745;&#21644;&#25512;&#26029;&#38382;&#39064;&#24102;&#26469;&#20102;&#26032;&#25361;&#25112;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20998;&#24067;&#24335;&#35745;&#31639;&#29615;&#22659;&#19979;&#23545;&#21322;&#21442;&#25968;&#20108;&#20803;&#36873;&#25321;&#27169;&#22411;&#30340;&#26368;&#22823;&#20998;&#25968;&#20272;&#35745;&#22120;&#65292;&#32780;&#26080;&#38656;&#39044;&#20808;&#25351;&#23450;&#22122;&#22768;&#20998;&#24067;&#12290;&#20256;&#32479;&#30340;&#20998;&#27835;&#20272;&#35745;&#22120;&#22312;&#35745;&#31639;&#19978;&#26114;&#36149;&#65292;&#24182;&#21463;&#21040;&#26426;&#22120;&#25968;&#37327;&#30340;&#38750;&#27491;&#21017;&#32422;&#26463;&#30340;&#38480;&#21046;&#65292;&#36825;&#26159;&#30001;&#20110;&#30446;&#26631;&#20989;&#25968;&#30340;&#39640;&#24230;&#38750;&#20809;&#28369;&#24615;&#36136;&#23548;&#33268;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;(1)&#22312;&#24179;&#28369;&#30446;&#26631;&#20043;&#21518;&#36827;&#34892;&#19968;&#27425;&#24615;&#20998;&#27835;&#20272;&#35745;&#20197;&#25918;&#23485;&#32422;&#26463;&#65292;&#20197;&#21450;(2)&#36890;&#36807;&#36845;&#20195;&#24179;&#28369;&#23436;&#20840;&#21435;&#38500;&#32422;&#26463;&#30340;&#22810;&#36718;&#20272;&#35745;&#12290;&#25105;&#20204;&#25351;&#23450;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#30340;&#26680;&#24179;&#28369;&#22120;&#36873;&#25321;&#65292;&#36890;&#36807;&#39034;&#24207;&#32553;&#23567;&#24102;&#23485;&#22312;&#22810;&#27425;&#36845;&#20195;&#20013;&#23454;&#29616;&#20102;&#23545;&#20248;&#21270;&#35823;&#24046;&#30340;&#36229;&#32447;&#24615;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2210.08393v3 Announce Type: replace-cross  Abstract: The development of modern technology has enabled data collection of unprecedented size, which poses new challenges to many statistical estimation and inference problems. This paper studies the maximum score estimator of a semi-parametric binary choice model under a distributed computing environment without pre-specifying the noise distribution. An intuitive divide-and-conquer estimator is computationally expensive and restricted by a non-regular constraint on the number of machines, due to the highly non-smooth nature of the objective function. We propose (1) a one-shot divide-and-conquer estimator after smoothing the objective to relax the constraint, and (2) a multi-round estimator to completely remove the constraint via iterative smoothing. We specify an adaptive choice of kernel smoother with a sequentially shrinking bandwidth to achieve the superlinear improvement of the optimization error over the multiple iterations. The
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35889;&#32858;&#31867;&#21644;&#20998;&#24067;&#30456;&#20284;&#24230;&#24230;&#37327;&#30340;&#26694;&#26550;&#26469;&#35299;&#20915;&#31163;&#25955;&#20998;&#24067;&#32858;&#31867;&#38382;&#39064;&#12290;&#36890;&#36807;&#20351;&#29992;&#32447;&#24615;&#26368;&#20248;&#20256;&#36755;&#26500;&#24314;&#30456;&#20284;&#24230;&#30697;&#38453;&#65292;&#25105;&#20204;&#22312;&#32858;&#31867;&#20934;&#30830;&#24615;&#21644;&#35745;&#31639;&#25928;&#29575;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2401.13913</link><description>&lt;p&gt;
&#31163;&#25955;&#20998;&#24067;&#30340;&#35889;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Spectral Clustering for Discrete Distributions. (arXiv:2401.13913v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13913
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35889;&#32858;&#31867;&#21644;&#20998;&#24067;&#30456;&#20284;&#24230;&#24230;&#37327;&#30340;&#26694;&#26550;&#26469;&#35299;&#20915;&#31163;&#25955;&#20998;&#24067;&#32858;&#31867;&#38382;&#39064;&#12290;&#36890;&#36807;&#20351;&#29992;&#32447;&#24615;&#26368;&#20248;&#20256;&#36755;&#26500;&#24314;&#30456;&#20284;&#24230;&#30697;&#38453;&#65292;&#25105;&#20204;&#22312;&#32858;&#31867;&#20934;&#30830;&#24615;&#21644;&#35745;&#31639;&#25928;&#29575;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#25955;&#20998;&#24067;&#32858;&#31867;&#65288;D2C&#65289;&#36890;&#24120;&#36890;&#36807;Wasserstein&#36136;&#24515;&#26041;&#27861;&#26469;&#35299;&#20915;&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#19968;&#20010;&#20849;&#21516;&#30340;&#20551;&#35774;&#19979;&#24037;&#20316;&#65292;&#21363;&#32858;&#31867;&#21487;&#20197;&#36890;&#36807;&#36136;&#24515;&#24456;&#22909;&#22320;&#34920;&#31034;&#65292;&#20294;&#22312;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#21487;&#33021;&#19981;&#25104;&#31435;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#22522;&#20110;&#35889;&#32858;&#31867;&#21644;&#20998;&#24067;&#30456;&#20284;&#24230;&#24230;&#37327;&#65288;&#20363;&#22914;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#21644;Wasserstein&#36317;&#31163;&#65289;&#30340;&#26694;&#26550;&#26469;&#35299;&#20915;D2C&#38382;&#39064;&#12290;&#20026;&#20102;&#25552;&#39640;&#21487;&#25193;&#23637;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#32447;&#24615;&#26368;&#20248;&#20256;&#36755;&#22312;&#22823;&#22411;&#25968;&#25454;&#38598;&#19978;&#39640;&#25928;&#22320;&#26500;&#24314;&#30456;&#20284;&#24230;&#30697;&#38453;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#65292;&#20445;&#35777;&#20102;&#25152;&#25552;&#26041;&#27861;&#22312;&#32858;&#31867;&#20998;&#24067;&#26041;&#38754;&#30340;&#25104;&#21151;&#12290;&#22312;&#21512;&#25104;&#25968;&#25454;&#21644;&#30495;&#23454;&#25968;&#25454;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#32858;&#31867;&#20934;&#30830;&#24615;&#21644;&#35745;&#31639;&#25928;&#29575;&#26041;&#38754;&#22823;&#22823;&#20248;&#20110;&#22522;&#20934;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Discrete distribution clustering (D2C) was often solved by Wasserstein barycenter methods. These methods are under a common assumption that clusters can be well represented by barycenters, which may not hold in many real applications. In this work, we propose a simple yet effective framework based on spectral clustering and distribution affinity measures (e.g., maximum mean discrepancy and Wasserstein distance) for D2C. To improve the scalability, we propose to use linear optimal transport to construct affinity matrices efficiently on large datasets. We provide theoretical guarantees for the success of the proposed methods in clustering distributions. Experiments on synthetic and real data show that our methods outperform the baselines largely in terms of both clustering accuracy and computational efficiency.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29109;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25193;&#23637;&#29616;&#26377;&#30340;&#35299;&#37322;&#24615;&#26041;&#27861;&#65292;&#21487;&#20197;&#29702;&#35299;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#27169;&#22411;&#20013;&#30340;&#39044;&#27979;&#26469;&#28304;&#21644;&#32622;&#20449;&#24230;&#65292;&#24182;&#21033;&#29992;&#25913;&#32534;&#21518;&#30340;&#29305;&#24449;&#37325;&#35201;&#24615;&#12289;&#37096;&#20998;&#20381;&#36182;&#22270;&#21644;&#20010;&#20307;&#26465;&#20214;&#26399;&#26395;&#22270;&#31561;&#26041;&#27861;&#26469;&#27979;&#37327;&#29305;&#24449;&#23545;&#39044;&#27979;&#20998;&#24067;&#30340;&#29109;&#21644;&#22522;&#20110;&#30495;&#23454;&#26631;&#31614;&#30340;&#23545;&#25968;&#20284;&#28982;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2310.12842</link><description>&lt;p&gt;
&#38024;&#23545;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#27169;&#22411;&#26080;&#20851;&#21464;&#37327;&#37325;&#35201;&#24615;&#65306;&#19968;&#31181;&#22522;&#20110;&#29109;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Model-agnostic variable importance for predictive uncertainty: an entropy-based approach. (arXiv:2310.12842v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12842
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29109;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25193;&#23637;&#29616;&#26377;&#30340;&#35299;&#37322;&#24615;&#26041;&#27861;&#65292;&#21487;&#20197;&#29702;&#35299;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#27169;&#22411;&#20013;&#30340;&#39044;&#27979;&#26469;&#28304;&#21644;&#32622;&#20449;&#24230;&#65292;&#24182;&#21033;&#29992;&#25913;&#32534;&#21518;&#30340;&#29305;&#24449;&#37325;&#35201;&#24615;&#12289;&#37096;&#20998;&#20381;&#36182;&#22270;&#21644;&#20010;&#20307;&#26465;&#20214;&#26399;&#26395;&#22270;&#31561;&#26041;&#27861;&#26469;&#27979;&#37327;&#29305;&#24449;&#23545;&#39044;&#27979;&#20998;&#24067;&#30340;&#29109;&#21644;&#22522;&#20110;&#30495;&#23454;&#26631;&#31614;&#30340;&#23545;&#25968;&#20284;&#28982;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#30456;&#20449;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#39044;&#27979;&#32467;&#26524;&#65292;&#24517;&#39035;&#29702;&#35299;&#23548;&#33268;&#36825;&#20123;&#39044;&#27979;&#30340;&#22240;&#32032;&#12290;&#23545;&#20110;&#27010;&#29575;&#21644;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#30340;&#27169;&#22411;&#26469;&#35828;&#65292;&#19981;&#20165;&#38656;&#35201;&#29702;&#35299;&#39044;&#27979;&#26412;&#36523;&#30340;&#21407;&#22240;&#65292;&#36824;&#35201;&#29702;&#35299;&#27169;&#22411;&#23545;&#36825;&#20123;&#39044;&#27979;&#30340;&#32622;&#20449;&#24230;&#12290;&#26412;&#25991;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#29616;&#26377;&#30340;&#35299;&#37322;&#24615;&#26041;&#27861;&#25193;&#23637;&#21040;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#30340;&#27169;&#22411;&#65292;&#24182;&#22914;&#20309;&#21033;&#29992;&#36825;&#20123;&#25193;&#23637;&#26469;&#29702;&#35299;&#27169;&#22411;&#39044;&#27979;&#20998;&#24067;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#12290;&#29305;&#21035;&#26159;&#36890;&#36807;&#25913;&#32534;&#25490;&#21015;&#29305;&#24449;&#37325;&#35201;&#24615;&#12289;&#37096;&#20998;&#20381;&#36182;&#22270;&#21644;&#20010;&#20307;&#26465;&#20214;&#26399;&#26395;&#22270;&#65292;&#25105;&#20204;&#35777;&#26126;&#21487;&#20197;&#33719;&#24471;&#23545;&#27169;&#22411;&#34892;&#20026;&#30340;&#26032;&#35265;&#35299;&#65292;&#24182;&#19988;&#21487;&#20197;&#20351;&#29992;&#36825;&#20123;&#26041;&#27861;&#26469;&#34913;&#37327;&#29305;&#24449;&#23545;&#39044;&#27979;&#20998;&#24067;&#30340;&#29109;&#21644;&#22522;&#20110;&#35813;&#20998;&#24067;&#30340;&#30495;&#23454;&#26631;&#31614;&#30340;&#23545;&#25968;&#20284;&#28982;&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#20351;&#29992;&#20004;&#20010;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#25152;&#25552;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In order to trust the predictions of a machine learning algorithm, it is necessary to understand the factors that contribute to those predictions. In the case of probabilistic and uncertainty-aware models, it is necessary to understand not only the reasons for the predictions themselves, but also the model's level of confidence in those predictions. In this paper, we show how existing methods in explainability can be extended to uncertainty-aware models and how such extensions can be used to understand the sources of uncertainty in a model's predictive distribution. In particular, by adapting permutation feature importance, partial dependence plots, and individual conditional expectation plots, we demonstrate that novel insights into model behaviour may be obtained and that these methods can be used to measure the impact of features on both the entropy of the predictive distribution and the log-likelihood of the ground truth labels under that distribution. With experiments using both s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#23398;&#20248;&#21270;&#22120;&#65288;STOP&#65289;&#65292;&#36890;&#36807;&#36882;&#24402;&#33258;&#25105;&#25913;&#36827;&#30340;&#20195;&#30721;&#29983;&#25104;&#65292;&#20351;&#29992;&#34701;&#21512;&#20102;&#35821;&#35328;&#27169;&#22411;&#30340;&#33050;&#25163;&#26550;&#31243;&#24207;&#26469;&#25913;&#36827;&#33258;&#36523;&#65292;&#20174;&#32780;&#29983;&#25104;&#24615;&#33021;&#26356;&#22909;&#30340;&#31243;&#24207;&#12290;</title><link>http://arxiv.org/abs/2310.02304</link><description>&lt;p&gt;
&#33258;&#23398;&#20248;&#21270;&#22120;&#65288;STOP&#65289;&#65306;&#36882;&#24402;&#33258;&#25105;&#25913;&#36827;&#30340;&#20195;&#30721;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Self-Taught Optimizer (STOP): Recursively Self-Improving Code Generation. (arXiv:2310.02304v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02304
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#23398;&#20248;&#21270;&#22120;&#65288;STOP&#65289;&#65292;&#36890;&#36807;&#36882;&#24402;&#33258;&#25105;&#25913;&#36827;&#30340;&#20195;&#30721;&#29983;&#25104;&#65292;&#20351;&#29992;&#34701;&#21512;&#20102;&#35821;&#35328;&#27169;&#22411;&#30340;&#33050;&#25163;&#26550;&#31243;&#24207;&#26469;&#25913;&#36827;&#33258;&#36523;&#65292;&#20174;&#32780;&#29983;&#25104;&#24615;&#33021;&#26356;&#22909;&#30340;&#31243;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#20960;&#24180;&#30340;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#65288;&#20363;&#22914;&#24605;&#32500;&#26641;&#21644;&#31243;&#24207;&#36741;&#21161;&#35821;&#35328;&#27169;&#22411;&#65289;&#21462;&#24471;&#20102;&#19968;&#20123;&#37325;&#35201;&#36827;&#23637;&#65292;&#36890;&#36807;&#25552;&#20379;&#19968;&#20010;&#8220;&#33050;&#25163;&#26550;&#8221;&#31243;&#24207;&#26469;&#35299;&#20915;&#38382;&#39064;&#65292;&#35813;&#31243;&#24207;&#26500;&#24314;&#20102;&#22810;&#27425;&#35843;&#29992;&#35821;&#35328;&#27169;&#22411;&#20197;&#29983;&#25104;&#26356;&#22909;&#30340;&#36755;&#20986;&#12290;&#33050;&#25163;&#26550;&#31243;&#24207;&#36890;&#24120;&#20351;&#29992;Python&#31561;&#32534;&#31243;&#35821;&#35328;&#32534;&#20889;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#19968;&#20010;&#34701;&#21512;&#20102;&#35821;&#35328;&#27169;&#22411;&#30340;&#33050;&#25163;&#26550;&#31243;&#24207;&#26469;&#25913;&#36827;&#33258;&#36523;&#12290;&#25105;&#20204;&#20174;&#19968;&#20010;&#31181;&#23376;&#8220;&#25913;&#36827;&#22120;&#8221;&#24320;&#22987;&#65292;&#36890;&#36807;&#22810;&#27425;&#26597;&#35810;&#35821;&#35328;&#27169;&#22411;&#24182;&#36820;&#22238;&#26368;&#20339;&#35299;&#20915;&#26041;&#26696;&#65292;&#26681;&#25454;&#32473;&#23450;&#30340;&#25928;&#29992;&#20989;&#25968;&#26469;&#25913;&#36827;&#36755;&#20837;&#31243;&#24207;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#36816;&#34892;&#36825;&#20010;&#31181;&#23376;&#25913;&#36827;&#22120;&#26469;&#25913;&#36827;&#33258;&#36523;&#12290;&#22312;&#19968;&#31995;&#21015;&#32454;&#20998;&#20219;&#21153;&#20013;&#65292;&#24471;&#21040;&#30340;&#25913;&#36827;&#25913;&#36827;&#22120;&#29983;&#25104;&#30340;&#31243;&#24207;&#22312;&#24615;&#33021;&#19978;&#26126;&#26174;&#20248;&#20110;&#31181;&#23376;&#25913;&#36827;&#22120;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#23545;&#35821;&#35328;&#27169;&#22411;&#25552;&#20986;&#30340;&#21508;&#31181;&#33258;&#25105;&#25913;&#36827;&#31574;&#30053;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#21253;&#25324;&#27874;&#26463;&#25628;&#32034;&#12289;&#36951;&#20256;&#31639;&#27861;&#21644;&#27169;&#25311;&#36864;&#28779;&#12290;&#30001;&#20110;&#35821;&#35328;&#27169;&#22411;&#26412;&#36523;&#27809;&#26377;&#25913;&#21464;&#65292;&#36825;&#24182;&#19981;&#26159;&#19968;&#31181;&#22686;&#38271;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
Several recent advances in AI systems (e.g., Tree-of-Thoughts and Program-Aided Language Models) solve problems by providing a "scaffolding" program that structures multiple calls to language models to generate better outputs. A scaffolding program is written in a programming language such as Python. In this work, we use a language-model-infused scaffolding program to improve itself. We start with a seed "improver" that improves an input program according to a given utility function by querying a language model several times and returning the best solution. We then run this seed improver to improve itself. Across a small set of downstream tasks, the resulting improved improver generates programs with significantly better performance than its seed improver. Afterward, we analyze the variety of self-improvement strategies proposed by the language model, including beam search, genetic algorithms, and simulated annealing. Since the language models themselves are not altered, this is not fu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24369;&#30417;&#30563;&#30340;&#20027;&#21160;&#23398;&#20064;&#31639;&#27861;&#65292;&#19981;&#20165;&#36873;&#25321;&#35201;&#27880;&#37322;&#30340;&#35266;&#27979;&#32467;&#26524;&#65292;&#36824;&#36873;&#25321;&#35201;&#33719;&#24471;&#30340;&#27880;&#37322;&#31934;&#24230;&#65292;&#24182;&#22312;&#39640;&#26031;&#36807;&#31243;&#20013;&#36827;&#34892;&#20102;&#23454;&#39564;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2204.08335</link><description>&lt;p&gt;
&#22522;&#20110;&#24369;&#30417;&#30563;&#30340;&#39640;&#26031;&#36807;&#31243;&#20027;&#21160;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Active Learning with Weak Supervision for Gaussian Processes. (arXiv:2204.08335v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.08335
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24369;&#30417;&#30563;&#30340;&#20027;&#21160;&#23398;&#20064;&#31639;&#27861;&#65292;&#19981;&#20165;&#36873;&#25321;&#35201;&#27880;&#37322;&#30340;&#35266;&#27979;&#32467;&#26524;&#65292;&#36824;&#36873;&#25321;&#35201;&#33719;&#24471;&#30340;&#27880;&#37322;&#31934;&#24230;&#65292;&#24182;&#22312;&#39640;&#26031;&#36807;&#31243;&#20013;&#36827;&#34892;&#20102;&#23454;&#39564;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#30417;&#30563;&#23398;&#20064;&#65292;&#36827;&#34892;&#25968;&#25454;&#27880;&#37322;&#38656;&#35201;&#32791;&#36153;&#22823;&#37327;&#25104;&#26412;&#12290;&#24403;&#27880;&#37322;&#39044;&#31639;&#26377;&#38480;&#26102;&#65292;&#21487;&#20197;&#20351;&#29992;&#20027;&#21160;&#23398;&#20064;&#26469;&#36873;&#25321;&#21644;&#27880;&#37322;&#37027;&#20123;&#21487;&#33021;&#22312;&#27169;&#22411;&#24615;&#33021;&#19978;&#33719;&#24471;&#26368;&#22823;&#25910;&#30410;&#30340;&#35266;&#27979;&#32467;&#26524;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20027;&#21160;&#23398;&#20064;&#31639;&#27861;&#65292;&#38500;&#20102;&#36873;&#25321;&#35201;&#27880;&#37322;&#30340;&#35266;&#27979;&#32467;&#26524;&#22806;&#65292;&#36824;&#36873;&#25321;&#35201;&#33719;&#24471;&#30340;&#27880;&#37322;&#31934;&#24230;&#12290;&#20551;&#23450;&#20855;&#26377;&#20302;&#31934;&#24230;&#30340;&#27880;&#37322;&#27604;&#20855;&#26377;&#39640;&#31934;&#24230;&#30340;&#27880;&#37322;&#26356;&#20415;&#23452;&#65292;&#36825;&#20351;&#24471;&#27169;&#22411;&#33021;&#22815;&#22312;&#30456;&#21516;&#30340;&#27880;&#37322;&#39044;&#31639;&#19979;&#25506;&#32034;&#36755;&#20837;&#31354;&#38388;&#30340;&#26356;&#22823;&#37096;&#20998;&#12290;&#25105;&#20204;&#22312;&#20808;&#21069;&#38024;&#23545;&#39640;&#26031;&#36807;&#31243;&#25552;&#20986;&#30340;BALD&#30446;&#26631;&#22522;&#30784;&#19978;&#26500;&#24314;&#20102;&#25105;&#20204;&#30340;&#33719;&#21462;&#20989;&#25968;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#33021;&#22815;&#35843;&#25972;&#20027;&#21160;&#23398;&#20064;&#24490;&#29615;&#20013;&#30340;&#27880;&#37322;&#31934;&#24230;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Annotating data for supervised learning can be costly. When the annotation budget is limited, active learning can be used to select and annotate those observations that are likely to give the most gain in model performance. We propose an active learning algorithm that, in addition to selecting which observation to annotate, selects the precision of the annotation that is acquired. Assuming that annotations with low precision are cheaper to obtain, this allows the model to explore a larger part of the input space, with the same annotation budget. We build our acquisition function on the previously proposed BALD objective for Gaussian Processes, and empirically demonstrate the gains of being able to adjust the annotation precision in the active learning loop.
&lt;/p&gt;</description></item></channel></rss>