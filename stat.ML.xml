<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#33021;&#22815;&#35780;&#20272;&#38750;&#31169;&#23494;&#25968;&#25454;&#30456;&#20851;&#39044;&#22788;&#29702;&#31639;&#27861;&#24341;&#36215;&#30340;&#39069;&#22806;&#38544;&#31169;&#25104;&#26412;&#65292;&#24182;&#21033;&#29992;&#24179;&#28369;DP&#21644;&#39044;&#22788;&#29702;&#31639;&#27861;&#30340;&#26377;&#30028;&#25935;&#24863;&#24615;&#24314;&#31435;&#25972;&#20307;&#38544;&#31169;&#20445;&#35777;&#30340;&#19978;&#38480;</title><link>https://arxiv.org/abs/2403.13041</link><description>&lt;p&gt;
&#20855;&#26377;&#38750;&#31169;&#23494;&#39044;&#22788;&#29702;&#30340;&#21487;&#35777;&#26126;&#38544;&#31169;
&lt;/p&gt;
&lt;p&gt;
Provable Privacy with Non-Private Pre-Processing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13041
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#33021;&#22815;&#35780;&#20272;&#38750;&#31169;&#23494;&#25968;&#25454;&#30456;&#20851;&#39044;&#22788;&#29702;&#31639;&#27861;&#24341;&#36215;&#30340;&#39069;&#22806;&#38544;&#31169;&#25104;&#26412;&#65292;&#24182;&#21033;&#29992;&#24179;&#28369;DP&#21644;&#39044;&#22788;&#29702;&#31639;&#27861;&#30340;&#26377;&#30028;&#25935;&#24863;&#24615;&#24314;&#31435;&#25972;&#20307;&#38544;&#31169;&#20445;&#35777;&#30340;&#19978;&#38480;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#20998;&#26512;&#24046;&#20998;&#31169;&#23494;&#65288;DP&#65289;&#26426;&#22120;&#23398;&#20064;&#31649;&#36947;&#26102;&#65292;&#36890;&#24120;&#20250;&#24573;&#30053;&#25968;&#25454;&#30456;&#20851;&#30340;&#39044;&#22788;&#29702;&#30340;&#28508;&#22312;&#38544;&#31169;&#25104;&#26412;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#35780;&#20272;&#30001;&#38750;&#31169;&#23494;&#25968;&#25454;&#30456;&#20851;&#39044;&#22788;&#29702;&#31639;&#27861;&#24341;&#36215;&#30340;&#39069;&#22806;&#38544;&#31169;&#25104;&#26412;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#36890;&#36807;&#21033;&#29992;&#20004;&#20010;&#26032;&#30340;&#25216;&#26415;&#27010;&#24565;&#24314;&#31435;&#20102;&#25972;&#20307;&#38544;&#31169;&#20445;&#35777;&#30340;&#19978;&#38480;&#65306;&#19968;&#31181;&#31216;&#20026;&#24179;&#28369;DP&#30340;DP&#21464;&#20307;&#20197;&#21450;&#39044;&#22788;&#29702;&#31639;&#27861;&#30340;&#26377;&#30028;&#25935;&#24863;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13041v1 Announce Type: cross  Abstract: When analysing Differentially Private (DP) machine learning pipelines, the potential privacy cost of data-dependent pre-processing is frequently overlooked in privacy accounting. In this work, we propose a general framework to evaluate the additional privacy cost incurred by non-private data-dependent pre-processing algorithms. Our framework establishes upper bounds on the overall privacy guarantees by utilising two new technical notions: a variant of DP termed Smooth DP and the bounded sensitivity of the pre-processing algorithms. In addition to the generic framework, we provide explicit overall privacy guarantees for multiple data-dependent pre-processing algorithms, such as data imputation, quantization, deduplication and PCA, when used in combination with several DP algorithms. Notably, this framework is also simple to implement, allowing direct integration into existing DP pipelines.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#23646;&#24615;&#27979;&#35797;&#31639;&#27861;&#26041;&#38754;&#30340;&#30740;&#31350;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36817;&#20284;&#32447;&#24615;&#35268;&#21010;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#20449;&#24687;&#29702;&#35770;&#19978;&#26368;&#20248;&#22320;&#35299;&#20915;&#26657;&#20934;&#24615;&#27979;&#35797;&#38382;&#39064;&#65288;&#26368;&#22810;&#19968;&#20010;&#24120;&#25968;&#20493;&#25968;&#65289;&#12290;</title><link>https://arxiv.org/abs/2402.13187</link><description>&lt;p&gt;
&#22312;&#27425;&#32447;&#24615;&#26102;&#38388;&#20869;&#27979;&#35797;&#26657;&#20934;&#24615;
&lt;/p&gt;
&lt;p&gt;
Testing Calibration in Subquadratic Time
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13187
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#23646;&#24615;&#27979;&#35797;&#31639;&#27861;&#26041;&#38754;&#30340;&#30740;&#31350;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36817;&#20284;&#32447;&#24615;&#35268;&#21010;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#20449;&#24687;&#29702;&#35770;&#19978;&#26368;&#20248;&#22320;&#35299;&#20915;&#26657;&#20934;&#24615;&#27979;&#35797;&#38382;&#39064;&#65288;&#26368;&#22810;&#19968;&#20010;&#24120;&#25968;&#20493;&#25968;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26368;&#36817;&#30340;&#26426;&#22120;&#23398;&#20064;&#21644;&#20915;&#31574;&#21046;&#23450;&#25991;&#29486;&#20013;&#65292;&#26657;&#20934;&#24615;&#24050;&#32463;&#25104;&#20026;&#20108;&#20803;&#39044;&#27979;&#27169;&#22411;&#36755;&#20986;&#30340;&#19968;&#20010;&#20540;&#24471;&#26399;&#26395;&#21644;&#24191;&#27867;&#30740;&#31350;&#30340;&#32479;&#35745;&#24615;&#36136;&#12290;&#28982;&#32780;&#65292;&#27979;&#37327;&#27169;&#22411;&#26657;&#20934;&#24615;&#30340;&#31639;&#27861;&#26041;&#38754;&#20173;&#28982;&#30456;&#23545;&#36739;&#23569;&#34987;&#25506;&#32034;&#12290;&#22312;&#35770;&#25991; [BGHN23] &#30340;&#21551;&#21457;&#19979;&#65292;&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20005;&#26684;&#30340;&#26694;&#26550;&#26469;&#34913;&#37327;&#21040;&#26657;&#20934;&#24615;&#30340;&#36317;&#31163;&#65292;&#25105;&#20204;&#36890;&#36807;&#23646;&#24615;&#27979;&#35797;&#30340;&#35270;&#35282;&#24341;&#20837;&#20102;&#26657;&#20934;&#24615;&#30740;&#31350;&#30340;&#31639;&#27861;&#26041;&#38754;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#20174;&#26679;&#26412;&#20013;&#36827;&#34892;&#26657;&#20934;&#24615;&#27979;&#35797;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#20174;&#20998;&#24067; $\mathcal{D}$&#65288;&#39044;&#27979;&#65292;&#20108;&#20803;&#32467;&#26524;&#65289;&#20013;&#32473;&#20986; $n$ &#27425;&#25277;&#26679;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#21306;&#20998; $\mathcal{D}$ &#23436;&#20840;&#26657;&#20934;&#21644; $\mathcal{D}$ &#36317;&#31163;&#26657;&#20934;&#24615;&#20026; $\varepsilon$ &#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13187v1 Announce Type: new  Abstract: In the recent literature on machine learning and decision making, calibration has emerged as a desirable and widely-studied statistical property of the outputs of binary prediction models. However, the algorithmic aspects of measuring model calibration have remained relatively less well-explored. Motivated by [BGHN23], which proposed a rigorous framework for measuring distances to calibration, we initiate the algorithmic study of calibration through the lens of property testing. We define the problem of calibration testing from samples where given $n$ draws from a distribution $\mathcal{D}$ on (predictions, binary outcomes), our goal is to distinguish between the case where $\mathcal{D}$ is perfectly calibrated, and the case where $\mathcal{D}$ is $\varepsilon$-far from calibration.   We design an algorithm based on approximate linear programming, which solves calibration testing information-theoretically optimally (up to constant factor
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#27425;&#40784;&#27425;&#31070;&#32463;&#32593;&#32476;&#22312;&#23567;&#21021;&#20540;&#38468;&#36817;&#30340;&#26799;&#24230;&#27969;&#21160;&#65292;&#21457;&#29616;&#26435;&#37325;&#20250;&#22312;&#26041;&#21521;&#19978;&#25910;&#25947;&#21040;&#31070;&#32463;&#30456;&#20851;&#20989;&#25968;&#30340;KKT&#28857;&#21644;&#26576;&#20123;&#38797;&#28857;&#38468;&#36817;&#12290;</title><link>https://arxiv.org/abs/2402.09226</link><description>&lt;p&gt;
&#22312;&#20004;&#27425;&#40784;&#27425;&#31070;&#32463;&#32593;&#32476;&#30340;&#23567;&#21021;&#20540;&#21644;&#38797;&#28857;&#38468;&#36817;&#30340;&#26041;&#21521;&#25910;&#25947;
&lt;/p&gt;
&lt;p&gt;
Directional Convergence Near Small Initializations and Saddles in Two-Homogeneous Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09226
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#27425;&#40784;&#27425;&#31070;&#32463;&#32593;&#32476;&#22312;&#23567;&#21021;&#20540;&#38468;&#36817;&#30340;&#26799;&#24230;&#27969;&#21160;&#65292;&#21457;&#29616;&#26435;&#37325;&#20250;&#22312;&#26041;&#21521;&#19978;&#25910;&#25947;&#21040;&#31070;&#32463;&#30456;&#20851;&#20989;&#25968;&#30340;KKT&#28857;&#21644;&#26576;&#20123;&#38797;&#28857;&#38468;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#27425;&#40784;&#27425;&#31070;&#32463;&#32593;&#32476;&#22312;&#23567;&#21021;&#20540;&#38468;&#36817;&#30340;&#26799;&#24230;&#27969;&#21160;&#21147;&#23398;&#65292;&#20854;&#20013;&#25152;&#26377;&#26435;&#37325;&#37117;&#21021;&#22987;&#21270;&#22312;&#21407;&#28857;&#38468;&#36817;&#12290;&#38024;&#23545;&#24179;&#26041;&#35823;&#24046;&#21644;&#36923;&#36753;&#25439;&#22833;&#65292;&#35770;&#25991;&#35777;&#26126;&#65292;&#23545;&#20110;&#36275;&#22815;&#23567;&#30340;&#21021;&#22987;&#20540;&#65292;&#26799;&#24230;&#27969;&#21160;&#21160;&#24577;&#22312;&#21407;&#28857;&#38468;&#36817;&#33457;&#36153;&#36275;&#22815;&#30340;&#26102;&#38388;&#65292;&#20351;&#24471;&#31070;&#32463;&#32593;&#32476;&#30340;&#26435;&#37325;&#21487;&#20197;&#36817;&#20284;&#22320;&#22312;&#26041;&#21521;&#19978;&#25910;&#25947;&#21040;&#31070;&#32463;&#30456;&#20851;&#20989;&#25968;&#30340;Karush-Kuhn-Tucker&#65288;KKT&#65289;&#28857;&#65292;&#35813;&#20989;&#25968;&#37327;&#21270;&#20102;&#31070;&#32463;&#32593;&#32476;&#36755;&#20986;&#19982;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#30456;&#24212;&#26631;&#31614;&#20043;&#38388;&#30340;&#20851;&#32852;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09226v1 Announce Type: new Abstract: This paper examines gradient flow dynamics of two-homogeneous neural networks for small initializations, where all weights are initialized near the origin. For both square and logistic losses, it is shown that for sufficiently small initializations, the gradient flow dynamics spend sufficient time in the neighborhood of the origin to allow the weights of the neural network to approximately converge in direction to the Karush-Kuhn-Tucker (KKT) points of a neural correlation function that quantifies the correlation between the output of the neural network and corresponding labels in the training data set. For square loss, it has been observed that neural networks undergo saddle-to-saddle dynamics when initialized close to the origin. Motivated by this, this paper also shows a similar directional convergence among weights of small magnitude in the neighborhood of certain saddle points.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Metropolis-adjusted Mirror Langevin&#31639;&#27861;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#32422;&#26463;&#31354;&#38388;&#20013;&#36827;&#34892;&#24555;&#36895;&#37319;&#26679;&#12290;&#36825;&#31181;&#31639;&#27861;&#26159;&#23545;Mirror Langevin&#31639;&#27861;&#30340;&#25913;&#36827;&#65292;&#36890;&#36807;&#28155;&#21152;&#25509;&#21463;-&#25298;&#32477;&#36807;&#28388;&#22120;&#26469;&#28040;&#38500;&#28176;&#36817;&#20559;&#24046;&#65292;&#24182;&#20855;&#26377;&#25351;&#25968;&#20248;&#21270;&#20381;&#36182;&#12290;</title><link>https://arxiv.org/abs/2312.08823</link><description>&lt;p&gt;
&#20351;&#29992;Metropolis-adjusted Mirror Langevin&#31639;&#27861;&#20174;&#32422;&#26463;&#31354;&#38388;&#20013;&#24555;&#36895;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Fast sampling from constrained spaces using the Metropolis-adjusted Mirror Langevin algorithm
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.08823
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Metropolis-adjusted Mirror Langevin&#31639;&#27861;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#32422;&#26463;&#31354;&#38388;&#20013;&#36827;&#34892;&#24555;&#36895;&#37319;&#26679;&#12290;&#36825;&#31181;&#31639;&#27861;&#26159;&#23545;Mirror Langevin&#31639;&#27861;&#30340;&#25913;&#36827;&#65292;&#36890;&#36807;&#28155;&#21152;&#25509;&#21463;-&#25298;&#32477;&#36807;&#28388;&#22120;&#26469;&#28040;&#38500;&#28176;&#36817;&#20559;&#24046;&#65292;&#24182;&#20855;&#26377;&#25351;&#25968;&#20248;&#21270;&#20381;&#36182;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;Metropolis-adjusted Mirror Langevin&#31639;&#27861;&#65292;&#29992;&#20110;&#20174;&#20854;&#25903;&#25345;&#26159;&#32039;&#20984;&#38598;&#30340;&#20998;&#24067;&#20013;&#36827;&#34892;&#36817;&#20284;&#37319;&#26679;&#12290;&#35813;&#31639;&#27861;&#22312;Mirror Langevin&#31639;&#27861;&#65288;Zhang et al., 2020&#65289;&#30340;&#21333;&#27493;&#39532;&#23572;&#31185;&#22827;&#38142;&#20013;&#28155;&#21152;&#20102;&#19968;&#20010;&#25509;&#21463;-&#25298;&#32477;&#36807;&#28388;&#22120;&#65292;Mirror Langevin&#31639;&#27861;&#26159;Mirror Langevin&#21160;&#21147;&#23398;&#30340;&#22522;&#26412;&#31163;&#25955;&#21270;&#12290;&#30001;&#20110;&#21253;&#21547;&#20102;&#36825;&#20010;&#36807;&#28388;&#22120;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#30456;&#23545;&#20110;&#30446;&#26631;&#26159;&#26080;&#20559;&#30340;&#65292;&#32780;&#24050;&#30693;&#30340;Mirror Langevin&#31639;&#27861;&#31561;Mirror Langevin&#21160;&#21147;&#23398;&#30340;&#31163;&#25955;&#21270;&#20855;&#26377;&#28176;&#36817;&#20559;&#24046;&#12290;&#23545;&#20110;&#35813;&#31639;&#27861;&#65292;&#25105;&#20204;&#36824;&#32473;&#20986;&#20102;&#28151;&#21512;&#21040;&#19968;&#20010;&#30456;&#23545;&#24179;&#28369;&#12289;&#20984;&#24615;&#22909;&#19988;&#19982;&#33258;&#20849;&#36717;&#38236;&#20687;&#20989;&#25968;&#30456;&#20851;&#30340;&#32422;&#26463;&#20998;&#24067;&#25152;&#38656;&#36845;&#20195;&#27425;&#25968;&#30340;&#19978;&#30028;&#12290;&#30001;&#20110;&#21253;&#21547;Metropolis-Hastings&#36807;&#28388;&#22120;&#23548;&#33268;&#30340;&#39532;&#23572;&#31185;&#22827;&#38142;&#26159;&#21487;&#36870;&#30340;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#23545;&#35823;&#24046;&#30340;&#25351;&#25968;&#20248;&#21270;&#20381;&#36182;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new method called the Metropolis-adjusted Mirror Langevin algorithm for approximate sampling from distributions whose support is a compact and convex set. This algorithm adds an accept-reject filter to the Markov chain induced by a single step of the Mirror Langevin algorithm (Zhang et al., 2020), which is a basic discretisation of the Mirror Langevin dynamics. Due to the inclusion of this filter, our method is unbiased relative to the target, while known discretisations of the Mirror Langevin dynamics including the Mirror Langevin algorithm have an asymptotic bias. For this algorithm, we also give upper bounds for the number of iterations taken to mix to a constrained distribution whose potential is relatively smooth, convex, and Lipschitz continuous with respect to a self-concordant mirror function. As a consequence of the reversibility of the Markov chain induced by the inclusion of the Metropolis-Hastings filter, we obtain an exponentially better dependence on the erro
&lt;/p&gt;</description></item><item><title>&#22522;&#20110;&#24230;&#37327;&#31354;&#38388;&#22823;&#23567;&#30340;&#28508;&#22312;&#34920;&#31034;&#22810;&#26679;&#24615;&#24230;&#37327;&#65292;&#21487;&#31283;&#23450;&#35745;&#31639;&#65292;&#33021;&#22815;&#36827;&#34892;&#22810;&#23610;&#24230;&#27604;&#36739;&#65292;&#22312;&#22810;&#20010;&#39046;&#22495;&#21644;&#20219;&#21153;&#20013;&#23637;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2311.16054</link><description>&lt;p&gt;
&#29992;&#20110;&#35780;&#20272;&#28508;&#22312;&#34920;&#31034;&#22810;&#26679;&#24615;&#30340;&#24230;&#37327;&#31354;&#38388;&#22823;&#23567;
&lt;/p&gt;
&lt;p&gt;
Metric Space Magnitude for Evaluating the Diversity of Latent Representations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.16054
&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#24230;&#37327;&#31354;&#38388;&#22823;&#23567;&#30340;&#28508;&#22312;&#34920;&#31034;&#22810;&#26679;&#24615;&#24230;&#37327;&#65292;&#21487;&#31283;&#23450;&#35745;&#31639;&#65292;&#33021;&#22815;&#36827;&#34892;&#22810;&#23610;&#24230;&#27604;&#36739;&#65292;&#22312;&#22810;&#20010;&#39046;&#22495;&#21644;&#20219;&#21153;&#20013;&#23637;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24230;&#37327;&#31354;&#38388;&#30340;&#22823;&#23567;&#26159;&#19968;&#31181;&#36817;&#26399;&#24314;&#31435;&#30340;&#19981;&#21464;&#24615;&#65292;&#33021;&#22815;&#22312;&#22810;&#20010;&#23610;&#24230;&#19978;&#25552;&#20379;&#31354;&#38388;&#30340;&#8220;&#26377;&#25928;&#22823;&#23567;&#8221;&#30340;&#34913;&#37327;&#65292;&#24182;&#25429;&#25417;&#21040;&#35768;&#22810;&#20960;&#20309;&#23646;&#24615;&#12290;&#25105;&#20204;&#21457;&#23637;&#20102;&#19968;&#31995;&#21015;&#22522;&#20110;&#22823;&#23567;&#30340;&#28508;&#22312;&#34920;&#31034;&#20869;&#22312;&#22810;&#26679;&#24615;&#24230;&#37327;&#65292;&#24418;&#24335;&#21270;&#20102;&#26377;&#38480;&#24230;&#37327;&#31354;&#38388;&#22823;&#23567;&#20989;&#25968;&#20043;&#38388;&#30340;&#26032;&#39062;&#19981;&#30456;&#20284;&#24615;&#27010;&#24565;&#12290;&#25105;&#20204;&#30340;&#24230;&#37327;&#22312;&#25968;&#25454;&#25200;&#21160;&#19979;&#20445;&#35777;&#31283;&#23450;&#65292;&#21487;&#20197;&#39640;&#25928;&#35745;&#31639;&#65292;&#24182;&#19988;&#33021;&#22815;&#23545;&#28508;&#22312;&#34920;&#31034;&#36827;&#34892;&#20005;&#26684;&#30340;&#22810;&#23610;&#24230;&#27604;&#36739;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#24230;&#37327;&#22312;&#23454;&#39564;&#22871;&#20214;&#20013;&#30340;&#23454;&#29992;&#24615;&#21644;&#21331;&#36234;&#24615;&#33021;&#65292;&#21253;&#25324;&#19981;&#21516;&#39046;&#22495;&#21644;&#20219;&#21153;&#30340;&#22810;&#26679;&#24615;&#35780;&#20272;&#12289;&#27169;&#24335;&#23849;&#28291;&#26816;&#27979;&#20197;&#21450;&#29992;&#20110;&#25991;&#26412;&#12289;&#22270;&#20687;&#21644;&#22270;&#24418;&#25968;&#25454;&#30340;&#29983;&#25104;&#27169;&#22411;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
The magnitude of a metric space is a recently-established invariant, providing a measure of the 'effective size' of a space across multiple scales while also capturing numerous geometrical properties. We develop a family of magnitude-based measures of the intrinsic diversity of latent representations, formalising a novel notion of dissimilarity between magnitude functions of finite metric spaces. Our measures are provably stable under perturbations of the data, can be efficiently calculated, and enable a rigorous multi-scale comparison of latent representations. We show the utility and superior performance of our measures in an experimental suite that comprises different domains and tasks, including the evaluation of diversity, the detection of mode collapse, and the evaluation of generative models for text, image, and graph data.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#39318;&#27425;&#30740;&#31350;&#20102;&#22312;&#26410;&#30693;&#21709;&#24212;&#19979;&#19968;&#27425;&#24615;&#31574;&#30053;&#20998;&#31867;&#30340;&#24773;&#26223;&#65292;&#38024;&#23545;&#29992;&#25143;&#25104;&#26412;&#20989;&#25968;&#19981;&#30830;&#23450;&#24615;&#65292;&#25552;&#20986;&#35299;&#20915;&#26041;&#26696;&#24182;&#23558;&#20219;&#21153;&#23450;&#20041;&#20026;&#26497;&#23567;-&#26497;&#22823;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2311.02761</link><description>&lt;p&gt;
&#19968;&#27425;&#24615;&#31574;&#30053;&#20998;&#31867;&#22312;&#26410;&#30693;&#25104;&#26412;&#19979;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
One-Shot Strategic Classification Under Unknown Costs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.02761
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#39318;&#27425;&#30740;&#31350;&#20102;&#22312;&#26410;&#30693;&#21709;&#24212;&#19979;&#19968;&#27425;&#24615;&#31574;&#30053;&#20998;&#31867;&#30340;&#24773;&#26223;&#65292;&#38024;&#23545;&#29992;&#25143;&#25104;&#26412;&#20989;&#25968;&#19981;&#30830;&#23450;&#24615;&#65292;&#25552;&#20986;&#35299;&#20915;&#26041;&#26696;&#24182;&#23558;&#20219;&#21153;&#23450;&#20041;&#20026;&#26497;&#23567;-&#26497;&#22823;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31574;&#30053;&#20998;&#31867;&#30340;&#30446;&#26631;&#26159;&#23398;&#20064;&#23545;&#31574;&#30053;&#36755;&#20837;&#25805;&#32437;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#20915;&#31574;&#35268;&#21017;&#12290;&#20043;&#21069;&#30340;&#30740;&#31350;&#20551;&#35774;&#36825;&#20123;&#21709;&#24212;&#26159;&#24050;&#30693;&#30340;&#65307;&#32780;&#26368;&#36817;&#30340;&#19968;&#20123;&#30740;&#31350;&#22788;&#29702;&#26410;&#30693;&#21709;&#24212;&#65292;&#20294;&#23427;&#20204;&#19987;&#38376;&#30740;&#31350;&#37325;&#22797;&#27169;&#22411;&#37096;&#32626;&#30340;&#22312;&#32447;&#35774;&#32622;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#39046;&#22495;&#65292;&#29305;&#21035;&#26159;&#22312;&#20844;&#20849;&#25919;&#31574;&#20013;&#65292;&#19968;&#20010;&#24120;&#35265;&#30340;&#28608;&#21169;&#29992;&#20363;&#20013;&#65292;&#22810;&#27425;&#37096;&#32626;&#26159;&#19981;&#21487;&#34892;&#30340;&#65292;&#29978;&#33267;&#19968;&#20010;&#31967;&#31957;&#30340;&#36718;&#27425;&#37117;&#26159;&#19981;&#21487;&#25509;&#21463;&#30340;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#39318;&#27425;&#24341;&#20837;&#20102;&#22312;&#26410;&#30693;&#21709;&#24212;&#19979;&#30340;&#19968;&#27425;&#24615;&#31574;&#30053;&#20998;&#31867;&#30340;&#27491;&#24335;&#30740;&#31350;&#65292;&#36825;&#38656;&#35201;&#22312;&#19968;&#27425;&#24615;&#36873;&#25321;&#19968;&#20010;&#20998;&#31867;&#22120;&#12290;&#30528;&#37325;&#20851;&#27880;&#29992;&#25143;&#25104;&#26412;&#20989;&#25968;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#23545;&#20110;&#19968;&#31867;&#24191;&#27867;&#30340;&#25104;&#26412;&#65292;&#21363;&#20351;&#23545;&#30495;&#23454;&#25104;&#26412;&#30340;&#23567;&#35823;&#24046;&#20063;&#21487;&#33021;&#22312;&#26368;&#22351;&#24773;&#20917;&#19979;&#23548;&#33268;&#20934;&#30830;&#24615;&#38477;&#33267;&#26497;&#20302;&#27700;&#24179;&#12290;&#37492;&#20110;&#27492;&#65292;&#25105;&#20204;&#23558;&#20219;&#21153;&#26694;&#23450;&#20026;&#26497;&#23567;-&#26497;&#22823;&#38382;&#39064;&#65292;&#30446;&#26631;&#26159;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.02761v2 Announce Type: replace  Abstract: The goal of strategic classification is to learn decision rules which are robust to strategic input manipulation. Earlier works assume that these responses are known; while some recent works handle unknown responses, they exclusively study online settings with repeated model deployments. But there are many domains$\unicode{x2014}$particularly in public policy, a common motivating use case$\unicode{x2014}$where multiple deployments are infeasible, or where even one bad round is unacceptable. To address this gap, we initiate the formal study of one-shot strategic classification under unknown responses, which requires committing to a single classifier once. Focusing on uncertainty in the users' cost function, we begin by proving that for a broad class of costs, even a small mis-estimation of the true cost can entail trivial accuracy in the worst case. In light of this, we frame the task as a minimax problem, with the goal of identifying
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#27424;&#38459;&#23612; Langevin Monte Carlo &#21152;&#36895;&#30340;&#36817;&#20284; Thompson &#37319;&#26679;&#31574;&#30053;&#65292;&#36890;&#36807;&#29305;&#23450;&#21183;&#20989;&#25968;&#30340;&#35774;&#35745;&#25913;&#21892;&#20102;&#39640;&#32500;&#38382;&#39064;&#20013;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#22312;&#39640;&#32500;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2401.11665</link><description>&lt;p&gt;
&#20351;&#29992;&#27424;&#38459;&#23612; Langevin Monte Carlo &#21152;&#36895;&#36817;&#20284; Thompson &#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Accelerating Approximate Thompson Sampling with Underdamped Langevin Monte Carlo. (arXiv:2401.11665v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11665
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#27424;&#38459;&#23612; Langevin Monte Carlo &#21152;&#36895;&#30340;&#36817;&#20284; Thompson &#37319;&#26679;&#31574;&#30053;&#65292;&#36890;&#36807;&#29305;&#23450;&#21183;&#20989;&#25968;&#30340;&#35774;&#35745;&#25913;&#21892;&#20102;&#39640;&#32500;&#38382;&#39064;&#20013;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#22312;&#39640;&#32500;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#27424;&#38459;&#23612; Langevin Monte Carlo &#30340;&#36817;&#20284; Thompson &#37319;&#26679;&#26041;&#27861;&#25193;&#23637;&#20102;&#20854;&#36866;&#29992;&#33539;&#22260;&#65292;&#20174;&#39640;&#26031;&#21518;&#39564;&#37319;&#26679;&#25193;&#23637;&#21040;&#26356;&#19968;&#33324;&#30340;&#24179;&#28369;&#21518;&#39564;&#12290;&#28982;&#32780;&#65292;&#22312;&#39640;&#32500;&#38382;&#39064;&#20013;&#35201;&#27714;&#39640;&#20934;&#30830;&#24615;&#26102;&#65292;&#20173;&#28982;&#38754;&#20020;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20284; Thompson &#37319;&#26679;&#31574;&#30053;&#65292;&#21033;&#29992;&#27424;&#38459;&#23612; Langevin Monte Carlo&#65292;&#21518;&#32773;&#26159;&#27169;&#25311;&#39640;&#32500;&#21518;&#39564;&#30340;&#36890;&#29992;&#24037;&#20855;&#12290;&#22522;&#20110;&#26631;&#20934;&#30340;&#24179;&#28369;&#24615;&#21644;&#23545;&#25968;&#20985;&#24615;&#26465;&#20214;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20351;&#29992;&#29305;&#23450;&#21183;&#20989;&#25968;&#30340;&#21152;&#36895;&#21518;&#39564;&#38598;&#20013;&#21644;&#37319;&#26679;&#12290;&#35813;&#35774;&#35745;&#25913;&#36827;&#20102;&#23454;&#29616;&#23545;&#25968;&#36951;&#25022;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#20174;$\mathcal{\tilde O}(d)$&#25913;&#36827;&#21040;$\mathcal{\tilde O}(\sqrt{d})$&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#21512;&#25104;&#23454;&#39564;&#22312;&#39640;&#32500;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#32463;&#39564;&#39564;&#35777;&#20102;&#25105;&#20204;&#31639;&#27861;&#30340;&#21487;&#25193;&#23637;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Approximate Thompson sampling with Langevin Monte Carlo broadens its reach from Gaussian posterior sampling to encompass more general smooth posteriors. However, it still encounters scalability issues in high-dimensional problems when demanding high accuracy. To address this, we propose an approximate Thompson sampling strategy, utilizing underdamped Langevin Monte Carlo, where the latter is the go-to workhorse for simulations of high-dimensional posteriors. Based on the standard smoothness and log-concavity conditions, we study the accelerated posterior concentration and sampling using a specific potential function. This design improves the sample complexity for realizing logarithmic regrets from $\mathcal{\tilde O}(d)$ to $\mathcal{\tilde O}(\sqrt{d})$. The scalability and robustness of our algorithm are also empirically validated through synthetic experiments in high-dimensional bandit problems.
&lt;/p&gt;</description></item><item><title>&#22312;&#20998;&#24067;&#24335;&#23398;&#20064;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#37327;&#23376;&#32593;&#32476;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#20351;&#29992;&#25351;&#25968;&#32423;&#36739;&#23569;&#30340;&#36890;&#20449;&#21644;&#30456;&#23545;&#36739;&#23567;&#30340;&#26102;&#38388;&#21644;&#31354;&#38388;&#22797;&#26434;&#24230;&#24320;&#38144;&#36827;&#34892;&#25512;&#29702;&#21644;&#35757;&#32451;&#12290;&#36825;&#26159;&#31532;&#19968;&#20010;&#23637;&#31034;&#20102;&#20855;&#26377;&#23494;&#38598;&#32463;&#20856;&#25968;&#25454;&#30340;&#36890;&#29992;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20855;&#26377;&#25351;&#25968;&#37327;&#23376;&#20248;&#21183;&#30340;&#20363;&#23376;&#12290;</title><link>http://arxiv.org/abs/2310.07136</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#23398;&#20064;&#20013;&#30340;&#25351;&#25968;&#37327;&#23376;&#36890;&#20449;&#20248;&#21183;
&lt;/p&gt;
&lt;p&gt;
Exponential Quantum Communication Advantage in Distributed Learning. (arXiv:2310.07136v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07136
&lt;/p&gt;
&lt;p&gt;
&#22312;&#20998;&#24067;&#24335;&#23398;&#20064;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#37327;&#23376;&#32593;&#32476;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#20351;&#29992;&#25351;&#25968;&#32423;&#36739;&#23569;&#30340;&#36890;&#20449;&#21644;&#30456;&#23545;&#36739;&#23567;&#30340;&#26102;&#38388;&#21644;&#31354;&#38388;&#22797;&#26434;&#24230;&#24320;&#38144;&#36827;&#34892;&#25512;&#29702;&#21644;&#35757;&#32451;&#12290;&#36825;&#26159;&#31532;&#19968;&#20010;&#23637;&#31034;&#20102;&#20855;&#26377;&#23494;&#38598;&#32463;&#20856;&#25968;&#25454;&#30340;&#36890;&#29992;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20855;&#26377;&#25351;&#25968;&#37327;&#23376;&#20248;&#21183;&#30340;&#20363;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#36229;&#36807;&#21333;&#20010;&#35774;&#22791;&#20869;&#23384;&#23481;&#37327;&#30340;&#22823;&#22411;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#35757;&#32451;&#21644;&#25512;&#29702;&#38656;&#35201;&#35774;&#35745;&#20998;&#24067;&#24335;&#26550;&#26500;&#65292;&#24517;&#39035;&#32771;&#34385;&#36890;&#20449;&#38480;&#21046;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#37327;&#23376;&#32593;&#32476;&#19978;&#36827;&#34892;&#20998;&#24067;&#24335;&#35745;&#31639;&#30340;&#26694;&#26550;&#65292;&#20854;&#20013;&#25968;&#25454;&#34987;&#32534;&#30721;&#20026;&#29305;&#27530;&#30340;&#37327;&#23376;&#24577;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#35813;&#26694;&#26550;&#20869;&#30340;&#26576;&#20123;&#27169;&#22411;&#20013;&#65292;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#36827;&#34892;&#25512;&#29702;&#21644;&#35757;&#32451;&#30340;&#36890;&#20449;&#24320;&#38144;&#30456;&#23545;&#20110;&#20854;&#32463;&#20856;&#23545;&#24212;&#27169;&#22411;&#21487;&#20197;&#25351;&#25968;&#32423;&#38477;&#20302;&#65292;&#24182;&#19988;&#30456;&#23545;&#20110;&#26631;&#20934;&#22522;&#20110;&#26799;&#24230;&#30340;&#26041;&#27861;&#65292;&#26102;&#38388;&#21644;&#31354;&#38388;&#22797;&#26434;&#24615;&#24320;&#38144;&#30456;&#23545;&#36739;&#23567;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#22312;&#20855;&#26377;&#23494;&#38598;&#32463;&#20856;&#25968;&#25454;&#30340;&#36890;&#29992;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#30340;&#24773;&#20917;&#19979;&#65292;&#26080;&#35770;&#25968;&#25454;&#32534;&#30721;&#25104;&#26412;&#22914;&#20309;&#65292;&#37117;&#20855;&#26377;&#25351;&#25968;&#37327;&#23376;&#20248;&#21183;&#30340;&#31034;&#20363;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#35813;&#31867;&#27169;&#22411;&#21487;&#20197;&#32534;&#30721;&#36755;&#20837;&#30340;&#39640;&#24230;&#38750;&#32447;&#24615;&#29305;&#24449;&#65292;&#24182;&#19988;&#23427;&#20204;&#30340;&#34920;&#36798;&#33021;&#21147;&#21576;&#25351;&#25968;&#22686;&#21152;&#12290;
&lt;/p&gt;
&lt;p&gt;
Training and inference with large machine learning models that far exceed the memory capacity of individual devices necessitates the design of distributed architectures, forcing one to contend with communication constraints. We present a framework for distributed computation over a quantum network in which data is encoded into specialized quantum states. We prove that for certain models within this framework, inference and training using gradient descent can be performed with exponentially less communication compared to their classical analogs, and with relatively modest time and space complexity overheads relative to standard gradient-based methods. To our knowledge, this is the first example of exponential quantum advantage for a generic class of machine learning problems with dense classical data that holds regardless of the data encoding cost. Moreover, we show that models in this class can encode highly nonlinear features of their inputs, and their expressivity increases exponenti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#25512;&#33616;&#31995;&#32479;&#20013;&#28608;&#21169;&#39640;&#36136;&#37327;&#20869;&#23481;&#30340;&#31639;&#27861;&#38382;&#39064;&#65292;&#32463;&#20856;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#20250;&#28608;&#21169;&#29983;&#20135;&#32773;&#21019;&#24314;&#20302;&#36136;&#37327;&#30340;&#20869;&#23481;&#65292;&#20294;&#26412;&#25991;&#25552;&#20986;&#30340;&#19968;&#31181;&#31639;&#27861;&#36890;&#36807;&#24809;&#32602;&#20302;&#36136;&#37327;&#20869;&#23481;&#30340;&#21019;&#24314;&#32773;&#65292;&#25104;&#21151;&#22320;&#28608;&#21169;&#20102;&#29983;&#20135;&#32773;&#21019;&#36896;&#39640;&#36136;&#37327;&#30340;&#20869;&#23481;&#12290;</title><link>http://arxiv.org/abs/2306.07479</link><description>&lt;p&gt;
&#22312;&#22312;&#32447;&#25512;&#33616;&#31995;&#32479;&#20013;&#28608;&#21169;&#39640;&#36136;&#37327;&#20869;&#23481;
&lt;/p&gt;
&lt;p&gt;
Incentivizing High-Quality Content in Online Recommender Systems. (arXiv:2306.07479v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07479
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#25512;&#33616;&#31995;&#32479;&#20013;&#28608;&#21169;&#39640;&#36136;&#37327;&#20869;&#23481;&#30340;&#31639;&#27861;&#38382;&#39064;&#65292;&#32463;&#20856;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#20250;&#28608;&#21169;&#29983;&#20135;&#32773;&#21019;&#24314;&#20302;&#36136;&#37327;&#30340;&#20869;&#23481;&#65292;&#20294;&#26412;&#25991;&#25552;&#20986;&#30340;&#19968;&#31181;&#31639;&#27861;&#36890;&#36807;&#24809;&#32602;&#20302;&#36136;&#37327;&#20869;&#23481;&#30340;&#21019;&#24314;&#32773;&#65292;&#25104;&#21151;&#22320;&#28608;&#21169;&#20102;&#29983;&#20135;&#32773;&#21019;&#36896;&#39640;&#36136;&#37327;&#30340;&#20869;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#20687;TikTok&#21644;YouTube&#36825;&#26679;&#30340;&#20869;&#23481;&#25512;&#33616;&#31995;&#32479;&#65292;&#24179;&#21488;&#30340;&#20915;&#31574;&#31639;&#27861;&#22609;&#36896;&#20102;&#20869;&#23481;&#29983;&#20135;&#32773;&#30340;&#28608;&#21169;&#65292;&#21253;&#25324;&#29983;&#20135;&#32773;&#22312;&#20869;&#23481;&#36136;&#37327;&#19978;&#25237;&#20837;&#22810;&#23569;&#21162;&#21147;&#12290;&#35768;&#22810;&#24179;&#21488;&#37319;&#29992;&#22312;&#32447;&#23398;&#20064;&#65292;&#36825;&#20250;&#20135;&#29983;&#36328;&#26102;&#38388;&#30340;&#28608;&#21169;&#65292;&#22240;&#20026;&#20170;&#22825;&#29983;&#20135;&#30340;&#20869;&#23481;&#20250;&#24433;&#21709;&#26410;&#26469;&#20869;&#23481;&#30340;&#25512;&#33616;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32447;&#23398;&#20064;&#20135;&#29983;&#30340;&#28608;&#21169;&#65292;&#20998;&#26512;&#20102;&#22312;&#32435;&#20160;&#22343;&#34913;&#19979;&#29983;&#20135;&#30340;&#20869;&#23481;&#36136;&#37327;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#20687;Hedge&#21644;EXP3&#36825;&#26679;&#30340;&#32463;&#20856;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#20250;&#28608;&#21169;&#29983;&#20135;&#32773;&#21019;&#24314;&#20302;&#36136;&#37327;&#30340;&#20869;&#23481;&#12290;&#29305;&#21035;&#22320;&#65292;&#20869;&#23481;&#36136;&#37327;&#22312;&#23398;&#20064;&#29575;&#26041;&#38754;&#26377;&#19978;&#38480;&#65292;&#24182;&#19988;&#38543;&#30528;&#20856;&#22411;&#23398;&#20064;&#29575;&#36827;&#23637;&#32780;&#36235;&#36817;&#20110;&#38646;&#12290;&#22312;&#36825;&#19968;&#36127;&#38754;&#32467;&#26524;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#19981;&#21516;&#30340;&#23398;&#20064;&#31639;&#27861;&#8212;&#8212;&#22522;&#20110;&#24809;&#32602;&#21019;&#24314;&#20302;&#36136;&#37327;&#20869;&#23481;&#30340;&#29983;&#20135;&#32773;&#8212;&#8212;&#27491;&#30830;&#28608;&#21169;&#29983;&#20135;&#32773;&#21019;&#24314;&#39640;&#36136;&#37327;&#20869;&#23481;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20381;&#36182;&#20110;&#26032;&#39062;&#30340;&#31574;&#30053;&#24615;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#24182;&#20811;&#26381;&#20102;&#22312;&#32452;&#21512;&#35774;&#32622;&#20013;&#24212;&#29992;&#23545;&#25239;&#24615;&#25216;&#26415;&#30340;&#25361;&#25112;&#12290;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#25104;&#21151;&#22320;&#28608;&#21169;&#29983;&#20135;&#32773;&#21019;&#24314;&#39640;&#36136;&#37327;&#20869;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;
For content recommender systems such as TikTok and YouTube, the platform's decision algorithm shapes the incentives of content producers, including how much effort the content producers invest in the quality of their content. Many platforms employ online learning, which creates intertemporal incentives, since content produced today affects recommendations of future content. In this paper, we study the incentives arising from online learning, analyzing the quality of content produced at a Nash equilibrium. We show that classical online learning algorithms, such as Hedge and EXP3, unfortunately incentivize producers to create low-quality content. In particular, the quality of content is upper bounded in terms of the learning rate and approaches zero for typical learning rate schedules. Motivated by this negative result, we design a different learning algorithm -- based on punishing producers who create low-quality content -- that correctly incentivizes producers to create high-quality co
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Wasserstein&#36317;&#31163;&#30340;&#25439;&#22833;&#20989;&#25968;hinge-Wasserstein&#65292;&#29992;&#20110;&#32531;&#35299;&#22238;&#24402;&#20219;&#21153;&#20013;&#30001;&#20110;&#36807;&#24230;&#33258;&#20449;&#23548;&#33268;&#30340;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#12290;&#36825;&#31181;&#25439;&#22833;&#20989;&#25968;&#26377;&#25928;&#25552;&#39640;&#20102;aleatoric&#21644;epistemic&#19981;&#30830;&#23450;&#24615;&#30340;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2306.00560</link><description>&lt;p&gt;
Hinge-Wasserstein: &#36890;&#36807;&#20998;&#31867;&#36991;&#20813;&#22238;&#24402;&#20013;&#30340;&#36807;&#24230;&#33258;&#20449;
&lt;/p&gt;
&lt;p&gt;
Hinge-Wasserstein: Mitigating Overconfidence in Regression by Classification. (arXiv:2306.00560v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00560
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Wasserstein&#36317;&#31163;&#30340;&#25439;&#22833;&#20989;&#25968;hinge-Wasserstein&#65292;&#29992;&#20110;&#32531;&#35299;&#22238;&#24402;&#20219;&#21153;&#20013;&#30001;&#20110;&#36807;&#24230;&#33258;&#20449;&#23548;&#33268;&#30340;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#12290;&#36825;&#31181;&#25439;&#22833;&#20989;&#25968;&#26377;&#25928;&#25552;&#39640;&#20102;aleatoric&#21644;epistemic&#19981;&#30830;&#23450;&#24615;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#24615;&#33021;&#26041;&#38754;&#24471;&#21040;&#20102;&#24040;&#22823;&#30340;&#25552;&#39640;&#65292;&#20294;&#23427;&#20204;&#23481;&#26131;&#20135;&#29983;&#36807;&#24230;&#33258;&#20449;&#12290;&#22312;&#27169;&#31946;&#29978;&#33267;&#19981;&#21487;&#39044;&#27979;&#30340;&#29616;&#23454;&#19990;&#30028;&#22330;&#26223;&#20013;&#65292;&#36825;&#31181;&#36807;&#24230;&#33258;&#20449;&#21487;&#33021;&#23545;&#24212;&#29992;&#31243;&#24207;&#30340;&#23433;&#20840;&#24615;&#26500;&#25104;&#37325;&#22823;&#39118;&#38505;&#12290;&#38024;&#23545;&#22238;&#24402;&#20219;&#21153;&#65292;&#37319;&#29992;&#22238;&#24402;-&#20998;&#31867;&#26041;&#27861;&#26377;&#28508;&#21147;&#32531;&#35299;&#36825;&#20123;&#27495;&#20041;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#39044;&#27979;&#25152;&#38656;&#36755;&#20986;&#30340;&#31163;&#25955;&#27010;&#29575;&#23494;&#24230;&#12290;&#28982;&#32780;&#65292;&#23494;&#24230;&#20272;&#35745;&#20173;&#28982;&#20542;&#21521;&#20110;&#36807;&#24230;&#33258;&#20449;&#65292;&#23588;&#20854;&#26159;&#22312;&#20351;&#29992;&#24120;&#35265;&#30340;NLL&#25439;&#22833;&#20989;&#25968;&#35757;&#32451;&#26102;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#31181;&#36807;&#24230;&#33258;&#20449;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Wasserstein&#36317;&#31163;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#21363;hinge-Wasserstein&#12290;&#19982;&#20197;&#21069;&#30340;&#24037;&#20316;&#30456;&#27604;&#65292;&#27492;&#25439;&#22833;&#26174;&#30528;&#25552;&#39640;&#20102;&#20004;&#31181;&#19981;&#30830;&#23450;&#24615;&#30340;&#36136;&#37327;&#65306; aleatoric&#19981;&#30830;&#23450;&#24615;&#21644;epistemic&#19981;&#30830;&#23450;&#24615;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#26032;&#25439;&#22833;&#30340;&#33021;&#21147;&#65292;&#20854;&#20013;&#20004;&#31181;&#31867;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#21487;&#20197;&#20998;&#21035;&#25511;&#21046;&#12290;&#27492;&#22806;&#65292;&#20316;&#20026;&#29616;&#23454;&#19990;&#30028;&#22330;&#26223;&#30340;&#28436;&#31034;&#65292;&#25105;&#20204;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern deep neural networks are prone to being overconfident despite their drastically improved performance. In ambiguous or even unpredictable real-world scenarios, this overconfidence can pose a major risk to the safety of applications. For regression tasks, the regression-by-classification approach has the potential to alleviate these ambiguities by instead predicting a discrete probability density over the desired output. However, a density estimator still tends to be overconfident when trained with the common NLL loss. To mitigate the overconfidence problem, we propose a loss function, hinge-Wasserstein, based on the Wasserstein Distance. This loss significantly improves the quality of both aleatoric and epistemic uncertainty, compared to previous work. We demonstrate the capabilities of the new loss on a synthetic dataset, where both types of uncertainty are controlled separately. Moreover, as a demonstration for real-world scenarios, we evaluate our approach on the benchmark dat
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;ReLU&#32593;&#32476;&#20013;&#30340;&#25104;&#23545;&#23398;&#20064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;&#19968;&#33324;&#25439;&#22833;&#20989;&#25968;&#30340;&#35823;&#24046;&#20272;&#35745;&#30340;&#23574;&#38160;&#30028;&#38480;&#65292;&#24182;&#22522;&#20110;&#25104;&#23545;&#26368;&#23567;&#20108;&#20056;&#25439;&#22833;&#24471;&#20986;&#20960;&#20046;&#26368;&#20248;&#30340;&#36807;&#24230;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2305.19640</link><description>&lt;p&gt;
&#28145;&#24230;ReLU&#32593;&#32476;&#20013;&#30340;&#25104;&#23545;&#23398;&#20064;&#26368;&#20248;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Optimal Estimates for Pairwise Learning with Deep ReLU Networks. (arXiv:2305.19640v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19640
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;ReLU&#32593;&#32476;&#20013;&#30340;&#25104;&#23545;&#23398;&#20064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;&#19968;&#33324;&#25439;&#22833;&#20989;&#25968;&#30340;&#35823;&#24046;&#20272;&#35745;&#30340;&#23574;&#38160;&#30028;&#38480;&#65292;&#24182;&#22522;&#20110;&#25104;&#23545;&#26368;&#23567;&#20108;&#20056;&#25439;&#22833;&#24471;&#20986;&#20960;&#20046;&#26368;&#20248;&#30340;&#36807;&#24230;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25104;&#23545;&#23398;&#20064;&#25351;&#30340;&#26159;&#22312;&#25439;&#22833;&#20989;&#25968;&#20013;&#32771;&#34385;&#19968;&#23545;&#26679;&#26412;&#30340;&#23398;&#20064;&#20219;&#21153;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;ReLU&#32593;&#32476;&#20013;&#30340;&#25104;&#23545;&#23398;&#20064;&#65292;&#24182;&#20272;&#35745;&#20102;&#36807;&#24230;&#27867;&#21270;&#35823;&#24046;&#12290;&#23545;&#20110;&#28385;&#36275;&#26576;&#20123;&#28201;&#21644;&#26465;&#20214;&#30340;&#19968;&#33324;&#25439;&#22833;&#20989;&#25968;&#65292;&#24314;&#31435;&#20102;&#35823;&#24046;&#20272;&#35745;&#30340;&#23574;&#38160;&#30028;&#38480;&#65292;&#20854;&#35823;&#24046;&#20272;&#35745;&#30340;&#38454;&#25968;&#20026;O&#65288;&#65288;Vlog&#65288;n&#65289;/ n&#65289;1 /&#65288;2-&#946;&#65289;&#65289;&#12290;&#29305;&#21035;&#22320;&#65292;&#23545;&#20110;&#25104;&#23545;&#26368;&#23567;&#20108;&#20056;&#25439;&#22833;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#36807;&#24230;&#27867;&#21270;&#35823;&#24046;&#30340;&#20960;&#20046;&#26368;&#20248;&#30028;&#38480;&#65292;&#22312;&#30495;&#23454;&#30340;&#39044;&#27979;&#22120;&#28385;&#36275;&#26576;&#20123;&#20809;&#28369;&#24615;&#27491;&#21017;&#24615;&#26102;&#65292;&#26368;&#20248;&#30028;&#38480;&#36798;&#21040;&#20102;&#26368;&#23567;&#21270;&#30028;&#38480;&#65292;&#24046;&#36317;&#20165;&#20026;&#23545;&#25968;&#39033;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pairwise learning refers to learning tasks where a loss takes a pair of samples into consideration. In this paper, we study pairwise learning with deep ReLU networks and estimate the excess generalization error. For a general loss satisfying some mild conditions, a sharp bound for the estimation error of order $O((V\log(n) /n)^{1/(2-\beta)})$ is established. In particular, with the pairwise least squares loss, we derive a nearly optimal bound of the excess generalization error which achieves the minimax lower bound up to a logrithmic term when the true predictor satisfies some smoothness regularities.
&lt;/p&gt;</description></item></channel></rss>