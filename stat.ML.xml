<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#21644;&#36125;&#21494;&#26031;&#28155;&#21152;&#22238;&#24402;&#26641;&#20316;&#20026;&#32447;&#24615;&#24809;&#32602;&#20272;&#35745;&#30340;&#28789;&#27963;&#25193;&#23637;&#65292;&#35299;&#20915;&#20102;&#28151;&#21512;&#39057;&#29575;&#25968;&#25454;&#20013;&#30340;&#39057;&#29575;&#19981;&#21305;&#37197;&#38382;&#39064;&#65292;&#25552;&#39640;&#20102;&#29616;&#22330;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.10574</link><description>&lt;p&gt;
&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#36827;&#34892;&#28151;&#21512;&#39057;&#29575;&#25968;&#25454;&#30340;&#29616;&#22330;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Nowcasting with mixed frequency data using Gaussian processes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10574
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#21644;&#36125;&#21494;&#26031;&#28155;&#21152;&#22238;&#24402;&#26641;&#20316;&#20026;&#32447;&#24615;&#24809;&#32602;&#20272;&#35745;&#30340;&#28789;&#27963;&#25193;&#23637;&#65292;&#35299;&#20915;&#20102;&#28151;&#21512;&#39057;&#29575;&#25968;&#25454;&#20013;&#30340;&#39057;&#29575;&#19981;&#21305;&#37197;&#38382;&#39064;&#65292;&#25552;&#39640;&#20102;&#29616;&#22330;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#24182;&#35752;&#35770;&#20102;&#29992;&#20110;&#28151;&#21512;&#25968;&#25454;&#37319;&#26679;&#65288;MIDAS&#65289;&#22238;&#24402;&#30340;&#36125;&#21494;&#26031;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#12290;&#36825;&#28041;&#21450;&#20351;&#29992;&#21463;&#38480;&#21644;&#38750;&#21463;&#38480;&#30340;MIDAS&#21464;&#20307;&#22788;&#29702;&#39057;&#29575;&#19981;&#21305;&#37197;&#65292;&#24182;&#25351;&#23450;&#35768;&#22810;&#39044;&#27979;&#21464;&#37327;&#19982;&#22240;&#21464;&#37327;&#20043;&#38388;&#30340;&#20989;&#25968;&#20851;&#31995;&#12290;&#25105;&#20204;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#21644;&#36125;&#21494;&#26031;&#28155;&#21152;&#22238;&#24402;&#26641;&#65288;BART&#65289;&#20316;&#20026;&#32447;&#24615;&#24809;&#32602;&#20272;&#35745;&#30340;&#28789;&#27963;&#25193;&#23637;&#12290;&#22312;&#29616;&#22330;&#39044;&#27979;&#21644;&#39044;&#27979;&#32451;&#20064;&#20013;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#23395;&#24230;&#32654;&#22269;&#20135;&#20986;&#22686;&#38271;&#21644;GDP&#20215;&#26684;&#25351;&#25968;&#30340;&#36890;&#36135;&#33192;&#32960;&#12290;&#36825;&#20123;&#26032;&#27169;&#22411;&#20197;&#35745;&#31639;&#25928;&#29575;&#30340;&#26041;&#24335;&#21033;&#29992;&#23439;&#35266;&#32463;&#27982;&#22823;&#25968;&#25454;&#65292;&#24182;&#22312;&#22810;&#20010;&#32500;&#24230;&#19978;&#25552;&#20379;&#20102;&#39044;&#27979;&#20934;&#30830;&#24230;&#30340;&#22686;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10574v1 Announce Type: new  Abstract: We propose and discuss Bayesian machine learning methods for mixed data sampling (MIDAS) regressions. This involves handling frequency mismatches with restricted and unrestricted MIDAS variants and specifying functional relationships between many predictors and the dependent variable. We use Gaussian processes (GP) and Bayesian additive regression trees (BART) as flexible extensions to linear penalized estimation. In a nowcasting and forecasting exercise we focus on quarterly US output growth and inflation in the GDP deflator. The new models leverage macroeconomic Big Data in a computationally efficient way and offer gains in predictive accuracy along several dimensions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#20248;&#21270;&#30340;&#26041;&#27861;&#20013;&#20984;&#27491;&#21017;&#21270;&#30340;&#33021;&#21147;&#21644;&#23616;&#38480;&#24615;&#38382;&#39064;&#65292;&#36890;&#36807;&#30740;&#31350;&#32473;&#23450;&#20998;&#24067;&#24773;&#20917;&#19979;&#65292;&#23545;&#25968;&#25454;&#37319;&#29992;&#20309;&#31181;&#27491;&#21017;&#21270;&#26041;&#27861;&#26159;&#26368;&#20248;&#30340;&#12290;</title><link>https://arxiv.org/abs/2212.13597</link><description>&lt;p&gt;
&#36866;&#29992;&#20110;&#25968;&#25454;&#28304;&#30340;&#26368;&#20248;&#27491;&#21017;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Optimal Regularization for a Data Source
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2212.13597
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#20248;&#21270;&#30340;&#26041;&#27861;&#20013;&#20984;&#27491;&#21017;&#21270;&#30340;&#33021;&#21147;&#21644;&#23616;&#38480;&#24615;&#38382;&#39064;&#65292;&#36890;&#36807;&#30740;&#31350;&#32473;&#23450;&#20998;&#24067;&#24773;&#20917;&#19979;&#65292;&#23545;&#25968;&#25454;&#37319;&#29992;&#20309;&#31181;&#27491;&#21017;&#21270;&#26041;&#27861;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22522;&#20110;&#20248;&#21270;&#30340;&#36870;&#38382;&#39064;&#21644;&#32479;&#35745;&#20272;&#35745;&#20013;&#65292;&#24120;&#24120;&#36890;&#36807;&#21152;&#20837;&#20419;&#20351;&#25968;&#25454;&#20445;&#30495;&#24615;&#30340;&#20934;&#21017;&#21644;&#20419;&#36827;&#35299;&#30340;&#25152;&#38656;&#32467;&#26500;&#24615;&#36136;&#30340;&#27491;&#21017;&#21270;&#39033;&#26469;&#35299;&#20915;&#38382;&#39064;&#12290;&#36873;&#25321;&#36866;&#24403;&#30340;&#27491;&#21017;&#21270;&#32422;&#26463;&#36890;&#24120;&#30001;&#21069;&#39046;&#22495;&#30693;&#35782;&#21644;&#35745;&#31639;&#32771;&#34385;&#20849;&#21516;&#39537;&#21160;&#12290;&#20984;&#27491;&#21017;&#21270;&#39033;&#22312;&#35745;&#31639;&#19978;&#20855;&#26377;&#21560;&#24341;&#21147;&#65292;&#20294;&#22312;&#25552;&#21319;&#32467;&#26500;&#31867;&#22411;&#26041;&#38754;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#38750;&#20984;&#27491;&#21017;&#21270;&#39033;&#22312;&#20419;&#36827;&#32467;&#26500;&#31867;&#22411;&#26041;&#38754;&#26356;&#20855;&#28789;&#27963;&#24615;&#65292;&#24182;&#19988;&#22312;&#26576;&#20123;&#24212;&#29992;&#20013;&#23637;&#31034;&#20986;&#20102;&#24378;&#22823;&#30340;&#23454;&#35777;&#24615;&#33021;&#65292;&#20294;&#21516;&#26102;&#20063;&#24102;&#26469;&#20102;&#35299;&#20915;&#30456;&#20851;&#20248;&#21270;&#38382;&#39064;&#30340;&#35745;&#31639;&#25361;&#25112;&#12290;&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#20197;&#19979;&#38382;&#39064;&#65292;&#23547;&#27714;&#23545;&#20984;&#27491;&#21017;&#21270;&#22312;&#25928;&#33021;&#21644;&#23616;&#38480;&#24615;&#26041;&#38754;&#30340;&#31995;&#32479;&#29702;&#35299;&#65306;&#32473;&#23450;&#19968;&#20010;&#20998;&#24067;&#65292;&#23545;&#20110;&#20174;&#35813;&#20998;&#24067;&#20013;&#25277;&#21462;&#30340;&#25968;&#25454;&#65292;&#20160;&#20040;&#26159;&#26368;&#20248;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#65311;
&lt;/p&gt;
&lt;p&gt;
In optimization-based approaches to inverse problems and to statistical estimation, it is common to augment criteria that enforce data fidelity with a regularizer that promotes desired structural properties in the solution. The choice of a suitable regularizer is typically driven by a combination of prior domain information and computational considerations. Convex regularizers are attractive computationally but they are limited in the types of structure they can promote. On the other hand, nonconvex regularizers are more flexible in the forms of structure they can promote and they have showcased strong empirical performance in some applications, but they come with the computational challenge of solving the associated optimization problems. In this paper, we seek a systematic understanding of the power and the limitations of convex regularization by investigating the following questions: Given a distribution, what is the optimal regularizer for data drawn from the distribution? What pro
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#20844;&#20849;&#25968;&#25454;&#30340;&#26368;&#20248;&#24046;&#20998;&#38544;&#31169;&#23398;&#20064;&#65292;&#24182;&#35299;&#20915;&#20102;&#22312;&#35757;&#32451;&#24046;&#20998;&#38544;&#31169;&#27169;&#22411;&#26102;&#22914;&#20309;&#21033;&#29992;&#20844;&#20849;&#25968;&#25454;&#25552;&#39640;&#20934;&#30830;&#24615;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.15056</link><description>&lt;p&gt;
&#20855;&#26377;&#20844;&#20849;&#25968;&#25454;&#30340;&#26368;&#20248;&#24046;&#20998;&#38544;&#31169;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Optimal Differentially Private Learning with Public Data. (arXiv:2306.15056v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15056
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#20844;&#20849;&#25968;&#25454;&#30340;&#26368;&#20248;&#24046;&#20998;&#38544;&#31169;&#23398;&#20064;&#65292;&#24182;&#35299;&#20915;&#20102;&#22312;&#35757;&#32451;&#24046;&#20998;&#38544;&#31169;&#27169;&#22411;&#26102;&#22914;&#20309;&#21033;&#29992;&#20844;&#20849;&#25968;&#25454;&#25552;&#39640;&#20934;&#30830;&#24615;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#33021;&#22815;&#30830;&#20445;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#19981;&#27844;&#28431;&#31169;&#23494;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#24046;&#20998;&#38544;&#31169;&#30340;&#20195;&#20215;&#26159;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#38477;&#20302;&#25110;&#26679;&#26412;&#22797;&#26434;&#24230;&#22686;&#21152;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#25105;&#20204;&#21487;&#33021;&#21487;&#20197;&#35775;&#38382;&#19981;&#28041;&#21450;&#38544;&#31169;&#38382;&#39064;&#30340;&#36741;&#21161;&#20844;&#20849;&#25968;&#25454;&#12290;&#36825;&#20419;&#20351;&#20102;&#26368;&#36817;&#30740;&#31350;&#20844;&#20849;&#25968;&#25454;&#22312;&#25552;&#39640;&#24046;&#20998;&#38544;&#31169;&#27169;&#22411;&#20934;&#30830;&#24615;&#26041;&#38754;&#30340;&#20316;&#29992;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20551;&#35774;&#26377;&#19968;&#23450;&#25968;&#37327;&#30340;&#20844;&#20849;&#25968;&#25454;&#65292;&#24182;&#35299;&#20915;&#20197;&#19979;&#22522;&#26412;&#24320;&#25918;&#38382;&#39064;&#65306;1.&#22312;&#26377;&#20844;&#20849;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#35757;&#32451;&#22522;&#20110;&#31169;&#26377;&#25968;&#25454;&#38598;&#30340;&#24046;&#20998;&#38544;&#31169;&#27169;&#22411;&#30340;&#26368;&#20248;&#65288;&#26368;&#22351;&#24773;&#20917;&#65289;&#35823;&#24046;&#26159;&#22810;&#23569;&#65311;&#21738;&#20123;&#31639;&#27861;&#26159;&#26368;&#20248;&#30340;&#65311;2.&#22914;&#20309;&#21033;&#29992;&#20844;&#20849;&#25968;&#25454;&#22312;&#23454;&#36341;&#20013;&#25913;&#36827;&#24046;&#20998;&#38544;&#31169;&#27169;&#22411;&#35757;&#32451;&#65311;&#25105;&#20204;&#22312;&#26412;&#22320;&#27169;&#22411;&#21644;&#20013;&#24515;&#27169;&#22411;&#30340;&#24046;&#20998;&#38544;&#31169;&#38382;&#39064;&#19979;&#32771;&#34385;&#36825;&#20123;&#38382;&#39064;&#12290;&#20026;&#20102;&#22238;&#31572;&#31532;&#19968;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#19977;&#20010;&#22522;&#26412;&#38382;&#39064;&#30340;&#26368;&#20248;&#35823;&#24046;&#29575;&#30340;&#32039;&#23494;&#65288;&#26368;&#39640;&#24120;&#25968;&#22240;&#23376;&#65289;&#19979;&#30028;&#21644;&#19978;&#30028;&#12290;&#36825;&#19977;&#20010;&#38382;&#39064;&#26159;&#65306;&#22343;&#20540;&#20272;&#35745;&#65292;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#21644;&#20984;&#22855;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Differential Privacy (DP) ensures that training a machine learning model does not leak private data. However, the cost of DP is lower model accuracy or higher sample complexity. In practice, we may have access to auxiliary public data that is free of privacy concerns. This has motivated the recent study of what role public data might play in improving the accuracy of DP models. In this work, we assume access to a given amount of public data and settle the following fundamental open questions: 1. What is the optimal (worst-case) error of a DP model trained over a private data set while having access to side public data? What algorithms are optimal? 2. How can we harness public data to improve DP model training in practice? We consider these questions in both the local and central models of DP. To answer the first question, we prove tight (up to constant factors) lower and upper bounds that characterize the optimal error rates of three fundamental problems: mean estimation, empirical ris
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#32447;&#24615;&#22238;&#22768;&#29366;&#24577;&#32593;&#32476;&#30340;&#35760;&#24518;&#23481;&#37327;&#35745;&#31639;&#38382;&#39064;&#12290;&#36890;&#36807;&#21457;&#29616;&#25968;&#20540;&#35780;&#20272;&#30340;&#19981;&#20934;&#30830;&#24615;&#20027;&#35201;&#28304;&#20110;&#25968;&#20540;&#26041;&#38754;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#25513;&#30721;&#30697;&#38453;MC&#30456;&#23545;&#20110;&#20013;&#31435;&#24615;&#30340;&#31283;&#20581;&#25968;&#20540;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#35299;&#20915;&#25968;&#20540;&#35780;&#20272;&#20013;&#30340;&#35823;&#24046;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.01457</link><description>&lt;p&gt;
&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#30340;&#35760;&#24518;&#65306;&#25105;&#20204;&#35745;&#31639;&#24471;&#23545;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Memory of recurrent networks: Do we compute it right?. (arXiv:2305.01457v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.01457
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#32447;&#24615;&#22238;&#22768;&#29366;&#24577;&#32593;&#32476;&#30340;&#35760;&#24518;&#23481;&#37327;&#35745;&#31639;&#38382;&#39064;&#12290;&#36890;&#36807;&#21457;&#29616;&#25968;&#20540;&#35780;&#20272;&#30340;&#19981;&#20934;&#30830;&#24615;&#20027;&#35201;&#28304;&#20110;&#25968;&#20540;&#26041;&#38754;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#25513;&#30721;&#30697;&#38453;MC&#30456;&#23545;&#20110;&#20013;&#31435;&#24615;&#30340;&#31283;&#20581;&#25968;&#20540;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#35299;&#20915;&#25968;&#20540;&#35780;&#20272;&#20013;&#30340;&#35823;&#24046;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25991;&#29486;&#20013;&#23545;&#20110;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#30340;&#35760;&#24518;&#23481;&#37327;&#65288;MC&#65289;&#30340;&#25968;&#20540;&#35780;&#20272;&#24120;&#24120;&#19982;&#24050;&#32463;&#24314;&#31435;&#30340;&#29702;&#35770;&#30028;&#38480;&#30456;&#30683;&#30462;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#32447;&#24615;&#22238;&#22768;&#29366;&#24577;&#32593;&#32476;&#30340;&#24773;&#20917;&#65292;&#23545;&#24212;&#30340;Kalman&#21487;&#25511;&#30697;&#38453;&#30340;&#31209;&#24050;&#34987;&#35777;&#26126;&#31561;&#20110;&#24635;&#35760;&#24518;&#23481;&#37327;&#12290;&#25105;&#20204;&#25581;&#31034;&#20102;&#20851;&#20110;&#35760;&#24518;&#19981;&#20934;&#30830;&#30340;&#25968;&#20540;&#35780;&#20272;&#30340;&#21508;&#31181;&#21407;&#22240;&#65292;&#24182;&#34920;&#26126;&#36825;&#20123;&#38382;&#39064;&#26159;&#32431;&#31929;&#25968;&#20540;&#26041;&#38754;&#19978;&#30340;&#65292;&#24448;&#24448;&#22312;&#36817;&#26399;&#25991;&#29486;&#20013;&#34987;&#24573;&#35270;&#12290;&#26356;&#26126;&#30830;&#22320;&#35828;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#32447;&#24615;MC&#30340;Krylov&#32467;&#26500;&#34987;&#24573;&#30053;&#26102;&#65292;&#29702;&#35770;MC&#21644;&#23427;&#30340;&#32463;&#39564;&#20540;&#20043;&#38388;&#20250;&#23384;&#22312;&#24046;&#36317;&#12290;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#30340;&#26041;&#27861;&#26159;&#65292;&#21033;&#29992;MC&#30456;&#23545;&#20110;&#36755;&#20837;&#25513;&#30721;&#30697;&#38453;&#30340;&#20013;&#31435;&#24615;&#65292;&#24320;&#21457;&#20986;&#31283;&#20581;&#30340;&#25968;&#20540;&#26041;&#27861;&#12290;&#27169;&#25311;&#32467;&#26524;&#26174;&#31034;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#24471;&#21040;&#30340;&#35760;&#24518;&#26354;&#32447;&#19982;&#29702;&#35770;&#23436;&#20840;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
Numerical evaluations of the memory capacity (MC) of recurrent neural networks reported in the literature often contradict well-established theoretical bounds. In this paper, we study the case of linear echo state networks, for which the total memory capacity has been proven to be equal to the rank of the corresponding Kalman controllability matrix. We shed light on various reasons for the inaccurate numerical estimations of the memory, and we show that these issues, often overlooked in the recent literature, are of an exclusively numerical nature. More explicitly, we prove that when the Krylov structure of the linear MC is ignored, a gap between the theoretical MC and its empirical counterpart is introduced. As a solution, we develop robust numerical approaches by exploiting a result of MC neutrality with respect to the input mask matrix. Simulations show that the memory curves that are recovered using the proposed methods fully agree with the theory.
&lt;/p&gt;</description></item></channel></rss>