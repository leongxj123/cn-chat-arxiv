<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>Transformers&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#22240;&#26524;&#32467;&#26500;&#30340;&#36807;&#31243;&#20013;&#65292;&#20851;&#38190;&#30340;&#35777;&#25454;&#26159;&#27880;&#24847;&#21147;&#30697;&#38453;&#30340;&#26799;&#24230;&#32534;&#30721;&#20102;token&#20043;&#38388;&#30340;&#20114;&#20449;&#24687;</title><link>https://arxiv.org/abs/2402.14735</link><description>&lt;p&gt;
Transformers&#22914;&#20309;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#22240;&#26524;&#32467;&#26500;
&lt;/p&gt;
&lt;p&gt;
How Transformers Learn Causal Structure with Gradient Descent
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14735
&lt;/p&gt;
&lt;p&gt;
Transformers&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#22240;&#26524;&#32467;&#26500;&#30340;&#36807;&#31243;&#20013;&#65292;&#20851;&#38190;&#30340;&#35777;&#25454;&#26159;&#27880;&#24847;&#21147;&#30697;&#38453;&#30340;&#26799;&#24230;&#32534;&#30721;&#20102;token&#20043;&#38388;&#30340;&#20114;&#20449;&#24687;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformers&#22312;&#24207;&#21015;&#24314;&#27169;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#20196;&#20154;&#38590;&#20197;&#32622;&#20449;&#30340;&#25104;&#21151;&#65292;&#36825;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#24402;&#21151;&#20110;&#33258;&#27880;&#24847;&#26426;&#21046;&#65292;&#23427;&#20801;&#35768;&#20449;&#24687;&#22312;&#24207;&#21015;&#30340;&#19981;&#21516;&#37096;&#20998;&#20043;&#38388;&#20256;&#36882;&#12290;&#33258;&#27880;&#24847;&#26426;&#21046;&#20351;&#24471;transformers&#33021;&#22815;&#32534;&#30721;&#22240;&#26524;&#32467;&#26500;&#65292;&#20174;&#32780;&#20351;&#20854;&#29305;&#21035;&#36866;&#21512;&#24207;&#21015;&#24314;&#27169;&#12290;&#28982;&#32780;&#65292;transformers&#36890;&#36807;&#26799;&#24230;&#35757;&#32451;&#31639;&#27861;&#23398;&#20064;&#36825;&#31181;&#22240;&#26524;&#32467;&#26500;&#30340;&#36807;&#31243;&#20173;&#28982;&#19981;&#22826;&#28165;&#26970;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#29702;&#35299;&#36825;&#20010;&#36807;&#31243;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#38656;&#35201;&#23398;&#20064;&#28508;&#22312;&#22240;&#26524;&#32467;&#26500;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#20219;&#21153;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#31616;&#21270;&#30340;&#20004;&#23618;transformer&#19978;&#30340;&#26799;&#24230;&#19979;&#38477;&#21487;&#20197;&#23398;&#20250;&#35299;&#20915;&#36825;&#20010;&#20219;&#21153;&#65292;&#36890;&#36807;&#22312;&#31532;&#19968;&#23618;&#27880;&#24847;&#21147;&#20013;&#32534;&#30721;&#28508;&#22312;&#22240;&#26524;&#22270;&#26469;&#23436;&#25104;&#12290;&#25105;&#20204;&#35777;&#26126;&#30340;&#20851;&#38190;&#27934;&#23519;&#26159;&#27880;&#24847;&#21147;&#30697;&#38453;&#30340;&#26799;&#24230;&#32534;&#30721;&#20102;token&#20043;&#38388;&#30340;&#20114;&#20449;&#24687;&#12290;&#30001;&#20110;&#25968;&#25454;&#22788;&#29702;&#19981;&#31561;&#24335;&#30340;&#32467;&#26524;&#65292;&#27880;&#24847;&#21147;&#30697;&#38453;&#20013;&#26368;&#22823;&#30340;&#26465;&#30446;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14735v1 Announce Type: new  Abstract: The incredible success of transformers on sequence modeling tasks can be largely attributed to the self-attention mechanism, which allows information to be transferred between different parts of a sequence. Self-attention allows transformers to encode causal structure which makes them particularly suitable for sequence modeling. However, the process by which transformers learn such causal structure via gradient-based training algorithms remains poorly understood. To better understand this process, we introduce an in-context learning task that requires learning latent causal structure. We prove that gradient descent on a simplified two-layer transformer learns to solve this task by encoding the latent causal graph in the first attention layer. The key insight of our proof is that the gradient of the attention matrix encodes the mutual information between tokens. As a consequence of the data processing inequality, the largest entries of th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#36830;&#24102;&#20559;&#24207;&#29305;&#24615;&#30340;&#38750;&#20984;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#38454;&#31639;&#27861;&#30340;&#36866;&#29992;&#33539;&#22260;&#65292;&#24182;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#22797;&#26434;&#24230;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2402.05071</link><description>&lt;p&gt;
&#25193;&#23637;&#20855;&#26377;&#36830;&#24102;&#20559;&#24207;&#29305;&#24615;&#30340;&#38750;&#20984;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#19968;&#38454;&#31639;&#27861;&#30340;&#36866;&#29992;&#33539;&#22260;
&lt;/p&gt;
&lt;p&gt;
Extending the Reach of First-Order Algorithms for Nonconvex Min-Max Problems with Cohypomonotonicity
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05071
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#36830;&#24102;&#20559;&#24207;&#29305;&#24615;&#30340;&#38750;&#20984;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#38454;&#31639;&#27861;&#30340;&#36866;&#29992;&#33539;&#22260;&#65292;&#24182;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#22797;&#26434;&#24230;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;&#28385;&#36275;rho-&#36830;&#24102;&#20559;&#24207;&#29305;&#24615;&#25110;&#22312;rho-&#24369;Minty&#21464;&#20998;&#19981;&#31561;&#24335;&#65288;MVI&#65289;&#20013;&#23384;&#22312;&#35299;&#30340;&#32422;&#26463;&#65292;L-&#20809;&#28369;&#30340;&#38750;&#20984;&#38750;&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#20854;&#20013;&#21442;&#25968;rho&gt;0&#30340;&#36739;&#22823;&#20540;&#23545;&#24212;&#26356;&#39640;&#30340;&#38750;&#20984;&#24615;&#31243;&#24230;&#12290;&#36825;&#20123;&#38382;&#39064;&#31867;&#21253;&#25324;&#20004;&#20010;&#29609;&#23478;&#24378;&#21270;&#23398;&#20064;&#65292;&#20132;&#20114;&#20027;&#23548;&#30340;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#20197;&#21450;&#26576;&#20123;&#32463;&#20856;&#26497;&#23567;&#26497;&#22823;&#31639;&#27861;&#26080;&#27861;&#35299;&#20915;&#30340;&#21512;&#25104;&#27979;&#35797;&#38382;&#39064;&#12290;&#24050;&#26377;&#29468;&#24819;&#35748;&#20026;&#19968;&#38454;&#26041;&#27861;&#21487;&#23481;&#24525;&#26368;&#22823;rho&#20026;1/L&#65292;&#20294;&#29616;&#26377;&#25991;&#29486;&#20013;&#30340;&#32467;&#26524;&#24050;&#20572;&#28382;&#22312;&#26356;&#20005;&#26684;&#30340;&#35201;&#27714;rho&lt;1/2L&#12290;&#36890;&#36807;&#31616;&#21333;&#30340;&#35770;&#35777;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#20855;&#26377;&#36830;&#24102;&#20559;&#24207;&#29305;&#24615;&#25110;&#24369;MVI&#26465;&#20214;&#19979;&#65292;rho&lt;1/L&#30340;&#26368;&#20248;&#25110;&#26368;&#20339;&#24050;&#30693;&#22797;&#26434;&#24230;&#20445;&#35777;&#12290;&#25105;&#20204;&#20998;&#26512;&#30340;&#31639;&#27861;&#26159;Halpern&#21644;Krasnosel'ski&#301;-Mann (KM)&#36845;&#20195;&#30340;&#38750;&#31934;&#30830;&#21464;&#31181;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#31639;&#27861;&#21644;&#22797;&#26434;&#24230;g...
&lt;/p&gt;
&lt;p&gt;
We focus on constrained, $L$-smooth, nonconvex-nonconcave min-max problems either satisfying $\rho$-cohypomonotonicity or admitting a solution to the $\rho$-weakly Minty Variational Inequality (MVI), where larger values of the parameter $\rho&gt;0$ correspond to a greater degree of nonconvexity. These problem classes include examples in two player reinforcement learning, interaction dominant min-max problems, and certain synthetic test problems on which classical min-max algorithms fail. It has been conjectured that first-order methods can tolerate value of $\rho$ no larger than $\frac{1}{L}$, but existing results in the literature have stagnated at the tighter requirement $\rho &lt; \frac{1}{2L}$. With a simple argument, we obtain optimal or best-known complexity guarantees with cohypomonotonicity or weak MVI conditions for $\rho &lt; \frac{1}{L}$. The algorithms we analyze are inexact variants of Halpern and Krasnosel'ski\u{\i}-Mann (KM) iterations. We also provide algorithms and complexity g
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38598;&#25104;&#35780;&#20998;&#28388;&#27874;&#22120;&#65288;EnSF&#65289;&#65292;&#22312;&#22788;&#29702;&#39640;&#32500;&#38750;&#32447;&#24615;&#28388;&#27874;&#38382;&#39064;&#26102;&#20855;&#26377;&#21331;&#36234;&#30340;&#20934;&#30830;&#24615;&#12290;EnSF&#21033;&#29992;&#35780;&#20998;&#27169;&#22411;&#22312;&#20266;&#26102;&#22495;&#20013;&#25551;&#36848;&#28388;&#27874;&#23494;&#24230;&#30340;&#28436;&#21270;&#65292;&#24182;&#36890;&#36807;&#35780;&#20998;&#20989;&#25968;&#23384;&#20648;&#20449;&#24687;&#65292;&#30456;&#27604;&#20110;&#20351;&#29992;&#33945;&#29305;&#21345;&#32599;&#26679;&#26412;&#30340;&#31890;&#23376;&#28388;&#27874;&#22120;&#21644;&#38598;&#25104;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#20855;&#26377;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2309.00983</link><description>&lt;p&gt;
&#29992;&#20110;&#36319;&#36394;&#39640;&#32500;&#38750;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#30340;&#38598;&#25104;&#35780;&#20998;&#28388;&#27874;&#22120;
&lt;/p&gt;
&lt;p&gt;
An Ensemble Score Filter for Tracking High-Dimensional Nonlinear Dynamical Systems. (arXiv:2309.00983v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00983
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38598;&#25104;&#35780;&#20998;&#28388;&#27874;&#22120;&#65288;EnSF&#65289;&#65292;&#22312;&#22788;&#29702;&#39640;&#32500;&#38750;&#32447;&#24615;&#28388;&#27874;&#38382;&#39064;&#26102;&#20855;&#26377;&#21331;&#36234;&#30340;&#20934;&#30830;&#24615;&#12290;EnSF&#21033;&#29992;&#35780;&#20998;&#27169;&#22411;&#22312;&#20266;&#26102;&#22495;&#20013;&#25551;&#36848;&#28388;&#27874;&#23494;&#24230;&#30340;&#28436;&#21270;&#65292;&#24182;&#36890;&#36807;&#35780;&#20998;&#20989;&#25968;&#23384;&#20648;&#20449;&#24687;&#65292;&#30456;&#27604;&#20110;&#20351;&#29992;&#33945;&#29305;&#21345;&#32599;&#26679;&#26412;&#30340;&#31890;&#23376;&#28388;&#27874;&#22120;&#21644;&#38598;&#25104;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#20855;&#26377;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38598;&#25104;&#35780;&#20998;&#28388;&#27874;&#22120;&#65288;EnSF&#65289;&#26469;&#35299;&#20915;&#39640;&#32500;&#38750;&#32447;&#24615;&#28388;&#27874;&#38382;&#39064;&#65292;&#24182;&#20855;&#26377;&#21331;&#36234;&#30340;&#20934;&#30830;&#24615;&#12290;&#29616;&#26377;&#30340;&#28388;&#27874;&#26041;&#27861;&#65288;&#22914;&#31890;&#23376;&#28388;&#27874;&#22120;&#25110;&#38598;&#25104;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65289;&#22312;&#22788;&#29702;&#39640;&#32500;&#21644;&#39640;&#24230;&#38750;&#32447;&#24615;&#38382;&#39064;&#26102;&#23384;&#22312;&#20302;&#20934;&#30830;&#24615;&#30340;&#20027;&#35201;&#32570;&#38519;&#12290;EnSF&#36890;&#36807;&#21033;&#29992;&#22522;&#20110;&#35780;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#22312;&#20266;&#26102;&#22495;&#20013;&#23450;&#20041;&#65292;&#26469;&#25551;&#36848;&#28388;&#27874;&#23494;&#24230;&#30340;&#28436;&#21270;&#65292;&#20174;&#32780;&#25915;&#20811;&#20102;&#36825;&#19968;&#25361;&#25112;&#12290;EnSF&#22312;&#35780;&#20998;&#20989;&#25968;&#20013;&#23384;&#20648;&#20102;&#36882;&#24402;&#26356;&#26032;&#30340;&#28388;&#27874;&#23494;&#24230;&#20989;&#25968;&#30340;&#20449;&#24687;&#65292;&#32780;&#19981;&#26159;&#22312;&#19968;&#32452;&#26377;&#38480;&#30340;&#33945;&#29305;&#21345;&#32599;&#26679;&#26412;&#20013;&#23384;&#20648;&#20449;&#24687;&#65288;&#29992;&#20110;&#31890;&#23376;&#28388;&#27874;&#22120;&#21644;&#38598;&#25104;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65289;&#12290;&#19982;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#26469;&#36817;&#20284;&#35780;&#20998;&#20989;&#25968;&#30340;&#29616;&#26377;&#25193;&#25955;&#27169;&#22411;&#19981;&#21516;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26080;&#38656;&#35757;&#32451;&#30340;&#35780;&#20998;&#20272;&#35745;&#26041;&#27861;&#65292;&#20351;&#29992;&#22522;&#20110;&#23567;&#25209;&#37327;&#30340;&#33945;&#29305;&#21345;&#32599;&#20272;&#35745;&#22120;&#26469;&#30452;&#25509;&#36817;&#20284;&#20219;&#20309;&#20266;&#31354;&#38388;-&#26102;&#38388;&#20301;&#32622;&#22788;&#30340;&#35780;&#20998;&#20989;&#25968;&#65292;&#20174;&#32780;&#25552;&#20379;&#20102;&#36275;&#22815;&#20934;&#30830;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose an ensemble score filter (EnSF) for solving high-dimensional nonlinear filtering problems with superior accuracy. A major drawback of existing filtering methods, e.g., particle filters or ensemble Kalman filters, is the low accuracy in handling high-dimensional and highly nonlinear problems. EnSF attacks this challenge by exploiting the score-based diffusion model, defined in a pseudo-temporal domain, to characterizing the evolution of the filtering density. EnSF stores the information of the recursively updated filtering density function in the score function, in stead of storing the information in a set of finite Monte Carlo samples (used in particle filters and ensemble Kalman filters). Unlike existing diffusion models that train neural networks to approximate the score function, we develop a training-free score estimation that uses mini-batch-based Monte Carlo estimator to directly approximate the score function at any pseudo-spatial-temporal location, which provides suf
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20302;&#27425;&#22810;&#39033;&#24335;&#35745;&#31639;&#22270;&#35770;&#20272;&#35745;&#23384;&#22312;&#35745;&#31639;&#38556;&#30861;&#65292;&#20256;&#32479;&#30340;&#20248;&#21270;&#20272;&#35745;&#26041;&#27861;&#20855;&#26377;&#25351;&#25968;&#32423;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#32780;&#26368;&#20248;&#22810;&#39033;&#24335;&#26102;&#38388;&#20272;&#35745;&#22120;&#21482;&#33021;&#36798;&#21040;&#36739;&#24930;&#30340;&#20272;&#35745;&#38169;&#35823;&#29575;&#12290;</title><link>http://arxiv.org/abs/2308.15728</link><description>&lt;p&gt;
&#36890;&#36807;&#20302;&#27425;&#22810;&#39033;&#24335;&#35745;&#31639;&#22270;&#35770;&#20272;&#35745;&#30340;&#19979;&#30028;
&lt;/p&gt;
&lt;p&gt;
Computational Lower Bounds for Graphon Estimation via Low-degree Polynomials. (arXiv:2308.15728v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15728
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20302;&#27425;&#22810;&#39033;&#24335;&#35745;&#31639;&#22270;&#35770;&#20272;&#35745;&#23384;&#22312;&#35745;&#31639;&#38556;&#30861;&#65292;&#20256;&#32479;&#30340;&#20248;&#21270;&#20272;&#35745;&#26041;&#27861;&#20855;&#26377;&#25351;&#25968;&#32423;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#32780;&#26368;&#20248;&#22810;&#39033;&#24335;&#26102;&#38388;&#20272;&#35745;&#22120;&#21482;&#33021;&#36798;&#21040;&#36739;&#24930;&#30340;&#20272;&#35745;&#38169;&#35823;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#35770;&#20272;&#35745;&#26159;&#32593;&#32476;&#20998;&#26512;&#20013;&#26368;&#22522;&#26412;&#30340;&#38382;&#39064;&#20043;&#19968;&#65292;&#22312;&#36807;&#21435;&#21313;&#24180;&#20013;&#21463;&#21040;&#20102;&#30456;&#24403;&#22823;&#30340;&#20851;&#27880;&#12290;&#20174;&#32479;&#35745;&#23398;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#39640;&#31561;&#25552;&#20986;&#20102;&#23545;&#20110;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;SBM&#65289;&#21644;&#38750;&#21442;&#25968;&#22270;&#35770;&#20272;&#35745;&#30340;&#22270;&#35770;&#20272;&#35745;&#30340;&#26497;&#23567;&#26497;&#24046;&#35823;&#24046;&#29575;&#12290;&#32479;&#35745;&#20248;&#21270;&#20272;&#35745;&#26159;&#22522;&#20110;&#32422;&#26463;&#26368;&#23567;&#20108;&#20056;&#27861;&#65292;&#24182;&#19988;&#22312;&#32500;&#24230;&#19978;&#20855;&#26377;&#25351;&#25968;&#32423;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#20174;&#35745;&#31639;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#24050;&#30693;&#30340;&#26368;&#20248;&#22810;&#39033;&#24335;&#26102;&#38388;&#20272;&#35745;&#22120;&#26159;&#22522;&#20110;&#36890;&#29992;&#22855;&#24322;&#20540;&#38408;&#20540;&#65288;USVT&#65289;&#65292;&#20294;&#26159;&#23427;&#21482;&#33021;&#36798;&#21040;&#27604;&#26497;&#23567;&#26497;&#24046;&#38169;&#35823;&#29575;&#24930;&#24471;&#22810;&#30340;&#20272;&#35745;&#38169;&#35823;&#29575;&#12290;&#20154;&#20204;&#33258;&#28982;&#20250;&#24819;&#30693;&#36947;&#36825;&#26679;&#30340;&#24046;&#36317;&#26159;&#21542;&#26159;&#24517;&#35201;&#30340;&#12290;USVT&#30340;&#35745;&#31639;&#20248;&#21270;&#24615;&#25110;&#22270;&#35770;&#20272;&#35745;&#20013;&#30340;&#35745;&#31639;&#38556;&#30861;&#30340;&#23384;&#22312;&#19968;&#30452;&#26159;&#19968;&#20010;&#38271;&#26399;&#23384;&#22312;&#30340;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23545;&#27492;&#36808;&#20986;&#20102;&#31532;&#19968;&#27493;&#65292;&#24182;&#20026;&#22270;&#35770;&#20272;&#35745;&#30340;&#35745;&#31639;&#38556;&#30861;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#35777;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graphon estimation has been one of the most fundamental problems in network analysis and has received considerable attention in the past decade. From the statistical perspective, the minimax error rate of graphon estimation has been established by Gao et al (2015) for both stochastic block model (SBM) and nonparametric graphon estimation. The statistical optimal estimators are based on constrained least squares and have computational complexity exponential in the dimension. From the computational perspective, the best-known polynomial-time estimator is based on universal singular value thresholding (USVT), but it can only achieve a much slower estimation error rate than the minimax one. It is natural to wonder if such a gap is essential. The computational optimality of the USVT or the existence of a computational barrier in graphon estimation has been a long-standing open problem. In this work, we take the first step towards it and provide rigorous evidence for the computational barrie
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#26816;&#27979;&#37329;&#34701;&#24066;&#22330;&#20013;&#30340;&#26080;&#27169;&#22411;&#38745;&#24577;&#22871;&#21033;&#26426;&#20250;&#65292;&#24182;&#21487;&#24212;&#29992;&#20110;&#20132;&#26131;&#35777;&#21048;&#25968;&#37327;&#36739;&#22810;&#30340;&#37329;&#34701;&#24066;&#22330;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#26131;&#22788;&#29702;&#24615;&#12289;&#26377;&#25928;&#24615;&#21644;&#31283;&#20581;&#24615;&#65292;&#24182;&#20351;&#29992;&#30495;&#23454;&#37329;&#34701;&#25968;&#25454;&#36827;&#34892;&#20102;&#31034;&#20363;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2306.16422</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#26816;&#27979;&#26080;&#27169;&#22411;&#38745;&#24577;&#22871;&#21033;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Neural networks can detect model-free static arbitrage strategies. (arXiv:2306.16422v1 [q-fin.CP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16422
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#26816;&#27979;&#37329;&#34701;&#24066;&#22330;&#20013;&#30340;&#26080;&#27169;&#22411;&#38745;&#24577;&#22871;&#21033;&#26426;&#20250;&#65292;&#24182;&#21487;&#24212;&#29992;&#20110;&#20132;&#26131;&#35777;&#21048;&#25968;&#37327;&#36739;&#22810;&#30340;&#37329;&#34701;&#24066;&#22330;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#26131;&#22788;&#29702;&#24615;&#12289;&#26377;&#25928;&#24615;&#21644;&#31283;&#20581;&#24615;&#65292;&#24182;&#20351;&#29992;&#30495;&#23454;&#37329;&#34701;&#25968;&#25454;&#36827;&#34892;&#20102;&#31034;&#20363;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#29702;&#35770;&#21644;&#25968;&#20540;&#26041;&#27861;&#35777;&#26126;&#20102;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#22312;&#24066;&#22330;&#23384;&#22312;&#22871;&#21033;&#26426;&#20250;&#26102;&#26816;&#27979;&#20986;&#26080;&#27169;&#22411;&#38745;&#24577;&#22871;&#21033;&#26426;&#20250;&#12290;&#30001;&#20110;&#20351;&#29992;&#20102;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#20132;&#26131;&#35777;&#21048;&#25968;&#37327;&#36739;&#22810;&#30340;&#37329;&#34701;&#24066;&#22330;&#65292;&#24182;&#30830;&#20445;&#30456;&#24212;&#20132;&#26131;&#31574;&#30053;&#30340;&#20960;&#20046;&#21363;&#26102;&#25191;&#34892;&#12290;&#20026;&#20102;&#35777;&#26126;&#20854;&#26131;&#22788;&#29702;&#24615;&#12289;&#26377;&#25928;&#24615;&#21644;&#31283;&#20581;&#24615;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20351;&#29992;&#30495;&#23454;&#37329;&#34701;&#25968;&#25454;&#30340;&#31034;&#20363;&#12290;&#20174;&#25216;&#26415;&#35282;&#24230;&#26469;&#30475;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21333;&#20010;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#36817;&#20284;&#35299;&#20915;&#19968;&#31867;&#20984;&#21322;&#26080;&#38480;&#35268;&#21010;&#38382;&#39064;&#65292;&#36825;&#26159;&#25512;&#23548;&#20986;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#30340;&#20851;&#38190;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we demonstrate both theoretically as well as numerically that neural networks can detect model-free static arbitrage opportunities whenever the market admits some. Due to the use of neural networks, our method can be applied to financial markets with a high number of traded securities and ensures almost immediate execution of the corresponding trading strategies. To demonstrate its tractability, effectiveness, and robustness we provide examples using real financial data. From a technical point of view, we prove that a single neural network can approximately solve a class of convex semi-infinite programs, which is the key result in order to derive our theoretical results that neural networks can detect model-free static arbitrage strategies whenever the financial market admits such opportunities.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#22312;&#32447;&#21453;&#39304;&#30340;&#23454;&#29616;&#24335;&#39044;&#27979;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#22312;&#27169;&#22411;&#37096;&#32626;&#33258;&#36523;&#25913;&#21464;&#25968;&#25454;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#20248;&#21270;&#20934;&#30830;&#24615;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.01094</link><description>&lt;p&gt;
&#36890;&#36807;&#37325;&#26032;&#21442;&#25968;&#21270;&#23398;&#20064;&#23454;&#29616;&#22312;&#32447;&#21453;&#39304;&#30340;&#23454;&#29616;&#24335;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Performative Prediction with Bandit Feedback: Learning through Reparameterization. (arXiv:2305.01094v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.01094
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#22312;&#32447;&#21453;&#39304;&#30340;&#23454;&#29616;&#24335;&#39044;&#27979;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#22312;&#27169;&#22411;&#37096;&#32626;&#33258;&#36523;&#25913;&#21464;&#25968;&#25454;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#20248;&#21270;&#20934;&#30830;&#24615;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#25968;&#25454;&#20998;&#24067;&#30001;&#27169;&#22411;&#37096;&#32626;&#33258;&#36523;&#25913;&#21464;&#30340;&#24773;&#24418;&#19979;&#39044;&#27979;&#30340;&#19968;&#20010;&#26694;&#26550;&#8212;&#8212;&#23454;&#29616;&#24335;&#39044;&#27979;&#12290;&#29616;&#26377;&#30740;&#31350;&#30340;&#37325;&#28857;&#22312;&#20110;&#20248;&#21270;&#20934;&#30830;&#24615;&#65292;&#20294;&#26159;&#20854;&#20551;&#35774;&#24448;&#24448;&#38590;&#20197;&#22312;&#23454;&#36341;&#20013;&#24471;&#21040;&#28385;&#36275;&#12290;&#26412;&#25991;&#38024;&#23545;&#36825;&#31867;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20004;&#23618;&#38646;&#38454;&#20248;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#37325;&#26032;&#21442;&#25968;&#21270;&#23454;&#29616;&#24335;&#39044;&#27979;&#30446;&#26631;&#65292;&#20174;&#32780;&#23558;&#38750;&#20984;&#30340;&#30446;&#26631;&#36716;&#21270;&#20026;&#20984;&#30340;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
Performative prediction, as introduced by Perdomo et al. (2020), is a framework for studying social prediction in which the data distribution itself changes in response to the deployment of a model. Existing work on optimizing accuracy in this setting hinges on two assumptions that are easily violated in practice: that the performative risk is convex over the deployed model, and that the mapping from the model to the data distribution is known to the model designer in advance. In this paper, we initiate the study of tractable performative prediction problems that do not require these assumptions. To tackle this more challenging setting, we develop a two-level zeroth-order optimization algorithm, where one level aims to compute the distribution map, and the other level reparameterizes the performative prediction objective as a function of the induced data distribution. Under mild conditions, this reparameterization allows us to transform the non-convex objective into a convex one and ac
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28040;&#24687;&#20256;&#36882;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#38543;&#26426;&#22270;&#27169;&#22411;&#19978;&#30340;&#25910;&#25947;&#24615;&#65292;&#23558;&#25910;&#25947;&#32467;&#35770;&#20174;&#21482;&#36866;&#29992;&#20110;&#24230;&#35268;&#33539;&#21270;&#24179;&#22343;&#32858;&#21512;&#20989;&#25968;&#25193;&#23637;&#21040;&#25152;&#26377;&#20256;&#32479;&#32858;&#21512;&#20989;&#25968;&#65292;&#24182;&#32771;&#34385;&#20102;&#32858;&#21512;&#20989;&#25968;&#37319;&#29992;&#36880;&#20010;&#22352;&#26631;&#26368;&#22823;&#20540;&#26102;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2304.11140</link><description>&lt;p&gt;
&#22522;&#20110;&#28040;&#24687;&#20256;&#36882;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#22823;&#35268;&#27169;&#38543;&#26426;&#22270;&#19978;&#30340;&#36890;&#29992;&#32858;&#21512;&#25910;&#25947;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Convergence of Message Passing Graph Neural Networks with Generic Aggregation On Large Random Graphs. (arXiv:2304.11140v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11140
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28040;&#24687;&#20256;&#36882;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#38543;&#26426;&#22270;&#27169;&#22411;&#19978;&#30340;&#25910;&#25947;&#24615;&#65292;&#23558;&#25910;&#25947;&#32467;&#35770;&#20174;&#21482;&#36866;&#29992;&#20110;&#24230;&#35268;&#33539;&#21270;&#24179;&#22343;&#32858;&#21512;&#20989;&#25968;&#25193;&#23637;&#21040;&#25152;&#26377;&#20256;&#32479;&#32858;&#21512;&#20989;&#25968;&#65292;&#24182;&#32771;&#34385;&#20102;&#32858;&#21512;&#20989;&#25968;&#37319;&#29992;&#36880;&#20010;&#22352;&#26631;&#26368;&#22823;&#20540;&#26102;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28040;&#24687;&#20256;&#36882;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#38543;&#26426;&#22270;&#27169;&#22411;&#19978;&#30340;&#25910;&#25947;&#24615;&#65292;&#24403;&#33410;&#28857;&#25968;&#37327;&#36235;&#36817;&#20110;&#26080;&#38480;&#26102;&#65292;&#35813;&#32593;&#32476;&#27169;&#22411;&#33021;&#25910;&#25947;&#20110;&#20854;&#36830;&#32493;&#27169;&#22411;&#12290;&#36804;&#20170;&#20026;&#27490;&#65292;&#35813;&#25910;&#25947;&#24615;&#32467;&#26524;&#21482;&#36866;&#29992;&#20110;&#32858;&#21512;&#20989;&#25968;&#37319;&#29992;&#24230;&#35268;&#33539;&#21270;&#24179;&#22343;&#20540;&#24418;&#24335;&#30340;&#32593;&#32476;&#32467;&#26500;&#12290;&#25105;&#20204;&#23558;&#27492;&#32467;&#26524;&#25193;&#23637;&#21040;&#21253;&#21547;&#25152;&#26377;&#20256;&#32479;&#28040;&#24687;&#20256;&#36882;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#22823;&#31867;&#32858;&#21512;&#20989;&#25968;&#19978;&#65292;&#20363;&#22914;&#22522;&#20110;&#27880;&#24847;&#21147;&#21644;&#26368;&#22823;&#21367;&#31215;&#30340;&#32593;&#32476;&#12290;&#22312;&#19968;&#23450;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#39640;&#27010;&#29575;&#30340;&#38750;&#28176;&#36827;&#19978;&#38480;&#26469;&#37327;&#21270;&#36825;&#31181;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#22522;&#20110;McDiarmid&#19981;&#31561;&#24335;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#25105;&#20204;&#29305;&#21035;&#22788;&#29702;&#20102;&#32858;&#21512;&#20989;&#25968;&#37319;&#29992;&#36880;&#20010;&#22352;&#26631;&#26368;&#22823;&#20540;&#30340;&#24773;&#20917;&#65292;&#22240;&#20026;&#23427;&#38656;&#35201;&#38750;&#24120;&#19981;&#21516;&#30340;&#35777;&#26126;&#25216;&#24039;&#65292;&#24182;&#20135;&#29983;&#20102;&#23450;&#24615;&#19981;&#21516;&#30340;&#25910;&#25947;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the convergence of message passing graph neural networks on random graph models to their continuous counterpart as the number of nodes tends to infinity. Until now, this convergence was only known for architectures with aggregation functions in the form of degree-normalized means. We extend such results to a very large class of aggregation functions, that encompasses all classically used message passing graph neural networks, such as attention-based mesage passing or max convolutional message passing on top of (degree-normalized) convolutional message passing. Under mild assumptions, we give non asymptotic bounds with high probability to quantify this convergence. Our main result is based on the McDiarmid inequality. Interestingly, we treat the case where the aggregation is a coordinate-wise maximum separately, at it necessitates a very different proof technique and yields a qualitatively different convergence rate.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28789;&#27963;&#36125;&#21494;&#26031;&#22238;&#24402;&#26641;&#27169;&#22411;flexBART&#65292;&#21487;&#20197;&#22312;&#21010;&#20998;&#20998;&#31867;&#27700;&#24179;&#30340;&#31163;&#25955;&#38598;&#26102;&#65292;&#23558;&#22810;&#20010;&#27700;&#24179;&#20998;&#37197;&#32473;&#20915;&#31574;&#26641;&#33410;&#28857;&#30340;&#20004;&#20010;&#20998;&#25903;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#23545;&#20998;&#31867;&#39044;&#27979;&#21464;&#37327;&#30340;&#28789;&#27963;&#24314;&#27169;&#65292;&#36328;&#32423;&#21035;&#30340;&#25968;&#25454;&#37096;&#20998;&#27719;&#24635;&#33021;&#21147;&#20063;&#24471;&#21040;&#20102;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2211.04459</link><description>&lt;p&gt;
flexBART:&#20855;&#26377;&#20998;&#31867;&#39044;&#27979;&#21464;&#37327;&#30340;&#28789;&#27963;&#36125;&#21494;&#26031;&#22238;&#24402;&#26641;
&lt;/p&gt;
&lt;p&gt;
flexBART: Flexible Bayesian regression trees with categorical predictors. (arXiv:2211.04459v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.04459
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28789;&#27963;&#36125;&#21494;&#26031;&#22238;&#24402;&#26641;&#27169;&#22411;flexBART&#65292;&#21487;&#20197;&#22312;&#21010;&#20998;&#20998;&#31867;&#27700;&#24179;&#30340;&#31163;&#25955;&#38598;&#26102;&#65292;&#23558;&#22810;&#20010;&#27700;&#24179;&#20998;&#37197;&#32473;&#20915;&#31574;&#26641;&#33410;&#28857;&#30340;&#20004;&#20010;&#20998;&#25903;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#23545;&#20998;&#31867;&#39044;&#27979;&#21464;&#37327;&#30340;&#28789;&#27963;&#24314;&#27169;&#65292;&#36328;&#32423;&#21035;&#30340;&#25968;&#25454;&#37096;&#20998;&#27719;&#24635;&#33021;&#21147;&#20063;&#24471;&#21040;&#20102;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#36125;&#21494;&#26031;&#21152;&#27861;&#22238;&#24402;&#26641;&#65288;BART&#65289;&#30340;&#23454;&#29616;&#26041;&#27861;&#37319;&#29992;&#29420;&#28909;&#32534;&#30721;&#23558;&#20998;&#31867;&#39044;&#27979;&#21464;&#37327;&#26367;&#25442;&#20026;&#22810;&#20010;&#20108;&#36827;&#21046;&#25351;&#26631;&#65292;&#27599;&#20010;&#25351;&#26631;&#23545;&#24212;&#20110;&#27599;&#20010;&#32423;&#21035;&#25110;&#31867;&#21035;&#12290;&#29992;&#36825;&#20123;&#25351;&#26631;&#26500;&#24314;&#30340;&#22238;&#24402;&#26641;&#36890;&#36807;&#21453;&#22797;&#21024;&#38500;&#19968;&#20010;&#32423;&#21035;&#26469;&#21010;&#20998;&#20998;&#31867;&#27700;&#24179;&#30340;&#31163;&#25955;&#38598;&#12290;&#28982;&#32780;&#65292;&#32477;&#22823;&#22810;&#25968;&#20998;&#21106;&#19981;&#33021;&#20351;&#29992;&#27492;&#31574;&#30053;&#26500;&#24314;&#65292;&#20005;&#37325;&#38480;&#21046;&#20102;BART&#22312;&#36328;&#32423;&#21035;&#30340;&#25968;&#25454;&#37096;&#20998;&#27719;&#24635;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;&#21463;&#23545;&#26834;&#29699;&#25968;&#25454;&#21644;&#37051;&#37324;&#29359;&#32618;&#21160;&#24577;&#20998;&#26512;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#36890;&#36807;&#37325;&#26032;&#23454;&#29616;&#20197;&#33021;&#22815;&#23558;&#22810;&#20010;&#27700;&#24179;&#20998;&#37197;&#32473;&#20915;&#31574;&#26641;&#33410;&#28857;&#30340;&#20004;&#20010;&#20998;&#25903;&#30340;&#22238;&#24402;&#26641;&#26469;&#20811;&#26381;&#20102;&#36825;&#20010;&#38480;&#21046;&#12290;&#20026;&#20102;&#23545;&#32858;&#21512;&#20026;&#23567;&#21306;&#22495;&#30340;&#31354;&#38388;&#25968;&#25454;&#24314;&#27169;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20915;&#31574;&#35268;&#21017;&#20808;&#39564;&#65292;&#36890;&#36807;&#20174;&#36866;&#24403;&#23450;&#20041;&#30340;&#32593;&#32476;&#30340;&#38543;&#26426;&#29983;&#25104;&#26641;&#20013;&#21024;&#38500;&#19968;&#20010;&#38543;&#26426;&#36793;&#26469;&#21019;&#24314;&#31354;&#38388;&#36830;&#32493;&#30340;&#21306;&#22495;&#12290;&#25105;&#20204;&#30340;&#37325;&#26032;&#23454;&#29616;&#65292;&#21487;&#22312;R&#30340;flexBART&#36719;&#20214;&#21253;&#20013;&#20351;&#29992;&#65292;&#20801;&#35768;&#28789;&#27963;&#22320;&#24314;&#27169;&#20998;&#31867;&#39044;&#27979;&#21464;&#37327;&#24182;&#25913;&#36827;&#36328;&#19981;&#21516;&#32423;&#21035;&#30340;&#25968;&#25454;&#37096;&#20998;&#27719;&#24635;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most implementations of Bayesian additive regression trees (BART) one-hot encode categorical predictors, replacing each one with several binary indicators, one for every level or category. Regression trees built with these indicators partition the discrete set of categorical levels by repeatedly removing one level at a time. Unfortunately, the vast majority of partitions cannot be built with this strategy, severely limiting BART's ability to partially pool data across groups of levels. Motivated by analyses of baseball data and neighborhood-level crime dynamics, we overcame this limitation by re-implementing BART with regression trees that can assign multiple levels to both branches of a decision tree node. To model spatial data aggregated into small regions, we further proposed a new decision rule prior that creates spatially contiguous regions by deleting a random edge from a random spanning tree of a suitably defined network. Our re-implementation, which is available in the flexBART
&lt;/p&gt;</description></item></channel></rss>