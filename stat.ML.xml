<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24120;&#29992;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#36817;&#20284;&#36125;&#21494;&#26031;&#26368;&#20248;&#26041;&#27861;&#65292;&#21487;&#20197;&#24674;&#22797;&#30001;&#26410;&#30693;&#20219;&#21153;&#20998;&#24067;&#23450;&#20041;&#30340;&#36125;&#21494;&#26031;&#21518;&#39564;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.19381</link><description>&lt;p&gt;
&#20851;&#20110;&#36817;&#36125;&#21494;&#26031;&#26368;&#20248;&#31639;&#27861;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
On Uncertainty Quantification for Near-Bayes Optimal Algorithms
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19381
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24120;&#29992;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#36817;&#20284;&#36125;&#21494;&#26031;&#26368;&#20248;&#26041;&#27861;&#65292;&#21487;&#20197;&#24674;&#22797;&#30001;&#26410;&#30693;&#20219;&#21153;&#20998;&#24067;&#23450;&#20041;&#30340;&#36125;&#21494;&#26031;&#21518;&#39564;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#24314;&#27169;&#20801;&#35768;&#23545;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#37327;&#21270;&#65292;&#22312;&#23433;&#20840;&#20851;&#38190;&#24212;&#29992;&#20013;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#31639;&#27861;&#65292;&#26500;&#24314;&#25110;&#23454;&#29616;&#23427;&#20204;&#30340;&#36125;&#21494;&#26031;&#23545;&#24212;&#26159;&#22256;&#38590;&#30340;&#12290; &#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#30340;&#26377;&#21069;&#36884;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#24120;&#29992;&#30340;ML&#31639;&#27861;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#39640;&#25928;&#65292;&#24182;&#19988;&#21487;&#33021;&#22312;&#26410;&#30693;&#20219;&#21153;&#20998;&#24067;&#19979;&#25509;&#36817;&#36125;&#21494;&#26031;&#26368;&#20248;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36890;&#36807;&#20351;&#29992;&#35813;&#31639;&#27861;&#26500;&#24314;&#19968;&#20010;&#38789;&#21518;&#39564;&#65292;&#21487;&#20197;&#24674;&#22797;&#30001;&#20219;&#21153;&#20998;&#24067;&#23450;&#20041;&#30340;&#36125;&#21494;&#26031;&#21518;&#39564;&#65292;&#22312;&#36825;&#31181;&#35774;&#32622;&#20013;&#26159;&#26410;&#30693;&#20294;&#26368;&#20248;&#30340;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#36890;&#29992;ML&#31639;&#27861;&#30340;&#23454;&#29992;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#12290;&#22522;&#20110;&#21508;&#31181;&#38750;NN&#21644;NN&#31639;&#27861;&#30340;&#23454;&#39564;&#34920;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19381v1 Announce Type: cross  Abstract: Bayesian modelling allows for the quantification of predictive uncertainty which is crucial in safety-critical applications. Yet for many machine learning (ML) algorithms, it is difficult to construct or implement their Bayesian counterpart. In this work we present a promising approach to address this challenge, based on the hypothesis that commonly used ML algorithms are efficient across a wide variety of tasks and may thus be near Bayes-optimal w.r.t. an unknown task distribution. We prove that it is possible to recover the Bayesian posterior defined by the task distribution, which is unknown but optimal in this setting, by building a martingale posterior using the algorithm. We further propose a practical uncertainty quantification method that apply to general ML algorithms. Experiments based on a variety of non-NN and NN algorithms demonstrate the efficacy of our method.
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24322;&#24120;&#26816;&#27979;&#31639;&#27861;"Signature Isolation Forest"&#65292;&#21033;&#29992;&#31895;&#36335;&#24452;&#29702;&#35770;&#30340;&#31614;&#21517;&#21464;&#25442;&#21435;&#38500;&#20102;Functional Isolation Forest&#30340;&#32447;&#24615;&#20869;&#31215;&#21644;&#35789;&#20856;&#36873;&#25321;&#26041;&#38754;&#30340;&#38480;&#21046;&#12290;</title><link>https://arxiv.org/abs/2403.04405</link><description>&lt;p&gt;
Signature Isolation Forest
&lt;/p&gt;
&lt;p&gt;
Signature Isolation Forest
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04405
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24322;&#24120;&#26816;&#27979;&#31639;&#27861;"Signature Isolation Forest"&#65292;&#21033;&#29992;&#31895;&#36335;&#24452;&#29702;&#35770;&#30340;&#31614;&#21517;&#21464;&#25442;&#21435;&#38500;&#20102;Functional Isolation Forest&#30340;&#32447;&#24615;&#20869;&#31215;&#21644;&#35789;&#20856;&#36873;&#25321;&#26041;&#38754;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Functional Isolation Forest (FIF)&#26159;&#19968;&#31181;&#38024;&#23545;&#21151;&#33021;&#25968;&#25454;&#35774;&#35745;&#30340;&#26368;&#26032;&#19968;&#27969;&#24322;&#24120;&#26816;&#27979;(AD)&#31639;&#27861;&#12290;&#23427;&#20381;&#36182;&#20110;&#19968;&#31181;&#26641;&#20998;&#21306;&#36807;&#31243;&#65292;&#36890;&#36807;&#23558;&#27599;&#20010;&#26354;&#32447;&#35266;&#27979;&#25237;&#24433;&#21040;&#36890;&#36807;&#32447;&#24615;&#20869;&#31215;&#32472;&#21046;&#30340;&#35789;&#20856;&#19978;&#26469;&#35745;&#31639;&#24322;&#24120;&#24471;&#20998;&#12290;&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#8220;Signature Isolation Forest&#8221;&#65292;&#19968;&#31181;&#21033;&#29992;&#31895;&#36335;&#24452;&#29702;&#35770;&#31614;&#21517;&#21464;&#25442;&#30340;&#26032;&#39062;AD&#31639;&#27861;&#31867;&#65292;&#26469;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#36890;&#36807;&#25552;&#20986;&#20004;&#31181;&#31639;&#27861;&#26469;&#28040;&#38500;FIF&#26045;&#21152;&#30340;&#38480;&#21046;&#65292;&#36825;&#20004;&#31181;&#31639;&#27861;&#29305;&#21035;&#38024;&#23545;FIF&#20869;&#31215;&#30340;&#32447;&#24615;&#24615;&#21644;&#35789;&#20856;&#30340;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04405v1 Announce Type: cross  Abstract: Functional Isolation Forest (FIF) is a recent state-of-the-art Anomaly Detection (AD) algorithm designed for functional data. It relies on a tree partition procedure where an abnormality score is computed by projecting each curve observation on a drawn dictionary through a linear inner product. Such linear inner product and the dictionary are a priori choices that highly influence the algorithm's performances and might lead to unreliable results, particularly with complex datasets. This work addresses these challenges by introducing \textit{Signature Isolation Forest}, a novel AD algorithm class leveraging the rough path theory's signature transform. Our objective is to remove the constraints imposed by FIF through the proposition of two algorithms which specifically target the linearity of the FIF inner product and the choice of the dictionary. We provide several numerical experiments, including a real-world applications benchmark sho
&lt;/p&gt;</description></item><item><title>&#23398;&#20064;&#25972;&#20010;&#20998;&#24067;&#22312;&#22238;&#24402;&#20013;&#30340;&#24615;&#33021;&#25552;&#21319;&#20027;&#35201;&#26469;&#33258;&#20110;&#20248;&#21270;&#30340;&#25913;&#36827;&#65292;&#32780;&#19981;&#26159;&#23398;&#20064;&#26356;&#22909;&#30340;&#34920;&#31034;&#12290;</title><link>https://arxiv.org/abs/2402.13425</link><description>&lt;p&gt;
&#22312;&#22238;&#24402;&#20013;&#25506;&#35752;&#30452;&#26041;&#22270;&#25439;&#22833;
&lt;/p&gt;
&lt;p&gt;
Investigating the Histogram Loss in Regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13425
&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#25972;&#20010;&#20998;&#24067;&#22312;&#22238;&#24402;&#20013;&#30340;&#24615;&#33021;&#25552;&#21319;&#20027;&#35201;&#26469;&#33258;&#20110;&#20248;&#21270;&#30340;&#25913;&#36827;&#65292;&#32780;&#19981;&#26159;&#23398;&#20064;&#26356;&#22909;&#30340;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36234;&#26469;&#36234;&#24120;&#35265;&#30340;&#26159;&#65292;&#22312;&#22238;&#24402;&#20013;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#26469;&#24314;&#27169;&#25972;&#20010;&#20998;&#24067;&#65292;&#21363;&#20351;&#21482;&#38656;&#35201;&#22343;&#20540;&#26469;&#36827;&#34892;&#39044;&#27979;&#12290; &#36825;&#31181;&#39069;&#22806;&#30340;&#24314;&#27169;&#36890;&#24120;&#20250;&#24102;&#26469;&#24615;&#33021;&#22686;&#30410;&#65292;&#20294;&#32972;&#21518;&#30340;&#21407;&#22240;&#23578;&#19981;&#23436;&#20840;&#28165;&#26970;&#12290; &#26412;&#25991;&#30740;&#31350;&#20102;&#22238;&#24402;&#20013;&#30340;&#19968;&#31181;&#26368;&#26032;&#26041;&#27861;&#65292;&#21363;&#30452;&#26041;&#22270;&#25439;&#22833;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#26368;&#23567;&#21270;&#30446;&#26631;&#20998;&#24067;&#21644;&#28789;&#27963;&#30452;&#26041;&#22270;&#39044;&#27979;&#20043;&#38388;&#30340;&#20132;&#21449;&#29109;&#26469;&#23398;&#20064;&#30446;&#26631;&#21464;&#37327;&#30340;&#26465;&#20214;&#20998;&#24067;&#12290; &#25105;&#20204;&#35774;&#35745;&#20102;&#29702;&#35770;&#21644;&#23454;&#35777;&#20998;&#26512;&#65292;&#20197;&#30830;&#23450;&#20026;&#20160;&#20040;&#20197;&#21450;&#20309;&#26102;&#20250;&#20986;&#29616;&#24615;&#33021;&#22686;&#30410;&#65292;&#20197;&#21450;&#25439;&#22833;&#30340;&#19981;&#21516;&#32452;&#20214;&#22914;&#20309;&#20026;&#27492;&#20570;&#20986;&#36129;&#29486;&#12290; &#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#36825;&#31181;&#35774;&#32622;&#20013;&#23398;&#20064;&#20998;&#24067;&#30340;&#22909;&#22788;&#26469;&#33258;&#20110;&#20248;&#21270;&#30340;&#25913;&#36827;&#65292;&#32780;&#19981;&#26159;&#23398;&#20064;&#26356;&#22909;&#30340;&#34920;&#31034;&#12290; &#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#30452;&#26041;&#22270;&#25439;&#22833;&#22312;&#24120;&#35265;&#30340;&#28145;&#24230;&#23398;&#20064;&#24212;&#29992;&#20013;&#30340;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13425v1 Announce Type: cross  Abstract: It is becoming increasingly common in regression to train neural networks that model the entire distribution even if only the mean is required for prediction. This additional modeling often comes with performance gain and the reasons behind the improvement are not fully known. This paper investigates a recent approach to regression, the Histogram Loss, which involves learning the conditional distribution of the target variable by minimizing the cross-entropy between a target distribution and a flexible histogram prediction. We design theoretical and empirical analyses to determine why and when this performance gain appears, and how different components of the loss contribute to it. Our results suggest that the benefits of learning distributions in this setup come from improvements in optimization rather than learning a better representation. We then demonstrate the viability of the Histogram Loss in common deep learning applications wi
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#22312;&#24222;&#22823;&#30340;&#22269;&#38469;&#35937;&#26827;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#20351;&#29992;&#20102;&#19968;&#20010;270M&#21442;&#25968;&#30340;Transformer&#27169;&#22411;&#65292;&#19981;&#20381;&#36182;&#20110;&#22797;&#26434;&#30340;&#21551;&#21457;&#24335;&#31639;&#27861;&#25110;&#26174;&#24335;&#25628;&#32034;&#65292;&#21462;&#24471;&#20102;&#22823;&#24072;&#32423;&#27700;&#24179;&#30340;&#22269;&#38469;&#35937;&#26827;&#23545;&#23616;&#30340;&#25104;&#21151;&#12290;&#27169;&#22411;&#22312;Lichess&#38378;&#30005;&#25112;&#35780;&#20998;&#19978;&#36798;&#21040;&#20102;2895&#65292;&#35299;&#20915;&#20102;&#19968;&#31995;&#21015;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22269;&#38469;&#35937;&#26827;&#35868;&#39064;&#65292;&#20248;&#20110;AlphaZero&#21644;GPT-3.5-turbo-instruct&#12290;&#36890;&#36807;&#31995;&#32479;&#30740;&#31350;&#65292;&#25105;&#20204;&#21457;&#29616;&#22823;&#35268;&#27169;&#30340;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#23545;&#20110;&#23454;&#29616;&#24378;&#22823;&#30340;&#22269;&#38469;&#35937;&#26827;&#23545;&#23616;&#25928;&#26524;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;</title><link>https://arxiv.org/abs/2402.04494</link><description>&lt;p&gt;
&#19981;&#38656;&#25628;&#32034;&#21363;&#21487;&#23454;&#29616;&#22823;&#24072;&#32423;&#22269;&#38469;&#35937;&#26827;&#23545;&#23616;
&lt;/p&gt;
&lt;p&gt;
Grandmaster-Level Chess Without Search
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04494
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#22312;&#24222;&#22823;&#30340;&#22269;&#38469;&#35937;&#26827;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#20351;&#29992;&#20102;&#19968;&#20010;270M&#21442;&#25968;&#30340;Transformer&#27169;&#22411;&#65292;&#19981;&#20381;&#36182;&#20110;&#22797;&#26434;&#30340;&#21551;&#21457;&#24335;&#31639;&#27861;&#25110;&#26174;&#24335;&#25628;&#32034;&#65292;&#21462;&#24471;&#20102;&#22823;&#24072;&#32423;&#27700;&#24179;&#30340;&#22269;&#38469;&#35937;&#26827;&#23545;&#23616;&#30340;&#25104;&#21151;&#12290;&#27169;&#22411;&#22312;Lichess&#38378;&#30005;&#25112;&#35780;&#20998;&#19978;&#36798;&#21040;&#20102;2895&#65292;&#35299;&#20915;&#20102;&#19968;&#31995;&#21015;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22269;&#38469;&#35937;&#26827;&#35868;&#39064;&#65292;&#20248;&#20110;AlphaZero&#21644;GPT-3.5-turbo-instruct&#12290;&#36890;&#36807;&#31995;&#32479;&#30740;&#31350;&#65292;&#25105;&#20204;&#21457;&#29616;&#22823;&#35268;&#27169;&#30340;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#23545;&#20110;&#23454;&#29616;&#24378;&#22823;&#30340;&#22269;&#38469;&#35937;&#26827;&#23545;&#23616;&#25928;&#26524;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#26032;&#30340;&#26426;&#22120;&#23398;&#20064;&#30340;&#31361;&#30772;&#24615;&#25104;&#21151;&#20027;&#35201;&#24402;&#21151;&#20110;&#35268;&#27169;&#21270;&#65292;&#21363;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#22823;&#35268;&#27169;&#26550;&#26500;&#21644;&#31354;&#21069;&#35268;&#27169;&#30340;&#25968;&#25454;&#38598;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#23545;&#22269;&#38469;&#35937;&#26827;&#30340;&#22823;&#35268;&#27169;&#35757;&#32451;&#30340;&#24433;&#21709;&#12290;&#19982;&#20256;&#32479;&#30340;&#20381;&#36182;&#22797;&#26434;&#21551;&#21457;&#24335;&#31639;&#27861;&#12289;&#26174;&#24335;&#25628;&#32034;&#25110;&#20108;&#32773;&#32467;&#21512;&#30340;&#22269;&#38469;&#35937;&#26827;&#24341;&#25806;&#19981;&#21516;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;1000&#19975;&#23616;&#22269;&#38469;&#35937;&#26827;&#23545;&#23616;&#30340;&#25968;&#25454;&#38598;&#19978;&#20351;&#29992;&#30417;&#30563;&#23398;&#20064;&#35757;&#32451;&#20102;&#19968;&#20010;&#25317;&#26377;2.7&#20159;&#21442;&#25968;&#30340;Transformer&#27169;&#22411;&#12290;&#25105;&#20204;&#29992;&#24378;&#22823;&#30340;Stockfish 16&#24341;&#25806;&#25552;&#20379;&#30340;&#21160;&#20316;&#20540;&#26469;&#27880;&#37322;&#25968;&#25454;&#38598;&#20013;&#30340;&#27599;&#20010;&#26827;&#23616;&#65292;&#20135;&#29983;&#22823;&#32422;150&#20159;&#20010;&#25968;&#25454;&#28857;&#12290;&#25105;&#20204;&#26368;&#22823;&#30340;&#27169;&#22411;&#22312;Lichess&#38378;&#30005;&#25112;Elo&#19978;&#36798;&#21040;&#20102;2895&#65292;&#25104;&#21151;&#35299;&#20915;&#20102;&#19968;&#31995;&#21015;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22269;&#38469;&#35937;&#26827;&#35868;&#39064;&#65292;&#32780;&#26080;&#38656;&#20219;&#20309;&#29305;&#23450;&#39046;&#22495;&#30340;&#35843;&#25972;&#25110;&#26174;&#24335;&#25628;&#32034;&#31639;&#27861;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#20248;&#20110;AlphaZero&#30340;&#31574;&#30053;&#21644;&#20215;&#20540;&#32593;&#32476;&#65288;&#26080;MCTS&#65289;&#20197;&#21450;GPT-3.5-turbo-instruct&#12290;&#23545;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#35268;&#27169;&#30340;&#31995;&#32479;&#30740;&#31350;&#34920;&#26126;&#65292;&#24378;&#22823;&#30340;&#22269;&#38469;&#35937;&#26827;&#23545;&#23616;&#21487;&#20197;&#22312;&#35268;&#27169;&#19978;&#21462;&#24471;&#26368;&#20339;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
The recent breakthrough successes in machine learning are mainly attributed to scale: namely large-scale attention-based architectures and datasets of unprecedented scale. This paper investigates the impact of training at scale for chess. Unlike traditional chess engines that rely on complex heuristics, explicit search, or a combination of both, we train a 270M parameter transformer model with supervised learning on a dataset of 10 million chess games. We annotate each board in the dataset with action-values provided by the powerful Stockfish 16 engine, leading to roughly 15 billion data points. Our largest model reaches a Lichess blitz Elo of 2895 against humans, and successfully solves a series of challenging chess puzzles, without any domain-specific tweaks or explicit search algorithms. We also show that our model outperforms AlphaZero's policy and value networks (without MCTS) and GPT-3.5-turbo-instruct. A systematic investigation of model and dataset size shows that strong chess 
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#30740;&#31350;&#20102;&#26080;&#21442;&#38543;&#26426;&#20248;&#21270;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#23436;&#20840;&#26080;&#21442;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#31616;&#21333;&#30340;&#36229;&#21442;&#25968;&#25628;&#32034;&#25216;&#26415;&#22312;&#38750;&#20984;&#21644;&#20984;&#35774;&#32622;&#19979;&#37117;&#33021;&#21462;&#24471;&#20248;&#20110;&#20808;&#36827;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;&#21516;&#26102;&#65292;&#35770;&#25991;&#36824;&#24314;&#31435;&#20102;&#19968;&#20010;&#19979;&#30028;&#65292;&#25351;&#20986;&#23436;&#20840;&#26080;&#21442;&#30340;&#26041;&#27861;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#26080;&#27861;&#23454;&#29616;&#12290;</title><link>https://arxiv.org/abs/2402.03126</link><description>&lt;p&gt;
&#26080;&#21442;&#38543;&#26426;&#20248;&#21270;&#30340;&#33258;&#30001;&#24230;&#26377;&#22810;&#39640;&#65311;
&lt;/p&gt;
&lt;p&gt;
How Free is Parameter-Free Stochastic Optimization?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03126
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#30740;&#31350;&#20102;&#26080;&#21442;&#38543;&#26426;&#20248;&#21270;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#23436;&#20840;&#26080;&#21442;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#31616;&#21333;&#30340;&#36229;&#21442;&#25968;&#25628;&#32034;&#25216;&#26415;&#22312;&#38750;&#20984;&#21644;&#20984;&#35774;&#32622;&#19979;&#37117;&#33021;&#21462;&#24471;&#20248;&#20110;&#20808;&#36827;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;&#21516;&#26102;&#65292;&#35770;&#25991;&#36824;&#24314;&#31435;&#20102;&#19968;&#20010;&#19979;&#30028;&#65292;&#25351;&#20986;&#23436;&#20840;&#26080;&#21442;&#30340;&#26041;&#27861;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#26080;&#27861;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#26080;&#21442;&#38543;&#26426;&#20248;&#21270;&#30340;&#38382;&#39064;&#65292;&#25506;&#35752;&#20102;&#22312;&#20160;&#20040;&#26465;&#20214;&#19979;&#21487;&#20197;&#23384;&#22312;&#23436;&#20840;&#26080;&#21442;&#30340;&#26041;&#27861;&#65306;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#36798;&#21040;&#19982;&#26368;&#20248;&#35843;&#21442;&#26041;&#27861;&#30456;&#31454;&#20105;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#32780;&#19981;&#38656;&#35201;&#23545;&#30495;&#23454;&#38382;&#39064;&#21442;&#25968;&#26377;&#24456;&#22810;&#30693;&#35782;&#12290;&#29616;&#26377;&#30340;&#26080;&#21442;&#26041;&#27861;&#21482;&#33021;&#34987;&#35270;&#20026;&#8220;&#37096;&#20998;&#8221;&#26080;&#21442;&#65292;&#22240;&#20026;&#23427;&#20204;&#38656;&#35201;&#23545;&#30495;&#23454;&#38382;&#39064;&#21442;&#25968;&#26377;&#19968;&#20123;&#38750;&#24179;&#20961;&#30340;&#30693;&#35782;&#65292;&#27604;&#22914;&#38543;&#26426;&#26799;&#24230;&#33539;&#25968;&#30340;&#19978;&#30028;&#12289;&#21040;&#26368;&#23567;&#20540;&#30340;&#36317;&#31163;&#30340;&#19978;&#30028;&#31561;&#12290;&#22312;&#38750;&#20984;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#36229;&#21442;&#25968;&#25628;&#32034;&#25216;&#26415;&#21487;&#20197;&#24471;&#21040;&#19968;&#20010;&#23436;&#20840;&#26080;&#21442;&#30340;&#26041;&#27861;&#65292;&#22312;&#24615;&#33021;&#19978;&#36229;&#36807;&#20102;&#26356;&#22797;&#26434;&#30340;&#20808;&#36827;&#31639;&#27861;&#12290;&#22312;&#20855;&#26377;&#22122;&#22768;&#20989;&#25968;&#20540;&#30340;&#20984;&#35774;&#32622;&#19979;&#65292;&#22312;&#36739;&#23567;&#30340;&#22122;&#22768;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#20063;&#25552;&#20379;&#20102;&#31867;&#20284;&#30340;&#32467;&#26524;&#12290;&#26368;&#21518;&#65292;&#20551;&#35774;&#21482;&#33021;&#35775;&#38382;&#38543;&#26426;&#26799;&#24230;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#19979;&#30028;&#65292;&#20351;&#24471;&#23436;&#20840;&#26080;&#21442;&#30340;&#26041;&#27861;&#26080;&#27861;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of parameter-free stochastic optimization, inquiring whether, and under what conditions, do fully parameter-free methods exist: these are methods that achieve convergence rates competitive with optimally tuned methods, without requiring significant knowledge of the true problem parameters. Existing parameter-free methods can only be considered ``partially'' parameter-free, as they require some non-trivial knowledge of the true problem parameters, such as a bound on the stochastic gradient norms, a bound on the distance to a minimizer, etc. In the non-convex setting, we demonstrate that a simple hyperparameter search technique results in a fully parameter-free method that outperforms more sophisticated state-of-the-art algorithms. We also provide a similar result in the convex setting with access to noisy function values under mild noise assumptions. Finally, assuming only access to stochastic gradients, we establish a lower bound that renders fully parameter-free s
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#26680;PCA&#36827;&#34892;&#22806;&#20998;&#24067;&#26816;&#27979;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#20027;&#25104;&#20998;&#23376;&#31354;&#38388;&#20013;&#24341;&#20837;&#38750;&#32447;&#24615;&#26144;&#23556;&#65292;&#23454;&#29616;&#20102;&#23545;&#20869;&#20998;&#24067;&#21644;&#22806;&#20998;&#24067;&#25968;&#25454;&#30340;&#26377;&#25928;&#21306;&#20998;&#12290;</title><link>https://arxiv.org/abs/2402.02949</link><description>&lt;p&gt;
&#22806;&#20998;&#24067;&#26816;&#27979;&#30340;&#26680;PCA
&lt;/p&gt;
&lt;p&gt;
Kernel PCA for Out-of-Distribution Detection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02949
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#26680;PCA&#36827;&#34892;&#22806;&#20998;&#24067;&#26816;&#27979;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#20027;&#25104;&#20998;&#23376;&#31354;&#38388;&#20013;&#24341;&#20837;&#38750;&#32447;&#24615;&#26144;&#23556;&#65292;&#23454;&#29616;&#20102;&#23545;&#20869;&#20998;&#24067;&#21644;&#22806;&#20998;&#24067;&#25968;&#25454;&#30340;&#26377;&#25928;&#21306;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22806;&#20998;&#24067;&#65288;OoD&#65289;&#26816;&#27979;&#23545;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#30340;&#21487;&#38752;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#29616;&#26377;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#30452;&#25509;&#24212;&#29992;&#20110;DNN&#29305;&#24449;&#30340;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#22312;&#26816;&#27979;&#26469;&#33258;&#20869;&#20998;&#24067;&#65288;InD&#65289;&#25968;&#25454;&#30340;OoD&#25968;&#25454;&#26041;&#38754;&#19981;&#36275;&#22815;&#12290;PCA&#30340;&#22833;&#36133;&#34920;&#26126;&#65292;&#20165;&#36890;&#36807;&#22312;&#32447;&#24615;&#23376;&#31354;&#38388;&#20013;&#36827;&#34892;&#31616;&#21333;&#22788;&#29702;&#26080;&#27861;&#24456;&#22909;&#22320;&#23558;OoD&#21644;InD&#20013;&#30340;&#32593;&#32476;&#29305;&#24449;&#20998;&#31163;&#24320;&#26469;&#65292;&#32780;&#21487;&#20197;&#36890;&#36807;&#36866;&#24403;&#30340;&#38750;&#32447;&#24615;&#26144;&#23556;&#26469;&#35299;&#20915;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#26680;PCA&#65288;KPCA&#65289;&#26694;&#26550;&#36827;&#34892;OoD&#26816;&#27979;&#65292;&#23547;&#25214;OoD&#21644;InD&#29305;&#24449;&#20197;&#26174;&#33879;&#19981;&#21516;&#30340;&#27169;&#24335;&#20998;&#37197;&#30340;&#23376;&#31354;&#38388;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#20004;&#31181;&#29305;&#24449;&#26144;&#23556;&#65292;&#22312;KPCA&#20013;&#24341;&#20837;&#38750;&#32447;&#24615;&#20869;&#26680;&#65292;&#20197;&#20419;&#36827;&#22312;&#20027;&#25104;&#20998;&#24352;&#25104;&#30340;&#23376;&#31354;&#38388;&#20013;InD&#21644;OoD&#25968;&#25454;&#20043;&#38388;&#30340;&#21487;&#20998;&#24615;&#12290;&#28982;&#21518;&#65292;&#36890;&#36807;&#22312;&#36825;&#31181;&#23376;&#31354;&#38388;&#20013;&#30340;&#37325;&#26500;&#35823;&#24046;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#24471;&#21040;$\mathcal{O}(1)$&#26102;&#38388;&#22797;&#26434;&#24230;&#30340;&#26816;&#27979;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Out-of-Distribution (OoD) detection is vital for the reliability of Deep Neural Networks (DNNs). Existing works have shown the insufficiency of Principal Component Analysis (PCA) straightforwardly applied on the features of DNNs in detecting OoD data from In-Distribution (InD) data. The failure of PCA suggests that the network features residing in OoD and InD are not well separated by simply proceeding in a linear subspace, which instead can be resolved through proper nonlinear mappings. In this work, we leverage the framework of Kernel PCA (KPCA) for OoD detection, seeking subspaces where OoD and InD features are allocated with significantly different patterns. We devise two feature mappings that induce non-linear kernels in KPCA to advocate the separability between InD and OoD data in the subspace spanned by the principal components. Given any test sample, the reconstruction error in such subspace is then used to efficiently obtain the detection result with $\mathcal{O}(1)$ time comp
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31283;&#23450;&#30340;&#26684;&#23376;&#38598;&#25104;&#25299;&#25169;&#25551;&#36848;&#31526;&#26694;&#26550;&#65292;&#23558;&#25345;&#20037;&#22270;&#36716;&#21270;&#20026;&#26377;&#38480;&#32500;&#21521;&#37327;&#31354;&#38388;&#30340;&#20803;&#32032;&#65292;&#36890;&#36807;&#22522;&#20110;&#31163;&#25955;&#27979;&#24230;&#30340;&#21151;&#33021;&#65292;&#35777;&#26126;&#20102;&#37096;&#20998;&#25104;&#21592;&#22312;&#24230;&#37327;&#19978;&#30340;&#31283;&#23450;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#31454;&#20105;&#29978;&#33267;&#36229;&#36234;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2312.17093</link><description>&lt;p&gt;
LITE&#65306;&#31283;&#23450;&#30340;&#26684;&#23376;&#38598;&#25104;&#25299;&#25169;&#25551;&#36848;&#31526;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
LITE: A Stable Framework for Lattice-Integrated Embedding of Topological Descriptors. (arXiv:2312.17093v2 [math.AT] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.17093
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31283;&#23450;&#30340;&#26684;&#23376;&#38598;&#25104;&#25299;&#25169;&#25551;&#36848;&#31526;&#26694;&#26550;&#65292;&#23558;&#25345;&#20037;&#22270;&#36716;&#21270;&#20026;&#26377;&#38480;&#32500;&#21521;&#37327;&#31354;&#38388;&#30340;&#20803;&#32032;&#65292;&#36890;&#36807;&#22522;&#20110;&#31163;&#25955;&#27979;&#24230;&#30340;&#21151;&#33021;&#65292;&#35777;&#26126;&#20102;&#37096;&#20998;&#25104;&#21592;&#22312;&#24230;&#37327;&#19978;&#30340;&#31283;&#23450;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#31454;&#20105;&#29978;&#33267;&#36229;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#25345;&#20037;&#22270;&#25551;&#36848;&#31526;&#23478;&#26063;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#36825;&#20123;&#22270;&#36716;&#21270;&#20026;&#26377;&#38480;&#32500;&#21521;&#37327;&#31354;&#38388;&#20013;&#30340;&#20803;&#32032;&#65292;&#20351;&#29992;&#22522;&#20110;&#23427;&#20204;&#25152;&#24341;&#36215;&#30340;&#31163;&#25955;&#27979;&#24230;&#30340;&#27867;&#20989;&#12290;&#34429;&#28982;&#25105;&#20204;&#30340;&#28966;&#28857;&#20027;&#35201;&#26159;&#22312;&#22522;&#20110;&#36523;&#20221;&#21644;&#39057;&#29575;&#30340;&#36716;&#25442;&#19978;&#65292;&#20294;&#25105;&#20204;&#24182;&#19981;&#23616;&#38480;&#20110;&#36825;&#20123;&#31867;&#22411;&#30340;&#25216;&#26415;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#36716;&#25442;&#23478;&#26063;&#31216;&#20026;LITE &#65288;Lattice Integrated Topological Embedding&#65289;&#65292;&#24182;&#19988;&#23545;&#35813;&#23478;&#26063;&#30340;&#19968;&#20123;&#25104;&#21592;&#22312;1-&#24247;&#25176;&#27931;&#32500;&#22855;-&#40065;&#23486;&#26031;&#22374;&#24230;&#37327;&#19979;&#35777;&#26126;&#20102;&#31283;&#23450;&#24615;&#65292;&#30830;&#20445;&#23545;&#32454;&#24494;&#30340;&#25968;&#25454;&#21464;&#21270;&#20855;&#26377;&#21453;&#24212;&#24615;&#12290;&#24191;&#27867;&#30340;&#23545;&#27604;&#20998;&#26512;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#25551;&#36848;&#31526;&#22312;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#25991;&#29486;&#20013;&#19982;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#30456;&#31454;&#20105;&#65292;&#24182;&#19988;&#32463;&#24120;&#36229;&#36234;&#29616;&#26377;&#30340;&#26041;&#27861;&#12290;&#36825;&#39033;&#30740;&#31350;&#19981;&#20165;&#20026;&#25968;&#25454;&#31185;&#23398;&#23478;&#24341;&#20837;&#20102;&#21019;&#26032;&#30340;&#35266;&#28857;&#65292;&#32780;&#19988;&#25209;&#35780;&#20102;&#30446;&#21069;&#20851;&#20110;&#21521;&#37327;&#21270;&#26041;&#27861;&#23398;&#30340;&#25991;&#29486;&#30340;&#36712;&#36857;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce a new family of descriptors for persistence diagrams. Our approach transforms these diagrams into elements of a finite-dimensional vector space using functionals based on the discrete measures they induce. While our focus is primarily on identity and frequency-based transformations, we do not restrict our approach exclusively to this types of techniques. We term this family of transformations as LITE (Lattice Integrated Topological Embedding) and prove stability for some members of this family against the 1-$Kantorovitch$-$Rubinstein$ metric, ensuring its responsiveness to subtle data variations. Extensive comparative analysis reveals that our descriptor performs competitively with the current state-of-art from the topological data analysis literature, and often surpasses, the existing methods. This research not only introduces an innovative perspective for data scientists but also critiques the current trajectory of literature on methodologies for vectorizi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23558;&#21464;&#20998;&#25512;&#26029;&#37325;&#26032;&#26694;&#26550;&#20026;&#22312;&#21464;&#20998;&#21442;&#25968;&#31354;&#38388;&#19978;&#30340;&#27010;&#29575;&#20998;&#24067;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#27779;&#29791;&#26031;&#22374;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#26469;&#35299;&#20915;&#20248;&#21270;&#38382;&#39064;&#65292;&#26377;&#25928;&#24615;&#32463;&#36807;&#23454;&#35777;&#23454;&#39564;&#35777;&#23454;&#12290;</title><link>http://arxiv.org/abs/2310.16705</link><description>&lt;p&gt;
&#27779;&#29791;&#26031;&#22374;&#26799;&#24230;&#27969;&#22312;&#21464;&#20998;&#25512;&#26029;&#30340;&#21464;&#20998;&#21442;&#25968;&#31354;&#38388;&#19978;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Wasserstein Gradient Flow over Variational Parameter Space for Variational Inference. (arXiv:2310.16705v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16705
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#21464;&#20998;&#25512;&#26029;&#37325;&#26032;&#26694;&#26550;&#20026;&#22312;&#21464;&#20998;&#21442;&#25968;&#31354;&#38388;&#19978;&#30340;&#27010;&#29575;&#20998;&#24067;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#27779;&#29791;&#26031;&#22374;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#26469;&#35299;&#20915;&#20248;&#21270;&#38382;&#39064;&#65292;&#26377;&#25928;&#24615;&#32463;&#36807;&#23454;&#35777;&#23454;&#39564;&#35777;&#23454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#25512;&#26029;&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;&#19968;&#20010;&#20248;&#21270;&#38382;&#39064;&#65292;&#20854;&#20013;&#21464;&#20998;&#21442;&#25968;&#34987;&#35843;&#25972;&#20197;&#20351;&#21464;&#20998;&#20998;&#24067;&#19982;&#30495;&#23454;&#21518;&#39564;&#23613;&#21487;&#33021;&#25509;&#36817;&#12290;&#21487;&#20197;&#36890;&#36807;&#40657;&#31665;&#21464;&#20998;&#25512;&#26029;&#20013;&#30340;&#26222;&#36890;&#26799;&#24230;&#19979;&#38477;&#25110;&#33258;&#28982;&#26799;&#24230;&#21464;&#20998;&#25512;&#26029;&#20013;&#30340;&#33258;&#28982;&#26799;&#24230;&#19979;&#38477;&#26469;&#35299;&#20915;&#20248;&#21270;&#20219;&#21153;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#21464;&#20998;&#25512;&#26029;&#37325;&#26032;&#26694;&#26550;&#20026;&#22312;&#19968;&#20010;&#8220;&#21464;&#20998;&#21442;&#25968;&#31354;&#38388;&#8221;&#20013;&#23450;&#20041;&#30340;&#27010;&#29575;&#20998;&#24067;&#30340;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#27779;&#29791;&#26031;&#22374;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#20248;&#21270;&#38382;&#39064;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#36825;&#20123;&#20248;&#21270;&#25216;&#26415;&#65292;&#21363;&#40657;&#31665;&#21464;&#20998;&#25512;&#26029;&#21644;&#33258;&#28982;&#26799;&#24230;&#21464;&#20998;&#25512;&#26029;&#65292;&#21487;&#20197;&#37325;&#26032;&#35299;&#37322;&#20026;&#25152;&#25552;&#20986;&#30340;&#27779;&#29791;&#26031;&#22374;&#26799;&#24230;&#19979;&#38477;&#30340;&#29305;&#23450;&#23454;&#20363;&#12290;&#20026;&#20102;&#25552;&#39640;&#20248;&#21270;&#25928;&#29575;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#23454;&#29992;&#30340;&#26041;&#27861;&#26469;&#25968;&#20540;&#27714;&#35299;&#31163;&#25955;&#26799;&#24230;&#27969;&#12290;&#36890;&#36807;&#22312;&#19968;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#35777;&#23454;&#39564;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational inference (VI) can be cast as an optimization problem in which the variational parameters are tuned to closely align a variational distribution with the true posterior. The optimization task can be approached through vanilla gradient descent in black-box VI or natural-gradient descent in natural-gradient VI. In this work, we reframe VI as the optimization of an objective that concerns probability distributions defined over a \textit{variational parameter space}. Subsequently, we propose Wasserstein gradient descent for tackling this optimization problem. Notably, the optimization techniques, namely black-box VI and natural-gradient VI, can be reinterpreted as specific instances of the proposed Wasserstein gradient descent. To enhance the efficiency of optimization, we develop practical methods for numerically solving the discrete gradient flows. We validate the effectiveness of the proposed methods through empirical experiments on a synthetic dataset, supplemented by theore
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#20998;&#26512;&#27491;&#20132;&#38543;&#26426;&#29305;&#24449;&#30340;&#26680;&#36817;&#20284;&#30340;&#20559;&#24046;&#21644;&#26041;&#24046;&#65292;&#25552;&#20379;&#20102;&#26126;&#30830;&#30340;&#34920;&#36798;&#24335;&#65292;&#24182;&#24471;&#20986;&#20102;&#23574;&#38160;&#25351;&#25968;&#30028;&#38480;&#65292;&#25903;&#25345;&#27491;&#20132;&#38543;&#26426;&#29305;&#24449;&#27604;&#38543;&#26426;&#20613;&#37324;&#21494;&#29305;&#24449;&#26356;&#20855;&#20449;&#24687;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.07370</link><description>&lt;p&gt;
&#27491;&#20132;&#38543;&#26426;&#29305;&#24449;: &#26126;&#30830;&#24418;&#24335;&#21644;&#23574;&#38160;&#19981;&#31561;&#24335;
&lt;/p&gt;
&lt;p&gt;
Orthogonal Random Features: Explicit Forms and Sharp Inequalities. (arXiv:2310.07370v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07370
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#20998;&#26512;&#27491;&#20132;&#38543;&#26426;&#29305;&#24449;&#30340;&#26680;&#36817;&#20284;&#30340;&#20559;&#24046;&#21644;&#26041;&#24046;&#65292;&#25552;&#20379;&#20102;&#26126;&#30830;&#30340;&#34920;&#36798;&#24335;&#65292;&#24182;&#24471;&#20986;&#20102;&#23574;&#38160;&#25351;&#25968;&#30028;&#38480;&#65292;&#25903;&#25345;&#27491;&#20132;&#38543;&#26426;&#29305;&#24449;&#27604;&#38543;&#26426;&#20613;&#37324;&#21494;&#29305;&#24449;&#26356;&#20855;&#20449;&#24687;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#29305;&#24449;&#36890;&#36807;&#38543;&#26426;&#21270;&#25216;&#26415;&#34987;&#24341;&#20837;&#20197;&#25193;&#23637;&#26680;&#26041;&#27861;&#12290;&#29305;&#21035;&#22320;&#65292;&#38543;&#26426;&#20613;&#37324;&#21494;&#29305;&#24449;&#21644;&#27491;&#20132;&#38543;&#26426;&#29305;&#24449;&#34987;&#29992;&#26469;&#36817;&#20284;&#27969;&#34892;&#30340;&#39640;&#26031;&#26680;&#12290;&#21069;&#32773;&#36890;&#36807;&#38543;&#26426;&#39640;&#26031;&#30697;&#38453;&#25191;&#34892;&#65292;&#24182;&#22312;&#24179;&#22343;&#21518;&#24471;&#21040;&#20102;&#23436;&#20840;&#31526;&#21512;&#39640;&#26031;&#26680;&#30340;&#32467;&#26524;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#22522;&#20110;&#29992;&#21040;Haar&#27491;&#20132;&#30697;&#38453;&#30340;&#27491;&#20132;&#38543;&#26426;&#29305;&#24449;&#30340;&#26680;&#36817;&#20284;&#30340;&#20559;&#24046;&#21644;&#26041;&#24046;&#12290;&#25105;&#20204;&#20351;&#29992;&#24402;&#19968;&#21270;&#36125;&#22622;&#23572;&#20989;&#25968;&#25552;&#20379;&#20102;&#36825;&#20123;&#37327;&#30340;&#26126;&#30830;&#34920;&#36798;&#24335;&#65292;&#24182;&#25512;&#23548;&#20102;&#25903;&#25345;&#27491;&#20132;&#38543;&#26426;&#29305;&#24449;&#27604;&#38543;&#26426;&#20613;&#37324;&#21494;&#29305;&#24449;&#26356;&#20855;&#20449;&#24687;&#24615;&#30340;&#23574;&#38160;&#25351;&#25968;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
Random features have been introduced to scale up kernel methods via randomization techniques. In particular, random Fourier features and orthogonal random features were used to approximate the popular Gaussian kernel. The former is performed by a random Gaussian matrix and leads exactly to the Gaussian kernel after averaging. In this work, we analyze the bias and the variance of the kernel approximation based on orthogonal random features which makes use of Haar orthogonal matrices. We provide explicit expressions for these quantities using normalized Bessel functions and derive sharp exponential bounds supporting the view that orthogonal random features are more informative than random Fourier features.
&lt;/p&gt;</description></item><item><title>TemperatureGAN&#26159;&#19968;&#20010;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65292;&#20351;&#29992;&#22320;&#38754;&#20197;&#19978;2m&#30340;&#22823;&#27668;&#28201;&#24230;&#25968;&#25454;&#65292;&#33021;&#22815;&#29983;&#25104;&#20855;&#26377;&#33391;&#22909;&#31354;&#38388;&#34920;&#31034;&#21644;&#19982;&#26172;&#22812;&#21608;&#26399;&#19968;&#33268;&#30340;&#26102;&#38388;&#21160;&#24577;&#30340;&#39640;&#20445;&#30495;&#26679;&#26412;&#12290;</title><link>http://arxiv.org/abs/2306.17248</link><description>&lt;p&gt;
TemperatureGAN: &#21306;&#22495;&#22823;&#27668;&#28201;&#24230;&#30340;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
TemperatureGAN: Generative Modeling of Regional Atmospheric Temperatures. (arXiv:2306.17248v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17248
&lt;/p&gt;
&lt;p&gt;
TemperatureGAN&#26159;&#19968;&#20010;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65292;&#20351;&#29992;&#22320;&#38754;&#20197;&#19978;2m&#30340;&#22823;&#27668;&#28201;&#24230;&#25968;&#25454;&#65292;&#33021;&#22815;&#29983;&#25104;&#20855;&#26377;&#33391;&#22909;&#31354;&#38388;&#34920;&#31034;&#21644;&#19982;&#26172;&#22812;&#21608;&#26399;&#19968;&#33268;&#30340;&#26102;&#38388;&#21160;&#24577;&#30340;&#39640;&#20445;&#30495;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#29983;&#25104;&#22120;&#23545;&#20110;&#20272;&#35745;&#27668;&#20505;&#23545;&#21508;&#20010;&#39046;&#22495;&#30340;&#24433;&#21709;&#38750;&#24120;&#26377;&#29992;&#12290;&#22312;&#21508;&#20010;&#39046;&#22495;&#20013;&#36827;&#34892;&#27668;&#20505;&#39118;&#38505;&#30340;&#39044;&#27979;&#65292;&#20363;&#22914;&#33021;&#28304;&#31995;&#32479;&#65292;&#38656;&#35201;&#20934;&#30830;&#65288;&#19982;&#22522;&#20934;&#30495;&#23454;&#25968;&#25454;&#26377;&#32479;&#35745;&#30456;&#20284;&#24615;&#65289;&#12289;&#21487;&#38752;&#65288;&#19981;&#20135;&#29983;&#38169;&#35823;&#26679;&#26412;&#65289;&#21644;&#39640;&#25928;&#30340;&#29983;&#25104;&#22120;&#12290;&#25105;&#20204;&#21033;&#29992;&#26469;&#33258;&#21271;&#32654;&#38470;&#22320;&#25968;&#25454;&#21516;&#21270;&#31995;&#32479;&#30340;&#25968;&#25454;&#65292;&#24341;&#20837;&#20102;TemperatureGAN&#65292;&#36825;&#26159;&#19968;&#20010;&#20197;&#26376;&#20221;&#12289;&#20301;&#32622;&#21644;&#26102;&#38388;&#27573;&#20026;&#26465;&#20214;&#30340;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65292;&#20197;&#27599;&#23567;&#26102;&#20998;&#36776;&#29575;&#29983;&#25104;&#22320;&#38754;&#20197;&#19978;2m&#30340;&#22823;&#27668;&#28201;&#24230;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#35780;&#20272;&#26041;&#27861;&#21644;&#25351;&#26631;&#26469;&#34913;&#37327;&#29983;&#25104;&#26679;&#26412;&#30340;&#36136;&#37327;&#12290;&#25105;&#20204;&#35777;&#26126;TemperatureGAN&#33021;&#22815;&#29983;&#25104;&#20855;&#26377;&#33391;&#22909;&#31354;&#38388;&#34920;&#31034;&#21644;&#19982;&#24050;&#30693;&#26172;&#22812;&#21608;&#26399;&#19968;&#33268;&#30340;&#26102;&#38388;&#21160;&#24577;&#30340;&#39640;&#20445;&#30495;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic generators are useful for estimating climate impacts on various sectors. Projecting climate risk in various sectors, e.g. energy systems, requires generators that are accurate (statistical resemblance to ground-truth), reliable (do not produce erroneous examples), and efficient. Leveraging data from the North American Land Data Assimilation System, we introduce TemperatureGAN, a Generative Adversarial Network conditioned on months, locations, and time periods, to generate 2m above ground atmospheric temperatures at an hourly resolution. We propose evaluation methods and metrics to measure the quality of generated samples. We show that TemperatureGAN produces high-fidelity examples with good spatial representation and temporal dynamics consistent with known diurnal cycles.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20445;&#25252;&#38544;&#31169;&#30340;&#26412;&#22320;&#20998;&#24067;&#22810;&#32593;&#32476;&#31038;&#21306;&#26816;&#27979;&#26041;&#27861;&#65292;&#21033;&#29992;&#38544;&#31169;&#20445;&#25252;&#26469;&#36827;&#34892;&#20849;&#35782;&#31038;&#21306;&#26816;&#27979;&#21644;&#20272;&#35745;&#12290;&#37319;&#29992;&#38543;&#26426;&#21709;&#24212;&#26426;&#21046;&#23545;&#32593;&#32476;&#36793;&#36827;&#34892;&#25200;&#21160;&#65292;&#36890;&#36807;&#38544;&#31169;&#20445;&#25252;&#20998;&#24067;&#24335;&#35889;&#32858;&#31867;&#31639;&#27861;&#22312;&#25200;&#21160;&#37051;&#25509;&#30697;&#38453;&#19978;&#25191;&#34892;&#65292;&#20197;&#38450;&#27490;&#31038;&#21306;&#20043;&#38388;&#30340;&#25269;&#28040;&#12290;&#21516;&#26102;&#65292;&#24320;&#21457;&#20102;&#20004;&#27493;&#20559;&#24046;&#35843;&#25972;&#36807;&#31243;&#26469;&#28040;&#38500;&#25200;&#21160;&#21644;&#32593;&#32476;&#30697;&#38453;&#24102;&#26469;&#30340;&#20559;&#24046;&#12290;</title><link>http://arxiv.org/abs/2306.15709</link><description>&lt;p&gt;
&#20445;&#25252;&#38544;&#31169;&#30340;&#26412;&#22320;&#20998;&#24067;&#22810;&#32593;&#32476;&#31038;&#21306;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Privacy-Preserving Community Detection for Locally Distributed Multiple Networks. (arXiv:2306.15709v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15709
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20445;&#25252;&#38544;&#31169;&#30340;&#26412;&#22320;&#20998;&#24067;&#22810;&#32593;&#32476;&#31038;&#21306;&#26816;&#27979;&#26041;&#27861;&#65292;&#21033;&#29992;&#38544;&#31169;&#20445;&#25252;&#26469;&#36827;&#34892;&#20849;&#35782;&#31038;&#21306;&#26816;&#27979;&#21644;&#20272;&#35745;&#12290;&#37319;&#29992;&#38543;&#26426;&#21709;&#24212;&#26426;&#21046;&#23545;&#32593;&#32476;&#36793;&#36827;&#34892;&#25200;&#21160;&#65292;&#36890;&#36807;&#38544;&#31169;&#20445;&#25252;&#20998;&#24067;&#24335;&#35889;&#32858;&#31867;&#31639;&#27861;&#22312;&#25200;&#21160;&#37051;&#25509;&#30697;&#38453;&#19978;&#25191;&#34892;&#65292;&#20197;&#38450;&#27490;&#31038;&#21306;&#20043;&#38388;&#30340;&#25269;&#28040;&#12290;&#21516;&#26102;&#65292;&#24320;&#21457;&#20102;&#20004;&#27493;&#20559;&#24046;&#35843;&#25972;&#36807;&#31243;&#26469;&#28040;&#38500;&#25200;&#21160;&#21644;&#32593;&#32476;&#30697;&#38453;&#24102;&#26469;&#30340;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#22810;&#23618;&#32593;&#32476;&#30001;&#20110;&#38544;&#31169;&#12289;&#25152;&#26377;&#26435;&#21644;&#36890;&#20449;&#25104;&#26412;&#30340;&#21407;&#22240;&#65292;&#24120;&#24120;&#20197;&#26412;&#22320;&#21644;&#20998;&#24067;&#24335;&#30340;&#26041;&#24335;&#23384;&#20648;&#21644;&#20998;&#26512;&#12290;&#20851;&#20110;&#22522;&#20110;&#36825;&#20123;&#25968;&#25454;&#30340;&#27169;&#22411;&#21270;&#32479;&#35745;&#26041;&#27861;&#29992;&#20110;&#31038;&#21306;&#26816;&#27979;&#30340;&#25991;&#29486;&#20173;&#28982;&#26377;&#38480;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22522;&#20110;&#26412;&#22320;&#23384;&#20648;&#21644;&#35745;&#31639;&#30340;&#32593;&#32476;&#25968;&#25454;&#30340;&#22810;&#23618;&#38543;&#26426;&#22359;&#27169;&#22411;&#20013;&#30340;&#20849;&#35782;&#31038;&#21306;&#26816;&#27979;&#21644;&#20272;&#35745;&#65292;&#24182;&#37319;&#29992;&#38544;&#31169;&#20445;&#25252;&#12290;&#24320;&#21457;&#20102;&#19968;&#31181;&#21517;&#20026;&#38544;&#31169;&#20445;&#25252;&#20998;&#24067;&#24335;&#35889;&#32858;&#31867;&#65288;ppDSC&#65289;&#30340;&#26032;&#31639;&#27861;&#12290;&#20026;&#20102;&#20445;&#25252;&#36793;&#30340;&#38544;&#31169;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#38543;&#26426;&#21709;&#24212;&#65288;RR&#65289;&#26426;&#21046;&#26469;&#25200;&#21160;&#32593;&#32476;&#36793;&#65292;&#35813;&#26426;&#21046;&#28385;&#36275;&#24046;&#20998;&#38544;&#31169;&#30340;&#24378;&#27010;&#24565;&#12290;ppDSC&#31639;&#27861;&#22312;&#24179;&#26041;&#30340;RR&#25200;&#21160;&#37051;&#25509;&#30697;&#38453;&#19978;&#25191;&#34892;&#65292;&#20197;&#38450;&#27490;&#19981;&#21516;&#23618;&#20043;&#38388;&#30340;&#31038;&#21306;&#30456;&#20114;&#25269;&#28040;&#12290;&#20026;&#20102;&#28040;&#38500;RR&#21644;&#24179;&#26041;&#32593;&#32476;&#30697;&#38453;&#25152;&#24102;&#26469;&#30340;&#20559;&#24046;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#20004;&#27493;&#20559;&#24046;&#35843;&#25972;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern multi-layer networks are commonly stored and analyzed in a local and distributed fashion because of the privacy, ownership, and communication costs. The literature on the model-based statistical methods for community detection based on these data is still limited. This paper proposes a new method for consensus community detection and estimation in a multi-layer stochastic block model using locally stored and computed network data with privacy protection. A novel algorithm named privacy-preserving Distributed Spectral Clustering (ppDSC) is developed. To preserve the edges' privacy, we adopt the randomized response (RR) mechanism to perturb the network edges, which satisfies the strong notion of differential privacy. The ppDSC algorithm is performed on the squared RR-perturbed adjacency matrices to prevent possible cancellation of communities among different layers. To remove the bias incurred by RR and the squared network matrices, we develop a two-step bias-adjustment procedure.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;PAC-Bayes&#35757;&#32451;&#26694;&#26550;&#65292;&#26080;&#38656;&#39069;&#22806;&#27491;&#21017;&#21270;&#21644;&#32593;&#26684;&#25628;&#32034;&#35843;&#25972;&#36229;&#21442;&#25968;&#21363;&#21487;&#36798;&#21040;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#23218;&#32654;&#30340;&#27979;&#35797;&#24615;&#33021;&#65292;&#26174;&#33879;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#27867;&#21270;&#33021;&#21147;&#24182;&#20855;&#26377;&#23454;&#38469;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2305.19243</link><description>&lt;p&gt;
Auto-tune: &#31070;&#32463;&#32593;&#32476;&#30340;&#20808;&#39564;&#19982;&#21518;&#39564;PAC-Bayes&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Auto-tune: PAC-Bayes Optimization over Prior and Posterior for Neural Networks. (arXiv:2305.19243v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19243
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;PAC-Bayes&#35757;&#32451;&#26694;&#26550;&#65292;&#26080;&#38656;&#39069;&#22806;&#27491;&#21017;&#21270;&#21644;&#32593;&#26684;&#25628;&#32034;&#35843;&#25972;&#36229;&#21442;&#25968;&#21363;&#21487;&#36798;&#21040;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#23218;&#32654;&#30340;&#27979;&#35797;&#24615;&#33021;&#65292;&#26174;&#33879;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#27867;&#21270;&#33021;&#21147;&#24182;&#20855;&#26377;&#23454;&#38469;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#31934;&#24515;&#35774;&#35745;&#35757;&#32451;&#36807;&#31243;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#30446;&#21069;&#26368;&#20808;&#36827;&#30340;&#35757;&#32451;&#26041;&#27861;&#28041;&#21450;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#25110;Adam&#20248;&#21270;&#31639;&#27861;&#65292;&#20197;&#21450;&#39069;&#22806;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#22914;&#26435;&#37325;&#34928;&#20943;&#12289;Dropout&#25110;&#22122;&#22768;&#27880;&#20837;&#12290;&#36890;&#36807;&#32593;&#26684;&#25628;&#32034;&#35843;&#25972;&#25968;&#37327;&#20247;&#22810;&#30340;&#36229;&#21442;&#25968;&#25165;&#33021;&#36798;&#21040;&#26368;&#20248;&#27867;&#21270;&#65292;&#36825;&#21487;&#33021;&#32791;&#26102;&#65292;&#24182;&#38656;&#35201;&#39069;&#22806;&#30340;&#39564;&#35777;&#25968;&#25454;&#38598;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#20999;&#23454;&#21487;&#34892;&#30340;PAC-Bayes&#35757;&#32451;&#26694;&#26550;&#65292;&#20960;&#20046;&#26159;&#26080;&#38656;&#35843;&#25972;&#65292;&#20063;&#19981;&#38656;&#35201;&#39069;&#22806;&#30340;&#27491;&#21017;&#21270;&#65292;&#32780;&#22312;&#23436;&#25104;&#32593;&#26684;&#25628;&#32034;&#21644;&#21152;&#20837;&#39069;&#22806;&#27491;&#21017;&#21270;&#21518;&#65292;&#36798;&#21040;&#20102;&#19982;SGD/Adam&#21487;&#27604;&#36739;&#30340;&#27979;&#35797;&#24615;&#33021;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#23637;&#31034;&#20102;PAC&#35757;&#32451;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#19978;&#23454;&#29616;&#26368;&#20808;&#36827;&#24615;&#33021;&#30340;&#26174;&#33879;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is widely recognized that the generalization ability of neural networks can be greatly enhanced through carefully designing the training procedure. The current state-of-the-art training approach involves utilizing stochastic gradient descent (SGD) or Adam optimization algorithms along with a combination of additional regularization techniques such as weight decay, dropout, or noise injection. Optimal generalization can only be achieved by tuning a multitude of hyperparameters through grid search, which can be time-consuming and necessitates additional validation datasets. To address this issue, we introduce a practical PAC-Bayes training framework that is nearly tuning-free and requires no additional regularization while achieving comparable testing performance to that of SGD/Adam after a complete grid search and with extra regularizations. Our proposed algorithm demonstrates the remarkable potential of PAC training to achieve state-of-the-art performance on deep neural networks wit
&lt;/p&gt;</description></item><item><title>&#23398;&#20064;&#33021;&#21147;&#26159;&#19968;&#31181;&#24230;&#37327;&#27169;&#22411;&#26377;&#25928;&#32500;&#24230;&#30340;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#24110;&#21161;&#25105;&#20204;&#21028;&#26029;&#26159;&#21542;&#38656;&#35201;&#33719;&#21462;&#26356;&#22810;&#25968;&#25454;&#25110;&#32773;&#23547;&#25214;&#26032;&#30340;&#20307;&#31995;&#32467;&#26500;&#20197;&#25552;&#39640;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.17332</link><description>&lt;p&gt;
&#23398;&#20064;&#33021;&#21147;&#65306;&#27169;&#22411;&#26377;&#25928;&#32500;&#24230;&#30340;&#24230;&#37327;&#26041;&#24335;
&lt;/p&gt;
&lt;p&gt;
Learning Capacity: A Measure of the Effective Dimensionality of a Model. (arXiv:2305.17332v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17332
&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#33021;&#21147;&#26159;&#19968;&#31181;&#24230;&#37327;&#27169;&#22411;&#26377;&#25928;&#32500;&#24230;&#30340;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#24110;&#21161;&#25105;&#20204;&#21028;&#26029;&#26159;&#21542;&#38656;&#35201;&#33719;&#21462;&#26356;&#22810;&#25968;&#25454;&#25110;&#32773;&#23547;&#25214;&#26032;&#30340;&#20307;&#31995;&#32467;&#26500;&#20197;&#25552;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#21033;&#29992;&#28909;&#21147;&#23398;&#21644;&#25512;&#29702;&#20043;&#38388;&#30340;&#27491;&#24335;&#23545;&#24212;&#20851;&#31995;&#65292;&#23558;&#26679;&#26412;&#25968;&#37327;&#35270;&#20026;&#21453;&#28201;&#24230;&#65292;&#23450;&#20041;&#20102;&#19968;&#31181;&#8220;&#23398;&#20064;&#33021;&#21147;&#8221;&#65292;&#36825;&#26159;&#27169;&#22411;&#26377;&#25928;&#32500;&#24230;&#30340;&#24230;&#37327;&#26041;&#24335;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#23545;&#20110;&#35768;&#22810;&#22312;&#20856;&#22411;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#28145;&#24230;&#32593;&#32476;&#65292;&#23398;&#20064;&#33021;&#21147;&#20165;&#21344;&#21442;&#25968;&#25968;&#37327;&#30340;&#19968;&#23567;&#37096;&#20998;&#65292;&#21462;&#20915;&#20110;&#29992;&#20110;&#35757;&#32451;&#30340;&#26679;&#26412;&#25968;&#37327;&#65292;&#24182;&#19988;&#22312;&#25968;&#20540;&#19978;&#19982;&#20174;PAC-Bayesian&#26694;&#26550;&#33719;&#24471;&#30340;&#33021;&#21147;&#27010;&#24565;&#19968;&#33268;&#12290;&#23398;&#20064;&#33021;&#21147;&#20316;&#20026;&#27979;&#35797;&#35823;&#24046;&#30340;&#20989;&#25968;&#19981;&#20250;&#20986;&#29616;&#21452;&#23792;&#19979;&#38477;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#27169;&#22411;&#30340;&#23398;&#20064;&#33021;&#21147;&#22312;&#38750;&#24120;&#23567;&#21644;&#38750;&#24120;&#22823;&#30340;&#26679;&#26412;&#22823;&#23567;&#22788;&#39281;&#21644;&#65292;&#36825;&#25552;&#20379;&#20102;&#25351;&#23548;&#65292;&#35828;&#26126;&#26159;&#21542;&#24212;&#35813;&#33719;&#21462;&#26356;&#22810;&#25968;&#25454;&#25110;&#32773;&#23547;&#25214;&#26032;&#30340;&#20307;&#31995;&#32467;&#26500;&#20197;&#25552;&#39640;&#24615;&#33021;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#23398;&#20064;&#33021;&#21147;&#26469;&#29702;&#35299;&#26377;&#25928;&#32500;&#25968;&#65292;&#21363;&#20351;&#26159;&#38750;&#21442;&#25968;&#27169;&#22411;&#65292;&#22914;&#38543;&#26426;&#26862;&#26519;&#12290;
&lt;/p&gt;
&lt;p&gt;
We exploit a formal correspondence between thermodynamics and inference, where the number of samples can be thought of as the inverse temperature, to define a "learning capacity'' which is a measure of the effective dimensionality of a model. We show that the learning capacity is a tiny fraction of the number of parameters for many deep networks trained on typical datasets, depends upon the number of samples used for training, and is numerically consistent with notions of capacity obtained from the PAC-Bayesian framework. The test error as a function of the learning capacity does not exhibit double descent. We show that the learning capacity of a model saturates at very small and very large sample sizes; this provides guidelines, as to whether one should procure more data or whether one should search for new architectures, to improve performance. We show how the learning capacity can be used to understand the effective dimensionality, even for non-parametric models such as random fores
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312; mini-batch &#20013;&#26174;&#24335;&#22320;&#23398;&#20064;&#35823;&#24046;&#30340;&#24207;&#21015;&#30456;&#20851;&#24615;&#65292;&#26469;&#25552;&#39640;&#28145;&#24230;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;</title><link>http://arxiv.org/abs/2305.17028</link><description>&lt;p&gt;
&#28145;&#24230;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#26356;&#22909;Batch&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Better Batch for Deep Probabilistic Time Series Forecasting. (arXiv:2305.17028v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17028
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312; mini-batch &#20013;&#26174;&#24335;&#22320;&#23398;&#20064;&#35823;&#24046;&#30340;&#24207;&#21015;&#30456;&#20851;&#24615;&#65292;&#26469;&#25552;&#39640;&#28145;&#24230;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#22240;&#20854;&#33021;&#22815;&#25552;&#20379;&#26377;&#20215;&#20540;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#32780;&#21463;&#21040;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#29616;&#26377;&#27169;&#22411;&#36807;&#20110;&#31616;&#21333;&#21270;&#38382;&#39064;&#65292;&#20551;&#35774;&#35823;&#24046;&#36807;&#31243;&#26159;&#19982;&#26102;&#38388;&#26080;&#20851;&#30340;&#65292;&#20174;&#32780;&#24573;&#30053;&#20102;&#35823;&#24046;&#36807;&#31243;&#20013;&#30340;&#24207;&#21015;&#30456;&#20851;&#24615;&#12290;&#36825;&#21487;&#33021;&#20250;&#38477;&#20302;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#65292;&#20351;&#36825;&#20123;&#27169;&#22411;&#23545;&#20915;&#31574;&#24615;&#20219;&#21153;&#30340;&#26377;&#25928;&#24615;&#20943;&#24369;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#19968;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#23558;&#35823;&#24046;&#33258;&#30456;&#20851;&#24615;&#32435;&#20837;&#32771;&#34385;&#65292;&#20197;&#22686;&#24378;&#27010;&#29575;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#28041;&#21450;&#26500;&#36896;&#19968;&#20010;mini-batch&#65292;&#20316;&#20026;$D$&#20010;&#36830;&#32493;&#26102;&#38388;&#24207;&#21015;&#27573;&#36827;&#34892;&#27169;&#22411;&#35757;&#32451;&#65292;&#24182;&#26174;&#24335;&#22320;&#23398;&#20064;&#19968;&#20010;&#21327;&#26041;&#24046;&#30697;&#38453;&#65292;&#35206;&#30422;&#20102;&#30456;&#37051;&#26102;&#38388;&#27493;&#20043;&#38388;&#30340;&#35823;&#24046;&#30456;&#20851;&#24615;&#12290;&#30001;&#27492;&#20135;&#29983;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#21487;&#29992;&#20110;&#25552;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#21644;&#22686;&#24378;&#19981;&#30830;&#23450;&#24615;&#30340;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep probabilistic time series forecasting has gained significant attention due to its ability to provide valuable uncertainty quantification for decision-making tasks. However, many existing models oversimplify the problem by assuming the error process is time-independent, thereby overlooking the serial correlation in the error process. This oversight can potentially diminish the accuracy of the forecasts, rendering these models less effective for decision-making purposes. To overcome this limitation, we propose an innovative training method that incorporates error autocorrelation to enhance the accuracy of probabilistic forecasting. Our method involves constructing a mini-batch as a collection of $D$ consecutive time series segments for model training and explicitly learning a covariance matrix over each mini-batch that encodes the error correlation among adjacent time steps. The resulting covariance matrix can be used to improve prediction accuracy and enhance uncertainty quantifica
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#26080;&#38480;&#32500;&#24230;&#24471;&#20998;&#25193;&#25955;&#27169;&#22411;&#22312;&#22810;&#20010;&#20998;&#36776;&#29575;&#27700;&#24179;&#19978;&#30340;&#31163;&#25955;&#21270;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;&#22810;&#32423;&#25193;&#25955;&#31639;&#27861;&#22312;&#22810;&#20010;&#20998;&#36776;&#29575;&#19978;&#39640;&#25928;&#22320;&#23398;&#20064;&#12290;&#23454;&#35777;&#34920;&#26126;&#65292;&#35813;&#27169;&#22411;&#22312;&#30456;&#21516;&#25110;&#26356;&#39640;&#20998;&#36776;&#29575;&#19979;&#20135;&#29983;&#27604;&#20256;&#32479;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#26356;&#39640;&#36136;&#37327;&#30340;&#26679;&#26412;&#65292;&#24182;&#21487;&#20197;&#29983;&#25104;&#19981;&#21516;&#20998;&#36776;&#29575;&#30340;&#22270;&#20687;&#24182;&#22788;&#29702;&#30697;&#24418;&#22495;&#12290;</title><link>http://arxiv.org/abs/2303.04772</link><description>&lt;p&gt;
&#22810;&#32423;&#25193;&#25955;&#65306;&#22270;&#20687;&#29983;&#25104;&#30340;&#26080;&#38480;&#32500;&#24230;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Multilevel Diffusion: Infinite Dimensional Score-Based Diffusion Models for Image Generation. (arXiv:2303.04772v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.04772
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#26080;&#38480;&#32500;&#24230;&#24471;&#20998;&#25193;&#25955;&#27169;&#22411;&#22312;&#22810;&#20010;&#20998;&#36776;&#29575;&#27700;&#24179;&#19978;&#30340;&#31163;&#25955;&#21270;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;&#22810;&#32423;&#25193;&#25955;&#31639;&#27861;&#22312;&#22810;&#20010;&#20998;&#36776;&#29575;&#19978;&#39640;&#25928;&#22320;&#23398;&#20064;&#12290;&#23454;&#35777;&#34920;&#26126;&#65292;&#35813;&#27169;&#22411;&#22312;&#30456;&#21516;&#25110;&#26356;&#39640;&#20998;&#36776;&#29575;&#19979;&#20135;&#29983;&#27604;&#20256;&#32479;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#26356;&#39640;&#36136;&#37327;&#30340;&#26679;&#26412;&#65292;&#24182;&#21487;&#20197;&#29983;&#25104;&#19981;&#21516;&#20998;&#36776;&#29575;&#30340;&#22270;&#20687;&#24182;&#22788;&#29702;&#30697;&#24418;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#26159;&#36817;&#24180;&#26469;&#22270;&#20687;&#29983;&#25104;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#20043;&#19968;&#12290;&#29616;&#26377;&#30340;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#36890;&#24120;&#22312;&#26377;&#38480;&#32500;&#24230;&#35774;&#32622;&#20013;&#34920;&#36848;&#65292;&#20854;&#20013;&#22270;&#20687;&#34987;&#35270;&#20026;&#20855;&#26377;&#26377;&#38480;&#23610;&#23544;&#30340;&#24352;&#37327;&#12290;&#26412;&#25991;&#22312;&#26080;&#38480;&#32500;&#24230;&#35774;&#32622;&#20013;&#24320;&#21457;&#20102;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#21363;&#25105;&#20204;&#23558;&#35757;&#32451;&#25968;&#25454;&#24314;&#27169;&#20026;&#25903;&#25745;&#22312;&#30697;&#24418;&#22495;&#19978;&#30340;&#20989;&#25968;&#12290;&#38500;&#20102;&#36861;&#27714;&#22312;&#26356;&#39640;&#20998;&#36776;&#29575;&#19979;&#29983;&#25104;&#22270;&#20687;&#20043;&#22806;&#65292;&#25105;&#20204;&#30340;&#20027;&#35201;&#21160;&#26426;&#26159;&#21019;&#24314;&#19968;&#20010;&#33391;&#22909;&#23450;&#20041;&#30340;&#26080;&#38480;&#32500;&#24230;&#23398;&#20064;&#38382;&#39064;&#65292;&#20197;&#20415;&#21487;&#20197;&#22312;&#22810;&#20010;&#20998;&#36776;&#29575;&#27700;&#24179;&#19978;&#19968;&#33268;&#22320;&#31163;&#25955;&#21270;&#23427;&#12290;&#25105;&#20204;&#24076;&#26395;&#33719;&#24471;&#33021;&#22815;&#27178;&#36328;&#19981;&#21516;&#20998;&#36776;&#29575;&#32423;&#21035;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#24182;&#25552;&#39640;&#35757;&#32451;&#36807;&#31243;&#30340;&#25928;&#29575;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#20811;&#26381;&#24403;&#21069;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#22312;&#26080;&#38480;&#32500;&#24230;&#35774;&#32622;&#20013;&#23384;&#22312;&#30340;&#20004;&#20010;&#32570;&#28857;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#20462;&#25913;&#20102;&#21069;&#21521;&#36807;&#31243;&#20197;&#30830;&#20445;&#22312;&#26080;&#38480;&#32500;&#24230;&#35774;&#32622;&#20013;&#28508;&#22312;&#20998;&#24067;&#26159;&#33391;&#22909;&#23450;&#20041;&#30340;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#32423;&#25193;&#25955;&#31639;&#27861;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#22312;&#22810;&#20010;&#20998;&#36776;&#29575;&#19978;&#39640;&#25928;&#22320;&#23398;&#20064;&#12290;&#25105;&#20204;&#23454;&#35777;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#22810;&#32423;&#27169;&#22411;&#22312;&#30456;&#21516;&#25110;&#26356;&#39640;&#20998;&#36776;&#29575;&#19979;&#20135;&#29983;&#27604;&#20256;&#32479;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#26356;&#39640;&#36136;&#37327;&#30340;&#26679;&#26412;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#26080;&#32541;&#22320;&#29983;&#25104;&#19981;&#21516;&#20998;&#36776;&#29575;&#30340;&#22270;&#20687;&#24182;&#22788;&#29702;&#30697;&#24418;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
Score-based diffusion models (SBDM) have recently emerged as state-of-the-art approaches for image generation. Existing SBDMs are typically formulated in a finite-dimensional setting, where images are considered as tensors of a finite size. This papers develops SBDMs in the infinite-dimensional setting, that is, we model the training data as functions supported on a rectangular domain. Besides the quest for generating images at ever higher resolution our primary motivation is to create a well-posed infinite-dimensional learning problem so that we can discretize it consistently on multiple resolution levels. We thereby hope to obtain diffusion models that generalize across different resolution levels and improve the efficiency of the training process. We demonstrate how to overcome two shortcomings of current SBDM approaches in the infinite-dimensional setting. First, we modify the forward process to ensure that the latent distribution is well-defined in the infinite-dimensional setting
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;Thompson-CHM&#30340;&#28176;&#36817;&#26368;&#20248;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#20984;&#21253;&#25104;&#21592;&#38382;&#39064;&#65292;&#19988;&#23558;&#31639;&#27861;&#25193;&#23637;&#21040;&#20102;&#19968;&#32500;&#21644;&#22810;&#32500;&#29615;&#22659;&#20013;&#12290;&#35813;&#31639;&#27861;&#22522;&#20110;&#27169;&#22359;&#21270;&#35774;&#35745;&#65292;&#21253;&#25324;&#20572;&#27490;&#35268;&#21017;&#21644;&#37319;&#26679;&#35268;&#21017;&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#29702;&#35770;&#32467;&#26524;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.02033</link><description>&lt;p&gt;
&#19968;&#20010;&#28176;&#36817;&#26368;&#20248;&#30340;&#20984;&#21253;&#25104;&#21592;&#38382;&#39064;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
An Asymptotically Optimal Algorithm for the Convex Hull Membership Problem. (arXiv:2302.02033v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.02033
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;Thompson-CHM&#30340;&#28176;&#36817;&#26368;&#20248;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#20984;&#21253;&#25104;&#21592;&#38382;&#39064;&#65292;&#19988;&#23558;&#31639;&#27861;&#25193;&#23637;&#21040;&#20102;&#19968;&#32500;&#21644;&#22810;&#32500;&#29615;&#22659;&#20013;&#12290;&#35813;&#31639;&#27861;&#22522;&#20110;&#27169;&#22359;&#21270;&#35774;&#35745;&#65292;&#21253;&#25324;&#20572;&#27490;&#35268;&#21017;&#21644;&#37319;&#26679;&#35268;&#21017;&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#29702;&#35770;&#32467;&#26524;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23558;&#20984;&#21253;&#25104;&#21592;&#38382;&#39064;&#30340;&#32431;&#25506;&#32034;&#35774;&#32622;&#19982;&#20984;&#21253;&#22343;&#20540;&#30340;&#26377;&#38480;&#20998;&#24067;&#38598;&#21512;&#20013;&#26377;&#25928;&#20934;&#30830;&#22320;&#30830;&#23450;&#32473;&#23450;&#28857;&#26159;&#21542;&#22312;&#20984;&#21253;&#20013;&#30456;&#20851;&#12290;&#25105;&#20204;&#22312;&#19968;&#32500;&#29615;&#22659;&#20013;&#23436;&#20840;&#21051;&#30011;&#20102;&#20984;&#21253;&#25104;&#21592;&#38382;&#39064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#28176;&#36817;&#26368;&#20248;&#31639;&#27861;&#65292;&#21517;&#20026;Thompson-CHM&#65292;&#20854;&#27169;&#22359;&#21270;&#35774;&#35745;&#21253;&#25324;&#20572;&#27490;&#35268;&#21017;&#21644;&#37319;&#26679;&#35268;&#21017;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#31639;&#27861;&#25193;&#23637;&#21040;&#20102;&#19968;&#20123;&#22312;&#22810;&#33218;&#36172;&#21338;&#26426;&#25991;&#29486;&#20013;&#24191;&#20041;&#30340;&#37325;&#35201;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;Thompson-CHM&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#30340;&#25193;&#23637;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#25968;&#20540;&#23454;&#39564;&#65292;&#20197;&#23637;&#31034;&#31639;&#27861;&#30340;&#32463;&#39564;&#34892;&#20026;&#19982;&#25105;&#20204;&#22312;&#23454;&#38469;&#26102;&#38388;&#33539;&#22260;&#20869;&#30340;&#29702;&#35770;&#32467;&#26524;&#30456;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work studies the pure-exploration setting for the convex hull membership (CHM) problem where one aims to efficiently and accurately determine if a given point lies in the convex hull of means of a finite set of distributions. We give a complete characterization of the sample complexity of the CHM problem in the one-dimensional setting. We present the first asymptotically optimal algorithm called Thompson-CHM, whose modular design consists of a stopping rule and a sampling rule. In addition, we extend the algorithm to settings that generalize several important problems in the multi-armed bandit literature. Furthermore, we discuss the extension of Thompson-CHM to higher dimensions. Finally, we provide numerical experiments to demonstrate the empirical behavior of the algorithm matches our theoretical results for realistic time horizons.
&lt;/p&gt;</description></item></channel></rss>