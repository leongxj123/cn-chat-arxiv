<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20943;&#23569;&#23618;&#27425;&#20998;&#31867;&#21464;&#37327;&#32500;&#24230;&#21644;&#31890;&#24230;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23454;&#20307;&#23884;&#20837;&#21644;&#33258;&#19978;&#32780;&#19979;&#32858;&#31867;&#31639;&#27861;&#26469;&#38477;&#20302;&#23618;&#20869;&#32500;&#24230;&#21644;&#25972;&#20307;&#31890;&#24230;&#12290;</title><link>https://arxiv.org/abs/2403.03613</link><description>&lt;p&gt;
&#20943;&#23569;&#23618;&#27425;&#20998;&#31867;&#21464;&#37327;&#30340;&#32500;&#24230;&#21644;&#31890;&#24230;
&lt;/p&gt;
&lt;p&gt;
Reducing the dimensionality and granularity in hierarchical categorical variables
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03613
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20943;&#23569;&#23618;&#27425;&#20998;&#31867;&#21464;&#37327;&#32500;&#24230;&#21644;&#31890;&#24230;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23454;&#20307;&#23884;&#20837;&#21644;&#33258;&#19978;&#32780;&#19979;&#32858;&#31867;&#31639;&#27861;&#26469;&#38477;&#20302;&#23618;&#20869;&#32500;&#24230;&#21644;&#25972;&#20307;&#31890;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23618;&#27425;&#20998;&#31867;&#21464;&#37327;&#24448;&#24448;&#20855;&#26377;&#35768;&#22810;&#32423;&#21035;&#65288;&#39640;&#31890;&#24230;&#65289;&#21644;&#27599;&#20010;&#32423;&#21035;&#20869;&#35768;&#22810;&#31867;&#21035;&#65288;&#39640;&#32500;&#24230;&#65289;&#12290;&#23558;&#36825;&#20123;&#21327;&#21464;&#37327;&#21253;&#21547;&#22312;&#39044;&#27979;&#27169;&#22411;&#20013;&#21487;&#33021;&#23548;&#33268;&#36807;&#24230;&#25311;&#21512;&#21644;&#20272;&#35745;&#38382;&#39064;&#12290;&#22312;&#24403;&#21069;&#25991;&#29486;&#20013;&#65292;&#23618;&#27425;&#21327;&#21464;&#37327;&#36890;&#24120;&#36890;&#36807;&#23884;&#22871;&#38543;&#26426;&#25928;&#24212;&#26469;&#32435;&#20837;&#12290;&#28982;&#32780;&#65292;&#36825;&#24182;&#19981;&#26377;&#21161;&#20110;&#20551;&#35774;&#31867;&#21035;&#23545;&#21709;&#24212;&#21464;&#37327;&#20855;&#26377;&#30456;&#21516;&#30340;&#24433;&#21709;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33719;&#24471;&#23618;&#27425;&#20998;&#31867;&#21464;&#37327;&#31616;&#21270;&#34920;&#31034;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#22312;&#23618;&#27425;&#35774;&#32622;&#20013;&#24212;&#29992;&#23454;&#20307;&#23884;&#20837;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#19978;&#32780;&#19979;&#30340;&#32858;&#31867;&#31639;&#27861;&#65292;&#21033;&#29992;&#23884;&#20837;&#20013;&#32534;&#30721;&#30340;&#20449;&#24687;&#26469;&#20943;&#23569;&#23618;&#20869;&#32500;&#24230;&#20197;&#21450;&#23618;&#27425;&#20998;&#31867;&#21464;&#37327;&#30340;&#25972;&#20307;&#31890;&#24230;&#12290;&#22312;&#27169;&#25311;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#22320;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03613v1 Announce Type: cross  Abstract: Hierarchical categorical variables often exhibit many levels (high granularity) and many classes within each level (high dimensionality). This may cause overfitting and estimation issues when including such covariates in a predictive model. In current literature, a hierarchical covariate is often incorporated via nested random effects. However, this does not facilitate the assumption of classes having the same effect on the response variable. In this paper, we propose a methodology to obtain a reduced representation of a hierarchical categorical variable. We show how entity embedding can be applied in a hierarchical setting. Subsequently, we propose a top-down clustering algorithm which leverages the information encoded in the embeddings to reduce both the within-level dimensionality as well as the overall granularity of the hierarchical categorical variable. In simulation experiments, we show that our methodology can effectively appro
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#27969;&#24418;&#23398;&#20064;&#30340;&#22312;&#27969;&#24418;&#19978;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#19968;&#27425;&#24615;&#26500;&#36896;&#33719;&#24471;&#26368;&#20339;&#35823;&#24046;&#30028;&#38480;&#12290;</title><link>https://arxiv.org/abs/2402.12687</link><description>&lt;p&gt;
&#22312;&#27969;&#24418;&#19978;&#23398;&#20064;&#32780;&#26080;&#38656;&#27969;&#24418;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Learning on manifolds without manifold learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12687
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#27969;&#24418;&#23398;&#20064;&#30340;&#22312;&#27969;&#24418;&#19978;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#19968;&#27425;&#24615;&#26500;&#36896;&#33719;&#24471;&#26368;&#20339;&#35823;&#24046;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#26410;&#30693;&#20998;&#24067;&#38543;&#26426;&#25277;&#26679;&#30340;&#25968;&#25454;&#36827;&#34892;&#20989;&#25968;&#36924;&#36817;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#12290;&#19982;&#36890;&#36807;&#26368;&#23567;&#21270;&#25439;&#22833;&#20989;&#25968;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#30427;&#34892;&#33539;&#24335;&#30456;&#21453;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#19968;&#31181;&#30452;&#25509;&#30340;&#19968;&#27425;&#24615;&#26500;&#36896;&#26041;&#27861;&#65292;&#24182;&#22312;&#27969;&#24418;&#20551;&#35774;&#19979;&#32473;&#20986;&#20102;&#26368;&#20339;&#35823;&#24046;&#30028;&#38480;&#65307;&#21363;&#20551;&#35774;&#25968;&#25454;&#26159;&#20174;&#39640;&#32500;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#30340;&#26410;&#30693;&#23376;&#27969;&#24418;&#20013;&#25277;&#26679;&#24471;&#21040;&#30340;&#12290; Neural Networks 132:253268, 2020 &#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#19968;&#27425;&#24615;&#30452;&#25509;&#26041;&#27861;&#26469;&#23454;&#29616;&#20989;&#25968;&#36924;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12687v1 Announce Type: new  Abstract: Function approximation based on data drawn randomly from an unknown distribution is an important problem in machine learning. In contrast to the prevalent paradigm of solving this problem by minimizing a loss functional, we have given a direct one-shot construction together with optimal error bounds under the manifold assumption; i.e., one assumes that the data is sampled from an unknown sub-manifold of a high dimensional Euclidean space. A great deal of research deals with obtaining information about this manifold, such as the eigendecomposition of the Laplace-Beltrami operator or coordinate charts, and using this information for function approximation. This two step approach implies some extra errors in the approximation stemming from basic quantities of the data in addition to the errors inherent in function approximation. In Neural Networks, 132:253268, 2020, we have proposed a one-shot direct method to achieve function approximation
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#39564;&#35777;&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#20219;&#21153;&#24179;&#22343;&#26657;&#20934;&#24615;&#30340;&#26041;&#27861;&#65292;&#23558;&#26657;&#20934;&#35823;&#24046;&#19982;&#24179;&#22343;&#32477;&#23545;&#35823;&#24046;&#20043;&#38388;&#30340;&#24046;&#20540;&#21644;&#23558;&#24179;&#22343;&#24179;&#26041;z-&#20998;&#25968;&#19982;1&#36827;&#34892;&#27604;&#36739;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#21069;&#32773;&#23545;&#19981;&#30830;&#23450;&#24615;&#20998;&#24067;&#25935;&#24863;&#65292;&#32780;&#21518;&#32773;&#22312;&#35813;&#26041;&#38754;&#25552;&#20379;&#20102;&#26368;&#21487;&#38752;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.10043</link><description>&lt;p&gt;
&#22914;&#20309;&#39564;&#35777;&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#20219;&#21153;&#30340;&#24179;&#22343;&#26657;&#20934;&#24615;&#65311;
&lt;/p&gt;
&lt;p&gt;
How to validate average calibration for machine learning regression tasks ?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10043
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#39564;&#35777;&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#20219;&#21153;&#24179;&#22343;&#26657;&#20934;&#24615;&#30340;&#26041;&#27861;&#65292;&#23558;&#26657;&#20934;&#35823;&#24046;&#19982;&#24179;&#22343;&#32477;&#23545;&#35823;&#24046;&#20043;&#38388;&#30340;&#24046;&#20540;&#21644;&#23558;&#24179;&#22343;&#24179;&#26041;z-&#20998;&#25968;&#19982;1&#36827;&#34892;&#27604;&#36739;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#21069;&#32773;&#23545;&#19981;&#30830;&#23450;&#24615;&#20998;&#24067;&#25935;&#24863;&#65292;&#32780;&#21518;&#32773;&#22312;&#35813;&#26041;&#38754;&#25552;&#20379;&#20102;&#26368;&#21487;&#38752;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#20219;&#21153;&#30340;&#24179;&#22343;&#26657;&#20934;&#24615;&#21487;&#20197;&#36890;&#36807;&#20004;&#31181;&#26041;&#24335;&#36827;&#34892;&#27979;&#35797;&#12290;&#19968;&#31181;&#26041;&#24335;&#26159;&#23558;&#26657;&#20934;&#35823;&#24046;&#65288;CE&#65289;&#20272;&#35745;&#20026;&#24179;&#22343;&#32477;&#23545;&#35823;&#24046;&#65288;MSE&#65289;&#19982;&#24179;&#22343;&#26041;&#24046;&#65288;MV&#65289;&#25110;&#24179;&#22343;&#24179;&#26041;&#19981;&#30830;&#23450;&#24615;&#20043;&#38388;&#30340;&#24046;&#20540;&#12290;&#21478;&#19968;&#31181;&#26041;&#24335;&#26159;&#23558;&#24179;&#22343;&#24179;&#26041;z-&#20998;&#25968;&#25110;&#32553;&#25918;&#35823;&#24046;&#65288;ZMS&#65289;&#19982;1&#36827;&#34892;&#27604;&#36739;&#12290;&#20004;&#31181;&#26041;&#27861;&#21487;&#33021;&#24471;&#20986;&#19981;&#21516;&#30340;&#32467;&#35770;&#65292;&#27491;&#22914;&#26469;&#33258;&#26368;&#36817;&#30340;&#26426;&#22120;&#23398;&#20064;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#25991;&#29486;&#20013;&#30340;&#25968;&#25454;&#38598;&#38598;&#21512;&#25152;&#31034;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;CE&#23545;&#19981;&#30830;&#23450;&#24615;&#20998;&#24067;&#38750;&#24120;&#25935;&#24863;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#31163;&#32676;&#19981;&#30830;&#23450;&#24615;&#30340;&#23384;&#22312;&#65292;&#22240;&#27492;&#26080;&#27861;&#21487;&#38752;&#22320;&#29992;&#20110;&#26657;&#20934;&#27979;&#35797;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;ZMS&#32479;&#35745;&#37327;&#19981;&#20855;&#26377;&#36825;&#31181;&#25935;&#24863;&#24615;&#38382;&#39064;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#25552;&#20379;&#20102;&#26368;&#21487;&#38752;&#30340;&#26041;&#27861;&#12290;&#25991;&#31456;&#36824;&#35752;&#35770;&#20102;&#23545;&#26465;&#20214;&#26657;&#20934;&#39564;&#35777;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10043v1 Announce Type: cross  Abstract: Average calibration of the uncertainties of machine learning regression tasks can be tested in two ways. One way is to estimate the calibration error (CE) as the difference between the mean absolute error (MSE) and the mean variance (MV) or mean squared uncertainty. The alternative is to compare the mean squared z-scores or scaled errors (ZMS) to 1. Both approaches might lead to different conclusion, as illustrated on an ensemble of datasets from the recent machine learning uncertainty quantification literature. It is shown here that the CE is very sensitive to the distribution of uncertainties, and notably to the presence of outlying uncertainties, and that it cannot be used reliably for calibration testing. By contrast, the ZMS statistic does not present this sensitivity issue and offers the most reliable approach in this context. Implications for the validation of conditional calibration are discussed.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#22312;&#32454;&#32990;&#22797;&#21512;&#29289;&#19978;&#24212;&#29992;&#39640;&#26031;&#36807;&#31243;&#65292;&#25552;&#20986;&#20102;&#20004;&#20010;&#26032;&#30340;&#26680;&#20989;&#25968;&#26469;&#25429;&#25417;&#39640;&#38454;&#32454;&#32990;&#20043;&#38388;&#30340;&#20132;&#20114;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2311.01198</link><description>&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#22312;&#32454;&#32990;&#22797;&#21512;&#29289;&#19978;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Gaussian Processes on Cellular Complexes. (arXiv:2311.01198v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01198
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#22312;&#32454;&#32990;&#22797;&#21512;&#29289;&#19978;&#24212;&#29992;&#39640;&#26031;&#36807;&#31243;&#65292;&#25552;&#20986;&#20102;&#20004;&#20010;&#26032;&#30340;&#26680;&#20989;&#25968;&#26469;&#25429;&#25417;&#39640;&#38454;&#32454;&#32990;&#20043;&#38388;&#30340;&#20132;&#20114;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#20154;&#20204;&#23545;&#22312;&#22270;&#19978;&#24320;&#21457;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26469;&#32771;&#34385;&#25299;&#25169;&#24402;&#32435;&#20559;&#32622;&#20135;&#29983;&#20102;&#30456;&#24403;&#22823;&#30340;&#20852;&#36259;&#12290;&#29305;&#21035;&#26159;&#65292;&#26368;&#36817;&#20851;&#27880;&#30340;&#26159;&#22312;&#36825;&#20123;&#32467;&#26500;&#19978;&#30340;&#39640;&#26031;&#36807;&#31243;&#65292;&#22240;&#20026;&#23427;&#20204;&#33021;&#22815;&#21516;&#26102;&#32771;&#34385;&#19981;&#30830;&#23450;&#24615;&#12290;&#28982;&#32780;&#65292;&#22270;&#20165;&#38480;&#20110;&#23545;&#20004;&#20010;&#39030;&#28857;&#20043;&#38388;&#30340;&#20851;&#31995;&#36827;&#34892;&#24314;&#27169;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36229;&#36234;&#20102;&#36825;&#31181;&#23545;&#31216;&#37197;&#32622;&#65292;&#24182;&#32771;&#34385;&#20102;&#21253;&#25324;&#39030;&#28857;&#12289;&#36793;&#21644;&#23427;&#20204;&#30340;&#19968;&#31181;&#24191;&#20041;&#21270;&#31216;&#20026;&#32454;&#32990;&#30340;&#20132;&#20114;&#20851;&#31995;&#12290;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#39640;&#26031;&#36807;&#31243;&#22312;&#32454;&#32990;&#22797;&#21512;&#29289;&#19978;&#30340;&#24212;&#29992;&#65292;&#36825;&#26159;&#23545;&#22270;&#30340;&#19968;&#31181;&#25512;&#24191;&#65292;&#21487;&#20197;&#25429;&#25417;&#36825;&#20123;&#39640;&#38454;&#32454;&#32990;&#20043;&#38388;&#30340;&#20132;&#20114;&#20316;&#29992;&#12290;&#25105;&#20204;&#30340;&#19968;&#20010;&#20851;&#38190;&#36129;&#29486;&#26159;&#25512;&#23548;&#20986;&#20004;&#20010;&#26032;&#22411;&#26680;&#20989;&#25968;&#65292;&#19968;&#20010;&#26159;&#23545;&#22270;Mat\'ern&#26680;&#36827;&#34892;&#25512;&#24191;&#65292;&#21478;&#19968;&#20010;&#26159;&#39069;&#22806;&#22320;&#28151;&#21512;&#20102;&#19981;&#21516;&#32454;&#32990;&#31867;&#22411;&#30340;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, there has been considerable interest in developing machine learning models on graphs in order to account for topological inductive biases. In particular, recent attention was given to Gaussian processes on such structures since they can additionally account for uncertainty. However, graphs are limited to modelling relations between two vertices. In this paper, we go beyond this dyadic setting and consider polyadic relations that include interactions between vertices, edges and one of their generalisations, known as cells. Specifically, we propose Gaussian processes on cellular complexes, a generalisation of graphs that captures interactions between these higher-order cells. One of our key contributions is the derivation of two novel kernels, one that generalises the graph Mat\'ern kernel and one that additionally mixes information of different cell types.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#22312;&#20915;&#31574;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#23398;&#20064;&#21487;&#34892;&#20915;&#31574;&#30340;&#20998;&#24067;&#65292;&#22312;&#21407;&#22987;&#31354;&#38388;&#21644;&#28508;&#22312;&#31354;&#38388;&#20043;&#38388;&#23454;&#29616;&#20102;&#21452;&#21521;&#26144;&#23556;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#20844;&#20849;&#20915;&#31574;&#21046;&#23450;&#20013;&#30340;&#38544;&#34255;&#32422;&#26463;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.18449</link><description>&lt;p&gt;
&#22522;&#20110;&#28508;&#22312;&#20915;&#31574;&#27169;&#22411;&#30340;&#20855;&#26377;&#38544;&#34255;&#32422;&#26463;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Bayesian Optimization with Hidden Constraints via Latent Decision Models. (arXiv:2310.18449v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18449
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#22312;&#20915;&#31574;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#23398;&#20064;&#21487;&#34892;&#20915;&#31574;&#30340;&#20998;&#24067;&#65292;&#22312;&#21407;&#22987;&#31354;&#38388;&#21644;&#28508;&#22312;&#31354;&#38388;&#20043;&#38388;&#23454;&#29616;&#20102;&#21452;&#21521;&#26144;&#23556;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#20844;&#20849;&#20915;&#31574;&#21046;&#23450;&#20013;&#30340;&#38544;&#34255;&#32422;&#26463;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;BO&#65289;&#24050;&#32463;&#25104;&#20026;&#35299;&#20915;&#22797;&#26434;&#20915;&#31574;&#38382;&#39064;&#30340;&#24378;&#22823;&#24037;&#20855;&#65292;&#23588;&#20854;&#22312;&#20844;&#20849;&#25919;&#31574;&#39046;&#22495;&#22914;&#35686;&#23519;&#21010;&#21306;&#26041;&#38754;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23450;&#20041;&#21487;&#34892;&#21306;&#22495;&#30340;&#22797;&#26434;&#24615;&#21644;&#20915;&#31574;&#30340;&#39640;&#32500;&#24230;&#65292;&#20854;&#22312;&#20844;&#20849;&#20915;&#31574;&#21046;&#23450;&#20013;&#30340;&#24191;&#27867;&#24212;&#29992;&#21463;&#21040;&#20102;&#38459;&#30861;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#8212;&#8212;&#38544;&#34255;&#32422;&#26463;&#28508;&#22312;&#31354;&#38388;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;HC-LSBO&#65289;&#65292;&#35813;&#26041;&#27861;&#38598;&#25104;&#20102;&#28508;&#22312;&#20915;&#31574;&#27169;&#22411;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#26469;&#23398;&#20064;&#21487;&#34892;&#20915;&#31574;&#30340;&#20998;&#24067;&#65292;&#23454;&#29616;&#20102;&#21407;&#22987;&#20915;&#31574;&#31354;&#38388;&#19982;&#36739;&#20302;&#32500;&#24230;&#30340;&#28508;&#22312;&#31354;&#38388;&#20043;&#38388;&#30340;&#21452;&#21521;&#26144;&#23556;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#24335;&#65292;HC-LSBO&#25429;&#25417;&#20102;&#20844;&#20849;&#20915;&#31574;&#21046;&#23450;&#20013;&#22266;&#26377;&#30340;&#38544;&#34255;&#32422;&#26463;&#30340;&#32454;&#24494;&#24046;&#21035;&#65292;&#22312;&#28508;&#22312;&#31354;&#38388;&#20013;&#36827;&#34892;&#20248;&#21270;&#30340;&#21516;&#26102;&#65292;&#22312;&#21407;&#22987;&#31354;&#38388;&#20013;&#35780;&#20272;&#30446;&#26631;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#36827;&#34892;&#25968;&#20540;&#23454;&#39564;&#26469;&#39564;&#35777;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#29305;&#21035;&#20851;&#27880;&#22823;&#35268;&#27169;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimization (BO) has emerged as a potent tool for addressing intricate decision-making challenges, especially in public policy domains such as police districting. However, its broader application in public policymaking is hindered by the complexity of defining feasible regions and the high-dimensionality of decisions. This paper introduces the Hidden-Constrained Latent Space Bayesian Optimization (HC-LSBO), a novel BO method integrated with a latent decision model. This approach leverages a variational autoencoder to learn the distribution of feasible decisions, enabling a two-way mapping between the original decision space and a lower-dimensional latent space. By doing so, HC-LSBO captures the nuances of hidden constraints inherent in public policymaking, allowing for optimization in the latent space while evaluating objectives in the original space. We validate our method through numerical experiments on both synthetic and real data sets, with a specific focus on large-scal
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;ExTRA&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#12290;&#36890;&#36807;&#30830;&#23450;&#28304;&#25968;&#25454;&#19978;&#30340;&#37325;&#35201;&#24615;&#26435;&#37325;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26368;&#23567;&#21270;&#21152;&#26435;&#28304;&#25968;&#25454;&#21644;&#30446;&#26631;&#25968;&#25454;&#38598;&#20043;&#38388;&#30340;KL&#25955;&#24230;&#12290;&#36890;&#36807;&#23454;&#39564;&#39564;&#35777;&#65292;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#36866;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.07424</link><description>&lt;p&gt;
&#36890;&#36807;&#25351;&#25968;&#20542;&#26012;&#35299;&#20915;RTB&#24066;&#22330;&#20013;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Addressing Distribution Shift in RTB Markets via Exponential Tilting. (arXiv:2308.07424v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07424
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;ExTRA&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#12290;&#36890;&#36807;&#30830;&#23450;&#28304;&#25968;&#25454;&#19978;&#30340;&#37325;&#35201;&#24615;&#26435;&#37325;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26368;&#23567;&#21270;&#21152;&#26435;&#28304;&#25968;&#25454;&#21644;&#30446;&#26631;&#25968;&#25454;&#38598;&#20043;&#38388;&#30340;KL&#25955;&#24230;&#12290;&#36890;&#36807;&#23454;&#39564;&#39564;&#35777;&#65292;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#30340;&#20998;&#24067;&#20559;&#31227;&#21487;&#33021;&#26159;&#24615;&#33021;&#19979;&#38477;&#30340;&#20027;&#35201;&#21407;&#22240;&#12290;&#26412;&#25991;&#28145;&#20837;&#25506;&#35752;&#20102;&#36825;&#20123;&#20559;&#31227;&#30340;&#29305;&#24615;&#65292;&#20027;&#35201;&#38024;&#23545;&#23454;&#26102;&#31454;&#20215;&#65288;RTB&#65289;&#24066;&#22330;&#27169;&#22411;&#30340;&#29305;&#28857;&#12290;&#25105;&#20204;&#24378;&#35843;&#20102;&#31867;&#21035;&#19981;&#24179;&#34913;&#21644;&#26679;&#26412;&#36873;&#25321;&#20559;&#24046;&#25152;&#24102;&#26469;&#30340;&#25361;&#25112;&#65292;&#36825;&#20004;&#32773;&#22343;&#26159;&#20998;&#24067;&#20559;&#31227;&#30340;&#24378;&#26377;&#21147;&#35825;&#22240;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;ExTRA&#65288;Exponential Tilt Reweighting Alignment&#65289;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#30001;Marty&#31561;&#20154;&#65288;2023&#65289;&#25552;&#20986;&#65292;&#29992;&#20110;&#35299;&#20915;&#25968;&#25454;&#20013;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#12290;ExTRA&#26041;&#27861;&#26088;&#22312;&#30830;&#23450;&#28304;&#25968;&#25454;&#19978;&#30340;&#37325;&#35201;&#24615;&#26435;&#37325;&#65292;&#20197;&#26368;&#23567;&#21270;&#21152;&#26435;&#28304;&#25968;&#25454;&#21644;&#30446;&#26631;&#25968;&#25454;&#38598;&#20043;&#38388;&#30340;KL&#25955;&#24230;&#12290;&#35813;&#26041;&#27861;&#30340;&#19968;&#20010;&#26174;&#33879;&#20248;&#28857;&#26159;&#23427;&#33021;&#22815;&#20351;&#29992;&#26377;&#26631;&#31614;&#30340;&#28304;&#25968;&#25454;&#21644;&#26080;&#26631;&#31614;&#30340;&#30446;&#26631;&#25968;&#25454;&#36827;&#34892;&#25805;&#20316;&#12290;&#36890;&#36807;&#27169;&#25311;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20998;&#24067;&#20559;&#31227;&#30340;&#24615;&#36136;&#65292;&#24182;&#35780;&#20272;&#20102;&#25152;&#25552;&#20986;&#27169;&#22411;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Distribution shift in machine learning models can be a primary cause of performance degradation. This paper delves into the characteristics of these shifts, primarily motivated by Real-Time Bidding (RTB) market models. We emphasize the challenges posed by class imbalance and sample selection bias, both potent instigators of distribution shifts. This paper introduces the Exponential Tilt Reweighting Alignment (ExTRA) algorithm, as proposed by Marty et al. (2023), to address distribution shifts in data. The ExTRA method is designed to determine the importance weights on the source data, aiming to minimize the KL divergence between the weighted source and target datasets. A notable advantage of this method is its ability to operate using labeled source data and unlabeled target data. Through simulated real-world data, we investigate the nature of distribution shift and evaluate the applicacy of the proposed model.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#36830;&#32493;&#20248;&#21270;&#22312;&#26377;&#21521;&#26080;&#29615;&#22270;&#32467;&#26500;&#23398;&#20064;&#20013;&#30340;&#20248;&#28857;&#21644;&#32570;&#28857;&#65292;&#20998;&#26512;&#20102;&#19981;&#30456;&#31561;&#22122;&#22768;&#26041;&#24046;&#20844;&#24335;&#20013;&#30340;&#38750;&#20984;&#24615;&#38382;&#39064;&#65292;&#24182;&#24314;&#35758;&#26410;&#26469;&#30740;&#31350;&#23558;&#26356;&#22810;&#22320;&#32771;&#34385;&#20808;&#39564;&#30693;&#35782;&#21644;&#24050;&#30693;&#32467;&#26500;&#65292;&#20197;&#23454;&#29616;&#26356;&#20581;&#22766;&#30340;&#20248;&#21270;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2304.02146</link><description>&lt;p&gt;
&#24102;&#36830;&#32493;&#20248;&#21270;&#30340;&#32467;&#26500;&#23398;&#20064;&#65306;&#23457;&#24910;&#35266;&#23519;&#21450;&#20854;&#21457;&#23637;
&lt;/p&gt;
&lt;p&gt;
Structure Learning with Continuous Optimization: A Sober Look and Beyond. (arXiv:2304.02146v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02146
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#36830;&#32493;&#20248;&#21270;&#22312;&#26377;&#21521;&#26080;&#29615;&#22270;&#32467;&#26500;&#23398;&#20064;&#20013;&#30340;&#20248;&#28857;&#21644;&#32570;&#28857;&#65292;&#20998;&#26512;&#20102;&#19981;&#30456;&#31561;&#22122;&#22768;&#26041;&#24046;&#20844;&#24335;&#20013;&#30340;&#38750;&#20984;&#24615;&#38382;&#39064;&#65292;&#24182;&#24314;&#35758;&#26410;&#26469;&#30740;&#31350;&#23558;&#26356;&#22810;&#22320;&#32771;&#34385;&#20808;&#39564;&#30693;&#35782;&#21644;&#24050;&#30693;&#32467;&#26500;&#65292;&#20197;&#23454;&#29616;&#26356;&#20581;&#22766;&#30340;&#20248;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#36830;&#32493;&#20248;&#21270;&#22312;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DAG&#65289;&#32467;&#26500;&#23398;&#20064;&#20013;&#30340;&#34920;&#29616;&#22909;&#22351;&#21450;&#20854;&#21407;&#22240;&#65292;&#24182;&#25552;&#20986;&#20102;&#21487;&#33021;&#20351;&#25628;&#32034;&#36807;&#31243;&#26356;&#21487;&#38752;&#30340;&#26041;&#21521;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#36830;&#32493;&#26041;&#27861;&#22312;&#20551;&#35774;&#22122;&#22768;&#26041;&#24046;&#30456;&#31561;&#21644;&#19981;&#30456;&#31561;&#30340;&#24773;&#20917;&#19979;&#30340;&#29616;&#35937;&#65292;&#24182;&#36890;&#36807;&#25552;&#20379;&#21453;&#20363;&#12289;&#29702;&#35770;&#35777;&#26126;&#21644;&#21487;&#33021;&#30340;&#26367;&#20195;&#35299;&#37322;&#26469;&#34920;&#26126;&#36825;&#31181;&#38472;&#36848;&#22312;&#20219;&#19968;&#24773;&#20917;&#19979;&#37117;&#21487;&#33021;&#19981;&#25104;&#31435;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;&#23545;&#20110;&#38750;&#30456;&#31561;&#22122;&#22768;&#26041;&#24046;&#20844;&#24335;&#65292;&#38750;&#20984;&#24615;&#21487;&#33021;&#26159;&#20027;&#35201;&#38382;&#39064;&#65292;&#32780;&#36830;&#32493;&#32467;&#26500;&#23398;&#20064;&#26041;&#38754;&#30340;&#26368;&#26032;&#36827;&#23637;&#21017;&#26080;&#27861;&#22312;&#23398;&#20064;&#36895;&#24230;&#21644;&#23454;&#29616;&#24471;&#20998;&#26041;&#38754;&#20248;&#20110;&#36138;&#24515;&#25628;&#32034;&#65292;&#24182;&#24314;&#35758;&#34701;&#21512;&#20808;&#39564;&#30693;&#35782;&#25110;&#24050;&#30693;&#32467;&#26500;&#30340;&#26356;&#20581;&#22766;&#30340;&#20248;&#21270;&#26041;&#27861;&#26159;&#26410;&#26469;&#30740;&#31350;&#30340;&#19968;&#20010;&#26377;&#24076;&#26395;&#30340;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates in which cases continuous optimization for directed acyclic graph (DAG) structure learning can and cannot perform well and why this happens, and suggests possible directions to make the search procedure more reliable. Reisach et al. (2021) suggested that the remarkable performance of several continuous structure learning approaches is primarily driven by a high agreement between the order of increasing marginal variances and the topological order, and demonstrated that these approaches do not perform well after data standardization. We analyze this phenomenon for continuous approaches assuming equal and non-equal noise variances, and show that the statement may not hold in either case by providing counterexamples, justifications, and possible alternative explanations. We further demonstrate that nonconvexity may be a main concern especially for the non-equal noise variances formulation, while recent advances in continuous structure learning fail to achieve impro
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#21464;&#37327;&#25968;&#37327;&#36828;&#22823;&#20110;&#26679;&#26412;&#22823;&#23567;&#30340;&#24773;&#20917;&#19979;&#65292;&#20934;&#30830;&#22320;&#20272;&#35745;&#22823;&#35268;&#27169;&#22240;&#26524;&#22810;&#26641;&#32467;&#26500;&#65292;&#32780;&#20960;&#20046;&#19981;&#38656;&#35201;&#20219;&#20309;&#20998;&#24067;&#25110;&#24314;&#27169;&#30340;&#20551;&#35774;&#12290;</title><link>http://arxiv.org/abs/2209.07028</link><description>&lt;p&gt;
&#20174;&#23567;&#26679;&#26412;&#20013;&#20272;&#35745;&#22823;&#30340;&#22240;&#26524;&#22810;&#26641;
&lt;/p&gt;
&lt;p&gt;
Estimating large causal polytrees from small samples. (arXiv:2209.07028v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.07028
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#21464;&#37327;&#25968;&#37327;&#36828;&#22823;&#20110;&#26679;&#26412;&#22823;&#23567;&#30340;&#24773;&#20917;&#19979;&#65292;&#20934;&#30830;&#22320;&#20272;&#35745;&#22823;&#35268;&#27169;&#22240;&#26524;&#22810;&#26641;&#32467;&#26500;&#65292;&#32780;&#20960;&#20046;&#19981;&#38656;&#35201;&#20219;&#20309;&#20998;&#24067;&#25110;&#24314;&#27169;&#30340;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20174;&#30456;&#23545;&#36739;&#23567;&#30340;&#29420;&#31435;&#21516;&#20998;&#24067;&#26679;&#26412;&#20013;&#20272;&#35745;&#22823;&#30340;&#22240;&#26524;&#22810;&#26641;&#30340;&#38382;&#39064;&#12290;&#36825;&#26159;&#22312;&#21464;&#37327;&#25968;&#37327;&#19982;&#26679;&#26412;&#22823;&#23567;&#30456;&#27604;&#38750;&#24120;&#22823;&#30340;&#24773;&#20917;&#19979;&#30830;&#23450;&#22240;&#26524;&#32467;&#26500;&#30340;&#38382;&#39064;&#65292;&#20363;&#22914;&#22522;&#22240;&#35843;&#25511;&#32593;&#32476;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#20197;&#39640;&#20934;&#30830;&#24230;&#24674;&#22797;&#26641;&#24418;&#32467;&#26500;&#12290;&#35813;&#31639;&#27861;&#38500;&#20102;&#19968;&#20123;&#28201;&#21644;&#30340;&#38750;&#36864;&#21270;&#26465;&#20214;&#22806;&#65292;&#22522;&#26412;&#19981;&#38656;&#35201;&#20998;&#24067;&#25110;&#24314;&#27169;&#30340;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of estimating a large causal polytree from a relatively small i.i.d. sample. This is motivated by the problem of determining causal structure when the number of variables is very large compared to the sample size, such as in gene regulatory networks. We give an algorithm that recovers the tree with high accuracy in such settings. The algorithm works under essentially no distributional or modeling assumptions other than some mild non-degeneracy conditions.
&lt;/p&gt;</description></item></channel></rss>