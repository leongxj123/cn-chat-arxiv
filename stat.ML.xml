<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#37325;&#26032;&#24605;&#32771;&#23545;&#25239;&#36870;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#31574;&#30053;&#27169;&#20223;&#21644;&#21487;&#36716;&#31227;&#22870;&#21169;&#24674;&#22797;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#28151;&#21512;&#26694;&#26550;PPO-AIRL + SAC&#20197;&#35299;&#20915;SAC&#31639;&#27861;&#22312;AIRL&#35757;&#32451;&#20013;&#26080;&#27861;&#20840;&#38754;&#35299;&#24320;&#22870;&#21169;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.14593</link><description>&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;&#23545;&#25239;&#36870;&#24378;&#21270;&#23398;&#20064;&#65306;&#20174;&#31574;&#30053;&#27169;&#20223;&#21644;&#21487;&#36716;&#31227;&#22870;&#21169;&#24674;&#22797;&#30340;&#35282;&#24230;
&lt;/p&gt;
&lt;p&gt;
Rethinking Adversarial Inverse Reinforcement Learning: From the Angles of Policy Imitation and Transferable Reward Recovery
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14593
&lt;/p&gt;
&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;&#23545;&#25239;&#36870;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#31574;&#30053;&#27169;&#20223;&#21644;&#21487;&#36716;&#31227;&#22870;&#21169;&#24674;&#22797;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#28151;&#21512;&#26694;&#26550;PPO-AIRL + SAC&#20197;&#35299;&#20915;SAC&#31639;&#27861;&#22312;AIRL&#35757;&#32451;&#20013;&#26080;&#27861;&#20840;&#38754;&#35299;&#24320;&#22870;&#21169;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#36870;&#24378;&#21270;&#23398;&#20064;&#65288;AIRL&#65289;&#20316;&#20026;&#27169;&#20223;&#23398;&#20064;&#20013;&#30340;&#22522;&#30707;&#26041;&#27861;&#12290;&#26412;&#25991;&#37325;&#26032;&#24605;&#32771;&#20102;AIRL&#30340;&#20004;&#20010;&#19981;&#21516;&#35282;&#24230;&#65306;&#31574;&#30053;&#27169;&#20223;&#21644;&#21487;&#36716;&#31227;&#22870;&#21169;&#24674;&#22797;&#12290;&#25105;&#20204;&#20174;&#29992;Soft Actor-Critic&#65288;SAC&#65289;&#26367;&#25442;AIRL&#20013;&#30340;&#20869;&#32622;&#31639;&#27861;&#24320;&#22987;&#65292;&#20197;&#22686;&#24378;&#26679;&#26412;&#25928;&#29575;&#65292;&#36825;&#35201;&#24402;&#21151;&#20110;SAC&#30340;&#31163;&#31574;&#30053;&#24418;&#24335;&#21644;&#30456;&#23545;&#20110;AIRL&#32780;&#35328;&#21487;&#35782;&#21035;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDP&#65289;&#27169;&#22411;&#12290;&#36825;&#30830;&#23454;&#22312;&#31574;&#30053;&#27169;&#20223;&#26041;&#38754;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#25913;&#36827;&#65292;&#20294;&#19981;&#24910;&#32473;&#21487;&#36716;&#31227;&#22870;&#21169;&#24674;&#22797;&#24102;&#26469;&#20102;&#32570;&#28857;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#38416;&#36848;&#20102;SAC&#31639;&#27861;&#26412;&#36523;&#22312;AIRL&#35757;&#32451;&#36807;&#31243;&#20013;&#26080;&#27861;&#20840;&#38754;&#35299;&#24320;&#22870;&#21169;&#20989;&#25968;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#28151;&#21512;&#26694;&#26550;&#65292;PPO-AIRL + SAC&#65292;&#20197;&#33719;&#24471;&#20196;&#20154;&#28385;&#24847;&#30340;&#36716;&#31227;&#25928;&#26524;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#29615;&#22659;&#25552;&#21462;&#35299;&#24320;&#30340;&#22870;&#21169;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14593v1 Announce Type: new  Abstract: Adversarial inverse reinforcement learning (AIRL) stands as a cornerstone approach in imitation learning. This paper rethinks the two different angles of AIRL: policy imitation and transferable reward recovery. We begin with substituting the built-in algorithm in AIRL with soft actor-critic (SAC) during the policy optimization process to enhance sample efficiency, thanks to the off-policy formulation of SAC and identifiable Markov decision process (MDP) models with respect to AIRL. It indeed exhibits a significant improvement in policy imitation but accidentally brings drawbacks to transferable reward recovery. To learn this issue, we illustrate that the SAC algorithm itself is not feasible to disentangle the reward function comprehensively during the AIRL training process, and propose a hybrid framework, PPO-AIRL + SAC, for satisfactory transfer effect. Additionally, we analyze the capability of environments to extract disentangled rewa
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#39046;&#22495;&#29305;&#23450;&#32467;&#26500;&#20449;&#24687;&#26469;&#24341;&#23548;&#20462;&#21098;&#30340;&#26041;&#27861; DASH &#22312;&#23398;&#20064;&#21160;&#24577;&#22522;&#22240;&#35843;&#25511;&#32593;&#32476;&#27169;&#22411;&#26102;&#34920;&#29616;&#20986;&#33394;&#65292;&#25552;&#20379;&#20102;&#26356;&#26377;&#24847;&#20041;&#30340;&#29983;&#29289;&#23398;&#35265;&#35299;</title><link>https://arxiv.org/abs/2403.04805</link><description>&lt;p&gt;
&#19981;&#26159;&#25152;&#26377;&#30340;&#31080;&#25454;&#37117;&#26159;&#24179;&#31561;&#30340;&#65292;&#32780;&#25105;&#20204;&#30693;&#36947;&#65306;&#29992;&#39046;&#22495;&#29305;&#23450;&#30693;&#35782;&#26469;&#24341;&#23548;&#20462;&#21098;
&lt;/p&gt;
&lt;p&gt;
Not all tickets are equal and we know it: Guiding pruning with domain-specific knowledge
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04805
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#39046;&#22495;&#29305;&#23450;&#32467;&#26500;&#20449;&#24687;&#26469;&#24341;&#23548;&#20462;&#21098;&#30340;&#26041;&#27861; DASH &#22312;&#23398;&#20064;&#21160;&#24577;&#22522;&#22240;&#35843;&#25511;&#32593;&#32476;&#27169;&#22411;&#26102;&#34920;&#29616;&#20986;&#33394;&#65292;&#25552;&#20379;&#20102;&#26356;&#26377;&#24847;&#20041;&#30340;&#29983;&#29289;&#23398;&#35265;&#35299;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32467;&#26500;&#23398;&#20064;&#23545;&#20110;&#31185;&#23398;&#21457;&#29616;&#21644;&#21487;&#35299;&#37322;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#24403;&#20195;&#20391;&#37325;&#20110;&#35745;&#31639;&#36164;&#28304;&#25928;&#29575;&#30340;&#20462;&#21098;&#31639;&#27861;&#22312;&#36873;&#25321;&#31526;&#21512;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#30340;&#26377;&#24847;&#20041;&#27169;&#22411;&#26041;&#38754;&#38754;&#20020;&#31639;&#27861;&#38556;&#30861;&#12290;&#20026;&#20102;&#20943;&#36731;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;DASH&#65292;&#21033;&#29992;&#21487;&#29992;&#30340;&#39046;&#22495;&#29305;&#23450;&#32467;&#26500;&#20449;&#24687;&#26469;&#24341;&#23548;&#20462;&#21098;&#12290;&#22312;&#23398;&#20064;&#21160;&#24577;&#22522;&#22240;&#35843;&#25511;&#32593;&#32476;&#27169;&#22411;&#30340;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;DASH&#19982;&#29616;&#26377;&#19968;&#33324;&#30693;&#35782;&#30456;&#32467;&#21512;&#65292;&#25552;&#20379;&#20102;&#19982;&#29983;&#29289;&#23398;&#19968;&#33268;&#30340;&#25968;&#25454;&#29305;&#23450;&#35265;&#35299;&#12290;&#23545;&#20110;&#36825;&#19968;&#20219;&#21153;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#20855;&#26377;&#22320;&#38754;&#30495;&#23454;&#20449;&#24687;&#30340;&#21512;&#25104;&#25968;&#25454;&#21644;&#20004;&#20010;&#30495;&#23454;&#19990;&#30028;&#24212;&#29992;&#20013;&#65292;DASH&#30340;&#26377;&#25928;&#24615;&#65292;&#20854;&#20248;&#20110;&#31454;&#20105;&#26041;&#27861;&#24456;&#22823;&#65292;&#24182;&#25552;&#20379;&#20102;&#26356;&#26377;&#24847;&#20041;&#30340;&#29983;&#29289;&#23398;&#35265;&#35299;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#34920;&#26126;&#65292;&#39046;&#22495;&#29305;&#23450;&#30340;&#32467;&#26500;&#20449;&#24687;&#20855;&#26377;&#25552;&#39640;&#27169;&#22411;&#34893;&#29983;&#31185;&#23398;&#27934;&#35265;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04805v1 Announce Type: new  Abstract: Neural structure learning is of paramount importance for scientific discovery and interpretability. Yet, contemporary pruning algorithms that focus on computational resource efficiency face algorithmic barriers to select a meaningful model that aligns with domain expertise. To mitigate this challenge, we propose DASH, which guides pruning by available domain-specific structural information. In the context of learning dynamic gene regulatory network models, we show that DASH combined with existing general knowledge on interaction partners provides data-specific insights aligned with biology. For this task, we show on synthetic data with ground truth information and two real world applications the effectiveness of DASH, which outperforms competing methods by a large margin and provides more meaningful biological insights. Our work shows that domain specific structural information bears the potential to improve model-derived scientific insi
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#21033;&#29992;&#19968;&#33268;&#24615;&#39044;&#27979;&#65292;&#25552;&#20379;&#22522;&#20110;&#27169;&#22411;&#29305;&#23450;&#20559;&#24046;&#30340;&#32622;&#20449;&#24230;&#37327;&#65292;&#20197;&#35299;&#20915;&#36873;&#25321;&#24615;&#22238;&#24402;&#20013;&#19981;&#30830;&#23450;&#24615;&#27979;&#37327;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.16300</link><description>&lt;p&gt;
Conformalized Selective Regression
&lt;/p&gt;
&lt;p&gt;
Conformalized Selective Regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16300
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#21033;&#29992;&#19968;&#33268;&#24615;&#39044;&#27979;&#65292;&#25552;&#20379;&#22522;&#20110;&#27169;&#22411;&#29305;&#23450;&#20559;&#24046;&#30340;&#32622;&#20449;&#24230;&#37327;&#65292;&#20197;&#35299;&#20915;&#36873;&#25321;&#24615;&#22238;&#24402;&#20013;&#19981;&#30830;&#23450;&#24615;&#27979;&#37327;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#27979;&#27169;&#22411;&#26159;&#21542;&#24635;&#26159;&#35201;&#25552;&#20379;&#39044;&#27979;&#65311;&#22312;&#36861;&#27714;&#26368;&#22823;&#39044;&#27979;&#24615;&#33021;&#30340;&#36807;&#31243;&#20013;&#65292;&#21487;&#38752;&#24615;&#21644;&#20844;&#24179;&#24615;&#24448;&#24448;&#34987;&#24573;&#35270;&#65292;&#23588;&#20854;&#26159;&#20851;&#20110;&#19981;&#30830;&#23450;&#24615;&#30340;&#20316;&#29992;&#12290;&#36873;&#25321;&#24615;&#22238;&#24402;&#65292;&#20063;&#31216;&#20026;&#8220;&#25298;&#32477;&#36873;&#39033;&#8221;&#65292;&#20801;&#35768;&#27169;&#22411;&#22312;&#23384;&#22312;&#30456;&#24403;&#22823;&#30340;&#19981;&#30830;&#23450;&#24615;&#24773;&#20917;&#19979;&#25918;&#24323;&#39044;&#27979;&#12290;&#23613;&#31649;7&#21313;&#24180;&#21069;&#23601;&#26368;&#21021;&#25552;&#20986;&#20102;&#36873;&#25321;&#24615;&#22238;&#24402;&#30340;&#26041;&#27861;&#65292;&#20294;&#22823;&#22810;&#25968;&#26041;&#27861;&#20027;&#35201;&#38598;&#20013;&#22312;&#29992;&#20110;&#27979;&#37327;&#19981;&#30830;&#23450;&#24615;&#30340;&#22522;&#20110;&#20998;&#24067;&#30340;&#20195;&#29702;&#65292;&#23588;&#20854;&#26159;&#26465;&#20214;&#26041;&#24046;&#12290;&#20294;&#36825;&#31181;&#20851;&#27880;&#24573;&#35270;&#20102;&#27169;&#22411;&#29305;&#23450;&#20559;&#24046;&#23545;&#27169;&#22411;&#24615;&#33021;&#30340;&#26174;&#33879;&#24433;&#21709;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36873;&#25321;&#24615;&#22238;&#24402;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#19968;&#33268;&#24615;&#39044;&#27979;&#65292;&#20026;&#22522;&#20110;&#27169;&#22411;&#29305;&#23450;&#20559;&#24046;&#30340;&#20010;&#21035;&#39044;&#27979;&#25552;&#20379;&#26377;&#26681;&#25454;&#30340;&#32622;&#20449;&#24230;&#24230;&#37327;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26631;&#20934;&#21270;&#30340;&#35780;&#20272;&#26694;&#26550;&#65292;&#20197;&#20415;&#36827;&#34892;&#24688;&#24403;&#30340;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16300v1 Announce Type: new  Abstract: Should prediction models always deliver a prediction? In the pursuit of maximum predictive performance, critical considerations of reliability and fairness are often overshadowed, particularly when it comes to the role of uncertainty. Selective regression, also known as the "reject option," allows models to abstain from predictions in cases of considerable uncertainty. Initially proposed seven decades ago, approaches to selective regression have mostly focused on distribution-based proxies for measuring uncertainty, particularly conditional variance. However, this focus neglects the significant influence of model-specific biases on a model's performance. In this paper, we propose a novel approach to selective regression by leveraging conformal prediction, which provides grounded confidence measures for individual predictions based on model-specific biases. In addition, we propose a standardized evaluation framework to allow proper compar
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#21644;&#19978;&#19979;&#25991;&#23398;&#20064;&#26041;&#27861;&#23454;&#29616;PDE&#36816;&#31639;&#31526;&#23398;&#20064;&#30340;&#39640;&#25928;&#26041;&#24335;&#65292;&#20197;&#25552;&#39640;&#25968;&#25454;&#25928;&#29575;&#24182;&#25913;&#21892;&#27169;&#22411;&#30340;&#22806;&#22495;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.15734</link><description>&lt;p&gt;
&#36890;&#36807;&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#21644;&#19978;&#19979;&#25991;&#23398;&#20064;&#23454;&#29616;&#39640;&#25928;&#30340;&#36816;&#31639;&#31526;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Data-Efficient Operator Learning via Unsupervised Pretraining and In-Context Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15734
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#21644;&#19978;&#19979;&#25991;&#23398;&#20064;&#26041;&#27861;&#23454;&#29616;PDE&#36816;&#31639;&#31526;&#23398;&#20064;&#30340;&#39640;&#25928;&#26041;&#24335;&#65292;&#20197;&#25552;&#39640;&#25968;&#25454;&#25928;&#29575;&#24182;&#25913;&#21892;&#27169;&#22411;&#30340;&#22806;&#22495;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#20154;&#20204;&#35265;&#35777;&#20102;&#23558;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#19982;&#29289;&#29702;&#39046;&#22495;&#29305;&#23450;&#27934;&#23519;&#21147;&#30456;&#32467;&#21512;&#65292;&#20197;&#35299;&#20915;&#22522;&#20110;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDEs&#65289;&#30340;&#31185;&#23398;&#38382;&#39064;&#30340;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#25968;&#25454;&#23494;&#38598;&#65292;&#36825;&#20123;&#26041;&#27861;&#20173;&#28982;&#38656;&#35201;&#22823;&#37327;PDE&#25968;&#25454;&#12290; &#36825;&#37325;&#26032;&#24341;&#20837;&#20102;&#23545;&#26114;&#36149;&#30340;&#25968;&#20540;PDE&#35299;&#20915;&#26041;&#26696;&#30340;&#38656;&#27714;&#65292;&#37096;&#20998;&#21066;&#24369;&#20102;&#36991;&#20813;&#36825;&#20123;&#26114;&#36149;&#27169;&#25311;&#30340;&#21407;&#22987;&#30446;&#26631;&#12290; &#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#20026;&#20102;&#23547;&#27714;&#25968;&#25454;&#25928;&#29575;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#29992;&#20110;PDE&#36816;&#31639;&#31526;&#23398;&#20064;&#30340;&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#21644;&#19978;&#19979;&#25991;&#23398;&#20064;&#26041;&#27861;&#12290; &#20026;&#20102;&#20943;&#23569;&#23545;&#24102;&#26377;&#27169;&#25311;&#35299;&#30340;&#35757;&#32451;&#25968;&#25454;&#30340;&#38656;&#27714;&#65292;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;&#37325;&#26500;&#30340;&#20195;&#29702;&#20219;&#21153;&#22312;&#26410;&#26631;&#35760;&#30340;PDE&#25968;&#25454;&#19978;&#39044;&#35757;&#32451;&#31070;&#32463;&#36816;&#31639;&#31526;&#12290; &#20026;&#20102;&#25552;&#39640;&#36229;&#20986;&#20998;&#24067;&#24615;&#33021;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#24110;&#21161;&#31070;&#32463;&#36816;&#31639;&#31526;&#28789;&#27963;&#22320;&#21033;&#29992;&#19978;&#19979;&#25991;&#23398;&#20064;&#26041;&#27861;&#65292;&#32780;&#26080;&#38656;&#39069;&#22806;&#30340;&#35757;&#32451;&#25104;&#26412;&#25110;&#35774;&#35745;&#12290; &#22312;&#21508;&#31181;PD&#19978;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#35777;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15734v1 Announce Type: new  Abstract: Recent years have witnessed the promise of coupling machine learning methods and physical domain-specific insight for solving scientific problems based on partial differential equations (PDEs). However, being data-intensive, these methods still require a large amount of PDE data. This reintroduces the need for expensive numerical PDE solutions, partially undermining the original goal of avoiding these expensive simulations. In this work, seeking data efficiency, we design unsupervised pretraining and in-context learning methods for PDE operator learning. To reduce the need for training data with simulated solutions, we pretrain neural operators on unlabeled PDE data using reconstruction-based proxy tasks. To improve out-of-distribution performance, we further assist neural operators in flexibly leveraging in-context learning methods, without incurring extra training costs or designs. Extensive empirical evaluations on a diverse set of PD
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25913;&#36827;&#20102;&#22522;&#20110;f-&#25955;&#24230;&#30340;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#65288;UDA&#65289;&#26694;&#26550;&#65292;&#24341;&#20837;&#20102;f-&#39046;&#22495;&#24046;&#24322;&#24230;&#37327;&#25351;&#26631;&#65292;&#24182;&#36890;&#36807;&#21435;&#38500;&#32477;&#23545;&#20540;&#20989;&#25968;&#21644;&#24341;&#20837;&#32553;&#25918;&#21442;&#25968;&#65292;&#25552;&#20986;&#20102;&#26032;&#30340;&#30446;&#26631;&#35823;&#24046;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#65292;&#20174;&#32780;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#24674;&#22797;&#20197;&#21069;&#30340;KL&#32467;&#26524;&#65292;&#23558;&#31639;&#27861;&#21644;&#29702;&#35770;&#20043;&#38388;&#30340;&#24046;&#36317;&#32553;&#23567;&#65292;&#24182;&#36890;&#36807;&#23450;&#20301;&#25216;&#26415;&#24320;&#21457;&#20102;&#24555;&#36895;&#29575;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20102;&#22522;&#20110;f-DD&#30340;&#39046;&#22495;&#23398;&#20064;&#31639;&#27861;&#22312;&#27969;&#34892;&#30340;UDA&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#20102;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.01887</link><description>&lt;p&gt;
&#22522;&#20110;f-&#25955;&#24230;&#21407;&#29702;&#30340;&#39046;&#22495;&#33258;&#36866;&#24212;&#65306;&#19968;&#20010;&#25913;&#36827;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
On f-Divergence Principled Domain Adaptation: An Improved Framework
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01887
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25913;&#36827;&#20102;&#22522;&#20110;f-&#25955;&#24230;&#30340;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#65288;UDA&#65289;&#26694;&#26550;&#65292;&#24341;&#20837;&#20102;f-&#39046;&#22495;&#24046;&#24322;&#24230;&#37327;&#25351;&#26631;&#65292;&#24182;&#36890;&#36807;&#21435;&#38500;&#32477;&#23545;&#20540;&#20989;&#25968;&#21644;&#24341;&#20837;&#32553;&#25918;&#21442;&#25968;&#65292;&#25552;&#20986;&#20102;&#26032;&#30340;&#30446;&#26631;&#35823;&#24046;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#65292;&#20174;&#32780;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#24674;&#22797;&#20197;&#21069;&#30340;KL&#32467;&#26524;&#65292;&#23558;&#31639;&#27861;&#21644;&#29702;&#35770;&#20043;&#38388;&#30340;&#24046;&#36317;&#32553;&#23567;&#65292;&#24182;&#36890;&#36807;&#23450;&#20301;&#25216;&#26415;&#24320;&#21457;&#20102;&#24555;&#36895;&#29575;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20102;&#22522;&#20110;f-DD&#30340;&#39046;&#22495;&#23398;&#20064;&#31639;&#27861;&#22312;&#27969;&#34892;&#30340;UDA&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#20102;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#65288;UDA&#65289;&#22312;&#35299;&#20915;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#20013;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#25913;&#36827;Acuna&#31561;&#20154;&#65288;2021&#24180;&#65289;&#25552;&#20986;&#30340;UDA&#30340;&#29702;&#35770;&#22522;&#30784;&#65292;&#23545;&#20854;&#22522;&#20110;f-&#25955;&#24230;&#30340;&#24046;&#24322;&#24230;&#36827;&#34892;&#20102;&#25913;&#36827;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#24230;&#37327;&#25351;&#26631;&#65292;&#21363;f-&#39046;&#22495;&#24046;&#24322;&#65288;f-DD&#65289;&#12290;&#36890;&#36807;&#21435;&#38500;&#32477;&#23545;&#20540;&#20989;&#25968;&#24182;&#24341;&#20837;&#19968;&#20010;&#32553;&#25918;&#21442;&#25968;&#65292;f-DD&#20135;&#29983;&#20102;&#26032;&#30340;&#30446;&#26631;&#35823;&#24046;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#24674;&#22797;&#20197;&#21069;&#22522;&#20110;KL&#30340;&#32467;&#26524;&#65292;&#24182;&#24357;&#21512;&#20102;Acuna&#31561;&#20154;&#65288;2021&#24180;&#65289;&#20013;&#25552;&#20986;&#30340;&#31639;&#27861;&#21644;&#29702;&#35770;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#21033;&#29992;&#23450;&#20301;&#25216;&#26415;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#24555;&#36895;&#29575;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#27969;&#34892;&#30340;UDA&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;&#22522;&#20110;f-DD&#30340;&#39046;&#22495;&#23398;&#20064;&#31639;&#27861;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Unsupervised domain adaptation (UDA) plays a crucial role in addressing distribution shifts in machine learning. In this work, we improve the theoretical foundations of UDA proposed by Acuna et al. (2021) by refining their f-divergence-based discrepancy and additionally introducing a new measure, f-domain discrepancy (f-DD). By removing the absolute value function and incorporating a scaling parameter, f-DD yields novel target error and sample complexity bounds, allowing us to recover previous KL-based results and bridging the gap between algorithms and theory presented in Acuna et al. (2021). Leveraging a localization technique, we also develop a fast-rate generalization bound. Empirical results demonstrate the superior performance of f-DD-based domain learning algorithms over previous works in popular UDA benchmarks.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#22810;&#23610;&#24230;&#38669;&#22855;&#25955;&#23556;&#32593;&#32476;&#65288;MHSNs&#65289;&#65292;&#21033;&#29992;&#22810;&#23610;&#24230;&#22522;&#30784;&#35789;&#20856;&#21644;&#21367;&#31215;&#32467;&#26500;&#65292;&#29983;&#25104;&#23545;&#33410;&#28857;&#25490;&#21015;&#19981;&#21464;&#30340;&#29305;&#24449;&#12290;</title><link>https://arxiv.org/abs/2311.10270</link><description>&lt;p&gt;
&#29992;&#20110;&#25968;&#25454;&#20998;&#26512;&#30340;&#22810;&#23610;&#24230;&#38669;&#22855;&#25955;&#23556;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Multiscale Hodge Scattering Networks for Data Analysis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.10270
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#22810;&#23610;&#24230;&#38669;&#22855;&#25955;&#23556;&#32593;&#32476;&#65288;MHSNs&#65289;&#65292;&#21033;&#29992;&#22810;&#23610;&#24230;&#22522;&#30784;&#35789;&#20856;&#21644;&#21367;&#31215;&#32467;&#26500;&#65292;&#29983;&#25104;&#23545;&#33410;&#28857;&#25490;&#21015;&#19981;&#21464;&#30340;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25955;&#23556;&#32593;&#32476;&#65292;&#29992;&#20110;&#22312;&#21333;&#32431;&#22797;&#21512;&#20223;&#23556;&#19978;&#27979;&#37327;&#30340;&#20449;&#21495;&#65292;&#31216;&#20026;\emph{&#22810;&#23610;&#24230;&#38669;&#22855;&#25955;&#23556;&#32593;&#32476;}&#65288;MHSNs&#65289;&#12290;&#25105;&#20204;&#30340;&#26500;&#36896;&#22522;&#20110;&#21333;&#32431;&#22797;&#21512;&#20223;&#23556;&#19978;&#30340;&#22810;&#23610;&#24230;&#22522;&#30784;&#35789;&#20856;&#65292;&#21363;$\kappa$-GHWT&#21644;$\kappa$-HGLET&#65292;&#25105;&#20204;&#26368;&#36817;&#20026;&#32473;&#23450;&#21333;&#32431;&#22797;&#21512;&#20223;&#23556;&#20013;&#30340;&#32500;&#24230;$\kappa \in \mathbb{N}$&#25512;&#24191;&#20102;&#22522;&#20110;&#33410;&#28857;&#30340;&#24191;&#20041;&#21704;-&#27779;&#20160;&#21464;&#25442;&#65288;GHWT&#65289;&#21644;&#20998;&#23618;&#22270;&#25289;&#26222;&#25289;&#26031;&#29305;&#24449;&#21464;&#25442;&#65288;HGLET&#65289;&#12290;$\kappa$-GHWT&#21644;$\kappa$-HGLET&#37117;&#24418;&#25104;&#20887;&#20313;&#38598;&#21512;&#65288;&#21363;&#35789;&#20856;&#65289;&#30340;&#22810;&#23610;&#24230;&#22522;&#30784;&#21521;&#37327;&#21644;&#32473;&#23450;&#20449;&#21495;&#30340;&#30456;&#24212;&#25193;&#23637;&#31995;&#25968;&#12290;&#25105;&#20204;&#30340;MHSNs&#20351;&#29992;&#31867;&#20284;&#20110;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#30340;&#20998;&#23618;&#32467;&#26500;&#26469;&#32423;&#32852;&#35789;&#20856;&#31995;&#25968;&#27169;&#30340;&#30697;&#12290;&#25152;&#24471;&#29305;&#24449;&#23545;&#21333;&#32431;&#22797;&#21512;&#20223;&#23556;&#30340;&#37325;&#26032;&#25490;&#24207;&#19981;&#21464;&#65288;&#21363;&#33410;&#28857;&#25490;&#21015;&#30340;&#32622;&#25442;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.10270v2 Announce Type: replace  Abstract: We propose new scattering networks for signals measured on simplicial complexes, which we call \emph{Multiscale Hodge Scattering Networks} (MHSNs). Our construction is based on multiscale basis dictionaries on simplicial complexes, i.e., the $\kappa$-GHWT and $\kappa$-HGLET, which we recently developed for simplices of dimension $\kappa \in \mathbb{N}$ in a given simplicial complex by generalizing the node-based Generalized Haar-Walsh Transform (GHWT) and Hierarchical Graph Laplacian Eigen Transform (HGLET). The $\kappa$-GHWT and the $\kappa$-HGLET both form redundant sets (i.e., dictionaries) of multiscale basis vectors and the corresponding expansion coefficients of a given signal. Our MHSNs use a layered structure analogous to a convolutional neural network (CNN) to cascade the moments of the modulus of the dictionary coefficients. The resulting features are invariant to reordering of the simplices (i.e., node permutation of the u
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36229;&#36234;&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#20351;&#40657;&#30418;&#27169;&#22411;&#21487;&#24178;&#39044;&#12290;&#36890;&#36807;&#22522;&#20110;&#27010;&#24565;&#30340;&#24178;&#39044;&#26469;&#24433;&#21709;&#27169;&#22411;&#30340;&#36755;&#20986;&#65292;&#24182;&#21033;&#29992;&#36825;&#31181;&#26041;&#27861;&#23545;&#40657;&#30418;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#24494;&#35843;&#21487;&#20197;&#25552;&#39640;&#24178;&#39044;&#30340;&#25928;&#26524;&#65292;&#24182;&#20135;&#29983;&#26356;&#22909;&#26657;&#20934;&#30340;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2401.13544</link><description>&lt;p&gt;
&#36229;&#36234;&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#65306;&#22914;&#20309;&#20351;&#40657;&#30418;&#27169;&#22411;&#21487;&#24178;&#39044;&#65311;
&lt;/p&gt;
&lt;p&gt;
Beyond Concept Bottleneck Models: How to Make Black Boxes Intervenable?. (arXiv:2401.13544v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13544
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36229;&#36234;&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#20351;&#40657;&#30418;&#27169;&#22411;&#21487;&#24178;&#39044;&#12290;&#36890;&#36807;&#22522;&#20110;&#27010;&#24565;&#30340;&#24178;&#39044;&#26469;&#24433;&#21709;&#27169;&#22411;&#30340;&#36755;&#20986;&#65292;&#24182;&#21033;&#29992;&#36825;&#31181;&#26041;&#27861;&#23545;&#40657;&#30418;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#24494;&#35843;&#21487;&#20197;&#25552;&#39640;&#24178;&#39044;&#30340;&#25928;&#26524;&#65292;&#24182;&#20135;&#29983;&#26356;&#22909;&#26657;&#20934;&#30340;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#21487;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#37325;&#26032;&#25506;&#32034;&#20102;&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#65288;CBM&#65289;&#65292;&#21253;&#25324;&#20174;&#21407;&#22987;&#29305;&#24449;&#20013;&#36880;&#27493;&#39044;&#27979;&#39640;&#32423;&#27010;&#24565;&#21644;&#20174;&#39044;&#27979;&#30340;&#27010;&#24565;&#20013;&#39044;&#27979;&#30446;&#26631;&#21464;&#37327;&#12290;&#36825;&#20010;&#27169;&#22411;&#31867;&#21035;&#30340;&#19968;&#20010;&#24341;&#20154;&#27880;&#30446;&#30340;&#20248;&#21183;&#26159;&#29992;&#25143;&#33021;&#22815;&#23545;&#39044;&#27979;&#30340;&#27010;&#24565;&#20540;&#36827;&#34892;&#24178;&#39044;&#65292;&#20174;&#32780;&#24433;&#21709;&#27169;&#22411;&#30340;&#19979;&#28216;&#36755;&#20986;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#22312;&#24050;&#32463;&#35757;&#32451;&#22909;&#20294;&#26412;&#36136;&#19978;&#19981;&#21487;&#35299;&#37322;&#30340;&#31070;&#32463;&#32593;&#32476;&#19978;&#36827;&#34892;&#22522;&#20110;&#27010;&#24565;&#30340;&#24178;&#39044;&#65292;&#32473;&#23450;&#19968;&#20010;&#24102;&#26377;&#27880;&#37322;&#30340;&#39564;&#35777;&#38598;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#27169;&#22411;&#30340;&#21487;&#24178;&#39044;&#24615;&#23450;&#20041;&#20026;&#22522;&#20110;&#27010;&#24565;&#24178;&#39044;&#30340;&#26377;&#25928;&#24615;&#30340;&#24230;&#37327;&#65292;&#24182;&#21033;&#29992;&#36825;&#20010;&#23450;&#20041;&#26469;&#23545;&#40657;&#30418;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#12290;&#23454;&#35777;&#19978;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#21512;&#25104;&#34920;&#26684;&#25968;&#25454;&#21644;&#33258;&#28982;&#22270;&#20687;&#22522;&#20934;&#19978;&#40657;&#30418;&#20998;&#31867;&#22120;&#30340;&#24178;&#39044;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#24494;&#35843;&#25552;&#39640;&#20102;&#24178;&#39044;&#30340;&#25928;&#26524;&#65292;&#24182;&#32463;&#24120;&#20135;&#29983;&#26356;&#22909;&#26657;&#20934;&#30340;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, interpretable machine learning has re-explored concept bottleneck models (CBM), comprising step-by-step prediction of the high-level concepts from the raw features and the target variable from the predicted concepts. A compelling advantage of this model class is the user's ability to intervene on the predicted concept values, affecting the model's downstream output. In this work, we introduce a method to perform such concept-based interventions on already-trained neural networks, which are not interpretable by design, given an annotated validation set. Furthermore, we formalise the model's intervenability as a measure of the effectiveness of concept-based interventions and leverage this definition to fine-tune black-box models. Empirically, we explore the intervenability of black-box classifiers on synthetic tabular and natural image benchmarks. We demonstrate that fine-tuning improves intervention effectiveness and often yields better-calibrated predictions. To showcase the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#21435;&#22122;&#25193;&#25955;&#21464;&#20998;&#25512;&#26029;&#65288;DDVI&#65289;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#34920;&#36798;&#24615;&#21464;&#20998;&#21518;&#39564;&#65292;&#24182;&#36890;&#36807;&#21453;&#36716;&#21152;&#22122;&#36807;&#31243;&#22312;&#28508;&#31354;&#38388;&#20013;&#36827;&#34892;&#25193;&#25955;&#12290;&#35813;&#26041;&#27861;&#26131;&#20110;&#23454;&#29616;&#65292;&#20860;&#23481;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#65292;&#24182;&#22312;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#20013;&#30340;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>http://arxiv.org/abs/2401.02739</link><description>&lt;p&gt;
&#25193;&#25955;&#21464;&#20998;&#25512;&#26029;&#65306;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#34920;&#36798;&#24615;&#21464;&#20998;&#21518;&#39564;
&lt;/p&gt;
&lt;p&gt;
Diffusion Variational Inference: Diffusion Models as Expressive Variational Posteriors. (arXiv:2401.02739v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02739
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#21435;&#22122;&#25193;&#25955;&#21464;&#20998;&#25512;&#26029;&#65288;DDVI&#65289;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#34920;&#36798;&#24615;&#21464;&#20998;&#21518;&#39564;&#65292;&#24182;&#36890;&#36807;&#21453;&#36716;&#21152;&#22122;&#36807;&#31243;&#22312;&#28508;&#31354;&#38388;&#20013;&#36827;&#34892;&#25193;&#25955;&#12290;&#35813;&#26041;&#27861;&#26131;&#20110;&#23454;&#29616;&#65292;&#20860;&#23481;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#65292;&#24182;&#22312;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#20013;&#30340;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#21435;&#22122;&#25193;&#25955;&#21464;&#20998;&#25512;&#26029;&#65288;DDVI&#65289;&#65292;&#19968;&#31181;&#29992;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#34920;&#36798;&#24615;&#21464;&#20998;&#21518;&#39564;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#36817;&#20284;&#25512;&#26029;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#36741;&#21161;&#28508;&#21464;&#37327;&#22686;&#21152;&#20102;&#21464;&#20998;&#21518;&#39564;&#65292;&#20174;&#32780;&#24471;&#21040;&#19968;&#20010;&#34920;&#36798;&#24615;&#30340;&#27169;&#22411;&#31867;&#65292;&#36890;&#36807;&#21453;&#36716;&#29992;&#25143;&#25351;&#23450;&#30340;&#21152;&#22122;&#36807;&#31243;&#22312;&#28508;&#31354;&#38388;&#20013;&#36827;&#34892;&#25193;&#25955;&#12290;&#25105;&#20204;&#36890;&#36807;&#20248;&#21270;&#19968;&#20010;&#21463;&#21040;&#35273;&#37266;-&#30561;&#30496;&#31639;&#27861;&#21551;&#21457;&#30340;&#36793;&#38469;&#20284;&#28982;&#26032;&#19979;&#30028;&#26469;&#25311;&#21512;&#36825;&#20123;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26131;&#20110;&#23454;&#29616;&#65288;&#23427;&#36866;&#37197;&#20102;&#27491;&#21017;&#21270;&#30340;ELBO&#25193;&#23637;&#65289;&#65292;&#19982;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#20860;&#23481;&#65292;&#24182;&#19988;&#34920;&#29616;&#20248;&#20110;&#22522;&#20110;&#24402;&#19968;&#21270;&#27969;&#25110;&#23545;&#25239;&#32593;&#32476;&#30340;&#26367;&#20195;&#36817;&#20284;&#21518;&#39564;&#31867;&#21035;&#12290;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#26102;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24471;&#21040;&#20102;&#21435;&#22122;&#25193;&#25955;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;DD-VAE&#65289;&#31639;&#27861;&#12290;&#25105;&#20204;&#23558;&#35813;&#31639;&#27861;&#24212;&#29992;&#20110;&#29983;&#29289;&#23398;&#20013;&#30340;&#19968;&#20010;&#28608;&#21169;&#20219;&#21153; -- &#20174;&#20154;&#31867;&#22522;&#22240;&#32452;&#20013;&#25512;&#26029;&#28508;&#22312;&#34880;&#32479; -- &#36229;&#36807;&#20102;&#24378;&#22522;&#32447;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose denoising diffusion variational inference (DDVI), an approximate inference algorithm for latent variable models which relies on diffusion models as expressive variational posteriors. Our method augments variational posteriors with auxiliary latents, which yields an expressive class of models that perform diffusion in latent space by reversing a user-specified noising process. We fit these models by optimizing a novel lower bound on the marginal likelihood inspired by the wake-sleep algorithm. Our method is easy to implement (it fits a regularized extension of the ELBO), is compatible with black-box variational inference, and outperforms alternative classes of approximate posteriors based on normalizing flows or adversarial networks. When applied to deep latent variable models, our method yields the denoising diffusion VAE (DD-VAE) algorithm. We use this algorithm on a motivating task in biology -- inferring latent ancestry from human genomes -- outperforming strong baselines
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39640;&#32500;&#22240;&#26524;&#25512;&#26029;&#30340;&#27169;&#22359;&#21270;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#23398;&#20064;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#27169;&#22411;&#26469;&#22238;&#31572;&#30001;&#39640;&#32500;&#25968;&#25454;&#24341;&#36215;&#30340;&#22240;&#26524;&#26597;&#35810;&#12290;</title><link>http://arxiv.org/abs/2401.01426</link><description>&lt;p&gt;
&#39640;&#32500;&#22240;&#26524;&#25512;&#26029;&#30340;&#27169;&#22359;&#21270;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Modular Learning of Deep Causal Generative Models for High-dimensional Causal Inference. (arXiv:2401.01426v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01426
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39640;&#32500;&#22240;&#26524;&#25512;&#26029;&#30340;&#27169;&#22359;&#21270;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#23398;&#20064;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#27169;&#22411;&#26469;&#22238;&#31572;&#30001;&#39640;&#32500;&#25968;&#25454;&#24341;&#36215;&#30340;&#22240;&#26524;&#26597;&#35810;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Pearl&#30340;&#22240;&#26524;&#23618;&#27425;&#32467;&#26500;&#22312;&#35266;&#27979;&#12289;&#24178;&#39044;&#21644;&#21453;&#20107;&#23454;&#38382;&#39064;&#20043;&#38388;&#24314;&#31435;&#20102;&#26126;&#30830;&#30340;&#20998;&#31163;&#12290;&#30740;&#31350;&#20154;&#21592;&#25552;&#20986;&#20102;&#35745;&#31639;&#21487;&#36776;&#35782;&#22240;&#26524;&#26597;&#35810;&#30340;&#22768;&#38899;&#21644;&#23436;&#25972;&#31639;&#27861;&#65292;&#22312;&#32473;&#23450;&#23618;&#27425;&#30340;&#22240;&#26524;&#32467;&#26500;&#21644;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#20351;&#29992;&#36739;&#20302;&#23618;&#27425;&#30340;&#23618;&#27425;&#30340;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#36825;&#20123;&#31639;&#27861;&#20551;&#35774;&#25105;&#20204;&#21487;&#20197;&#20934;&#30830;&#20272;&#35745;&#25968;&#25454;&#30340;&#27010;&#29575;&#20998;&#24067;&#65292;&#36825;&#23545;&#20110;&#22914;&#22270;&#20687;&#36825;&#26679;&#30340;&#39640;&#32500;&#21464;&#37327;&#26159;&#19968;&#20010;&#19981;&#20999;&#23454;&#38469;&#30340;&#20551;&#35774;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#29616;&#20195;&#29983;&#25104;&#24335;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#21487;&#20197;&#34987;&#35757;&#32451;&#26469;&#23398;&#20064;&#22914;&#20309;&#20934;&#30830;&#22320;&#20174;&#36825;&#26679;&#30340;&#39640;&#32500;&#20998;&#24067;&#20013;&#37319;&#26679;&#12290;&#29305;&#21035;&#26159;&#38543;&#30528;&#22270;&#20687;&#22522;&#27169;&#22411;&#30340;&#26368;&#36817;&#20852;&#36215;&#65292;&#21033;&#29992;&#39044;&#35757;&#32451;&#27169;&#22411;&#26469;&#22238;&#31572;&#24102;&#26377;&#36825;&#26679;&#39640;&#32500;&#25968;&#25454;&#30340;&#22240;&#26524;&#26597;&#35810;&#26159;&#38750;&#24120;&#26377;&#21560;&#24341;&#21147;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#39034;&#24207;&#35757;&#32451;&#31639;&#27861;&#65292;&#32473;&#23450;&#22240;&#26524;&#32467;&#26500;&#21644;&#39044;&#35757;&#32451;&#30340;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#65292;&#21487;&#20197;&#35757;&#32451;&#19968;&#20010;&#27169;&#22411;&#26469;&#20272;&#35745;&#30001;&#39640;&#32500;&#25968;&#25454;&#24341;&#36215;&#30340;&#22240;&#26524;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pearl's causal hierarchy establishes a clear separation between observational, interventional, and counterfactual questions. Researchers proposed sound and complete algorithms to compute identifiable causal queries at a given level of the hierarchy using the causal structure and data from the lower levels of the hierarchy. However, most of these algorithms assume that we can accurately estimate the probability distribution of the data, which is an impractical assumption for high-dimensional variables such as images. On the other hand, modern generative deep learning architectures can be trained to learn how to accurately sample from such high-dimensional distributions. Especially with the recent rise of foundation models for images, it is desirable to leverage pre-trained models to answer causal queries with such high-dimensional data. To address this, we propose a sequential training algorithm that, given the causal structure and a pre-trained conditional generative model, can train a
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#21327;&#21464;&#37327;&#20559;&#31227;&#19979;&#30340;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#32597;&#35265;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#24212;&#24615;&#26041;&#27861;&#26469;&#20943;&#36731;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#20559;&#24046;&#23545;&#27169;&#22411;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2310.16638</link><description>&lt;p&gt;
&#36866;&#24212;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#21327;&#21464;&#37327;&#20559;&#31227;&#36866;&#24212;
&lt;/p&gt;
&lt;p&gt;
Covariate Shift Adaptation Robust to Density-Ratio Estimation. (arXiv:2310.16638v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16638
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#21327;&#21464;&#37327;&#20559;&#31227;&#19979;&#30340;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#32597;&#35265;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#24212;&#24615;&#26041;&#27861;&#26469;&#20943;&#36731;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#20559;&#24046;&#23545;&#27169;&#22411;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#19968;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#21487;&#20197;&#35775;&#38382;&#20855;&#26377;&#21327;&#21464;&#37327;&#21644;&#32467;&#26524;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#32780;&#27979;&#35797;&#25968;&#25454;&#21482;&#21253;&#21547;&#21327;&#21464;&#37327;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#20027;&#35201;&#30446;&#26631;&#26159;&#39044;&#27979;&#27979;&#35797;&#25968;&#25454;&#20013;&#32570;&#22833;&#30340;&#32467;&#26524;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20010;&#30446;&#26631;&#65292;&#25105;&#20204;&#22312;&#21327;&#21464;&#37327;&#20559;&#31227;&#19979;&#35757;&#32451;&#21442;&#25968;&#22238;&#24402;&#27169;&#22411;&#65292;&#20854;&#20013;&#35757;&#32451;&#25968;&#25454;&#21644;&#27979;&#35797;&#25968;&#25454;&#20043;&#38388;&#30340;&#21327;&#21464;&#37327;&#20998;&#24067;&#19981;&#21516;&#12290;&#23545;&#20110;&#36825;&#20010;&#38382;&#39064;&#65292;&#29616;&#26377;&#30740;&#31350;&#25552;&#20986;&#20102;&#36890;&#36807;&#20351;&#29992;&#23494;&#24230;&#27604;&#30340;&#37325;&#35201;&#24615;&#21152;&#26435;&#26469;&#36827;&#34892;&#21327;&#21464;&#37327;&#20559;&#31227;&#36866;&#24212;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#23545;&#35757;&#32451;&#25968;&#25454;&#25439;&#22833;&#36827;&#34892;&#21152;&#26435;&#24179;&#22343;&#65292;&#27599;&#20010;&#26435;&#37325;&#26159;&#35757;&#32451;&#25968;&#25454;&#21644;&#27979;&#35797;&#25968;&#25454;&#20043;&#38388;&#30340;&#21327;&#21464;&#37327;&#23494;&#24230;&#27604;&#30340;&#20272;&#35745;&#65292;&#20197;&#36817;&#20284;&#27979;&#35797;&#25968;&#25454;&#30340;&#39118;&#38505;&#12290;&#23613;&#31649;&#23427;&#20801;&#35768;&#25105;&#20204;&#33719;&#24471;&#19968;&#20010;&#26368;&#23567;&#21270;&#27979;&#35797;&#25968;&#25454;&#39118;&#38505;&#30340;&#27169;&#22411;&#65292;&#20294;&#20854;&#24615;&#33021;&#20005;&#37325;&#20381;&#36182;&#20110;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#12290;&#27492;&#22806;&#65292;&#21363;&#20351;&#23494;&#24230;&#27604;&#21487;&#20197;&#19968;&#33268;&#22320;&#20272;&#35745;&#65292;&#23494;&#24230;&#27604;&#30340;&#20272;&#35745;&#35823;&#24046;&#20063;&#20250;&#23548;&#33268;&#22238;&#24402;&#27169;&#22411;&#30340;&#20272;&#35745;&#22120;&#20135;&#29983;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Consider a scenario where we have access to train data with both covariates and outcomes while test data only contains covariates. In this scenario, our primary aim is to predict the missing outcomes of the test data. With this objective in mind, we train parametric regression models under a covariate shift, where covariate distributions are different between the train and test data. For this problem, existing studies have proposed covariate shift adaptation via importance weighting using the density ratio. This approach averages the train data losses, each weighted by an estimated ratio of the covariate densities between the train and test data, to approximate the test-data risk. Although it allows us to obtain a test-data risk minimizer, its performance heavily relies on the accuracy of the density ratio estimation. Moreover, even if the density ratio can be consistently estimated, the estimation errors of the density ratio also yield bias in the estimators of the regression model's 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#20294;&#26377;&#25928;&#30340;&#22810;&#30446;&#26631;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;Thompson&#37319;&#26679;&#20174;GP Pareto&#21069;&#27839;&#20013;&#36873;&#25321;&#26032;&#30340;&#20505;&#36873;&#32773;&#65292;&#36991;&#20813;&#20102;&#32321;&#26434;&#30340;&#33719;&#21462;&#20989;&#25968;&#20248;&#21270;&#27493;&#39588;&#12290;</title><link>http://arxiv.org/abs/2310.15788</link><description>&lt;p&gt;
qPOTS: &#39640;&#25928;&#30340;&#25209;&#37327;&#22810;&#30446;&#26631;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
qPOTS: Efficient batch multiobjective Bayesian optimization via Pareto optimal Thompson sampling. (arXiv:2310.15788v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15788
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#20294;&#26377;&#25928;&#30340;&#22810;&#30446;&#26631;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;Thompson&#37319;&#26679;&#20174;GP Pareto&#21069;&#27839;&#20013;&#36873;&#25321;&#26032;&#30340;&#20505;&#36873;&#32773;&#65292;&#36991;&#20813;&#20102;&#32321;&#26434;&#30340;&#33719;&#21462;&#20989;&#25968;&#20248;&#21270;&#27493;&#39588;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#36827;&#21270;&#26041;&#27861;&#22312;&#22810;&#30446;&#26631;&#20248;&#21270;&#20013;&#38750;&#24120;&#26377;&#25928;&#65292;&#20294;&#23545;&#30446;&#26631;&#36827;&#34892;&#22823;&#37327;&#26597;&#35810;&#21487;&#33021;&#19981;&#21033;&#20110;&#30446;&#26631;&#33457;&#36153;&#24456;&#22810;&#25110;&#32773;&#35745;&#31639;&#37327;&#24456;&#22823;&#30340;&#26102;&#20505;&#12290;&#29992;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#26367;&#20195;&#29289;&#21644;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;BO&#65289;&#26469;&#35299;&#20915;&#22810;&#30446;&#26631;&#20248;&#21270;&#26159;&#19968;&#31181;&#39640;&#25928;&#30340;&#26041;&#27861;&#12290;&#22810;&#30446;&#26631;&#36125;&#21494;&#26031;&#20248;&#21270;(MOBO)&#28041;&#21450;&#26500;&#24314;&#19968;&#20010;&#34987;&#20248;&#21270;&#29992;&#26469;&#33719;&#24471;&#26032;&#35266;&#23519;&#20505;&#36873;&#30340;&#33719;&#21462;&#20989;&#25968;&#12290;&#36825;&#20010;&#8220;&#20869;&#37096;&#8221;&#20248;&#21270;&#21487;&#33021;&#24456;&#22256;&#38590;&#65292;&#22240;&#20026;&#33719;&#21462;&#20989;&#25968;&#26159;&#38750;&#20984;&#30340;&#65292;&#19981;&#21487;&#24494;&#30340;&#21644;/&#25110;&#32773;&#19981;&#20986;&#27874;&#65292;MOBO&#30340;&#25104;&#21151;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#20381;&#36182;&#20110;&#36825;&#20010;&#20869;&#37096;&#20248;&#21270;&#12290;&#25105;&#20204;&#25682;&#24323;&#36825;&#20010;&#22256;&#38590;&#30340;&#33719;&#21462;&#20989;&#25968;&#20248;&#21270;&#27493;&#39588;&#65292;&#25552;&#20986;&#19968;&#31181;&#31616;&#21333;&#20294;&#26377;&#25928;&#30340;&#22522;&#20110;Thompson&#37319;&#26679;&#30340;&#26041;&#27861;($q\texttt{POTS}$)&#65292;&#20854;&#20013;&#26032;&#30340;&#20505;&#36873;&#32773;&#26159;&#20174;&#36890;&#36807;&#27714;&#35299;&#19968;&#20010;&#26356;&#20415;&#23452;&#30340;&#22810;&#20010;&#21518;&#39564;&#26679;&#26412;&#36335;&#24452;&#30340;GP Pareto&#21069;&#27839;&#20013;&#36873;&#25321;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Classical evolutionary approaches for multiobjective optimization are quite effective but incur a lot of queries to the objectives; this can be prohibitive when objectives are expensive oracles. A sample-efficient approach to solving multiobjective optimization is via Gaussian process (GP) surrogates and Bayesian optimization (BO). Multiobjective Bayesian optimization (MOBO) involves the construction of an acquisition function which is optimized to acquire new observation candidates. This ``inner'' optimization can be hard due to various reasons: acquisition functions being nonconvex, nondifferentiable and/or unavailable in analytical form; the success of MOBO heavily relies on this inner optimization. We do away with this hard acquisition function optimization step and propose a simple, but effective, Thompson sampling based approach ($q\texttt{POTS}$) where new candidate(s) are chosen from the Pareto frontier of random GP posterior sample paths obtained by solving a much cheaper mult
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#28857;&#23545;&#28857;&#22810;&#26234;&#33021;&#20307;&#32593;&#32476;&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#27604;&#20363;&#31215;&#20998;&#65288;PI&#65289;&#25511;&#21046;&#31574;&#30053;&#30340;&#39044;&#26465;&#20214;PI&#20849;&#35782;&#31639;&#27861;&#65292;&#20445;&#35777;&#20102;&#20854;&#22312;&#21463;&#38480;&#24378;&#20984;&#20989;&#25968;&#19979;&#30340;&#32447;&#24615;&#25910;&#25947;&#24615;&#65292;&#26080;&#38656;&#20010;&#20307;&#23616;&#37096;&#20195;&#20215;&#20989;&#25968;&#30340;&#20984;&#24615;&#65292;&#24182;&#19988;&#36890;&#36807;&#24341;&#20837;&#23616;&#37096;&#39044;&#26465;&#20214;&#36827;&#19968;&#27493;&#21152;&#36895;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.00419</link><description>&lt;p&gt;
&#21463;&#38480;&#24378;&#20984;&#24615;&#19979;&#30340;&#39044;&#26465;&#20214;PI&#20849;&#35782;&#31639;&#27861;&#30340;&#32447;&#24615;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Linear Convergence of Pre-Conditioned PI Consensus Algorithm under Restricted Strong Convexity. (arXiv:2310.00419v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00419
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#28857;&#23545;&#28857;&#22810;&#26234;&#33021;&#20307;&#32593;&#32476;&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#27604;&#20363;&#31215;&#20998;&#65288;PI&#65289;&#25511;&#21046;&#31574;&#30053;&#30340;&#39044;&#26465;&#20214;PI&#20849;&#35782;&#31639;&#27861;&#65292;&#20445;&#35777;&#20102;&#20854;&#22312;&#21463;&#38480;&#24378;&#20984;&#20989;&#25968;&#19979;&#30340;&#32447;&#24615;&#25910;&#25947;&#24615;&#65292;&#26080;&#38656;&#20010;&#20307;&#23616;&#37096;&#20195;&#20215;&#20989;&#25968;&#30340;&#20984;&#24615;&#65292;&#24182;&#19988;&#36890;&#36807;&#24341;&#20837;&#23616;&#37096;&#39044;&#26465;&#20214;&#36827;&#19968;&#27493;&#21152;&#36895;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#22312;&#28857;&#23545;&#28857;&#22810;&#26234;&#33021;&#20307;&#32593;&#32476;&#20013;&#35299;&#20915;&#20998;&#24067;&#24335;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#32593;&#32476;&#34987;&#20551;&#23450;&#20026;&#21516;&#27493;&#21644;&#36830;&#36890;&#30340;&#12290;&#37319;&#29992;&#27604;&#20363;&#31215;&#20998;&#65288;PI&#65289;&#25511;&#21046;&#31574;&#30053;&#65292;&#24320;&#21457;&#20102;&#22810;&#31181;&#20855;&#26377;&#22266;&#23450;&#27493;&#38271;&#30340;&#31639;&#27861;&#65292;&#20854;&#20013;&#26368;&#26089;&#30340;&#26159;PI&#20849;&#35782;&#31639;&#27861;&#12290;&#21033;&#29992;&#26446;&#38597;&#26222;&#35834;&#22827;&#29702;&#35770;&#65292;&#25105;&#20204;&#39318;&#27425;&#20445;&#35777;&#20102;&#20855;&#26377;&#36895;&#29575;&#21305;&#37197;&#31163;&#25955;&#21270;&#30340;&#21463;&#38480;&#24378;&#20984;&#20989;&#25968;&#30340;PI&#20849;&#35782;&#31639;&#27861;&#30340;&#25351;&#25968;&#25910;&#25947;&#24615;&#65292;&#32780;&#19981;&#38656;&#35201;&#20010;&#20307;&#23616;&#37096;&#20195;&#20215;&#20989;&#25968;&#30340;&#20984;&#24615;&#12290;&#20026;&#20102;&#21152;&#36895;PI&#20849;&#35782;&#31639;&#27861;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#23616;&#37096;&#39044;&#26465;&#20214;&#30340;&#24418;&#24335;&#65292;&#21363;&#24120;&#25968;&#27491;&#23450;&#30697;&#38453;&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#39564;&#35777;&#20854;&#30456;&#27604;&#20110;&#31361;&#20986;&#30340;&#20998;&#24067;&#24335;&#20984;&#20248;&#21270;&#31639;&#27861;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper considers solving distributed convex optimization problems in peer-to-peer multi-agent networks. The network is assumed to be synchronous and connected. By using the proportional-integral (PI) control strategy, various algorithms with fixed stepsize have been developed. The earliest among them is the PI consensus algorithm. Using Lyapunov theory, we guarantee exponential convergence of the PI consensus algorithm for restricted strongly convex functions with rate-matching discretization, without requiring convexity of individual local cost functions, for the first time. In order to accelerate the PI consensus algorithm, we incorporate local pre-conditioning in the form of constant positive definite matrices and numerically validate its efficiency compared to the prominent distributed convex optimization algorithms. Unlike classical pre-conditioning, where only the gradients are multiplied by a pre-conditioner, the proposed pre-conditioning modifies both the gradients and the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#31070;&#32463;&#21152;&#24615;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#20174;&#36125;&#21494;&#26031;&#35282;&#24230;&#32771;&#34385;&#21152;&#24615;&#32467;&#26500;&#65292;&#22312;&#24674;&#22797;&#30340;&#29305;&#24449;&#20132;&#20114;&#20013;&#25552;&#20379;&#21487;&#20449;&#21306;&#38388;&#65292;&#25552;&#20379;&#21487;&#22788;&#29702;&#30340;&#36793;&#32536;&#20284;&#28982;&#20272;&#35745;&#65292;&#21487;&#29992;&#20110;&#25191;&#34892;&#38544;&#24335;&#29305;&#24449;&#36873;&#25321;&#24182;&#23545;&#29305;&#24449;&#23545;&#36827;&#34892;&#25490;&#21517;&#12290;</title><link>http://arxiv.org/abs/2305.16905</link><description>&lt;p&gt;
&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#31070;&#32463;&#21152;&#24615;&#27169;&#22411;&#65306;&#36125;&#21494;&#26031;&#25512;&#29702;&#25552;&#39640;&#35299;&#37322;&#24615;
&lt;/p&gt;
&lt;p&gt;
Laplace-Approximated Neural Additive Models: Improving Interpretability with Bayesian Inference. (arXiv:2305.16905v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16905
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#31070;&#32463;&#21152;&#24615;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#20174;&#36125;&#21494;&#26031;&#35282;&#24230;&#32771;&#34385;&#21152;&#24615;&#32467;&#26500;&#65292;&#22312;&#24674;&#22797;&#30340;&#29305;&#24449;&#20132;&#20114;&#20013;&#25552;&#20379;&#21487;&#20449;&#21306;&#38388;&#65292;&#25552;&#20379;&#21487;&#22788;&#29702;&#30340;&#36793;&#32536;&#20284;&#28982;&#20272;&#35745;&#65292;&#21487;&#29992;&#20110;&#25191;&#34892;&#38544;&#24335;&#29305;&#24449;&#36873;&#25321;&#24182;&#23545;&#29305;&#24449;&#23545;&#36827;&#34892;&#25490;&#21517;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#22312;&#35768;&#22810;&#39046;&#22495;&#21462;&#24471;&#20102;&#25104;&#21151;&#24212;&#29992;&#65292;&#20294;&#23427;&#20204;&#30340;&#40657;&#30418;&#24615;&#36136;&#38459;&#30861;&#20102;&#35299;&#37322;&#24615;&#12290;&#31070;&#32463;&#21152;&#24615;&#27169;&#22411;&#65288;NAM&#65289;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#23558;&#32593;&#32476;&#20998;&#20026;&#21152;&#24615;&#23376;&#32593;&#32476;&#65292;&#20174;&#32780;&#20351;&#36755;&#20837;&#29305;&#24449;&#21644;&#39044;&#27979;&#20043;&#38388;&#30340;&#20132;&#20114;&#21464;&#24471;&#26126;&#26174;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20174;&#36125;&#21494;&#26031;&#35282;&#24230;&#32771;&#34385;&#21152;&#24615;&#32467;&#26500;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#23454;&#29992;&#30340;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#26041;&#27861;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#20197;&#19979;&#19977;&#20010;&#26041;&#38754;&#25552;&#39640;&#20102;&#21487;&#35299;&#37322;&#24615;&#65306;a&#65289;&#23427;&#36890;&#36807;&#20272;&#35745;&#23376;&#32593;&#32476;&#30340;&#20989;&#25968;&#31354;&#38388;&#19981;&#30830;&#23450;&#24615;&#20026;&#24674;&#22797;&#30340;&#29305;&#24449;&#20132;&#20114;&#25552;&#20379;&#21487;&#20449;&#21306;&#38388;&#65307;b&#65289;&#23427;&#25552;&#20379;&#21487;&#22788;&#29702;&#30340;&#36793;&#32536;&#20284;&#28982;&#20272;&#35745;&#65292;&#21487;&#29992;&#20110;&#36890;&#36807;&#32463;&#39564;&#36125;&#21494;&#26031;&#36807;&#31243;&#25191;&#34892;&#29305;&#24449;&#30340;&#38544;&#24335;&#36873;&#25321;&#65307;c&#65289;&#23427;&#21487;&#29992;&#20110;&#23545;&#29305;&#24449;&#23545;&#36827;&#34892;&#25490;&#21517;&#65292;&#20316;&#20026;&#31934;&#32454;&#35843;&#25972;&#30340;&#20132;&#20114;&#27169;&#22411;&#20505;&#36873;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23454;&#35777;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#31070;&#32463;&#21152;&#24615;&#27169;&#22411;&#65288;LA-NAM&#65289;&#25552;&#39640;&#20102;NAM&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#36827;&#19968;&#27493;&#25581;&#31034;&#20102;&#23398;&#20064;&#21040;&#30340;&#23376;&#32593;&#32476;&#30340;&#20132;&#20114;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep neural networks (DNNs) have found successful applications in many fields, but their black-box nature hinders interpretability. This is addressed by the neural additive model (NAM), in which the network is divided into additive sub-networks, thus making apparent the interaction between input features and predictions. In this paper, we approach the additive structure from a Bayesian perspective and develop a practical Laplace approximation. This enhances interpretability in three primary ways: a) It provides credible intervals for the recovered feature interactions by estimating function-space uncertainty of the sub-networks; b) it yields a tractable estimate of the marginal likelihood, which can be used to perform an implicit selection of features through an empirical Bayes procedure; and c) it can be used to rank feature pairs as candidates for second-order interactions in fine-tuned interaction models. We show empirically that our proposed Laplace-approximated NAM (LA-NAM) improv
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#31070;&#32463;&#25511;&#21046;&#21464;&#37327;&#30340;&#26041;&#24046;&#32553;&#20943;&#26041;&#27861;&#65292;&#25512;&#23548;&#24182;&#24471;&#20986;&#20102;&#22312;&#21508;&#31181;&#36941;&#21382;&#24615;&#20551;&#35774;&#19979;&#28176;&#36817;&#26041;&#24046;&#30340;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2304.01111</link><description>&lt;p&gt;
&#31070;&#32463;&#25511;&#21046;&#21464;&#37327;&#22312;MCMC&#20013;&#30340;&#29702;&#35770;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Theoretical guarantees for neural control variates in MCMC. (arXiv:2304.01111v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01111
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#31070;&#32463;&#25511;&#21046;&#21464;&#37327;&#30340;&#26041;&#24046;&#32553;&#20943;&#26041;&#27861;&#65292;&#25512;&#23548;&#24182;&#24471;&#20986;&#20102;&#22312;&#21508;&#31181;&#36941;&#21382;&#24615;&#20551;&#35774;&#19979;&#28176;&#36817;&#26041;&#24046;&#30340;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21152;&#24615;&#25511;&#21046;&#21464;&#37327;&#21644;&#26368;&#23567;&#21270;&#28176;&#36817;&#26041;&#24046;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#26041;&#24046;&#32553;&#20943;&#26041;&#27861;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#25511;&#21046;&#21464;&#37327;&#34920;&#31034;&#20026;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#29305;&#23450;&#24773;&#20917;&#12290;&#22312;&#22522;&#30784;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#21508;&#31181;&#36941;&#21382;&#24615;&#20551;&#35774;&#19979;&#65292;&#25512;&#23548;&#20102;&#28176;&#36817;&#26041;&#24046;&#30340;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#12290;&#35813;&#26041;&#27861;&#20381;&#36182;&#20110;&#26041;&#24046;&#32553;&#20943;&#31639;&#27861;&#21644;&#20989;&#25968;&#36924;&#36817;&#29702;&#35770;&#30340;&#38543;&#26426;&#35823;&#24046;&#30340;&#26368;&#26032;&#25104;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a variance reduction approach for Markov chains based on additive control variates and the minimization of an appropriate estimate for the asymptotic variance. We focus on the particular case when control variates are represented as deep neural networks. We derive the optimal convergence rate of the asymptotic variance under various ergodicity assumptions on the underlying Markov chain. The proposed approach relies upon recent results on the stochastic errors of variance reduction algorithms and function approximation theory.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#19968;&#38454;&#22686;&#24191;&#25289;&#26684;&#26391;&#26085;&#26041;&#27861;&#26469;&#35299;&#20915;&#32422;&#26463;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#20854;&#25805;&#20316;&#22797;&#26434;&#24230;&#20026; ${\cal O}(\varepsilon^{-4}\log\varepsilon^{-1})$&#12290;</title><link>http://arxiv.org/abs/2301.02060</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#32422;&#26463;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#38382;&#39064;&#30340;&#19968;&#38454;&#22686;&#24191;&#25289;&#26684;&#26391;&#26085;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A first-order augmented Lagrangian method for constrained minimax optimization. (arXiv:2301.02060v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.02060
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#19968;&#38454;&#22686;&#24191;&#25289;&#26684;&#26391;&#26085;&#26041;&#27861;&#26469;&#35299;&#20915;&#32422;&#26463;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#20854;&#25805;&#20316;&#22797;&#26434;&#24230;&#20026; ${\cal O}(\varepsilon^{-4}\log\varepsilon^{-1})$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#32422;&#26463;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#19968;&#38454;&#22686;&#24191;&#25289;&#26684;&#26391;&#26085;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#20854;&#23376;&#38382;&#39064;&#34987;&#21457;&#29616;&#26159;&#19968;&#20010;&#26356;&#31616;&#21333;&#30340;&#32467;&#26500;&#21270;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#20316;&#32773;&#22312; [26] &#20013;&#26368;&#36817;&#24320;&#21457;&#30340;&#19968;&#38454;&#26041;&#27861;&#26469;&#36866;&#24403;&#22320;&#35299;&#20915;&#12290;&#22312;&#19968;&#20123;&#36866;&#24403;&#30340;&#20551;&#35774;&#19979;&#65292;&#20026;&#20102;&#25214;&#21040;&#32422;&#26463;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#19968;&#20010; $\varepsilon$-KKT &#35299;&#65292;&#35813;&#26041;&#27861;&#30340;&#25805;&#20316;&#22797;&#26434;&#24230;&#20026; ${\cal O}(\varepsilon^{-4}\log\varepsilon^{-1})$&#65292;&#35813;&#22797;&#26434;&#24230;&#26159;&#30001;&#22522;&#26412;&#25805;&#20316;&#27979;&#37327;&#24471;&#21040;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we study a class of constrained minimax problems. In particular, we propose a first-order augmented Lagrangian method for solving them, whose subproblems turn out to be a much simpler structured minimax problem and are suitably solved by a first-order method recently developed in [26] by the authors. Under some suitable assumptions, an \emph{operation complexity} of ${\cal O}(\varepsilon^{-4}\log\varepsilon^{-1})$, measured by its fundamental operations, is established for the first-order augmented Lagrangian method for finding an $\varepsilon$-KKT solution of the constrained minimax problems.
&lt;/p&gt;</description></item></channel></rss>