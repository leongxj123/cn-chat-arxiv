<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#30740;&#31350;&#20102;&#22312;&#27844;&#28431;ReLU&#32593;&#32476;&#19978;&#20351;&#29992;&#38128;&#38142;&#25439;&#22833;&#36827;&#34892;&#35757;&#32451;&#30340;&#36807;&#31243;&#20013;&#65292;&#20449;&#22122;&#27604;&#65288;SNR&#65289;&#26465;&#20214;&#23545;&#20110;&#33391;&#24615;&#21644;&#38750;&#33391;&#24615;&#36807;&#25311;&#21512;&#30340;&#24433;&#21709;&#65292;&#24182;&#21457;&#29616;&#39640;SNR&#20540;&#20250;&#23548;&#33268;&#33391;&#24615;&#36807;&#25311;&#21512;&#65292;&#20302;SNR&#20540;&#21017;&#20250;&#23548;&#33268;&#26377;&#23475;&#36807;&#25311;&#21512;&#12290;</title><link>https://arxiv.org/abs/2403.06903</link><description>&lt;p&gt;
&#20855;&#26377;&#36866;&#24230;&#36755;&#20837;&#32500;&#24230;&#30340;&#27844;&#28431;ReLU&#32593;&#32476;&#20013;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Benign overfitting in leaky ReLU networks with moderate input dimension
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06903
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#22312;&#27844;&#28431;ReLU&#32593;&#32476;&#19978;&#20351;&#29992;&#38128;&#38142;&#25439;&#22833;&#36827;&#34892;&#35757;&#32451;&#30340;&#36807;&#31243;&#20013;&#65292;&#20449;&#22122;&#27604;&#65288;SNR&#65289;&#26465;&#20214;&#23545;&#20110;&#33391;&#24615;&#21644;&#38750;&#33391;&#24615;&#36807;&#25311;&#21512;&#30340;&#24433;&#21709;&#65292;&#24182;&#21457;&#29616;&#39640;SNR&#20540;&#20250;&#23548;&#33268;&#33391;&#24615;&#36807;&#25311;&#21512;&#65292;&#20302;SNR&#20540;&#21017;&#20250;&#23548;&#33268;&#26377;&#23475;&#36807;&#25311;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33391;&#24615;&#36807;&#25311;&#21512;&#38382;&#39064;&#25506;&#35752;&#20102;&#19968;&#20010;&#27169;&#22411;&#26159;&#21542;&#33021;&#22815;&#23436;&#32654;&#22320;&#25311;&#21512;&#22024;&#26434;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#21516;&#26102;&#21448;&#33021;&#22815;&#24456;&#22909;&#22320;&#27867;&#21270;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#20108;&#23618;&#27844;&#28431;ReLU&#32593;&#32476;&#19978;&#20351;&#29992;&#38128;&#38142;&#25439;&#22833;&#36827;&#34892;&#35757;&#32451;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;&#38382;&#39064;&#65292;&#38024;&#23545;&#20108;&#20998;&#31867;&#20219;&#21153;&#12290;&#25105;&#20204;&#32771;&#34385;&#36755;&#20837;&#25968;&#25454;&#65292;&#21487;&#20197;&#20998;&#35299;&#20026;&#19968;&#20010;&#20849;&#21516;&#20449;&#21495;&#21644;&#19968;&#20010;&#38543;&#26426;&#22122;&#22768;&#25104;&#20998;&#30340;&#24635;&#21644;&#65292;&#36825;&#20004;&#32773;&#30456;&#20114;&#27491;&#20132;&#12290;&#25105;&#20204;&#34920;&#24449;&#20102;&#27169;&#22411;&#21442;&#25968;&#30340;&#20449;&#22122;&#27604;&#65288;SNR&#65289;&#26465;&#20214;&#65292;&#23548;&#33268;&#20102;&#33391;&#24615;&#21644;&#38750;&#33391;&#24615;&#65288;&#26377;&#23475;&#65289;&#36807;&#25311;&#21512;&#65306;&#29305;&#21035;&#26159;&#65292;&#22914;&#26524;SNR&#24456;&#39640;&#65292;&#21017;&#21457;&#29983;&#33391;&#24615;&#36807;&#25311;&#21512;&#65292;&#30456;&#21453;&#65292;&#22914;&#26524;SNR&#24456;&#20302;&#65292;&#21017;&#21457;&#29983;&#26377;&#23475;&#36807;&#25311;&#21512;&#12290;&#25105;&#20204;&#23558;&#33391;&#24615;&#21644;&#38750;&#33391;&#24615;&#36807;&#25311;&#21512;&#24402;&#22240;&#20110;&#19968;&#20010;&#36817;&#20284;&#36793;&#30028;&#26368;&#22823;&#21270;&#24615;&#36136;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#38128;&#38142;&#25439;&#22833;&#19979;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#35757;&#32451;&#30340;&#27844;&#28431;ReLU&#32593;&#32476;&#28385;&#36275;&#36825;&#19968;&#24615;&#36136;&#12290;&#19982;&#20197;&#21069;&#30340;&#24037;&#20316;&#30456;&#27604;&#65292;&#25105;&#20204;&#19981;&#38656;&#35201;nea
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06903v1 Announce Type: new  Abstract: The problem of benign overfitting asks whether it is possible for a model to perfectly fit noisy training data and still generalize well. We study benign overfitting in two-layer leaky ReLU networks trained with the hinge loss on a binary classification task. We consider input data which can be decomposed into the sum of a common signal and a random noise component, which lie on subspaces orthogonal to one another. We characterize conditions on the signal to noise ratio (SNR) of the model parameters giving rise to benign versus non-benign, or harmful, overfitting: in particular, if the SNR is high then benign overfitting occurs, conversely if the SNR is low then harmful overfitting occurs. We attribute both benign and non-benign overfitting to an approximate margin maximization property and show that leaky ReLU networks trained on hinge loss with Gradient Descent (GD) satisfy this property. In contrast to prior work we do not require nea
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24322;&#24120;&#26816;&#27979;&#31639;&#27861;"Signature Isolation Forest"&#65292;&#21033;&#29992;&#31895;&#36335;&#24452;&#29702;&#35770;&#30340;&#31614;&#21517;&#21464;&#25442;&#21435;&#38500;&#20102;Functional Isolation Forest&#30340;&#32447;&#24615;&#20869;&#31215;&#21644;&#35789;&#20856;&#36873;&#25321;&#26041;&#38754;&#30340;&#38480;&#21046;&#12290;</title><link>https://arxiv.org/abs/2403.04405</link><description>&lt;p&gt;
Signature Isolation Forest
&lt;/p&gt;
&lt;p&gt;
Signature Isolation Forest
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04405
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24322;&#24120;&#26816;&#27979;&#31639;&#27861;"Signature Isolation Forest"&#65292;&#21033;&#29992;&#31895;&#36335;&#24452;&#29702;&#35770;&#30340;&#31614;&#21517;&#21464;&#25442;&#21435;&#38500;&#20102;Functional Isolation Forest&#30340;&#32447;&#24615;&#20869;&#31215;&#21644;&#35789;&#20856;&#36873;&#25321;&#26041;&#38754;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Functional Isolation Forest (FIF)&#26159;&#19968;&#31181;&#38024;&#23545;&#21151;&#33021;&#25968;&#25454;&#35774;&#35745;&#30340;&#26368;&#26032;&#19968;&#27969;&#24322;&#24120;&#26816;&#27979;(AD)&#31639;&#27861;&#12290;&#23427;&#20381;&#36182;&#20110;&#19968;&#31181;&#26641;&#20998;&#21306;&#36807;&#31243;&#65292;&#36890;&#36807;&#23558;&#27599;&#20010;&#26354;&#32447;&#35266;&#27979;&#25237;&#24433;&#21040;&#36890;&#36807;&#32447;&#24615;&#20869;&#31215;&#32472;&#21046;&#30340;&#35789;&#20856;&#19978;&#26469;&#35745;&#31639;&#24322;&#24120;&#24471;&#20998;&#12290;&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#8220;Signature Isolation Forest&#8221;&#65292;&#19968;&#31181;&#21033;&#29992;&#31895;&#36335;&#24452;&#29702;&#35770;&#31614;&#21517;&#21464;&#25442;&#30340;&#26032;&#39062;AD&#31639;&#27861;&#31867;&#65292;&#26469;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#36890;&#36807;&#25552;&#20986;&#20004;&#31181;&#31639;&#27861;&#26469;&#28040;&#38500;FIF&#26045;&#21152;&#30340;&#38480;&#21046;&#65292;&#36825;&#20004;&#31181;&#31639;&#27861;&#29305;&#21035;&#38024;&#23545;FIF&#20869;&#31215;&#30340;&#32447;&#24615;&#24615;&#21644;&#35789;&#20856;&#30340;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04405v1 Announce Type: cross  Abstract: Functional Isolation Forest (FIF) is a recent state-of-the-art Anomaly Detection (AD) algorithm designed for functional data. It relies on a tree partition procedure where an abnormality score is computed by projecting each curve observation on a drawn dictionary through a linear inner product. Such linear inner product and the dictionary are a priori choices that highly influence the algorithm's performances and might lead to unreliable results, particularly with complex datasets. This work addresses these challenges by introducing \textit{Signature Isolation Forest}, a novel AD algorithm class leveraging the rough path theory's signature transform. Our objective is to remove the constraints imposed by FIF through the proposition of two algorithms which specifically target the linearity of the FIF inner product and the choice of the dictionary. We provide several numerical experiments, including a real-world applications benchmark sho
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#22312;&#21521;&#37327;&#23450;&#20041;&#27880;&#24847;&#21147;&#30340;&#26041;&#27861;&#65292;&#23558;&#26631;&#20934;transformer&#20013;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#20174;&#20108;&#27425;&#26041;&#38477;&#20302;&#21040;&#19982;&#26102;&#38388;&#32447;&#24615;&#30456;&#20851;&#65292;&#34920;&#29616;&#19982;&#26631;&#20934;&#27880;&#24847;&#21147;&#23218;&#32654;&#65292;&#20294;&#20801;&#35768;&#19978;&#19979;&#25991;&#31383;&#21475;&#25193;&#23637;&#21040;&#36828;&#36828;&#36229;&#20986;&#26631;&#20934;&#30340;&#33539;&#22260;&#12290;</title><link>https://arxiv.org/abs/2402.17512</link><description>&lt;p&gt;
Latent Attention for Linear Time Transformers
&lt;/p&gt;
&lt;p&gt;
Latent Attention for Linear Time Transformers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17512
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#22312;&#21521;&#37327;&#23450;&#20041;&#27880;&#24847;&#21147;&#30340;&#26041;&#27861;&#65292;&#23558;&#26631;&#20934;transformer&#20013;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#20174;&#20108;&#27425;&#26041;&#38477;&#20302;&#21040;&#19982;&#26102;&#38388;&#32447;&#24615;&#30456;&#20851;&#65292;&#34920;&#29616;&#19982;&#26631;&#20934;&#27880;&#24847;&#21147;&#23218;&#32654;&#65292;&#20294;&#20801;&#35768;&#19978;&#19979;&#25991;&#31383;&#21475;&#25193;&#23637;&#21040;&#36828;&#36828;&#36229;&#20986;&#26631;&#20934;&#30340;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#20934;transformer&#20013;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#38543;&#30528;&#24207;&#21015;&#38271;&#24230;&#30340;&#22686;&#21152;&#21576;&#20108;&#27425;&#26041;&#22686;&#38271;&#12290;&#25105;&#20204;&#24341;&#20837;&#19968;&#31181;&#36890;&#36807;&#23450;&#20041;&#28508;&#22312;&#21521;&#37327;&#30340;&#27880;&#24847;&#21147;&#26469;&#23558;&#20854;&#38477;&#20302;&#21040;&#19982;&#26102;&#38388;&#32447;&#24615;&#30456;&#20851;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#36731;&#26494;&#20316;&#20026;&#26631;&#20934;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#26367;&#20195;&#21697;&#12290;&#25105;&#20204;&#30340;&#8220;Latte Transformer&#8221;&#27169;&#22411;&#21487;&#29992;&#20110;&#21452;&#21521;&#21644;&#21333;&#21521;&#20219;&#21153;&#65292;&#22240;&#26524;&#29256;&#26412;&#20801;&#35768;&#19968;&#31181;&#22312;&#25512;&#29702;&#35821;&#35328;&#29983;&#25104;&#20219;&#21153;&#20013;&#20869;&#23384;&#21644;&#26102;&#38388;&#39640;&#25928;&#30340;&#36882;&#24402;&#23454;&#29616;&#12290;&#26631;&#20934;transformer&#30340;&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#38543;&#30528;&#24207;&#21015;&#38271;&#24230;&#32447;&#24615;&#22686;&#38271;&#65292;&#32780;Latte Transformer&#35745;&#31639;&#19979;&#19968;&#20010;&#26631;&#35760;&#25152;&#38656;&#30340;&#26102;&#38388;&#26159;&#24658;&#23450;&#30340;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#23454;&#35777;&#34920;&#29616;&#21487;&#19982;&#26631;&#20934;&#27880;&#24847;&#21147;&#23218;&#32654;&#65292;&#20294;&#20801;&#35768;&#23558;&#19978;&#19979;&#25991;&#31383;&#21475;&#25193;&#23637;&#21040;&#36828;&#36828;&#36229;&#20986;&#26631;&#20934;&#27880;&#24847;&#21147;&#23454;&#38469;&#21487;&#34892;&#30340;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17512v1 Announce Type: new  Abstract: The time complexity of the standard attention mechanism in a transformer scales quadratically with the length of the sequence. We introduce a method to reduce this to linear scaling with time, based on defining attention via latent vectors. The method is readily usable as a drop-in replacement for the standard attention mechanism. Our "Latte Transformer" model can be implemented for both bidirectional and unidirectional tasks, with the causal version allowing a recurrent implementation which is memory and time-efficient during inference of language generation tasks. Whilst next token prediction scales linearly with the sequence length for a standard transformer, a Latte Transformer requires constant time to compute the next token. The empirical performance of our method is comparable to standard attention, yet allows scaling to context windows much larger than practical in standard attention.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;POMDP&#32467;&#26500;&#30340;&#26032;&#39062;&#35206;&#30422;&#20551;&#35774;&#65292;&#20197;&#35299;&#20915;&#26410;&#26469;&#20381;&#36182;&#20215;&#20540;&#20989;&#25968;&#26041;&#27861;&#20013;&#30340;&#38271;&#24230;&#25351;&#25968;&#22686;&#38271;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.14703</link><description>&lt;p&gt;
&#22312;&#26410;&#26469;&#20381;&#36182;&#20215;&#20540;&#20989;&#25968;&#20013;&#25506;&#35752;&#26410;&#26469;&#21644;&#21382;&#21490;&#30340;&#35781;&#21650;&#22312;&#31163;&#32447;&#35780;&#20272;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
On the Curses of Future and History in Future-dependent Value Functions for Off-policy Evaluation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14703
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;POMDP&#32467;&#26500;&#30340;&#26032;&#39062;&#35206;&#30422;&#20551;&#35774;&#65292;&#20197;&#35299;&#20915;&#26410;&#26469;&#20381;&#36182;&#20215;&#20540;&#20989;&#25968;&#26041;&#27861;&#20013;&#30340;&#38271;&#24230;&#25351;&#25968;&#22686;&#38271;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#37096;&#20998;&#21487;&#35266;&#27979;&#29615;&#22659;&#20013;&#22797;&#26434;&#35266;&#27979;&#30340;&#31163;&#32447;&#35780;&#20272;(OPE)&#65292;&#26088;&#22312;&#24320;&#21457;&#33021;&#22815;&#36991;&#20813;&#23545;&#26102;&#38388;&#36328;&#24230;&#25351;&#25968;&#20381;&#36182;&#30340;&#20272;&#35745;&#22120;&#12290;&#26368;&#36817;&#65292;Uehara&#31561;&#20154;&#65288;2022&#24180;&#65289;&#25552;&#20986;&#20102;&#26410;&#26469;&#20381;&#36182;&#20215;&#20540;&#20989;&#25968;&#20316;&#20026;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#30340;&#19968;&#20010;&#26377;&#21069;&#36884;&#30340;&#26694;&#26550;&#12290;&#28982;&#32780;&#65292;&#35813;&#26694;&#26550;&#20063;&#21462;&#20915;&#20110;&#26410;&#26469;&#20381;&#36182;&#20215;&#20540;&#20989;&#25968;&#30340;&#26377;&#30028;&#24615;&#20197;&#21450;&#20854;&#20182;&#30456;&#20851;&#25968;&#37327;&#65292;&#25105;&#20204;&#21457;&#29616;&#36825;&#20123;&#25968;&#37327;&#21487;&#33021;&#20250;&#38543;&#30528;&#38271;&#24230;&#21576;&#25351;&#25968;&#22686;&#38271;&#65292;&#20174;&#32780;&#25273;&#21435;&#35813;&#26041;&#27861;&#30340;&#20248;&#21183;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#38024;&#23545;POMDP&#32467;&#26500;&#30340;&#26032;&#39062;&#35206;&#30422;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14703v1 Announce Type: cross  Abstract: We study off-policy evaluation (OPE) in partially observable environments with complex observations, with the goal of developing estimators whose guarantee avoids exponential dependence on the horizon. While such estimators exist for MDPs and POMDPs can be converted to history-based MDPs, their estimation errors depend on the state-density ratio for MDPs which becomes history ratios after conversion, an exponential object. Recently, Uehara et al. (2022) proposed future-dependent value functions as a promising framework to address this issue, where the guarantee for memoryless policies depends on the density ratio over the latent state space. However, it also depends on the boundedness of the future-dependent value function and other related quantities, which we show could be exponential-in-length and thus erasing the advantage of the method. In this paper, we discover novel coverage assumptions tailored to the structure of POMDPs, such
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#23454;&#29992;&#30340;&#20108;&#38454;&#36172;&#24466;&#20984;&#20248;&#21270;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#23545;&#20110;&#19968;&#31867;&#31216;&#20043;&#20026;$\kappa$-&#20984;&#30340;&#20984;&#20989;&#25968;&#23454;&#29616;&#20102;&#26368;&#20248;&#30340;&#21518;&#26399;&#25439;&#22833;&#30028;&#38480;&#12290;&#35813;&#31639;&#27861;&#22312;&#22810;&#20010;&#24212;&#29992;&#20013;&#34920;&#29616;&#20986;&#39640;&#25928;&#24615;&#33021;&#65292;&#21253;&#25324;&#36172;&#24466;&#36923;&#36753;&#22238;&#24402;&#12290;</title><link>https://arxiv.org/abs/2402.08929</link><description>&lt;p&gt;
&#20108;&#38454;&#26041;&#27861;&#29992;&#20110;&#36172;&#24466;&#20248;&#21270;&#19982;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Second Order Methods for Bandit Optimization and Control
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08929
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#23454;&#29992;&#30340;&#20108;&#38454;&#36172;&#24466;&#20984;&#20248;&#21270;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#23545;&#20110;&#19968;&#31867;&#31216;&#20043;&#20026;$\kappa$-&#20984;&#30340;&#20984;&#20989;&#25968;&#23454;&#29616;&#20102;&#26368;&#20248;&#30340;&#21518;&#26399;&#25439;&#22833;&#30028;&#38480;&#12290;&#35813;&#31639;&#27861;&#22312;&#22810;&#20010;&#24212;&#29992;&#20013;&#34920;&#29616;&#20986;&#39640;&#25928;&#24615;&#33021;&#65292;&#21253;&#25324;&#36172;&#24466;&#36923;&#36753;&#22238;&#24402;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Bandit&#20984;&#20248;&#21270;(BCO)&#26159;&#19968;&#31181;&#22312;&#19981;&#30830;&#23450;&#24615;&#19979;&#36827;&#34892;&#22312;&#32447;&#20915;&#31574;&#30340;&#36890;&#29992;&#26694;&#26550;&#12290;&#23613;&#31649;&#24050;&#32463;&#24314;&#31435;&#20102;&#19968;&#33324;&#20984;&#25439;&#22833;&#30340;&#32039;&#26463;&#21518;&#26399;&#30028;&#38480;&#65292;&#20294;&#29616;&#26377;&#31639;&#27861;&#22312;&#39640;&#32500;&#25968;&#25454;&#19978;&#20855;&#26377;&#38590;&#20197;&#24525;&#21463;&#30340;&#35745;&#31639;&#25104;&#26412;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21463;&#22312;&#32447;&#29275;&#39039;&#27493;&#39588;&#31639;&#27861;&#21551;&#21457;&#30340;&#31616;&#21333;&#23454;&#29992;&#30340;BCO&#31639;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#23545;&#20110;&#19968;&#31867;&#25105;&#20204;&#31216;&#20043;&#20026;$\kappa$-&#20984;&#30340;&#20984;&#20989;&#25968;&#23454;&#29616;&#20102;&#26368;&#20248;(&#20174;&#23618;&#38754;&#19978;&#35762;)&#30340;&#21518;&#26399;&#30028;&#38480;&#12290;&#36825;&#20010;&#31867;&#21253;&#21547;&#20102;&#19968;&#31995;&#21015;&#23454;&#38469;&#30456;&#20851;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#21253;&#25324;&#32447;&#24615;&#12289;&#20108;&#27425;&#21644;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#12290;&#38500;&#20102;&#26368;&#20248;&#30340;&#21518;&#26399;&#25439;&#22833;&#65292;&#36825;&#31181;&#26041;&#27861;&#20063;&#26159;&#19968;&#20123;&#32463;&#36807;&#28145;&#20837;&#30740;&#31350;&#30340;&#24212;&#29992;&#20013;&#24050;&#30693;&#30340;&#26368;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#21253;&#25324;&#36172;&#24466;&#36923;&#36753;&#22238;&#24402;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08929v1 Announce Type: new Abstract: Bandit convex optimization (BCO) is a general framework for online decision making under uncertainty. While tight regret bounds for general convex losses have been established, existing algorithms achieving these bounds have prohibitive computational costs for high dimensional data.   In this paper, we propose a simple and practical BCO algorithm inspired by the online Newton step algorithm. We show that our algorithm achieves optimal (in terms of horizon) regret bounds for a large class of convex functions that we call $\kappa$-convex. This class contains a wide range of practically relevant loss functions including linear, quadratic, and generalized linear models. In addition to optimal regret, this method is the most efficient known algorithm for several well-studied applications including bandit logistic regression.   Furthermore, we investigate the adaptation of our second-order bandit algorithm to online convex optimization with mem
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#23558;&#27010;&#29575;Lambert&#38382;&#39064;&#19982;&#26368;&#20248;&#36136;&#37327;&#20256;&#36755;&#12289;Schr\"odinger&#26725;&#21644;&#21453;&#24212;-&#25193;&#25955;&#20559;&#24494;&#20998;&#26041;&#31243;&#31561;&#39046;&#22495;&#36830;&#25509;&#36215;&#26469;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#27010;&#29575;Lambert&#38382;&#39064;&#30340;&#35299;&#30340;&#23384;&#22312;&#21644;&#21807;&#19968;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#25968;&#20540;&#27714;&#35299;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.07961</link><description>&lt;p&gt;
&#27010;&#29575;Lambert&#38382;&#39064;&#30340;&#35299;&#20915;&#26041;&#26696;&#65306;&#19982;&#26368;&#20248;&#36136;&#37327;&#20256;&#36755;&#12289;Schr\"odinger&#26725;&#21644;&#21453;&#24212;-&#25193;&#25955;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#36830;&#25509;
&lt;/p&gt;
&lt;p&gt;
Solution of the Probabilistic Lambert Problem: Connections with Optimal Mass Transport, Schr\"odinger Bridge and Reaction-Diffusion PDEs. (arXiv:2401.07961v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.07961
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#23558;&#27010;&#29575;Lambert&#38382;&#39064;&#19982;&#26368;&#20248;&#36136;&#37327;&#20256;&#36755;&#12289;Schr\"odinger&#26725;&#21644;&#21453;&#24212;-&#25193;&#25955;&#20559;&#24494;&#20998;&#26041;&#31243;&#31561;&#39046;&#22495;&#36830;&#25509;&#36215;&#26469;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#27010;&#29575;Lambert&#38382;&#39064;&#30340;&#35299;&#30340;&#23384;&#22312;&#21644;&#21807;&#19968;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#25968;&#20540;&#27714;&#35299;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Lambert&#38382;&#39064;&#28041;&#21450;&#36890;&#36807;&#36895;&#24230;&#25511;&#21046;&#22312;&#35268;&#23450;&#30340;&#39134;&#34892;&#26102;&#38388;&#20869;&#23558;&#33322;&#22825;&#22120;&#20174;&#32473;&#23450;&#30340;&#21021;&#22987;&#20301;&#32622;&#36716;&#31227;&#21040;&#32473;&#23450;&#30340;&#32456;&#31471;&#20301;&#32622;&#65292;&#21463;&#21040;&#37325;&#21147;&#21147;&#22330;&#30340;&#38480;&#21046;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;Lambert&#38382;&#39064;&#30340;&#27010;&#29575;&#21464;&#31181;&#65292;&#20854;&#20013;&#20301;&#32622;&#21521;&#37327;&#30340;&#31471;&#28857;&#32422;&#26463;&#30340;&#30693;&#35782;&#34987;&#23427;&#20204;&#21508;&#33258;&#30340;&#32852;&#21512;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#25152;&#26367;&#20195;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20855;&#26377;&#31471;&#28857;&#32852;&#21512;&#27010;&#29575;&#23494;&#24230;&#32422;&#26463;&#30340;Lambert&#38382;&#39064;&#26159;&#19968;&#20010;&#24191;&#20041;&#30340;&#26368;&#20248;&#36136;&#37327;&#20256;&#36755;&#65288;OMT&#65289;&#38382;&#39064;&#65292;&#20174;&#32780;&#23558;&#36825;&#20010;&#32463;&#20856;&#30340;&#22825;&#20307;&#21160;&#21147;&#23398;&#38382;&#39064;&#19982;&#29616;&#20195;&#38543;&#26426;&#25511;&#21046;&#21644;&#38543;&#26426;&#26426;&#22120;&#23398;&#20064;&#30340;&#26032;&#20852;&#30740;&#31350;&#39046;&#22495;&#32852;&#31995;&#36215;&#26469;&#12290;&#36825;&#20010;&#26032;&#21457;&#29616;&#30340;&#36830;&#25509;&#20351;&#25105;&#20204;&#33021;&#22815;&#20005;&#26684;&#24314;&#31435;&#27010;&#29575;Lambert&#38382;&#39064;&#30340;&#35299;&#30340;&#23384;&#22312;&#24615;&#21644;&#21807;&#19968;&#24615;&#12290;&#21516;&#26679;&#30340;&#36830;&#25509;&#36824;&#24110;&#21161;&#36890;&#36807;&#25193;&#25955;&#27491;&#35268;&#21270;&#25968;&#20540;&#27714;&#35299;&#27010;&#29575;Lambert&#38382;&#39064;&#65292;&#21363;&#36890;&#36807;&#36827;&#19968;&#27493;&#30340;&#36830;&#25509;&#26469;&#21033;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Lambert's problem concerns with transferring a spacecraft from a given initial to a given terminal position within prescribed flight time via velocity control subject to a gravitational force field. We consider a probabilistic variant of the Lambert problem where the knowledge of the endpoint constraints in position vectors are replaced by the knowledge of their respective joint probability density functions. We show that the Lambert problem with endpoint joint probability density constraints is a generalized optimal mass transport (OMT) problem, thereby connecting this classical astrodynamics problem with a burgeoning area of research in modern stochastic control and stochastic machine learning. This newfound connection allows us to rigorously establish the existence and uniqueness of solution for the probabilistic Lambert problem. The same connection also helps to numerically solve the probabilistic Lambert problem via diffusion regularization, i.e., by leveraging further connection 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20174;&#31532;&#19968;&#21407;&#29702;&#20013;&#24471;&#21040;&#20102;&#36203;&#24067;&#23398;&#20064;&#30340;&#26126;&#30830;&#34920;&#36798;&#24335;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#20123;&#23398;&#20064;&#35268;&#21017;&#22312;&#22823;&#25968;&#25454;&#26497;&#38480;&#19979;&#25910;&#25947;&#21040;&#21407;&#22987;&#30340;&#23384;&#20648;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2401.07110</link><description>&lt;p&gt;
&#20174;&#31532;&#19968;&#21407;&#29702;&#20013;&#30340;&#36203;&#24067;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Hebbian Learning from First Principles. (arXiv:2401.07110v1 [cond-mat.dis-nn])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.07110
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#31532;&#19968;&#21407;&#29702;&#20013;&#24471;&#21040;&#20102;&#36203;&#24067;&#23398;&#20064;&#30340;&#26126;&#30830;&#34920;&#36798;&#24335;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#20123;&#23398;&#20064;&#35268;&#21017;&#22312;&#22823;&#25968;&#25454;&#26497;&#38480;&#19979;&#25910;&#25947;&#21040;&#21407;&#22987;&#30340;&#23384;&#20648;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#38024;&#23545;&#31070;&#32463;&#32593;&#32476;&#30340;Hopfield&#27169;&#22411;&#21450;&#20854;&#23494;&#38598;&#27010;&#21270;&#24418;&#24335;&#30340;&#21407;&#22987;&#23384;&#20648;&#26041;&#26696;&#24050;&#36890;&#36807;&#20551;&#35774;&#20854;&#21704;&#23494;&#39039;&#37327;&#30340;&#34920;&#36798;&#24335;&#20026;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#21327;&#35758;&#65292;&#25104;&#20026;&#30495;&#27491;&#30340;&#36203;&#24067;&#23398;&#20064;&#35268;&#21017;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#20381;&#38752;Jaynes&#30340;&#26368;&#22823;&#29109;&#26497;&#20540;&#27861;&#24471;&#21040;&#20102;&#36825;&#20123;&#26126;&#30830;&#30340;&#34920;&#36798;&#24335;&#12290;&#38500;&#20102;&#24418;&#24335;&#19978;&#25512;&#23548;&#20986;&#36825;&#20123;&#36203;&#24067;&#23398;&#20064;&#30340;&#35268;&#21017;&#65292;&#36825;&#20010;&#26500;&#24314;&#36824;&#31361;&#26174;&#20102;&#29109;&#26497;&#20540;&#20013;&#30340;&#26391;&#26684;&#26391;&#26085;&#32422;&#26463;&#22914;&#20309;&#24378;&#21046;&#32593;&#32476;&#32467;&#26524;&#19978;&#30340;&#31070;&#32463;&#30456;&#20851;&#24615;&#65306;&#36825;&#20123;&#23581;&#35797;&#27169;&#20223;&#25552;&#20379;&#32473;&#32593;&#32476;&#36827;&#34892;&#35757;&#32451;&#30340;&#25968;&#25454;&#38598;&#20013;&#38544;&#34255;&#30340;&#32463;&#39564;&#25903;&#25345;&#65292;&#32780;&#19988;&#32593;&#32476;&#36234;&#23494;&#38598;&#65292;&#33021;&#22815;&#25429;&#25417;&#21040;&#30340;&#30456;&#20851;&#24615;&#26102;&#38388;&#36234;&#38271;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#22823;&#25968;&#25454;&#26497;&#38480;&#19979;&#65292;&#26080;&#35770;&#26159;&#21542;&#23384;&#22312;&#25945;&#24072;&#65292;&#36825;&#20123;&#36203;&#24067;&#23398;&#20064;&#35268;&#21017;&#37117;&#20250;&#25910;&#25947;&#21040;&#21407;&#22987;&#30340;&#23384;&#20648;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, the original storage prescription for the Hopfield model of neural networks -- as well as for its dense generalizations -- has been turned into a genuine Hebbian learning rule by postulating the expression of its Hamiltonian for both the supervised and unsupervised protocols. In these notes, first, we obtain these explicit expressions by relying upon maximum entropy extremization \`a la Jaynes. Beyond providing a formal derivation of these recipes for Hebbian learning, this construction also highlights how Lagrangian constraints within entropy extremization force network's outcomes on neural correlations: these try to mimic the empirical counterparts hidden in the datasets provided to the network for its training and, the denser the network, the longer the correlations that it is able to capture. Next, we prove that, in the big data limit, whatever the presence of a teacher (or its lacking), not only these Hebbian learning rules converge to the original storage prescription o
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20351;&#29992;&#20855;&#26377;&#31934;&#30830;&#35268;&#33539;&#19981;&#21464;&#24615;&#30340;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#25214;&#21040;&#20102;&#22235;&#32500;SU&#65288;3&#65289;&#35268;&#33539;&#29702;&#35770;&#30340;&#20248;&#31168;&#22266;&#23450;&#28857;&#20316;&#29992;&#30340;&#21442;&#25968;&#21270;&#26041;&#27861;&#65292;&#20026;&#26410;&#26469;&#30340;&#33945;&#29305;&#21345;&#27931;&#27169;&#25311;&#25171;&#19979;&#20102;&#24517;&#35201;&#30340;&#22522;&#30784;&#12290;</title><link>http://arxiv.org/abs/2401.06481</link><description>&lt;p&gt;
&#20351;&#29992;&#20855;&#26377;&#35268;&#33539;&#31561;&#21464;&#24615;&#30340;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#26426;&#22120;&#23398;&#20064;SU&#65288;3&#65289;&#35268;&#33539;&#29702;&#35770;&#30340;&#22266;&#23450;&#28857;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
Machine learning a fixed point action for SU(3) gauge theory with a gauge equivariant convolutional neural network. (arXiv:2401.06481v1 [hep-lat] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06481
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;&#20855;&#26377;&#31934;&#30830;&#35268;&#33539;&#19981;&#21464;&#24615;&#30340;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#25214;&#21040;&#20102;&#22235;&#32500;SU&#65288;3&#65289;&#35268;&#33539;&#29702;&#35770;&#30340;&#20248;&#31168;&#22266;&#23450;&#28857;&#20316;&#29992;&#30340;&#21442;&#25968;&#21270;&#26041;&#27861;&#65292;&#20026;&#26410;&#26469;&#30340;&#33945;&#29305;&#21345;&#27931;&#27169;&#25311;&#25171;&#19979;&#20102;&#24517;&#35201;&#30340;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22266;&#23450;&#28857;&#30340;&#26684;&#23376;&#20316;&#29992;&#34987;&#35774;&#35745;&#25104;&#20855;&#26377;&#19981;&#21463;&#31163;&#25955;&#21270;&#25928;&#24212;&#24433;&#21709;&#30340;&#36830;&#32493;&#32463;&#20856;&#24615;&#36136;&#65292;&#24182;&#22312;&#37327;&#23376;&#23618;&#38754;&#19978;&#20943;&#23569;&#26684;&#23376;&#25928;&#24212;&#12290;&#23427;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#29992;&#36739;&#31895;&#30340;&#26684;&#23376;&#26469;&#25552;&#21462;&#36830;&#32493;&#29289;&#29702;&#30340;&#21487;&#33021;&#26041;&#27861;&#65292;&#20174;&#32780;&#32469;&#36807;&#19982;&#36830;&#32493;&#26497;&#38480;&#30456;&#20851;&#30340;&#20020;&#30028;&#20943;&#24930;&#21644;&#25299;&#25169;&#20923;&#32467;&#38382;&#39064;&#12290;&#23454;&#38469;&#24212;&#29992;&#30340;&#20851;&#38190;&#26159;&#25214;&#21040;&#19968;&#20010;&#31934;&#30830;&#19988;&#32039;&#20945;&#30340;&#22266;&#23450;&#28857;&#20316;&#29992;&#21442;&#25968;&#21270;&#26041;&#27861;&#65292;&#22240;&#20026;&#20854;&#35768;&#22810;&#24615;&#36136;&#21482;&#26159;&#38544;&#21547;&#23450;&#20041;&#30340;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#37325;&#26032;&#24605;&#32771;&#20102;&#22914;&#20309;&#21442;&#25968;&#21270;&#22266;&#23450;&#28857;&#20316;&#29992;&#30340;&#38382;&#39064;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#20351;&#29992;&#20855;&#26377;&#31934;&#30830;&#35268;&#33539;&#19981;&#21464;&#24615;&#30340;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#33719;&#24471;&#22235;&#32500;SU&#65288;3&#65289;&#35268;&#33539;&#29702;&#35770;&#30340;&#22266;&#23450;&#28857;&#20316;&#29992;&#12290;&#22823;&#30340;&#31639;&#23376;&#31354;&#38388;&#20351;&#25105;&#20204;&#33021;&#22815;&#25214;&#21040;&#27604;&#20043;&#21069;&#30740;&#31350;&#26356;&#22909;&#30340;&#21442;&#25968;&#21270;&#26041;&#27861;&#65292;&#36825;&#26159;&#26410;&#26469;&#33945;&#29305;&#21345;&#27931;&#27169;&#25311;&#30340;&#24517;&#35201;&#31532;&#19968;&#27493;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fixed point lattice actions are designed to have continuum classical properties unaffected by discretization effects and reduced lattice artifacts at the quantum level. They provide a possible way to extract continuum physics with coarser lattices, thereby allowing to circumvent problems with critical slowing down and topological freezing toward the continuum limit. A crucial ingredient for practical applications is to find an accurate and compact parametrization of a fixed point action, since many of its properties are only implicitly defined. Here we use machine learning methods to revisit the question of how to parametrize fixed point actions. In particular, we obtain a fixed point action for four-dimensional SU(3) gauge theory using convolutional neural networks with exact gauge invariance. The large operator space allows us to find superior parametrizations compared to previous studies, a necessary first step for future Monte Carlo simulations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;5/2&#38454;&#21644;7/2&#38454;$L^2$-&#20934;&#30830;&#30340;&#38543;&#26426;Runge-Kutta-Nystr\"om&#26041;&#27861;&#65292;&#29992;&#20110;&#36817;&#20284;&#24213;&#23618;&#30340;&#21704;&#23494;&#39039;&#27969;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#22312;&#39640;&#32500;&#30446;&#26631;&#20998;&#24067;&#20013;&#30340;&#21331;&#36234;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.07399</link><description>&lt;p&gt;
&#38543;&#26426;Runge-Kutta-Nystr\"om&#26041;&#27861;&#22312;&#38750;&#21487;&#36870;&#39532;&#23572;&#31185;&#22827;&#38142;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Randomized Runge-Kutta-Nystr\"om. (arXiv:2310.07399v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07399
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;5/2&#38454;&#21644;7/2&#38454;$L^2$-&#20934;&#30830;&#30340;&#38543;&#26426;Runge-Kutta-Nystr\"om&#26041;&#27861;&#65292;&#29992;&#20110;&#36817;&#20284;&#24213;&#23618;&#30340;&#21704;&#23494;&#39039;&#27969;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#22312;&#39640;&#32500;&#30446;&#26631;&#20998;&#24067;&#20013;&#30340;&#21331;&#36234;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;5/2&#38454;&#21644;7/2&#38454;$L^2$-&#20934;&#30830;&#30340;&#38543;&#26426;Runge-Kutta-Nystr\"om&#26041;&#27861;&#65292;&#29992;&#20110;&#36817;&#20284;&#24213;&#23618;&#30340;&#21704;&#23494;&#39039;&#27969;&#65292;&#21253;&#25324;&#19981;&#35843;&#25972;&#30340;&#21704;&#23494;&#39039;&#33945;&#29305;&#21345;&#27931;&#21644;&#19981;&#35843;&#25972;&#30340;&#21160;&#21147;&#23398;&#26391;&#20043;&#19975;&#38142;&#12290;&#36890;&#36807;&#22312;&#21183;&#33021;&#20989;&#25968;&#30340;&#26799;&#24230;&#21644;&#28023;&#26862;&#30697;&#38453;&#30340;Lipschitz&#20551;&#35774;&#19979;&#25552;&#20379;&#20102;&#37327;&#21270;&#30340;5/2&#38454;$L^2$-&#20934;&#30830;&#24230;&#19978;&#38480;&#12290;&#23545;&#20110;&#19968;&#20123;&#8220;&#33391;&#22909;&#34892;&#20026;&#8221;&#30340;&#39640;&#32500;&#30446;&#26631;&#20998;&#24067;&#65292;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#23545;&#24212;&#30340;&#39532;&#23572;&#31185;&#22827;&#38142;&#34920;&#29616;&#20986;&#24456;&#39640;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present 5/2- and 7/2-order $L^2$-accurate randomized Runge-Kutta-Nystr\"om methods to approximate the Hamiltonian flow underlying various non-reversible Markov chain Monte Carlo chains including unadjusted Hamiltonian Monte Carlo and unadjusted kinetic Langevin chains. Quantitative 5/2-order $L^2$-accuracy upper bounds are provided under gradient and Hessian Lipschitz assumptions on the potential energy function. The superior complexity of the corresponding Markov chains is numerically demonstrated for a selection of `well-behaved', high-dimensional target distributions.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#21487;&#23454;&#29616;&#22238;&#24402;&#38382;&#39064;&#30340;PAC&#23398;&#20064;&#21644;&#22312;&#32447;&#23398;&#20064;&#30340;&#32479;&#35745;&#22797;&#26434;&#24230;&#65292;&#24182;&#25552;&#20986;&#20102;&#23545;&#20110;&#21487;&#23398;&#20064;&#24615;&#30340;&#24517;&#35201;&#26465;&#20214;&#21644;&#20805;&#20998;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2307.03848</link><description>&lt;p&gt;
&#21487;&#23454;&#29616;&#22238;&#24402;&#30340;&#26368;&#20248;&#23398;&#20064;&#31639;&#27861;&#65306;PAC&#23398;&#20064;&#21644;&#22312;&#32447;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Optimal Learners for Realizable Regression: PAC Learning and Online Learning. (arXiv:2307.03848v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03848
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#21487;&#23454;&#29616;&#22238;&#24402;&#38382;&#39064;&#30340;PAC&#23398;&#20064;&#21644;&#22312;&#32447;&#23398;&#20064;&#30340;&#32479;&#35745;&#22797;&#26434;&#24230;&#65292;&#24182;&#25552;&#20986;&#20102;&#23545;&#20110;&#21487;&#23398;&#20064;&#24615;&#30340;&#24517;&#35201;&#26465;&#20214;&#21644;&#20805;&#20998;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#26088;&#22312;&#23545;&#21487;&#23454;&#29616;&#22238;&#24402;&#22312;PAC&#23398;&#20064;&#21644;&#22312;&#32447;&#23398;&#20064;&#30340;&#32479;&#35745;&#22797;&#26434;&#24230;&#36827;&#34892;&#21051;&#30011;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#35777;&#26126;&#20102;&#26377;&#38480;&#30340;fat shattering&#32500;&#24230;&#23545;&#20110;PAC&#23398;&#20064;&#30340;&#20805;&#20998;&#24615;&#20197;&#21450;&#26377;&#38480;&#30340;scaled Natarajan&#32500;&#24230;&#23545;&#20110;&#24517;&#35201;&#24615;&#30340;&#23384;&#22312;&#65292;&#20294;&#33258;&#20174;Simon 1997&#65288;SICOMP '97&#65289;&#30340;&#24037;&#20316;&#20197;&#26469;&#65292;&#23545;&#20110;&#26356;&#23436;&#25972;&#30340;&#21051;&#30011;&#30340;&#36827;&#23637;&#29978;&#23569;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#39318;&#20808;&#24341;&#20837;&#20102;&#19968;&#31181;&#26368;&#23567;&#21270;&#23454;&#20363;&#26368;&#20248;&#23398;&#20064;&#31639;&#27861;&#26469;&#23545;&#21487;&#23454;&#29616;&#22238;&#24402;&#36827;&#34892;&#23398;&#20064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26082;&#23450;&#24615;&#21448;&#23450;&#37327;&#22320;&#21051;&#30011;&#20102;&#21738;&#20123;&#31867;&#30340;&#23454;&#25968;&#39044;&#27979;&#22120;&#21487;&#20197;&#34987;&#23398;&#20064;&#30340;&#26032;&#39062;&#32500;&#24230;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#19968;&#20010;&#19982;&#22270;&#32500;&#24230;&#30456;&#20851;&#30340;&#32452;&#21512;&#32500;&#24230;&#65292;&#35813;&#32500;&#24230;&#21051;&#30011;&#20102;&#22312;&#21487;&#23454;&#29616;&#35774;&#32622;&#20013;&#30340;ERM&#21487;&#23398;&#20064;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#26681;&#25454;&#19982;DS&#32500;&#24230;&#30456;&#20851;&#30340;&#32452;&#21512;&#32500;&#24230;&#24314;&#31435;&#20102;&#23398;&#20064;&#21487;&#34892;&#24615;&#30340;&#24517;&#35201;&#26465;&#20214;&#65292;&#24182;&#29468;&#27979;&#23427;&#20063;&#21487;&#33021;&#26159;&#20805;&#20998;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we aim to characterize the statistical complexity of realizable regression both in the PAC learning setting and the online learning setting.  Previous work had established the sufficiency of finiteness of the fat shattering dimension for PAC learnability and the necessity of finiteness of the scaled Natarajan dimension, but little progress had been made towards a more complete characterization since the work of Simon 1997 (SICOMP '97). To this end, we first introduce a minimax instance optimal learner for realizable regression and propose a novel dimension that both qualitatively and quantitatively characterizes which classes of real-valued predictors are learnable. We then identify a combinatorial dimension related to the Graph dimension that characterizes ERM learnability in the realizable setting. Finally, we establish a necessary condition for learnability based on a combinatorial dimension related to the DS dimension, and conjecture that it may also be sufficient in 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#22343;&#22330;&#25511;&#21046;(MFC)&#21644;&#22343;&#22330;&#21338;&#24328;(MFG)&#20013;&#30340;&#24378;&#21270;&#23398;&#20064;&#30340;&#32479;&#35745;&#25928;&#29575;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#20048;&#35266;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#31639;&#27861;&#65292;&#24182;&#20165;&#23545;&#36716;&#31227;&#21160;&#21147;&#23398;&#20855;&#26377;Lipschitz&#36830;&#32493;&#24615;&#30340;&#20551;&#35774;&#65292;&#26368;&#21518;&#24314;&#31435;&#20102;&#19968;&#20010;&#25351;&#25968;&#32423;&#30340;&#19979;&#30028;&#25903;&#25345;MFC&#35774;&#32622;&#12290;</title><link>http://arxiv.org/abs/2305.11283</link><description>&lt;p&gt;
&#20851;&#20110;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#22343;&#22330;&#24378;&#21270;&#23398;&#20064;&#30340;&#32479;&#35745;&#25928;&#29575;
&lt;/p&gt;
&lt;p&gt;
On the Statistical Efficiency of Mean Field Reinforcement Learning with General Function Approximation. (arXiv:2305.11283v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11283
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#22343;&#22330;&#25511;&#21046;(MFC)&#21644;&#22343;&#22330;&#21338;&#24328;(MFG)&#20013;&#30340;&#24378;&#21270;&#23398;&#20064;&#30340;&#32479;&#35745;&#25928;&#29575;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#20048;&#35266;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#31639;&#27861;&#65292;&#24182;&#20165;&#23545;&#36716;&#31227;&#21160;&#21147;&#23398;&#20855;&#26377;Lipschitz&#36830;&#32493;&#24615;&#30340;&#20551;&#35774;&#65292;&#26368;&#21518;&#24314;&#31435;&#20102;&#19968;&#20010;&#25351;&#25968;&#32423;&#30340;&#19979;&#30028;&#25903;&#25345;MFC&#35774;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#22343;&#22330;&#25511;&#21046;&#65288;MFC&#65289;&#21644;&#22343;&#22330;&#21338;&#24328;&#65288;MFG&#65289;&#20013;&#24378;&#21270;&#23398;&#20064;&#30340;&#32479;&#35745;&#25928;&#29575;&#12290;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;Mean-Field Model-Based Eluder Dimension (MBED)&#30340;&#26032;&#27010;&#24565;&#65292;&#21253;&#21547;&#20102;&#19968;&#31995;&#21015;&#20016;&#23500;&#30340;&#22343;&#22330;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#20048;&#35266;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#36820;&#22238;&#19968;&#20010;$\epsilon$&#20248;&#30340;&#31574;&#30053;&#65292;&#36866;&#29992;&#20110;MFC&#25110;$\epsilon$&#32435;&#20160;&#22343;&#34913;&#31574;&#30053;&#36866;&#29992;&#20110;MFG&#65292;&#26679;&#26412;&#22797;&#26434;&#24230;&#22810;&#39033;&#24335;&#19982;&#30456;&#20851;&#21442;&#25968;&#26080;&#20851;&#65292;&#19982;&#29366;&#24577;&#12289;&#21160;&#20316;&#21644;&#20195;&#29702;&#25968;&#37327;&#26080;&#20851;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#20165;&#23545;&#36716;&#31227;&#21160;&#21147;&#23398;&#20855;&#26377;Lipschitz&#36830;&#32493;&#24615;&#30340;&#20551;&#35774;&#65292;&#36991;&#20813;&#20102;&#20197;&#21069;&#30340;&#24378;&#32467;&#26500;&#20551;&#35774;&#12290;&#26368;&#21518;&#65292;&#22312;tabular&#35774;&#32622;&#19979;&#65292;&#20551;&#35774;&#26377;&#19968;&#20010;&#29983;&#25104;&#27169;&#22411;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#25351;&#25968;&#32423;&#30340;&#19979;&#30028;&#25903;&#25345;MFC&#35774;&#32622;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26679;&#26412;&#39640;&#25928;&#30340;&#27169;&#22411;&#28040;&#38500;&#31639;&#27861;&#20197;&#36924;&#36817;&#26368;&#20248;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the statistical efficiency of Reinforcement Learning in Mean-Field Control (MFC) and Mean-Field Game (MFG) with general function approximation. We introduce a new concept called Mean-Field Model-Based Eluder Dimension (MBED), which subsumes a rich family of Mean-Field RL problems. Additionally, we propose algorithms based on Optimistic Maximal Likelihood Estimation, which can return an $\epsilon$-optimal policy for MFC or an $\epsilon$-Nash Equilibrium policy for MFG, with sample complexity polynomial w.r.t. relevant parameters and independent of the number of states, actions and the number of agents. Notably, our results only require a mild assumption of Lipschitz continuity on transition dynamics and avoid strong structural assumptions in previous work. Finally, in the tabular setting, given the access to a generative model, we establish an exponential lower bound for MFC setting, while providing a novel sample-efficient model elimination algorithm to approxim
&lt;/p&gt;</description></item></channel></rss>