<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25552;&#20986;&#20102;&#26356;&#24378;&#30340;&#24179;&#22343;&#24773;&#20917;&#35745;&#31639;&#20998;&#31163;&#65292;&#23545;&#20110;&#8220;&#20856;&#22411;&#8221;&#24773;&#20917;&#19979;&#30340;&#23398;&#20064;&#20219;&#21153;&#23454;&#20363;&#65292;&#21333;&#27169;&#24577;&#23398;&#20064;&#22312;&#35745;&#31639;&#19978;&#26159;&#22256;&#38590;&#30340;&#65292;&#20294;&#22810;&#27169;&#24577;&#23398;&#20064;&#21364;&#24456;&#23481;&#26131;&#12290;</title><link>https://arxiv.org/abs/2404.02254</link><description>&lt;p&gt;
&#20851;&#20110;&#22810;&#27169;&#24577;&#19982;&#21333;&#27169;&#24577;&#26426;&#22120;&#23398;&#20064;&#20043;&#38388;&#26356;&#24378;&#30340;&#35745;&#31639;&#20998;&#31163;
&lt;/p&gt;
&lt;p&gt;
On Stronger Computational Separations Between Multimodal and Unimodal Machine Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02254
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#26356;&#24378;&#30340;&#24179;&#22343;&#24773;&#20917;&#35745;&#31639;&#20998;&#31163;&#65292;&#23545;&#20110;&#8220;&#20856;&#22411;&#8221;&#24773;&#20917;&#19979;&#30340;&#23398;&#20064;&#20219;&#21153;&#23454;&#20363;&#65292;&#21333;&#27169;&#24577;&#23398;&#20064;&#22312;&#35745;&#31639;&#19978;&#26159;&#22256;&#38590;&#30340;&#65292;&#20294;&#22810;&#27169;&#24577;&#23398;&#20064;&#21364;&#24456;&#23481;&#26131;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22810;&#27169;&#24577;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#23558;&#22810;&#31181;&#25968;&#25454;&#27169;&#24577;&#65288;&#20363;&#22914;&#25991;&#26412;&#21644;&#22270;&#20687;&#65289;&#32467;&#21512;&#36215;&#26469;&#20197;&#20419;&#36827;&#26356;&#22909;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#23398;&#20064;&#65292;&#36825;&#20173;&#28982;&#36866;&#29992;&#20110;&#30456;&#24212;&#30340;&#21333;&#27169;&#24577;&#20219;&#21153;&#65288;&#20363;&#22914;&#25991;&#26412;&#29983;&#25104;&#65289;&#12290;&#26368;&#36817;&#65292;&#22810;&#27169;&#24577;&#26426;&#22120;&#23398;&#20064;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#32463;&#39564;&#25104;&#21151;&#65288;&#20363;&#22914;GPT-4&#65289;&#12290;&#21463;&#21040;&#20026;&#36825;&#31181;&#32463;&#39564;&#25104;&#21151;&#24320;&#21457;&#29702;&#35770;&#22522;&#30784;&#30340;&#21160;&#26426;&#65292;Lu&#65288;NeurIPS '23&#65292;ALT '24&#65289;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#27169;&#24577;&#23398;&#20064;&#29702;&#35770;&#65292;&#24182;&#32771;&#34385;&#20102;&#22810;&#27169;&#24577;&#21644;&#21333;&#27169;&#24577;&#23398;&#20064;&#30340;&#29702;&#35770;&#27169;&#22411;&#20043;&#38388;&#21487;&#33021;&#30340;&#20998;&#31163;&#12290;&#29305;&#21035;&#26159;Lu&#65288;ALT '24&#65289;&#23637;&#31034;&#20102;&#19968;&#31181;&#35745;&#31639;&#20998;&#31163;&#65292;&#36825;&#23545;&#23398;&#20064;&#20219;&#21153;&#30340;&#26368;&#22351;&#24773;&#20917;&#23454;&#20363;&#26159;&#30456;&#20851;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02254v1 Announce Type: cross  Abstract: In multimodal machine learning, multiple modalities of data (e.g., text and images) are combined to facilitate the learning of a better machine learning model, which remains applicable to a corresponding unimodal task (e.g., text generation). Recently, multimodal machine learning has enjoyed huge empirical success (e.g. GPT-4). Motivated to develop theoretical justification for this empirical success, Lu (NeurIPS '23, ALT '24) introduces a theory of multimodal learning, and considers possible separations between theoretical models of multimodal and unimodal learning. In particular, Lu (ALT '24) shows a computational separation, which is relevant to worst-case instances of the learning task.   In this paper, we give a stronger average-case computational separation, where for "typical" instances of the learning task, unimodal learning is computationally hard, but multimodal learning is easy. We then question how "organic" the average-cas
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#39318;&#27425;&#35777;&#26126;&#20102;&#22312;&#36716;&#31227;&#23398;&#20064;&#35774;&#32622;&#19979;&#65292;&#33391;&#24615;&#36807;&#25311;&#21512;&#32447;&#24615;&#25554;&#20540;&#22120;&#30340;&#38750;&#28176;&#36817;&#36229;&#39069;&#39118;&#38505;&#30028;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#31867;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2404.00522</link><description>&lt;p&gt;
&#26368;&#23567;&#33539;&#25968;&#25554;&#20540;&#22312;&#21327;&#21464;&#37327;&#36716;&#31227;&#19979;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Minimum-Norm Interpolation Under Covariate Shift
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00522
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#39318;&#27425;&#35777;&#26126;&#20102;&#22312;&#36716;&#31227;&#23398;&#20064;&#35774;&#32622;&#19979;&#65292;&#33391;&#24615;&#36807;&#25311;&#21512;&#32447;&#24615;&#25554;&#20540;&#22120;&#30340;&#38750;&#28176;&#36817;&#36229;&#39069;&#39118;&#38505;&#30028;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#31867;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36716;&#31227;&#23398;&#20064;&#26159;&#29616;&#23454;&#19990;&#30028;&#26426;&#22120;&#23398;&#20064;&#37096;&#32626;&#30340;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#65292;&#24182;&#22312;&#36807;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#30340;&#23454;&#39564;&#30740;&#31350;&#20013;&#24471;&#21040;&#24191;&#27867;&#30740;&#31350;&#12290;&#28982;&#32780;&#65292;&#21363;&#20351;&#22312;&#32447;&#24615;&#22238;&#24402;&#30340;&#26368;&#31616;&#21333;&#35774;&#32622;&#20013;&#65292;&#22312;&#23545;&#36716;&#31227;&#23398;&#20064;&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#23384;&#22312;&#26174;&#33879;&#24046;&#36317;&#12290;&#22312;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#30340;&#20998;&#24067;&#30740;&#31350;&#20013;&#65292;&#24050;&#32463;&#21457;&#29616;&#20102;&#19968;&#31181;&#34987;&#31216;&#20026;&#8220;&#33391;&#24615;&#36807;&#25311;&#21512;&#8221;&#29616;&#35937;&#30340;&#29616;&#35937;&#65292;&#21363;&#32447;&#24615;&#25554;&#20540;&#22120;&#20250;&#23545;&#22122;&#22768;&#35757;&#32451;&#26631;&#31614;&#36807;&#25311;&#21512;&#65292;&#20294;&#20173;&#28982;&#33021;&#24456;&#22909;&#22320;&#27867;&#21270;&#12290;&#36825;&#31181;&#34892;&#20026;&#21457;&#29983;&#22312;&#28304;&#21327;&#26041;&#24046;&#30697;&#38453;&#21644;&#36755;&#20837;&#25968;&#25454;&#32500;&#24230;&#19978;&#30340;&#29305;&#23450;&#26465;&#20214;&#19979;&#12290;&#22240;&#27492;&#65292;&#33258;&#28982;&#32780;&#28982;&#22320;&#24819;&#30693;&#36947;&#36825;&#26679;&#30340;&#39640;&#32500;&#32447;&#24615;&#27169;&#22411;&#22312;&#36716;&#31227;&#23398;&#20064;&#19979;&#22914;&#20309;&#34892;&#20026;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#36716;&#31227;&#23398;&#20064;&#35774;&#32622;&#20013;&#33391;&#24615;&#36807;&#25311;&#21512;&#32447;&#24615;&#25554;&#20540;&#22120;&#30340;&#31532;&#19968;&#20010;&#38750;&#28176;&#36817;&#36229;&#39069;&#39118;&#38505;&#30028;&#12290;&#36890;&#36807;&#25105;&#20204;&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23545;&#36716;&#31227;&#23398;&#20064;&#20013;&#30340;\textit {b&#36827;&#34892;&#20998;&#31867;}}&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00522v1 Announce Type: new  Abstract: Transfer learning is a critical part of real-world machine learning deployments and has been extensively studied in experimental works with overparameterized neural networks. However, even in the simplest setting of linear regression a notable gap still exists in the theoretical understanding of transfer learning. In-distribution research on high-dimensional linear regression has led to the identification of a phenomenon known as \textit{benign overfitting}, in which linear interpolators overfit to noisy training labels and yet still generalize well. This behavior occurs under specific conditions on the source covariance matrix and input data dimension. Therefore, it is natural to wonder how such high-dimensional linear models behave under transfer learning. We prove the first non-asymptotic excess risk bounds for benignly-overfit linear interpolators in the transfer learning setting. From our analysis, we propose a taxonomy of \textit{b
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#28151;&#21512;&#27169;&#22411;&#20013;&#24314;&#31435;&#20102;&#19968;&#20010;&#36890;&#29992;&#19979;&#30028;&#65292;&#36890;&#36807;Chernoff&#25955;&#24230;&#26469;&#34920;&#36798;&#65292;&#23558;&#20854;&#25299;&#23637;&#21040;&#20855;&#26377;&#27425;&#25351;&#25968;&#23614;&#37096;&#30340;&#28151;&#21512;&#27169;&#22411;&#65292;&#24182;&#35777;&#26126;&#20102;&#36845;&#20195;&#31639;&#27861;&#22312;&#36825;&#20123;&#28151;&#21512;&#27169;&#22411;&#20013;&#23454;&#29616;&#20102;&#26368;&#20339;&#35823;&#24046;&#29575;</title><link>https://arxiv.org/abs/2402.15432</link><description>&lt;p&gt;
&#22312;&#27425;&#25351;&#25968;&#28151;&#21512;&#27169;&#22411;&#20013;&#23454;&#29616;&#26497;&#23567;&#21270;&#32858;&#31867;&#35823;&#24046;&#65306;&#36890;&#29992;&#19979;&#30028;&#21644;&#26368;&#20339;&#36895;&#29575;
&lt;/p&gt;
&lt;p&gt;
Universal Lower Bounds and Optimal Rates: Achieving Minimax Clustering Error in Sub-Exponential Mixture Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15432
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#28151;&#21512;&#27169;&#22411;&#20013;&#24314;&#31435;&#20102;&#19968;&#20010;&#36890;&#29992;&#19979;&#30028;&#65292;&#36890;&#36807;Chernoff&#25955;&#24230;&#26469;&#34920;&#36798;&#65292;&#23558;&#20854;&#25299;&#23637;&#21040;&#20855;&#26377;&#27425;&#25351;&#25968;&#23614;&#37096;&#30340;&#28151;&#21512;&#27169;&#22411;&#65292;&#24182;&#35777;&#26126;&#20102;&#36845;&#20195;&#31639;&#27861;&#22312;&#36825;&#20123;&#28151;&#21512;&#27169;&#22411;&#20013;&#23454;&#29616;&#20102;&#26368;&#20339;&#35823;&#24046;&#29575;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32858;&#31867;&#26159;&#26080;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#65292;&#36890;&#24120;&#36890;&#36807;&#28151;&#21512;&#27169;&#22411;&#30340;&#35270;&#35282;&#26469;&#30740;&#31350;&#12290;&#22312;&#39640;&#26031;&#21644;&#27425;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#20013;&#24674;&#22797;&#32858;&#31867;&#26631;&#31614;&#30340;&#26368;&#20339;&#35823;&#24046;&#29575;&#28041;&#21450;&#21040;&#29305;&#23450;&#30340;&#20449;&#22122;&#27604;&#12290;&#31616;&#21333;&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#22914;Lloyd&#31639;&#27861;&#65292;&#21487;&#20197;&#36798;&#21040;&#36825;&#20010;&#26368;&#20339;&#35823;&#24046;&#29575;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#20026;&#20219;&#20309;&#28151;&#21512;&#27169;&#22411;&#20013;&#30340;&#35823;&#24046;&#29575;&#24314;&#31435;&#20102;&#19968;&#20010;&#36890;&#29992;&#19979;&#30028;&#65292;&#36890;&#36807;Chernoff&#25955;&#24230;&#26469;&#34920;&#36798;&#65292;&#36825;&#26159;&#19968;&#20010;&#27604;&#20449;&#22122;&#27604;&#26356;&#36890;&#29992;&#30340;&#27169;&#22411;&#20449;&#24687;&#24230;&#37327;&#12290;&#28982;&#21518;&#25105;&#20204;&#35777;&#26126;&#20102;&#36845;&#20195;&#31639;&#27861;&#22312;&#28151;&#21512;&#27169;&#22411;&#20013;&#23454;&#29616;&#20102;&#36825;&#20010;&#19979;&#30028;&#65292;&#29305;&#21035;&#24378;&#35843;&#20102;&#20855;&#26377;&#25289;&#26222;&#25289;&#26031;&#20998;&#24067;&#35823;&#24046;&#30340;&#20301;&#32622;-&#23610;&#24230;&#28151;&#21512;&#12290;&#27492;&#22806;&#65292;&#38024;&#23545;&#26356;&#36866;&#21512;&#30001;&#27850;&#26494;&#25110;&#36127;&#20108;&#39033;&#28151;&#21512;&#27169;&#22411;&#24314;&#27169;&#30340;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20854;&#20998;&#24067;&#23646;&#20110;&#25351;&#25968;&#26063;&#30340;&#28151;&#21512;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15432v1 Announce Type: cross  Abstract: Clustering is a pivotal challenge in unsupervised machine learning and is often investigated through the lens of mixture models. The optimal error rate for recovering cluster labels in Gaussian and sub-Gaussian mixture models involves ad hoc signal-to-noise ratios. Simple iterative algorithms, such as Lloyd's algorithm, attain this optimal error rate. In this paper, we first establish a universal lower bound for the error rate in clustering any mixture model, expressed through a Chernoff divergence, a more versatile measure of model information than signal-to-noise ratios. We then demonstrate that iterative algorithms attain this lower bound in mixture models with sub-exponential tails, notably emphasizing location-scale mixtures featuring Laplace-distributed errors. Additionally, for datasets better modelled by Poisson or Negative Binomial mixtures, we study mixture models whose distributions belong to an exponential family. In such m
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26368;&#36817;&#37051;&#35780;&#20998;&#20989;&#25968;&#20272;&#35745;&#22120;&#65292;&#36890;&#36807;&#21033;&#29992;&#35757;&#32451;&#38598;&#20013;&#30340;&#22810;&#20010;&#26679;&#26412;&#22823;&#22823;&#38477;&#20302;&#20102;&#20272;&#35745;&#22120;&#30340;&#26041;&#24046;&#65292;&#21487;&#29992;&#20110;&#35757;&#32451;&#19968;&#33268;&#24615;&#27169;&#22411;&#21644;&#25193;&#25955;&#27169;&#22411;&#65292;&#25552;&#39640;&#25910;&#25947;&#36895;&#24230;&#12289;&#26679;&#26412;&#36136;&#37327;&#65292;&#24182;&#20026;&#36827;&#19968;&#27493;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#26032;&#30340;&#21487;&#33021;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.08018</link><description>&lt;p&gt;
&#25193;&#25955;&#29983;&#25104;&#27169;&#22411;&#30340;&#26368;&#36817;&#37051;&#35780;&#20998;&#20272;&#35745;&#22120;
&lt;/p&gt;
&lt;p&gt;
Nearest Neighbour Score Estimators for Diffusion Generative Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08018
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26368;&#36817;&#37051;&#35780;&#20998;&#20989;&#25968;&#20272;&#35745;&#22120;&#65292;&#36890;&#36807;&#21033;&#29992;&#35757;&#32451;&#38598;&#20013;&#30340;&#22810;&#20010;&#26679;&#26412;&#22823;&#22823;&#38477;&#20302;&#20102;&#20272;&#35745;&#22120;&#30340;&#26041;&#24046;&#65292;&#21487;&#29992;&#20110;&#35757;&#32451;&#19968;&#33268;&#24615;&#27169;&#22411;&#21644;&#25193;&#25955;&#27169;&#22411;&#65292;&#25552;&#39640;&#25910;&#25947;&#36895;&#24230;&#12289;&#26679;&#26412;&#36136;&#37327;&#65292;&#24182;&#20026;&#36827;&#19968;&#27493;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#26032;&#30340;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35780;&#20998;&#20989;&#25968;&#20272;&#35745;&#26159;&#35757;&#32451;&#21644;&#37319;&#26679;&#25193;&#25955;&#29983;&#25104;&#27169;&#22411;&#30340;&#22522;&#30784;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#26368;&#24120;&#29992;&#30340;&#20272;&#35745;&#22120;&#35201;&#20040;&#26159;&#26377;&#20559;&#30340;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#65292;&#35201;&#20040;&#26159;&#22522;&#20110;&#26465;&#20214;&#35780;&#20998;&#30340;&#39640;&#26041;&#24046;&#33945;&#29305;&#21345;&#27931;&#20272;&#35745;&#22120;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#26368;&#36817;&#37051;&#35780;&#20998;&#20989;&#25968;&#20272;&#35745;&#22120;&#65292;&#21033;&#29992;&#35757;&#32451;&#38598;&#20013;&#30340;&#22810;&#20010;&#26679;&#26412;&#22823;&#22823;&#38477;&#20302;&#20102;&#20272;&#35745;&#22120;&#30340;&#26041;&#24046;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#24341;&#20154;&#27880;&#30446;&#30340;&#24212;&#29992;&#20013;&#21033;&#29992;&#20102;&#20302;&#26041;&#24046;&#20272;&#35745;&#22120;&#12290;&#22312;&#20351;&#29992;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#36827;&#34892;&#35757;&#32451;&#19968;&#33268;&#24615;&#27169;&#22411;&#26102;&#65292;&#25105;&#20204;&#25253;&#21578;&#20102;&#25910;&#25947;&#36895;&#24230;&#21644;&#26679;&#26412;&#36136;&#37327;&#26174;&#33879;&#25552;&#39640;&#12290;&#22312;&#25193;&#25955;&#27169;&#22411;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#21487;&#20197;&#26367;&#20195;&#23398;&#20064;&#32593;&#32476;&#36827;&#34892;&#27010;&#29575;&#27969;ODE&#31215;&#20998;&#65292;&#20026;&#26410;&#26469;&#30740;&#31350;&#24320;&#36767;&#20102;&#26377;&#21069;&#26223;&#30340;&#26032;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
Score function estimation is the cornerstone of both training and sampling from diffusion generative models. Despite this fact, the most commonly used estimators are either biased neural network approximations or high variance Monte Carlo estimators based on the conditional score. We introduce a novel nearest neighbour score function estimator which utilizes multiple samples from the training set to dramatically decrease estimator variance. We leverage our low variance estimator in two compelling applications. Training consistency models with our estimator, we report a significant increase in both convergence speed and sample quality. In diffusion models, we show that our estimator can replace a learned network for probability-flow ODE integration, opening promising new avenues of future research.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20379;&#20102;&#39318;&#20010;&#38024;&#23545;&#39044;&#35757;&#32451;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#38750;&#24179;&#20961;&#27867;&#21270;&#30028;&#38480;&#65292;&#34920;&#26126;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#21457;&#29616;&#36866;&#29992;&#20110;&#26410;&#35265;&#25968;&#25454;&#30340;&#35268;&#24459;&#24615;&#12290;&#24314;&#31435;&#20102;&#26377;&#25928;&#30340;&#21387;&#32553;&#30028;&#38480;&#65292;&#35777;&#26126;&#36739;&#22823;&#30340;&#27169;&#22411;&#20855;&#26377;&#26356;&#22909;&#30340;&#27867;&#21270;&#30028;&#38480;&#24182;&#26356;&#26131;&#21387;&#32553;&#12290;</title><link>https://arxiv.org/abs/2312.17173</link><description>&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#38750;&#24179;&#20961;&#27867;&#21270;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Non-Vacuous Generalization Bounds for Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.17173
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20379;&#20102;&#39318;&#20010;&#38024;&#23545;&#39044;&#35757;&#32451;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#38750;&#24179;&#20961;&#27867;&#21270;&#30028;&#38480;&#65292;&#34920;&#26126;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#21457;&#29616;&#36866;&#29992;&#20110;&#26410;&#35265;&#25968;&#25454;&#30340;&#35268;&#24459;&#24615;&#12290;&#24314;&#31435;&#20102;&#26377;&#25928;&#30340;&#21387;&#32553;&#30028;&#38480;&#65292;&#35777;&#26126;&#36739;&#22823;&#30340;&#27169;&#22411;&#20855;&#26377;&#26356;&#22909;&#30340;&#27867;&#21270;&#30028;&#38480;&#24182;&#26356;&#26131;&#21387;&#32553;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#21253;&#21547;&#25968;&#21313;&#20159;&#20010;&#21442;&#25968;&#65292;&#36825;&#24341;&#21457;&#20102;&#19968;&#20010;&#38382;&#39064;&#65292;&#23427;&#20204;&#26159;&#21542;&#21487;&#20197;&#22312;&#35757;&#32451;&#25968;&#25454;&#20043;&#22806;&#36827;&#34892;&#27867;&#21270;&#65292;&#25110;&#32773;&#21482;&#26159;&#37325;&#22797;&#23427;&#20204;&#30340;&#35757;&#32451;&#35821;&#26009;&#24211;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#39318;&#20010;&#38024;&#23545;&#39044;&#35757;&#32451;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#38750;&#24179;&#20961;&#27867;&#21270;&#30028;&#38480;&#65292;&#34920;&#26126;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#21457;&#29616;&#36866;&#29992;&#20110;&#26410;&#35265;&#25968;&#25454;&#30340;&#35268;&#24459;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20351;&#29992;&#39044;&#27979;&#24179;&#28369;&#23548;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#26080;&#30028;&#23545;&#25968;&#20284;&#28982;&#25439;&#22833;&#30340;&#21387;&#32553;&#30028;&#38480;&#65292;&#24182;&#19988;&#25105;&#20204;&#25193;&#23637;&#20102;&#35813;&#30028;&#38480;&#20197;&#22788;&#29702;&#23376;&#37319;&#26679;&#65292;&#21152;&#36895;&#23545;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#30340;&#30028;&#38480;&#35745;&#31639;&#12290;&#20026;&#20102;&#23454;&#29616;&#38750;&#24179;&#20961;&#27867;&#21270;&#30028;&#38480;&#25152;&#38656;&#30340;&#26497;&#31471;&#21387;&#32553;&#31243;&#24230;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;SubLoRA&#65292;&#36825;&#26159;&#19968;&#31181;&#20302;&#32500;&#38750;&#32447;&#24615;&#21442;&#25968;&#21270;&#26041;&#27861;&#12290;&#20351;&#29992;&#36825;&#31181;&#26041;&#27861;&#65292;&#25105;&#20204;&#21457;&#29616;&#36739;&#22823;&#30340;&#27169;&#22411;&#20855;&#26377;&#26356;&#22909;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#19988;&#27604;&#36739;&#23567;&#30340;&#27169;&#22411;&#26356;&#26131;&#21387;&#32553;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern language models can contain billions of parameters, raising the question of whether they can generalize beyond the training data or simply regurgitate their training corpora. We provide the first non-vacuous generalization bounds for pretrained large language models (LLMs), indicating that language models are capable of discovering regularities that generalize to unseen data. In particular, we derive a compression bound that is valid for the unbounded log-likelihood loss using prediction smoothing, and we extend the bound to handle subsampling, accelerating bound computation on massive datasets. To achieve the extreme level of compression required for non-vacuous generalization bounds, we devise SubLoRA, a low-dimensional non-linear parameterization. Using this approach, we find that larger models have better generalization bounds and are more compressible than smaller models.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#39640;&#26031;&#22240;&#23376;&#22270;&#20013;&#36827;&#34892;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#32622;&#20449;&#20256;&#25773;&#35299;&#20915;&#35757;&#32451;&#21644;&#39044;&#27979;&#38382;&#39064;&#65292;&#25903;&#25345;&#20998;&#24067;&#24335;&#21644;&#24322;&#27493;&#35757;&#32451;&#65292;&#21487;&#25193;&#23637;&#33267;&#28145;&#24230;&#32593;&#32476;&#65292;&#25552;&#20379;&#25345;&#32493;&#23398;&#20064;&#30340;&#33258;&#28982;&#26041;&#24335;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#35270;&#39057;&#21435;&#22122;&#21644;&#22270;&#20687;&#20998;&#31867;&#20219;&#21153;&#20013;&#30340;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2311.14649</link><description>&lt;p&gt;
&#22312;&#20855;&#26377;&#39640;&#26031;&#32622;&#20449;&#20256;&#25773;&#30340;&#28145;&#24230;&#22240;&#23376;&#22270;&#20013;&#36827;&#34892;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Learning in Deep Factor Graphs with Gaussian Belief Propagation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.14649
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#39640;&#26031;&#22240;&#23376;&#22270;&#20013;&#36827;&#34892;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#32622;&#20449;&#20256;&#25773;&#35299;&#20915;&#35757;&#32451;&#21644;&#39044;&#27979;&#38382;&#39064;&#65292;&#25903;&#25345;&#20998;&#24067;&#24335;&#21644;&#24322;&#27493;&#35757;&#32451;&#65292;&#21487;&#25193;&#23637;&#33267;&#28145;&#24230;&#32593;&#32476;&#65292;&#25552;&#20379;&#25345;&#32493;&#23398;&#20064;&#30340;&#33258;&#28982;&#26041;&#24335;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#35270;&#39057;&#21435;&#22122;&#21644;&#22270;&#20687;&#20998;&#31867;&#20219;&#21153;&#20013;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#39640;&#26031;&#22240;&#23376;&#22270;&#20013;&#36827;&#34892;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#23558;&#25152;&#26377;&#30456;&#20851;&#25968;&#37327;&#65288;&#36755;&#20837;&#12289;&#36755;&#20986;&#12289;&#21442;&#25968;&#12289;&#28508;&#21464;&#37327;&#65289;&#35270;&#20026;&#22270;&#27169;&#22411;&#20013;&#30340;&#38543;&#26426;&#21464;&#37327;&#65292;&#24182;&#23558;&#35757;&#32451;&#21644;&#39044;&#27979;&#37117;&#35270;&#20026;&#20855;&#26377;&#19981;&#21516;&#35266;&#23519;&#33410;&#28857;&#30340;&#25512;&#29702;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#36825;&#20123;&#38382;&#39064;&#21487;&#20197;&#36890;&#36807;&#32622;&#20449;&#20256;&#25773;&#65288;BP&#65289;&#26377;&#25928;&#22320;&#35299;&#20915;&#65292;&#20854;&#26356;&#26032;&#26412;&#36136;&#19978;&#26159;&#26412;&#22320;&#30340;&#65292;&#20026;&#20998;&#24067;&#24335;&#21644;&#24322;&#27493;&#35757;&#32451;&#25552;&#20379;&#20102;&#20196;&#20154;&#20852;&#22859;&#30340;&#26426;&#20250;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#25193;&#23637;&#21040;&#28145;&#23618;&#32593;&#32476;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#33258;&#28982;&#30340;&#25345;&#32493;&#23398;&#20064;&#26041;&#24335;&#65306;&#20351;&#29992;&#24403;&#21069;&#20219;&#21153;&#30340;BP&#20272;&#35745;&#21442;&#25968;&#36793;&#38469;&#20316;&#20026;&#19979;&#19968;&#20010;&#20219;&#21153;&#30340;&#21442;&#25968;&#20808;&#39564;&#12290;&#22312;&#35270;&#39057;&#21435;&#22122;&#20219;&#21153;&#19978;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21487;&#23398;&#20064;&#21442;&#25968;&#30456;&#23545;&#20110;&#20256;&#32479;&#22240;&#23376;&#22270;&#26041;&#27861;&#30340;&#20248;&#21183;&#65292;&#21516;&#26102;&#23637;&#31034;&#20102;&#28145;&#24230;&#22240;&#23376;&#22270;&#22312;&#25345;&#32493;&#22270;&#20687;&#20998;&#31867;&#26041;&#38754;&#30340;&#40723;&#33310;&#20154;&#24515;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.14649v2 Announce Type: replace  Abstract: We propose an approach to do learning in Gaussian factor graphs. We treat all relevant quantities (inputs, outputs, parameters, latents) as random variables in a graphical model, and view both training and prediction as inference problems with different observed nodes. Our experiments show that these problems can be efficiently solved with belief propagation (BP), whose updates are inherently local, presenting exciting opportunities for distributed and asynchronous training. Our approach can be scaled to deep networks and provides a natural means to do continual learning: use the BP-estimated parameter marginals of the current task as parameter priors for the next. On a video denoising task we demonstrate the benefit of learnable parameters over a classical factor graph approach and we show encouraging performance of deep factor graphs for continual image classification.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#26080;&#22122;&#22768;&#35266;&#27979;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25955;&#20081;&#25968;&#25454;&#36924;&#36817;&#30340;&#26032;&#31639;&#27861;&#65292;&#24182;&#24341;&#20837;&#38543;&#26426;&#25506;&#32034;&#27493;&#39588;&#20197;&#23454;&#29616;&#25509;&#36817;&#26368;&#20248;&#22635;&#20805;&#36317;&#31163;&#30340;&#36895;&#29575;&#34928;&#20943;&#12290;&#35813;&#31639;&#27861;&#22312;&#23454;&#29616;&#30340;&#26131;&#29992;&#24615;&#21644;&#32047;&#31215;&#36951;&#25022;&#36793;&#30028;&#30340;&#24615;&#33021;&#19978;&#36229;&#36807;&#20102;&#20256;&#32479;&#30340;GP-UCB&#31639;&#27861;&#65292;&#24182;&#22312;&#22810;&#20010;&#31034;&#20363;&#20013;&#20248;&#20110;&#20854;&#20182;&#36125;&#21494;&#26031;&#20248;&#21270;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2401.17037</link><description>&lt;p&gt;
&#22522;&#20110;&#26080;&#22122;&#22768;&#35266;&#27979;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65306;&#36890;&#36807;&#38543;&#26426;&#25506;&#32034;&#25913;&#21892;&#36951;&#25022;&#36793;&#30028;
&lt;/p&gt;
&lt;p&gt;
Bayesian Optimization with Noise-Free Observations: Improved Regret Bounds via Random Exploration. (arXiv:2401.17037v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.17037
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#26080;&#22122;&#22768;&#35266;&#27979;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25955;&#20081;&#25968;&#25454;&#36924;&#36817;&#30340;&#26032;&#31639;&#27861;&#65292;&#24182;&#24341;&#20837;&#38543;&#26426;&#25506;&#32034;&#27493;&#39588;&#20197;&#23454;&#29616;&#25509;&#36817;&#26368;&#20248;&#22635;&#20805;&#36317;&#31163;&#30340;&#36895;&#29575;&#34928;&#20943;&#12290;&#35813;&#31639;&#27861;&#22312;&#23454;&#29616;&#30340;&#26131;&#29992;&#24615;&#21644;&#32047;&#31215;&#36951;&#25022;&#36793;&#30028;&#30340;&#24615;&#33021;&#19978;&#36229;&#36807;&#20102;&#20256;&#32479;&#30340;GP-UCB&#31639;&#27861;&#65292;&#24182;&#22312;&#22810;&#20010;&#31034;&#20363;&#20013;&#20248;&#20110;&#20854;&#20182;&#36125;&#21494;&#26031;&#20248;&#21270;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#26080;&#22122;&#22768;&#35266;&#27979;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#26032;&#30340;&#22522;&#20110;&#25955;&#20081;&#25968;&#25454;&#36924;&#36817;&#30340;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#38543;&#26426;&#25506;&#32034;&#27493;&#39588;&#30830;&#20445;&#26597;&#35810;&#28857;&#30340;&#22635;&#20805;&#36317;&#31163;&#20197;&#25509;&#36817;&#26368;&#20248;&#30340;&#36895;&#29575;&#34928;&#20943;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20445;&#30041;&#20102;&#32463;&#20856;&#30340;GP-UCB&#31639;&#27861;&#30340;&#26131;&#23454;&#29616;&#24615;&#65292;&#24182;&#28385;&#36275;&#20102;&#20960;&#20046;&#19982;arXiv:2002.05096&#20013;&#30340;&#29468;&#24819;&#30456;&#21305;&#37197;&#30340;&#32047;&#31215;&#36951;&#25022;&#36793;&#30028;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;COLT&#30340;&#19968;&#20010;&#24320;&#25918;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#26032;&#31639;&#27861;&#22312;&#20960;&#20010;&#31034;&#20363;&#20013;&#20248;&#20110;GP-UCB&#21644;&#20854;&#20182;&#27969;&#34892;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies Bayesian optimization with noise-free observations. We introduce new algorithms rooted in scattered data approximation that rely on a random exploration step to ensure that the fill-distance of query points decays at a near-optimal rate. Our algorithms retain the ease of implementation of the classical GP-UCB algorithm and satisfy cumulative regret bounds that nearly match those conjectured in arXiv:2002.05096, hence solving a COLT open problem. Furthermore, the new algorithms outperform GP-UCB and other popular Bayesian optimization strategies in several examples.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;IW-GAE&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24320;&#21457;&#19968;&#31181;&#26032;&#39062;&#30340;&#21152;&#26435;&#32676;&#20934;&#30830;&#29575;&#20272;&#35745;&#22120;&#26469;&#35299;&#20915;&#38750;&#30417;&#30563;&#39046;&#22495;&#36866;&#24212;&#20013;&#30340;&#26657;&#20934;&#21644;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#32463;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#39564;&#39564;&#35777;&#65292;&#35813;&#26041;&#27861;&#22312;&#22788;&#29702;&#25968;&#25454;&#20998;&#24067;&#20559;&#31227;&#26041;&#38754;&#34920;&#29616;&#20986;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.10611</link><description>&lt;p&gt;
IW-GAE: &#29992;&#20110;&#25552;&#39640;&#38750;&#30417;&#30563;&#39046;&#22495;&#36866;&#24212;&#20013;&#30340;&#26657;&#20934;&#21644;&#27169;&#22411;&#36873;&#25321;&#30340;&#21152;&#26435;&#32676;&#20934;&#30830;&#29575;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
IW-GAE: Importance weighted group accuracy estimation for improved calibration and model selection in unsupervised domain adaptation. (arXiv:2310.10611v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10611
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;IW-GAE&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24320;&#21457;&#19968;&#31181;&#26032;&#39062;&#30340;&#21152;&#26435;&#32676;&#20934;&#30830;&#29575;&#20272;&#35745;&#22120;&#26469;&#35299;&#20915;&#38750;&#30417;&#30563;&#39046;&#22495;&#36866;&#24212;&#20013;&#30340;&#26657;&#20934;&#21644;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#32463;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#39564;&#39564;&#35777;&#65292;&#35813;&#26041;&#27861;&#22312;&#22788;&#29702;&#25968;&#25454;&#20998;&#24067;&#20559;&#31227;&#26041;&#38754;&#34920;&#29616;&#20986;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35745;&#31639;&#27169;&#22411;&#22312;&#27979;&#35797;&#26679;&#26412;&#19978;&#30340;&#20934;&#30830;&#29575;&#24182;&#20174;&#20013;&#25512;&#26029;&#20854;&#32622;&#20449;&#24230;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#26680;&#24515;&#38382;&#39064;&#65292;&#19982;&#19981;&#30830;&#23450;&#24615;&#34920;&#31034;&#12289;&#27169;&#22411;&#36873;&#25321;&#21644;&#25506;&#32034;&#31561;&#37325;&#35201;&#24212;&#29992;&#23494;&#20999;&#30456;&#20851;&#12290;&#34429;&#28982;&#36825;&#20123;&#36830;&#25509;&#22312;&#29420;&#31435;&#21516;&#20998;&#24067;&#35774;&#32622;&#20013;&#24050;&#32463;&#34987;&#24191;&#27867;&#30740;&#31350;&#65292;&#20294;&#25968;&#25454;&#20998;&#24067;&#30340;&#20559;&#31227;&#32473;&#20256;&#32479;&#26041;&#27861;&#24102;&#26469;&#20102;&#37325;&#22823;&#25361;&#25112;&#12290;&#22240;&#27492;&#65292;&#22312;&#38750;&#30417;&#30563;&#39046;&#22495;&#36866;&#24212;&#38382;&#39064;&#20013;&#65292;&#27169;&#22411;&#26657;&#20934;&#21644;&#27169;&#22411;&#36873;&#25321;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#36825;&#26159;&#19968;&#31181;&#22312;&#27809;&#26377;&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#22312;&#25968;&#25454;&#20998;&#24067;&#21457;&#29983;&#20559;&#31227;&#30340;&#39046;&#22495;&#20013;&#34920;&#29616;&#33391;&#22909;&#30340;&#22330;&#26223;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#24320;&#21457;&#19968;&#31181;&#26032;&#39062;&#30340;&#21152;&#26435;&#32676;&#20934;&#30830;&#29575;&#20272;&#35745;&#22120;&#26469;&#35299;&#20915;&#30001;&#20110;&#25968;&#25454;&#20998;&#24067;&#30340;&#20559;&#31227;&#32780;&#24102;&#26469;&#30340;&#22256;&#38590;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#21046;&#23450;&#20102;&#19968;&#20010;&#20248;&#21270;&#38382;&#39064;&#65292;&#25214;&#21040;&#23548;&#33268;&#22312;&#25968;&#25454;&#20998;&#24067;&#20559;&#31227;&#30340;&#39046;&#22495;&#20013;&#20934;&#30830;&#20272;&#35745;&#32676;&#20934;&#30830;&#29575;&#30340;&#37325;&#35201;&#26435;&#37325;&#65292;&#24182;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#12290;&#22823;&#37327;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20102;&#32676;&#20934;&#30830;&#29575;&#20272;&#35745;&#22312;&#27169;&#22411;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reasoning about a model's accuracy on a test sample from its confidence is a central problem in machine learning, being connected to important applications such as uncertainty representation, model selection, and exploration. While these connections have been well-studied in the i.i.d. settings, distribution shifts pose significant challenges to the traditional methods. Therefore, model calibration and model selection remain challenging in the unsupervised domain adaptation problem--a scenario where the goal is to perform well in a distribution shifted domain without labels. In this work, we tackle difficulties coming from distribution shifts by developing a novel importance weighted group accuracy estimator. Specifically, we formulate an optimization problem for finding an importance weight that leads to an accurate group accuracy estimation in the distribution shifted domain with theoretical analyses. Extensive experiments show the effectiveness of group accuracy estimation on model 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#31070;&#32463;&#32593;&#32476;&#30340;&#38544;&#24615;&#20559;&#24046;&#65292;&#30528;&#30524;&#20110;&#20854;&#20013;&#28041;&#21450;&#30340;&#20613;&#37324;&#21494;&#39057;&#29575;&#19982;&#22270;&#20687;&#20998;&#31867;&#21644;&#23545;&#25239;&#24615;&#25915;&#20987;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21487;&#20197;&#21457;&#29616;&#36825;&#20123;&#39057;&#29575;&#20043;&#38388;&#30340;&#38750;&#32447;&#24615;&#30456;&#20851;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.15203</link><description>&lt;p&gt;
&#36890;&#36807;&#20869;&#22312;&#32500;&#24230;&#23558;&#38544;&#24615;&#20559;&#35265;&#21644;&#23545;&#25239;&#24615;&#25915;&#20987;&#30456;&#20851;&#32852;
&lt;/p&gt;
&lt;p&gt;
Relating Implicit Bias and Adversarial Attacks through Intrinsic Dimension. (arXiv:2305.15203v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15203
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#31070;&#32463;&#32593;&#32476;&#30340;&#38544;&#24615;&#20559;&#24046;&#65292;&#30528;&#30524;&#20110;&#20854;&#20013;&#28041;&#21450;&#30340;&#20613;&#37324;&#21494;&#39057;&#29575;&#19982;&#22270;&#20687;&#20998;&#31867;&#21644;&#23545;&#25239;&#24615;&#25915;&#20987;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21487;&#20197;&#21457;&#29616;&#36825;&#20123;&#39057;&#29575;&#20043;&#38388;&#30340;&#38750;&#32447;&#24615;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#31070;&#32463;&#32593;&#32476;&#22312;&#20998;&#31867;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#20247;&#25152;&#21608;&#30693;&#23427;&#20204;&#26131;&#21463;&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#24433;&#21709;&#12290;&#36825;&#20123;&#25915;&#20987;&#26159;&#38024;&#23545;&#27169;&#22411;&#30340;&#36755;&#20837;&#25968;&#25454;&#36827;&#34892;&#30340;&#23567;&#24178;&#25200;&#65292;&#26088;&#22312;&#27450;&#39575;&#27169;&#22411;&#12290;&#33258;&#28982;&#32780;&#28982;&#30340;&#38382;&#39064;&#26159;&#65292;&#27169;&#22411;&#30340;&#32467;&#26500;&#12289;&#35774;&#32622;&#25110;&#23646;&#24615;&#19982;&#25915;&#20987;&#30340;&#24615;&#36136;&#20043;&#38388;&#21487;&#33021;&#23384;&#22312;&#28508;&#22312;&#32852;&#31995;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#36890;&#36807;&#20851;&#27880;&#31070;&#32463;&#32593;&#32476;&#30340;&#38544;&#24615;&#20559;&#24046;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#36825;&#25351;&#30340;&#26159;&#20854;&#22266;&#26377;&#20542;&#21521;&#20110;&#25903;&#25345;&#29305;&#23450;&#27169;&#24335;&#25110;&#32467;&#26524;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#38544;&#24615;&#20559;&#24046;&#30340;&#19968;&#20010;&#26041;&#38754;&#65292;&#20854;&#20013;&#21253;&#25324;&#36827;&#34892;&#20934;&#30830;&#22270;&#20687;&#20998;&#31867;&#25152;&#38656;&#30340;&#22522;&#26412;&#20613;&#37324;&#21494;&#39057;&#29575;&#12290;&#25105;&#20204;&#36827;&#34892;&#27979;&#35797;&#20197;&#35780;&#20272;&#36825;&#20123;&#39057;&#29575;&#19982;&#25104;&#21151;&#25915;&#20987;&#25152;&#38656;&#30340;&#39057;&#29575;&#20043;&#38388;&#30340;&#32479;&#35745;&#20851;&#31995;&#12290;&#20026;&#20102;&#28145;&#20837;&#25506;&#35752;&#36825;&#31181;&#20851;&#31995;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#25581;&#31034;&#22352;&#26631;&#38598;&#20043;&#38388;&#30340;&#38750;&#32447;&#24615;&#30456;&#20851;&#24615;&#65292;&#22312;&#25105;&#20204;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#20123;&#22352;&#26631;&#38598;&#23601;&#26159;&#21069;&#36848;&#30340;&#20613;&#37324;&#21494;&#39057;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite their impressive performance in classification, neural networks are known to be vulnerable to adversarial attacks. These attacks are small perturbations of the input data designed to fool the model. Naturally, a question arises regarding the potential connection between the architecture, settings, or properties of the model and the nature of the attack. In this work, we aim to shed light on this problem by focusing on the implicit bias of the neural network, which refers to its inherent inclination to favor specific patterns or outcomes. Specifically, we investigate one aspect of the implicit bias, which involves the essential Fourier frequencies required for accurate image classification. We conduct tests to assess the statistical relationship between these frequencies and those necessary for a successful attack. To delve into this relationship, we propose a new method that can uncover non-linear correlations between sets of coordinates, which, in our case, are the aforementio
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#25293;&#21334;&#35774;&#35745;&#39046;&#22495;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#65292;&#21363;&#26368;&#20248;&#25293;&#21334;&#35774;&#35745;&#12290;&#22312;&#30740;&#31350;&#20013;&#65292;&#20316;&#32773;&#35777;&#26126;&#20102;&#31070;&#32463;&#32593;&#32476;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#21487;&#20197;&#36890;&#36807;&#31616;&#21333;&#30340;&#20998;&#27573;&#32447;&#24615;&#36335;&#24452;&#36830;&#25509;&#19981;&#21516;&#30340;&#23616;&#37096;&#26368;&#20248;&#35299;&#65292;&#24182;&#21462;&#24471;&#20102;&#25104;&#21151;&#12290;</title><link>http://arxiv.org/abs/2305.11005</link><description>&lt;p&gt;
&#25293;&#21334;&#35774;&#35745;&#20013;&#30340;&#27169;&#24335;&#36830;&#36890;&#24615;
&lt;/p&gt;
&lt;p&gt;
Mode Connectivity in Auction Design. (arXiv:2305.11005v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11005
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#25293;&#21334;&#35774;&#35745;&#39046;&#22495;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#65292;&#21363;&#26368;&#20248;&#25293;&#21334;&#35774;&#35745;&#12290;&#22312;&#30740;&#31350;&#20013;&#65292;&#20316;&#32773;&#35777;&#26126;&#20102;&#31070;&#32463;&#32593;&#32476;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#21487;&#20197;&#36890;&#36807;&#31616;&#21333;&#30340;&#20998;&#27573;&#32447;&#24615;&#36335;&#24452;&#36830;&#25509;&#19981;&#21516;&#30340;&#23616;&#37096;&#26368;&#20248;&#35299;&#65292;&#24182;&#21462;&#24471;&#20102;&#25104;&#21151;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#20248;&#25293;&#21334;&#35774;&#35745;&#26159;&#31639;&#27861;&#21338;&#24328;&#35770;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#65292;&#21363;&#20351;&#22312;&#38750;&#24120;&#31616;&#21333;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#20010;&#38382;&#39064;&#20063;&#24456;&#38590;&#12290;&#26368;&#36817;&#19981;&#21516;&#30340;&#32463;&#27982;&#23398;&#21487;&#24494;&#20998;&#29702;&#35770;&#34920;&#26126;&#65292;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#26377;&#25928;&#22320;&#23398;&#20064;&#24050;&#30693;&#30340;&#26368;&#20248;&#25293;&#21334;&#26426;&#21046;&#65292;&#21457;&#29616;&#26377;&#36259;&#30340;&#26032;&#26426;&#21046;&#12290;&#20026;&#20102;&#29702;&#35770;&#19978;&#35777;&#26126;&#23427;&#20204;&#30340;&#23454;&#35777;&#25104;&#21151;&#65292;&#25105;&#20204;&#32858;&#28966;&#20110;&#31532;&#19968;&#20010;&#36825;&#26679;&#30340;&#32593;&#32476;&#65292;RochetNet&#65292;&#24182;&#30740;&#31350;&#25152;&#35859;&#30340;&#20223;&#23556;&#26497;&#22823;&#21270;&#25293;&#21334;&#30340;&#24191;&#20041;&#29256;&#26412;&#12290;&#25105;&#20204;&#35777;&#26126;&#23427;&#20204;&#28385;&#36275;&#27169;&#24335;&#36830;&#36890;&#24615;&#65292;&#21363;&#23616;&#37096;&#26368;&#20248;&#35299;&#36890;&#36807;&#19968;&#20010;&#31616;&#21333;&#30340;&#20998;&#27573;&#32447;&#24615;&#36335;&#24452;&#36830;&#25509;&#65292;&#36335;&#24452;&#19978;&#30340;&#27599;&#20010;&#35299;&#37117;&#20960;&#20046;&#21644;&#20004;&#20010;&#23616;&#37096;&#26368;&#20248;&#35299;&#20043;&#19968;&#19968;&#26679;&#22909;&#12290;&#27169;&#24335;&#36830;&#36890;&#24615;&#26368;&#36817;&#34987;&#35777;&#26126;&#26159;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#39044;&#27979;&#38382;&#39064;&#30340;&#19968;&#20010;&#26377;&#36259;&#30340;&#32463;&#39564;&#21644;&#29702;&#35770;&#30340;&#23646;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26159;&#23545;&#21487;&#24494;&#20998;&#32463;&#27982;&#23398;&#39046;&#22495;&#20013;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#35299;&#20915;&#38750;&#32447;&#24615;&#35774;&#35745;&#38382;&#39064;&#30340;&#31532;&#19968;&#20010;&#36825;&#26679;&#30340;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Optimal auction design is a fundamental problem in algorithmic game theory. This problem is notoriously difficult already in very simple settings. Recent work in differentiable economics showed that neural networks can efficiently learn known optimal auction mechanisms and discover interesting new ones. In an attempt to theoretically justify their empirical success, we focus on one of the first such networks, RochetNet, and a generalized version for affine maximizer auctions. We prove that they satisfy mode connectivity, i.e., locally optimal solutions are connected by a simple, piecewise linear path such that every solution on the path is almost as good as one of the two local optima. Mode connectivity has been recently investigated as an intriguing empirical and theoretically justifiable property of neural networks used for prediction problems. Our results give the first such analysis in the context of differentiable economics, where neural networks are used directly for solving non-
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20989;&#25968;&#25968;&#25454;&#30340;&#20998;&#24067;&#24335;&#26799;&#24230;&#19979;&#38477;&#20989;&#25968;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#26694;&#26550;&#19979;&#36890;&#36807;&#31215;&#20998;&#31639;&#23376;&#26041;&#27861;&#24471;&#21040;&#20102;&#35813;&#31639;&#27861;&#30340;&#29702;&#35770;&#29702;&#35299;&#65292;&#24182;&#21462;&#24471;&#20102;&#19981;&#39281;&#21644;&#36793;&#30028;&#30340;&#32622;&#20449;&#24230;&#26368;&#20248;&#23398;&#20064;&#29575;&#12290;</title><link>http://arxiv.org/abs/2305.07408</link><description>&lt;p&gt;
&#38754;&#21521;&#20989;&#25968;&#23398;&#20064;&#30340;&#20998;&#24067;&#24335;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Distributed Gradient Descent for Functional Learning. (arXiv:2305.07408v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07408
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20989;&#25968;&#25968;&#25454;&#30340;&#20998;&#24067;&#24335;&#26799;&#24230;&#19979;&#38477;&#20989;&#25968;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#26694;&#26550;&#19979;&#36890;&#36807;&#31215;&#20998;&#31639;&#23376;&#26041;&#27861;&#24471;&#21040;&#20102;&#35813;&#31639;&#27861;&#30340;&#29702;&#35770;&#29702;&#35299;&#65292;&#24182;&#21462;&#24471;&#20102;&#19981;&#39281;&#21644;&#36793;&#30028;&#30340;&#32622;&#20449;&#24230;&#26368;&#20248;&#23398;&#20064;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#19981;&#21516;&#31867;&#22411;&#30340;&#20998;&#24067;&#24335;&#23398;&#20064;&#26041;&#26696;&#22240;&#20854;&#22312;&#22788;&#29702;&#22823;&#35268;&#27169;&#25968;&#25454;&#20449;&#24687;&#26041;&#38754;&#30340;&#24040;&#22823;&#20248;&#21183;&#32780;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#38024;&#23545;&#26368;&#36817;&#20174;&#20989;&#25968;&#25968;&#25454;&#20998;&#26512;&#20013;&#20135;&#29983;&#30340;&#22823;&#25968;&#25454;&#25361;&#25112;&#65292;&#25105;&#20204;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#26694;&#26550;&#19979;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#24067;&#24335;&#26799;&#24230;&#19979;&#38477;&#20989;&#25968;&#23398;&#20064;&#65288;DGDFL&#65289;&#31639;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#26469;&#33258;&#20247;&#22810;&#26412;&#22320;&#26426;&#22120;&#65288;&#22788;&#29702;&#22120;&#65289;&#30340;&#20989;&#25968;&#25968;&#25454;&#12290;&#22522;&#20110;&#31215;&#20998;&#31639;&#23376;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;DGDFL&#31639;&#27861;&#22312;&#25991;&#29486;&#20013;&#30340;&#35768;&#22810;&#26041;&#38754;&#30340;&#31532;&#19968;&#20010;&#29702;&#35770;&#29702;&#35299;&#12290;&#22312;&#29702;&#35299;DGDFL&#30340;&#36807;&#31243;&#20013;&#65292;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#24182;&#20840;&#38754;&#30740;&#31350;&#20102;&#22522;&#20110;&#25968;&#25454;&#30340;&#28176;&#36827;&#24335;&#19979;&#38477;&#20989;&#25968;&#23398;&#20064;&#65288;GDFL&#65289;&#31639;&#27861;&#19982;&#21333;&#26426;&#27169;&#22411;&#30456;&#20851;&#32852;&#12290;&#22312;&#28201;&#21644;&#30340;&#26465;&#20214;&#19979;&#65292;&#24471;&#21040;&#20102;DGDFL&#30340;&#32622;&#20449;&#24230;&#26368;&#20248;&#23398;&#20064;&#29575;&#65292;&#36991;&#20813;&#20102;&#20808;&#21069;&#22312;&#27491;&#21017;&#24615;&#32034;&#24341;&#19978;&#36973;&#21463;&#30340;&#39281;&#21644;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, different types of distributed learning schemes have received increasing attention for their strong advantages in handling large-scale data information. In the information era, to face the big data challenges which stem from functional data analysis very recently, we propose a novel distributed gradient descent functional learning (DGDFL) algorithm to tackle functional data across numerous local machines (processors) in the framework of reproducing kernel Hilbert space. Based on integral operator approaches, we provide the first theoretical understanding of the DGDFL algorithm in many different aspects in the literature. On the way of understanding DGDFL, firstly, a data-based gradient descent functional learning (GDFL) algorithm associated with a single-machine model is proposed and comprehensively studied. Under mild conditions, confidence-based optimal learning rates of DGDFL are obtained without the saturation boundary on the regularity index suffered in previous w
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#36816;&#29992;&#25968;&#23398;&#21644;&#20248;&#21270;&#29702;&#35770;&#26041;&#27861;&#65292;&#23601; ReLU &#31070;&#32463;&#32593;&#32476;&#30340;&#28145;&#24230;&#19979;&#30028;&#20570;&#20102;&#25506;&#31350;&#65292;&#26377;&#21161;&#20110;&#26356;&#22909;&#22320;&#29702;&#35299;&#36825;&#31181;&#32593;&#32476;&#25152;&#33021;&#34920;&#31034;&#30340;&#20989;&#25968;&#31867;&#30340;&#24615;&#36136;&#12290;&#27492;&#22806;&#65292;&#35813;&#30740;&#31350;&#36824;&#32943;&#23450;&#20102;&#19968;&#39033;&#26087;&#30340;&#20998;&#27573;&#32447;&#24615;&#20989;&#25968;&#29468;&#24819;&#12290;</title><link>http://arxiv.org/abs/2105.14835</link><description>&lt;p&gt;
&#20851;&#20110; ReLU &#31070;&#32463;&#32593;&#32476;&#28145;&#24230;&#19979;&#30028;&#30340;&#25506;&#31350;
&lt;/p&gt;
&lt;p&gt;
Towards Lower Bounds on the Depth of ReLU Neural Networks. (arXiv:2105.14835v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2105.14835
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#36816;&#29992;&#25968;&#23398;&#21644;&#20248;&#21270;&#29702;&#35770;&#26041;&#27861;&#65292;&#23601; ReLU &#31070;&#32463;&#32593;&#32476;&#30340;&#28145;&#24230;&#19979;&#30028;&#20570;&#20102;&#25506;&#31350;&#65292;&#26377;&#21161;&#20110;&#26356;&#22909;&#22320;&#29702;&#35299;&#36825;&#31181;&#32593;&#32476;&#25152;&#33021;&#34920;&#31034;&#30340;&#20989;&#25968;&#31867;&#30340;&#24615;&#36136;&#12290;&#27492;&#22806;&#65292;&#35813;&#30740;&#31350;&#36824;&#32943;&#23450;&#20102;&#19968;&#39033;&#26087;&#30340;&#20998;&#27573;&#32447;&#24615;&#20989;&#25968;&#29468;&#24819;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36816;&#29992;&#28151;&#21512;&#25972;&#25968;&#20248;&#21270;&#12289;&#22810;&#38754;&#20307;&#29702;&#35770;&#21644;&#28909;&#24102;&#20960;&#20309;&#23398;&#31561;&#25216;&#26415;&#65292;&#20026;&#29702;&#35299;&#20855;&#26377; ReLU &#28608;&#27963;&#21644;&#32473;&#23450;&#32467;&#26500;&#30340;&#31070;&#32463;&#32593;&#32476;&#25152;&#33021;&#34920;&#31034;&#30340;&#20989;&#25968;&#31867;&#20570;&#20986;&#20102;&#26356;&#22909;&#30340;&#36129;&#29486;&#12290;&#23613;&#31649;&#26222;&#36866;&#36924;&#36817;&#23450;&#29702;&#35748;&#20026;&#21333;&#23618;&#38544;&#34255;&#23618;&#23601;&#36275;&#20197;&#23398;&#20064;&#20219;&#20309;&#20989;&#25968;&#65292;&#20294;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#25968;&#23398;&#30340;&#23545;&#31216;&#24615;&#65292;&#24182;&#35814;&#32454;&#25506;&#35752;&#20102;&#28155;&#21152;&#26356;&#22810;&#23618;&#65288;&#26080;&#22823;&#23567;&#38480;&#21046;&#65289;&#26102;&#26159;&#21542;&#20005;&#26684;&#22686;&#21152;&#20102;&#21487;&#34920;&#31034;&#20989;&#25968;&#30340;&#31867;&#12290;&#20316;&#20026;&#30740;&#31350;&#21103;&#20135;&#21697;&#65292;&#25105;&#20204;&#32943;&#23450;&#20102; Wang &#21644; Sun&#65288;2005&#65289;&#26377;&#20851;&#20998;&#27573;&#32447;&#24615;&#20989;&#25968;&#30340;&#19968;&#20010;&#26087;&#29468;&#24819;&#12290;&#25105;&#20204;&#36824;&#32473;&#20986;&#20102;&#34920;&#31034;&#20855;&#26377;&#23545;&#25968;&#28145;&#24230;&#20989;&#25968;&#25152;&#38656;&#30340;&#31070;&#32463;&#32593;&#32476;&#22823;&#23567;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
We contribute to a better understanding of the class of functions that can be represented by a neural network with ReLU activations and a given architecture. Using techniques from mixed-integer optimization, polyhedral theory, and tropical geometry, we provide a mathematical counterbalance to the universal approximation theorems which suggest that a single hidden layer is sufficient for learning any function. In particular, we investigate whether the class of exactly representable functions strictly increases by adding more layers (with no restrictions on size). As a by-product of our investigations, we settle an old conjecture about piecewise linear functions by Wang and Sun (2005) in the affirmative. We also present upper bounds on the sizes of neural networks required to represent functions with logarithmic depth.
&lt;/p&gt;</description></item></channel></rss>