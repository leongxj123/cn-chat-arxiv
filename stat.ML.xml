<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#23398;&#20064;&#21033;&#29992;&#35266;&#27979;&#25968;&#25454;&#25552;&#20986;&#20102;&#19968;&#31181;&#36880;&#27493;&#21452;&#37325;&#24378;&#20581;&#26041;&#27861;&#65292;&#36890;&#36807;&#21521;&#21518;&#24402;&#32435;&#35299;&#20915;&#20102;&#26368;&#20339;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;&#30340;&#38382;&#39064;</title><link>https://arxiv.org/abs/2404.00221</link><description>&lt;p&gt;
&#21033;&#29992;&#35266;&#27979;&#25968;&#25454;&#36827;&#34892;&#24378;&#20581;&#23398;&#20064;&#20197;&#33719;&#24471;&#26368;&#20339;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
Robust Learning for Optimal Dynamic Treatment Regimes with Observational Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00221
&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#21033;&#29992;&#35266;&#27979;&#25968;&#25454;&#25552;&#20986;&#20102;&#19968;&#31181;&#36880;&#27493;&#21452;&#37325;&#24378;&#20581;&#26041;&#27861;&#65292;&#36890;&#36807;&#21521;&#21518;&#24402;&#32435;&#35299;&#20915;&#20102;&#26368;&#20339;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;&#30340;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#20844;&#20849;&#25919;&#31574;&#21644;&#21307;&#30103;&#24178;&#39044;&#28041;&#21450;&#20854;&#27835;&#30103;&#20998;&#37197;&#20013;&#30340;&#21160;&#24577;&#24615;&#65292;&#27835;&#30103;&#36890;&#24120;&#20381;&#25454;&#20808;&#21069;&#27835;&#30103;&#30340;&#21382;&#21490;&#21644;&#30456;&#20851;&#29305;&#24449;&#23545;&#27599;&#20010;&#38454;&#27573;&#30340;&#25928;&#26524;&#20855;&#26377;&#24322;&#36136;&#24615;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#32479;&#35745;&#23398;&#20064;&#26368;&#20339;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;(DTR)&#65292;&#26681;&#25454;&#20010;&#20307;&#30340;&#21382;&#21490;&#25351;&#23548;&#27599;&#20010;&#38454;&#27573;&#30340;&#26368;&#20339;&#27835;&#30103;&#20998;&#37197;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35266;&#27979;&#25968;&#25454;&#30340;&#36880;&#27493;&#21452;&#37325;&#24378;&#20581;&#26041;&#27861;&#65292;&#22312;&#39034;&#24207;&#21487;&#24573;&#30053;&#24615;&#20551;&#35774;&#19979;&#23398;&#20064;&#26368;&#20339;DTR&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#21521;&#21518;&#24402;&#32435;&#35299;&#20915;&#20102;&#39034;&#24207;&#27835;&#30103;&#20998;&#37197;&#38382;&#39064;&#65292;&#22312;&#27599;&#19968;&#27493;&#20013;&#65292;&#25105;&#20204;&#32467;&#21512;&#20542;&#21521;&#35780;&#20998;&#21644;&#34892;&#21160;&#20540;&#20989;&#25968;(Q&#20989;&#25968;)&#30340;&#20272;&#35745;&#37327;&#65292;&#26500;&#24314;&#20102;&#25919;&#31574;&#20215;&#20540;&#30340;&#22686;&#24378;&#21453;&#21521;&#27010;&#29575;&#21152;&#26435;&#20272;&#35745;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00221v1 Announce Type: cross  Abstract: Many public policies and medical interventions involve dynamics in their treatment assignments, where treatments are sequentially assigned to the same individuals across multiple stages, and the effect of treatment at each stage is usually heterogeneous with respect to the history of prior treatments and associated characteristics. We study statistical learning of optimal dynamic treatment regimes (DTRs) that guide the optimal treatment assignment for each individual at each stage based on the individual's history. We propose a step-wise doubly-robust approach to learn the optimal DTR using observational data under the assumption of sequential ignorability. The approach solves the sequential treatment assignment problem through backward induction, where, at each step, we combine estimators of propensity scores and action-value functions (Q-functions) to construct augmented inverse probability weighting estimators of values of policies 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#22312;&#20998;&#25955;&#26426;&#22120;&#23398;&#20064;&#29983;&#24577;&#31995;&#32479;&#20013;&#30740;&#31350;&#20102;&#22996;&#25176;&#30340;&#25968;&#25454;&#25910;&#38598;&#38382;&#39064;&#65292;&#36890;&#36807;&#35774;&#35745;&#26368;&#20248;&#22865;&#32422;&#35299;&#20915;&#20102;&#27169;&#22411;&#36136;&#37327;&#35780;&#20272;&#30340;&#19981;&#30830;&#23450;&#24615;&#21644;&#23545;&#26368;&#20248;&#24615;&#33021;&#32570;&#20047;&#39044;&#20808;&#30693;&#35782;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2309.01837</link><description>&lt;p&gt;
&#22996;&#25176;&#20998;&#25955;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#25968;&#25454;&#25910;&#38598;
&lt;/p&gt;
&lt;p&gt;
Delegating Data Collection in Decentralized Machine Learning. (arXiv:2309.01837v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01837
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#22312;&#20998;&#25955;&#26426;&#22120;&#23398;&#20064;&#29983;&#24577;&#31995;&#32479;&#20013;&#30740;&#31350;&#20102;&#22996;&#25176;&#30340;&#25968;&#25454;&#25910;&#38598;&#38382;&#39064;&#65292;&#36890;&#36807;&#35774;&#35745;&#26368;&#20248;&#22865;&#32422;&#35299;&#20915;&#20102;&#27169;&#22411;&#36136;&#37327;&#35780;&#20272;&#30340;&#19981;&#30830;&#23450;&#24615;&#21644;&#23545;&#26368;&#20248;&#24615;&#33021;&#32570;&#20047;&#39044;&#20808;&#30693;&#35782;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#20998;&#25955;&#26426;&#22120;&#23398;&#20064;&#29983;&#24577;&#31995;&#32479;&#30340;&#20986;&#29616;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#25968;&#25454;&#25910;&#38598;&#30340;&#22996;&#25176;&#38382;&#39064;&#12290;&#20197;&#22865;&#32422;&#29702;&#35770;&#20026;&#20986;&#21457;&#28857;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#35299;&#20915;&#20004;&#20010;&#22522;&#26412;&#26426;&#22120;&#23398;&#20064;&#25361;&#25112;&#30340;&#26368;&#20248;&#21644;&#36817;&#20284;&#26368;&#20248;&#22865;&#32422;&#65306;&#27169;&#22411;&#36136;&#37327;&#35780;&#20272;&#30340;&#19981;&#30830;&#23450;&#24615;&#21644;&#23545;&#20219;&#20309;&#27169;&#22411;&#26368;&#20248;&#24615;&#33021;&#30340;&#32570;&#20047;&#30693;&#35782;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#36890;&#36807;&#31616;&#21333;&#30340;&#32447;&#24615;&#22865;&#32422;&#21487;&#20197;&#35299;&#20915;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#65292;&#21363;&#20351;&#22996;&#25176;&#20154;&#21482;&#26377;&#19968;&#20010;&#23567;&#30340;&#27979;&#35797;&#38598;&#65292;&#20063;&#33021;&#23454;&#29616;1-1/e&#30340;&#19968;&#31561;&#25928;&#29992;&#27700;&#24179;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#22996;&#25176;&#20154;&#27979;&#35797;&#38598;&#22823;&#23567;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#21487;&#20197;&#36798;&#21040;&#23545;&#26368;&#20248;&#25928;&#29992;&#30340;&#36924;&#36817;&#12290;&#20026;&#20102;&#35299;&#20915;&#23545;&#26368;&#20248;&#24615;&#33021;&#32570;&#20047;&#39044;&#20808;&#30693;&#35782;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20984;&#38382;&#39064;&#65292;&#21487;&#20197;&#33258;&#36866;&#24212;&#21644;&#39640;&#25928;&#22320;&#35745;&#31639;&#26368;&#20248;&#22865;&#32422;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by the emergence of decentralized machine learning ecosystems, we study the delegation of data collection. Taking the field of contract theory as our starting point, we design optimal and near-optimal contracts that deal with two fundamental machine learning challenges: lack of certainty in the assessment of model quality and lack of knowledge regarding the optimal performance of any model. We show that lack of certainty can be dealt with via simple linear contracts that achieve 1-1/e fraction of the first-best utility, even if the principal has a small test set. Furthermore, we give sufficient conditions on the size of the principal's test set that achieves a vanishing additive approximation to the optimal utility. To address the lack of a priori knowledge regarding the optimal performance, we give a convex program that can adaptively and efficiently compute the optimal contract.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#22522;&#20110;Haar&#38543;&#26426;&#37193;&#25110;&#27491;&#20132;&#28145;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#30340;&#26576;&#20123;&#27169;&#22411;&#30340;&#36755;&#20986;&#20250;&#25910;&#25947;&#20110;&#39640;&#26031;&#36807;&#31243;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#39640;&#26031;&#36807;&#31243;&#19981;&#33021;&#29992;&#20110;&#36890;&#36807;&#36125;&#21494;&#26031;&#32479;&#35745;&#23398;&#26469;&#26377;&#25928;&#39044;&#27979;QNN&#30340;&#36755;&#20986;&#12290;</title><link>http://arxiv.org/abs/2305.09957</link><description>&lt;p&gt;
&#28145;&#24230;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#23545;&#24212;&#39640;&#26031;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Deep quantum neural networks form Gaussian processes. (arXiv:2305.09957v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09957
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#22522;&#20110;Haar&#38543;&#26426;&#37193;&#25110;&#27491;&#20132;&#28145;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#30340;&#26576;&#20123;&#27169;&#22411;&#30340;&#36755;&#20986;&#20250;&#25910;&#25947;&#20110;&#39640;&#26031;&#36807;&#31243;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#39640;&#26031;&#36807;&#31243;&#19981;&#33021;&#29992;&#20110;&#36890;&#36807;&#36125;&#21494;&#26031;&#32479;&#35745;&#23398;&#26469;&#26377;&#25928;&#39044;&#27979;QNN&#30340;&#36755;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20247;&#25152;&#21608;&#30693;&#65292;&#20174;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#20808;&#39564;&#26465;&#20214;&#24320;&#22987;&#21021;&#22987;&#21270;&#30340;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#22312;&#38544;&#34255;&#23618;&#31070;&#32463;&#20803;&#25968;&#30446;&#36275;&#22815;&#22823;&#30340;&#26497;&#38480;&#19979;&#25910;&#25947;&#21040;&#39640;&#26031;&#36807;&#31243;&#12290;&#26412;&#25991;&#35777;&#26126;&#20102;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#65288;QNNs&#65289;&#20063;&#23384;&#22312;&#31867;&#20284;&#30340;&#32467;&#26524;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22522;&#20110;Haar&#38543;&#26426;&#37193;&#25110;&#27491;&#20132;&#28145;QNNs&#30340;&#26576;&#20123;&#27169;&#22411;&#30340;&#36755;&#20986;&#22312;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#32500;&#24230;$d$&#36275;&#22815;&#22823;&#26102;&#20250;&#25910;&#25947;&#20110;&#39640;&#26031;&#36807;&#31243;&#12290;&#30001;&#20110;&#36755;&#20837;&#29366;&#24577;&#12289;&#27979;&#37327;&#30340;&#21487;&#35266;&#27979;&#37327;&#20197;&#21450;&#37193;&#30697;&#38453;&#30340;&#20803;&#32032;&#19981;&#29420;&#31435;&#31561;&#22240;&#32032;&#30340;&#20316;&#29992;&#65292;&#26412;&#25991;&#23545;&#36825;&#19968;&#32467;&#26524;&#30340;&#25512;&#23548;&#27604;&#32463;&#20856;&#24773;&#24418;&#26356;&#21152;&#24494;&#22937;&#12290;&#25105;&#20204;&#20998;&#26512;&#30340;&#19968;&#20010;&#37325;&#35201;&#21518;&#26524;&#26159;&#65292;&#36825;&#20010;&#32467;&#26524;&#24471;&#21040;&#30340;&#39640;&#26031;&#36807;&#31243;&#19981;&#33021;&#36890;&#36807;&#36125;&#21494;&#26031;&#32479;&#35745;&#23398;&#26469;&#26377;&#25928;&#22320;&#39044;&#27979;QNN&#30340;&#36755;&#20986;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#23450;&#29702;&#34920;&#26126;&#65292;Haar&#38543;&#26426;QNNs&#20013;&#30340;&#27979;&#37327;&#29616;&#35937;&#27604;&#20197;&#21069;&#35748;&#20026;&#30340;&#35201;&#26356;&#20005;&#37325;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#28436;&#21592;&#30340;&#38598;&#20013;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is well known that artificial neural networks initialized from independent and identically distributed priors converge to Gaussian processes in the limit of large number of neurons per hidden layer. In this work we prove an analogous result for Quantum Neural Networks (QNNs). Namely, we show that the outputs of certain models based on Haar random unitary or orthogonal deep QNNs converge to Gaussian processes in the limit of large Hilbert space dimension $d$. The derivation of this result is more nuanced than in the classical case due the role played by the input states, the measurement observable, and the fact that the entries of unitary matrices are not independent. An important consequence of our analysis is that the ensuing Gaussian processes cannot be used to efficiently predict the outputs of the QNN via Bayesian statistics. Furthermore, our theorems imply that the concentration of measure phenomenon in Haar random QNNs is much worse than previously thought, as we prove that ex
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#36923;&#36753;&#25512;&#29702;&#20219;&#21153;&#20013;&#23545;&#26410;&#30693;&#25968;&#25454;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#25552;&#20379;&#20102;&#32593;&#32476;&#26550;&#26500;&#22312;&#35813;&#35774;&#32622;&#19979;&#30340;&#34920;&#29616;&#35777;&#25454;&#65292;&#21457;&#29616;&#20102;&#19968;&#31867;&#32593;&#32476;&#27169;&#22411;&#22312;&#26410;&#30693;&#25968;&#25454;&#19978;&#23398;&#20064;&#20102;&#26368;&#23567;&#24230;&#25554;&#20540;&#22120;&#65292;&#24182;&#23545;&#38271;&#24230;&#26222;&#36890;&#21270;&#29616;&#35937;&#25552;&#20379;&#20102;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2301.13105</link><description>&lt;p&gt;
&#23545;&#26410;&#30693;&#25968;&#25454;&#30340;&#27867;&#21270;&#12289;&#36923;&#36753;&#25512;&#29702;&#21644;&#23398;&#20301;&#35838;&#31243;&#30340;&#27010;&#36848;
&lt;/p&gt;
&lt;p&gt;
Generalization on the Unseen, Logic Reasoning and Degree Curriculum. (arXiv:2301.13105v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.13105
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#36923;&#36753;&#25512;&#29702;&#20219;&#21153;&#20013;&#23545;&#26410;&#30693;&#25968;&#25454;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#25552;&#20379;&#20102;&#32593;&#32476;&#26550;&#26500;&#22312;&#35813;&#35774;&#32622;&#19979;&#30340;&#34920;&#29616;&#35777;&#25454;&#65292;&#21457;&#29616;&#20102;&#19968;&#31867;&#32593;&#32476;&#27169;&#22411;&#22312;&#26410;&#30693;&#25968;&#25454;&#19978;&#23398;&#20064;&#20102;&#26368;&#23567;&#24230;&#25554;&#20540;&#22120;&#65292;&#24182;&#23545;&#38271;&#24230;&#26222;&#36890;&#21270;&#29616;&#35937;&#25552;&#20379;&#20102;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#36923;&#36753;&#65288;&#24067;&#23572;&#65289;&#20989;&#25968;&#30340;&#23398;&#20064;&#65292;&#37325;&#28857;&#22312;&#20110;&#23545;&#26410;&#30693;&#25968;&#25454;&#30340;&#27867;&#21270;&#65288;GOTU&#65289;&#35774;&#23450;&#65292;&#36825;&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#20998;&#24067;&#22806;&#27867;&#21270;&#30340;&#26696;&#20363;&#12290;&#36825;&#26159;&#30001;&#20110;&#26576;&#20123;&#25512;&#29702;&#20219;&#21153;&#65288;&#20363;&#22914;&#31639;&#26415;/&#36923;&#36753;&#65289;&#20013;&#25968;&#25454;&#30340;&#20016;&#23500;&#32452;&#21512;&#24615;&#36136;&#20351;&#24471;&#20195;&#34920;&#24615;&#25968;&#25454;&#37319;&#26679;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#24182;&#19988;&#22312;GOTU&#19979;&#25104;&#21151;&#23398;&#20064;&#20026;&#31532;&#19968;&#20010;&#8220;&#25512;&#29702;&#8221;&#23398;&#20064;&#32773;&#23637;&#31034;&#20102;&#19968;&#20010;&#23567;&#25554;&#22270;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#36890;&#36807;(S)GD&#35757;&#32451;&#30340;&#19981;&#21516;&#32593;&#32476;&#26550;&#26500;&#22312;GOTU&#19979;&#30340;&#34920;&#29616;&#65292;&#24182;&#25552;&#20379;&#20102;&#29702;&#35770;&#21644;&#23454;&#39564;&#35777;&#25454;&#65292;&#35777;&#26126;&#20102;&#19968;&#20010;&#31867;&#21035;&#30340;&#32593;&#32476;&#27169;&#22411;&#65288;&#21253;&#25324;Transformer&#30340;&#23454;&#20363;&#12289;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#21644;&#23545;&#35282;&#32447;&#32447;&#24615;&#32593;&#32476;&#65289;&#22312;&#26410;&#30693;&#25968;&#25454;&#19978;&#23398;&#20064;&#20102;&#26368;&#23567;&#24230;&#25554;&#20540;&#22120;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#35777;&#25454;&#34920;&#26126;&#65292;&#20854;&#20182;&#20855;&#26377;&#26356;&#22823;&#23398;&#20064;&#36895;&#29575;&#25110;&#22343;&#22330;&#32593;&#32476;&#30340;&#23454;&#20363;&#36798;&#21040;&#20102;&#28183;&#28431;&#26368;&#23567;&#24230;&#35299;&#12290;&#36825;&#20123;&#21457;&#29616;&#24102;&#26469;&#20102;&#20004;&#20010;&#24433;&#21709;&#65306;&#65288;1&#65289;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#38271;&#24230;&#26222;&#36890;&#21270;&#30340;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
This paper considers the learning of logical (Boolean) functions with focus on the generalization on the unseen (GOTU) setting, a strong case of out-of-distribution generalization. This is motivated by the fact that the rich combinatorial nature of data in certain reasoning tasks (e.g., arithmetic/logic) makes representative data sampling challenging, and learning successfully under GOTU gives a first vignette of an 'extrapolating' or 'reasoning' learner. We then study how different network architectures trained by (S)GD perform under GOTU and provide both theoretical and experimental evidence that for a class of network models including instances of Transformers, random features models, and diagonal linear networks, a min-degree-interpolator is learned on the unseen. We also provide evidence that other instances with larger learning rates or mean-field networks reach leaky min-degree solutions. These findings lead to two implications: (1) we provide an explanation to the length genera
&lt;/p&gt;</description></item></channel></rss>