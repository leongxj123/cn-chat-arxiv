<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#24322;&#24120;&#20540;&#30699;&#27491;&#26426;&#21046;&#65292;&#36890;&#36807;&#23558;&#30699;&#27491;&#21644;&#20272;&#35745;&#38598;&#25104;&#21040;&#32852;&#21512;&#20248;&#21270;&#26694;&#26550;&#20013;&#65292;&#21033;&#29992;&#26368;&#20248;&#36755;&#36816;&#21644;&#20985;&#25104;&#26412;&#20989;&#25968;&#26469;&#26816;&#27979;&#21644;&#31227;&#38500;&#24322;&#24120;&#20540;&#65292;&#24182;&#36873;&#25321;&#26368;&#20339;&#20998;&#24067;&#26469;&#25191;&#34892;&#20272;&#35745;&#20219;&#21153;</title><link>https://arxiv.org/abs/2403.14067</link><description>&lt;p&gt;
&#36890;&#36807;&#26368;&#20248;&#36755;&#36816;&#30340;&#33258;&#21160;&#24322;&#24120;&#20540;&#30699;&#27491;
&lt;/p&gt;
&lt;p&gt;
Automatic Outlier Rectification via Optimal Transport
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14067
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#24322;&#24120;&#20540;&#30699;&#27491;&#26426;&#21046;&#65292;&#36890;&#36807;&#23558;&#30699;&#27491;&#21644;&#20272;&#35745;&#38598;&#25104;&#21040;&#32852;&#21512;&#20248;&#21270;&#26694;&#26550;&#20013;&#65292;&#21033;&#29992;&#26368;&#20248;&#36755;&#36816;&#21644;&#20985;&#25104;&#26412;&#20989;&#25968;&#26469;&#26816;&#27979;&#21644;&#31227;&#38500;&#24322;&#24120;&#20540;&#65292;&#24182;&#36873;&#25321;&#26368;&#20339;&#20998;&#24067;&#26469;&#25191;&#34892;&#20272;&#35745;&#20219;&#21153;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#27010;&#24565;&#26694;&#26550;&#65292;&#20351;&#29992;&#20855;&#26377;&#20985;&#25104;&#26412;&#20989;&#25968;&#30340;&#26368;&#20248;&#36755;&#36816;&#26469;&#26816;&#27979;&#24322;&#24120;&#20540;&#12290;&#20256;&#32479;&#30340;&#24322;&#24120;&#20540;&#26816;&#27979;&#26041;&#27861;&#36890;&#24120;&#20351;&#29992;&#20004;&#38454;&#27573;&#27969;&#31243;&#65306;&#39318;&#20808;&#26816;&#27979;&#24182;&#31227;&#38500;&#24322;&#24120;&#20540;&#65292;&#28982;&#21518;&#22312;&#28165;&#27905;&#25968;&#25454;&#19978;&#25191;&#34892;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#24182;&#27809;&#26377;&#23558;&#24322;&#24120;&#20540;&#31227;&#38500;&#19982;&#20272;&#35745;&#20219;&#21153;&#32852;&#31995;&#36215;&#26469;&#65292;&#30041;&#19979;&#20102;&#25913;&#36827;&#30340;&#31354;&#38388;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#23616;&#38480;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#24322;&#24120;&#20540;&#30699;&#27491;&#26426;&#21046;&#65292;&#23558;&#30699;&#27491;&#21644;&#20272;&#35745;&#38598;&#25104;&#21040;&#19968;&#20010;&#32852;&#21512;&#20248;&#21270;&#26694;&#26550;&#20013;&#12290;&#25105;&#20204;&#39318;&#20808;&#21033;&#29992;&#20855;&#26377;&#20985;&#25104;&#26412;&#20989;&#25968;&#30340;&#26368;&#20248;&#36755;&#36816;&#36317;&#31163;&#26469;&#26500;&#24314;&#27010;&#29575;&#20998;&#24067;&#31354;&#38388;&#20013;&#30340;&#30699;&#27491;&#38598;&#21512;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#36873;&#25321;&#22312;&#30699;&#27491;&#38598;&#21512;&#20013;&#30340;&#26368;&#20339;&#20998;&#24067;&#26469;&#25191;&#34892;&#20272;&#35745;&#20219;&#21153;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#22312;&#26412;&#25991;&#20013;&#24341;&#20837;&#30340;&#20985;&#25104;&#26412;&#20989;&#25968;&#26159;&#20351;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#20855;&#26377;&#20851;&#38190;&#24615;&#30340;&#22240;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14067v1 Announce Type: cross  Abstract: In this paper, we propose a novel conceptual framework to detect outliers using optimal transport with a concave cost function. Conventional outlier detection approaches typically use a two-stage procedure: first, outliers are detected and removed, and then estimation is performed on the cleaned data. However, this approach does not inform outlier removal with the estimation task, leaving room for improvement. To address this limitation, we propose an automatic outlier rectification mechanism that integrates rectification and estimation within a joint optimization framework. We take the first step to utilize an optimal transport distance with a concave cost function to construct a rectification set in the space of probability distributions. Then, we select the best distribution within the rectification set to perform the estimation task. Notably, the concave cost function we introduced in this paper is the key to making our estimator e
&lt;/p&gt;</description></item><item><title>gadjid&#36719;&#20214;&#21253;&#25552;&#20379;&#20102;&#19968;&#31181;&#29992;&#20110;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#30340;&#35843;&#25972;&#35782;&#21035;&#36317;&#31163;&#65292;&#36890;&#36807;&#24341;&#20837;&#26694;&#26550;&#26469;&#35745;&#31639;&#22240;&#26524;&#36317;&#31163;&#65292;&#36825;&#20123;&#36317;&#31163;&#33021;&#22815;&#39640;&#25928;&#35780;&#20272;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#23398;&#20064;&#30340;&#22270;&#24418;&#65292;&#24182;&#19988;&#22312;&#22788;&#29702;&#22823;&#35268;&#27169;&#22270;&#24418;&#26102;&#20855;&#26377;&#36739;&#39640;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.08616</link><description>&lt;p&gt;
Adjustment Identification Distance: &#19968;&#31181;&#29992;&#20110;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#30340;&#35843;&#25972;&#35782;&#21035;&#36317;&#31163;
&lt;/p&gt;
&lt;p&gt;
Adjustment Identification Distance: A gadjid for Causal Structure Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08616
&lt;/p&gt;
&lt;p&gt;
gadjid&#36719;&#20214;&#21253;&#25552;&#20379;&#20102;&#19968;&#31181;&#29992;&#20110;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#30340;&#35843;&#25972;&#35782;&#21035;&#36317;&#31163;&#65292;&#36890;&#36807;&#24341;&#20837;&#26694;&#26550;&#26469;&#35745;&#31639;&#22240;&#26524;&#36317;&#31163;&#65292;&#36825;&#20123;&#36317;&#31163;&#33021;&#22815;&#39640;&#25928;&#35780;&#20272;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#23398;&#20064;&#30340;&#22270;&#24418;&#65292;&#24182;&#19988;&#22312;&#22788;&#29702;&#22823;&#35268;&#27169;&#22270;&#24418;&#26102;&#20855;&#26377;&#36739;&#39640;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#23398;&#20064;&#30340;&#22270;&#24418;&#30340;&#35780;&#20272;&#26159;&#22256;&#38590;&#30340;&#65306;&#20004;&#20010;&#22270;&#24418;&#20043;&#38388;&#19981;&#21516;&#30340;&#36793;&#30340;&#25968;&#37327;&#19981;&#33021;&#21453;&#26144;&#20986;&#23427;&#20204;&#22312;&#24314;&#35758;&#22240;&#26524;&#25928;&#24212;&#30340;&#35782;&#21035;&#20844;&#24335;&#26041;&#38754;&#26377;&#20309;&#19981;&#21516;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#24320;&#21457;&#22270;&#24418;&#20043;&#38388;&#30340;&#22240;&#26524;&#36317;&#31163;&#65292;&#20854;&#20013;&#21253;&#25324;&#26377;&#21521;&#26080;&#29615;&#22270;&#30340;&#32467;&#26500;&#24178;&#39044;&#36317;&#31163;&#20316;&#20026;&#19968;&#31181;&#29305;&#27530;&#24773;&#20917;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#20010;&#26694;&#26550;&#24320;&#21457;&#20102;&#25913;&#36827;&#30340;&#22522;&#20110;&#35843;&#25972;&#30340;&#36317;&#31163;&#65292;&#20197;&#21450;&#23545;&#23436;&#25104;&#30340;&#37096;&#20998;&#26377;&#21521;&#26080;&#29615;&#22270;&#21644;&#22240;&#26524;&#24207;&#21015;&#30340;&#25193;&#23637;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#22810;&#39033;&#24335;&#26102;&#38388;&#21487;&#36798;&#24615;&#31639;&#27861;&#26469;&#39640;&#25928;&#35745;&#31639;&#36317;&#31163;&#12290;&#22312;&#25105;&#20204;&#30340;gadjid&#36719;&#20214;&#21253;&#20013;&#65288;&#22312;https://github.com/CausalDisco/gadjid&#19978;&#24320;&#28304;&#65289;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#25105;&#20204;&#30340;&#36317;&#31163;&#23454;&#29616;&#65307;&#23427;&#20204;&#30340;&#36816;&#34892;&#36895;&#24230;&#27604;&#32467;&#26500;&#24178;&#39044;&#36317;&#31163;&#24555;&#20960;&#20010;&#25968;&#37327;&#32423;&#65292;&#20174;&#32780;&#20026;&#20197;&#21069;&#26080;&#27861;&#25193;&#23637;&#30340;&#22270;&#24418;&#23610;&#23544;&#25552;&#20379;&#20102;&#19968;&#20010;&#22240;&#26524;&#21457;&#29616;&#30340;&#25104;&#21151;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
Evaluating graphs learned by causal discovery algorithms is difficult: The number of edges that differ between two graphs does not reflect how the graphs differ with respect to the identifying formulas they suggest for causal effects. We introduce a framework for developing causal distances between graphs which includes the structural intervention distance for directed acyclic graphs as a special case. We use this framework to develop improved adjustment-based distances as well as extensions to completed partially directed acyclic graphs and causal orders. We develop polynomial-time reachability algorithms to compute the distances efficiently. In our package gadjid (open source at https://github.com/CausalDisco/gadjid), we provide implementations of our distances; they are orders of magnitude faster than the structural intervention distance and thereby provide a success metric for causal discovery that scales to graph sizes that were previously prohibitive.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21629;&#21517;&#20026;FKMD&#30340;&#20808;&#36827;KMD&#25216;&#26415;&#65292;&#36890;&#36807;&#26102;&#38388;&#23884;&#20837;&#21644;&#39532;&#27663;&#36317;&#31163;&#32553;&#25918;&#65292;&#21487;&#20197;&#22686;&#24378;&#23545;&#39640;&#32500;&#21160;&#21147;&#31995;&#32479;&#30340;&#20998;&#26512;&#21644;&#39044;&#27979;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#29305;&#24449;&#26410;&#30693;&#30340;&#24773;&#20917;&#65292;&#24182;&#22312;&#19993;&#27688;&#37240;&#20108;&#32957;&#25968;&#25454;&#38477;&#32500;&#21644;&#20998;&#26512;Lorenz&#21560;&#24341;&#23376;&#21644;&#30284;&#30151;&#30740;&#31350;&#20013;&#32454;&#32990;&#20449;&#21495;&#38382;&#39064;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2312.09146</link><description>&lt;p&gt;
&#23545;Koopman&#27169;&#24577;&#20998;&#35299;&#36827;&#34892;&#29305;&#24449;&#21270;&#22788;&#29702;
&lt;/p&gt;
&lt;p&gt;
Featurizing Koopman Mode Decomposition
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.09146
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21629;&#21517;&#20026;FKMD&#30340;&#20808;&#36827;KMD&#25216;&#26415;&#65292;&#36890;&#36807;&#26102;&#38388;&#23884;&#20837;&#21644;&#39532;&#27663;&#36317;&#31163;&#32553;&#25918;&#65292;&#21487;&#20197;&#22686;&#24378;&#23545;&#39640;&#32500;&#21160;&#21147;&#31995;&#32479;&#30340;&#20998;&#26512;&#21644;&#39044;&#27979;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#29305;&#24449;&#26410;&#30693;&#30340;&#24773;&#20917;&#65292;&#24182;&#22312;&#19993;&#27688;&#37240;&#20108;&#32957;&#25968;&#25454;&#38477;&#32500;&#21644;&#20998;&#26512;Lorenz&#21560;&#24341;&#23376;&#21644;&#30284;&#30151;&#30740;&#31350;&#20013;&#32454;&#32990;&#20449;&#21495;&#38382;&#39064;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20808;&#36827;&#30340;Koopman&#27169;&#24577;&#20998;&#35299;&#65288;KMD&#65289;&#25216;&#26415;&#65306;&#21629;&#21517;&#20026;&#29305;&#24449;&#21270;Koopman&#27169;&#24577;&#20998;&#35299;&#65288;FKMD&#65289;&#65292;&#35813;&#25216;&#26415;&#21033;&#29992;&#26102;&#38388;&#23884;&#20837;&#21644;&#39532;&#27663;&#36317;&#31163;&#32553;&#25918;&#26469;&#22686;&#24378;&#23545;&#39640;&#32500;&#21160;&#21147;&#31995;&#32479;&#30340;&#20998;&#26512;&#21644;&#39044;&#27979;&#12290;&#26102;&#38388;&#23884;&#20837;&#25193;&#23637;&#20102;&#35266;&#27979;&#31354;&#38388;&#65292;&#26356;&#22909;&#22320;&#25429;&#25417;&#22522;&#30784;&#27969;&#24418;&#32467;&#26500;&#65292;&#32780;&#24212;&#29992;&#20110;&#26680;&#20989;&#25968;&#25110;&#38543;&#26426;&#20613;&#37324;&#21494;&#29305;&#24449;&#30340;&#39532;&#27663;&#36317;&#31163;&#32553;&#25918;&#65292;&#21017;&#26681;&#25454;&#31995;&#32479;&#30340;&#21160;&#24577;&#35843;&#25972;&#35266;&#27979;&#20540;&#12290;&#36825;&#26377;&#21161;&#20110;&#22312;&#19981;&#20107;&#20808;&#30693;&#36947;&#33391;&#22909;&#29305;&#24449;&#30340;&#24773;&#20917;&#19979;&#23545;KMD&#36827;&#34892;&#29305;&#24449;&#21270;&#22788;&#29702;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;FKMD&#20013;&#30340;&#39532;&#27663;&#36317;&#31163;&#32553;&#25918;&#21487;&#29992;&#20110;&#23545;&#19993;&#27688;&#37240;&#20108;&#32957;&#25968;&#25454;&#36827;&#34892;&#26377;&#25928;&#30340;&#38477;&#32500;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;FKMD&#22914;&#20309;&#25913;&#21892;&#23545;&#39640;&#32500;Lorenz&#21560;&#24341;&#23376;&#21644;&#30284;&#30151;&#30740;&#31350;&#20013;&#30340;&#32454;&#32990;&#20449;&#21495;&#38382;&#39064;&#30340;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.09146v3 Announce Type: replace-cross  Abstract: This article introduces an advanced Koopman mode decomposition (KMD) technique -- coined Featurized Koopman Mode Decomposition (FKMD) -- that uses time embedding and Mahalanobis scaling to enhance analysis and prediction of high dimensional dynamical systems. The time embedding expands the observation space to better capture underlying manifold structure, while the Mahalanobis scaling, applied to kernel or random Fourier features, adjusts observations based on the system's dynamics. This aids in featurizing KMD in cases where good features are not a priori known. We find that the Mahalanobis scaling from FKMD can be used for effective dimensionality reduction of alanine dipeptide data. We also show that FKMD improves predictions for a high-dimensional Lorenz attractor and a cell signaling problem from cancer research.
&lt;/p&gt;</description></item><item><title>&#20998;&#22359;&#26159;&#36830;&#32493;&#23398;&#20064;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#65292;&#21344;&#25454;&#23454;&#39564;&#20013;&#31163;&#32447;&#23398;&#20064;&#24615;&#33021;&#19979;&#38477;&#30340;&#32422;&#19968;&#21322;&#12290;&#24403;&#21069;&#30340;&#36830;&#32493;&#23398;&#20064;&#31639;&#27861;&#27809;&#26377;&#35299;&#20915;&#20998;&#22359;&#38382;&#39064;&#65292;&#21482;&#26377;&#22312;&#25968;&#25454;&#20998;&#24067;&#27809;&#26377;&#21464;&#21270;&#26102;&#34920;&#29616;&#19982;&#26222;&#36890;SGD&#35757;&#32451;&#30456;&#20223;&#12290;</title><link>http://arxiv.org/abs/2310.02206</link><description>&lt;p&gt;
&#20998;&#22359;&#65306;&#21363;&#20351;&#22312;&#19981;&#25913;&#21464;&#20219;&#21153;&#30340;&#24773;&#20917;&#19979;&#22312;&#36830;&#32493;&#23398;&#20064;&#20013;&#36951;&#24536;&#20063;&#24456;&#37325;&#35201;
&lt;/p&gt;
&lt;p&gt;
Chunking: Forgetting Matters in Continual Learning even without Changing Tasks. (arXiv:2310.02206v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02206
&lt;/p&gt;
&lt;p&gt;
&#20998;&#22359;&#26159;&#36830;&#32493;&#23398;&#20064;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#65292;&#21344;&#25454;&#23454;&#39564;&#20013;&#31163;&#32447;&#23398;&#20064;&#24615;&#33021;&#19979;&#38477;&#30340;&#32422;&#19968;&#21322;&#12290;&#24403;&#21069;&#30340;&#36830;&#32493;&#23398;&#20064;&#31639;&#27861;&#27809;&#26377;&#35299;&#20915;&#20998;&#22359;&#38382;&#39064;&#65292;&#21482;&#26377;&#22312;&#25968;&#25454;&#20998;&#24067;&#27809;&#26377;&#21464;&#21270;&#26102;&#34920;&#29616;&#19982;&#26222;&#36890;SGD&#35757;&#32451;&#30456;&#20223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36830;&#32493;&#23398;&#20064;&#65288;CL&#65289;&#30340;&#30740;&#31350;&#20013;&#65292;&#20027;&#35201;&#20851;&#27880;&#21160;&#24577;&#21464;&#21270;&#30340;&#25968;&#25454;&#20998;&#24067;&#25152;&#24102;&#26469;&#30340;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;CL&#21487;&#20197;&#20998;&#35299;&#20026;&#20004;&#20010;&#23376;&#38382;&#39064;&#65306;&#65288;a&#65289;&#25968;&#25454;&#20998;&#24067;&#30340;&#21464;&#21270;&#65292;&#20197;&#21450;&#65288;b&#65289;&#22788;&#29702;&#25968;&#25454;&#34987;&#20998;&#25104;&#22359;&#30340;&#20107;&#23454;&#65292;&#22240;&#27492;&#22312;&#20219;&#20309;&#26102;&#38388;&#28857;&#19978;&#21482;&#26377;&#19968;&#37096;&#20998;&#25968;&#25454;&#21487;&#29992;&#20110;&#35757;&#32451;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20851;&#27880;&#21518;&#32773;&#30340;&#23376;&#38382;&#39064;--&#25968;&#25454;&#30340;&#20998;&#22359;--&#24182;&#27880;&#24847;&#21040;&#20197;&#21069;&#23545;CL&#25991;&#29486;&#20013;&#20851;&#20110;&#20998;&#22359;&#30340;&#20998;&#26512;&#24456;&#23569;&#12290;&#25105;&#20204;&#26174;&#31034;&#20986;&#20998;&#22359;&#26159;CL&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#65292;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#21344;&#25454;&#20102;&#31163;&#32447;&#23398;&#20064;&#24615;&#33021;&#19979;&#38477;&#30340;&#32422;&#19968;&#21322;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#26174;&#31034;&#65292;&#24403;&#21069;&#30340;CL&#31639;&#27861;&#27809;&#26377;&#35299;&#20915;&#20998;&#22359;&#23376;&#38382;&#39064;&#65292;&#21482;&#26377;&#22312;&#25968;&#25454;&#20998;&#24067;&#27809;&#26377;&#21464;&#21270;&#26102;&#25165;&#33021;&#34920;&#29616;&#20986;&#19982;&#26222;&#36890;SGD&#35757;&#32451;&#19968;&#26679;&#30340;&#27700;&#24179;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#20026;&#20160;&#20040;&#22312;&#25968;&#25454;&#22359;&#19978;&#36827;&#34892;&#23398;&#20064;&#26102;&#24615;&#33021;&#20250;&#19979;&#38477;&#65292;&#24182;&#21457;&#29616;&#36951;&#24536;&#26159;&#19968;&#20010;&#32463;&#24120;&#34987;&#30475;&#20316;&#26159;&#38382;&#39064;&#30340;&#21407;&#22240;&#12290;
&lt;/p&gt;
&lt;p&gt;
Work on continual learning (CL) has largely focused on the problems arising from the dynamically-changing data distribution. However, CL can be decomposed into two sub-problems: (a) shifts in the data distribution, and (b) dealing with the fact that the data is split into chunks and so only a part of the data is available to be trained on at any point in time. In this work, we look at the latter sub-problem -- the chunking of data -- and note that previous analysis of chunking in the CL literature is sparse. We show that chunking is an important part of CL, accounting for around half of the performance drop from offline learning in our experiments. Furthermore, our results reveal that current CL algorithms do not address the chunking sub-problem, only performing as well as plain SGD training when there is no shift in the data distribution. We analyse why performance drops when learning occurs on chunks of data, and find that forgetting, which is often seen to be a problem due to distri
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;CLIP&#20013;&#30340;&#21487;&#36716;&#31227;&#34920;&#31034;&#23398;&#20064;&#21644;&#38646;&#26679;&#26412;&#20256;&#36882;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;CLIP&#31867;&#22411;&#26041;&#27861;&#65292;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.00927</link><description>&lt;p&gt;
&#29702;&#35299;CLIP&#20013;&#30340;&#21487;&#36716;&#31227;&#34920;&#31034;&#23398;&#20064;&#21644;&#38646;&#26679;&#26412;&#20256;&#36882;
&lt;/p&gt;
&lt;p&gt;
Understanding Transferable Representation Learning and Zero-shot Transfer in CLIP. (arXiv:2310.00927v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00927
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;CLIP&#20013;&#30340;&#21487;&#36716;&#31227;&#34920;&#31034;&#23398;&#20064;&#21644;&#38646;&#26679;&#26412;&#20256;&#36882;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;CLIP&#31867;&#22411;&#26041;&#27861;&#65292;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24577;&#23398;&#20064;&#22240;&#20854;&#33021;&#22815;&#21033;&#29992;&#19981;&#21516;&#25968;&#25454;&#28304;&#65288;&#20363;&#22914;&#25991;&#26412;&#21644;&#22270;&#20687;&#65289;&#30340;&#20449;&#24687;&#26469;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#32780;&#26085;&#30410;&#21463;&#21040;&#20851;&#27880;&#12290;&#36817;&#24180;&#26469;&#65292;CLIP&#20316;&#20026;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#37319;&#29992;&#35270;&#35273;-&#35821;&#35328;&#23545;&#27604;&#39044;&#35757;&#32451;&#26469;&#23398;&#20064;&#32852;&#21512;&#22270;&#20687;&#21644;&#25991;&#26412;&#34920;&#31034;&#65292;&#24182;&#22312;&#38646;&#26679;&#26412;&#23398;&#20064;&#21644;&#25991;&#26412;&#24341;&#23548;&#30340;&#33258;&#28982;&#22270;&#20687;&#29983;&#25104;&#26041;&#38754;&#34920;&#29616;&#20986;&#38750;&#20961;&#30340;&#24615;&#33021;&#12290;&#23613;&#31649;CLIP&#22312;&#23454;&#36341;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#25104;&#21151;&#65292;&#20294;&#20854;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#22256;&#38590;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#27491;&#24335;&#30740;&#31350;&#20102;CLIP&#20013;&#30340;&#21487;&#36716;&#31227;&#34920;&#31034;&#23398;&#20064;&#65292;&#24182;&#23637;&#31034;&#20102;&#19981;&#21516;&#27169;&#24577;&#30340;&#29305;&#24449;&#22914;&#20309;&#23545;&#40784;&#12290;&#25105;&#20204;&#36824;&#20998;&#26512;&#20102;&#20854;&#22312;&#19979;&#28216;&#20219;&#21153;&#20013;&#30340;&#38646;&#26679;&#26412;&#20256;&#36882;&#24615;&#33021;&#12290;&#21463;&#21040;&#25105;&#20204;&#20998;&#26512;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;CLIP&#31867;&#22411;&#26041;&#27861;&#65292;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#27604;CLIP&#21644;&#20854;&#20182;&#26368;&#20808;&#36827;&#26041;&#27861;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-modal learning has become increasingly popular due to its ability to leverage information from different data sources (e.g., text and images) to improve the model performance. Recently, CLIP has emerged as an effective approach that employs vision-language contrastive pretraining to learn joint image and text representations and exhibits remarkable performance in zero-shot learning and text-guided natural image generation. Despite the huge practical success of CLIP, its theoretical understanding remains elusive. In this paper, we formally study transferrable representation learning underlying CLIP and demonstrate how features from different modalities get aligned. We also analyze its zero-shot transfer performance on the downstream tasks. Inspired by our analysis, we propose a new CLIP-type approach, which achieves better performance than CLIP and other state-of-the-art methods on benchmark datasets.
&lt;/p&gt;</description></item><item><title>&#38024;&#23545;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#65292;&#26412;&#25991;&#24341;&#20837;&#20102;&#20004;&#31181;&#24378;&#20581;&#30340;&#38543;&#26426;&#39044;&#22788;&#29702;&#25216;&#26415;&#65292;&#20998;&#21035;&#35299;&#20915;&#20102;&#20840;&#25968;&#25454;KRR&#38382;&#39064;&#21644;&#38480;&#21046;&#29256;KRR&#38382;&#39064;&#65292;&#20811;&#26381;&#20102;&#20197;&#24448;&#39044;&#22788;&#29702;&#22120;&#30340;&#25925;&#38556;&#27169;&#24335;&#12290;</title><link>http://arxiv.org/abs/2304.12465</link><description>&lt;p&gt;
&#24378;&#20581;&#30340;&#38543;&#26426;&#39044;&#22788;&#29702;&#26041;&#27861;&#35299;&#20915;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Robust, randomized preconditioning for kernel ridge regression. (arXiv:2304.12465v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12465
&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#65292;&#26412;&#25991;&#24341;&#20837;&#20102;&#20004;&#31181;&#24378;&#20581;&#30340;&#38543;&#26426;&#39044;&#22788;&#29702;&#25216;&#26415;&#65292;&#20998;&#21035;&#35299;&#20915;&#20102;&#20840;&#25968;&#25454;KRR&#38382;&#39064;&#21644;&#38480;&#21046;&#29256;KRR&#38382;&#39064;&#65292;&#20811;&#26381;&#20102;&#20197;&#24448;&#39044;&#22788;&#29702;&#22120;&#30340;&#25925;&#38556;&#27169;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#38543;&#26426;&#39044;&#22788;&#29702;&#25216;&#26415;&#65292;&#29992;&#20110;&#24378;&#20581;&#22320;&#35299;&#20915;&#20855;&#26377;&#20013;&#22823;&#35268;&#27169;&#25968;&#25454;&#28857;&#65288;$10^4 \leq N \leq 10^7$&#65289;&#30340;&#26680;&#23725;&#22238;&#24402;&#65288;KRR&#65289;&#38382;&#39064;&#12290;&#31532;&#19968;&#31181;&#26041;&#27861;&#65292;RPCholesky&#39044;&#22788;&#29702;&#65292;&#33021;&#22815;&#22312;&#20551;&#35774;&#26680;&#30697;&#38453;&#29305;&#24449;&#20540;&#26377;&#36275;&#22815;&#24555;&#36895;&#30340;&#22810;&#39033;&#24335;&#34928;&#20943;&#30340;&#24773;&#20917;&#19979;&#65292;&#20197;$O&#65288;N ^ 2&#65289;$&#31639;&#27861;&#25805;&#20316;&#20934;&#30830;&#22320;&#35299;&#20915;&#20840;&#25968;&#25454;KRR&#38382;&#39064;&#12290;&#31532;&#20108;&#31181;&#26041;&#27861;&#65292;KRILL&#39044;&#22788;&#29702;&#65292;&#20197;$O&#65288;&#65288;N + k ^ 2&#65289;k \ logk&#65289;$&#30340;&#20195;&#20215;&#65292;&#20026;KRR&#38382;&#39064;&#30340;&#38480;&#21046;&#29256;&#26412;&#25552;&#20379;&#20934;&#30830;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#35813;&#29256;&#26412;&#28041;&#21450;$k \ll N$&#36873;&#25321;&#30340;&#25968;&#25454;&#20013;&#24515;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#35299;&#20915;&#20102;&#24191;&#27867;&#30340;KRR&#38382;&#39064;&#65292;&#20811;&#26381;&#20102;&#20197;&#21069;&#30340;KRR&#39044;&#22788;&#29702;&#22120;&#30340;&#25925;&#38556;&#27169;&#24335;&#65292;&#20351;&#23427;&#20204;&#25104;&#20026;&#23454;&#38469;&#24212;&#29992;&#30340;&#29702;&#24819;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces two randomized preconditioning techniques for robustly solving kernel ridge regression (KRR) problems with a medium to large number of data points ($10^4 \leq N \leq 10^7$). The first method, RPCholesky preconditioning, is capable of accurately solving the full-data KRR problem in $O(N^2)$ arithmetic operations, assuming sufficiently rapid polynomial decay of the kernel matrix eigenvalues. The second method, KRILL preconditioning, offers an accurate solution to a restricted version of the KRR problem involving $k \ll N$ selected data centers at a cost of $O((N + k^2) k \log k)$ operations. The proposed methods solve a broad range of KRR problems and overcome the failure modes of previous KRR preconditioners, making them ideal for practical applications.
&lt;/p&gt;</description></item></channel></rss>