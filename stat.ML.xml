<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#36890;&#36807;&#25552;&#20379;&#35777;&#25454;&#34920;&#26126;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#31070;&#32463;&#22349;&#22604;&#20027;&#35201;&#26159;&#36890;&#36807;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#36827;&#34892;&#28145;&#24230;&#29305;&#24449;&#23398;&#20064;&#30340;&#65292;&#26435;&#37325;&#30340;&#22855;&#24322;&#32467;&#26500;&#19982;AGOP&#39640;&#24230;&#30456;&#20851;&#65292;&#23548;&#33268;&#31867;&#20869;&#21464;&#24322;&#22349;&#22604;&#12290;</title><link>https://arxiv.org/abs/2402.13728</link><description>&lt;p&gt;
&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#20316;&#20026;&#28145;&#24230;&#31070;&#32463;&#22349;&#22604;&#26426;&#21046;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Average gradient outer product as a mechanism for deep neural collapse
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13728
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25552;&#20379;&#35777;&#25454;&#34920;&#26126;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#31070;&#32463;&#22349;&#22604;&#20027;&#35201;&#26159;&#36890;&#36807;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#36827;&#34892;&#28145;&#24230;&#29305;&#24449;&#23398;&#20064;&#30340;&#65292;&#26435;&#37325;&#30340;&#22855;&#24322;&#32467;&#26500;&#19982;AGOP&#39640;&#24230;&#30456;&#20851;&#65292;&#23548;&#33268;&#31867;&#20869;&#21464;&#24322;&#22349;&#22604;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Deep Neural Collapse (DNC)&#25351;&#30340;&#26159;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#26368;&#21518;&#20960;&#23618;&#25968;&#25454;&#34920;&#31034;&#30340;&#24778;&#20154;&#21018;&#24615;&#32467;&#26500;&#12290;&#23613;&#31649;&#36825;&#31181;&#29616;&#35937;&#22312;&#21508;&#31181;&#24773;&#22659;&#20013;&#37117;&#24471;&#21040;&#20102;&#27979;&#37327;&#65292;&#20294;&#20854;&#20986;&#29616;&#21482;&#26377;&#37096;&#20998;&#34987;&#29702;&#35299;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#20805;&#20998;&#35777;&#25454;&#65292;&#34920;&#26126;DNC&#20027;&#35201;&#26159;&#36890;&#36807;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;(AGOP)&#36827;&#34892;&#28145;&#24230;&#29305;&#24449;&#23398;&#20064;&#32780;&#21457;&#29983;&#30340;&#12290;&#30456;&#27604;&#20110;&#35299;&#37322;&#31070;&#32463;&#22349;&#22604;&#30340;&#29305;&#24449;&#19981;&#21487;&#30693;&#26041;&#27861;&#65292;&#22914;&#26080;&#32422;&#26463;&#29305;&#24449;&#27169;&#22411;&#65292;&#36825;&#19968;&#36827;&#23637;&#26356;&#36827;&#19968;&#27493;&#12290;&#25105;&#20204;&#32487;&#32493;&#25552;&#20379;&#35777;&#25454;&#34920;&#26126;&#65292;&#26435;&#37325;&#30340;&#21491;&#22855;&#24322;&#21521;&#37327;&#21644;&#22855;&#24322;&#20540;&#26159;DNN&#20013;&#31867;&#20869;&#21464;&#24322;&#22349;&#22604;&#30340;&#20027;&#35201;&#22240;&#32032;&#12290;&#27491;&#22914;&#26368;&#36817;&#30340;&#30740;&#31350;&#25152;&#31034;&#65292;&#36825;&#31181;&#22855;&#24322;&#32467;&#26500;&#19982;AGOP&#30340;&#39640;&#24230;&#30456;&#20851;&#12290;&#28982;&#21518;&#25105;&#20204;&#22312;&#23454;&#39564;&#21644;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;AGOP&#22312;&#38543;&#26426;&#21021;&#22987;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#20013;&#24341;&#21457;&#31070;&#32463;&#22349;&#22604;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13728v1 Announce Type: new  Abstract: Deep Neural Collapse (DNC) refers to the surprisingly rigid structure of the data representations in the final layers of Deep Neural Networks (DNNs). Though the phenomenon has been measured in a wide variety of settings, its emergence is only partially understood. In this work, we provide substantial evidence that DNC formation occurs primarily through deep feature learning with the average gradient outer product (AGOP). This takes a step further compared to efforts that explain neural collapse via feature-agnostic approaches, such as the unconstrained features model. We proceed by providing evidence that the right singular vectors and values of the weights are responsible for the majority of within-class variability collapse in DNNs. As shown in recent work, this singular structure is highly correlated with that of the AGOP. We then establish experimentally and theoretically that AGOP induces neural collapse in a randomly initialized ne
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#31163;&#32447;&#25968;&#25454;&#20013;&#30340;&#38544;&#31169;&#27169;&#22411;&#20197;&#21450;&#22522;&#20110;&#27169;&#22411;&#30340;&#31574;&#30053;&#20248;&#21270;&#65292;&#23454;&#29616;&#20102;&#20174;&#31163;&#32447;&#25968;&#25454;&#20013;&#35757;&#32451;&#20855;&#26377;&#38544;&#31169;&#20445;&#25252;&#30340;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#12290;&#21516;&#26102;&#65292;&#30740;&#31350;&#36824;&#24635;&#32467;&#20102;&#22312;&#36825;&#31181;&#35774;&#32622;&#19979;&#38544;&#31169;&#30340;&#20195;&#20215;&#12290;</title><link>https://arxiv.org/abs/2402.05525</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Model-Based Offline Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05525
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#31163;&#32447;&#25968;&#25454;&#20013;&#30340;&#38544;&#31169;&#27169;&#22411;&#20197;&#21450;&#22522;&#20110;&#27169;&#22411;&#30340;&#31574;&#30053;&#20248;&#21270;&#65292;&#23454;&#29616;&#20102;&#20174;&#31163;&#32447;&#25968;&#25454;&#20013;&#35757;&#32451;&#20855;&#26377;&#38544;&#31169;&#20445;&#25252;&#30340;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#12290;&#21516;&#26102;&#65292;&#30740;&#31350;&#36824;&#24635;&#32467;&#20102;&#22312;&#36825;&#31181;&#35774;&#32622;&#19979;&#38544;&#31169;&#30340;&#20195;&#20215;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35299;&#20915;&#20102;&#20855;&#26377;&#38544;&#31169;&#20445;&#35777;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#65292;&#30446;&#26631;&#26159;&#35757;&#32451;&#19968;&#20010;&#30456;&#23545;&#20110;&#25968;&#25454;&#38598;&#20013;&#27599;&#20010;&#36712;&#36857;&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;&#30340;&#31574;&#30053;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;DP-MORL&#65292;&#19968;&#31181;&#24102;&#26377;&#24046;&#20998;&#38544;&#31169;&#20445;&#35777;&#30340;MBRL&#31639;&#27861;&#12290;&#39318;&#20808;&#65292;&#20351;&#29992;DP-FedAvg&#20174;&#31163;&#32447;&#25968;&#25454;&#20013;&#23398;&#20064;&#29615;&#22659;&#30340;&#38544;&#31169;&#27169;&#22411;&#65292;DP-FedAvg&#26159;&#19968;&#31181;&#20026;&#31070;&#32463;&#32593;&#32476;&#25552;&#20379;&#36712;&#36857;&#32423;&#24046;&#20998;&#38544;&#31169;&#20445;&#35777;&#30340;&#35757;&#32451;&#26041;&#27861;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;&#27169;&#22411;&#30340;&#31574;&#30053;&#20248;&#21270;&#20174;&#65288;&#21463;&#32602;&#30340;&#65289;&#38544;&#31169;&#27169;&#22411;&#20013;&#25512;&#23548;&#20986;&#31574;&#30053;&#65292;&#26080;&#38656;&#36827;&#19968;&#27493;&#19982;&#31995;&#32479;&#20132;&#20114;&#25110;&#35775;&#38382;&#36755;&#20837;&#25968;&#25454;&#12290;&#25105;&#20204;&#32463;&#39564;&#35777;&#26126;&#65292;DP-MORL&#33021;&#22815;&#20174;&#31163;&#32447;&#25968;&#25454;&#20013;&#35757;&#32451;&#20986;&#20855;&#26377;&#38544;&#31169;&#20445;&#25252;&#30340;RL&#20195;&#29702;&#65292;&#24182;&#36827;&#19968;&#27493;&#27010;&#36848;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#38544;&#31169;&#30340;&#20195;&#20215;&#12290;
&lt;/p&gt;
&lt;p&gt;
We address offline reinforcement learning with privacy guarantees, where the goal is to train a policy that is differentially private with respect to individual trajectories in the dataset. To achieve this, we introduce DP-MORL, an MBRL algorithm coming with differential privacy guarantees. A private model of the environment is first learned from offline data using DP-FedAvg, a training method for neural networks that provides differential privacy guarantees at the trajectory level. Then, we use model-based policy optimization to derive a policy from the (penalized) private model, without any further interaction with the system or access to the input data. We empirically show that DP-MORL enables the training of private RL agents from offline data and we furthermore outline the price of privacy in this setting.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#22122;&#22768;&#35843;&#24230;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#30446;&#26631;&#20998;&#24067;&#21644;&#20272;&#35745;&#20998;&#24067;&#20043;&#38388;KL&#25955;&#24230;&#30340;&#19978;&#30028;&#20197;&#21450;Wasserstein&#36317;&#31163;&#30340;&#25913;&#36827;&#35823;&#24046;&#30028;&#38480;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#33258;&#21160;&#35843;&#33410;&#22122;&#22768;&#35843;&#24230;&#30340;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.04650</link><description>&lt;p&gt;
&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#22122;&#22768;&#35843;&#24230;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
An analysis of the noise schedule for score-based generative models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04650
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#22122;&#22768;&#35843;&#24230;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#30446;&#26631;&#20998;&#24067;&#21644;&#20272;&#35745;&#20998;&#24067;&#20043;&#38388;KL&#25955;&#24230;&#30340;&#19978;&#30028;&#20197;&#21450;Wasserstein&#36317;&#31163;&#30340;&#25913;&#36827;&#35823;&#24046;&#30028;&#38480;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#33258;&#21160;&#35843;&#33410;&#22122;&#22768;&#35843;&#24230;&#30340;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#65288;SGMs&#65289;&#26088;&#22312;&#36890;&#36807;&#20165;&#20351;&#29992;&#30446;&#26631;&#25968;&#25454;&#30340;&#22122;&#22768;&#25200;&#21160;&#26679;&#26412;&#26469;&#23398;&#20064;&#24471;&#20998;&#20989;&#25968;&#65292;&#20174;&#32780;&#20272;&#35745;&#30446;&#26631;&#25968;&#25454;&#20998;&#24067;&#12290;&#26368;&#36817;&#30340;&#25991;&#29486;&#20027;&#35201;&#20851;&#27880;&#35780;&#20272;&#30446;&#26631;&#20998;&#24067;&#21644;&#20272;&#35745;&#20998;&#24067;&#20043;&#38388;&#30340;&#35823;&#24046;&#65292;&#36890;&#36807;KL&#25955;&#24230;&#21644;Wasserstein&#36317;&#31163;&#26469;&#34913;&#37327;&#29983;&#25104;&#36136;&#37327;&#12290;&#33267;&#20170;&#20026;&#27490;&#65292;&#25152;&#26377;&#29616;&#26377;&#32467;&#26524;&#37117;&#26159;&#38024;&#23545;&#26102;&#38388;&#22343;&#21248;&#21464;&#21270;&#30340;&#22122;&#22768;&#35843;&#24230;&#24471;&#21040;&#30340;&#12290;&#22312;&#23545;&#25968;&#25454;&#20998;&#24067;&#36827;&#34892;&#28201;&#21644;&#20551;&#35774;&#30340;&#21069;&#25552;&#19979;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#30446;&#26631;&#20998;&#24067;&#21644;&#20272;&#35745;&#20998;&#24067;&#20043;&#38388;KL&#25955;&#24230;&#30340;&#19978;&#30028;&#65292;&#26126;&#30830;&#20381;&#36182;&#20110;&#20219;&#20309;&#26102;&#38388;&#30456;&#20851;&#30340;&#22122;&#22768;&#35843;&#24230;&#12290;&#20551;&#35774;&#24471;&#20998;&#26159;&#21033;&#26222;&#24076;&#33576;&#36830;&#32493;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;Wasserstein&#36317;&#31163;&#35823;&#24046;&#30028;&#38480;&#65292;&#21033;&#29992;&#20102;&#26377;&#21033;&#30340;&#25910;&#32553;&#26426;&#21046;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#25152;&#25552;&#20986;&#30340;&#19978;&#30028;&#33258;&#21160;&#35843;&#33410;&#22122;&#22768;&#35843;&#24230;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Score-based generative models (SGMs) aim at estimating a target data distribution by learning score functions using only noise-perturbed samples from the target. Recent literature has focused extensively on assessing the error between the target and estimated distributions, gauging the generative quality through the Kullback-Leibler (KL) divergence and Wasserstein distances.  All existing results  have been obtained so far for time-homogeneous speed of the noise schedule.  Under mild assumptions on the data distribution, we establish an upper bound for the KL divergence between the target and the estimated distributions, explicitly depending on any time-dependent noise schedule. Assuming that the score is Lipschitz continuous, we provide an improved error bound in Wasserstein distance, taking advantage of favourable underlying contraction mechanisms. We also propose an algorithm to automatically tune the noise schedule using the proposed upper bound. We illustrate empirically the perfo
&lt;/p&gt;</description></item><item><title>&#26631;&#20934; Gaussian &#36807;&#31243;&#22312;&#39640;&#32500;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#34920;&#29616;&#20248;&#31168;&#65292;&#32463;&#39564;&#35777;&#25454;&#26174;&#31034;&#20854;&#22312;&#20989;&#25968;&#20272;&#35745;&#21644;&#21327;&#26041;&#24046;&#24314;&#27169;&#20013;&#20811;&#26381;&#20102;&#39640;&#32500;&#36755;&#20837;&#22256;&#38590;&#65292;&#27604;&#19987;&#38376;&#20026;&#39640;&#32500;&#20248;&#21270;&#35774;&#35745;&#30340;&#26041;&#27861;&#34920;&#29616;&#26356;&#22909;&#12290;</title><link>https://arxiv.org/abs/2402.02746</link><description>&lt;p&gt;
&#26631;&#20934; Gaussian &#36807;&#31243;&#22312;&#39640;&#32500;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#36275;&#20197;&#24212;&#23545;
&lt;/p&gt;
&lt;p&gt;
Standard Gaussian Process is All You Need for High-Dimensional Bayesian Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02746
&lt;/p&gt;
&lt;p&gt;
&#26631;&#20934; Gaussian &#36807;&#31243;&#22312;&#39640;&#32500;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#34920;&#29616;&#20248;&#31168;&#65292;&#32463;&#39564;&#35777;&#25454;&#26174;&#31034;&#20854;&#22312;&#20989;&#25968;&#20272;&#35745;&#21644;&#21327;&#26041;&#24046;&#24314;&#27169;&#20013;&#20811;&#26381;&#20102;&#39640;&#32500;&#36755;&#20837;&#22256;&#38590;&#65292;&#27604;&#19987;&#38376;&#20026;&#39640;&#32500;&#20248;&#21270;&#35774;&#35745;&#30340;&#26041;&#27861;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38271;&#26399;&#20197;&#26469;&#65292;&#20154;&#20204;&#26222;&#36941;&#35748;&#20026;&#20351;&#29992;&#26631;&#20934; Gaussian &#36807;&#31243;&#65288;GP&#65289;&#36827;&#34892;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;BO&#65289;&#65292;&#21363;&#26631;&#20934; BO&#65292;&#22312;&#39640;&#32500;&#20248;&#21270;&#38382;&#39064;&#20013;&#25928;&#26524;&#19981;&#20339;&#12290;&#36825;&#31181;&#35266;&#24565;&#21487;&#20197;&#37096;&#20998;&#24402;&#22240;&#20110; Gaussian &#36807;&#31243;&#22312;&#21327;&#26041;&#24046;&#24314;&#27169;&#21644;&#20989;&#25968;&#20272;&#35745;&#20013;&#23545;&#39640;&#32500;&#36755;&#20837;&#30340;&#22256;&#38590;&#12290;&#34429;&#28982;&#36825;&#20123;&#25285;&#24551;&#30475;&#36215;&#26469;&#21512;&#29702;&#65292;&#20294;&#32570;&#20047;&#25903;&#25345;&#36825;&#31181;&#35266;&#28857;&#30340;&#32463;&#39564;&#35777;&#25454;&#12290;&#26412;&#25991;&#31995;&#32479;&#22320;&#30740;&#31350;&#20102;&#22312;&#21508;&#31181;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#22522;&#20934;&#38382;&#39064;&#19978;&#65292;&#20351;&#29992;&#26631;&#20934; GP &#22238;&#24402;&#36827;&#34892;&#39640;&#32500;&#20248;&#21270;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#26631;&#20934; GP &#30340;&#34920;&#29616;&#22987;&#32456;&#20301;&#20110;&#26368;&#20339;&#33539;&#22260;&#20869;&#65292;&#24448;&#24448;&#27604;&#19987;&#38376;&#20026;&#39640;&#32500;&#20248;&#21270;&#35774;&#35745;&#30340;&#29616;&#26377; BO &#26041;&#27861;&#34920;&#29616;&#26356;&#22909;&#12290;&#19982;&#21051;&#26495;&#21360;&#35937;&#30456;&#21453;&#65292;&#25105;&#20204;&#21457;&#29616;&#26631;&#20934; GP &#21487;&#20197;&#20316;&#20026;&#23398;&#20064;&#39640;&#32500;&#30446;&#26631;&#20989;&#25968;&#30340;&#33021;&#21147;&#24378;&#22823;&#30340;&#20195;&#29702;&#12290;&#22312;&#27809;&#26377;&#24378;&#32467;&#26500;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#26631;&#20934; GP &#36827;&#34892; BO &#21487;&#20197;&#33719;&#24471;&#38750;&#24120;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
There has been a long-standing and widespread belief that Bayesian Optimization (BO) with standard Gaussian process (GP), referred to as standard BO, is ineffective in high-dimensional optimization problems. This perception may partly stem from the intuition that GPs struggle with high-dimensional inputs for covariance modeling and function estimation. While these concerns seem reasonable, empirical evidence supporting this belief is lacking. In this paper, we systematically investigated BO with standard GP regression across a variety of synthetic and real-world benchmark problems for high-dimensional optimization. Surprisingly, the performance with standard GP consistently ranks among the best, often outperforming existing BO methods specifically designed for high-dimensional optimization by a large margin. Contrary to the stereotype, we found that standard GP can serve as a capable surrogate for learning high-dimensional target functions. Without strong structural assumptions, BO wit
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#20110;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#22312;&#24378;&#23545;&#25968;&#20985;&#25968;&#25454;&#20998;&#24067;&#20551;&#35774;&#19979;&#30340;&#23436;&#25972;&#25910;&#25947;&#29702;&#35770;&#20445;&#35777;&#65292;&#33719;&#24471;&#20102;&#23545;&#20110;&#21442;&#25968;&#20272;&#35745;&#21644;&#37319;&#26679;&#31639;&#27861;&#30340;&#26368;&#20248;&#19978;&#38480;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2311.13584</link><description>&lt;p&gt;
&#20851;&#20110;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#21450;&#20854;&#35823;&#24046;&#30028;&#38480;&#65306;&#23436;&#20840;&#25910;&#25947;&#20272;&#35745;&#19979;&#30340;&#23545;&#25968;&#20985;&#24773;&#20917;
&lt;/p&gt;
&lt;p&gt;
On diffusion-based generative models and their error bounds: The log-concave case with full convergence estimates
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.13584
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#20110;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#22312;&#24378;&#23545;&#25968;&#20985;&#25968;&#25454;&#20998;&#24067;&#20551;&#35774;&#19979;&#30340;&#23436;&#25972;&#25910;&#25947;&#29702;&#35770;&#20445;&#35777;&#65292;&#33719;&#24471;&#20102;&#23545;&#20110;&#21442;&#25968;&#20272;&#35745;&#21644;&#37319;&#26679;&#31639;&#27861;&#30340;&#26368;&#20248;&#19978;&#38480;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#24378;&#23545;&#25968;&#20985;&#25968;&#25454;&#20998;&#24067;&#30340;&#20551;&#35774;&#19979;&#20026;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#25910;&#25947;&#34892;&#20026;&#25552;&#20379;&#20102;&#23436;&#25972;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#32780;&#25105;&#20204;&#29992;&#20110;&#24471;&#20998;&#20272;&#35745;&#30340;&#36924;&#36817;&#20989;&#25968;&#31867;&#30001;Lipschitz&#36830;&#32493;&#20989;&#25968;&#32452;&#25104;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#20010;&#28608;&#21169;&#24615;&#20363;&#23376;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#24378;&#22823;&#20043;&#22788;&#65292;&#21363;&#20174;&#20855;&#26377;&#26410;&#30693;&#22343;&#20540;&#30340;&#39640;&#26031;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#23545;&#30456;&#20851;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#21363;&#24471;&#20998;&#20272;&#35745;&#65292;&#25552;&#20379;&#20102;&#26126;&#30830;&#30340;&#20272;&#35745;&#65292;&#21516;&#26102;&#23558;&#20854;&#19982;&#30456;&#24212;&#30340;&#37319;&#26679;&#20272;&#35745;&#32467;&#21512;&#36215;&#26469;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#26368;&#22909;&#30340;&#24050;&#30693;&#19978;&#38480;&#20272;&#35745;&#65292;&#28041;&#21450;&#20851;&#38190;&#24863;&#20852;&#36259;&#30340;&#25968;&#37327;&#65292;&#22914;&#25968;&#25454;&#20998;&#24067;&#65288;&#20855;&#26377;&#26410;&#30693;&#22343;&#20540;&#30340;&#39640;&#26031;&#20998;&#24067;&#65289;&#19982;&#25105;&#20204;&#30340;&#37319;&#26679;&#31639;&#27861;&#20043;&#38388;&#30340;Wasserstein-2&#36317;&#31163;&#30340;&#32500;&#24230;&#21644;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.13584v2 Announce Type: replace  Abstract: We provide full theoretical guarantees for the convergence behaviour of diffusion-based generative models under the assumption of strongly log-concave data distributions while our approximating class of functions used for score estimation is made of Lipschitz continuous functions. We demonstrate via a motivating example, sampling from a Gaussian distribution with unknown mean, the powerfulness of our approach. In this case, explicit estimates are provided for the associated optimization problem, i.e. score approximation, while these are combined with the corresponding sampling estimates. As a result, we obtain the best known upper bound estimates in terms of key quantities of interest, such as the dimension and rates of convergence, for the Wasserstein-2 distance between the data distribution (Gaussian with unknown mean) and our sampling algorithm.   Beyond the motivating example and in order to allow for the use of a diverse range o
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#22270;&#26497;&#38480;&#20013;&#22270;&#19978;&#20449;&#21495;&#30340;&#20449;&#21495;&#37319;&#26679;&#29702;&#35770;&#65292;&#35777;&#26126;&#20102;Poincar\'e&#19981;&#31561;&#24335;&#24182;&#23637;&#31034;&#20102;&#19968;&#33268;&#24615;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2311.10610</link><description>&lt;p&gt;
&#20449;&#21495;&#22312;&#22823;&#22270;&#19978;&#30340;&#37319;&#26679;&#30340;Poincar\'e&#19981;&#31561;&#24335;&#21644;&#19968;&#33268;&#24615;&#32467;&#26524;
&lt;/p&gt;
&lt;p&gt;
A Poincar\'e Inequality and Consistency Results for Signal Sampling on Large Graphs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.10610
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#22270;&#26497;&#38480;&#20013;&#22270;&#19978;&#20449;&#21495;&#30340;&#20449;&#21495;&#37319;&#26679;&#29702;&#35770;&#65292;&#35777;&#26126;&#20102;Poincar\'e&#19981;&#31561;&#24335;&#24182;&#23637;&#31034;&#20102;&#19968;&#33268;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#22270;&#26426;&#22120;&#23398;&#20064;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;&#23398;&#20064;&#27169;&#22411;&#30340;&#22797;&#26434;&#24615;&#38543;&#30528;&#22270;&#30340;&#22823;&#23567;&#32780;&#22686;&#21152;&#12290;&#23545;&#22270;&#36827;&#34892;&#23376;&#37319;&#26679;&#26159;&#19968;&#31181;&#21487;&#34892;&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#20294;&#22312;&#22270;&#19978;&#36827;&#34892;&#37319;&#26679;&#26159;&#38750;&#24179;&#20961;&#30340;&#65292;&#22240;&#20026;&#22270;&#26159;&#38750;&#27431;&#20960;&#37324;&#24471;&#30340;&#12290;&#29616;&#26377;&#30340;&#22270;&#37319;&#26679;&#25216;&#26415;&#19981;&#20165;&#38656;&#35201;&#35745;&#31639;&#22823;&#30697;&#38453;&#30340;&#35889;&#65292;&#32780;&#19988;&#22312;&#22270;&#21457;&#29983;&#21464;&#21270;&#65288;&#20363;&#22914;&#22686;&#38271;&#65289;&#26102;&#38656;&#35201;&#37325;&#22797;&#36825;&#20123;&#35745;&#31639;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#19968;&#31181;&#22270;&#26497;&#38480;--&#22270;&#19978;&#30340;&#20449;&#21495;&#37319;&#26679;&#29702;&#35770;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22270;&#19978;&#20449;&#21495;&#30340;Poincar\'e&#19981;&#31561;&#24335;&#65292;&#24182;&#23637;&#31034;&#20102;&#28385;&#36275;&#36825;&#19968;&#19981;&#31561;&#24335;&#30340;&#33410;&#28857;&#23376;&#38598;&#30340;&#34917;&#38598;&#26159;&#22270;&#19978;&#20449;&#21495;Paley-Wiener&#31354;&#38388;&#30340;&#21807;&#19968;&#37319;&#26679;&#38598;&#12290;&#36890;&#36807;&#19982;&#35889;&#32858;&#31867;&#21644;&#39640;&#26031;&#28040;&#20803;&#30340;&#32852;&#31995;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#26679;&#30340;&#37319;&#26679;&#38598;&#26159;&#19968;&#33268;&#30340;&#65292;&#21363;&#25910;&#25947;&#30340;&#22270;&#24207;&#21015;&#19978;&#30340;&#21807;&#19968;&#37319;&#26679;&#38598;&#25910;&#25947;&#21040;&#22270;&#26497;&#38480;&#19978;&#30340;&#21807;&#19968;&#37319;&#26679;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.10610v2 Announce Type: replace  Abstract: Large-scale graph machine learning is challenging as the complexity of learning models scales with the graph size. Subsampling the graph is a viable alternative, but sampling on graphs is nontrivial as graphs are non-Euclidean. Existing graph sampling techniques require not only computing the spectra of large matrices but also repeating these computations when the graph changes, e.g., grows. In this paper, we introduce a signal sampling theory for a type of graph limit -- the graphon. We prove a Poincar\'e inequality for graphon signals and show that complements of node subsets satisfying this inequality are unique sampling sets for Paley-Wiener spaces of graphon signals. Exploiting connections with spectral clustering and Gaussian elimination, we prove that such sampling sets are consistent in the sense that unique sampling sets on a convergent graph sequence converge to unique sampling sets on the graphon. We then propose a related
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#38750;&#31283;&#24577;&#29615;&#22659;&#30340;&#32479;&#35745;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#24212;&#29992;&#31283;&#23450;&#24615;&#21407;&#21017;&#36873;&#25321;&#22238;&#28335;&#31383;&#21475;&#26469;&#26368;&#22823;&#21270;&#21382;&#21490;&#25968;&#25454;&#21033;&#29992;&#65292;&#24182;&#20445;&#25345;&#32047;&#31215;&#20559;&#24046;&#22312;&#21487;&#25509;&#21463;&#33539;&#22260;&#20869;&#12290;&#35813;&#26041;&#27861;&#23637;&#31034;&#20102;&#23545;&#26410;&#30693;&#38750;&#31283;&#24577;&#30340;&#36866;&#24212;&#24615;&#65292;&#36951;&#25022;&#30028;&#22312;&#24378;&#20984;&#25110;&#28385;&#36275;Lipschitz&#26465;&#20214;&#19979;&#26159;&#26497;&#23567;&#21270;&#30340;&#26368;&#20248;&#35299;&#12290;&#35813;&#30740;&#31350;&#30340;&#21019;&#26032;&#28857;&#26159;&#20989;&#25968;&#30456;&#20284;&#24230;&#24230;&#37327;&#21644;&#38750;&#31283;&#24577;&#25968;&#25454;&#24207;&#21015;&#21010;&#20998;&#25216;&#26415;&#12290;</title><link>http://arxiv.org/abs/2310.18304</link><description>&lt;p&gt;
&#23398;&#20064;&#38750;&#31283;&#24577;&#26465;&#20214;&#19979;&#30340;&#31283;&#23450;&#24615;&#21407;&#21017;
&lt;/p&gt;
&lt;p&gt;
A Stability Principle for Learning under Non-Stationarity. (arXiv:2310.18304v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18304
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#38750;&#31283;&#24577;&#29615;&#22659;&#30340;&#32479;&#35745;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#24212;&#29992;&#31283;&#23450;&#24615;&#21407;&#21017;&#36873;&#25321;&#22238;&#28335;&#31383;&#21475;&#26469;&#26368;&#22823;&#21270;&#21382;&#21490;&#25968;&#25454;&#21033;&#29992;&#65292;&#24182;&#20445;&#25345;&#32047;&#31215;&#20559;&#24046;&#22312;&#21487;&#25509;&#21463;&#33539;&#22260;&#20869;&#12290;&#35813;&#26041;&#27861;&#23637;&#31034;&#20102;&#23545;&#26410;&#30693;&#38750;&#31283;&#24577;&#30340;&#36866;&#24212;&#24615;&#65292;&#36951;&#25022;&#30028;&#22312;&#24378;&#20984;&#25110;&#28385;&#36275;Lipschitz&#26465;&#20214;&#19979;&#26159;&#26497;&#23567;&#21270;&#30340;&#26368;&#20248;&#35299;&#12290;&#35813;&#30740;&#31350;&#30340;&#21019;&#26032;&#28857;&#26159;&#20989;&#25968;&#30456;&#20284;&#24230;&#24230;&#37327;&#21644;&#38750;&#31283;&#24577;&#25968;&#25454;&#24207;&#21015;&#21010;&#20998;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#38750;&#31283;&#23450;&#29615;&#22659;&#20013;&#24320;&#21457;&#20102;&#19968;&#20010;&#28789;&#27963;&#30340;&#32479;&#35745;&#23398;&#20064;&#26694;&#26550;&#12290;&#22312;&#27599;&#20010;&#26102;&#38388;&#27573;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#31283;&#23450;&#24615;&#21407;&#21017;&#26469;&#36873;&#25321;&#19968;&#20010;&#22238;&#28335;&#31383;&#21475;&#65292;&#26368;&#22823;&#38480;&#24230;&#22320;&#21033;&#29992;&#21382;&#21490;&#25968;&#25454;&#65292;&#21516;&#26102;&#23558;&#32047;&#31215;&#20559;&#24046;&#20445;&#25345;&#22312;&#19982;&#38543;&#26426;&#35823;&#24046;&#30456;&#23545;&#21487;&#25509;&#21463;&#30340;&#33539;&#22260;&#20869;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#23545;&#26410;&#30693;&#38750;&#31283;&#23450;&#24615;&#30340;&#36866;&#24212;&#24615;&#12290;&#24403;&#20154;&#21475;&#25439;&#22833;&#20989;&#25968;&#24378;&#20984;&#25110;&#20165;&#28385;&#36275;Lipschitz&#26465;&#20214;&#26102;&#65292;&#36951;&#25022;&#30028;&#26159;&#26497;&#23567;&#21270;&#30340;&#26368;&#20248;&#35299;&#65292;&#20165;&#21463;&#23545;&#25968;&#22240;&#23376;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#26680;&#24515;&#26159;&#20004;&#20010;&#26032;&#39062;&#30340;&#32452;&#25104;&#37096;&#20998;&#65306;&#20989;&#25968;&#20043;&#38388;&#30340;&#30456;&#20284;&#24230;&#24230;&#37327;&#21644;&#23558;&#38750;&#31283;&#24577;&#25968;&#25454;&#24207;&#21015;&#21010;&#20998;&#20026;&#20934;&#31283;&#24577;&#29255;&#27573;&#30340;&#20998;&#21106;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a versatile framework for statistical learning in non-stationary environments. In each time period, our approach applies a stability principle to select a look-back window that maximizes the utilization of historical data while keeping the cumulative bias within an acceptable range relative to the stochastic error. Our theory showcases the adaptability of this approach to unknown non-stationarity. The regret bound is minimax optimal up to logarithmic factors when the population losses are strongly convex, or Lipschitz only. At the heart of our analysis lie two novel components: a measure of similarity between functions and a segmentation technique for dividing the non-stationary data sequence into quasi-stationary pieces.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;EIF+&#21644;ExIFFI&#20004;&#31181;&#25913;&#36827;&#20102;&#25193;&#23637;&#23396;&#31435;&#26862;&#26519;&#30340;&#26041;&#27861;&#65292;&#20998;&#21035;&#22686;&#24378;&#20102;&#27169;&#22411;&#30340;&#25512;&#24191;&#33021;&#21147;&#21644;&#35299;&#37322;&#24615;&#33021;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20854;&#22312;&#24322;&#24120;&#26816;&#27979;&#20219;&#21153;&#20013;&#20855;&#26377;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2310.05468</link><description>&lt;p&gt;
ExIFFI&#21644;EIF+&#65306;&#35299;&#37322;&#24615;&#21644;&#22686;&#24378;&#30340;&#25512;&#24191;&#33021;&#21147;&#20197;&#25193;&#23637;&#25193;&#23637;&#23396;&#31435;&#26862;&#26519;
&lt;/p&gt;
&lt;p&gt;
ExIFFI and EIF+: Interpretability and Enhanced Generalizability to Extend the Extended Isolation Forest. (arXiv:2310.05468v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05468
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;EIF+&#21644;ExIFFI&#20004;&#31181;&#25913;&#36827;&#20102;&#25193;&#23637;&#23396;&#31435;&#26862;&#26519;&#30340;&#26041;&#27861;&#65292;&#20998;&#21035;&#22686;&#24378;&#20102;&#27169;&#22411;&#30340;&#25512;&#24191;&#33021;&#21147;&#21644;&#35299;&#37322;&#24615;&#33021;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20854;&#22312;&#24322;&#24120;&#26816;&#27979;&#20219;&#21153;&#20013;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24322;&#24120;&#26816;&#27979;&#26159;&#19968;&#31181;&#37325;&#35201;&#30340;&#26080;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#65292;&#28041;&#21450;&#22312;&#22797;&#26434;&#25968;&#25454;&#38598;&#21644;&#31995;&#32479;&#20013;&#35782;&#21035;&#24322;&#24120;&#34892;&#20026;&#12290;&#34429;&#28982;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#21644;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#65288;DSS&#65289;&#25552;&#20379;&#20102;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#20165;&#20165;&#23450;&#20301;&#24322;&#24120;&#24448;&#24448;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#19981;&#36275;&#12290;&#36825;&#20123;&#31995;&#32479;&#30340;&#29992;&#25143;&#36890;&#24120;&#38656;&#35201;&#20102;&#35299;&#39044;&#27979;&#32972;&#21518;&#30340;&#21407;&#22240;&#65292;&#20197;&#20415;&#36827;&#34892;&#26681;&#26412;&#21407;&#22240;&#20998;&#26512;&#24182;&#22686;&#24378;&#23545;&#27169;&#22411;&#30340;&#20449;&#20219;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#24322;&#24120;&#26816;&#27979;&#30340;&#26080;&#30417;&#30563;&#24615;&#36136;&#65292;&#21019;&#24314;&#21487;&#35299;&#37322;&#30340;&#24037;&#20855;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;EIF+&#65292;&#36825;&#26159;&#25193;&#23637;&#23396;&#31435;&#26862;&#26519;&#65288;EIF&#65289;&#30340;&#22686;&#24378;&#21464;&#20307;&#65292;&#26088;&#22312;&#22686;&#24378;&#27867;&#21270;&#33021;&#21147;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;ExIFFI&#65292;&#19968;&#31181;&#23558;&#25193;&#23637;&#23396;&#31435;&#26862;&#26519;&#19982;&#35299;&#37322;&#24615;&#21151;&#33021;&#65288;&#29305;&#24449;&#25490;&#21517;&#65289;&#30456;&#32467;&#21512;&#30340;&#26032;&#26041;&#27861;&#12290;&#23454;&#39564;&#32467;&#26524;&#25552;&#20379;&#20102;&#20197;&#23396;&#31435;&#22522;&#20110;&#26041;&#27861;&#36827;&#34892;&#24322;&#24120;&#26816;&#27979;&#30340;&#32508;&#21512;&#27604;&#36739;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Anomaly detection, an essential unsupervised machine learning task, involves identifying unusual behaviors within complex datasets and systems. While Machine Learning algorithms and decision support systems (DSSs) offer effective solutions for this task, simply pinpointing anomalies often falls short in real-world applications. Users of these systems often require insight into the underlying reasons behind predictions to facilitate Root Cause Analysis and foster trust in the model. However, due to the unsupervised nature of anomaly detection, creating interpretable tools is challenging. This work introduces EIF+, an enhanced variant of Extended Isolation Forest (EIF), designed to enhance generalization capabilities. Additionally, we present ExIFFI, a novel approach that equips Extended Isolation Forest with interpretability features, specifically feature rankings. Experimental results provide a comprehensive comparative analysis of Isolation-based approaches for Anomaly Detection, incl
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24754;&#35266;&#38750;&#32447;&#24615;&#26368;&#23567;&#20108;&#20056;&#20540;&#36845;&#20195;&#31639;&#27861;&#65288;PNLSVI&#65289;&#65292;&#29992;&#20110;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#38382;&#39064;&#12290;&#35813;&#31639;&#27861;&#20855;&#26377;&#21019;&#26032;&#30340;&#26041;&#24046;&#21152;&#26435;&#22238;&#24402;&#26041;&#26696;&#12289;&#26041;&#24046;&#20272;&#35745;&#23376;&#31243;&#24207;&#21644;&#24754;&#35266;&#20540;&#36845;&#20195;&#26041;&#27861;&#30340;&#35268;&#21010;&#38454;&#27573;&#12290;</title><link>http://arxiv.org/abs/2310.01380</link><description>&lt;p&gt;
&#24754;&#35266;&#38750;&#32447;&#24615;&#26368;&#23567;&#20108;&#20056;&#20540;&#36845;&#20195;&#31639;&#27861;&#29992;&#20110;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Pessimistic Nonlinear Least-Squares Value Iteration for Offline Reinforcement Learning. (arXiv:2310.01380v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01380
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24754;&#35266;&#38750;&#32447;&#24615;&#26368;&#23567;&#20108;&#20056;&#20540;&#36845;&#20195;&#31639;&#27861;&#65288;PNLSVI&#65289;&#65292;&#29992;&#20110;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#38382;&#39064;&#12290;&#35813;&#31639;&#27861;&#20855;&#26377;&#21019;&#26032;&#30340;&#26041;&#24046;&#21152;&#26435;&#22238;&#24402;&#26041;&#26696;&#12289;&#26041;&#24046;&#20272;&#35745;&#23376;&#31243;&#24207;&#21644;&#24754;&#35266;&#20540;&#36845;&#20195;&#26041;&#27861;&#30340;&#35268;&#21010;&#38454;&#27573;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#65288;Offline RL&#65289;&#26159;&#25351;&#26234;&#33021;&#20307;&#26681;&#25454;&#30001;&#34892;&#20026;&#31574;&#30053;&#25910;&#38598;&#30340;&#25968;&#25454;&#23398;&#20064;&#26368;&#20248;&#31574;&#30053;&#30340;&#20219;&#21153;&#65292;&#36817;&#24180;&#26469;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#34429;&#28982;&#22312;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#24050;&#32463;&#24471;&#21040;&#20102;&#24191;&#27867;&#30740;&#31350;&#65292;&#24182;&#22312;&#19968;&#23450;&#20551;&#35774;&#19979;&#21462;&#24471;&#20102;&#26368;&#20248;&#32467;&#26524;&#65292;&#20294;&#24456;&#22810;&#30740;&#31350;&#23558;&#20852;&#36259;&#36716;&#21521;&#20102;&#38750;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;&#38750;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#20855;&#26377;&#23454;&#20363;&#20381;&#36182;&#21518;&#24724;&#20445;&#35777;&#30340;&#30740;&#31350;&#24037;&#20316;&#21364;&#24456;&#26377;&#38480;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#24754;&#35266;&#38750;&#32447;&#24615;&#26368;&#23567;&#20108;&#20056;&#20540;&#36845;&#20195;&#65288;PNLSVI&#65289;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#29992;&#20110;&#38750;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#35774;&#35745;&#21253;&#25324;&#19977;&#20010;&#21019;&#26032;&#30340;&#32452;&#25104;&#37096;&#20998;&#65306;&#65288;1&#65289;&#19968;&#31181;&#22522;&#20110;&#26041;&#24046;&#21152;&#26435;&#22238;&#24402;&#30340;&#26041;&#26696;&#65292;&#36866;&#29992;&#20110;&#24191;&#27867;&#30340;&#20989;&#25968;&#31867;&#65307;&#65288;2&#65289;&#19968;&#31181;&#26041;&#24046;&#20272;&#35745;&#23376;&#31243;&#24207;&#65307;&#21644;&#65288;3&#65289;&#19968;&#20010;&#21033;&#29992;&#24754;&#35266;&#20540;&#36845;&#20195;&#26041;&#27861;&#30340;&#35268;&#21010;&#38454;&#27573;&#12290;
&lt;/p&gt;
&lt;p&gt;
Offline reinforcement learning (RL), where the agent aims to learn the optimal policy based on the data collected by a behavior policy, has attracted increasing attention in recent years. While offline RL with linear function approximation has been extensively studied with optimal results achieved under certain assumptions, many works shift their interest to offline RL with non-linear function approximation. However, limited works on offline RL with non-linear function approximation have instance-dependent regret guarantees. In this paper, we propose an oracle-efficient algorithm, dubbed Pessimistic Nonlinear Least-Square Value Iteration (PNLSVI), for offline RL with non-linear function approximation. Our algorithmic design comprises three innovative components: (1) a variance-based weighted regression scheme that can be applied to a wide range of function classes, (2) a subroutine for variance estimation, and (3) a planning phase that utilizes a pessimistic value iteration approach. O
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#8220;&#29420;&#31435;&#25237;&#24433;&#8221;&#30340;&#26500;&#36896;&#65292;&#23427;&#22312;&#21464;&#20998;&#25512;&#26029;&#21644;&#26368;&#20248;&#22343;&#22330;&#36924;&#36817;&#20013;&#20855;&#26377;&#26368;&#20248;&#30340;&#25928;&#26524;&#65292;&#21487;&#20197;&#23454;&#29616;&#39640;&#32500;&#25193;&#25955;&#36807;&#31243;&#30340;&#29420;&#31435;&#22352;&#26631;&#30340;&#26368;&#20248;&#36924;&#36817;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#38271;&#26102;&#38388;&#25910;&#25947;&#24615;&#21644;&#24930;&#30340;&#36335;&#24452;&#22686;&#38271;&#29575;&#12290;</title><link>http://arxiv.org/abs/2309.13332</link><description>&lt;p&gt;
&#29420;&#31435;&#25237;&#24433;&#30340;&#25193;&#25955;&#65306;&#21464;&#20998;&#25512;&#26029;&#21644;&#26368;&#20248;&#22343;&#22330;&#36924;&#36817;&#30340;&#26799;&#24230;&#27969;
&lt;/p&gt;
&lt;p&gt;
Independent projections of diffusions: Gradient flows for variational inference and optimal mean field approximations. (arXiv:2309.13332v1 [math.PR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13332
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#8220;&#29420;&#31435;&#25237;&#24433;&#8221;&#30340;&#26500;&#36896;&#65292;&#23427;&#22312;&#21464;&#20998;&#25512;&#26029;&#21644;&#26368;&#20248;&#22343;&#22330;&#36924;&#36817;&#20013;&#20855;&#26377;&#26368;&#20248;&#30340;&#25928;&#26524;&#65292;&#21487;&#20197;&#23454;&#29616;&#39640;&#32500;&#25193;&#25955;&#36807;&#31243;&#30340;&#29420;&#31435;&#22352;&#26631;&#30340;&#26368;&#20248;&#36924;&#36817;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#38271;&#26102;&#38388;&#25910;&#25947;&#24615;&#21644;&#24930;&#30340;&#36335;&#24452;&#22686;&#38271;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#20309;&#29992;&#29420;&#31435;&#22352;&#26631;&#30340;&#36807;&#31243;&#26469;&#26368;&#20248;&#22320;&#36924;&#36817;&#39640;&#32500;&#25193;&#25955;&#36807;&#31243;&#65311;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#8220;&#29420;&#31435;&#25237;&#24433;&#8221;&#30340;&#26500;&#36896;&#65292;&#23427;&#22312;&#20004;&#20010;&#33258;&#28982;&#20934;&#21017;&#19979;&#26159;&#26368;&#20248;&#30340;&#12290;&#39318;&#20808;&#65292;&#24403;&#21407;&#22987;&#25193;&#25955;&#36807;&#31243;&#26159;&#21487;&#36870;&#30340;&#19988;&#20855;&#26377;&#19981;&#21464;&#27979;&#24230;&#961;&#8727;&#26102;&#65292;&#29420;&#31435;&#25237;&#24433;&#20316;&#20026;&#29420;&#31435;&#22352;&#26631;&#30340;&#31354;&#38388;&#19978;&#30456;&#23545;&#29109;H(&#8901;|&#961;&#8727;)&#30340;Wasserstein&#26799;&#24230;&#27969;&#12290;&#36825;&#19982;&#32479;&#35745;&#25991;&#29486;&#20013;&#20851;&#20110;&#22343;&#22330;&#21464;&#20998;&#25512;&#26029;&#30340;Langevin&#37319;&#26679;&#26041;&#26696;&#26377;&#20851;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#20851;&#20110;&#29420;&#31435;&#25237;&#24433;&#30340;&#38271;&#26102;&#38388;&#25910;&#25947;&#30340;&#23450;&#24615;&#21644;&#23450;&#37327;&#32467;&#26524;&#65292;&#20854;&#20013;&#22312;&#23545;&#25968;&#20985;&#24773;&#20917;&#19979;&#30340;&#23450;&#37327;&#32467;&#26524;&#26159;&#36890;&#36807;&#19968;&#31181;&#26032;&#30340;&#23545;&#25968;Sobolev&#19981;&#31561;&#24335;&#30340;&#21464;&#20307;&#25512;&#23548;&#20986;&#26469;&#30340;&#12290;&#20854;&#27425;&#65292;&#22312;&#25152;&#26377;&#20855;&#26377;&#29420;&#31435;&#22352;&#26631;&#30340;&#36807;&#31243;&#20013;&#65292;&#29420;&#31435;&#25237;&#24433;&#26174;&#31034;&#20986;&#20102;&#36335;&#24452;&#22686;&#38271;&#29575;&#26368;&#24930;&#12290;
&lt;/p&gt;
&lt;p&gt;
What is the optimal way to approximate a high-dimensional diffusion process by one in which the coordinates are independent? This paper presents a construction, called the \emph{independent projection}, which is optimal for two natural criteria. First, when the original diffusion is reversible with invariant measure $\rho_*$, the independent projection serves as the Wasserstein gradient flow for the relative entropy $H(\cdot\,|\,\rho_*)$ constrained to the space of product measures. This is related to recent Langevin-based sampling schemes proposed in the statistical literature on mean field variational inference. In addition, we provide both qualitative and quantitative results on the long-time convergence of the independent projection, with quantitative results in the log-concave case derived via a new variant of the logarithmic Sobolev inequality. Second, among all processes with independent coordinates, the independent projection is shown to exhibit the slowest growth rate of path-
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22534;&#21472;&#22238;&#24402;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#24635;&#20307;&#39118;&#38505;&#24182;&#21463;&#38750;&#36127;&#24615;&#32422;&#26463;&#65292;&#25104;&#21151;&#38477;&#20302;&#20102;&#35823;&#24046;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22534;&#21472;&#20272;&#35745;&#22120;&#30456;&#27604;&#20854;&#20013;&#26368;&#20339;&#30340;&#21333;&#20010;&#20272;&#35745;&#22120;&#20855;&#26377;&#26356;&#23567;&#30340;&#24635;&#20307;&#39118;&#38505;&#12290;</title><link>http://arxiv.org/abs/2309.09880</link><description>&lt;p&gt;
&#30001;&#22534;&#21472;&#22238;&#24402;&#20943;&#23569;&#35823;&#24046;
&lt;/p&gt;
&lt;p&gt;
Error Reduction from Stacked Regressions. (arXiv:2309.09880v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09880
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22534;&#21472;&#22238;&#24402;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#24635;&#20307;&#39118;&#38505;&#24182;&#21463;&#38750;&#36127;&#24615;&#32422;&#26463;&#65292;&#25104;&#21151;&#38477;&#20302;&#20102;&#35823;&#24046;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22534;&#21472;&#20272;&#35745;&#22120;&#30456;&#27604;&#20854;&#20013;&#26368;&#20339;&#30340;&#21333;&#20010;&#20272;&#35745;&#22120;&#20855;&#26377;&#26356;&#23567;&#30340;&#24635;&#20307;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22534;&#21472;&#22238;&#24402;&#26159;&#19968;&#31181;&#38598;&#25104;&#25216;&#26415;&#65292;&#23427;&#36890;&#36807;&#24418;&#25104;&#19981;&#21516;&#22238;&#24402;&#20272;&#35745;&#22120;&#30340;&#32447;&#24615;&#32452;&#21512;&#26469;&#25552;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#20256;&#32479;&#26041;&#27861;&#20351;&#29992;&#20132;&#21449;&#39564;&#35777;&#25968;&#25454;&#26469;&#29983;&#25104;&#30001;&#26500;&#25104;&#20272;&#35745;&#22120;&#39044;&#27979;&#65292;&#24182;&#20351;&#29992;&#24102;&#38750;&#36127;&#24615;&#32422;&#26463;&#30340;&#26368;&#23567;&#20108;&#20056;&#27861;&#23398;&#20064;&#32452;&#21512;&#26435;&#37325;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#31867;&#20284;&#22320;&#36890;&#36807;&#26368;&#23567;&#21270;&#19968;&#31181;&#20272;&#35745;&#30340;&#24635;&#20307;&#39118;&#38505;&#26469;&#23398;&#20064;&#36825;&#20123;&#26435;&#37325;&#65292;&#24182;&#21463;&#21040;&#38750;&#36127;&#24615;&#32422;&#26463;&#12290;&#24403;&#26500;&#25104;&#30340;&#20272;&#35745;&#22120;&#26159;&#36890;&#36807;&#33267;&#23569;&#19977;&#20010;&#32500;&#24230;&#20998;&#38548;&#30340;&#23884;&#22871;&#23376;&#31354;&#38388;&#30340;&#32447;&#24615;&#26368;&#23567;&#20108;&#20056;&#25237;&#24433;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#30001;&#20110;&#25910;&#32553;&#25928;&#24212;&#65292;&#25152;&#24471;&#21040;&#30340;&#22534;&#21472;&#20272;&#35745;&#22120;&#30340;&#24635;&#20307;&#39118;&#38505;&#20005;&#26684;&#23567;&#20110;&#20854;&#20013;&#26368;&#20339;&#30340;&#21333;&#20010;&#20272;&#35745;&#22120;&#12290;&#36825;&#37324;&#30340;&#8220;&#26368;&#20339;&#8221;&#26159;&#25351;&#26368;&#23567;&#21270;&#36873;&#25321;&#20934;&#21017;&#22914;AIC&#25110;BIC&#30340;&#27169;&#22411;&#12290;&#25442;&#21477;&#35805;&#35828;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#26368;&#20339;&#30340;&#21333;&#20010;&#20272;&#35745;&#22120;&#26159;&#19981;&#21487;&#25509;&#21463;&#30340;&#12290;&#22240;&#20026;&#20248;&#21270;&#38382;&#39064;&#21487;&#20197;&#37325;&#26500;&#20026;&#21516;&#20449;&#24687;&#22238;&#24402;&#65292;&#25152;&#20197;...
&lt;/p&gt;
&lt;p&gt;
Stacking regressions is an ensemble technique that forms linear combinations of different regression estimators to enhance predictive accuracy. The conventional approach uses cross-validation data to generate predictions from the constituent estimators, and least-squares with nonnegativity constraints to learn the combination weights. In this paper, we learn these weights analogously by minimizing an estimate of the population risk subject to a nonnegativity constraint. When the constituent estimators are linear least-squares projections onto nested subspaces separated by at least three dimensions, we show that thanks to a shrinkage effect, the resulting stacked estimator has strictly smaller population risk than best single estimator among them. Here ``best'' refers to a model that minimizes a selection criterion such as AIC or BIC. In other words, in this setting, the best single estimator is inadmissible. Because the optimization problem can be reformulated as isotonic regression, t
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#39640;&#38454;&#24635;&#21464;&#24046;&#27491;&#21017;&#21270;&#30340;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#35757;&#32451;&#38750;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#65292;&#36991;&#20813;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.02293</link><description>&lt;p&gt;
&#29992;&#27491;&#21017;&#21270;&#39640;&#38454;&#24635;&#21464;&#24046;&#30340;&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;&#35757;&#32451;&#38750;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
A stochastic optimization approach to train non-linear neural networks with regularization of higher-order total variation. (arXiv:2308.02293v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02293
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#39640;&#38454;&#24635;&#21464;&#24046;&#27491;&#21017;&#21270;&#30340;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#35757;&#32451;&#38750;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#65292;&#36991;&#20813;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#21253;&#25324;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#20869;&#30340;&#39640;&#24230;&#34920;&#36798;&#30340;&#21442;&#25968;&#27169;&#22411;&#21487;&#20197;&#26356;&#22909;&#22320;&#24314;&#27169;&#22797;&#26434;&#27010;&#24565;&#65292;&#20294;&#35757;&#32451;&#36825;&#31181;&#39640;&#24230;&#38750;&#32447;&#24615;&#27169;&#22411;&#24050;&#30693;&#20250;&#23548;&#33268;&#20005;&#37325;&#30340;&#36807;&#25311;&#21512;&#39118;&#38505;&#12290;&#38024;&#23545;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#30740;&#31350;&#32771;&#34385;&#20102;&#19968;&#31181;k&#38454;&#24635;&#21464;&#24046;&#65288;k-TV&#65289;&#27491;&#21017;&#21270;&#65292;&#23427;&#34987;&#23450;&#20041;&#20026;&#35201;&#35757;&#32451;&#30340;&#21442;&#25968;&#27169;&#22411;&#30340;k&#38454;&#23548;&#25968;&#30340;&#24179;&#26041;&#31215;&#20998;&#65292;&#36890;&#36807;&#24809;&#32602;k-TV&#26469;&#20135;&#29983;&#19968;&#20010;&#26356;&#24179;&#28369;&#30340;&#20989;&#25968;&#65292;&#20174;&#32780;&#36991;&#20813;&#36807;&#25311;&#21512;&#12290;&#23613;&#31649;&#23558;k-TV&#39033;&#24212;&#29992;&#20110;&#19968;&#33324;&#30340;&#21442;&#25968;&#27169;&#22411;&#30001;&#20110;&#31215;&#20998;&#32780;&#23548;&#33268;&#35745;&#31639;&#22797;&#26434;&#65292;&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#31181;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#35757;&#32451;&#24102;&#26377;k-TV&#27491;&#21017;&#21270;&#30340;&#19968;&#33324;&#27169;&#22411;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#26174;&#24335;&#30340;&#25968;&#20540;&#31215;&#20998;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#32467;&#26500;&#20219;&#24847;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#65292;&#22240;&#20026;&#23427;&#21482;&#38656;&#35201;&#36827;&#34892;&#31616;&#21333;&#30340;&#38543;&#26426;&#26799;&#24230;&#20248;&#21270;&#21363;&#21487;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
While highly expressive parametric models including deep neural networks have an advantage to model complicated concepts, training such highly non-linear models is known to yield a high risk of notorious overfitting. To address this issue, this study considers a $k$th order total variation ($k$-TV) regularization, which is defined as the squared integral of the $k$th order derivative of the parametric models to be trained; penalizing the $k$-TV is expected to yield a smoother function, which is expected to avoid overfitting. While the $k$-TV terms applied to general parametric models are computationally intractable due to the integration, this study provides a stochastic optimization algorithm, that can efficiently train general models with the $k$-TV regularization without conducting explicit numerical integration. The proposed approach can be applied to the training of even deep neural networks whose structure is arbitrary, as it can be implemented by only a simple stochastic gradien
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38543;&#26426;&#38598;&#21512;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;RS-CNN&#65289;&#29992;&#20110;&#20998;&#31867;&#65292;&#36890;&#36807;&#39044;&#27979;&#20449;&#24565;&#20989;&#25968;&#32780;&#19981;&#26159;&#27010;&#29575;&#30690;&#37327;&#38598;&#21512;&#65292;&#20197;&#34920;&#31034;&#27169;&#22411;&#30340;&#32622;&#20449;&#24230;&#21644;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#12290;&#22522;&#20110;&#35748;&#35782;&#35770;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#27169;&#22411;&#33021;&#22815;&#20272;&#35745;&#30001;&#26377;&#38480;&#35757;&#32451;&#38598;&#24341;&#36215;&#30340;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.05772</link><description>&lt;p&gt;
&#38543;&#26426;&#38598;&#21512;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;RS-CNN&#65289;&#29992;&#20110;&#35748;&#35782;&#35770;&#28145;&#24230;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Random-Set Convolutional Neural Network (RS-CNN) for Epistemic Deep Learning. (arXiv:2307.05772v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05772
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38543;&#26426;&#38598;&#21512;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;RS-CNN&#65289;&#29992;&#20110;&#20998;&#31867;&#65292;&#36890;&#36807;&#39044;&#27979;&#20449;&#24565;&#20989;&#25968;&#32780;&#19981;&#26159;&#27010;&#29575;&#30690;&#37327;&#38598;&#21512;&#65292;&#20197;&#34920;&#31034;&#27169;&#22411;&#30340;&#32622;&#20449;&#24230;&#21644;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#12290;&#22522;&#20110;&#35748;&#35782;&#35770;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#27169;&#22411;&#33021;&#22815;&#20272;&#35745;&#30001;&#26377;&#38480;&#35757;&#32451;&#38598;&#24341;&#36215;&#30340;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#36234;&#26469;&#36234;&#22810;&#22320;&#24212;&#29992;&#20110;&#23433;&#20840;&#20851;&#38190;&#39046;&#22495;&#65292;&#23545;&#25239;&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#33267;&#20851;&#37325;&#35201;&#65292;&#38169;&#35823;&#30340;&#39044;&#27979;&#21487;&#33021;&#23548;&#33268;&#28508;&#22312;&#30340;&#28798;&#38590;&#24615;&#21518;&#26524;&#12290;&#36825;&#31361;&#20986;&#20102;&#23398;&#20064;&#31995;&#32479;&#38656;&#35201;&#33021;&#22815;&#30830;&#23450;&#27169;&#22411;&#23545;&#20854;&#39044;&#27979;&#30340;&#32622;&#20449;&#24230;&#20197;&#21450;&#19982;&#20043;&#30456;&#20851;&#32852;&#30340;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#30340;&#25163;&#27573;&#65292;&#8220;&#30693;&#36947;&#19968;&#20010;&#27169;&#22411;&#19981;&#30693;&#36947;&#8221;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29992;&#20110;&#20998;&#31867;&#30340;&#38543;&#26426;&#38598;&#21512;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;RS-CNN&#65289;&#65292;&#20854;&#39044;&#27979;&#20449;&#24565;&#20989;&#25968;&#32780;&#19981;&#26159;&#27010;&#29575;&#30690;&#37327;&#38598;&#21512;&#65292;&#20351;&#29992;&#38543;&#26426;&#38598;&#21512;&#30340;&#25968;&#23398;&#65292;&#21363;&#23545;&#26679;&#26412;&#31354;&#38388;&#30340;&#24130;&#38598;&#30340;&#20998;&#24067;&#12290;&#22522;&#20110;&#35748;&#35782;&#35770;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#38543;&#26426;&#38598;&#27169;&#22411;&#33021;&#22815;&#34920;&#31034;&#26426;&#22120;&#23398;&#20064;&#20013;&#30001;&#26377;&#38480;&#35757;&#32451;&#38598;&#24341;&#36215;&#30340;&#8220;&#35748;&#35782;&#24615;&#8221;&#19981;&#30830;&#23450;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#36817;&#20284;&#39044;&#27979;&#20449;&#24565;&#20989;&#25968;&#30456;&#20851;&#32852;&#30340;&#32622;&#20449;&#38598;&#30340;&#22823;&#23567;&#26469;&#20272;&#35745;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning is increasingly deployed in safety-critical domains where robustness against adversarial attacks is crucial and erroneous predictions could lead to potentially catastrophic consequences. This highlights the need for learning systems to be equipped with the means to determine a model's confidence in its prediction and the epistemic uncertainty associated with it, 'to know when a model does not know'. In this paper, we propose a novel Random-Set Convolutional Neural Network (RS-CNN) for classification which predicts belief functions rather than probability vectors over the set of classes, using the mathematics of random sets, i.e., distributions over the power set of the sample space. Based on the epistemic deep learning approach, random-set models are capable of representing the 'epistemic' uncertainty induced in machine learning by limited training sets. We estimate epistemic uncertainty by approximating the size of credal sets associated with the predicted belief func
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;Tsallis&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#65292;&#22312;&#35752;&#35770;&#27491;&#21017;&#21270;&#21442;&#25968;&#25509;&#36817;0&#26102;&#30340;&#25910;&#25947;&#36895;&#29575;&#26102;&#65292;&#21033;&#29992;&#37327;&#21270;&#21644;&#24433;&#23376;&#26041;&#27861;&#30830;&#23450;&#20102;&#25910;&#25947;&#36895;&#29575;&#65292;&#24182;&#19982;KL&#25955;&#24230;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#35777;&#26126;KL&#25955;&#24230;&#22312;Tsallis&#30456;&#23545;&#29109;&#24847;&#20041;&#19979;&#20855;&#26377;&#26368;&#24555;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2304.06616</link><description>&lt;p&gt;
Tsallis&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816;&#30340;&#25910;&#25947;&#36895;&#29575;
&lt;/p&gt;
&lt;p&gt;
Convergence rate of Tsallis entropic regularized optimal transport. (arXiv:2304.06616v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06616
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;Tsallis&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#65292;&#22312;&#35752;&#35770;&#27491;&#21017;&#21270;&#21442;&#25968;&#25509;&#36817;0&#26102;&#30340;&#25910;&#25947;&#36895;&#29575;&#26102;&#65292;&#21033;&#29992;&#37327;&#21270;&#21644;&#24433;&#23376;&#26041;&#27861;&#30830;&#23450;&#20102;&#25910;&#25947;&#36895;&#29575;&#65292;&#24182;&#19982;KL&#25955;&#24230;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#35777;&#26126;KL&#25955;&#24230;&#22312;Tsallis&#30456;&#23545;&#29109;&#24847;&#20041;&#19979;&#20855;&#26377;&#26368;&#24555;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;Tsallis&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#65292;&#24182;&#19988;&#35752;&#35770;&#20102;&#24403;&#27491;&#21017;&#21270;&#21442;&#25968;$\varepsilon$&#36235;&#36817;&#20110;0&#26102;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#21033;&#29992;Eckstein-Nutz&#25552;&#20986;&#30340;&#37327;&#21270;&#21644;&#24433;&#23376;&#26041;&#27861;&#26469;&#30830;&#23450;Tsallis&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;&#25105;&#20204;&#23558;&#20854;&#19982;&#20351;&#29992;Kullback-Leibler&#65288;KL&#65289;&#25955;&#24230;&#30340;&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816;&#30340;&#25910;&#25947;&#36895;&#29575;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;Tsallis&#30456;&#23545;&#29109;&#24847;&#20041;&#19979;KL&#20855;&#26377;&#26368;&#24555;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we consider Tsallis entropic regularized optimal transport and discuss the convergence rate as the regularization parameter $\varepsilon$ goes to $0$. In particular, we establish the convergence rate of the Tsallis entropic regularized optimal transport using the quantization and shadow arguments developed by Eckstein--Nutz. We compare this to the convergence rate of the entropic regularized optimal transport with Kullback--Leibler (KL) divergence and show that KL is the fastest convergence rate in terms of Tsallis relative entropy.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29702;&#35770;&#26469;&#25551;&#36848;&#38750;&#36127;&#36229;&#39532;&#27663;&#36807;&#31243;&#65292;&#24182;&#25512;&#23548;&#20986;&#19968;&#20010;&#26032;&#30340;&#26497;&#22823;&#19981;&#31561;&#24335;&#65292;&#36866;&#29992;&#20110;&#38750;&#21487;&#31215;&#24773;&#20917;&#65292;&#24182;&#35828;&#26126;&#20102;&#28151;&#21512;&#26041;&#27861;&#30340;&#25193;&#23637;&#20197;&#21450;&#35813;&#29702;&#35770;&#22312;&#39034;&#24207;&#32479;&#35745;&#20013;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2304.01163</link><description>&lt;p&gt;
&#38750;&#21487;&#31215;&#38750;&#36127;&#36229;&#39532;&#27663;&#36807;&#31243;&#30340;&#25193;&#23637;&#32500;&#23572;&#19981;&#31561;&#24335;
&lt;/p&gt;
&lt;p&gt;
The extended Ville's inequality for nonintegrable nonnegative supermartingales. (arXiv:2304.01163v1 [math.PR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01163
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29702;&#35770;&#26469;&#25551;&#36848;&#38750;&#36127;&#36229;&#39532;&#27663;&#36807;&#31243;&#65292;&#24182;&#25512;&#23548;&#20986;&#19968;&#20010;&#26032;&#30340;&#26497;&#22823;&#19981;&#31561;&#24335;&#65292;&#36866;&#29992;&#20110;&#38750;&#21487;&#31215;&#24773;&#20917;&#65292;&#24182;&#35828;&#26126;&#20102;&#28151;&#21512;&#26041;&#27861;&#30340;&#25193;&#23637;&#20197;&#21450;&#35813;&#29702;&#35770;&#22312;&#39034;&#24207;&#32479;&#35745;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312; Robbins &#30340;&#21021;&#22987;&#24037;&#20316;&#22522;&#30784;&#19978;&#65292;&#20005;&#23494;&#22320;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#36127;&#36229;&#39532;&#27663;&#36807;&#31243;&#30340;&#25193;&#23637;&#29702;&#35770;&#65292;&#19981;&#38656;&#35201;&#21487;&#31215;&#24615;&#25110;&#26377;&#38480;&#24615;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102; Robbins &#39044;&#31034;&#30340;&#19968;&#20010;&#20851;&#38190;&#26497;&#22823;&#19981;&#31561;&#24335;&#65292;&#31216;&#20026;&#25193;&#23637;&#32500;&#23572;&#19981;&#31561;&#24335;&#65292;&#23427;&#21152;&#24378;&#20102;&#32463;&#20856;&#30340;&#32500;&#23572;&#19981;&#31561;&#24335;&#65288;&#36866;&#29992;&#20110;&#21487;&#31215;&#38750;&#36127;&#36229;&#39532;&#27663;&#36807;&#31243;&#65289;&#65292;&#24182;&#36866;&#29992;&#20110;&#25105;&#20204;&#30340;&#38750;&#21487;&#31215;&#35774;&#32622;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#28151;&#21512;&#26041;&#27861;&#30340;&#25193;&#23637;&#65292;&#36866;&#29992;&#20110;&#25105;&#20204;&#25193;&#23637;&#30340;&#38750;&#36127;&#36229;&#39532;&#27663;&#36807;&#31243;&#30340; $\sigma$- &#26377;&#38480;&#28151;&#21512;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#25105;&#20204;&#29702;&#35770;&#22312;&#39034;&#24207;&#32479;&#35745;&#20013;&#30340;&#19968;&#20123;&#24212;&#29992;&#65292;&#22914;&#22312;&#25512;&#23548;&#38750;&#21442;&#25968;&#32622;&#20449;&#24207;&#21015;&#21644;&#65288;&#25193;&#23637;&#65289;e-&#36807;&#31243;&#20013;&#20351;&#29992;&#19981;&#36866;&#24403;&#28151;&#21512;&#65288;&#20808;&#39564;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Following initial work by Robbins, we rigorously present an extended theory of nonnegative supermartingales, requiring neither integrability nor finiteness. In particular, we derive a key maximal inequality foreshadowed by Robbins, which we call the extended Ville's inequality, that strengthens the classical Ville's inequality (for integrable nonnegative supermartingales), and also applies to our nonintegrable setting. We derive an extension of the method of mixtures, which applies to $\sigma$-finite mixtures of our extended nonnegative supermartingales. We present some implications of our theory for sequential statistics, such as the use of improper mixtures (priors) in deriving nonparametric confidence sequences and (extended) e-processes.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21452;&#37325;&#40065;&#26834;&#36125;&#21494;&#26031;&#25512;&#26029;&#31243;&#24207;&#65292;&#23454;&#29616;&#20102;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#30340;&#20559;&#24046;&#26657;&#27491;&#24182;&#24418;&#25104;&#20102;&#21487;&#20449;&#21306;&#38388;&#12290;</title><link>http://arxiv.org/abs/2211.16298</link><description>&lt;p&gt;
&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#30340;&#21452;&#37325;&#40065;&#26834;&#36125;&#21494;&#26031;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Double Robust Bayesian Inference on Average Treatment Effects. (arXiv:2211.16298v3 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.16298
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21452;&#37325;&#40065;&#26834;&#36125;&#21494;&#26031;&#25512;&#26029;&#31243;&#24207;&#65292;&#23454;&#29616;&#20102;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#30340;&#20559;&#24046;&#26657;&#27491;&#24182;&#24418;&#25104;&#20102;&#21487;&#20449;&#21306;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#26080;&#20559;&#24615;&#19979;&#30340;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;ATE&#65289;&#30340;&#21452;&#37325;&#40065;&#26834;&#36125;&#21494;&#26031;&#25512;&#26029;&#31243;&#24207;&#12290;&#25105;&#20204;&#30340;&#40065;&#26834;&#36125;&#21494;&#26031;&#26041;&#27861;&#21253;&#25324;&#20004;&#20010;&#35843;&#25972;&#27493;&#39588;&#65306;&#39318;&#20808;&#65292;&#25105;&#20204;&#23545;&#26465;&#20214;&#22343;&#20540;&#20989;&#25968;&#30340;&#20808;&#39564;&#20998;&#24067;&#36827;&#34892;&#26657;&#27491;&#65307;&#20854;&#27425;&#65292;&#25105;&#20204;&#22312;&#20135;&#29983;&#30340;ATE&#30340;&#21518;&#39564;&#20998;&#24067;&#19978;&#24341;&#20837;&#19968;&#20010;&#37325;&#26032;&#23621;&#20013;&#26415;&#35821;&#12290;&#25105;&#20204;&#36890;&#36807;&#24314;&#31435;&#21452;&#37325;&#40065;&#26834;&#24615;&#19979;&#30340;&#21322;&#21442;&#25968;Bernstein-von Mises&#23450;&#29702;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#36125;&#21494;&#26031;&#20272;&#35745;&#37327;&#21644;&#21452;&#37325;&#40065;&#26834;&#39057;&#29575;&#20272;&#35745;&#37327;&#30340;&#28176;&#36817;&#31561;&#20215;&#24615;&#65307;&#21363;&#65292;&#26465;&#20214;&#22343;&#20540;&#20989;&#25968;&#30340;&#32570;&#20047;&#24179;&#28369;&#24615;&#21487;&#20197;&#36890;&#36807;&#27010;&#29575;&#24471;&#20998;&#30340;&#39640;&#35268;&#21017;&#24615;&#36827;&#34892;&#34917;&#20607;&#65292;&#21453;&#20043;&#20134;&#28982;&#12290;&#22240;&#27492;&#65292;&#20135;&#29983;&#30340;&#36125;&#21494;&#26031;&#28857;&#20272;&#35745;&#20869;&#22312;&#21270;&#20102;&#39057;&#29575;&#22411;&#21452;&#37325;&#40065;&#26834;&#20272;&#35745;&#37327;&#30340;&#20559;&#24046;&#26657;&#27491;&#65292;&#32780;&#36125;&#21494;&#26031;&#21487;&#20449;&#38598;&#24418;&#25104;&#30340;&#32622;&#20449;&#21306;&#38388;&#20855;&#26377;&#28176;&#36817;&#31934;&#30830;&#30340;&#35206;&#30422;&#27010;&#29575;&#12290;&#22312;&#27169;&#25311;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#36825;&#31181;&#40065;&#26834;&#30340;&#36125;&#21494;&#26031;&#31243;&#24207;&#23548;&#33268;&#20102;&#26174;&#30528;&#30340;...
&lt;/p&gt;
&lt;p&gt;
We study a double robust Bayesian inference procedure on the average treatment effect (ATE) under unconfoundedness. Our robust Bayesian approach involves two adjustment steps: first, we make a correction for prior distributions of the conditional mean function; second, we introduce a recentering term on the posterior distribution of the resulting ATE. We prove asymptotic equivalence of our Bayesian estimator and double robust frequentist estimators by establishing a new semiparametric Bernstein-von Mises theorem under double robustness; i.e., the lack of smoothness of conditional mean functions can be compensated by high regularity of the propensity score and vice versa. Consequently, the resulting Bayesian point estimator internalizes the bias correction as the frequentist-type doubly robust estimator, and the Bayesian credible sets form confidence intervals with asymptotically exact coverage probability. In simulations, we find that this robust Bayesian procedure leads to significant
&lt;/p&gt;</description></item></channel></rss>