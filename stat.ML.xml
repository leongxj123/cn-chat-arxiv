<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21160;&#21147;&#23398;&#27169;&#22411;&#26469;&#35299;&#37322;&#31070;&#32463;&#32553;&#25918;&#23450;&#24459;&#12290;&#36890;&#36807;&#20998;&#26512;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#65292;&#30740;&#31350;&#21457;&#29616;&#35757;&#32451;&#26102;&#38388;&#21644;&#27169;&#22411;&#22823;&#23567;&#30340;&#32553;&#25918;&#20855;&#26377;&#19981;&#21516;&#30340;&#24130;&#24459;&#25351;&#25968;&#65292;&#32780;&#35745;&#31639;&#26368;&#20248;&#32553;&#25918;&#35268;&#21017;&#35201;&#27714;&#22686;&#21152;&#35757;&#32451;&#27493;&#25968;&#24555;&#20110;&#22686;&#21152;&#27169;&#22411;&#21442;&#25968;&#65292;&#19982;&#23454;&#35777;&#35266;&#23519;&#30456;&#19968;&#33268;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01092</link><description>&lt;p&gt;
&#31070;&#32463;&#32553;&#25918;&#23450;&#24459;&#30340;&#21160;&#21147;&#23398;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Dynamical Model of Neural Scaling Laws
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01092
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21160;&#21147;&#23398;&#27169;&#22411;&#26469;&#35299;&#37322;&#31070;&#32463;&#32553;&#25918;&#23450;&#24459;&#12290;&#36890;&#36807;&#20998;&#26512;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#65292;&#30740;&#31350;&#21457;&#29616;&#35757;&#32451;&#26102;&#38388;&#21644;&#27169;&#22411;&#22823;&#23567;&#30340;&#32553;&#25918;&#20855;&#26377;&#19981;&#21516;&#30340;&#24130;&#24459;&#25351;&#25968;&#65292;&#32780;&#35745;&#31639;&#26368;&#20248;&#32553;&#25918;&#35268;&#21017;&#35201;&#27714;&#22686;&#21152;&#35757;&#32451;&#27493;&#25968;&#24555;&#20110;&#22686;&#21152;&#27169;&#22411;&#21442;&#25968;&#65292;&#19982;&#23454;&#35777;&#35266;&#23519;&#30456;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#65292;&#31070;&#32463;&#32593;&#32476;&#30340;&#24615;&#33021;&#38543;&#30528;&#35757;&#32451;&#26102;&#38388;&#12289;&#25968;&#25454;&#38598;&#22823;&#23567;&#21644;&#27169;&#22411;&#22823;&#23567;&#30340;&#22686;&#21152;&#32780;&#39044;&#27979;&#24615;&#22320;&#25552;&#39640;&#65292;&#36328;&#22810;&#20010;&#25968;&#37327;&#32423;&#12290;&#36825;&#31181;&#29616;&#35937;&#34987;&#31216;&#20026;&#31070;&#32463;&#32553;&#25918;&#23450;&#24459;&#12290;&#26368;&#37325;&#35201;&#30340;&#26159;&#35745;&#31639;&#26368;&#20248;&#32553;&#25918;&#23450;&#24459;&#65292;&#23427;&#25253;&#21578;&#20102;&#22312;&#36873;&#25321;&#26368;&#20339;&#27169;&#22411;&#22823;&#23567;&#26102;&#24615;&#33021;&#19982;&#35745;&#31639;&#25968;&#37327;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#19968;&#20010;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#36827;&#34892;&#35757;&#32451;&#21644;&#27867;&#21270;&#30340;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#20316;&#20026;&#32593;&#32476;&#35757;&#32451;&#21644;&#27867;&#21270;&#30340;&#21487;&#35299;&#27169;&#22411;&#12290;&#36825;&#20010;&#27169;&#22411;&#22797;&#29616;&#20102;&#20851;&#20110;&#31070;&#32463;&#32553;&#25918;&#23450;&#24459;&#30340;&#35768;&#22810;&#35266;&#23519;&#32467;&#26524;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#23545;&#20110;&#20026;&#20160;&#20040;&#35757;&#32451;&#26102;&#38388;&#21644;&#27169;&#22411;&#22823;&#23567;&#30340;&#32553;&#25918;&#20855;&#26377;&#19981;&#21516;&#30340;&#24130;&#24459;&#25351;&#25968;&#25552;&#20986;&#20102;&#19968;&#20010;&#39044;&#27979;&#12290;&#22240;&#27492;&#65292;&#29702;&#35770;&#39044;&#27979;&#20102;&#19968;&#31181;&#19981;&#23545;&#31216;&#30340;&#35745;&#31639;&#26368;&#20248;&#32553;&#25918;&#35268;&#21017;&#65292;&#20854;&#20013;&#35757;&#32451;&#27493;&#25968;&#30340;&#22686;&#21152;&#36895;&#24230;&#24555;&#20110;&#27169;&#22411;&#21442;&#25968;&#30340;&#22686;&#21152;&#36895;&#24230;&#65292;&#19982;&#26368;&#36817;&#30340;&#23454;&#35777;&#35266;&#23519;&#19968;&#33268;&#12290;&#20854;&#27425;&#65292;&#35266;&#23519;&#21040;&#22312;&#35757;&#32451;&#30340;&#26089;&#26399;&#65292;&#32593;&#32476;&#20250;&#25910;&#25947;&#21040;&#26080;&#38480;&#23485;&#24230;&#24773;&#20917;&#19979;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
On a variety of tasks, the performance of neural networks predictably improves with training time, dataset size and model size across many orders of magnitude. This phenomenon is known as a neural scaling law. Of fundamental importance is the compute-optimal scaling law, which reports the performance as a function of units of compute when choosing model sizes optimally. We analyze a random feature model trained with gradient descent as a solvable model of network training and generalization. This reproduces many observations about neural scaling laws. First, our model makes a prediction about why the scaling of performance with training time and with model size have different power law exponents. Consequently, the theory predicts an asymmetric compute-optimal scaling rule where the number of training steps are increased faster than model parameters, consistent with recent empirical observations. Second, it has been observed that early in training, networks converge to their infinite-wi
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21160;&#20316;&#21452;&#27169;&#25311;&#32534;&#30721;&#65292;&#36890;&#36807;&#36882;&#24402;&#19981;&#21464;&#24615;&#32422;&#26463;&#25193;&#23637;&#20102;&#21333;&#27493;&#25511;&#21046;&#24615;&#65292;&#23398;&#20064;&#20102;&#19968;&#20010;&#21487;&#20197;&#24179;&#28369;&#25240;&#25187;&#36828;&#26399;&#20803;&#32032;&#30340;&#22810;&#27493;&#25511;&#21046;&#24230;&#37327;</title><link>https://arxiv.org/abs/2403.16369</link><description>&lt;p&gt;
&#20351;&#29992;&#19981;&#21464;&#24615;&#23398;&#20064;&#22522;&#20110;&#21160;&#20316;&#30340;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Learning Action-based Representations Using Invariance
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16369
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21160;&#20316;&#21452;&#27169;&#25311;&#32534;&#30721;&#65292;&#36890;&#36807;&#36882;&#24402;&#19981;&#21464;&#24615;&#32422;&#26463;&#25193;&#23637;&#20102;&#21333;&#27493;&#25511;&#21046;&#24615;&#65292;&#23398;&#20064;&#20102;&#19968;&#20010;&#21487;&#20197;&#24179;&#28369;&#25240;&#25187;&#36828;&#26399;&#20803;&#32032;&#30340;&#22810;&#27493;&#25511;&#21046;&#24230;&#37327;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#20351;&#29992;&#39640;&#32500;&#24230;&#35266;&#27979;&#24517;&#39035;&#33021;&#22815;&#22312;&#35768;&#22810;&#22806;&#28304;&#24615;&#24178;&#25200;&#20013;&#35782;&#21035;&#30456;&#20851;&#29366;&#24577;&#29305;&#24449;&#12290;&#19968;&#20010;&#33021;&#22815;&#25429;&#25417;&#21487;&#25511;&#24615;&#30340;&#34920;&#31034;&#36890;&#36807;&#30830;&#23450;&#24433;&#21709;&#20195;&#29702;&#25511;&#21046;&#30340;&#22240;&#32032;&#26469;&#35782;&#21035;&#36825;&#20123;&#29366;&#24577;&#20803;&#32032;&#12290;&#34429;&#28982;&#35832;&#22914;&#36870;&#21160;&#21147;&#23398;&#21644;&#20114;&#20449;&#24687;&#31561;&#26041;&#27861;&#21487;&#20197;&#25429;&#25417;&#26377;&#38480;&#25968;&#37327;&#30340;&#26102;&#38388;&#27493;&#30340;&#21487;&#25511;&#24615;&#65292;&#20294;&#25429;&#33719;&#38271;&#26102;&#38388;&#20803;&#32032;&#20173;&#28982;&#26159;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#12290;&#30701;&#35270;&#30340;&#21487;&#25511;&#24615;&#21487;&#20197;&#25429;&#25417;&#20195;&#29702;&#21363;&#23558;&#25758;&#21521;&#22681;&#22721;&#30340;&#30636;&#38388;&#65292;&#20294;&#19981;&#33021;&#22312;&#20195;&#29702;&#36824;&#26377;&#19968;&#23450;&#36317;&#31163;&#20043;&#26102;&#25429;&#25417;&#22681;&#22721;&#30340;&#25511;&#21046;&#30456;&#20851;&#24615;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21160;&#20316;&#21452;&#27169;&#25311;&#32534;&#30721;&#65292;&#36825;&#26159;&#19968;&#31181;&#21463;&#21040;&#21452;&#27169;&#25311;&#19981;&#21464;&#37327;&#20551;&#24230;&#37327;&#21551;&#21457;&#30340;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#36882;&#24402;&#19981;&#21464;&#24615;&#32422;&#26463;&#25193;&#23637;&#20102;&#21333;&#27493;&#25511;&#21046;&#24615;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#24335;&#65292;&#21160;&#20316;&#21452;&#27169;&#25311;&#23398;&#20064;&#20102;&#19968;&#20010;&#24179;&#28369;&#25240;&#25187;&#36828;&#26399;&#20803;&#32032;&#30340;&#22810;&#27493;&#25511;&#21046;&#24230;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16369v1 Announce Type: cross  Abstract: Robust reinforcement learning agents using high-dimensional observations must be able to identify relevant state features amidst many exogeneous distractors. A representation that captures controllability identifies these state elements by determining what affects agent control. While methods such as inverse dynamics and mutual information capture controllability for a limited number of timesteps, capturing long-horizon elements remains a challenging problem. Myopic controllability can capture the moment right before an agent crashes into a wall, but not the control-relevance of the wall while the agent is still some distance away. To address this we introduce action-bisimulation encoding, a method inspired by the bisimulation invariance pseudometric, that extends single-step controllability with a recursive invariance constraint. By doing this, action-bisimulation learns a multi-step controllability metric that smoothly discounts dist
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#32467;&#26500;&#28151;&#21512;&#27010;&#29575;&#20998;&#24067;&#25552;&#20379;&#20102;&#20934;&#30830;&#30340;&#21518;&#39564;&#25512;&#26029;&#65292;&#21516;&#26102;&#20855;&#26377;&#26356;&#23567;&#30340;&#35745;&#31639;&#21344;&#29992;&#37327;&#65292;&#30456;&#36739;&#20110;&#29616;&#26377;&#30340;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;SBI&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.07454</link><description>&lt;p&gt;
&#20351;&#29992;&#39640;&#26031;&#23616;&#37096;&#32447;&#24615;&#26144;&#23556;&#36827;&#34892;&#24555;&#36895;&#12289;&#20934;&#30830;&#21644;&#36731;&#37327;&#32423;&#30340;&#39034;&#24207;&#20223;&#30495;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Fast, accurate and lightweight sequential simulation-based inference using Gaussian locally linear mappings
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07454
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#32467;&#26500;&#28151;&#21512;&#27010;&#29575;&#20998;&#24067;&#25552;&#20379;&#20102;&#20934;&#30830;&#30340;&#21518;&#39564;&#25512;&#26029;&#65292;&#21516;&#26102;&#20855;&#26377;&#26356;&#23567;&#30340;&#35745;&#31639;&#21344;&#29992;&#37327;&#65292;&#30456;&#36739;&#20110;&#29616;&#26377;&#30340;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;SBI&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07454v1 &#20844;&#21578;&#31867;&#22411;: &#36328;&#39046;&#22495; &#25688;&#35201;: &#38024;&#23545;&#20855;&#26377;&#38590;&#20197;&#22788;&#29702;&#30340;&#20284;&#28982;&#20989;&#25968;&#30340;&#22797;&#26434;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#21487;&#20197;&#20351;&#29992;&#22810;&#27425;&#35843;&#29992;&#35745;&#31639;&#27169;&#25311;&#22120;&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#12290; &#36825;&#20123;&#26041;&#27861;&#34987;&#32479;&#31216;&#20026;&#8220;&#22522;&#20110;&#20223;&#30495;&#30340;&#25512;&#26029;&#8221;&#65288;SBI&#65289;&#12290; &#26368;&#36817;&#30340;SBI&#26041;&#27861;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#25552;&#20379;&#36817;&#20284;&#20294;&#34920;&#36798;&#20016;&#23500;&#30340;&#26500;&#36896;&#65292;&#29992;&#20110;&#19981;&#21487;&#29992;&#30340;&#20284;&#28982;&#20989;&#25968;&#21644;&#21518;&#39564;&#20998;&#24067;&#12290; &#28982;&#32780;&#65292;&#23427;&#20204;&#36890;&#24120;&#26080;&#27861;&#23454;&#29616;&#20934;&#30830;&#24615;&#21644;&#35745;&#31639;&#38656;&#27714;&#20043;&#38388;&#30340;&#26368;&#20339;&#25240;&#34935;&#12290; &#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25552;&#20379;&#20284;&#28982;&#20989;&#25968;&#21644;&#21518;&#39564;&#20998;&#24067;&#36817;&#20284;&#30340;&#26367;&#20195;&#26041;&#27861;&#65292;&#20351;&#29992;&#32467;&#26500;&#21270;&#30340;&#27010;&#29575;&#20998;&#24067;&#28151;&#21512;&#29289;&#12290; &#30456;&#23545;&#20110;&#26368;&#20808;&#36827;&#30340;&#22522;&#20110;NN&#30340;SBI&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20135;&#29983;&#20934;&#30830;&#30340;&#21518;&#39564;&#25512;&#26029;&#30340;&#21516;&#26102;&#65292;&#20855;&#26377;&#26356;&#23567;&#30340;&#35745;&#31639;&#21344;&#29992;&#37327;&#12290; &#25105;&#20204;&#22312;SBI&#25991;&#29486;&#20013;&#30340;&#20960;&#20010;&#22522;&#20934;&#27169;&#22411;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07454v1 Announce Type: cross  Abstract: Bayesian inference for complex models with an intractable likelihood can be tackled using algorithms performing many calls to computer simulators. These approaches are collectively known as "simulation-based inference" (SBI). Recent SBI methods have made use of neural networks (NN) to provide approximate, yet expressive constructs for the unavailable likelihood function and the posterior distribution. However, they do not generally achieve an optimal trade-off between accuracy and computational demand. In this work, we propose an alternative that provides both approximations to the likelihood and the posterior distribution, using structured mixtures of probability distributions. Our approach produces accurate posterior inference when compared to state-of-the-art NN-based SBI methods, while exhibiting a much smaller computational footprint. We illustrate our results on several benchmark models from the SBI literature.
&lt;/p&gt;</description></item><item><title>&#20998;&#26512;&#31070;&#32463;&#32593;&#32476;&#21644;LLMs&#20013;&#20248;&#21270;&#36712;&#36857;&#30340;&#22797;&#26434;&#24615;&#65292;&#25581;&#31034;&#20102;&#20248;&#21270;&#36807;&#31243;&#20013;&#30340;&#20851;&#38190;&#29305;&#24449;&#65292;&#21253;&#25324;&#26041;&#21521;&#25506;&#32034;&#21644;&#26041;&#21521;&#27491;&#21017;&#21270;&#12290;</title><link>https://arxiv.org/abs/2403.07379</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#21644;LLMs&#20013;&#20248;&#21270;&#36712;&#36857;&#30340;&#29305;&#24449;&#65306;&#38271;&#24230;&#12289;&#25296;&#28857;&#21644;&#27515;&#32993;&#21516;
&lt;/p&gt;
&lt;p&gt;
Hallmarks of Optimization Trajectories in Neural Networks and LLMs: The Lengths, Bends, and Dead Ends
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07379
&lt;/p&gt;
&lt;p&gt;
&#20998;&#26512;&#31070;&#32463;&#32593;&#32476;&#21644;LLMs&#20013;&#20248;&#21270;&#36712;&#36857;&#30340;&#22797;&#26434;&#24615;&#65292;&#25581;&#31034;&#20102;&#20248;&#21270;&#36807;&#31243;&#20013;&#30340;&#20851;&#38190;&#29305;&#24449;&#65292;&#21253;&#25324;&#26041;&#21521;&#25506;&#32034;&#21644;&#26041;&#21521;&#27491;&#21017;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20840;&#26032;&#30340;&#26041;&#27861;&#26469;&#29702;&#35299;&#31070;&#32463;&#32593;&#32476;&#30340;&#26426;&#21046;&#65292;&#36890;&#36807;&#20998;&#26512;&#20854;&#20248;&#21270;&#36712;&#36857;&#20013;&#21253;&#21547;&#30340;&#20016;&#23500;&#21442;&#25968;&#32467;&#26500;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20123;&#20851;&#20110;&#20248;&#21270;&#36712;&#36857;&#22797;&#26434;&#24615;&#30340;&#33258;&#28982;&#27010;&#24565;&#65292;&#26082;&#23450;&#24615;&#21448;&#23450;&#37327;&#22320;&#25581;&#31034;&#20102;&#21508;&#31181;&#20248;&#21270;&#36873;&#25321;&#65288;&#22914;&#21160;&#37327;&#12289;&#26435;&#37325;&#34928;&#20943;&#21644;&#25209;&#22823;&#23567;&#65289;&#20043;&#38388;&#25152;&#28041;&#21450;&#30340;&#20869;&#22312;&#24494;&#22937;&#21644;&#30456;&#20114;&#20316;&#29992;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#20123;&#27010;&#24565;&#26469;&#25552;&#20379;&#20851;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20248;&#21270;&#26412;&#36136;&#30340;&#20851;&#38190;&#29305;&#24449;&#65306;&#20309;&#26102;&#39034;&#21033;&#36827;&#34892;&#65292;&#20309;&#26102;&#38519;&#20837;&#27515;&#32993;&#21516;&#12290;&#27492;&#22806;&#65292;&#22522;&#20110;&#25105;&#20204;&#30340;&#36712;&#36857;&#35270;&#35282;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#21160;&#37327;&#21644;&#26435;&#37325;&#34928;&#20943;&#20043;&#38388;&#20419;&#36827;&#26041;&#21521;&#25506;&#32034;&#30340;&#20132;&#32455;&#34892;&#20026;&#65292;&#20197;&#21450;&#20854;&#20182;&#19968;&#20123;&#34892;&#20026;&#30340;&#26041;&#21521;&#27491;&#21017;&#21270;&#34892;&#20026;&#12290;&#25105;&#20204;&#22312;&#22823;&#35268;&#27169;&#35270;&#35273;&#21644;&#35821;&#35328;&#35774;&#32622;&#20013;&#36827;&#34892;&#23454;&#39564;&#65292;&#21253;&#25324;&#20855;&#26377;&#26368;&#22810;120&#20159;&#20010;&#21442;&#25968;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07379v1 Announce Type: cross  Abstract: We propose a fresh take on understanding the mechanisms of neural networks by analyzing the rich structure of parameters contained within their optimization trajectories. Towards this end, we introduce some natural notions of the complexity of optimization trajectories, both qualitative and quantitative, which reveal the inherent nuance and interplay involved between various optimization choices, such as momentum, weight decay, and batch size. We use them to provide key hallmarks about the nature of optimization in deep neural networks: when it goes right, and when it finds itself in a dead end. Further, thanks to our trajectory perspective, we uncover an intertwined behaviour of momentum and weight decay that promotes directional exploration, as well as a directional regularization behaviour of some others. We perform experiments over large-scale vision and language settings, including large language models (LLMs) with up to 12 billio
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;ML-UQ&#26657;&#20934;&#32479;&#35745;&#37327;&#30340;&#20351;&#29992;&#38382;&#39064;&#65292;&#21457;&#29616;&#19968;&#20123;&#32479;&#35745;&#37327;&#23545;&#20110;&#29983;&#25104;&#20998;&#24067;&#30340;&#36873;&#25321;&#36807;&#20110;&#25935;&#24863;&#65292;&#21487;&#33021;&#24433;&#21709;&#26657;&#20934;&#35786;&#26029;&#12290;</title><link>https://arxiv.org/abs/2403.00423</link><description>&lt;p&gt;
&#20351;&#29992;&#27169;&#25311;&#21442;&#32771;&#20540;&#39564;&#35777;ML-UQ&#26657;&#20934;&#32479;&#35745;&#37327;&#65306;&#19968;&#39033;&#25935;&#24863;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Validation of ML-UQ calibration statistics using simulated reference values: a sensitivity analysis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00423
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;ML-UQ&#26657;&#20934;&#32479;&#35745;&#37327;&#30340;&#20351;&#29992;&#38382;&#39064;&#65292;&#21457;&#29616;&#19968;&#20123;&#32479;&#35745;&#37327;&#23545;&#20110;&#29983;&#25104;&#20998;&#24067;&#30340;&#36873;&#25321;&#36807;&#20110;&#25935;&#24863;&#65292;&#21487;&#33021;&#24433;&#21709;&#26657;&#20934;&#35786;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#20123;&#27969;&#34892;&#30340;&#26426;&#22120;&#23398;&#20064;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65288;ML-UQ&#65289;&#26657;&#20934;&#32479;&#35745;&#37327;&#27809;&#26377;&#39044;&#23450;&#20041;&#30340;&#21442;&#32771;&#20540;&#65292;&#20027;&#35201;&#29992;&#20110;&#27604;&#36739;&#30740;&#31350;&#12290;&#22240;&#27492;&#65292;&#26657;&#20934;&#20960;&#20046;&#20174;&#19981;&#34987;&#39564;&#35777;&#65292;&#35786;&#26029;&#30041;&#32473;&#35835;&#32773;&#30340;&#21028;&#26029;&#12290;&#25552;&#20986;&#20102;&#22522;&#20110;&#23454;&#38469;&#19981;&#30830;&#23450;&#24615;&#23548;&#20986;&#30340;&#21512;&#25104;&#26657;&#20934;&#25968;&#25454;&#38598;&#30340;&#27169;&#25311;&#21442;&#32771;&#20540;&#65292;&#20197;&#24357;&#34917;&#36825;&#19968;&#38382;&#39064;&#12290;&#30001;&#20110;&#29992;&#20110;&#27169;&#25311;&#21512;&#25104;&#35823;&#24046;&#30340;&#29983;&#25104;&#27010;&#29575;&#20998;&#24067;&#36890;&#24120;&#27809;&#26377;&#32422;&#26463;&#65292;&#25152;&#20197;&#27169;&#25311;&#21442;&#32771;&#20540;&#23545;&#29983;&#25104;&#20998;&#24067;&#36873;&#25321;&#30340;&#25935;&#24863;&#24615;&#21487;&#33021;&#20250;&#25104;&#20026;&#38382;&#39064;&#65292;&#23545;&#26657;&#20934;&#35786;&#26029;&#20135;&#29983;&#24576;&#30097;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#36825;&#19968;&#38382;&#39064;&#30340;&#21508;&#20010;&#26041;&#38754;&#65292;&#24182;&#26174;&#31034;&#19968;&#20123;&#32479;&#35745;&#37327;&#23545;&#20110;&#29992;&#20110;&#39564;&#35777;&#26102;&#29983;&#25104;&#20998;&#24067;&#30340;&#36873;&#25321;&#36807;&#20110;&#25935;&#24863;&#65292;&#24403;&#29983;&#25104;&#20998;&#24067;&#26410;&#30693;&#26102;&#12290;&#20363;&#22914;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00423v1 Announce Type: cross  Abstract: Some popular Machine Learning Uncertainty Quantification (ML-UQ) calibration statistics do not have predefined reference values and are mostly used in comparative studies. In consequence, calibration is almost never validated and the diagnostic is left to the appreciation of the reader. Simulated reference values, based on synthetic calibrated datasets derived from actual uncertainties, have been proposed to palliate this problem. As the generative probability distribution for the simulation of synthetic errors is often not constrained, the sensitivity of simulated reference values to the choice of generative distribution might be problematic, shedding a doubt on the calibration diagnostic. This study explores various facets of this problem, and shows that some statistics are excessively sensitive to the choice of generative distribution to be used for validation when the generative distribution is unknown. This is the case, for instan
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#22312;&#36125;&#21494;&#26031;&#35774;&#32622;&#20013;&#25506;&#35752;&#20102;&#22266;&#23450;&#32622;&#20449;&#24230;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#20256;&#32479;&#39057;&#29575;&#35774;&#23450;&#19979;&#30340;&#31639;&#27861;&#22312;&#27492;&#35774;&#32622;&#19979;&#34920;&#29616;&#27425;&#20248;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#24615;&#33021;&#19982;&#29702;&#35770;&#19979;&#38480;&#30456;&#21305;&#37197;&#30340;&#36830;&#32493;&#25490;&#38500;&#21464;&#31181;&#12290;</title><link>https://arxiv.org/abs/2402.10429</link><description>&lt;p&gt;
&#22312;&#36125;&#21494;&#26031;&#35774;&#32622;&#20013;&#30340;&#22266;&#23450;&#32622;&#20449;&#24230;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Fixed Confidence Best Arm Identification in the Bayesian Setting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10429
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#22312;&#36125;&#21494;&#26031;&#35774;&#32622;&#20013;&#25506;&#35752;&#20102;&#22266;&#23450;&#32622;&#20449;&#24230;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#20256;&#32479;&#39057;&#29575;&#35774;&#23450;&#19979;&#30340;&#31639;&#27861;&#22312;&#27492;&#35774;&#32622;&#19979;&#34920;&#29616;&#27425;&#20248;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#24615;&#33021;&#19982;&#29702;&#35770;&#19979;&#38480;&#30456;&#21305;&#37197;&#30340;&#36830;&#32493;&#25490;&#38500;&#21464;&#31181;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#36125;&#21494;&#26031;&#35774;&#32622;&#20013;&#30340;&#22266;&#23450;&#32622;&#20449;&#24230;&#26368;&#20339;&#33218;&#35782;&#21035;&#65288;FC-BAI&#65289;&#38382;&#39064;&#12290;&#35813;&#38382;&#39064;&#26088;&#22312;&#22312;&#24050;&#30693;&#20808;&#39564;&#37319;&#26679;&#30340;&#24773;&#20917;&#19979;&#20197;&#22266;&#23450;&#32622;&#20449;&#27700;&#24179;&#25214;&#21040;&#22343;&#20540;&#26368;&#22823;&#30340;&#33218;&#12290;&#22823;&#22810;&#25968;&#20851;&#20110;FC-BAI&#38382;&#39064;&#30340;&#30740;&#31350;&#37117;&#26159;&#22312;&#39057;&#29575;&#35774;&#23450;&#20013;&#36827;&#34892;&#30340;&#65292;&#22312;&#35813;&#35774;&#23450;&#19979;&#65292;&#28216;&#25103;&#24320;&#22987;&#21069;&#21363;&#30830;&#23450;&#20102;&#36172;&#21338;&#27169;&#22411;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#36125;&#21494;&#26031;&#35774;&#32622;&#20013;&#65292;&#20256;&#32479;&#30340;&#22312;&#39057;&#29575;&#35774;&#23450;&#20013;&#30740;&#31350;&#30340;FC-BAI&#31639;&#27861;&#65288;&#22914;track-and-stop&#21644;top-two&#31639;&#27861;&#65289;&#20250;&#23548;&#33268;&#20219;&#24847;&#27425;&#20248;&#30340;&#34920;&#29616;&#12290;&#25105;&#20204;&#21516;&#26102;&#35777;&#26126;&#20102;&#22312;&#36125;&#21494;&#26031;&#35774;&#32622;&#19979;&#39044;&#26399;&#26679;&#26412;&#25968;&#30340;&#19979;&#38480;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#36830;&#32493;&#25490;&#38500;&#30340;&#21464;&#31181;&#65292;&#20854;&#24615;&#33021;&#19982;&#19979;&#38480;&#30456;&#21305;&#37197;&#65292;&#26368;&#22810;&#24046;&#19968;&#20010;&#23545;&#25968;&#22240;&#23376;&#12290;&#20223;&#30495;&#39564;&#35777;&#20102;&#29702;&#35770;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10429v1 Announce Type: cross  Abstract: We consider the fixed-confidence best arm identification (FC-BAI) problem in the Bayesian Setting. This problem aims to find the arm of the largest mean with a fixed confidence level when the bandit model has been sampled from the known prior. Most studies on the FC-BAI problem have been conducted in the frequentist setting, where the bandit model is predetermined before the game starts. We show that the traditional FC-BAI algorithms studied in the frequentist setting, such as track-and-stop and top-two algorithms, result in arbitrary suboptimal performances in the Bayesian setting. We also prove a lower bound of the expected number of samples in the Bayesian setting and introduce a variant of successive elimination that has a matching performance with the lower bound up to a logarithmic factor. Simulations verify the theoretical results.
&lt;/p&gt;</description></item><item><title>&#20102;&#35299;&#31070;&#32463;&#32593;&#32476;&#20174;&#36755;&#20837;-&#26631;&#31614;&#23545;&#20013;&#25552;&#21462;&#32479;&#35745;&#20449;&#24687;&#30340;&#26426;&#21046;&#26159;&#30417;&#30563;&#23398;&#20064;&#20013;&#26368;&#37325;&#35201;&#30340;&#26410;&#35299;&#20915;&#38382;&#39064;&#20043;&#19968;&#12290;&#21069;&#20154;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#65292;&#26435;&#37325;&#30340;&#26684;&#25289;&#22982;&#30697;&#38453;&#19982;&#27169;&#22411;&#30340;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#25104;&#27491;&#27604;&#65292;&#36825;&#34987;&#31216;&#20026;&#31070;&#32463;&#29305;&#24449;&#20998;&#26512;&#65288;NFA&#65289;&#12290;&#26412;&#30740;&#31350;&#35299;&#37322;&#20102;&#36825;&#31181;&#30456;&#20851;&#24615;&#30340;&#20986;&#29616;&#65292;&#24182;&#21457;&#29616;NFA&#31561;&#20215;&#20110;&#26435;&#37325;&#30697;&#38453;&#30340;&#24038;&#22855;&#24322;&#32467;&#26500;&#19982;&#19982;&#36825;&#20123;&#26435;&#37325;&#30456;&#20851;&#30340;&#32463;&#39564;&#31070;&#32463;&#20999;&#32447;&#26680;&#30340;&#26174;&#33879;&#25104;&#20998;&#20043;&#38388;&#30340;&#23545;&#40784;&#12290;&#22312;&#26089;&#26399;&#35757;&#32451;&#38454;&#27573;&#65292;&#21487;&#20197;&#36890;&#36807;&#35299;&#26512;&#30340;&#26041;&#24335;&#39044;&#27979;NFA&#30340;&#21457;&#23637;&#36895;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.05271</link><description>&lt;p&gt;
&#26799;&#24230;&#19979;&#38477;&#24341;&#21457;&#20102;&#28145;&#24230;&#38750;&#32447;&#24615;&#32593;&#32476;&#26435;&#37325;&#19982;&#32463;&#39564;NTK&#20043;&#38388;&#30340;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Gradient descent induces alignment between weights and the empirical NTK for deep non-linear networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05271
&lt;/p&gt;
&lt;p&gt;
&#20102;&#35299;&#31070;&#32463;&#32593;&#32476;&#20174;&#36755;&#20837;-&#26631;&#31614;&#23545;&#20013;&#25552;&#21462;&#32479;&#35745;&#20449;&#24687;&#30340;&#26426;&#21046;&#26159;&#30417;&#30563;&#23398;&#20064;&#20013;&#26368;&#37325;&#35201;&#30340;&#26410;&#35299;&#20915;&#38382;&#39064;&#20043;&#19968;&#12290;&#21069;&#20154;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#65292;&#26435;&#37325;&#30340;&#26684;&#25289;&#22982;&#30697;&#38453;&#19982;&#27169;&#22411;&#30340;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#25104;&#27491;&#27604;&#65292;&#36825;&#34987;&#31216;&#20026;&#31070;&#32463;&#29305;&#24449;&#20998;&#26512;&#65288;NFA&#65289;&#12290;&#26412;&#30740;&#31350;&#35299;&#37322;&#20102;&#36825;&#31181;&#30456;&#20851;&#24615;&#30340;&#20986;&#29616;&#65292;&#24182;&#21457;&#29616;NFA&#31561;&#20215;&#20110;&#26435;&#37325;&#30697;&#38453;&#30340;&#24038;&#22855;&#24322;&#32467;&#26500;&#19982;&#19982;&#36825;&#20123;&#26435;&#37325;&#30456;&#20851;&#30340;&#32463;&#39564;&#31070;&#32463;&#20999;&#32447;&#26680;&#30340;&#26174;&#33879;&#25104;&#20998;&#20043;&#38388;&#30340;&#23545;&#40784;&#12290;&#22312;&#26089;&#26399;&#35757;&#32451;&#38454;&#27573;&#65292;&#21487;&#20197;&#36890;&#36807;&#35299;&#26512;&#30340;&#26041;&#24335;&#39044;&#27979;NFA&#30340;&#21457;&#23637;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#31070;&#32463;&#32593;&#32476;&#20174;&#36755;&#20837;-&#26631;&#31614;&#23545;&#20013;&#25552;&#21462;&#32479;&#35745;&#20449;&#24687;&#30340;&#26426;&#21046;&#26159;&#30417;&#30563;&#23398;&#20064;&#20013;&#26368;&#37325;&#35201;&#30340;&#26410;&#35299;&#20915;&#38382;&#39064;&#20043;&#19968;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#30830;&#23450;&#65292;&#22312;&#19968;&#33324;&#32467;&#26500;&#30340;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#26435;&#37325;&#30340;&#26684;&#25289;&#22982;&#30697;&#38453;&#19982;&#27169;&#22411;&#30340;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#25104;&#27491;&#27604;&#65292;&#36825;&#20010;&#35828;&#27861;&#34987;&#31216;&#20026;&#31070;&#32463;&#29305;&#24449;&#20998;&#26512;&#65288;NFA&#65289;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#25968;&#37327;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#22914;&#20309;&#30456;&#20851;&#23578;&#19981;&#28165;&#26970;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35299;&#37322;&#20102;&#36825;&#31181;&#30456;&#20851;&#24615;&#30340;&#20986;&#29616;&#12290;&#25105;&#20204;&#21457;&#29616;NFA&#31561;&#20215;&#20110;&#26435;&#37325;&#30697;&#38453;&#30340;&#24038;&#22855;&#24322;&#32467;&#26500;&#19982;&#19982;&#36825;&#20123;&#26435;&#37325;&#30456;&#20851;&#30340;&#32463;&#39564;&#31070;&#32463;&#20999;&#32447;&#26680;&#30340;&#26174;&#33879;&#25104;&#20998;&#20043;&#38388;&#30340;&#23545;&#40784;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20808;&#21069;&#30740;&#31350;&#20013;&#24341;&#20837;&#30340;NFA&#26159;&#30001;&#38548;&#31163;&#36825;&#31181;&#23545;&#40784;&#30340;&#20013;&#24515;&#21270;NFA&#39537;&#21160;&#30340;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22312;&#26089;&#26399;&#35757;&#32451;&#38454;&#27573;&#65292;&#21487;&#20197;&#36890;&#36807;&#35299;&#26512;&#30340;&#26041;&#24335;&#39044;&#27979;NFA&#30340;&#21457;&#23637;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding the mechanisms through which neural networks extract statistics from input-label pairs is one of the most important unsolved problems in supervised learning. Prior works have identified that the gram matrices of the weights in trained neural networks of general architectures are proportional to the average gradient outer product of the model, in a statement known as the Neural Feature Ansatz (NFA). However, the reason these quantities become correlated during training is poorly understood. In this work, we explain the emergence of this correlation. We identify that the NFA is equivalent to alignment between the left singular structure of the weight matrices and a significant component of the empirical neural tangent kernels associated with those weights. We establish that the NFA introduced in prior works is driven by a centered NFA that isolates this alignment. We show that the speed of NFA development can be predicted analytically at early training times in terms of sim
&lt;/p&gt;</description></item><item><title>&#22312;&#20559;&#31163;&#39640;&#26031;&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#20013;&#65292;&#26412;&#25991;&#36890;&#36807;&#26500;&#36896;Voronoi-based&#25439;&#22833;&#20989;&#25968;&#26469;&#35299;&#20915;&#21442;&#25968;&#20272;&#35745;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.05220</link><description>&lt;p&gt;
&#20851;&#20110;&#20559;&#31163;&#39640;&#26031;&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#21442;&#25968;&#20272;&#35745;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Parameter Estimation in Deviated Gaussian Mixture of Experts
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05220
&lt;/p&gt;
&lt;p&gt;
&#22312;&#20559;&#31163;&#39640;&#26031;&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#20013;&#65292;&#26412;&#25991;&#36890;&#36807;&#26500;&#36896;Voronoi-based&#25439;&#22833;&#20989;&#25968;&#26469;&#35299;&#20915;&#21442;&#25968;&#20272;&#35745;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#22312;&#20559;&#31163;&#39640;&#26031;&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#20013;&#30340;&#21442;&#25968;&#20272;&#35745;&#38382;&#39064;&#65292;&#20854;&#20013;&#25968;&#25454;&#30001;$(1 - \lambda^{\ast}) g_0(Y| X)+ \lambda^{\ast} \sum_{i = 1}^{k_{\ast}} p_{i}^{\ast} f(Y|(a_{i}^{\ast})^{\top}X+b_i^{\ast},\sigma_{i}^{\ast})$&#29983;&#25104;&#65292;&#20854;&#20013;$X, Y$&#20998;&#21035;&#26159;&#21327;&#21464;&#37327;&#21521;&#37327;&#21644;&#21709;&#24212;&#21464;&#37327;&#65292;$g_{0}(Y|X)$&#26159;&#24050;&#30693;&#20989;&#25968;&#65292;$\lambda^{\ast} \in [0, 1]$&#26159;&#30495;&#23454;&#20294;&#26410;&#30693;&#30340;&#28151;&#21512;&#27604;&#20363;&#65292;$(p_{i}^{\ast}, a_{i}^{\ast}, b_{i}^{\ast}, \sigma_{i}^{\ast})$&#23545;&#20110;$1 \leq i \leq k^{\ast}$&#26159;&#39640;&#26031;&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#30340;&#26410;&#30693;&#21442;&#25968;&#12290;&#35813;&#38382;&#39064;&#28304;&#33258;&#20110;&#25311;&#21512;&#20248;&#24230;&#26816;&#39564;&#65292;&#24403;&#25105;&#20204;&#24076;&#26395;&#26816;&#39564;&#25968;&#25454;&#26159;&#21542;&#30001;$g_{0}(Y|X)$&#65288;&#38646;&#20551;&#35774;&#65289;&#29983;&#25104;&#65292;&#36824;&#26159;&#30001;&#25972;&#20010;&#28151;&#21512;&#65288;&#22791;&#25321;&#20551;&#35774;&#65289;&#29983;&#25104;&#12290;&#22522;&#20110;&#19987;&#23478;&#20989;&#25968;&#30340;&#20195;&#25968;&#32467;&#26500;&#21644;$g_0$&#19982;&#28151;&#21512;&#37096;&#20998;&#30340;&#21487;&#21306;&#20998;&#24615;&#65292;&#25105;&#20204;&#26500;&#36896;&#20102;&#26032;&#30340;&#22522;&#20110;Voronoi&#30340;&#25439;&#22833;&#20989;&#25968;&#26469;&#25429;&#25417;c
&lt;/p&gt;
&lt;p&gt;
We consider the parameter estimation problem in the deviated Gaussian mixture of experts in which the data are generated from $(1 - \lambda^{\ast}) g_0(Y| X)+ \lambda^{\ast} \sum_{i = 1}^{k_{\ast}} p_{i}^{\ast} f(Y|(a_{i}^{\ast})^{\top}X+b_i^{\ast},\sigma_{i}^{\ast})$, where $X, Y$ are respectively a covariate vector and a response variable, $g_{0}(Y|X)$ is a known function, $\lambda^{\ast} \in [0, 1]$ is true but unknown mixing proportion, and $(p_{i}^{\ast}, a_{i}^{\ast}, b_{i}^{\ast}, \sigma_{i}^{\ast})$ for $1 \leq i \leq k^{\ast}$ are unknown parameters of the Gaussian mixture of experts. This problem arises from the goodness-of-fit test when we would like to test whether the data are generated from $g_{0}(Y|X)$ (null hypothesis) or they are generated from the whole mixture (alternative hypothesis). Based on the algebraic structure of the expert functions and the distinguishability between $g_0$ and the mixture part, we construct novel Voronoi-based loss functions to capture the c
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#30830;&#23450;&#24615;MoE&#27169;&#22411;&#19979;&#20351;&#29992;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#30340;&#24615;&#33021;&#65292;&#24182;&#24314;&#31435;&#20102;&#24378;&#21487;&#35782;&#21035;&#24615;&#26465;&#20214;&#26469;&#25551;&#36848;&#19981;&#21516;&#31867;&#22411;&#19987;&#23478;&#20989;&#25968;&#30340;&#25910;&#25947;&#34892;&#20026;&#12290;</title><link>https://arxiv.org/abs/2402.02952</link><description>&lt;p&gt;
&#20851;&#20110;Softmax Gating&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#20013;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Least Squares Estimation in Softmax Gating Mixture of Experts
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02952
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#30830;&#23450;&#24615;MoE&#27169;&#22411;&#19979;&#20351;&#29992;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#30340;&#24615;&#33021;&#65292;&#24182;&#24314;&#31435;&#20102;&#24378;&#21487;&#35782;&#21035;&#24615;&#26465;&#20214;&#26469;&#25551;&#36848;&#19981;&#21516;&#31867;&#22411;&#19987;&#23478;&#20989;&#25968;&#30340;&#25910;&#25947;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19987;&#23478;&#27169;&#22411;&#26159;&#19968;&#31181;&#32479;&#35745;&#26426;&#22120;&#23398;&#20064;&#35774;&#35745;&#65292;&#20351;&#29992;Softmax Gating&#20989;&#25968;&#32858;&#21512;&#22810;&#20010;&#19987;&#23478;&#32593;&#32476;&#65292;&#20197;&#24418;&#25104;&#19968;&#20010;&#26356;&#22797;&#26434;&#21644;&#34920;&#36798;&#21147;&#26356;&#24378;&#30340;&#27169;&#22411;&#12290;&#23613;&#31649;&#30001;&#20110;&#21487;&#25193;&#23637;&#24615;&#32780;&#22312;&#22810;&#20010;&#24212;&#29992;&#39046;&#22495;&#20013;&#24191;&#27867;&#20351;&#29992;&#65292;&#20294;MoE&#27169;&#22411;&#30340;&#25968;&#23398;&#21644;&#32479;&#35745;&#24615;&#36136;&#22797;&#26434;&#19988;&#38590;&#20197;&#20998;&#26512;&#12290;&#22240;&#27492;&#65292;&#20197;&#21069;&#30340;&#29702;&#35770;&#24037;&#20316;&#20027;&#35201;&#38598;&#20013;&#22312;&#27010;&#29575;MoE&#27169;&#22411;&#19978;&#65292;&#36825;&#20123;&#27169;&#22411;&#20551;&#35774;&#25968;&#25454;&#26159;&#30001;&#39640;&#26031;MoE&#27169;&#22411;&#29983;&#25104;&#30340;&#65292;&#36825;&#22312;&#23454;&#36341;&#20013;&#26159;&#19981;&#20999;&#23454;&#38469;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#30830;&#23450;&#24615;MoE&#27169;&#22411;&#19979;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#65288;LSE&#65289;&#30340;&#24615;&#33021;&#65292;&#22312;&#35813;&#27169;&#22411;&#20013;&#65292;&#25968;&#25454;&#26681;&#25454;&#22238;&#24402;&#27169;&#22411;&#36827;&#34892;&#37319;&#26679;&#65292;&#36825;&#26159;&#19968;&#20010;&#23578;&#26410;&#34987;&#20805;&#20998;&#25506;&#32034;&#30340;&#35774;&#32622;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#31216;&#20026;&#24378;&#21487;&#35782;&#21035;&#24615;&#30340;&#26465;&#20214;&#65292;&#20197;&#34920;&#24449;&#19981;&#21516;&#31867;&#22411;&#19987;&#23478;&#20989;&#25968;&#30340;&#25910;&#25947;&#34892;&#20026;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#24378;&#21487;&#35782;&#21035;&#19987;&#23478;&#30340;&#20272;&#35745;&#36895;&#24230;&#65292;&#21363;
&lt;/p&gt;
&lt;p&gt;
Mixture of experts (MoE) model is a statistical machine learning design that aggregates multiple expert networks using a softmax gating function in order to form a more intricate and expressive model. Despite being commonly used in several applications owing to their scalability, the mathematical and statistical properties of MoE models are complex and difficult to analyze. As a result, previous theoretical works have primarily focused on probabilistic MoE models by imposing the impractical assumption that the data are generated from a Gaussian MoE model. In this work, we investigate the performance of the least squares estimators (LSE) under a deterministic MoE model where the data are sampled according to a regression model, a setting that has remained largely unexplored. We establish a condition called strong identifiability to characterize the convergence behavior of various types of expert functions. We demonstrate that the rates for estimating strongly identifiable experts, namel
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28201;&#24230;&#23545;Softmax&#39640;&#26031;&#28151;&#21512;&#19987;&#23478;&#30340;&#37319;&#26679;&#25928;&#29575;&#30340;&#24433;&#21709;&#65292;&#35777;&#26126;&#20102;&#30001;&#20110;&#28201;&#24230;&#21644;&#20854;&#20182;&#27169;&#22411;&#21442;&#25968;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#21442;&#25968;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#24230;&#36739;&#24930;&#65292;&#24182;&#19988;&#21487;&#33021;&#24456;&#24930;&#12290;</title><link>http://arxiv.org/abs/2401.13875</link><description>&lt;p&gt;
&#28201;&#24230;&#23545;Softmax&#39640;&#26031;&#28151;&#21512;&#19987;&#23478;&#26159;&#21542;&#20855;&#26377;&#37319;&#26679;&#25928;&#29575;&#65311;
&lt;/p&gt;
&lt;p&gt;
Is Temperature Sample Efficient for Softmax Gaussian Mixture of Experts?. (arXiv:2401.13875v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13875
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28201;&#24230;&#23545;Softmax&#39640;&#26031;&#28151;&#21512;&#19987;&#23478;&#30340;&#37319;&#26679;&#25928;&#29575;&#30340;&#24433;&#21709;&#65292;&#35777;&#26126;&#20102;&#30001;&#20110;&#28201;&#24230;&#21644;&#20854;&#20182;&#27169;&#22411;&#21442;&#25968;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#21442;&#25968;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#24230;&#36739;&#24930;&#65292;&#24182;&#19988;&#21487;&#33021;&#24456;&#24930;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#23494;&#38598;-&#31232;&#30095;&#38376;&#25511;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;&#65288;MoE&#65289;&#24050;&#25104;&#20026;&#24191;&#20026;&#20351;&#29992;&#30340;&#31232;&#30095;MoE&#30340;&#26377;&#25928;&#26367;&#20195;&#26041;&#26696;&#12290;&#19982;&#21518;&#32773;&#27169;&#22411;&#20013;&#22266;&#23450;&#28608;&#27963;&#30340;&#19987;&#23478;&#25968;&#37327;&#19981;&#21516;&#65292;&#21069;&#32773;&#27169;&#22411;&#21033;&#29992;&#28201;&#24230;&#26469;&#25511;&#21046;softmax&#26435;&#37325;&#20998;&#24067;&#21644;MoE&#30340;&#31232;&#30095;&#24615;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#31283;&#23450;&#19987;&#23478;&#30340;&#19987;&#19994;&#21270;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#20197;&#21069;&#26377;&#23581;&#35797;&#20174;&#29702;&#35770;&#19978;&#29702;&#35299;&#31232;&#30095;MoE&#30340;&#26041;&#27861;&#65292;&#23545;&#20110;&#23494;&#38598;&#21040;&#31232;&#30095;&#38376;&#25511;MoE&#30340;&#20840;&#38754;&#20998;&#26512;&#20173;&#28982;&#22256;&#38590;&#37325;&#37325;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#26088;&#22312;&#25506;&#35752;&#23494;&#38598;&#21040;&#31232;&#30095;&#38376;&#25511;&#23545;Gaussian MoE&#19979;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#35777;&#26126;&#30001;&#20110;&#28201;&#24230;&#21644;&#20854;&#20182;&#27169;&#22411;&#21442;&#25968;&#20043;&#38388;&#36890;&#36807;&#19968;&#20123;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#21442;&#25968;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#24230;&#27604;&#20219;&#20309;&#22810;&#39033;&#24335;&#36895;&#29575;&#37117;&#35201;&#24930;&#65292;&#24182;&#19988;&#21487;&#33021;&#24930;&#21040;$\mathcal{
&lt;/p&gt;
&lt;p&gt;
Dense-to-sparse gating mixture of experts (MoE) has recently become an effective alternative to a well-known sparse MoE. Rather than fixing the number of activated experts as in the latter model, which could limit the investigation of potential experts, the former model utilizes the temperature to control the softmax weight distribution and the sparsity of the MoE during training in order to stabilize the expert specialization. Nevertheless, while there are previous attempts to theoretically comprehend the sparse MoE, a comprehensive analysis of the dense-to-sparse gating MoE has remained elusive. Therefore, we aim to explore the impacts of the dense-to-sparse gate on the maximum likelihood estimation under the Gaussian MoE in this paper. We demonstrate that due to interactions between the temperature and other model parameters via some partial differential equations, the convergence rates of parameter estimations are slower than any polynomial rates, and could be as slow as $\mathcal{
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#25968;&#38454;&#25193;&#25955;&#27169;&#22411;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#20854;&#20013;&#36890;&#36807;&#23558;&#20998;&#25968;&#24067;&#26391;&#36816;&#21160;&#34920;&#31034;&#20026;&#22885;&#24681;&#26031;&#22374;-&#20044;&#20262;&#36125;&#20811;&#36807;&#31243;&#30340;&#38543;&#26426;&#31215;&#20998;&#65292;&#23454;&#29616;&#20102;&#39537;&#21160;&#22122;&#22768;&#25910;&#25947;&#21040;&#38750;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#30340;&#25928;&#26524;&#12290;&#36825;&#26159;&#31532;&#19968;&#20010;&#22312;&#20855;&#26377;&#26080;&#38480;&#20108;&#27425;&#21464;&#24046;&#30340;&#38543;&#26426;&#36807;&#31243;&#19978;&#26500;&#24314;&#29983;&#25104;&#27169;&#22411;&#30340;&#23581;&#35797;&#12290;</title><link>http://arxiv.org/abs/2310.17638</link><description>&lt;p&gt;
&#29983;&#25104;&#20998;&#25968;&#38454;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Generative Fractional Diffusion Models. (arXiv:2310.17638v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17638
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#25968;&#38454;&#25193;&#25955;&#27169;&#22411;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#20854;&#20013;&#36890;&#36807;&#23558;&#20998;&#25968;&#24067;&#26391;&#36816;&#21160;&#34920;&#31034;&#20026;&#22885;&#24681;&#26031;&#22374;-&#20044;&#20262;&#36125;&#20811;&#36807;&#31243;&#30340;&#38543;&#26426;&#31215;&#20998;&#65292;&#23454;&#29616;&#20102;&#39537;&#21160;&#22122;&#22768;&#25910;&#25947;&#21040;&#38750;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#30340;&#25928;&#26524;&#12290;&#36825;&#26159;&#31532;&#19968;&#20010;&#22312;&#20855;&#26377;&#26080;&#38480;&#20108;&#27425;&#21464;&#24046;&#30340;&#38543;&#26426;&#36807;&#31243;&#19978;&#26500;&#24314;&#29983;&#25104;&#27169;&#22411;&#30340;&#23581;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23558;&#22522;&#20110;&#20998;&#25968;&#24067;&#26391;&#36816;&#21160;&#65288;FBM&#65289;&#30340;&#36830;&#32493;&#26102;&#38388;&#26694;&#26550;&#25512;&#24191;&#21040;&#22522;&#20110;&#20998;&#25968;&#24067;&#26391;&#36816;&#21160;&#30340;&#36817;&#20284;&#24418;&#24335;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;FBM&#34920;&#31034;&#20026;&#23478;&#26063;&#22885;&#24681;&#26031;&#22374;-&#20044;&#20262;&#36125;&#20811;&#36807;&#31243;&#30340;&#38543;&#26426;&#31215;&#20998;&#65292;&#25512;&#23548;&#20986;&#36830;&#32493;&#20877;&#21442;&#25968;&#21270;&#25216;&#24039;&#21644;&#36870;&#26102;&#27169;&#22411;&#65292;&#23450;&#20041;&#20102;&#20855;&#26377;&#39537;&#21160;&#22122;&#22768;&#25910;&#25947;&#21040;&#26080;&#38480;&#20108;&#27425;&#21464;&#24046;&#30340;&#38750;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#30340;&#29983;&#25104;&#20998;&#25968;&#38454;&#25193;&#25955;&#27169;&#22411;&#65288;GFDM&#65289;&#12290;FBM&#30340;&#36203;&#26031;&#29305;&#25351;&#25968;$H \in (0,1)$ &#21487;&#20197;&#25511;&#21046;&#36335;&#24452;&#21464;&#25442;&#20998;&#24067;&#30340;&#31895;&#31961;&#24230;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#31532;&#19968;&#27425;&#23581;&#35797;&#22312;&#20855;&#26377;&#26080;&#38480;&#20108;&#27425;&#21464;&#24046;&#30340;&#38543;&#26426;&#36807;&#31243;&#19978;&#24314;&#31435;&#29983;&#25104;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
We generalize the continuous time framework for score-based generative models from an underlying Brownian motion (BM) to an approximation of fractional Brownian motion (FBM). We derive a continuous reparameterization trick and the reverse time model by representing FBM as a stochastic integral over a family of Ornstein-Uhlenbeck processes to define generative fractional diffusion models (GFDM) with driving noise converging to a non-Markovian process of infinite quadratic variation. The Hurst index $H\in(0,1)$ of FBM enables control of the roughness of the distribution transforming path. To the best of our knowledge, this is the first attempt to build a generative model upon a stochastic process with infinite quadratic variation.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#29702;&#35770;&#65292;&#29992;&#20110;&#30740;&#31350;Softmax Gating Multinomial Logistic Mixture of Experts&#27169;&#22411;&#12290;&#36890;&#36807;&#24314;&#31435;&#27169;&#22411;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#25581;&#31034;&#20102;softmax gating&#21644;&#19987;&#23478;&#20989;&#25968;&#20043;&#38388;&#23384;&#22312;&#30340;&#20114;&#20316;&#29992;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#25913;&#21518;&#30340;softmax gating&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2310.14188</link><description>&lt;p&gt;
&#19968;&#31181;Softmax Gating Multinomial Logistic Mixture of Experts&#30340;&#36890;&#29992;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
A General Theory for Softmax Gating Multinomial Logistic Mixture of Experts. (arXiv:2310.14188v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14188
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#29702;&#35770;&#65292;&#29992;&#20110;&#30740;&#31350;Softmax Gating Multinomial Logistic Mixture of Experts&#27169;&#22411;&#12290;&#36890;&#36807;&#24314;&#31435;&#27169;&#22411;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#25581;&#31034;&#20102;softmax gating&#21644;&#19987;&#23478;&#20989;&#25968;&#20043;&#38388;&#23384;&#22312;&#30340;&#20114;&#20316;&#29992;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#25913;&#21518;&#30340;softmax gating&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Mixture-of-experts&#65288;MoE&#65289;&#27169;&#22411;&#36890;&#36807;&#38376;&#25511;&#20989;&#25968;&#23558;&#22810;&#20010;&#23376;&#27169;&#22411;&#30340;&#33021;&#21147;&#32467;&#21512;&#36215;&#26469;&#65292;&#22312;&#35768;&#22810;&#22238;&#24402;&#21644;&#20998;&#31867;&#24212;&#29992;&#20013;&#23454;&#29616;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;&#20174;&#29702;&#35770;&#19978;&#35762;&#65292;&#34429;&#28982;&#20043;&#21069;&#24050;&#32463;&#23581;&#35797;&#36890;&#36807;&#39640;&#26031;MoE&#27169;&#22411;&#20013;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#26469;&#29702;&#35299;&#35813;&#27169;&#22411;&#22312;&#22238;&#24402;&#35774;&#32622;&#19979;&#30340;&#34892;&#20026;&#65292;&#20294;&#22312;&#20998;&#31867;&#38382;&#39064;&#30340;&#35774;&#32622;&#19979;&#32570;&#20047;&#30456;&#20851;&#20998;&#26512;&#12290;&#25105;&#20204;&#36890;&#36807;&#24314;&#31435;softmax gating multinomial logistic MoE&#27169;&#22411;&#30340;&#23494;&#24230;&#20272;&#35745;&#21644;&#21442;&#25968;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#24230;&#26469;&#24357;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#24403;&#37096;&#20998;&#19987;&#23478;&#21442;&#25968;&#28040;&#22833;&#26102;&#65292;&#30001;&#20110;softmax gating&#21644;&#19987;&#23478;&#20989;&#25968;&#20043;&#38388;&#23384;&#22312;&#22266;&#26377;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#20114;&#20316;&#29992;&#65292;&#36825;&#20123;&#25910;&#25947;&#36895;&#24230;&#27604;&#22810;&#39033;&#24335;&#36895;&#24230;&#26356;&#24930;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#20462;&#25913;softmax gating&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mixture-of-experts (MoE) model incorporates the power of multiple submodels via gating functions to achieve greater performance in numerous regression and classification applications. From a theoretical perspective, while there have been previous attempts to comprehend the behavior of that model under the regression settings through the convergence analysis of maximum likelihood estimation in the Gaussian MoE model, such analysis under the setting of a classification problem has remained missing in the literature. We close this gap by establishing the convergence rates of density estimation and parameter estimation in the softmax gating multinomial logistic MoE model. Notably, when part of the expert parameters vanish, these rates are shown to be slower than polynomial rates owing to an inherent interaction between the softmax gating and expert functions via partial differential equations. To address this issue, we propose using a novel class of modified softmax gating functions which 
&lt;/p&gt;</description></item><item><title>&#22312;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20197;&#22266;&#23450;&#32622;&#20449;&#24230;&#36827;&#34892;&#26368;&#20248;&#33218;&#35782;&#21035;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#26469;&#35782;&#21035;&#20855;&#26377;&#26368;&#22823;&#24179;&#22343;&#20540;&#30340;&#33218;&#65292;&#21516;&#26102;&#38480;&#21046;&#20102;&#20915;&#31574;&#38169;&#35823;&#30340;&#27010;&#29575;&#65292;&#24182;&#24314;&#31435;&#20102;&#20572;&#27490;&#26102;&#38388;&#22686;&#38271;&#29575;&#30340;&#19979;&#30028;&#12290;</title><link>http://arxiv.org/abs/2310.13393</link><description>&lt;p&gt;
&#22312;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#20197;&#22266;&#23450;&#32622;&#20449;&#24230;&#36827;&#34892;&#26368;&#20248;&#33218;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Optimal Best Arm Identification with Fixed Confidence in Restless Bandits. (arXiv:2310.13393v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13393
&lt;/p&gt;
&lt;p&gt;
&#22312;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20197;&#22266;&#23450;&#32622;&#20449;&#24230;&#36827;&#34892;&#26368;&#20248;&#33218;&#35782;&#21035;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#26469;&#35782;&#21035;&#20855;&#26377;&#26368;&#22823;&#24179;&#22343;&#20540;&#30340;&#33218;&#65292;&#21516;&#26102;&#38480;&#21046;&#20102;&#20915;&#31574;&#38169;&#35823;&#30340;&#27010;&#29575;&#65292;&#24182;&#24314;&#31435;&#20102;&#20572;&#27490;&#26102;&#38388;&#22686;&#38271;&#29575;&#30340;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#20855;&#26377;&#26377;&#38480;&#25968;&#30446;&#33218;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#20197;&#19981;&#26029;&#21464;&#21270;&#30340;&#24418;&#24335;&#36827;&#34892;&#26368;&#20248;&#33218;&#35782;&#21035;&#12290;&#27599;&#20010;&#33218;&#20135;&#29983;&#30340;&#31163;&#25955;&#26102;&#38388;&#25968;&#25454;&#24418;&#25104;&#20102;&#19968;&#20010;&#21462;&#20540;&#22312;&#20849;&#21516;&#12289;&#26377;&#38480;&#29366;&#24577;&#31354;&#38388;&#20013;&#30340;&#21516;&#36136;&#39532;&#23572;&#21487;&#22827;&#38142;&#12290;&#27599;&#20010;&#33218;&#30340;&#29366;&#24577;&#36716;&#31227;&#30001;&#19968;&#20010;&#36981;&#24490;&#21333;&#21442;&#25968;&#25351;&#25968;&#26063;&#30340;&#36716;&#31227;&#27010;&#29575;&#30697;&#38453;&#65288;TPM&#65289;&#25429;&#33719;&#12290;&#27599;&#20010;&#33218;&#30340;TPM&#30340;&#23454;&#20540;&#21442;&#25968;&#26159;&#26410;&#30693;&#30340;&#65292;&#23646;&#20110;&#32473;&#23450;&#31354;&#38388;&#12290;&#32473;&#23450;&#22312;&#33218;&#30340;&#20849;&#21516;&#29366;&#24577;&#31354;&#38388;&#19978;&#23450;&#20041;&#30340;&#20989;&#25968;f&#65292;&#30446;&#26631;&#26159;&#22312;&#26679;&#26412;&#25968;&#26368;&#23569;&#30340;&#24773;&#20917;&#19979;&#35782;&#21035;&#26368;&#20248;&#33218;&#65292;&#21363;&#22312;&#35813;&#33218;&#30340;&#31283;&#24577;&#20998;&#24067;&#19979;&#35780;&#20272;f&#30340;&#24179;&#22343;&#20540;&#26368;&#22823;&#30340;&#33218;&#65292;&#21516;&#26102;&#28385;&#36275;&#23545;&#20915;&#31574;&#38169;&#35823;&#27010;&#29575;&#65288;&#21363;&#22266;&#23450;&#32622;&#20449;&#24230;&#21306;&#38388;&#65289;&#30340;&#19978;&#30028;&#12290;&#22312;&#28176;&#36827;&#24615;&#30340;&#35823;&#24046;&#27010;&#29575;&#36235;&#20110;&#38646;&#30340;&#24773;&#20917;&#19979;&#65292;&#24314;&#31435;&#20102;&#26399;&#26395;&#20572;&#27490;&#26102;&#38388;&#22686;&#38271;&#29575;&#30340;&#19979;&#30028;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26368;&#20248;&#33218;&#35782;&#21035;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study best arm identification in a restless multi-armed bandit setting with finitely many arms. The discrete-time data generated by each arm forms a homogeneous Markov chain taking values in a common, finite state space. The state transitions in each arm are captured by an ergodic transition probability matrix (TPM) that is a member of a single-parameter exponential family of TPMs. The real-valued parameters of the arm TPMs are unknown and belong to a given space. Given a function $f$ defined on the common state space of the arms, the goal is to identify the best arm -- the arm with the largest average value of $f$ evaluated under the arm's stationary distribution -- with the fewest number of samples, subject to an upper bound on the decision's error probability (i.e., the fixed-confidence regime). A lower bound on the growth rate of the expected stopping time is established in the asymptote of a vanishing error probability. Furthermore, a policy for best arm identification is propo
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#21457;&#29616;&#28151;&#21512;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25512;&#26029;&#28508;&#22312;&#22240;&#26524;&#27169;&#22411;&#20197;&#21450;&#27599;&#20010;&#26679;&#26412;&#23646;&#20110;&#29305;&#23450;&#28151;&#21512;&#25104;&#20998;&#30340;&#27010;&#29575;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#22240;&#26524;&#21457;&#29616;&#20219;&#21153;&#20013;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.06312</link><description>&lt;p&gt;
&#20174;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#21457;&#29616;&#28151;&#21512;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Discovering Mixtures of Structural Causal Models from Time Series Data. (arXiv:2310.06312v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06312
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#21457;&#29616;&#28151;&#21512;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25512;&#26029;&#28508;&#22312;&#22240;&#26524;&#27169;&#22411;&#20197;&#21450;&#27599;&#20010;&#26679;&#26412;&#23646;&#20110;&#29305;&#23450;&#28151;&#21512;&#25104;&#20998;&#30340;&#27010;&#29575;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#22240;&#26524;&#21457;&#29616;&#20219;&#21153;&#20013;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#37329;&#34701;&#12289;&#27668;&#20505;&#31185;&#23398;&#21644;&#31070;&#32463;&#31185;&#23398;&#31561;&#39046;&#22495;&#65292;&#20174;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#25512;&#26029;&#22240;&#26524;&#20851;&#31995;&#26159;&#19968;&#20010;&#24040;&#22823;&#30340;&#25361;&#25112;&#12290;&#23613;&#31649;&#29616;&#20195;&#25216;&#26415;&#21487;&#20197;&#22788;&#29702;&#21464;&#37327;&#20043;&#38388;&#30340;&#38750;&#32447;&#24615;&#20851;&#31995;&#21644;&#28789;&#27963;&#30340;&#22122;&#22768;&#20998;&#24067;&#65292;&#20294;&#23427;&#20204;&#20381;&#36182;&#20110;&#31616;&#21270;&#20551;&#35774;&#65292;&#21363;&#25968;&#25454;&#26469;&#33258;&#30456;&#21516;&#30340;&#28508;&#22312;&#22240;&#26524;&#27169;&#22411;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25918;&#26494;&#20102;&#36825;&#20010;&#20551;&#35774;&#65292;&#20174;&#26469;&#28304;&#20110;&#19981;&#21516;&#22240;&#26524;&#27169;&#22411;&#28151;&#21512;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#36827;&#34892;&#22240;&#26524;&#21457;&#29616;&#12290;&#25105;&#20204;&#25512;&#26029;&#20102;&#28508;&#22312;&#30340;&#32467;&#26500;&#24615;&#22240;&#26524;&#27169;&#22411;&#65292;&#20197;&#21450;&#27599;&#20010;&#26679;&#26412;&#23646;&#20110;&#29305;&#23450;&#28151;&#21512;&#25104;&#20998;&#30340;&#21518;&#39564;&#27010;&#29575;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#37319;&#29992;&#20102;&#19968;&#20010;&#31471;&#23545;&#31471;&#30340;&#35757;&#32451;&#36807;&#31243;&#65292;&#26368;&#22823;&#21270;&#20102;&#25968;&#25454;&#20284;&#28982;&#30340;&#35777;&#25454;&#19979;&#30028;&#12290;&#36890;&#36807;&#23545;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#30340;&#24191;&#27867;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#22240;&#26524;&#21457;&#29616;&#20219;&#21153;&#20013;&#36229;&#36234;&#20102;&#26368;&#20808;&#36827;&#30340;&#22522;&#20934;&#26041;&#27861;&#65292;&#23588;&#20854;&#26159;&#24403;&#25968;&#25454;&#26469;&#33258;&#19981;&#21516;&#30340;&#28508;&#22312;&#22240;&#26524;&#27169;&#22411;&#26102;&#12290;
&lt;/p&gt;
&lt;p&gt;
In fields such as finance, climate science, and neuroscience, inferring causal relationships from time series data poses a formidable challenge. While contemporary techniques can handle nonlinear relationships between variables and flexible noise distributions, they rely on the simplifying assumption that data originates from the same underlying causal model. In this work, we relax this assumption and perform causal discovery from time series data originating from mixtures of different causal models. We infer both the underlying structural causal models and the posterior probability for each sample belonging to a specific mixture component. Our approach employs an end-to-end training process that maximizes an evidence-lower bound for data likelihood. Through extensive experimentation on both synthetic and real-world datasets, we demonstrate that our method surpasses state-of-the-art benchmarks in causal discovery tasks, particularly when the data emanates from diverse underlying causal
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20445;&#25345;&#25490;&#24207;&#30340;&#24178;&#39044;&#20998;&#24067;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#26524;&#20844;&#24179;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#19968;&#20010;&#29702;&#24819;&#30340;&#19990;&#30028;&#20013;&#28040;&#38500;&#21463;&#20445;&#25252;&#23646;&#24615;&#23545;&#30446;&#26631;&#30340;&#22240;&#26524;&#24433;&#21709;&#26469;&#20943;&#23569;&#19981;&#20844;&#24179;&#12290;</title><link>http://arxiv.org/abs/2307.12797</link><description>&lt;p&gt;
&#36890;&#36807;&#20445;&#25345;&#25490;&#24207;&#30340;&#24178;&#39044;&#20998;&#24067;&#23454;&#29616;&#22240;&#26524;&#20844;&#24179;&#30340;&#26426;&#22120;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Causal Fair Machine Learning via Rank-Preserving Interventional Distributions. (arXiv:2307.12797v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12797
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20445;&#25345;&#25490;&#24207;&#30340;&#24178;&#39044;&#20998;&#24067;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#26524;&#20844;&#24179;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#19968;&#20010;&#29702;&#24819;&#30340;&#19990;&#30028;&#20013;&#28040;&#38500;&#21463;&#20445;&#25252;&#23646;&#24615;&#23545;&#30446;&#26631;&#30340;&#22240;&#26524;&#24433;&#21709;&#26469;&#20943;&#23569;&#19981;&#20844;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#26524;&#30456;&#21516;&#30340;&#20010;&#20307;&#24471;&#21040;&#30456;&#21516;&#30340;&#23545;&#24453;&#65292;&#32780;&#19981;&#21516;&#30340;&#20010;&#20307;&#24471;&#21040;&#19981;&#21516;&#30340;&#23545;&#24453;&#65292;&#37027;&#20040;&#19968;&#20010;&#20915;&#31574;&#34987;&#23450;&#20041;&#20026;&#20844;&#24179;&#30340;&#12290;&#26681;&#25454;&#36825;&#20010;&#23450;&#20041;&#65292;&#22312;&#35774;&#35745;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20197;&#20943;&#23569;&#33258;&#21160;&#20915;&#31574;&#31995;&#32479;&#20013;&#30340;&#19981;&#20844;&#24179;&#26102;&#65292;&#24517;&#39035;&#24341;&#20837;&#22240;&#26524;&#24605;&#32771;&#26469;&#24341;&#20837;&#21463;&#20445;&#25252;&#23646;&#24615;&#12290;&#26681;&#25454;&#26368;&#36817;&#30340;&#25552;&#35758;&#65292;&#25105;&#20204;&#23558;&#20010;&#20307;&#23450;&#20041;&#20026;&#22312;&#19968;&#20010;&#20551;&#35774;&#30340;&#12289;&#29702;&#24819;&#30340;&#65288;FiND&#65289;&#19990;&#30028;&#20013;&#26159;&#35268;&#33539;&#19978;&#30456;&#31561;&#30340;&#65292;&#36825;&#20010;&#19990;&#30028;&#20013;&#21463;&#20445;&#25252;&#23646;&#24615;&#23545;&#30446;&#26631;&#27809;&#26377;&#65288;&#30452;&#25509;&#25110;&#38388;&#25509;&#65289;&#30340;&#22240;&#26524;&#24433;&#21709;&#12290;&#25105;&#20204;&#25552;&#20986;&#20445;&#25345;&#25490;&#24207;&#30340;&#24178;&#39044;&#20998;&#24067;&#26469;&#23450;&#20041;&#36825;&#20010;FiND&#19990;&#30028;&#30340;&#20272;&#35745;&#30446;&#26631;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#20272;&#35745;&#26041;&#27861;&#12290;&#36890;&#36807;&#27169;&#25311;&#21644;&#23454;&#35777;&#25968;&#25454;&#30340;&#39564;&#35777;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#26041;&#27861;&#21644;&#29983;&#25104;&#27169;&#22411;&#30340;&#35780;&#20215;&#26631;&#20934;&#12290;&#36890;&#36807;&#36825;&#20123;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#24178;&#39044;&#26041;&#27861;&#26377;&#25928;&#22320;&#35782;&#21035;&#20986;&#26368;&#21463;&#27495;&#35270;&#30340;&#20010;&#20307;&#24182;&#20943;&#23569;&#19981;&#20844;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
A decision can be defined as fair if equal individuals are treated equally and unequals unequally. Adopting this definition, the task of designing machine learning models that mitigate unfairness in automated decision-making systems must include causal thinking when introducing protected attributes. Following a recent proposal, we define individuals as being normatively equal if they are equal in a fictitious, normatively desired (FiND) world, where the protected attribute has no (direct or indirect) causal effect on the target. We propose rank-preserving interventional distributions to define an estimand of this FiND world and a warping method for estimation. Evaluation criteria for both the method and resulting model are presented and validated through simulations and empirical data. With this, we show that our warping approach effectively identifies the most discriminated individuals and mitigates unfairness.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#33258;&#21160;&#20998;&#31867;&#21644;&#27169;&#25311;&#32676;&#20307;&#32769;&#40736;&#34892;&#20026;&#30340;&#24037;&#20855;&#65292;&#36890;&#36807;&#21333;&#19968;&#27169;&#22411;&#36328;&#31548;&#20351;&#29992;&#32622;&#25442;&#30697;&#38453;&#21305;&#37197;&#32769;&#40736;&#36523;&#20221;&#65292;&#22312;&#23478;&#40736;&#29615;&#22659;&#19979;&#30740;&#31350;&#32769;&#40736;&#21487;&#20197;&#25429;&#25417;&#21040;&#20010;&#20307;&#34892;&#20026;&#30340;&#26102;&#38388;&#22240;&#32032;&#65292;&#32780;&#19988;&#26080;&#38656;&#20154;&#20026;&#24178;&#39044;&#12290;</title><link>http://arxiv.org/abs/2306.03066</link><description>&lt;p&gt;
&#12298;&#40736;&#31867;&#19982;&#37197;&#20598;&#65306;&#21333;&#19968;&#27169;&#22411;&#33258;&#21160;&#23545;&#32676;&#20307;&#20013;&#30340;&#32769;&#40736;&#34892;&#20026;&#36827;&#34892;&#20998;&#31867;&#21644;&#24314;&#27169;&#36328;&#31548;&#12299;
&lt;/p&gt;
&lt;p&gt;
Of Mice and Mates: Automated Classification and Modelling of Mouse Behaviour in Groups using a Single Model across Cages. (arXiv:2306.03066v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03066
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#33258;&#21160;&#20998;&#31867;&#21644;&#27169;&#25311;&#32676;&#20307;&#32769;&#40736;&#34892;&#20026;&#30340;&#24037;&#20855;&#65292;&#36890;&#36807;&#21333;&#19968;&#27169;&#22411;&#36328;&#31548;&#20351;&#29992;&#32622;&#25442;&#30697;&#38453;&#21305;&#37197;&#32769;&#40736;&#36523;&#20221;&#65292;&#22312;&#23478;&#40736;&#29615;&#22659;&#19979;&#30740;&#31350;&#32769;&#40736;&#21487;&#20197;&#25429;&#25417;&#21040;&#20010;&#20307;&#34892;&#20026;&#30340;&#26102;&#38388;&#22240;&#32032;&#65292;&#32780;&#19988;&#26080;&#38656;&#20154;&#20026;&#24178;&#39044;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34892;&#20026;&#23454;&#39564;&#36890;&#24120;&#22312;&#19987;&#38376;&#30340;&#31454;&#25216;&#22330;&#20013;&#36827;&#34892;&#65292;&#20294;&#36825;&#21487;&#33021;&#20250;&#28151;&#28102;&#20998;&#26512;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#24037;&#20855;&#26469;&#30740;&#31350;&#23478;&#40736;&#29615;&#22659;&#20013;&#30340;&#32769;&#40736;&#65292;&#20026;&#29983;&#29289;&#23398;&#23478;&#25552;&#20379;&#20102;&#25429;&#25417;&#20010;&#20307;&#34892;&#20026;&#30340;&#26102;&#38388;&#22240;&#32032;&#21644;&#27169;&#25311;&#26368;&#23567;&#20154;&#20026;&#24178;&#39044;&#19979;&#31548;&#21451;&#20043;&#38388;&#20114;&#21160;&#21644;&#30456;&#20114;&#20381;&#36182;&#30340;&#21487;&#33021;&#24615;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#8220;&#27963;&#21160;&#26631;&#31614;&#27169;&#22359;&#8221;&#65288;ALM&#65289;&#26469;&#33258;&#21160;&#23545;&#32769;&#40736;&#34892;&#20026;&#36827;&#34892;&#20998;&#31867;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#8220;&#32676;&#20307;&#34892;&#20026;&#27169;&#22411;&#8221;&#65288;GBM&#65289;&#26469;&#27010;&#25324;&#20182;&#20204;&#22312;&#31548;&#23376;&#20013;&#30340;&#32852;&#21512;&#34892;&#20026;&#65292;&#20351;&#29992;&#32622;&#25442;&#30697;&#38453;&#23558;&#27599;&#20010;&#31548;&#23376;&#20013;&#30340;&#32769;&#40736;&#36523;&#20221;&#19982;&#27169;&#22411;&#21305;&#37197;&#12290;&#25105;&#20204;&#36824;&#21457;&#24067;&#20102;&#20004;&#20010;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#35757;&#32451;&#34892;&#20026;&#20998;&#31867;&#22120;&#65288;ABODe&#65289;&#21644;&#34892;&#20026;&#24314;&#27169;&#65288;IMADGE&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Behavioural experiments often happen in specialised arenas, but this may confound the analysis. To address this issue, we provide tools to study mice in the homecage environment, equipping biologists with the possibility to capture the temporal aspect of the individual's behaviour and model the interaction and interdependence between cage-mates with minimal human intervention. We develop the Activity Labelling Module (ALM) to automatically classify mouse behaviour from video, and a novel Group Behaviour Model (GBM) for summarising their joint behaviour across cages, using a permutation matrix to match the mouse identities in each cage to the model. We also release two datasets, ABODe for training behaviour classifiers and IMADGE for modelling behaviour.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#27604;&#36739;&#20102;BBOB&#19978;&#20116;&#31181;&#39640;&#32500;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#19982;&#20256;&#32479;&#26041;&#27861;&#20197;&#21450;CMA-ES&#31639;&#27861;&#30340;&#24615;&#33021;&#65292;&#32467;&#26524;&#34920;&#26126;... (&#26681;&#25454;&#35770;&#25991;&#30340;&#20855;&#20307;&#20869;&#23481;&#36827;&#34892;&#24635;&#32467;)</title><link>http://arxiv.org/abs/2303.00890</link><description>&lt;p&gt;
BBOB&#19978;&#39640;&#32500;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#30340;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Comparison of High-Dimensional Bayesian Optimization Algorithms on BBOB. (arXiv:2303.00890v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.00890
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#27604;&#36739;&#20102;BBOB&#19978;&#20116;&#31181;&#39640;&#32500;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#19982;&#20256;&#32479;&#26041;&#27861;&#20197;&#21450;CMA-ES&#31639;&#27861;&#30340;&#24615;&#33021;&#65292;&#32467;&#26524;&#34920;&#26126;... (&#26681;&#25454;&#35770;&#25991;&#30340;&#20855;&#20307;&#20869;&#23481;&#36827;&#34892;&#24635;&#32467;)
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#26159;&#19968;&#31867;&#22522;&#20110;&#40657;&#30418;&#12289;&#22522;&#20110;&#20195;&#29702;&#30340;&#21551;&#21457;&#24335;&#31639;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#20248;&#21270;&#35780;&#20272;&#25104;&#26412;&#39640;&#12289;&#21482;&#33021;&#25317;&#26377;&#26377;&#38480;&#30340;&#35780;&#20272;&#39044;&#31639;&#30340;&#38382;&#39064;&#12290;&#36125;&#21494;&#26031;&#20248;&#21270;&#22312;&#35299;&#20915;&#24037;&#19994;&#30028;&#30340;&#25968;&#20540;&#20248;&#21270;&#38382;&#39064;&#20013;&#23588;&#20026;&#21463;&#27426;&#36814;&#65292;&#22240;&#20026;&#30446;&#26631;&#20989;&#25968;&#30340;&#35780;&#20272;&#36890;&#24120;&#20381;&#36182;&#32791;&#26102;&#30340;&#27169;&#25311;&#25110;&#29289;&#29702;&#23454;&#39564;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#24037;&#19994;&#38382;&#39064;&#28041;&#21450;&#22823;&#37327;&#21442;&#25968;&#65292;&#36825;&#32473;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#24102;&#26469;&#20102;&#25361;&#25112;&#65292;&#20854;&#24615;&#33021;&#22312;&#32500;&#24230;&#36229;&#36807;15&#20010;&#21464;&#37327;&#26102;&#24120;&#24120;&#19979;&#38477;&#12290;&#34429;&#28982;&#24050;&#32463;&#25552;&#20986;&#20102;&#35768;&#22810;&#26032;&#31639;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20294;&#30446;&#21069;&#36824;&#19981;&#28165;&#26970;&#21738;&#31181;&#31639;&#27861;&#22312;&#21738;&#31181;&#20248;&#21270;&#22330;&#26223;&#20013;&#34920;&#29616;&#26368;&#22909;&#12290;&#26412;&#30740;&#31350;&#27604;&#36739;&#20102;5&#31181;&#26368;&#26032;&#30340;&#39640;&#32500;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#19982;&#20256;&#32479;&#36125;&#21494;&#26031;&#20248;&#21270;&#21644;CMA-ES&#31639;&#27861;&#22312;COCA&#29615;&#22659;&#19979;24&#20010;BBOB&#20989;&#25968;&#19978;&#30340;&#24615;&#33021;&#65292;&#22312;&#32500;&#24230;&#20174;10&#21040;60&#20010;&#21464;&#37327;&#19981;&#26029;&#22686;&#21152;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20102;&#23545;&#27604;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#35777;&#23454;&#20102;...
&lt;/p&gt;
&lt;p&gt;
Bayesian Optimization (BO) is a class of black-box, surrogate-based heuristics that can efficiently optimize problems that are expensive to evaluate, and hence admit only small evaluation budgets. BO is particularly popular for solving numerical optimization problems in industry, where the evaluation of objective functions often relies on time-consuming simulations or physical experiments. However, many industrial problems depend on a large number of parameters. This poses a challenge for BO algorithms, whose performance is often reported to suffer when the dimension grows beyond 15 variables. Although many new algorithms have been proposed to address this problem, it is not well understood which one is the best for which optimization scenario.  In this work, we compare five state-of-the-art high-dimensional BO algorithms, with vanilla BO and CMA-ES on the 24 BBOB functions of the COCO environment at increasing dimensionality, ranging from 10 to 60 variables. Our results confirm the su
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#20998;&#24067;&#24335;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#39640;&#32500;&#31232;&#30095;Cox&#27604;&#20363;&#39118;&#38505;&#27169;&#22411;&#20013;&#20272;&#35745;&#21644;&#25512;&#26029;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#24046;&#26041;&#27861;&#65292;&#25105;&#20204;&#21487;&#20197;&#20135;&#29983;&#28176;&#36817;&#26377;&#25928;&#30340;&#20998;&#24067;&#24335;&#32622;&#20449;&#21306;&#38388;&#65292;&#24182;&#25552;&#20379;&#20102;&#26377;&#25928;&#30340;&#20998;&#24067;&#24335;&#20551;&#35774;&#26816;&#39564;&#12290;</title><link>http://arxiv.org/abs/2302.12111</link><description>&lt;p&gt;
&#38754;&#21521;Cox&#27169;&#22411;&#30340;&#39640;&#25928;&#36890;&#20449;&#24335;&#20998;&#24067;&#24335;&#20272;&#35745;&#21644;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Communication-Efficient Distributed Estimation and Inference for Cox's Model. (arXiv:2302.12111v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.12111
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#20998;&#24067;&#24335;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#39640;&#32500;&#31232;&#30095;Cox&#27604;&#20363;&#39118;&#38505;&#27169;&#22411;&#20013;&#20272;&#35745;&#21644;&#25512;&#26029;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#24046;&#26041;&#27861;&#65292;&#25105;&#20204;&#21487;&#20197;&#20135;&#29983;&#28176;&#36817;&#26377;&#25928;&#30340;&#20998;&#24067;&#24335;&#32622;&#20449;&#21306;&#38388;&#65292;&#24182;&#25552;&#20379;&#20102;&#26377;&#25928;&#30340;&#20998;&#24067;&#24335;&#20551;&#35774;&#26816;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#22240;&#38544;&#31169;&#21644;&#25152;&#26377;&#26435;&#38382;&#39064;&#26080;&#27861;&#20849;&#20139;&#20010;&#20307;&#25968;&#25454;&#30340;&#22810;&#20013;&#24515;&#29983;&#29289;&#21307;&#23398;&#30740;&#31350;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#39640;&#32500;&#31232;&#30095;Cox&#27604;&#20363;&#39118;&#38505;&#27169;&#22411;&#30340;&#36890;&#20449;&#39640;&#25928;&#36845;&#20195;&#20998;&#24067;&#24335;&#31639;&#27861;&#29992;&#20110;&#20272;&#35745;&#21644;&#25512;&#26029;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#21363;&#20351;&#36827;&#34892;&#20102;&#30456;&#23545;&#36739;&#23569;&#30340;&#36845;&#20195;&#65292;&#25105;&#20204;&#30340;&#20272;&#35745;&#20540;&#22312;&#38750;&#24120;&#28201;&#21644;&#30340;&#26465;&#20214;&#19979;&#21487;&#20197;&#36798;&#21040;&#19982;&#29702;&#24819;&#20840;&#26679;&#26412;&#20272;&#35745;&#20540;&#30456;&#21516;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#20026;&#20102;&#26500;&#24314;&#39640;&#32500;&#21361;&#38505;&#22238;&#24402;&#31995;&#25968;&#30340;&#32447;&#24615;&#32452;&#21512;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#24046;&#26041;&#27861;&#65292;&#24314;&#31435;&#20102;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#33268;&#30340;&#26041;&#24046;&#20272;&#35745;&#65292;&#21487;&#20197;&#20135;&#29983;&#28176;&#36817;&#26377;&#25928;&#30340;&#20998;&#24067;&#24335;&#32622;&#20449;&#21306;&#38388;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#22522;&#20110;&#35013;&#39280;&#20998;&#25968;&#26816;&#39564;&#30340;&#20219;&#24847;&#22352;&#26631;&#20803;&#32032;&#30340;&#26377;&#25928;&#21644;&#24378;&#22823;&#30340;&#20998;&#24067;&#24335;&#20551;&#35774;&#26816;&#39564;&#12290;&#25105;&#20204;&#36824;&#20801;&#35768;&#26102;&#38388;&#20381;&#36182;&#21327;&#21464;&#37327;&#20197;&#21450;&#34987;&#23457;&#26597;&#30340;&#29983;&#23384;&#26102;&#38388;&#12290;&#22312;&#22810;&#31181;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#25968;&#23383;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by multi-center biomedical studies that cannot share individual data due to privacy and ownership concerns, we develop communication-efficient iterative distributed algorithms for estimation and inference in the high-dimensional sparse Cox proportional hazards model. We demonstrate that our estimator, even with a relatively small number of iterations, achieves the same convergence rate as the ideal full-sample estimator under very mild conditions. To construct confidence intervals for linear combinations of high-dimensional hazard regression coefficients, we introduce a novel debiased method, establish central limit theorems, and provide consistent variance estimators that yield asymptotically valid distributed confidence intervals. In addition, we provide valid and powerful distributed hypothesis tests for any coordinate element based on a decorrelated score test. We allow time-dependent covariates as well as censored survival times. Extensive numerical experiments on both s
&lt;/p&gt;</description></item></channel></rss>