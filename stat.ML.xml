<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20449;&#20219;&#23398;&#20064;&#29702;&#35770;&#65292;&#36890;&#36807;&#20351;&#29992;&#20984;&#38598;&#30340;&#27010;&#29575;&#26469;&#24314;&#27169;&#25968;&#25454;&#29983;&#25104;&#20998;&#24067;&#30340;&#21464;&#24322;&#24615;&#65292;&#20174;&#26377;&#38480;&#26679;&#26412;&#30340;&#35757;&#32451;&#38598;&#20013;&#25512;&#26029;&#20986;&#20449;&#20219;&#38598;&#65292;&#24182;&#25512;&#23548;&#20986;bounds&#12290;</title><link>https://rss.arxiv.org/abs/2402.00957</link><description>&lt;p&gt;
&#20449;&#20219;&#23398;&#20064;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Credal Learning Theory
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.00957
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20449;&#20219;&#23398;&#20064;&#29702;&#35770;&#65292;&#36890;&#36807;&#20351;&#29992;&#20984;&#38598;&#30340;&#27010;&#29575;&#26469;&#24314;&#27169;&#25968;&#25454;&#29983;&#25104;&#20998;&#24067;&#30340;&#21464;&#24322;&#24615;&#65292;&#20174;&#26377;&#38480;&#26679;&#26412;&#30340;&#35757;&#32451;&#38598;&#20013;&#25512;&#26029;&#20986;&#20449;&#20219;&#38598;&#65292;&#24182;&#25512;&#23548;&#20986;bounds&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#26159;&#26426;&#22120;&#23398;&#20064;&#30340;&#22522;&#30784;&#65292;&#20026;&#20174;&#26410;&#30693;&#27010;&#29575;&#20998;&#24067;&#20013;&#23398;&#20064;&#21040;&#30340;&#27169;&#22411;&#30340;&#39118;&#38505;&#25552;&#20379;&#29702;&#35770;&#36793;&#30028;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#38469;&#37096;&#32626;&#20013;&#65292;&#25968;&#25454;&#20998;&#24067;&#21487;&#33021;&#20250;&#21464;&#21270;&#65292;&#23548;&#33268;&#39046;&#22495;&#36866;&#24212;/&#27867;&#21270;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#8220;&#20449;&#20219;&#8221;&#23398;&#20064;&#29702;&#35770;&#30340;&#22522;&#30784;&#65292;&#20351;&#29992;&#27010;&#29575;&#30340;&#20984;&#38598;&#65288;&#20449;&#20219;&#38598;&#65289;&#26469;&#24314;&#27169;&#25968;&#25454;&#29983;&#25104;&#20998;&#24067;&#30340;&#21464;&#24322;&#24615;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#36825;&#26679;&#30340;&#20449;&#20219;&#38598;&#21487;&#20197;&#20174;&#26377;&#38480;&#26679;&#26412;&#30340;&#35757;&#32451;&#38598;&#20013;&#25512;&#26029;&#20986;&#26469;&#12290;&#23545;&#20110;&#26377;&#38480;&#20551;&#35774;&#31354;&#38388;&#65288;&#26080;&#35770;&#26159;&#21542;&#21487;&#23454;&#29616;&#65289;&#21644;&#26080;&#38480;&#27169;&#22411;&#31354;&#38388;&#65292;&#25512;&#23548;&#20986;&#30028;&#38480;&#65292;&#36825;&#30452;&#25509;&#25512;&#24191;&#20102;&#32463;&#20856;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Statistical learning theory is the foundation of machine learning, providing theoretical bounds for the risk of models learnt from a (single) training set, assumed to issue from an unknown probability distribution. In actual deployment, however, the data distribution may (and often does) vary, causing domain adaptation/generalization issues. In this paper we lay the foundations for a `credal' theory of learning, using convex sets of probabilities (credal sets) to model the variability in the data-generating distribution. Such credal sets, we argue, may be inferred from a finite sample of training sets. Bounds are derived for the case of finite hypotheses spaces (both assuming realizability or not) as well as infinite model spaces, which directly generalize classical results.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20840;&#23616;&#21644;&#23616;&#37096;&#39532;&#27663;&#36317;&#31163;&#30340;&#20998;&#31867;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#26925;&#22278;&#24418;&#20998;&#24067;&#30340;&#31454;&#20105;&#31867;&#21035;&#65292;&#35813;&#26041;&#27861;&#30456;&#27604;&#27969;&#34892;&#30340;&#21442;&#25968;&#21270;&#21644;&#38750;&#21442;&#25968;&#21270;&#20998;&#31867;&#22120;&#20855;&#26377;&#26356;&#22909;&#30340;&#28789;&#27963;&#24615;&#21644;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.08283</link><description>&lt;p&gt;
&#20351;&#29992;&#20840;&#23616;&#21644;&#23616;&#37096;&#39532;&#27663;&#36317;&#31163;&#30340;&#20998;&#31867;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Classification Using Global and Local Mahalanobis Distances
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08283
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20840;&#23616;&#21644;&#23616;&#37096;&#39532;&#27663;&#36317;&#31163;&#30340;&#20998;&#31867;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#26925;&#22278;&#24418;&#20998;&#24067;&#30340;&#31454;&#20105;&#31867;&#21035;&#65292;&#35813;&#26041;&#27861;&#30456;&#27604;&#27969;&#34892;&#30340;&#21442;&#25968;&#21270;&#21644;&#38750;&#21442;&#25968;&#21270;&#20998;&#31867;&#22120;&#20855;&#26377;&#26356;&#22909;&#30340;&#28789;&#27963;&#24615;&#21644;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26469;&#33258;&#19981;&#21516;&#31867;&#21035;&#30340;&#35266;&#23519;&#20540;&#30340;&#39532;&#27663;&#36317;&#31163;&#30340;&#26032;&#22411;&#21322;&#21442;&#25968;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#30340;&#24037;&#20855;&#26159;&#19968;&#20010;&#20855;&#26377;&#36923;&#36753;&#38142;&#25509;&#20989;&#25968;&#30340;&#24191;&#20041;&#21152;&#24615;&#27169;&#22411;&#65292;&#23427;&#20351;&#29992;&#36825;&#20123;&#36317;&#31163;&#20316;&#20026;&#29305;&#24449;&#26469;&#20272;&#35745;&#19981;&#21516;&#31867;&#21035;&#30340;&#21518;&#39564;&#27010;&#29575;&#12290;&#23613;&#31649;&#27969;&#34892;&#30340;&#21442;&#25968;&#21270;&#20998;&#31867;&#22120;&#22914;&#32447;&#24615;&#21644;&#20108;&#27425;&#21028;&#21035;&#20998;&#26512;&#20027;&#35201;&#22522;&#20110;&#22522;&#30784;&#20998;&#24067;&#30340;&#27491;&#24577;&#24615;&#65292;&#20294;&#25152;&#25552;&#20986;&#30340;&#20998;&#31867;&#22120;&#26356;&#21152;&#28789;&#27963;&#65292;&#19981;&#21463;&#27492;&#31867;&#21442;&#25968;&#21270;&#20551;&#35774;&#30340;&#38480;&#21046;&#12290;&#30001;&#20110;&#26925;&#22278;&#20998;&#24067;&#30340;&#23494;&#24230;&#26159;&#39532;&#27663;&#36317;&#31163;&#30340;&#20989;&#25968;&#65292;&#24403;&#31454;&#20105;&#31867;&#21035;&#26159;&#65288;&#20960;&#20046;&#65289;&#26925;&#22278;&#24418;&#26102;&#65292;&#35813;&#20998;&#31867;&#22120;&#30340;&#25928;&#26524;&#24456;&#22909;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#23427;&#32463;&#24120;&#32988;&#36807;&#27969;&#34892;&#30340;&#38750;&#21442;&#25968;&#21270;&#20998;&#31867;&#22120;&#65292;&#29305;&#21035;&#26159;&#24403;&#26679;&#26412;&#37327;&#30456;&#23545;&#20110;&#25968;&#25454;&#32500;&#25968;&#36739;&#23567;&#26102;&#12290;&#20026;&#20102;&#24212;&#23545;&#38750;&#26925;&#22278;&#21644;&#21487;&#33021;&#22810;&#23792;&#30340;&#20998;&#24067;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#39532;&#27663;&#36317;&#31163;&#30340;&#23616;&#37096;&#29256;&#26412;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;
&lt;/p&gt;
&lt;p&gt;
We propose a novel semi-parametric classifier based on Mahalanobis distances of an observation from the competing classes. Our tool is a generalized additive model with the logistic link function that uses these distances as features to estimate the posterior probabilities of the different classes. While popular parametric classifiers like linear and quadratic discriminant analyses are mainly motivated by the normality of the underlying distributions, the proposed classifier is more flexible and free from such parametric assumptions. Since the densities of elliptic distributions are functions of Mahalanobis distances, this classifier works well when the competing classes are (nearly) elliptic. In such cases, it often outperforms popular nonparametric classifiers, especially when the sample size is small compared to the dimension of the data. To cope with non-elliptic and possibly multimodal distributions, we propose a local version of the Mahalanobis distance. Subsequently, we propose 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#28176;&#21464;&#33609;&#22270;&#31639;&#27861;&#65292;&#29992;&#20110;&#35757;&#32451;&#25968;&#25454;&#24402;&#22240;&#21644;&#25439;&#22833;&#22320;&#35980;&#30740;&#31350;&#12290;&#20316;&#32773;&#22312;&#19977;&#20010;&#24212;&#29992;&#20013;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.03994</link><description>&lt;p&gt;
&#20351;&#29992;&#28176;&#21464;&#33609;&#22270;&#36827;&#34892;&#35757;&#32451;&#25968;&#25454;&#24402;&#22240;&#21644;&#25439;&#22833;&#22320;&#35980;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Gradient Sketches for Training Data Attribution and Studying the Loss Landscape
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03994
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#28176;&#21464;&#33609;&#22270;&#31639;&#27861;&#65292;&#29992;&#20110;&#35757;&#32451;&#25968;&#25454;&#24402;&#22240;&#21644;&#25439;&#22833;&#22320;&#35980;&#30740;&#31350;&#12290;&#20316;&#32773;&#22312;&#19977;&#20010;&#24212;&#29992;&#20013;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#25237;&#24433;&#25110;&#28176;&#21464;&#21644;Hessian&#21521;&#37327;&#20056;&#31215;&#30340;&#33609;&#22270;&#22312;&#38656;&#35201;&#23384;&#20648;&#35768;&#22810;&#36825;&#20123;&#21521;&#37327;&#24182;&#20445;&#30041;&#20851;&#20110;&#23427;&#20204;&#30340;&#30456;&#23545;&#20960;&#20309;&#20449;&#24687;&#30340;&#24212;&#29992;&#20013;&#36215;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#20004;&#20010;&#37325;&#35201;&#22330;&#26223;&#26159;&#35757;&#32451;&#25968;&#25454;&#24402;&#22240;&#65288;&#36319;&#36394;&#27169;&#22411;&#23545;&#35757;&#32451;&#25968;&#25454;&#30340;&#34892;&#20026;&#65289;&#65292;&#20854;&#20013;&#38656;&#35201;&#23384;&#20648;&#27599;&#20010;&#35757;&#32451;&#31034;&#20363;&#30340;&#28176;&#21464;&#65292;&#20197;&#21450;Hessian&#30340;&#39057;&#35889;&#30740;&#31350;&#65288;&#20998;&#26512;&#35757;&#32451;&#21160;&#24577;&#65289;&#65292;&#20854;&#20013;&#38656;&#35201;&#23384;&#20648;&#22810;&#20010;Hessian&#21521;&#37327;&#20056;&#31215;&#12290;&#34429;&#28982;&#20351;&#29992;&#23494;&#38598;&#30697;&#38453;&#30340;&#33609;&#22270;&#26131;&#20110;&#23454;&#29616;&#65292;&#20294;&#23427;&#20204;&#21463;&#23384;&#20648;&#38480;&#21046;&#65292;&#19981;&#33021;&#25193;&#23637;&#21040;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#12290;&#22312;&#31070;&#32463;&#32593;&#32476;&#20869;&#22312;&#32500;&#24230;&#30340;&#30740;&#31350;&#24037;&#20316;&#30340;&#25512;&#21160;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#24182;&#30740;&#31350;&#20102;&#21487;&#20280;&#32553;&#33609;&#22270;&#31639;&#27861;&#30340;&#35774;&#35745;&#31354;&#38388;&#12290;&#25105;&#20204;&#22312;&#19977;&#20010;&#24212;&#29992;&#20013;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65306;&#35757;&#32451;&#25968;&#25454;&#24402;&#22240;&#65292;Hessian&#35889;&#20998;&#26512;&#21644;&#24494;&#35843;&#39044;&#20808;&#35757;&#32451;&#26102;&#30340;&#20869;&#22312;&#32500;&#24230;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;
Random projections or sketches of gradients and Hessian vector products play an essential role in applications where one needs to store many such vectors while retaining accurate information about their relative geometry. Two important scenarios are training data attribution (tracing a model's behavior to the training data), where one needs to store a gradient for each training example, and the study of the spectrum of the Hessian (to analyze the training dynamics), where one needs to store multiple Hessian vector products. While sketches that use dense matrices are easy to implement, they are memory bound and cannot be scaled to modern neural networks. Motivated by work on the intrinsic dimension of neural networks, we propose and study a design space for scalable sketching algorithms. We demonstrate the efficacy of our approach in three applications: training data attribution, the analysis of the Hessian spectrum and the computation of the intrinsic dimension when fine-tuning pre-tra
&lt;/p&gt;</description></item><item><title>&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#19982;f-&#20998;&#24067;&#26063;&#30340;&#27491;&#21017;&#21270;&#30340;&#35299;&#20915;&#26041;&#26696;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#26159;&#21807;&#19968;&#30340;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#19981;&#21516;&#30340;f-&#20998;&#24067;&#27491;&#21017;&#21270;&#31561;&#25928;&#22320;&#34920;&#31034;&#12290;</title><link>https://arxiv.org/abs/2402.00501</link><description>&lt;p&gt;
&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#19982;f-&#20998;&#24067;&#26063;&#27491;&#21017;&#21270;&#30340;&#31561;&#20215;&#24615;
&lt;/p&gt;
&lt;p&gt;
Equivalence of the Empirical Risk Minimization to Regularization on the Family of f-Divergences
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00501
&lt;/p&gt;
&lt;p&gt;
&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#19982;f-&#20998;&#24067;&#26063;&#30340;&#27491;&#21017;&#21270;&#30340;&#35299;&#20915;&#26041;&#26696;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#26159;&#21807;&#19968;&#30340;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#19981;&#21516;&#30340;f-&#20998;&#24067;&#27491;&#21017;&#21270;&#31561;&#25928;&#22320;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23545;f&#20013;&#30340;&#28201;&#21644;&#26465;&#20214;&#19979;&#65292;&#32473;&#20986;&#20102;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#19982;f-&#20998;&#24067;&#30340;&#27491;&#21017;&#21270;&#65288;ERM-$f$DR&#65289;&#30340;&#35299;&#27861;&#12290;&#22312;&#36825;&#20123;&#26465;&#20214;&#19979;&#65292;&#26368;&#20248;&#27979;&#24230;&#34987;&#35777;&#26126;&#26159;&#21807;&#19968;&#30340;&#12290;&#24182;&#32473;&#20986;&#20102;&#29305;&#23450;&#36873;&#25321;&#20989;&#25968;f&#30340;&#35299;&#20915;&#26041;&#26696;&#30340;&#31034;&#20363;&#12290;&#36890;&#36807;&#21033;&#29992;f-&#20998;&#24067;&#26063;&#30340;&#28789;&#27963;&#24615;&#65292;&#33719;&#24471;&#20102;&#20808;&#21069;&#23545;&#24120;&#35265;&#27491;&#21017;&#21270;&#36873;&#25321;&#30340;&#24050;&#30693;&#35299;&#20915;&#26041;&#26696;&#65292;&#21253;&#25324;&#30456;&#23545;&#29109;&#27491;&#21017;&#21270;&#30340;&#21807;&#19968;&#35299;&#65288;Type-I&#21644;Type-II&#65289;&#12290;&#23545;&#35299;&#30340;&#20998;&#26512;&#25581;&#31034;&#20102;&#22312;ERM-$f$DR&#38382;&#39064;&#20013;&#20351;&#29992;f-&#20998;&#24067;&#26102;&#30340;&#20197;&#19979;&#23646;&#24615;&#65306;$i)$ f-&#20998;&#24067;&#27491;&#21017;&#21270;&#24378;&#21046;&#23558;&#35299;&#30340;&#25903;&#25345;&#19982;&#21442;&#32771;&#27979;&#24230;&#30340;&#25903;&#25345;&#37325;&#21512;&#65292;&#24341;&#20837;&#20102;&#22312;&#35757;&#32451;&#25968;&#25454;&#25552;&#20379;&#30340;&#35777;&#25454;&#20013;&#21344;&#20027;&#23548;&#22320;&#20301;&#30340;&#24378;&#24402;&#32435;&#20559;&#24046;&#65307;$ii)$ &#20219;&#20309;f-&#20998;&#24067;&#30340;&#27491;&#21017;&#21270;&#37117;&#31561;&#20215;&#20110;&#21478;&#19968;&#31181;f-&#20998;&#24067;&#30340;&#27491;&#21017;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
The solution to empirical risk minimization with $f$-divergence regularization (ERM-$f$DR) is presented under mild conditions on $f$. Under such conditions, the optimal measure is shown to be unique. Examples of the solution for particular choices of the function $f$ are presented. Previously known solutions to common regularization choices are obtained by leveraging the flexibility of the family of $f$-divergences. These include the unique solutions to empirical risk minimization with relative entropy regularization (Type-I and Type-II). The analysis of the solution unveils the following properties of $f$-divergences when used in the ERM-$f$DR problem: $i\bigl)$ $f$-divergence regularization forces the support of the solution to coincide with the support of the reference measure, which introduces a strong inductive bias that dominates the evidence provided by the training data; and $ii\bigl)$ any $f$-divergence regularization is equivalent to a different $f$-divergence regularization 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22810;&#26679;&#30340;&#31232;&#30095;&#24773;&#20917;&#19979;&#20855;&#26377;&#23614;&#37096;&#33258;&#36866;&#24212;&#25910;&#32553;&#29305;&#24615;&#30340;&#40065;&#26834;&#31232;&#30095;&#20272;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#26032;&#30340;&#20840;&#23616;-&#23616;&#37096;-&#23614;&#37096;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#23454;&#29616;&#65292;&#33021;&#22815;&#26681;&#25454;&#31232;&#30095;&#31243;&#24230;&#33258;&#36866;&#24212;&#35843;&#25972;&#20808;&#39564;&#30340;&#23614;&#37096;&#37325;&#37327;&#20197;&#36866;&#24212;&#26356;&#22810;&#25110;&#26356;&#23569;&#20449;&#21495;&#12290;</title><link>https://arxiv.org/abs/2007.02192</link><description>&lt;p&gt;
&#23614;&#37096;&#33258;&#36866;&#24212;&#36125;&#21494;&#26031;&#25910;&#32553;
&lt;/p&gt;
&lt;p&gt;
Tail-adaptive Bayesian shrinkage
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2007.02192
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22810;&#26679;&#30340;&#31232;&#30095;&#24773;&#20917;&#19979;&#20855;&#26377;&#23614;&#37096;&#33258;&#36866;&#24212;&#25910;&#32553;&#29305;&#24615;&#30340;&#40065;&#26834;&#31232;&#30095;&#20272;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#26032;&#30340;&#20840;&#23616;-&#23616;&#37096;-&#23614;&#37096;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#23454;&#29616;&#65292;&#33021;&#22815;&#26681;&#25454;&#31232;&#30095;&#31243;&#24230;&#33258;&#36866;&#24212;&#35843;&#25972;&#20808;&#39564;&#30340;&#23614;&#37096;&#37325;&#37327;&#20197;&#36866;&#24212;&#26356;&#22810;&#25110;&#26356;&#23569;&#20449;&#21495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#22238;&#24402;&#38382;&#39064;&#19979;&#22810;&#26679;&#30340;&#31232;&#30095;&#24773;&#20917;&#19979;&#30340;&#40065;&#26834;&#36125;&#21494;&#26031;&#26041;&#27861;&#12290;&#20256;&#32479;&#30340;&#25910;&#32553;&#20808;&#39564;&#20027;&#35201;&#35774;&#35745;&#29992;&#20110;&#22312;&#25152;&#35859;&#30340;&#36229;&#31232;&#30095;&#39046;&#22495;&#20174;&#25104;&#21315;&#19978;&#19975;&#20010;&#39044;&#27979;&#21464;&#37327;&#20013;&#26816;&#27979;&#23569;&#25968;&#20449;&#21495;&#12290;&#28982;&#32780;&#65292;&#24403;&#31232;&#30095;&#31243;&#24230;&#36866;&#20013;&#26102;&#65292;&#23427;&#20204;&#21487;&#33021;&#34920;&#29616;&#19981;&#23613;&#20154;&#24847;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22810;&#26679;&#31232;&#30095;&#24773;&#20917;&#19979;&#20855;&#26377;&#23614;&#37096;&#33258;&#36866;&#24212;&#25910;&#32553;&#29305;&#24615;&#30340;&#40065;&#26834;&#31232;&#30095;&#20272;&#35745;&#26041;&#27861;&#12290;&#22312;&#36825;&#31181;&#29305;&#24615;&#20013;&#65292;&#20808;&#39564;&#30340;&#23614;&#37096;&#37325;&#37327;&#20250;&#33258;&#36866;&#24212;&#35843;&#25972;&#65292;&#38543;&#30528;&#31232;&#30095;&#27700;&#24179;&#30340;&#22686;&#21152;&#25110;&#20943;&#23569;&#21464;&#24471;&#26356;&#22823;&#25110;&#26356;&#23567;&#65292;&#20197;&#36866;&#24212;&#20808;&#39564;&#22320;&#26356;&#22810;&#25110;&#26356;&#23569;&#30340;&#20449;&#21495;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20840;&#23616;&#23616;&#37096;&#23614;&#37096;&#65288;GLT&#65289;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#20197;&#30830;&#20445;&#36825;&#31181;&#23646;&#24615;&#12290;&#25105;&#20204;&#32771;&#23519;&#20102;&#20808;&#39564;&#30340;&#23614;&#37096;&#25351;&#25968;&#19982;&#22522;&#30784;&#31232;&#30095;&#27700;&#24179;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#35777;&#26126;GLT&#21518;&#39564;&#20250;&#22312;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2007.02192v4 Announce Type: replace-cross  Abstract: Robust Bayesian methods for high-dimensional regression problems under diverse sparse regimes are studied. Traditional shrinkage priors are primarily designed to detect a handful of signals from tens of thousands of predictors in the so-called ultra-sparsity domain. However, they may not perform desirably when the degree of sparsity is moderate. In this paper, we propose a robust sparse estimation method under diverse sparsity regimes, which has a tail-adaptive shrinkage property. In this property, the tail-heaviness of the prior adjusts adaptively, becoming larger or smaller as the sparsity level increases or decreases, respectively, to accommodate more or fewer signals, a posteriori. We propose a global-local-tail (GLT) Gaussian mixture distribution that ensures this property. We examine the role of the tail-index of the prior in relation to the underlying sparsity level and demonstrate that the GLT posterior contracts at the
&lt;/p&gt;</description></item><item><title>FairWASP&#26159;&#19968;&#31181;&#24555;&#36895;&#21644;&#26368;&#20248;&#30340;&#20844;&#24179;Wasserstein&#39044;&#22788;&#29702;&#26041;&#27861;&#65292;&#36890;&#36807;&#37325;&#26032;&#21152;&#26435;&#25968;&#25454;&#38598;&#26469;&#20943;&#23569;&#20998;&#31867;&#25968;&#25454;&#38598;&#20013;&#30340;&#19981;&#24179;&#31561;&#24615;&#65292;&#21516;&#26102;&#28385;&#36275;&#20154;&#21475;&#24179;&#31561;&#24615;&#20934;&#21017;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#29992;&#20110;&#26500;&#24314;&#21487;&#20197;&#36755;&#20837;&#20219;&#20309;&#20998;&#31867;&#26041;&#27861;&#30340;&#25968;&#25454;&#38598;&#12290;</title><link>http://arxiv.org/abs/2311.00109</link><description>&lt;p&gt;
FairWASP&#65306;&#24555;&#36895;&#21644;&#26368;&#20248;&#30340;&#20844;&#24179;Wasserstein&#39044;&#22788;&#29702;
&lt;/p&gt;
&lt;p&gt;
FairWASP: Fast and Optimal Fair Wasserstein Pre-processing. (arXiv:2311.00109v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00109
&lt;/p&gt;
&lt;p&gt;
FairWASP&#26159;&#19968;&#31181;&#24555;&#36895;&#21644;&#26368;&#20248;&#30340;&#20844;&#24179;Wasserstein&#39044;&#22788;&#29702;&#26041;&#27861;&#65292;&#36890;&#36807;&#37325;&#26032;&#21152;&#26435;&#25968;&#25454;&#38598;&#26469;&#20943;&#23569;&#20998;&#31867;&#25968;&#25454;&#38598;&#20013;&#30340;&#19981;&#24179;&#31561;&#24615;&#65292;&#21516;&#26102;&#28385;&#36275;&#20154;&#21475;&#24179;&#31561;&#24615;&#20934;&#21017;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#29992;&#20110;&#26500;&#24314;&#21487;&#20197;&#36755;&#20837;&#20219;&#20309;&#20998;&#31867;&#26041;&#27861;&#30340;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30340;&#24555;&#36895;&#21457;&#23637;&#26088;&#22312;&#20943;&#23569;&#19981;&#21516;&#23376;&#32676;&#20307;&#20043;&#38388;&#27169;&#22411;&#36755;&#20986;&#30340;&#19981;&#24179;&#31561;&#24615;&#12290;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#35757;&#32451;&#25968;&#25454;&#21487;&#33021;&#20250;&#34987;&#19981;&#21516;&#29992;&#25143;&#22312;&#22810;&#20010;&#19979;&#28216;&#24212;&#29992;&#20013;&#20351;&#29992;&#65292;&#36825;&#24847;&#21619;&#30528;&#23545;&#35757;&#32451;&#25968;&#25454;&#26412;&#36523;&#36827;&#34892;&#24178;&#39044;&#21487;&#33021;&#26159;&#26368;&#26377;&#25928;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39044;&#22788;&#29702;&#26041;&#27861;FairWASP&#65292;&#26088;&#22312;&#20943;&#23569;&#20998;&#31867;&#25968;&#25454;&#38598;&#20013;&#30340;&#19981;&#24179;&#31561;&#24615;&#65292;&#32780;&#19981;&#20250;&#20462;&#25913;&#21407;&#22987;&#25968;&#25454;&#12290;FairWASP&#36820;&#22238;&#26679;&#26412;&#32423;&#26435;&#37325;&#65292;&#20351;&#37325;&#26032;&#21152;&#26435;&#30340;&#25968;&#25454;&#38598;&#26368;&#23567;&#21270;&#19982;&#21407;&#22987;&#25968;&#25454;&#38598;&#30340;Wasserstein&#36317;&#31163;&#65292;&#21516;&#26102;&#28385;&#36275;&#65288;&#32463;&#39564;&#29256;&#26412;&#30340;&#65289;&#20154;&#21475;&#24179;&#31561;&#24615;&#65292;&#36825;&#26159;&#19968;&#31181;&#24120;&#29992;&#30340;&#20844;&#24179;&#24615;&#20934;&#21017;&#12290;&#25105;&#20204;&#20174;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#25972;&#25968;&#26435;&#37325;&#30340;&#26368;&#20248;&#24615;&#65292;&#36825;&#24847;&#21619;&#30528;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#31561;&#21516;&#22320;&#29702;&#35299;&#20026;&#22797;&#21046;&#25110;&#21024;&#38500;&#26679;&#26412;&#12290;&#22240;&#27492;&#65292;FairWASP&#21487;&#29992;&#20110;&#26500;&#24314;&#21487;&#20197;&#36755;&#20837;&#20219;&#20309;&#20998;&#31867;&#26041;&#27861;&#30340;&#25968;&#25454;&#38598;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#25509;&#21463;&#26679;&#26412;&#26435;&#37325;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent years have seen a surge of machine learning approaches aimed at reducing disparities in model outputs across different subgroups. In many settings, training data may be used in multiple downstream applications by different users, which means it may be most effective to intervene on the training data itself. In this work, we present FairWASP, a novel pre-processing approach designed to reduce disparities in classification datasets without modifying the original data. FairWASP returns sample-level weights such that the reweighted dataset minimizes the Wasserstein distance to the original dataset while satisfying (an empirical version of) demographic parity, a popular fairness criterion. We show theoretically that integer weights are optimal, which means our method can be equivalently understood as duplicating or eliminating samples. FairWASP can therefore be used to construct datasets which can be fed into any classification method, not just methods which accept sample weights. Ou
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#36890;&#36807;&#24352;&#37327;&#32593;&#32476;&#29702;&#35299;&#21644;&#28436;&#21270;&#21367;&#31215;&#30340;&#26032;&#35270;&#35282;&#65292;&#21487;&#20197;&#36890;&#36807;&#32472;&#21046;&#21644;&#25805;&#20316;&#24352;&#37327;&#32593;&#32476;&#26469;&#36827;&#34892;&#20989;&#25968;&#36716;&#25442;&#12289;&#23376;&#24352;&#37327;&#35775;&#38382;&#21644;&#34701;&#21512;&#12290;&#30740;&#31350;&#20154;&#21592;&#36824;&#28436;&#31034;&#20102;&#21367;&#31215;&#22270;&#34920;&#30340;&#23548;&#20986;&#20197;&#21450;&#21508;&#31181;&#33258;&#21160;&#24494;&#20998;&#25805;&#20316;&#21644;&#20108;&#38454;&#20449;&#24687;&#36924;&#36817;&#22270;&#34920;&#30340;&#29983;&#25104;&#65292;&#21516;&#26102;&#36824;&#25552;&#20379;&#20102;&#29305;&#23450;&#20110;&#21367;&#31215;&#30340;&#22270;&#34920;&#36716;&#25442;&#65292;&#20197;&#20248;&#21270;&#35745;&#31639;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.02275</link><description>&lt;p&gt;
&#36879;&#36807;&#24352;&#37327;&#32593;&#32476;&#30340;&#35270;&#35282;&#35299;&#26512;&#21367;&#31215;
&lt;/p&gt;
&lt;p&gt;
Convolutions Through the Lens of Tensor Networks. (arXiv:2307.02275v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02275
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#36890;&#36807;&#24352;&#37327;&#32593;&#32476;&#29702;&#35299;&#21644;&#28436;&#21270;&#21367;&#31215;&#30340;&#26032;&#35270;&#35282;&#65292;&#21487;&#20197;&#36890;&#36807;&#32472;&#21046;&#21644;&#25805;&#20316;&#24352;&#37327;&#32593;&#32476;&#26469;&#36827;&#34892;&#20989;&#25968;&#36716;&#25442;&#12289;&#23376;&#24352;&#37327;&#35775;&#38382;&#21644;&#34701;&#21512;&#12290;&#30740;&#31350;&#20154;&#21592;&#36824;&#28436;&#31034;&#20102;&#21367;&#31215;&#22270;&#34920;&#30340;&#23548;&#20986;&#20197;&#21450;&#21508;&#31181;&#33258;&#21160;&#24494;&#20998;&#25805;&#20316;&#21644;&#20108;&#38454;&#20449;&#24687;&#36924;&#36817;&#22270;&#34920;&#30340;&#29983;&#25104;&#65292;&#21516;&#26102;&#36824;&#25552;&#20379;&#20102;&#29305;&#23450;&#20110;&#21367;&#31215;&#30340;&#22270;&#34920;&#36716;&#25442;&#65292;&#20197;&#20248;&#21270;&#35745;&#31639;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#21367;&#31215;&#30340;&#30452;&#35266;&#27010;&#24565;&#31616;&#21333;&#65292;&#20294;&#20854;&#20998;&#26512;&#27604;&#31264;&#23494;&#23618;&#26356;&#21152;&#22797;&#26434;&#65292;&#36825;&#20351;&#24471;&#29702;&#35770;&#21644;&#31639;&#27861;&#30340;&#25512;&#24191;&#21464;&#24471;&#22256;&#38590;&#12290;&#25105;&#20204;&#36890;&#36807;&#24352;&#37327;&#32593;&#32476;&#65288;TN&#65289;&#25552;&#20379;&#20102;&#23545;&#21367;&#31215;&#30340;&#26032;&#35270;&#35282;&#65292;&#36890;&#36807;&#32472;&#21046;&#22270;&#34920;&#12289;&#25805;&#20316;&#22270;&#34920;&#36827;&#34892;&#20989;&#25968;&#36716;&#25442;&#12289;&#23376;&#24352;&#37327;&#35775;&#38382;&#21644;&#34701;&#21512;&#26469;&#25512;&#29702;&#24213;&#23618;&#24352;&#37327;&#20056;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#25512;&#23548;&#21508;&#31181;&#33258;&#21160;&#24494;&#20998;&#25805;&#20316;&#30340;&#22270;&#34920;&#20197;&#21450;&#20855;&#26377;&#23436;&#25972;&#36229;&#21442;&#25968;&#25903;&#25345;&#12289;&#25209;&#22788;&#29702;&#12289;&#36890;&#36947;&#32452;&#21644;&#20219;&#24847;&#21367;&#31215;&#32500;&#24230;&#27867;&#21270;&#30340;&#27969;&#34892;&#30340;&#20108;&#38454;&#20449;&#24687;&#36924;&#36817;&#30340;&#22270;&#34920;&#26469;&#23637;&#31034;&#36825;&#31181;&#34920;&#36798;&#33021;&#21147;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22522;&#20110;&#36830;&#25509;&#27169;&#24335;&#25552;&#20379;&#20102;&#29305;&#23450;&#20110;&#21367;&#31215;&#30340;&#36716;&#25442;&#65292;&#20801;&#35768;&#22312;&#35780;&#20272;&#20043;&#21069;&#37325;&#26032;&#36830;&#25509;&#21644;&#31616;&#21270;&#22270;&#34920;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#20381;&#36182;&#20110;&#39640;&#25928;TN&#32553;&#24182;&#30340;&#24050;&#24314;&#31435;&#26426;&#21046;&#26469;&#25506;&#31350;&#35745;&#31639;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;TN&#23454;&#29616;&#21152;&#36895;&#20102;&#26368;&#36817;&#25552;&#20986;&#30340;
&lt;/p&gt;
&lt;p&gt;
Despite their simple intuition, convolutions are more tedious to analyze than dense layers, which complicates the generalization of theoretical and algorithmic ideas. We provide a new perspective onto convolutions through tensor networks (TNs) which allow reasoning about the underlying tensor multiplications by drawing diagrams, and manipulating them to perform function transformations, sub-tensor access, and fusion. We demonstrate this expressive power by deriving the diagrams of various autodiff operations and popular approximations of second-order information with full hyper-parameter support, batching, channel groups, and generalization to arbitrary convolution dimensions. Further, we provide convolution-specific transformations based on the connectivity pattern which allow to re-wire and simplify diagrams before evaluation. Finally, we probe computational performance, relying on established machinery for efficient TN contraction. Our TN implementation speeds up a recently-proposed
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#34920;&#31034;&#30340;&#26032;&#22411;&#25955;&#24230;&#8212;&#8212;&#34920;&#31034;Jensen-Shannon&#25955;&#24230;&#65292;&#36890;&#36807;&#23558;&#25968;&#25454;&#20998;&#24067;&#23884;&#20837;&#21040;RKHS&#20013;&#65292;&#24182;&#21033;&#29992;&#34920;&#31034;&#30340;&#21327;&#26041;&#24046;&#31639;&#23376;&#30340;&#39057;&#35889;&#65292;&#23454;&#29616;&#23545;&#25968;&#25454;&#20998;&#24067;&#30340;&#20272;&#35745;&#65292;&#24182;&#25552;&#20379;&#20102;&#20855;&#26377;&#28789;&#27963;&#24615;&#65292;&#21487;&#25193;&#23637;&#24615;&#65292;&#21487;&#24494;&#20998;&#24615;&#30340;&#32463;&#39564;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#20989;&#25968;&#21644;&#22522;&#20110;&#26680;&#30697;&#38453;&#30340;&#20272;&#35745;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2305.16446</link><description>&lt;p&gt;
&#22522;&#20110;&#34920;&#31034;&#30340;Jensen-Shannon&#25955;&#24230;
&lt;/p&gt;
&lt;p&gt;
The Representation Jensen-Shannon Divergence. (arXiv:2305.16446v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16446
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#34920;&#31034;&#30340;&#26032;&#22411;&#25955;&#24230;&#8212;&#8212;&#34920;&#31034;Jensen-Shannon&#25955;&#24230;&#65292;&#36890;&#36807;&#23558;&#25968;&#25454;&#20998;&#24067;&#23884;&#20837;&#21040;RKHS&#20013;&#65292;&#24182;&#21033;&#29992;&#34920;&#31034;&#30340;&#21327;&#26041;&#24046;&#31639;&#23376;&#30340;&#39057;&#35889;&#65292;&#23454;&#29616;&#23545;&#25968;&#25454;&#20998;&#24067;&#30340;&#20272;&#35745;&#65292;&#24182;&#25552;&#20379;&#20102;&#20855;&#26377;&#28789;&#27963;&#24615;&#65292;&#21487;&#25193;&#23637;&#24615;&#65292;&#21487;&#24494;&#20998;&#24615;&#30340;&#32463;&#39564;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#20989;&#25968;&#21644;&#22522;&#20110;&#26680;&#30697;&#38453;&#30340;&#20272;&#35745;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32479;&#35745;&#25955;&#24230;&#37327;&#21270;&#27010;&#29575;&#20998;&#24067;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#31181;&#37325;&#35201;&#26041;&#27861;&#12290;&#20294;&#26159;&#65292;&#30001;&#20110;&#25968;&#25454;&#30340;&#24213;&#23618;&#20998;&#24067;&#36890;&#24120;&#26410;&#30693;&#65292;&#20174;&#32463;&#39564;&#26679;&#26412;&#20013;&#20272;&#35745;&#25955;&#24230;&#26159;&#19968;&#20010;&#22522;&#26412;&#38590;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;(RKHS)&#20013;&#21327;&#26041;&#24046;&#31639;&#23376;&#30340;&#26032;&#22411;&#25955;&#24230;&#8212;&#8212;&#34920;&#31034;Jensen-Shannon&#25955;&#24230;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#25968;&#25454;&#20998;&#24067;&#23884;&#20837;&#21040;RKHS&#20013;&#65292;&#24182;&#21033;&#29992;&#34920;&#31034;&#30340;&#21327;&#26041;&#24046;&#31639;&#23376;&#30340;&#39057;&#35889;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#20174;&#32463;&#39564;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#30340;&#20272;&#35745;&#20989;&#25968;&#65292;&#23427;&#36890;&#36807;&#20351;&#29992;Fourier&#29305;&#24449;&#23558;&#25968;&#25454;&#26144;&#23556;&#21040;RKHS&#20013;&#12290;&#27492;&#20272;&#35745;&#20989;&#25968;&#26159;&#28789;&#27963;&#12289;&#21487;&#25193;&#23637;&#12289;&#21487;&#24494;&#20998;&#30340;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#23567;&#25209;&#37327;&#20248;&#21270;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#30697;&#38453;&#30340;&#20272;&#35745;&#20989;&#25968;&#65292;&#32780;&#19981;&#38656;&#35201;&#23545;RKHS&#36827;&#34892;&#26174;&#24335;&#26144;&#23556;&#12290;&#25105;&#20204;&#35777;&#26126;&#36825;&#20010;&#37327;&#26159;Jensen-Shannon&#25955;&#24230;&#30340;&#19968;&#20010;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
Statistical divergences quantify the difference between probability distributions finding multiple uses in machine-learning. However, a fundamental challenge is to estimate divergence from empirical samples since the underlying distributions of the data are usually unknown. In this work, we propose the representation Jensen-Shannon Divergence, a novel divergence based on covariance operators in reproducing kernel Hilbert spaces (RKHS). Our approach embeds the data distributions in an RKHS and exploits the spectrum of the covariance operators of the representations. We provide an estimator from empirical covariance matrices by explicitly mapping the data to an RKHS using Fourier features. This estimator is flexible, scalable, differentiable, and suitable for minibatch-based optimization problems. Additionally, we provide an estimator based on kernel matrices without having an explicit mapping to the RKHS. We show that this quantity is a lower bound on the Jensen-Shannon divergence, and 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#31070;&#32463;&#19981;&#23436;&#20840;&#20998;&#35299;&#30340;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#33258;&#30417;&#30563;&#35757;&#32451;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#29983;&#25104;&#36866;&#29992;&#20110;&#29305;&#23450;&#38382;&#39064;&#22495;&#30340;&#26377;&#25928;&#39044;&#22788;&#29702;&#22120;&#12290;&#20854;&#36890;&#36807;&#26367;&#25442;&#20256;&#32479;&#25163;&#24037;&#39044;&#22788;&#29702;&#22120;&#26174;&#30528;&#25552;&#39640;&#20102;&#25910;&#25947;&#21644;&#35745;&#31639;&#25928;&#29575;&#65292;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#38382;&#39064;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#22343;&#34920;&#29616;&#20986;&#31454;&#20105;&#21147;&#12290;</title><link>http://arxiv.org/abs/2305.16368</link><description>&lt;p&gt;
&#31070;&#32463;&#19981;&#23436;&#20840;&#20998;&#35299;&#65306;&#23398;&#20064;&#20849;&#36717;&#26799;&#24230;&#27861;&#30340;&#39044;&#22788;&#29702;&#22120;
&lt;/p&gt;
&lt;p&gt;
Neural incomplete factorization: learning preconditioners for the conjugate gradient method. (arXiv:2305.16368v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16368
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#31070;&#32463;&#19981;&#23436;&#20840;&#20998;&#35299;&#30340;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#33258;&#30417;&#30563;&#35757;&#32451;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#29983;&#25104;&#36866;&#29992;&#20110;&#29305;&#23450;&#38382;&#39064;&#22495;&#30340;&#26377;&#25928;&#39044;&#22788;&#29702;&#22120;&#12290;&#20854;&#36890;&#36807;&#26367;&#25442;&#20256;&#32479;&#25163;&#24037;&#39044;&#22788;&#29702;&#22120;&#26174;&#30528;&#25552;&#39640;&#20102;&#25910;&#25947;&#21644;&#35745;&#31639;&#25928;&#29575;&#65292;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#38382;&#39064;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#22343;&#34920;&#29616;&#20986;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#65292;&#29992;&#20110;&#21152;&#36895;&#31185;&#23398;&#35745;&#31639;&#21644;&#20248;&#21270;&#20013;&#36935;&#21040;&#30340;&#22823;&#35268;&#27169;&#32447;&#24615;&#26041;&#31243;&#32452;&#27714;&#35299;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#33258;&#30417;&#30563;&#35757;&#32451;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#29983;&#25104;&#36866;&#29992;&#20110;&#29305;&#23450;&#38382;&#39064;&#22495;&#30340;&#26377;&#25928;&#39044;&#22788;&#29702;&#22120;&#12290;&#36890;&#36807;&#26367;&#25442;&#19982;&#20849;&#36717;&#26799;&#24230;&#27861;&#19968;&#36215;&#20351;&#29992;&#30340;&#20256;&#32479;&#25163;&#24037;&#39044;&#22788;&#29702;&#22120;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#65288;&#31216;&#20026;&#31070;&#32463;&#19981;&#23436;&#20840;&#20998;&#35299;&#65289;&#26174;&#30528;&#21152;&#36895;&#20102;&#25910;&#25947;&#21644;&#35745;&#31639;&#25928;&#29575;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26680;&#24515;&#26159;&#19968;&#31181;&#21463;&#31232;&#30095;&#30697;&#38453;&#29702;&#35770;&#21551;&#21457;&#30340;&#26032;&#22411;&#28040;&#24687;&#20256;&#36882;&#22359;&#65292;&#23427;&#19982;&#23547;&#25214;&#30697;&#38453;&#30340;&#31232;&#30095;&#20998;&#35299;&#30340;&#30446;&#26631;&#30456;&#19968;&#33268;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#38382;&#39064;&#21644;&#26469;&#33258;&#31185;&#23398;&#35745;&#31639;&#30340;&#30495;&#23454;&#38382;&#39064;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#31070;&#32463;&#19981;&#23436;&#20840;&#20998;&#35299;&#22987;&#32456;&#20248;&#20110;&#26368;&#24120;&#35265;&#30340;&#36890;&#29992;&#39044;&#22788;&#29702;&#22120;&#65292;&#21253;&#25324;&#19981;&#23436;&#20840;&#30340;Cholesky&#26041;&#27861;&#65292;&#22312;&#25910;&#25947;&#36895;&#24230;&#21644;&#35745;&#31639;&#25928;&#29575;&#26041;&#38754;&#34920;&#29616;&#20986;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we develop a novel data-driven approach to accelerate solving large-scale linear equation systems encountered in scientific computing and optimization. Our method utilizes self-supervised training of a graph neural network to generate an effective preconditioner tailored to the specific problem domain. By replacing conventional hand-crafted preconditioners used with the conjugate gradient method, our approach, named neural incomplete factorization (NeuralIF), significantly speeds-up convergence and computational efficiency. At the core of our method is a novel message-passing block, inspired by sparse matrix theory, that aligns with the objective to find a sparse factorization of the matrix. We evaluate our proposed method on both a synthetic and a real-world problem arising from scientific computing. Our results demonstrate that NeuralIF consistently outperforms the most common general-purpose preconditioners, including the incomplete Cholesky method, achieving competit
&lt;/p&gt;</description></item></channel></rss>