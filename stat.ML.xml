<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#20915;&#31574;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#23545;&#20110;&#20219;&#20309;&#36125;&#21494;&#26031;&#22238;&#24402;&#27169;&#22411;&#65292;&#21487;&#20197;&#24471;&#21040;&#27599;&#20010;&#26465;&#20214;&#20998;&#20301;&#25968;&#30340;&#26368;&#20339;&#21644;&#21487;&#35299;&#37322;&#30340;&#32447;&#24615;&#20272;&#35745;&#20540;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#35813;&#26041;&#27861;&#26159;&#19968;&#31181;&#36866;&#29992;&#20110;&#29305;&#23450;&#20998;&#20301;&#25968;&#23376;&#38598;&#36873;&#25321;&#30340;&#26377;&#25928;&#24037;&#20855;&#12290;</title><link>http://arxiv.org/abs/2311.02043</link><description>&lt;p&gt;
&#22522;&#20110;&#23376;&#38598;&#36873;&#25321;&#30340;&#36125;&#21494;&#26031;&#20998;&#20301;&#22238;&#24402;&#65306;&#21518;&#39564;&#24635;&#32467;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Bayesian Quantile Regression with Subset Selection: A Posterior Summarization Perspective. (arXiv:2311.02043v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.02043
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#20915;&#31574;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#23545;&#20110;&#20219;&#20309;&#36125;&#21494;&#26031;&#22238;&#24402;&#27169;&#22411;&#65292;&#21487;&#20197;&#24471;&#21040;&#27599;&#20010;&#26465;&#20214;&#20998;&#20301;&#25968;&#30340;&#26368;&#20339;&#21644;&#21487;&#35299;&#37322;&#30340;&#32447;&#24615;&#20272;&#35745;&#20540;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#35813;&#26041;&#27861;&#26159;&#19968;&#31181;&#36866;&#29992;&#20110;&#29305;&#23450;&#20998;&#20301;&#25968;&#23376;&#38598;&#36873;&#25321;&#30340;&#26377;&#25928;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#20301;&#22238;&#24402;&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#24037;&#20855;&#65292;&#29992;&#20110;&#25512;&#26029;&#21327;&#21464;&#37327;&#22914;&#20309;&#24433;&#21709;&#21709;&#24212;&#20998;&#24067;&#30340;&#29305;&#23450;&#20998;&#20301;&#25968;&#12290;&#29616;&#26377;&#26041;&#27861;&#35201;&#20040;&#20998;&#21035;&#20272;&#35745;&#27599;&#20010;&#24863;&#20852;&#36259;&#20998;&#20301;&#25968;&#30340;&#26465;&#20214;&#20998;&#20301;&#25968;&#65292;&#35201;&#20040;&#20351;&#29992;&#21322;&#21442;&#25968;&#25110;&#38750;&#21442;&#25968;&#27169;&#22411;&#20272;&#35745;&#25972;&#20010;&#26465;&#20214;&#20998;&#24067;&#12290;&#21069;&#32773;&#32463;&#24120;&#20135;&#29983;&#19981;&#36866;&#21512;&#23454;&#38469;&#25968;&#25454;&#30340;&#27169;&#22411;&#65292;&#24182;&#19988;&#19981;&#22312;&#20998;&#20301;&#25968;&#20043;&#38388;&#20849;&#20139;&#20449;&#24687;&#65292;&#32780;&#21518;&#32773;&#21017;&#20197;&#22797;&#26434;&#19988;&#21463;&#38480;&#21046;&#30340;&#27169;&#22411;&#20026;&#29305;&#28857;&#65292;&#38590;&#20197;&#35299;&#37322;&#21644;&#35745;&#31639;&#25928;&#29575;&#20302;&#19979;&#12290;&#27492;&#22806;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#37117;&#19981;&#36866;&#21512;&#20110;&#29305;&#23450;&#20998;&#20301;&#25968;&#30340;&#23376;&#38598;&#36873;&#25321;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#20174;&#36125;&#21494;&#26031;&#20915;&#31574;&#20998;&#26512;&#30340;&#35282;&#24230;&#20986;&#21457;&#65292;&#25552;&#20986;&#20102;&#32447;&#24615;&#20998;&#20301;&#20272;&#35745;&#12289;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#23376;&#38598;&#36873;&#25321;&#30340;&#22522;&#26412;&#38382;&#39064;&#12290;&#23545;&#20110;&#20219;&#20309;&#36125;&#21494;&#26031;&#22238;&#24402;&#27169;&#22411;&#65292;&#25105;&#20204;&#20026;&#27599;&#20010;&#22522;&#20110;&#27169;&#22411;&#30340;&#26465;&#20214;&#20998;&#20301;&#25968;&#25512;&#23548;&#20986;&#26368;&#20339;&#21644;&#21487;&#35299;&#37322;&#30340;&#32447;&#24615;&#20272;&#35745;&#20540;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#24341;&#20837;&#20102;&#19968;&#31181;&#20998;&#20301;&#25968;&#32858;&#28966;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantile regression is a powerful tool for inferring how covariates affect specific percentiles of the response distribution. Existing methods either estimate conditional quantiles separately for each quantile of interest or estimate the entire conditional distribution using semi- or non-parametric models. The former often produce inadequate models for real data and do not share information across quantiles, while the latter are characterized by complex and constrained models that can be difficult to interpret and computationally inefficient. Further, neither approach is well-suited for quantile-specific subset selection. Instead, we pose the fundamental problems of linear quantile estimation, uncertainty quantification, and subset selection from a Bayesian decision analysis perspective. For any Bayesian regression model, we derive optimal and interpretable linear estimates and uncertainty quantification for each model-based conditional quantile. Our approach introduces a quantile-focu
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#25552;&#20986;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#25105;&#20204;&#21487;&#20197;&#35299;&#37322;&#26377;&#20851;&#20381;&#36182;&#36755;&#20837;&#30340;&#40657;&#31665;&#27169;&#22411;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#19968;&#20123;&#21512;&#29702;&#30340;&#20551;&#35774;&#19979;&#65292;&#38750;&#32447;&#24615;&#20989;&#25968;&#21487;&#20197;&#21807;&#19968;&#20998;&#35299;&#20026;&#27599;&#20010;&#21487;&#33021;&#23376;&#38598;&#30340;&#20989;&#25968;&#20043;&#21644;&#12290;&#36825;&#20010;&#26694;&#26550;&#26377;&#25928;&#22320;&#25512;&#24191;&#20102;Hoeffding&#20998;&#35299;&#65292;&#24182;&#25552;&#20379;&#20102;&#26032;&#39062;&#30340;&#21487;&#35299;&#37322;&#24615;&#25351;&#26631;&#12290;</title><link>http://arxiv.org/abs/2310.06567</link><description>&lt;p&gt;
&#36890;&#36807;Hoeffding&#20998;&#35299;&#30340;&#25512;&#24191;&#65292;&#29702;&#35299;&#26377;&#20851;&#20381;&#36182;&#36755;&#20837;&#30340;&#40657;&#31665;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Understanding black-box models with dependent inputs through a generalization of Hoeffding's decomposition. (arXiv:2310.06567v1 [math.FA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06567
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25552;&#20986;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#25105;&#20204;&#21487;&#20197;&#35299;&#37322;&#26377;&#20851;&#20381;&#36182;&#36755;&#20837;&#30340;&#40657;&#31665;&#27169;&#22411;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#19968;&#20123;&#21512;&#29702;&#30340;&#20551;&#35774;&#19979;&#65292;&#38750;&#32447;&#24615;&#20989;&#25968;&#21487;&#20197;&#21807;&#19968;&#20998;&#35299;&#20026;&#27599;&#20010;&#21487;&#33021;&#23376;&#38598;&#30340;&#20989;&#25968;&#20043;&#21644;&#12290;&#36825;&#20010;&#26694;&#26550;&#26377;&#25928;&#22320;&#25512;&#24191;&#20102;Hoeffding&#20998;&#35299;&#65292;&#24182;&#25552;&#20379;&#20102;&#26032;&#39062;&#30340;&#21487;&#35299;&#37322;&#24615;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35299;&#37322;&#40657;&#31665;&#27169;&#22411;&#30340;&#20027;&#35201;&#25361;&#25112;&#20043;&#19968;&#26159;&#33021;&#22815;&#23558;&#38750;&#20114;&#19981;&#30456;&#20851;&#38543;&#26426;&#36755;&#20837;&#30340;&#24179;&#26041;&#21487;&#31215;&#20989;&#25968;&#21807;&#19968;&#20998;&#35299;&#20026;&#27599;&#20010;&#21487;&#33021;&#23376;&#38598;&#30340;&#20989;&#25968;&#20043;&#21644;&#12290;&#28982;&#32780;&#65292;&#22788;&#29702;&#36755;&#20837;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#21487;&#33021;&#24456;&#22797;&#26434;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#26469;&#30740;&#31350;&#36825;&#20010;&#38382;&#39064;&#65292;&#23558;&#19977;&#20010;&#25968;&#23398;&#39046;&#22495;&#32852;&#31995;&#36215;&#26469;&#65306;&#27010;&#29575;&#35770;&#12289;&#20989;&#25968;&#20998;&#26512;&#21644;&#32452;&#21512;&#25968;&#23398;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#22312;&#36755;&#20837;&#19978;&#30340;&#20004;&#20010;&#21512;&#29702;&#20551;&#35774;&#19979;&#65288;&#38750;&#23436;&#32654;&#30340;&#20989;&#25968;&#20381;&#36182;&#24615;&#21644;&#38750;&#36864;&#21270;&#30340;&#38543;&#26426;&#20381;&#36182;&#24615;&#65289;&#65292;&#24635;&#26159;&#21487;&#20197;&#21807;&#19968;&#20998;&#35299;&#36825;&#26679;&#19968;&#20010;&#20989;&#25968;&#12290;&#36825;&#31181;&#8220;&#35268;&#33539;&#20998;&#35299;&#8221;&#30456;&#23545;&#30452;&#35266;&#65292;&#25581;&#31034;&#20102;&#38750;&#32447;&#24615;&#30456;&#20851;&#36755;&#20837;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#30340;&#32447;&#24615;&#29305;&#24615;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#20013;&#65292;&#25105;&#20204;&#26377;&#25928;&#22320;&#25512;&#24191;&#20102;&#20247;&#25152;&#21608;&#30693;&#30340;Hoeffding&#20998;&#35299;&#65292;&#21487;&#20197;&#30475;&#20316;&#26159;&#19968;&#20010;&#29305;&#27530;&#24773;&#20917;&#12290;&#40657;&#31665;&#27169;&#22411;&#30340;&#26012;&#25237;&#24433;&#20026;&#26032;&#39062;&#30340;&#21487;&#35299;&#37322;&#24615;&#25351;&#26631;&#25552;&#20379;&#20102;&#21487;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
One of the main challenges for interpreting black-box models is the ability to uniquely decompose square-integrable functions of non-mutually independent random inputs into a sum of functions of every possible subset of variables. However, dealing with dependencies among inputs can be complicated. We propose a novel framework to study this problem, linking three domains of mathematics: probability theory, functional analysis, and combinatorics. We show that, under two reasonable assumptions on the inputs (non-perfect functional dependence and non-degenerate stochastic dependence), it is always possible to decompose uniquely such a function. This ``canonical decomposition'' is relatively intuitive and unveils the linear nature of non-linear functions of non-linearly dependent inputs. In this framework, we effectively generalize the well-known Hoeffding decomposition, which can be seen as a particular case. Oblique projections of the black-box model allow for novel interpretability indic
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24182;&#34892;&#26102;&#38388;&#27010;&#29575;&#25968;&#20540;ODE&#27714;&#35299;&#22120;&#65292;&#36890;&#36807;&#23558;&#25968;&#20540;&#27169;&#25311;&#38382;&#39064;&#35270;&#20026;&#36125;&#21494;&#26031;&#29366;&#24577;&#20272;&#35745;&#38382;&#39064;&#65292;&#24182;&#21033;&#29992;&#36125;&#21494;&#26031;&#28388;&#27874;&#21644;&#24179;&#28369;&#30340;&#26694;&#26550;&#65292;&#23454;&#29616;&#20102;&#22312;&#24182;&#34892;&#22788;&#29702;&#25152;&#26377;&#26102;&#38388;&#27493;&#39588;&#30340;&#21516;&#26102;&#23558;&#26102;&#38388;&#24320;&#38144;&#38477;&#20302;&#21040;&#23545;&#25968;&#32423;&#21035;&#12290;</title><link>http://arxiv.org/abs/2310.01145</link><description>&lt;p&gt;
&#24182;&#34892;&#26102;&#38388;&#27010;&#29575;&#25968;&#20540;ODE&#27714;&#35299;&#22120;
&lt;/p&gt;
&lt;p&gt;
Parallel-in-Time Probabilistic Numerical ODE Solvers. (arXiv:2310.01145v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01145
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24182;&#34892;&#26102;&#38388;&#27010;&#29575;&#25968;&#20540;ODE&#27714;&#35299;&#22120;&#65292;&#36890;&#36807;&#23558;&#25968;&#20540;&#27169;&#25311;&#38382;&#39064;&#35270;&#20026;&#36125;&#21494;&#26031;&#29366;&#24577;&#20272;&#35745;&#38382;&#39064;&#65292;&#24182;&#21033;&#29992;&#36125;&#21494;&#26031;&#28388;&#27874;&#21644;&#24179;&#28369;&#30340;&#26694;&#26550;&#65292;&#23454;&#29616;&#20102;&#22312;&#24182;&#34892;&#22788;&#29702;&#25152;&#26377;&#26102;&#38388;&#27493;&#39588;&#30340;&#21516;&#26102;&#23558;&#26102;&#38388;&#24320;&#38144;&#38477;&#20302;&#21040;&#23545;&#25968;&#32423;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#24120;&#24494;&#20998;&#26041;&#31243;(ODE)&#30340;&#27010;&#29575;&#25968;&#20540;&#27714;&#35299;&#22120;&#23558;&#21160;&#21147;&#31995;&#32479;&#30340;&#25968;&#20540;&#20223;&#30495;&#38382;&#39064;&#35270;&#20026;&#36125;&#21494;&#26031;&#29366;&#24577;&#20272;&#35745;&#38382;&#39064;&#12290;&#38500;&#20102;&#29983;&#25104;ODE&#35299;&#30340;&#21518;&#39564;&#20998;&#24067;&#24182;&#22240;&#27492;&#37327;&#21270;&#26041;&#27861;&#26412;&#36523;&#30340;&#25968;&#20540;&#36924;&#36817;&#35823;&#24046;&#20043;&#22806;&#65292;&#36825;&#31181;&#24418;&#24335;&#21270;&#26041;&#27861;&#30340;&#19968;&#20010;&#19981;&#24120;&#34987;&#27880;&#24847;&#21040;&#30340;&#20248;&#21183;&#26159;&#36890;&#36807;&#22312;&#36125;&#21494;&#26031;&#28388;&#27874;&#21644;&#24179;&#28369;&#30340;&#26694;&#26550;&#20013;&#36827;&#34892;&#25968;&#20540;&#27169;&#25311;&#32780;&#33719;&#24471;&#30340;&#31639;&#27861;&#28789;&#27963;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#36825;&#31181;&#28789;&#27963;&#24615;&#65292;&#22522;&#20110;&#26102;&#38388;&#24182;&#34892;&#36845;&#20195;&#25193;&#23637;&#21345;&#23572;&#26364;&#24179;&#28369;&#22120;&#30340;&#20844;&#24335;&#21270;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#24182;&#34892;&#26102;&#38388;&#27010;&#29575;&#25968;&#20540;ODE&#27714;&#35299;&#22120;&#12290;&#19982;&#24403;&#21069;&#30340;&#27010;&#29575;&#27714;&#35299;&#22120;&#20381;&#27425;&#25353;&#26102;&#38388;&#39034;&#24207;&#27169;&#25311;&#21160;&#21147;&#31995;&#32479;&#19981;&#21516;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20197;&#24182;&#34892;&#26041;&#24335;&#22788;&#29702;&#25152;&#26377;&#26102;&#38388;&#27493;&#39588;&#65292;&#20174;&#32780;&#23558;&#26102;&#38388;&#24320;&#38144;&#20174;&#32447;&#24615;&#38477;&#20302;&#21040;&#23545;&#25968;&#32423;&#21035;&#30340;&#26102;&#38388;&#27493;&#39588;&#25968;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;&#22810;&#31181;&#38382;&#39064;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Probabilistic numerical solvers for ordinary differential equations (ODEs) treat the numerical simulation of dynamical systems as problems of Bayesian state estimation. Aside from producing posterior distributions over ODE solutions and thereby quantifying the numerical approximation error of the method itself, one less-often noted advantage of this formalism is the algorithmic flexibility gained by formulating numerical simulation in the framework of Bayesian filtering and smoothing. In this paper, we leverage this flexibility and build on the time-parallel formulation of iterated extended Kalman smoothers to formulate a parallel-in-time probabilistic numerical ODE solver. Instead of simulating the dynamical system sequentially in time, as done by current probabilistic solvers, the proposed method processes all time steps in parallel and thereby reduces the span cost from linear to logarithmic in the number of time steps. We demonstrate the effectiveness of our approach on a variety o
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#40723;&#21169;&#30446;&#26631;&#22495;&#20013;&#30340;&#39044;&#27979;&#19982;&#20854;&#21069;&#20960;&#20010;&#22855;&#24322;&#21521;&#37327;&#23545;&#40784;&#26469;&#23454;&#29616;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;&#36825;&#20010;&#26041;&#27861;&#36890;&#36807;&#27491;&#21017;&#21270;&#20998;&#31867;&#22120;&#19982;&#26080;&#30417;&#30563;&#30446;&#26631;&#25968;&#25454;&#23545;&#40784;&#65292;&#32780;&#19981;&#26159;&#27491;&#21017;&#21270;&#34920;&#31034;&#12290;&#36890;&#36807;&#28040;&#38500;&#23545;&#26368;&#20248;&#32852;&#21512;&#39118;&#38505;&#20551;&#35774;&#30340;&#20381;&#36182;&#65292;&#35813;&#26041;&#27861;&#23637;&#31034;&#20102;&#24456;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2211.14960</link><description>&lt;p&gt;
&#20998;&#24067;&#20559;&#31227;&#30340;&#26631;&#31614;&#23545;&#40784;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Label Alignment Regularization for Distribution Shift. (arXiv:2211.14960v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.14960
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#40723;&#21169;&#30446;&#26631;&#22495;&#20013;&#30340;&#39044;&#27979;&#19982;&#20854;&#21069;&#20960;&#20010;&#22855;&#24322;&#21521;&#37327;&#23545;&#40784;&#26469;&#23454;&#29616;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;&#36825;&#20010;&#26041;&#27861;&#36890;&#36807;&#27491;&#21017;&#21270;&#20998;&#31867;&#22120;&#19982;&#26080;&#30417;&#30563;&#30446;&#26631;&#25968;&#25454;&#23545;&#40784;&#65292;&#32780;&#19981;&#26159;&#27491;&#21017;&#21270;&#34920;&#31034;&#12290;&#36890;&#36807;&#28040;&#38500;&#23545;&#26368;&#20248;&#32852;&#21512;&#39118;&#38505;&#20551;&#35774;&#30340;&#20381;&#36182;&#65292;&#35813;&#26041;&#27861;&#23637;&#31034;&#20102;&#24456;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#24378;&#35843;&#20102;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#26631;&#31614;&#23545;&#40784;&#23646;&#24615;&#65288;LAP&#65289;&#65292;&#21363;&#25968;&#25454;&#38598;&#20013;&#25152;&#26377;&#26631;&#31614;&#30340;&#21521;&#37327;&#22823;&#37096;&#20998;&#22312;&#25968;&#25454;&#30697;&#38453;&#30340;&#21069;&#20960;&#20010;&#22855;&#24322;&#21521;&#37327;&#30340;&#24352;&#25104;&#31354;&#38388;&#20869;&#12290;&#21463;&#21040;&#36825;&#19968;&#35266;&#23519;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#40723;&#21169;&#30446;&#26631;&#22495;&#20013;&#30340;&#39044;&#27979;&#19982;&#20854;&#21069;&#20960;&#20010;&#22855;&#24322;&#21521;&#37327;&#23545;&#40784;&#12290;&#19982;&#20256;&#32479;&#30340;&#39046;&#22495;&#36866;&#24212;&#26041;&#27861;&#19987;&#27880;&#20110;&#27491;&#21017;&#21270;&#34920;&#31034;&#19981;&#21516;&#65292;&#25105;&#20204;&#30456;&#21453;&#65292;&#36890;&#36807;&#22312;&#28304;&#22495;&#21644;&#30446;&#26631;&#22495;&#20013;&#20351;&#29992;LAP&#65292;&#29992;&#27491;&#21017;&#21270;&#20998;&#31867;&#22120;&#19982;&#26080;&#30417;&#30563;&#30446;&#26631;&#25968;&#25454;&#23545;&#40784;&#12290;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;&#22312;&#19968;&#23450;&#30340;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#30340;&#35299;&#20915;&#26041;&#26696;&#20301;&#20110;&#30446;&#26631;&#22495;&#25968;&#25454;&#30340;&#21069;&#20960;&#20010;&#21491;&#22855;&#24322;&#21521;&#37327;&#30340;&#24352;&#25104;&#31354;&#38388;&#20869;&#65292;&#24182;&#19982;&#26368;&#20248;&#35299;&#23545;&#40784;&#12290;&#36890;&#36807;&#28040;&#38500;&#32463;&#20856;&#39046;&#22495;&#36866;&#24212;&#29702;&#35770;&#20013;&#24120;&#35265;&#30340;&#26368;&#20248;&#32852;&#21512;&#39118;&#38505;&#20551;&#35774;&#30340;&#20381;&#36182;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent work has highlighted the label alignment property (LAP) in supervised learning, where the vector of all labels in the dataset is mostly in the span of the top few singular vectors of the data matrix. Drawing inspiration from this observation, we propose a regularization method for unsupervised domain adaptation that encourages alignment between the predictions in the target domain and its top singular vectors. Unlike conventional domain adaptation approaches that focus on regularizing representations, we instead regularize the classifier to align with the unsupervised target data, guided by the LAP in both the source and target domains. Theoretical analysis demonstrates that, under certain assumptions, our solution resides within the span of the top right singular vectors of the target domain data and aligns with the optimal solution. By removing the reliance on the commonly used optimal joint risk assumption found in classic domain adaptation theory, we showcase the effectivene
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#32452;&#20302;&#22797;&#26434;&#24230;&#20998;&#31867;&#22120;&#65292;&#35813;&#20998;&#31867;&#22120;&#21487;&#20197;&#36817;&#20284;&#20110;&#20219;&#24847;&#36830;&#32493;&#20989;&#25968;&#21644;&#24067;&#23572;&#20989;&#25968;&#65292;&#19988;&#22312;&#32473;&#23450;&#31867;&#26465;&#20214;&#23494;&#24230;&#30340;&#24773;&#20917;&#19979;&#65292;&#20854;&#35823;&#24046;&#19982;&#26368;&#20248;&#35823;&#24046;&#30456;&#21516;&#12290;</title><link>http://arxiv.org/abs/2108.06339</link><description>&lt;p&gt;
&#38543;&#26426;&#25237;&#24433;&#20998;&#31867;&#30340;&#26368;&#20248;&#24615;&#21644;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Optimality and complexity of classification by random projection. (arXiv:2108.06339v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2108.06339
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#32452;&#20302;&#22797;&#26434;&#24230;&#20998;&#31867;&#22120;&#65292;&#35813;&#20998;&#31867;&#22120;&#21487;&#20197;&#36817;&#20284;&#20110;&#20219;&#24847;&#36830;&#32493;&#20989;&#25968;&#21644;&#24067;&#23572;&#20989;&#25968;&#65292;&#19988;&#22312;&#32473;&#23450;&#31867;&#26465;&#20214;&#23494;&#24230;&#30340;&#24773;&#20917;&#19979;&#65292;&#20854;&#35823;&#24046;&#19982;&#26368;&#20248;&#35823;&#24046;&#30456;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#31867;&#22120;&#30340;&#27867;&#21270;&#35823;&#24046;&#19982;&#36873;&#25321;&#20998;&#31867;&#22120;&#30340;&#20989;&#25968;&#38598;&#30340;&#22797;&#26434;&#24230;&#26377;&#20851;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#32452;&#20302;&#22797;&#26434;&#24230;&#20998;&#31867;&#22120;&#65292;&#21253;&#25324;&#36890;&#36807;&#38543;&#26426;&#19968;&#32500;&#29305;&#24449;&#20570;&#38408;&#20540;&#22788;&#29702;&#12290;&#35813;&#29305;&#24449;&#36890;&#36807;&#23558;&#25968;&#25454;&#23884;&#20837;&#21040;&#30001;&#39640;&#27425;&#21333;&#39033;&#24335;&#21442;&#25968;&#21270;&#30340;&#26356;&#39640;&#32500;&#31354;&#38388;&#20013;&#21518;&#22312;&#38543;&#26426;&#30452;&#32447;&#19978;&#36827;&#34892;&#25237;&#24433;&#32780;&#24471;&#21040;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25193;&#23637;&#30340;&#25968;&#25454;&#34987;&#25237;&#24433;n&#27425;&#65292;&#24182;&#20174;&#36825;n&#20010;&#20013;&#36873;&#20986;&#34920;&#29616;&#22312;&#35757;&#32451;&#25968;&#25454;&#19978;&#26368;&#22909;&#30340;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#31867;&#22411;&#30340;&#20998;&#31867;&#22120;&#26159;&#26497;&#20854;&#28789;&#27963;&#30340;&#65292;&#22240;&#20026;&#23427;&#26377;&#21487;&#33021;&#36817;&#20284;&#20110;&#20219;&#20309;&#22312;&#32039;&#33268;&#38598;&#19978;&#30340;&#36830;&#32493;&#20989;&#25968;&#65292;&#20197;&#21450;&#23558;&#25903;&#25745;&#38598;&#25286;&#20998;&#20026;&#21487;&#27979;&#23376;&#38598;&#30340;&#20219;&#20309;&#24067;&#23572;&#20989;&#25968;&#12290;&#29305;&#21035;&#22320;&#65292;&#22914;&#26524;&#32473;&#23450;&#31867;&#26465;&#20214;&#23494;&#24230;&#30340;&#23436;&#20840;&#30693;&#35782;&#65292;&#21017;&#36825;&#20123;&#20302;&#22797;&#26434;&#24230;&#20998;&#31867;&#22120;&#30340;&#35823;&#24046;&#23558;&#22312;k&#21644;n&#36235;&#36817;&#20110;&#26080;&#31351;&#22823;&#26102;&#25910;&#25947;&#21040;&#26368;&#20248;&#65288;&#36125;&#21494;&#26031;&#65289;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
The generalization error of a classifier is related to the complexity of the set of functions among which the classifier is chosen. We study a family of low-complexity classifiers consisting of thresholding a random one-dimensional feature. The feature is obtained by projecting the data on a random line after embedding it into a higher-dimensional space parametrized by monomials of order up to k. More specifically, the extended data is projected n-times and the best classifier among those n, based on its performance on training data, is chosen. We show that this type of classifier is extremely flexible, as it is likely to approximate, to an arbitrary precision, any continuous function on a compact set as well as any boolean function on a compact set that splits the support into measurable subsets. In particular, given full knowledge of the class conditional densities, the error of these low-complexity classifiers would converge to the optimal (Bayes) error as k and n go to infinity. On
&lt;/p&gt;</description></item></channel></rss>