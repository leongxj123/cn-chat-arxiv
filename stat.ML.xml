<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;HyperBERT&#27169;&#22411;&#65292;&#36890;&#36807;&#22312;&#39044;&#35757;&#32451;&#30340;BERT&#27169;&#22411;&#20013;&#24341;&#20837;&#36229;&#22270;&#24863;&#30693;&#23618;&#65292;&#20811;&#26381;&#20102;&#29616;&#26377;&#26041;&#27861;&#22312;&#33410;&#28857;&#20998;&#31867;&#20219;&#21153;&#19978;&#38590;&#20197;&#25429;&#25417;&#36229;&#22270;&#32467;&#26500;&#20449;&#24687;&#21644;&#25991;&#26412;&#23646;&#24615;&#30340;&#23616;&#38480;&#24615;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#25928;&#26524;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.07309</link><description>&lt;p&gt;
HyperBERT:&#23558;&#28151;&#21512;&#36229;&#22270;&#24863;&#30693;&#23618;&#19982;&#35821;&#35328;&#27169;&#22411;&#29992;&#20110;&#25991;&#26412;&#23646;&#24615;&#36229;&#22270;&#19978;&#30340;&#33410;&#28857;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
HyperBERT: Mixing Hypergraph-Aware Layers with Language Models for Node Classification on Text-Attributed Hypergraphs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07309
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;HyperBERT&#27169;&#22411;&#65292;&#36890;&#36807;&#22312;&#39044;&#35757;&#32451;&#30340;BERT&#27169;&#22411;&#20013;&#24341;&#20837;&#36229;&#22270;&#24863;&#30693;&#23618;&#65292;&#20811;&#26381;&#20102;&#29616;&#26377;&#26041;&#27861;&#22312;&#33410;&#28857;&#20998;&#31867;&#20219;&#21153;&#19978;&#38590;&#20197;&#25429;&#25417;&#36229;&#22270;&#32467;&#26500;&#20449;&#24687;&#21644;&#25991;&#26412;&#23646;&#24615;&#30340;&#23616;&#38480;&#24615;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#25928;&#26524;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36229;&#22270;&#36890;&#36807;&#22797;&#26434;&#30340;&#25299;&#25169;&#32467;&#26500;&#26631;&#35760;&#65292;&#34920;&#36798;&#22810;&#20010;&#23454;&#20307;&#20043;&#38388;&#30340;&#39640;&#38454;&#30456;&#20114;&#20316;&#29992;&#65292;&#20854;&#20013;&#36229;&#36793;&#25198;&#28436;&#37325;&#35201;&#35282;&#33394;&#12290;&#26368;&#36817;&#65292;&#22522;&#20110;&#36229;&#22270;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#22312;&#23398;&#20064;&#25991;&#26412;&#23646;&#24615;&#36229;&#22270;&#19978;&#30340;&#33410;&#28857;&#20998;&#31867;&#38382;&#39064;&#20013;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#30740;&#31350;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#24448;&#24448;&#38590;&#20197;&#21516;&#26102;&#25429;&#25417;&#36229;&#22270;&#32467;&#26500;&#20449;&#24687;&#30340;&#20840;&#37096;&#20869;&#23481;&#21644;&#33410;&#28857;&#23646;&#24615;&#20013;&#30340;&#20016;&#23500;&#35821;&#35328;&#23646;&#24615;&#65292;&#36825;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#24433;&#21709;&#20102;&#23427;&#20204;&#30340;&#25928;&#26524;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#22914;&#20309;&#36890;&#36807;&#20026;&#33410;&#28857;&#20998;&#31867;&#20219;&#21153;&#36827;&#19968;&#27493;&#22686;&#24378;&#39044;&#35757;&#32451;&#30340;BERT&#27169;&#22411;&#65292;&#24341;&#20837;&#19987;&#38376;&#30340;&#36229;&#22270;&#24863;&#30693;&#23618;&#12290;&#36825;&#20123;&#23618;&#23558;&#39640;&#38454;&#32467;&#26500;&#24402;&#32435;&#20559;&#24046;&#24341;&#20837;&#35821;&#35328;&#27169;&#22411;&#20013;&#65292;&#20174;&#32780;&#25552;&#39640;&#27169;&#22411;&#21033;&#29992;&#36229;&#22270;&#32467;&#26500;&#20013;&#30340;&#39640;&#38454;&#19978;&#19979;&#25991;&#20449;&#24687;&#21644;&#25991;&#26412;&#20013;&#30340;&#35821;&#20041;&#20449;&#24687;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hypergraphs are marked by complex topology, expressing higher-order interactions among multiple entities with hyperedges. Lately, hypergraph-based deep learning methods to learn informative data representations for the problem of node classification on text-attributed hypergraphs have garnered increasing research attention. However, existing methods struggle to simultaneously capture the full extent of hypergraph structural information and the rich linguistic attributes inherent in the nodes attributes, which largely hampers their effectiveness and generalizability. To overcome these challenges, we explore ways to further augment a pretrained BERT model with specialized hypergraph-aware layers for the task of node classification. Such layers introduce higher-order structural inductive bias into the language model, thus improving the model's capacity to harness both higher-order context information from the hypergraph structure and semantic information present in text. In this paper, we
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;Rademacher&#22797;&#26434;&#24230;&#30340;&#26041;&#27861;&#22312;&#23545;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#23569;&#31867;&#21035;&#22270;&#20687;&#20998;&#31867;&#26102;&#29983;&#25104;&#38750;&#31354;&#27867;&#21270;&#30028;&#38480;&#12290;&#20854;&#20013;&#30340;&#20851;&#38190;&#25216;&#26415;&#36129;&#29486;&#26159;&#21457;&#23637;&#20102;&#38024;&#23545;&#20989;&#25968;&#31354;&#38388;&#21644;&#20855;&#26377;&#19968;&#33324;Lipschitz&#28608;&#27963;&#20989;&#25968;&#30340;CNNs&#30340;&#26032;&#30340;Talagrand&#21387;&#32553;&#24341;&#29702;&#12290;</title><link>https://arxiv.org/abs/2208.04284</link><description>&lt;p&gt;
&#22522;&#20110;Rademacher&#22797;&#26434;&#24230;&#30340;&#28145;&#24230;&#23398;&#20064;&#19968;&#33324;&#21270;&#30028;&#38480;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Rademacher Complexity-based Generalization Bounds for Deep Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2208.04284
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;Rademacher&#22797;&#26434;&#24230;&#30340;&#26041;&#27861;&#22312;&#23545;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#23569;&#31867;&#21035;&#22270;&#20687;&#20998;&#31867;&#26102;&#29983;&#25104;&#38750;&#31354;&#27867;&#21270;&#30028;&#38480;&#12290;&#20854;&#20013;&#30340;&#20851;&#38190;&#25216;&#26415;&#36129;&#29486;&#26159;&#21457;&#23637;&#20102;&#38024;&#23545;&#20989;&#25968;&#31354;&#38388;&#21644;&#20855;&#26377;&#19968;&#33324;Lipschitz&#28608;&#27963;&#20989;&#25968;&#30340;CNNs&#30340;&#26032;&#30340;Talagrand&#21387;&#32553;&#24341;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23637;&#31034;&#20102;&#22522;&#20110;Rademacher&#22797;&#26434;&#24230;&#30340;&#26041;&#27861;&#21487;&#20197;&#29983;&#25104;&#23545;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNNs&#65289;&#36827;&#34892;&#20998;&#31867;&#23569;&#37327;&#31867;&#21035;&#22270;&#20687;&#38750;&#31354;&#27867;&#21270;&#30028;&#38480;&#12290;&#26032;&#30340;Talagrand&#21387;&#32553;&#24341;&#29702;&#30340;&#21457;&#23637;&#23545;&#20110;&#39640;&#32500;&#26144;&#23556;&#20989;&#25968;&#31354;&#38388;&#21644;&#20855;&#26377;&#19968;&#33324;Lipschitz&#28608;&#27963;&#20989;&#25968;&#30340;CNNs&#26159;&#19968;&#20010;&#20851;&#38190;&#25216;&#26415;&#36129;&#29486;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;Rademacher&#22797;&#26434;&#24230;&#19981;&#20381;&#36182;&#20110;CNNs&#30340;&#32593;&#32476;&#38271;&#24230;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#35832;&#22914;ReLU&#65292;Leaky ReLU&#65292;Parametric Rectifier Linear Unit&#65292;Sigmoid&#21644;Tanh&#31561;&#29305;&#23450;&#31867;&#22411;&#30340;&#28608;&#27963;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
We show that the Rademacher complexity-based approach can generate non-vacuous generalisation bounds on Convolutional Neural Networks (CNNs) for classifying a small number of classes of images. The development of new Talagrand's contraction lemmas for high-dimensional mappings between function spaces and CNNs for general Lipschitz activation functions is a key technical contribution. Our results show that the Rademacher complexity does not depend on the network length for CNNs with some special types of activation functions such as ReLU, Leaky ReLU, Parametric Rectifier Linear Unit, Sigmoid, and Tanh.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#20855;&#26377;&#21644;&#27809;&#26377;&#31454;&#20105;&#39118;&#38505;&#30340;&#29983;&#23384;&#32467;&#26524;&#30340;&#25130;&#23614;&#26080;&#20559;&#21464;&#25442;&#26041;&#27861;&#65292;&#21487;&#20197;&#20272;&#35745;&#24322;&#36136;&#27835;&#30103;&#25928;&#24212;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#26356;&#22810;&#26368;&#20808;&#36827;&#30340;&#36866;&#29992;&#20110;&#34987;&#25130;&#23614;&#32467;&#26524;&#30340;HTE&#23398;&#20064;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#38480;&#21046;&#26377;&#38480;&#26679;&#26412;&#36807;&#24230;&#39118;&#38505;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.11263</link><description>&lt;p&gt;
&#36890;&#36807;&#65288;&#27491;&#20132;&#65289;&#23436;&#20840;&#26080;&#20559;&#30340;&#25130;&#23614;&#23398;&#20064;&#26469;&#20272;&#35745;&#29983;&#23384;&#32467;&#26524;&#30340;&#24322;&#36136;&#27835;&#30103;&#25928;&#24212;
&lt;/p&gt;
&lt;p&gt;
Estimating heterogeneous treatment effect from survival outcomes via (orthogonal) censoring unbiased learning. (arXiv:2401.11263v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11263
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#20855;&#26377;&#21644;&#27809;&#26377;&#31454;&#20105;&#39118;&#38505;&#30340;&#29983;&#23384;&#32467;&#26524;&#30340;&#25130;&#23614;&#26080;&#20559;&#21464;&#25442;&#26041;&#27861;&#65292;&#21487;&#20197;&#20272;&#35745;&#24322;&#36136;&#27835;&#30103;&#25928;&#24212;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#26356;&#22810;&#26368;&#20808;&#36827;&#30340;&#36866;&#29992;&#20110;&#34987;&#25130;&#23614;&#32467;&#26524;&#30340;HTE&#23398;&#20064;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#38480;&#21046;&#26377;&#38480;&#26679;&#26412;&#36807;&#24230;&#39118;&#38505;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#35266;&#23519;&#25968;&#25454;&#20013;&#20272;&#35745;&#24322;&#36136;&#27835;&#30103;&#25928;&#24212;&#65288;HTE&#65289;&#30340;&#26041;&#27861;&#20027;&#35201;&#38598;&#20013;&#22312;&#36830;&#32493;&#25110;&#20108;&#20803;&#32467;&#26524;&#19978;&#65292;&#36739;&#23569;&#20851;&#27880;&#29983;&#23384;&#32467;&#26524;&#65292;&#20960;&#20046;&#27809;&#26377;&#20851;&#27880;&#31454;&#20105;&#39118;&#38505;&#24773;&#26223;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#36866;&#29992;&#20110;&#20855;&#26377;&#21644;&#27809;&#26377;&#31454;&#20105;&#39118;&#38505;&#30340;&#29983;&#23384;&#32467;&#26524;&#30340;&#25130;&#23614;&#26080;&#20559;&#21464;&#25442;&#65288;CUTs&#65289;&#12290;&#20351;&#29992;&#36825;&#20123;CUTs&#23558;&#26102;&#38388;&#21040;&#20107;&#20214;&#32467;&#26524;&#36716;&#25442;&#21518;&#65292;&#23545;&#36830;&#32493;&#32467;&#26524;&#30340;HTE&#23398;&#20064;&#26041;&#27861;&#30340;&#30452;&#25509;&#24212;&#29992;&#21487;&#20197;&#20135;&#29983;&#19968;&#33268;&#20272;&#35745;&#30340;&#24322;&#36136;&#32047;&#31215;&#21457;&#29983;&#29575;&#25928;&#24212;&#12289;&#24635;&#25928;&#24212;&#21644;&#21487;&#20998;&#31163;&#30452;&#25509;&#25928;&#24212;&#12290;&#25105;&#20204;&#30340;CUTs&#21487;&#20197;&#20351;&#29992;&#27604;&#20197;&#21069;&#26356;&#22810;&#30340;&#26368;&#20808;&#36827;&#30340;&#36866;&#29992;&#20110;&#34987;&#25130;&#23614;&#32467;&#26524;&#30340;HTE&#23398;&#20064;&#26041;&#27861;&#65292;&#29305;&#21035;&#26159;&#22312;&#31454;&#20105;&#39118;&#38505;&#24773;&#26223;&#19979;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#36890;&#29992;&#30340;&#26080;&#27169;&#22411;&#23398;&#20064;&#29305;&#23450;oracle&#19981;&#31561;&#24335;&#26469;&#38480;&#21046;&#26377;&#38480;&#26679;&#26412;&#30340;&#36807;&#24230;&#39118;&#38505;&#12290;oracle&#25928;&#29575;&#32467;&#26524;&#21462;&#20915;&#20110;&#19968;&#20010;oracle&#36873;&#25321;&#22120;&#21644;&#20174;&#25152;&#26377;&#27493;&#39588;&#20013;&#20272;&#35745;&#30340;&#24178;&#25200;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Methods for estimating heterogeneous treatment effects (HTE) from observational data have largely focused on continuous or binary outcomes, with less attention paid to survival outcomes and almost none to settings with competing risks. In this work, we develop censoring unbiased transformations (CUTs) for survival outcomes both with and without competing risks.After converting time-to-event outcomes using these CUTs, direct application of HTE learners for continuous outcomes yields consistent estimates of heterogeneous cumulative incidence effects, total effects, and separable direct effects. Our CUTs enable application of a much larger set of state of the art HTE learners for censored outcomes than had previously been available, especially in competing risks settings. We provide generic model-free learner-specific oracle inequalities bounding the finite-sample excess risk. The oracle efficiency results depend on the oracle selector and estimated nuisance functions from all steps invol
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#23574;&#23792;&#21327;&#26041;&#24046;&#27169;&#22411;&#20013;&#30340;&#26368;&#20248;&#24046;&#20998;&#38544;&#31169;&#20027;&#25104;&#20998;&#20998;&#26512;&#21644;&#21327;&#26041;&#24046;&#20272;&#35745;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#39640;&#25928;&#30340;&#24046;&#20998;&#38544;&#31169;&#20272;&#35745;&#22120;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#26368;&#23567;&#26368;&#22823;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.03820</link><description>&lt;p&gt;
&#22312;&#24102;&#26377;&#23574;&#23792;&#21327;&#26041;&#24046;&#30697;&#38453;&#20013;&#30340;&#26368;&#20248;&#24046;&#20998;&#38544;&#31169;&#20027;&#25104;&#20998;&#20998;&#26512;&#21644;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Optimal Differentially Private PCA and Estimation for Spiked Covariance Matrices. (arXiv:2401.03820v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03820
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#23574;&#23792;&#21327;&#26041;&#24046;&#27169;&#22411;&#20013;&#30340;&#26368;&#20248;&#24046;&#20998;&#38544;&#31169;&#20027;&#25104;&#20998;&#20998;&#26512;&#21644;&#21327;&#26041;&#24046;&#20272;&#35745;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#39640;&#25928;&#30340;&#24046;&#20998;&#38544;&#31169;&#20272;&#35745;&#22120;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#26368;&#23567;&#26368;&#22823;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24403;&#20195;&#32479;&#35745;&#23398;&#20013;&#65292;&#20272;&#35745;&#21327;&#26041;&#24046;&#30697;&#38453;&#21450;&#20854;&#30456;&#20851;&#30340;&#20027;&#25104;&#20998;&#26159;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#12290;&#23613;&#31649;&#24050;&#24320;&#21457;&#20986;&#20855;&#26377;&#33391;&#22909;&#24615;&#36136;&#30340;&#26368;&#20248;&#20272;&#35745;&#31243;&#24207;&#65292;&#20294;&#23545;&#38544;&#31169;&#20445;&#25252;&#30340;&#22686;&#21152;&#38656;&#27714;&#32473;&#36825;&#20010;&#32463;&#20856;&#38382;&#39064;&#24341;&#20837;&#20102;&#26032;&#30340;&#22797;&#26434;&#24615;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#23574;&#23792;&#21327;&#26041;&#24046;&#27169;&#22411;&#20013;&#30340;&#26368;&#20248;&#24046;&#20998;&#38544;&#31169;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#21644;&#21327;&#26041;&#24046;&#20272;&#35745;&#12290;&#25105;&#20204;&#31934;&#30830;&#22320;&#21051;&#30011;&#20102;&#22312;&#35813;&#27169;&#22411;&#19979;&#29305;&#24449;&#20540;&#21644;&#29305;&#24449;&#21521;&#37327;&#30340;&#25935;&#24863;&#24615;&#65292;&#24182;&#24314;&#31435;&#20102;&#20272;&#35745;&#20027;&#25104;&#20998;&#21644;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#26368;&#23567;&#26368;&#22823;&#25910;&#25947;&#29575;&#12290;&#36825;&#20123;&#25910;&#25947;&#29575;&#21253;&#25324;&#19968;&#33324;&#30340;Schatten&#33539;&#25968;&#65292;&#21253;&#25324;&#35889;&#33539;&#25968;&#65292;Frobenius&#33539;&#25968;&#21644;&#26680;&#33539;&#25968;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#35745;&#31639;&#39640;&#25928;&#30340;&#24046;&#20998;&#38544;&#31169;&#20272;&#35745;&#22120;&#65292;&#24182;&#35777;&#26126;&#23427;&#20204;&#30340;&#26368;&#23567;&#26368;&#22823;&#24615;&#65292;&#30452;&#21040;&#23545;&#25968;&#22240;&#23376;&#12290;&#21478;&#22806;&#65292;&#21305;&#37197;&#30340;minimax&#26368;&#23567;&#26368;&#22823;&#29575;&#20063;&#24471;&#21040;&#20102;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating a covariance matrix and its associated principal components is a fundamental problem in contemporary statistics. While optimal estimation procedures have been developed with well-understood properties, the increasing demand for privacy preservation introduces new complexities to this classical problem. In this paper, we study optimal differentially private Principal Component Analysis (PCA) and covariance estimation within the spiked covariance model.  We precisely characterize the sensitivity of eigenvalues and eigenvectors under this model and establish the minimax rates of convergence for estimating both the principal components and covariance matrix. These rates hold up to logarithmic factors and encompass general Schatten norms, including spectral norm, Frobenius norm, and nuclear norm as special cases.  We introduce computationally efficient differentially private estimators and prove their minimax optimality, up to logarithmic factors. Additionally, matching minimax l
&lt;/p&gt;</description></item><item><title>&#22312;&#20998;&#24067;&#24335;&#23398;&#20064;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#37327;&#23376;&#32593;&#32476;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#20351;&#29992;&#25351;&#25968;&#32423;&#36739;&#23569;&#30340;&#36890;&#20449;&#21644;&#30456;&#23545;&#36739;&#23567;&#30340;&#26102;&#38388;&#21644;&#31354;&#38388;&#22797;&#26434;&#24230;&#24320;&#38144;&#36827;&#34892;&#25512;&#29702;&#21644;&#35757;&#32451;&#12290;&#36825;&#26159;&#31532;&#19968;&#20010;&#23637;&#31034;&#20102;&#20855;&#26377;&#23494;&#38598;&#32463;&#20856;&#25968;&#25454;&#30340;&#36890;&#29992;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20855;&#26377;&#25351;&#25968;&#37327;&#23376;&#20248;&#21183;&#30340;&#20363;&#23376;&#12290;</title><link>http://arxiv.org/abs/2310.07136</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#23398;&#20064;&#20013;&#30340;&#25351;&#25968;&#37327;&#23376;&#36890;&#20449;&#20248;&#21183;
&lt;/p&gt;
&lt;p&gt;
Exponential Quantum Communication Advantage in Distributed Learning. (arXiv:2310.07136v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07136
&lt;/p&gt;
&lt;p&gt;
&#22312;&#20998;&#24067;&#24335;&#23398;&#20064;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#37327;&#23376;&#32593;&#32476;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#20351;&#29992;&#25351;&#25968;&#32423;&#36739;&#23569;&#30340;&#36890;&#20449;&#21644;&#30456;&#23545;&#36739;&#23567;&#30340;&#26102;&#38388;&#21644;&#31354;&#38388;&#22797;&#26434;&#24230;&#24320;&#38144;&#36827;&#34892;&#25512;&#29702;&#21644;&#35757;&#32451;&#12290;&#36825;&#26159;&#31532;&#19968;&#20010;&#23637;&#31034;&#20102;&#20855;&#26377;&#23494;&#38598;&#32463;&#20856;&#25968;&#25454;&#30340;&#36890;&#29992;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20855;&#26377;&#25351;&#25968;&#37327;&#23376;&#20248;&#21183;&#30340;&#20363;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#36229;&#36807;&#21333;&#20010;&#35774;&#22791;&#20869;&#23384;&#23481;&#37327;&#30340;&#22823;&#22411;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#35757;&#32451;&#21644;&#25512;&#29702;&#38656;&#35201;&#35774;&#35745;&#20998;&#24067;&#24335;&#26550;&#26500;&#65292;&#24517;&#39035;&#32771;&#34385;&#36890;&#20449;&#38480;&#21046;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#37327;&#23376;&#32593;&#32476;&#19978;&#36827;&#34892;&#20998;&#24067;&#24335;&#35745;&#31639;&#30340;&#26694;&#26550;&#65292;&#20854;&#20013;&#25968;&#25454;&#34987;&#32534;&#30721;&#20026;&#29305;&#27530;&#30340;&#37327;&#23376;&#24577;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#35813;&#26694;&#26550;&#20869;&#30340;&#26576;&#20123;&#27169;&#22411;&#20013;&#65292;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#36827;&#34892;&#25512;&#29702;&#21644;&#35757;&#32451;&#30340;&#36890;&#20449;&#24320;&#38144;&#30456;&#23545;&#20110;&#20854;&#32463;&#20856;&#23545;&#24212;&#27169;&#22411;&#21487;&#20197;&#25351;&#25968;&#32423;&#38477;&#20302;&#65292;&#24182;&#19988;&#30456;&#23545;&#20110;&#26631;&#20934;&#22522;&#20110;&#26799;&#24230;&#30340;&#26041;&#27861;&#65292;&#26102;&#38388;&#21644;&#31354;&#38388;&#22797;&#26434;&#24615;&#24320;&#38144;&#30456;&#23545;&#36739;&#23567;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#22312;&#20855;&#26377;&#23494;&#38598;&#32463;&#20856;&#25968;&#25454;&#30340;&#36890;&#29992;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#30340;&#24773;&#20917;&#19979;&#65292;&#26080;&#35770;&#25968;&#25454;&#32534;&#30721;&#25104;&#26412;&#22914;&#20309;&#65292;&#37117;&#20855;&#26377;&#25351;&#25968;&#37327;&#23376;&#20248;&#21183;&#30340;&#31034;&#20363;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#35813;&#31867;&#27169;&#22411;&#21487;&#20197;&#32534;&#30721;&#36755;&#20837;&#30340;&#39640;&#24230;&#38750;&#32447;&#24615;&#29305;&#24449;&#65292;&#24182;&#19988;&#23427;&#20204;&#30340;&#34920;&#36798;&#33021;&#21147;&#21576;&#25351;&#25968;&#22686;&#21152;&#12290;
&lt;/p&gt;
&lt;p&gt;
Training and inference with large machine learning models that far exceed the memory capacity of individual devices necessitates the design of distributed architectures, forcing one to contend with communication constraints. We present a framework for distributed computation over a quantum network in which data is encoded into specialized quantum states. We prove that for certain models within this framework, inference and training using gradient descent can be performed with exponentially less communication compared to their classical analogs, and with relatively modest time and space complexity overheads relative to standard gradient-based methods. To our knowledge, this is the first example of exponential quantum advantage for a generic class of machine learning problems with dense classical data that holds regardless of the data encoding cost. Moreover, we show that models in this class can encode highly nonlinear features of their inputs, and their expressivity increases exponenti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#21152;&#26435;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#20351;&#29992;&#25935;&#24863;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#20445;&#25252;&#38544;&#31169;&#12290;&#36825;&#26159;&#31532;&#19968;&#20010;&#22312;&#26435;&#37325;ERM&#20013;&#24212;&#29992;&#24046;&#20998;&#38544;&#31169;&#30340;&#31639;&#27861;&#65292;&#24182;&#19988;&#22312;&#19968;&#23450;&#30340;&#26465;&#20214;&#19979;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;DP&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2307.13127</link><description>&lt;p&gt;
&#19968;&#20010;&#24046;&#20998;&#38544;&#31169;&#21152;&#26435;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#31639;&#27861;&#21450;&#20854;&#22312;&#32467;&#26524;&#21152;&#26435;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
A Differentially Private Weighted Empirical Risk Minimization Procedure and its Application to Outcome Weighted Learning. (arXiv:2307.13127v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13127
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#21152;&#26435;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#20351;&#29992;&#25935;&#24863;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#20445;&#25252;&#38544;&#31169;&#12290;&#36825;&#26159;&#31532;&#19968;&#20010;&#22312;&#26435;&#37325;ERM&#20013;&#24212;&#29992;&#24046;&#20998;&#38544;&#31169;&#30340;&#31639;&#27861;&#65292;&#24182;&#19988;&#22312;&#19968;&#23450;&#30340;&#26465;&#20214;&#19979;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;DP&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;(ERM)&#26694;&#26550;&#20013;&#65292;&#20351;&#29992;&#21253;&#21547;&#20010;&#20154;&#20449;&#24687;&#30340;&#25968;&#25454;&#26469;&#26500;&#24314;&#39044;&#27979;&#27169;&#22411;&#26159;&#24120;&#35265;&#30340;&#20570;&#27861;&#12290;&#23613;&#31649;&#36825;&#20123;&#27169;&#22411;&#22312;&#39044;&#27979;&#19978;&#21487;&#20197;&#38750;&#24120;&#20934;&#30830;&#65292;&#20294;&#20351;&#29992;&#25935;&#24863;&#25968;&#25454;&#24471;&#21040;&#30340;&#32467;&#26524;&#21487;&#33021;&#23481;&#26131;&#21463;&#21040;&#38544;&#31169;&#25915;&#20987;&#12290;&#24046;&#20998;&#38544;&#31169;(DP)&#26159;&#19968;&#31181;&#26377;&#21560;&#24341;&#21147;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#36890;&#36807;&#25552;&#20379;&#25968;&#23398;&#19978;&#21487;&#35777;&#26126;&#30340;&#38544;&#31169;&#25439;&#22833;&#30028;&#38480;&#26469;&#35299;&#20915;&#36825;&#20123;&#25968;&#25454;&#38544;&#31169;&#38382;&#39064;&#12290;&#20808;&#21069;&#30340;&#24037;&#20316;&#20027;&#35201;&#38598;&#20013;&#22312;&#23558;DP&#24212;&#29992;&#20110;&#26080;&#26435;&#37325;&#30340;ERM&#20013;&#12290;&#25105;&#20204;&#32771;&#34385;&#21040;&#20102;&#26435;&#37325;ERM(wERM)&#30340;&#37325;&#35201;&#25512;&#24191;&#12290;&#22312;wERM&#20013;&#65292;&#21487;&#20197;&#20026;&#27599;&#20010;&#20010;&#20307;&#30340;&#30446;&#26631;&#20989;&#25968;&#36129;&#29486;&#20998;&#37197;&#19981;&#21516;&#30340;&#26435;&#37325;&#12290;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#26377;&#24046;&#20998;&#38544;&#31169;&#20445;&#38556;&#30340;wERM&#31639;&#27861;&#65292;&#24182;&#22312;&#19968;&#23450;&#30340;&#27491;&#21017;&#26465;&#20214;&#19979;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#29702;&#35770;&#35777;&#26126;&#12290;&#23558;&#29616;&#26377;&#30340;DP-ERM&#31243;&#24207;&#25193;&#23637;&#21040;wERM&#20026;&#32467;&#26524;&#21152;&#26435;&#23398;&#20064;&#38138;&#24179;&#20102;&#36947;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is commonplace to use data containing personal information to build predictive models in the framework of empirical risk minimization (ERM). While these models can be highly accurate in prediction, results obtained from these models with the use of sensitive data may be susceptible to privacy attacks. Differential privacy (DP) is an appealing framework for addressing such data privacy issues by providing mathematically provable bounds on the privacy loss incurred when releasing information from sensitive data. Previous work has primarily concentrated on applying DP to unweighted ERM. We consider an important generalization to weighted ERM (wERM). In wERM, each individual's contribution to the objective function can be assigned varying weights. In this context, we propose the first differentially private wERM algorithm, backed by a rigorous theoretical proof of its DP guarantees under mild regularity conditions. Extending the existing DP-ERM procedures to wERM paves a path to derivin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31163;&#32447;&#31574;&#30053;&#23398;&#20064;&#31639;&#27861;&#65292;&#23427;&#19981;&#38656;&#35201;&#32479;&#19968;&#20132;&#21472;&#20551;&#35774;&#65292;&#32780;&#26159;&#21033;&#29992;&#20215;&#20540;&#30340;&#19979;&#38480;&#32622;&#20449;&#21306;&#38388;&#65288;LCBs&#65289;&#20248;&#21270;&#31574;&#30053;&#65292;&#22240;&#27492;&#33021;&#22815;&#36866;&#24212;&#20801;&#35768;&#34892;&#20026;&#31574;&#30053;&#28436;&#21464;&#21644;&#20542;&#21521;&#24615;&#20943;&#24369;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2212.09900</link><description>&lt;p&gt;
&#26080;&#20132;&#21472;&#31574;&#30053;&#23398;&#20064;&#65306;&#24754;&#35266;&#21644;&#24191;&#20041;&#32463;&#39564;Bernstein&#19981;&#31561;&#24335;
&lt;/p&gt;
&lt;p&gt;
Policy learning "without'' overlap: Pessimism and generalized empirical Bernstein's inequality. (arXiv:2212.09900v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.09900
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31163;&#32447;&#31574;&#30053;&#23398;&#20064;&#31639;&#27861;&#65292;&#23427;&#19981;&#38656;&#35201;&#32479;&#19968;&#20132;&#21472;&#20551;&#35774;&#65292;&#32780;&#26159;&#21033;&#29992;&#20215;&#20540;&#30340;&#19979;&#38480;&#32622;&#20449;&#21306;&#38388;&#65288;LCBs&#65289;&#20248;&#21270;&#31574;&#30053;&#65292;&#22240;&#27492;&#33021;&#22815;&#36866;&#24212;&#20801;&#35768;&#34892;&#20026;&#31574;&#30053;&#28436;&#21464;&#21644;&#20542;&#21521;&#24615;&#20943;&#24369;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31163;&#32447;&#31574;&#30053;&#23398;&#20064;&#65292;&#26088;&#22312;&#21033;&#29992;&#20808;&#21069;&#25910;&#38598;&#21040;&#30340;&#35266;&#27979;&#65288;&#26469;&#33258;&#20110;&#22266;&#23450;&#30340;&#25110;&#26159;&#36866;&#24212;&#28436;&#21464;&#30340;&#34892;&#20026;&#31574;&#30053;&#65289;&#26469;&#23398;&#20064;&#32473;&#23450;&#31867;&#21035;&#20013;&#30340;&#26368;&#20248;&#20010;&#24615;&#21270;&#20915;&#31574;&#35268;&#21017;&#12290;&#29616;&#26377;&#30340;&#31574;&#30053;&#23398;&#20064;&#26041;&#27861;&#20381;&#36182;&#20110;&#19968;&#20010;&#32479;&#19968;&#20132;&#21472;&#20551;&#35774;&#65292;&#21363;&#31163;&#32447;&#25968;&#25454;&#38598;&#20013;&#25506;&#32034;&#25152;&#26377;&#20010;&#24615;&#21270;&#29305;&#24449;&#30340;&#25152;&#26377;&#21160;&#20316;&#30340;&#20542;&#21521;&#24615;&#19979;&#30028;&#12290;&#25442;&#21477;&#35805;&#35828;&#65292;&#36825;&#20123;&#26041;&#27861;&#30340;&#24615;&#33021;&#21462;&#20915;&#20110;&#31163;&#32447;&#25968;&#25454;&#38598;&#20013;&#26368;&#22351;&#30340;&#20542;&#21521;&#24615;&#12290;&#30001;&#20110;&#25968;&#25454;&#25910;&#38598;&#36807;&#31243;&#19981;&#21463;&#25511;&#21046;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#36825;&#31181;&#20551;&#35774;&#21487;&#33021;&#19981;&#22826;&#29616;&#23454;&#65292;&#29305;&#21035;&#26159;&#24403;&#20801;&#35768;&#34892;&#20026;&#31574;&#30053;&#38543;&#26102;&#38388;&#28436;&#21464;&#24182;&#19988;&#20542;&#21521;&#24615;&#20943;&#24369;&#26102;&#12290;&#20026;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#23427;&#20248;&#21270;&#31574;&#30053;&#20215;&#20540;&#30340;&#19979;&#38480;&#32622;&#20449;&#21306;&#38388;&#65288;LCBs&#65289;&#8212;&#8212;&#32780;&#19981;&#26159;&#28857;&#20272;&#35745;&#12290;LCBs&#36890;&#36807;&#37327;&#21270;&#22686;&#24378;&#20498;&#25968;&#20542;&#21521;&#26435;&#37325;&#30340;&#20272;&#35745;&#19981;&#30830;&#23450;&#24615;&#26469;&#26500;&#24314;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies offline policy learning, which aims at utilizing observations collected a priori (from either fixed or adaptively evolving behavior policies) to learn the optimal individualized decision rule in a given class. Existing policy learning methods rely on a uniform overlap assumption, i.e., the propensities of exploring all actions for all individual characteristics are lower bounded in the offline dataset. In other words, the performance of these methods depends on the worst-case propensity in the offline dataset. As one has no control over the data collection process, this assumption can be unrealistic in many situations, especially when the behavior policies are allowed to evolve over time with diminishing propensities.  In this paper, we propose a new algorithm that optimizes lower confidence bounds (LCBs) -- instead of point estimates -- of the policy values. The LCBs are constructed by quantifying the estimation uncertainty of the augmented inverse propensity weight
&lt;/p&gt;</description></item></channel></rss>