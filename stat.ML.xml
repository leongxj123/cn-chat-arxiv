<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340; tamed interactive particle Langevin algorithms&#65288;tIPLA&#65289;&#31867;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#22810;&#39033;&#24335;&#22686;&#38271;&#24773;&#20917;&#19979;&#33719;&#24471;&#31283;&#23450;&#19988;&#20855;&#26377;&#26368;&#20339;&#36895;&#29575;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#35823;&#24046;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2403.19587</link><description>&lt;p&gt;
&#39535;&#26381;&#20132;&#20114;&#24335;&#31890;&#23376; Langevin &#31639;&#27861; -- &#36229;&#32447;&#24615;&#24773;&#20917;
&lt;/p&gt;
&lt;p&gt;
Taming the Interactive Particle Langevin Algorithm -- the superlinear case
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19587
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340; tamed interactive particle Langevin algorithms&#65288;tIPLA&#65289;&#31867;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#22810;&#39033;&#24335;&#22686;&#38271;&#24773;&#20917;&#19979;&#33719;&#24471;&#31283;&#23450;&#19988;&#20855;&#26377;&#26368;&#20339;&#36895;&#29575;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#35823;&#24046;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22312;&#38543;&#26426;&#20248;&#21270;&#26041;&#38754;&#30340;&#36827;&#23637;&#20135;&#29983;&#20102;&#20132;&#20114;&#24335;&#31890;&#23376; Langevin &#31639;&#27861;&#65288;IPLA&#65289;&#65292;&#35813;&#31639;&#27861;&#21033;&#29992;&#20132;&#20114;&#31890;&#23376;&#31995;&#32479;&#65288;IPS&#65289;&#30340;&#27010;&#24565;&#26469;&#39640;&#25928;&#22320;&#20174;&#36817;&#20284;&#21518;&#39564;&#23494;&#24230;&#20013;&#25277;&#26679;&#12290;&#36825;&#22312;&#26399;&#26395;&#26368;&#22823;&#21270;&#65288;EM&#65289;&#26694;&#26550;&#20013;&#21464;&#24471;&#23588;&#20026;&#20851;&#38190;&#65292;&#20854;&#20013; E &#27493;&#39588;&#22312;&#35745;&#31639;&#19978;&#20855;&#26377;&#25361;&#25112;&#24615;&#29978;&#33267;&#26159;&#38590;&#20197;&#22788;&#29702;&#30340;&#12290;&#23613;&#31649;&#20808;&#21069;&#30340;&#30740;&#31350;&#20391;&#37325;&#20110;&#26799;&#24230;&#26368;&#22810;&#32447;&#24615;&#22686;&#38271;&#30340;&#20984;&#24773;&#20917;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#23558;&#27492;&#26694;&#26550;&#25193;&#23637;&#21040;&#21253;&#25324;&#22810;&#39033;&#24335;&#22686;&#38271;&#12290;&#37319;&#29992;&#39535;&#26381;&#25216;&#26415;&#29983;&#25104;&#26126;&#30830;&#30340;&#31163;&#25955;&#21270;&#26041;&#26696;&#65292;&#20174;&#32780;&#20135;&#29983;&#19968;&#31867;&#31283;&#23450;&#30340;&#12289;&#22312;&#36825;&#31181;&#38750;&#32447;&#24615;&#24773;&#20917;&#19979;&#65292;&#31216;&#20026;&#39535;&#26381;&#20132;&#20114;&#24335;&#31890;&#23376; Langevin &#31639;&#27861;&#65288;tIPLA&#65289;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#33719;&#24471;&#20102;&#26032;&#31867;&#22312; Wasserstein-2 &#36317;&#31163;&#19979;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#35823;&#24046;&#20272;&#35745;&#65292;&#20855;&#26377;&#26368;&#20339;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19587v1 Announce Type: cross  Abstract: Recent advances in stochastic optimization have yielded the interactive particle Langevin algorithm (IPLA), which leverages the notion of interacting particle systems (IPS) to efficiently sample from approximate posterior densities. This becomes particularly crucial within the framework of Expectation-Maximization (EM), where the E-step is computationally challenging or even intractable. Although prior research has focused on scenarios involving convex cases with gradients of log densities that grow at most linearly, our work extends this framework to include polynomial growth. Taming techniques are employed to produce an explicit discretization scheme that yields a new class of stable, under such non-linearities, algorithms which are called tamed interactive particle Langevin algorithms (tIPLA). We obtain non-asymptotic convergence error estimates in Wasserstein-2 distance for the new class under an optimal rate.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#23454;&#29992;&#25351;&#21335;&#65292;&#20171;&#32461;&#20102;&#22235;&#31181;&#24120;&#29992;&#32479;&#35745;&#36317;&#31163;&#30340;&#27010;&#24565;&#65292;&#20197;&#24110;&#21161;&#35780;&#20272;&#29983;&#25104;&#27169;&#22411;&#65292;&#26080;&#38656;&#39640;&#28145;&#30340;&#25968;&#23398;&#21644;&#32479;&#35745;&#30693;&#35782;&#12290;</title><link>https://arxiv.org/abs/2403.12636</link><description>&lt;p&gt;
&#29992;&#20110;&#31185;&#23398;&#20013;&#35780;&#20272;&#29983;&#25104;&#27169;&#22411;&#30340;&#32479;&#35745;&#36317;&#31163;&#30340;&#23454;&#29992;&#25351;&#21335;
&lt;/p&gt;
&lt;p&gt;
A Practical Guide to Statistical Distances for Evaluating Generative Models in Science
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12636
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#23454;&#29992;&#25351;&#21335;&#65292;&#20171;&#32461;&#20102;&#22235;&#31181;&#24120;&#29992;&#32479;&#35745;&#36317;&#31163;&#30340;&#27010;&#24565;&#65292;&#20197;&#24110;&#21161;&#35780;&#20272;&#29983;&#25104;&#27169;&#22411;&#65292;&#26080;&#38656;&#39640;&#28145;&#30340;&#25968;&#23398;&#21644;&#32479;&#35745;&#30693;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#27169;&#22411;&#22312;&#35768;&#22810;&#31185;&#23398;&#39046;&#22495;&#20013;&#26159;&#38750;&#24120;&#23453;&#36149;&#30340;&#65292;&#22240;&#20026;&#23427;&#20204;&#33021;&#22815;&#25429;&#25417;&#39640;&#32500;&#21644;&#22797;&#26434;&#30340;&#20998;&#24067;&#65292;&#20363;&#22914;&#36924;&#30495;&#30340;&#22270;&#20687;&#12289;&#34507;&#30333;&#36136;&#32467;&#26500;&#21644;&#36830;&#25509;&#32452;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#20026;&#29702;&#35299;&#27969;&#34892;&#30340;&#32479;&#35745;&#36317;&#31163;&#27010;&#24565;&#25552;&#20379;&#19968;&#20010;&#26131;&#20110;&#29702;&#35299;&#30340;&#20837;&#21475;&#28857;&#65292;&#21482;&#38656;&#35201;&#25968;&#23398;&#21644;&#32479;&#35745;&#23398;&#30340;&#22522;&#30784;&#30693;&#35782;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#20195;&#34920;&#19981;&#21516;&#26041;&#27861;&#35770;&#30340;&#22235;&#31181;&#24120;&#29992;&#32479;&#35745;&#36317;&#31163;&#27010;&#24565;&#65306;&#20351;&#29992;&#20302;&#32500;&#25237;&#24433;&#65288;Sliced-Wasserstein; SW)&#12289;&#20351;&#29992;&#20998;&#31867;&#22120;&#33719;&#21462;&#36317;&#31163;&#65288;Classifier Two-Sample Tests; C2ST)&#12289;&#36890;&#36807;&#26680;&#36827;&#34892;&#23884;&#20837;&#65288;Maximum Mean Discrepancy; MMD) &#25110;&#31070;&#32463;&#32593;&#32476;&#65288;Fr\'echet Inception Distance; FID)&#12290;&#25105;&#20204;&#24378;&#35843;&#27599;&#20010;&#36317;&#31163;&#32972;&#21518;&#30340;&#30452;&#35273;&#65292;&#24182;&#35299;&#37322;&#23427;&#20204;&#30340;&#20248;&#28857;&#12289;&#21487;&#20280;&#32553;&#24615;&#12289;&#22797;&#26434;&#24615;&#21644;&#32570;&#38519;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12636v1 Announce Type: new  Abstract: Generative models are invaluable in many fields of science because of their ability to capture high-dimensional and complicated distributions, such as photo-realistic images, protein structures, and connectomes. How do we evaluate the samples these models generate? This work aims to provide an accessible entry point to understanding popular notions of statistical distances, requiring only foundational knowledge in mathematics and statistics. We focus on four commonly used notions of statistical distances representing different methodologies: Using low-dimensional projections (Sliced-Wasserstein; SW), obtaining a distance using classifiers (Classifier Two-Sample Tests; C2ST), using embeddings through kernels (Maximum Mean Discrepancy; MMD), or neural networks (Fr\'echet Inception Distance; FID). We highlight the intuition behind each distance and explain their merits, scalability, complexity, and pitfalls. To demonstrate how these distanc
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#38024;&#23545;&#19977;&#31867;&#21464;&#20998;&#19981;&#31561;&#24335;&#38382;&#39064;&#25552;&#20986;&#20102;&#20855;&#26377;&#38543;&#26426;&#37325;&#25490;&#30340;&#38543;&#26426;&#22806;&#25512;&#27861;&#65288;SEG-RR&#65289;&#65292;&#24182;&#35777;&#26126;&#20854;&#22312;&#21333;&#35843;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#27604;&#22343;&#21248;&#26367;&#25442;&#37319;&#26679;SEG&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>https://arxiv.org/abs/2403.07148</link><description>&lt;p&gt;
&#20855;&#26377;&#38543;&#26426;&#37325;&#25490;&#30340;&#38543;&#26426;&#22806;&#25512;&#27861;&#65306;&#25913;&#36827;&#21464;&#20998;&#19981;&#31561;&#24335;&#30340;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Stochastic Extragradient with Random Reshuffling: Improved Convergence for Variational Inequalities
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07148
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#38024;&#23545;&#19977;&#31867;&#21464;&#20998;&#19981;&#31561;&#24335;&#38382;&#39064;&#25552;&#20986;&#20102;&#20855;&#26377;&#38543;&#26426;&#37325;&#25490;&#30340;&#38543;&#26426;&#22806;&#25512;&#27861;&#65288;SEG-RR&#65289;&#65292;&#24182;&#35777;&#26126;&#20854;&#22312;&#21333;&#35843;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#27604;&#22343;&#21248;&#26367;&#25442;&#37319;&#26679;SEG&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#22806;&#25512;&#27861;&#65288;SEG&#65289;&#26041;&#27861;&#26159;&#35299;&#20915;&#20986;&#29616;&#22312;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#26377;&#38480;&#27714;&#21644;&#26497;&#23567;-&#26497;&#22823;&#20248;&#21270;&#21644;&#21464;&#20998;&#19981;&#31561;&#24335;&#38382;&#39064;&#65288;VIPs&#65289;&#30340;&#26368;&#27969;&#34892;&#31639;&#27861;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;SEG&#25910;&#25947;&#20998;&#26512;&#19987;&#27880;&#20110;&#20854;&#24102;&#26367;&#25442;&#21464;&#20307;&#65292;&#32780;&#26041;&#27861;&#30340;&#23454;&#38469;&#23454;&#29616;&#20250;&#38543;&#26426;&#37325;&#26032;&#25490;&#21015;&#20998;&#37327;&#24182;&#25353;&#39034;&#24207;&#20351;&#29992;&#23427;&#20204;&#12290;&#19982;&#24191;&#20026;&#30740;&#31350;&#30340;&#24102;&#26367;&#25442;&#21464;&#20307;&#19981;&#21516;&#65292;&#20855;&#26377;&#38543;&#26426;&#37325;&#25490;&#30340;SEG&#65288;SEG-RR&#65289;&#32570;&#20047;&#24050;&#24314;&#31435;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#38024;&#23545;&#19977;&#31867;VIPs&#65288;i&#65289;&#24378;&#21333;&#35843;&#65292;&#65288;ii&#65289;&#20223;&#23556;&#21644;&#65288;iii&#65289;&#21333;&#35843;&#25552;&#20379;&#20102;SEG-RR&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;SEG-RR&#23454;&#29616;&#27604;&#22343;&#21248;&#24102;&#26367;&#25442;&#37319;&#26679;SEG&#20855;&#26377;&#26356;&#24555;&#25910;&#25947;&#36895;&#24230;&#30340;&#26465;&#20214;&#12290;&#22312;&#21333;&#35843;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#30340;SEG-RR&#20998;&#26512;&#20445;&#35777;&#20102;&#25910;&#25947;&#21040;&#20219;&#24847;&#31934;&#24230;&#32780;&#26080;&#38656;&#22823;&#25209;&#37327;&#22823;&#23567;&#65292;&#36825;&#26159;&#23545;&#22823;&#25209;&#37327;&#22823;&#23567;&#32780;&#35328;&#30340;&#24378;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07148v1 Announce Type: cross  Abstract: The Stochastic Extragradient (SEG) method is one of the most popular algorithms for solving finite-sum min-max optimization and variational inequality problems (VIPs) appearing in various machine learning tasks. However, existing convergence analyses of SEG focus on its with-replacement variants, while practical implementations of the method randomly reshuffle components and sequentially use them. Unlike the well-studied with-replacement variants, SEG with Random Reshuffling (SEG-RR) lacks established theoretical guarantees. In this work, we provide a convergence analysis of SEG-RR for three classes of VIPs: (i) strongly monotone, (ii) affine, and (iii) monotone. We derive conditions under which SEG-RR achieves a faster convergence rate than the uniform with-replacement sampling SEG. In the monotone setting, our analysis of SEG-RR guarantees convergence to an arbitrary accuracy without large batch sizes, a strong requirement needed in 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#22312;&#21160;&#24577;&#31995;&#32479;&#20013;&#21033;&#29992;&#26799;&#24230;&#19979;&#38477;&#36827;&#34892;&#30417;&#30563;&#23398;&#20064;&#30340;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#30340;&#24615;&#33021;&#65292;&#24182;&#35777;&#26126;&#22312;&#19981;&#38656;&#35201;&#28023;&#37327;&#36807;&#21442;&#25968;&#21270;&#30340;&#24773;&#20917;&#19979;&#65292;&#26799;&#24230;&#19979;&#38477;&#21487;&#20197;&#36798;&#21040;&#26368;&#20248;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.12241</link><description>&lt;p&gt;
&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#30340;&#26799;&#24230;&#19979;&#38477;&#25910;&#25947;&#24615;&#65306;&#38750;&#28176;&#36817;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Convergence of Gradient Descent for Recurrent Neural Networks: A Nonasymptotic Analysis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12241
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#22312;&#21160;&#24577;&#31995;&#32479;&#20013;&#21033;&#29992;&#26799;&#24230;&#19979;&#38477;&#36827;&#34892;&#30417;&#30563;&#23398;&#20064;&#30340;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#30340;&#24615;&#33021;&#65292;&#24182;&#35777;&#26126;&#22312;&#19981;&#38656;&#35201;&#28023;&#37327;&#36807;&#21442;&#25968;&#21270;&#30340;&#24773;&#20917;&#19979;&#65292;&#26799;&#24230;&#19979;&#38477;&#21487;&#20197;&#36798;&#21040;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20998;&#26512;&#22312;&#30417;&#30563;&#23398;&#20064;&#35774;&#32622;&#19979;&#21033;&#29992;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#22312;&#21160;&#24577;&#31995;&#32479;&#20013;&#30340;&#34920;&#29616;&#65292;&#24182;&#35777;&#26126;&#26799;&#24230;&#19979;&#38477;&#21487;&#20197;&#22312;\emph{&#19981;}&#38656;&#35201;&#28023;&#37327;&#36807;&#21442;&#25968;&#21270;&#30340;&#24773;&#20917;&#19979;&#36798;&#21040;&#26368;&#20248;&#24615;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#28145;&#20837;&#30340;&#38750;&#28176;&#36817;&#24615;&#20998;&#26512;&#65292;(i)&#21033;&#29992;&#24207;&#21015;&#38271;&#24230;$T$&#12289;&#26679;&#26412;&#22823;&#23567;$n$&#21644;&#29615;&#22659;&#32500;&#24230;$d$&#32473;&#20986;&#20102;&#32593;&#32476;&#22823;&#23567;$m$&#21644;&#36845;&#20195;&#22797;&#26434;&#24230;$\tau$&#30340;&#23574;&#38160;&#30028;&#38480;&#65292;(ii)&#30830;&#23450;&#20102;&#21160;&#24577;&#31995;&#32479;&#20013;&#38271;&#26399;&#20381;&#36182;&#23545;&#25910;&#25947;&#21644;&#32593;&#32476;&#23485;&#24230;&#30028;&#38480;&#30340;&#26174;&#30528;&#24433;&#21709;&#65292;&#36825;&#20123;&#30028;&#38480;&#30001;&#28608;&#27963;&#20989;&#25968;&#30340;Lipschitz&#36830;&#32493;&#24615;&#20915;&#23450;&#30340;&#25130;&#27490;&#28857;&#26469;&#34920;&#24449;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#36825;&#19968;&#20998;&#26512;&#25581;&#31034;&#20102;&#19968;&#20010;&#22949;&#21892;&#21021;&#22987;&#21270;&#30340;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#22312;$n$&#20010;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#36890;&#36807;&#32593;&#32476;&#22823;&#23567;$m$&#20165;&#23545;&#25968;&#22320;&#38543;$n$&#25193;&#23637;&#23601;&#36798;&#21040;&#26368;&#20248;&#24615;&#12290;&#36825;&#19982;&#20197;&#21069;&#30340;&#24037;&#20316;&#24418;&#25104;&#40092;&#26126;&#23545;&#27604;&#65292;&#21069;&#32773;&#38656;&#35201;&#39640;&#38454;&#22810;&#39033;&#24335;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12241v1 Announce Type: new  Abstract: We analyze recurrent neural networks trained with gradient descent in the supervised learning setting for dynamical systems, and prove that gradient descent can achieve optimality \emph{without} massive overparameterization. Our in-depth nonasymptotic analysis (i) provides sharp bounds on the network size $m$ and iteration complexity $\tau$ in terms of the sequence length $T$, sample size $n$ and ambient dimension $d$, and (ii) identifies the significant impact of long-term dependencies in the dynamical system on the convergence and network width bounds characterized by a cutoff point that depends on the Lipschitz continuity of the activation function. Remarkably, this analysis reveals that an appropriately-initialized recurrent neural network trained with $n$ samples can achieve optimality with a network size $m$ that scales only logarithmically with $n$. This sharply contrasts with the prior works that require high-order polynomial dep
&lt;/p&gt;</description></item><item><title>&#31070;&#32463;&#32593;&#32476;&#22312;&#39640;&#32500;&#25968;&#25454;&#20013;&#21457;&#29616;&#32479;&#35745;&#27169;&#24335;&#65292;&#30740;&#31350;&#20102;&#22914;&#20309;&#39640;&#25928;&#22320;&#20174;&#39640;&#38454;&#32047;&#31215;&#37327;&#20013;&#25552;&#21462;&#29305;&#24449;&#65292;&#24182;&#25506;&#35752;&#20102;&#22312;&#23574;&#23792;&#32047;&#31215;&#37327;&#27169;&#22411;&#20013;&#30340;&#32479;&#35745;&#21644;&#35745;&#31639;&#38480;&#21046;&#12290;</title><link>https://arxiv.org/abs/2312.14922</link><description>&lt;p&gt;
&#20174;&#39640;&#38454;&#32479;&#35745;&#37327;&#20013;&#39640;&#25928;&#23398;&#20064;&#65306;&#20551;&#35774;&#26816;&#39564;&#12289;&#38543;&#26426;&#29305;&#24449;&#21644;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Learning from higher-order statistics, efficiently: hypothesis tests, random features, and neural networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.14922
&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#22312;&#39640;&#32500;&#25968;&#25454;&#20013;&#21457;&#29616;&#32479;&#35745;&#27169;&#24335;&#65292;&#30740;&#31350;&#20102;&#22914;&#20309;&#39640;&#25928;&#22320;&#20174;&#39640;&#38454;&#32047;&#31215;&#37327;&#20013;&#25552;&#21462;&#29305;&#24449;&#65292;&#24182;&#25506;&#35752;&#20102;&#22312;&#23574;&#23792;&#32047;&#31215;&#37327;&#27169;&#22411;&#20013;&#30340;&#32479;&#35745;&#21644;&#35745;&#31639;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#25797;&#38271;&#21457;&#29616;&#39640;&#32500;&#25968;&#25454;&#38598;&#20013;&#30340;&#32479;&#35745;&#27169;&#24335;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#24230;&#37327;&#19977;&#20010;&#25110;&#26356;&#22810;&#21464;&#37327;&#38388;&#30340;&#38750;&#39640;&#26031;&#30456;&#20851;&#24615;&#30340;&#39640;&#38454;&#32047;&#31215;&#37327;&#23545;&#31070;&#32463;&#32593;&#32476;&#30340;&#24615;&#33021;&#29305;&#21035;&#37325;&#35201;&#12290;&#20294;&#31070;&#32463;&#32593;&#32476;&#26377;&#22810;&#26377;&#25928;&#22320;&#20174;&#39640;&#38454;&#32047;&#31215;&#37327;&#20013;&#25552;&#21462;&#29305;&#24449;&#65311;&#25105;&#20204;&#22312;&#23574;&#23792;&#32047;&#31215;&#37327;&#27169;&#22411;&#20013;&#25506;&#35752;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#36825;&#37324;&#32479;&#35745;&#23398;&#23478;&#38656;&#35201;&#20174;$d$&#32500;&#36755;&#20837;&#30340;&#38454;-$p\ge 4$&#32047;&#31215;&#37327;&#20013;&#24674;&#22797;&#20986;&#19968;&#20010;&#29305;&#26435;&#26041;&#21521;&#25110;&#8220;&#23574;&#23792;&#8221;&#12290;&#25105;&#20204;&#39318;&#20808;&#36890;&#36807;&#20998;&#26512;&#25152;&#38656;&#26679;&#26412;&#25968;$n$&#26469;&#34920;&#24449;&#24674;&#22797;&#23574;&#23792;&#30340;&#22522;&#26412;&#32479;&#35745;&#21644;&#35745;&#31639;&#38480;&#21046;&#65292;&#20197;&#24378;&#28872;&#21306;&#20998;&#26469;&#33258;&#23574;&#23792;&#32047;&#31215;&#37327;&#27169;&#22411;&#21644;&#21508;&#21521;&#21516;&#24615;&#39640;&#26031;&#36755;&#20837;&#30340;&#36755;&#20837;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#32479;&#35745;&#19978;&#30340;&#21487;&#21306;&#20998;&#24615;&#38656;&#35201;$n\gtrsim d$&#20010;&#26679;&#26412;&#65292;&#32780;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#21306;&#20998;&#36825;&#20004;&#20010;&#20998;&#24067;&#21017;&#38656;&#35201;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.14922v2 Announce Type: replace-cross  Abstract: Neural networks excel at discovering statistical patterns in high-dimensional data sets. In practice, higher-order cumulants, which quantify the non-Gaussian correlations between three or more variables, are particularly important for the performance of neural networks. But how efficient are neural networks at extracting features from higher-order cumulants? We study this question in the spiked cumulant model, where the statistician needs to recover a privileged direction or "spike" from the order-$p\ge 4$ cumulants of $d$-dimensional inputs. We first characterise the fundamental statistical and computational limits of recovering the spike by analysing the number of samples $n$ required to strongly distinguish between inputs from the spiked cumulant model and isotropic Gaussian inputs. We find that statistical distinguishability requires $n\gtrsim d$ samples, while distinguishing the two distributions in polynomial time require
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#23545;&#25239;&#24615;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#38024;&#23545;&#20219;&#24847;&#31574;&#30053;&#65292;&#25552;&#20986;&#20102;&#20351;&#29992;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#26041;&#27861;&#30340;&#20027;&#25511;&#22522;&#30784;&#26694;&#26550;&#65292;&#24182;&#20351;&#29992;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#30340;OMD&#26469;&#20943;&#36731;&#26041;&#24046;&#30340;&#24433;&#21709;&#65292;&#21462;&#24471;&#20102;&#36739;&#22909;&#30340;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2205.14839</link><description>&lt;p&gt;
&#23545;&#25239;&#24615;&#36172;&#21338;&#26426;&#38024;&#23545;&#20219;&#24847;&#31574;&#30053;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Adversarial Bandits against Arbitrary Strategies
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2205.14839
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#23545;&#25239;&#24615;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#38024;&#23545;&#20219;&#24847;&#31574;&#30053;&#65292;&#25552;&#20986;&#20102;&#20351;&#29992;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#26041;&#27861;&#30340;&#20027;&#25511;&#22522;&#30784;&#26694;&#26550;&#65292;&#24182;&#20351;&#29992;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#30340;OMD&#26469;&#20943;&#36731;&#26041;&#24046;&#30340;&#24433;&#21709;&#65292;&#21462;&#24471;&#20102;&#36739;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#38024;&#23545;&#20219;&#24847;&#31574;&#30053;&#30340;&#23545;&#25239;&#24615;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#20854;&#20013;S&#26159;&#38382;&#39064;&#38590;&#24230;&#30340;&#21442;&#25968;&#65292;&#35813;&#21442;&#25968;&#23545;&#20110;&#20195;&#29702;&#20154;&#26469;&#35828;&#26159;&#26410;&#30693;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#20351;&#29992;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#26041;&#27861;&#65288;OMD&#65289;&#30340;&#20027;&#25511;&#22522;&#30784;&#26694;&#26550;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20379;&#20102;&#19968;&#20010;&#20855;&#26377;&#31616;&#21333;OMD&#30340;&#20027;&#25511;&#22522;&#30784;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;$\tilde{O}(S^{1/2}K^{1/3}T^{2/3})$&#30340;&#32467;&#26524;&#65292;&#20854;&#20013;$T^{2/3}$&#26469;&#33258;&#25439;&#22833;&#20272;&#35745;&#22120;&#30340;&#26041;&#24046;&#12290;&#20026;&#20102;&#20943;&#36731;&#26041;&#24046;&#30340;&#24433;&#21709;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#30340;OMD&#65292;&#24182;&#23454;&#29616;&#20102;$\tilde{O}(\min\{\mathbb{E}[\sqrt{SKT\rho_T(h^\dagger)}],S\sqrt{KT}\})$&#30340;&#32467;&#26524;&#65292;&#20854;&#20013;$\rho_T(h^\dagger)$&#26159;&#25439;&#22833;&#20272;&#35745;&#22120;&#30340;&#26041;&#24046;&#39033;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the adversarial bandit problem against arbitrary strategies, in which $S$ is the parameter for the hardness of the problem and this parameter is not given to the agent. To handle this problem, we adopt the master-base framework using the online mirror descent method (OMD). We first provide a master-base algorithm with simple OMD, achieving $\tilde{O}(S^{1/2}K^{1/3}T^{2/3})$, in which $T^{2/3}$ comes from the variance of loss estimators. To mitigate the impact of the variance, we propose using adaptive learning rates for OMD and achieve $\tilde{O}(\min\{\mathbb{E}[\sqrt{SKT\rho_T(h^\dagger)}],S\sqrt{KT}\})$, where $\rho_T(h^\dagger)$ is a variance term for loss estimators.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#22240;&#26524;&#27169;&#22411; (DCM)&#65292;&#23427;&#21487;&#20197;&#22312;&#21482;&#26377;&#35266;&#27979;&#25968;&#25454;&#21644;&#22240;&#26524;&#22270;&#21487;&#29992;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#24178;&#39044;&#21644;&#21453;&#20107;&#23454;&#25512;&#26029;&#65292;&#20854;&#20855;&#26377;&#36739;&#22909;&#30340;&#34920;&#29616;&#12290;&#21516;&#26102;&#65292;&#35770;&#25991;&#36824;&#25552;&#20379;&#20102;&#19968;&#31181;&#20998;&#26512;&#21453;&#20107;&#23454;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#26356;&#24191;&#27867;&#30340;&#22330;&#26223;&#12290;</title><link>http://arxiv.org/abs/2302.00860</link><description>&lt;p&gt;
&#21033;&#29992;&#25193;&#25955;&#27169;&#22411;&#36827;&#34892;&#24178;&#39044;&#21644;&#21453;&#20107;&#23454;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Interventional and Counterfactual Inference with Diffusion Models. (arXiv:2302.00860v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.00860
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#22240;&#26524;&#27169;&#22411; (DCM)&#65292;&#23427;&#21487;&#20197;&#22312;&#21482;&#26377;&#35266;&#27979;&#25968;&#25454;&#21644;&#22240;&#26524;&#22270;&#21487;&#29992;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#24178;&#39044;&#21644;&#21453;&#20107;&#23454;&#25512;&#26029;&#65292;&#20854;&#20855;&#26377;&#36739;&#22909;&#30340;&#34920;&#29616;&#12290;&#21516;&#26102;&#65292;&#35770;&#25991;&#36824;&#25552;&#20379;&#20102;&#19968;&#31181;&#20998;&#26512;&#21453;&#20107;&#23454;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#26356;&#24191;&#27867;&#30340;&#22330;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#21482;&#26377;&#35266;&#27979;&#25968;&#25454;&#21644;&#22240;&#26524;&#22270;&#21487;&#29992;&#30340;&#22240;&#26524;&#20805;&#20998;&#35774;&#32622;&#20013;&#22238;&#31572;&#35266;&#27979;&#12289;&#24178;&#39044;&#21644;&#21453;&#20107;&#23454;&#26597;&#35810;&#30340;&#38382;&#39064;&#12290;&#21033;&#29992;&#25193;&#25955;&#27169;&#22411;&#30340;&#26368;&#26032;&#21457;&#23637;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#22522;&#20110;&#25193;&#25955;&#30340;&#22240;&#26524;&#27169;&#22411; (DCM)&#65292;&#26469;&#23398;&#20064;&#29983;&#25104;&#29420;&#29305;&#30340;&#28508;&#22312;&#32534;&#30721;&#30340;&#22240;&#26524;&#26426;&#21046;&#12290;&#36825;&#20123;&#32534;&#30721;&#20351;&#25105;&#20204;&#33021;&#22815;&#22312;&#24178;&#39044;&#19979;&#30452;&#25509;&#37319;&#26679;&#21644;&#36827;&#34892;&#21453;&#20107;&#23454;&#25512;&#26029;&#12290;&#25193;&#25955;&#27169;&#22411;&#22312;&#36825;&#37324;&#26159;&#19968;&#20010;&#33258;&#28982;&#30340;&#36873;&#25321;&#65292;&#22240;&#20026;&#23427;&#20204;&#21487;&#20197;&#23558;&#27599;&#20010;&#33410;&#28857;&#32534;&#30721;&#20026;&#19968;&#20010;&#20195;&#34920;&#22806;&#29983;&#22122;&#22768;&#30340;&#28508;&#22312;&#34920;&#31034;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#35780;&#20272;&#34920;&#26126;&#65292;&#22312;&#22238;&#31572;&#22240;&#26524;&#26597;&#35810;&#26041;&#38754;&#65292;&#19982;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#30456;&#27604;&#65292;&#26377;&#26174;&#30528;&#30340;&#25913;&#36827;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#32467;&#26524;&#65292;&#20026;&#20998;&#26512;&#19968;&#33324;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#20013;&#30340;&#21453;&#20107;&#23454;&#20272;&#35745;&#25552;&#20379;&#19968;&#31181;&#26041;&#27861;&#65292;&#36825;&#23545;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#20197;&#22806;&#30340;&#35774;&#32622;&#21487;&#33021;&#20063;&#26377;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of answering observational, interventional, and counterfactual queries in a causally sufficient setting where only observational data and the causal graph are available. Utilizing the recent developments in diffusion models, we introduce diffusion-based causal models (DCM) to learn causal mechanisms, that generate unique latent encodings. These encodings enable us to directly sample under interventions and perform abduction for counterfactuals. Diffusion models are a natural fit here, since they can encode each node to a latent representation that acts as a proxy for exogenous noise. Our empirical evaluations demonstrate significant improvements over existing state-of-the-art methods for answering causal queries. Furthermore, we provide theoretical results that offer a methodology for analyzing counterfactual estimation in general encoder-decoder models, which could be useful in settings beyond our proposed approach.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#22122;&#22768;&#29305;&#24449;&#30340;&#19978;&#19979;&#25991;&#32447;&#24615;Bandit&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31639;&#27861;&#65292;&#36890;&#36807;&#35266;&#23519;&#20449;&#24687;&#65292;&#23454;&#29616;&#20102;&#36125;&#21494;&#26031;&#31070;&#35861;&#24182;&#24471;&#21040;&#20102;$\tilde{O}(d\sqrt{T})$&#30340;&#36951;&#25022;&#30028;&#12290;</title><link>http://arxiv.org/abs/1703.01347</link><description>&lt;p&gt;
&#24102;&#22122;&#22768;&#29305;&#24449;&#30340;&#19978;&#19979;&#25991;&#32447;&#24615;Bandit&#65306;&#26397;&#21521;&#36125;&#21494;&#26031;&#31070;&#35861;&#21069;&#36827;
&lt;/p&gt;
&lt;p&gt;
Contextual Linear Bandits under Noisy Features: Towards Bayesian Oracles. (arXiv:1703.01347v3 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1703.01347
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#22122;&#22768;&#29305;&#24449;&#30340;&#19978;&#19979;&#25991;&#32447;&#24615;Bandit&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31639;&#27861;&#65292;&#36890;&#36807;&#35266;&#23519;&#20449;&#24687;&#65292;&#23454;&#29616;&#20102;&#36125;&#21494;&#26031;&#31070;&#35861;&#24182;&#24471;&#21040;&#20102;$\tilde{O}(d\sqrt{T})$&#30340;&#36951;&#25022;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#24102;&#26377;&#22122;&#22768;&#21644;&#32570;&#22833;&#39033;&#30340;&#19978;&#19979;&#25991;&#32447;&#24615;Bandit&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#22122;&#22768;&#30340;&#25361;&#25112;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#22312;&#35266;&#27979;&#22122;&#22768;&#29305;&#24449;&#30340;&#24773;&#20917;&#19979;&#32473;&#20986;&#30340;&#36125;&#21494;&#26031;&#31070;&#35861;&#12290;&#25105;&#20204;&#30340;&#36125;&#21494;&#26031;&#20998;&#26512;&#21457;&#29616;&#65292;&#26368;&#20248;&#20551;&#35774;&#21487;&#33021;&#20250;&#36828;&#31163;&#28508;&#22312;&#30340;&#21487;&#23454;&#29616;&#20989;&#25968;&#65292;&#36825;&#21462;&#20915;&#20110;&#22122;&#22768;&#29305;&#24449;&#65292;&#36825;&#26159;&#39640;&#24230;&#38750;&#30452;&#35266;&#30340;&#65292;&#24182;&#19988;&#22312;&#32463;&#20856;&#30340;&#26080;&#22122;&#22768;&#35774;&#32622;&#19979;&#19981;&#20250;&#21457;&#29983;&#12290;&#36825;&#24847;&#21619;&#30528;&#32463;&#20856;&#26041;&#27861;&#19981;&#33021;&#20445;&#35777;&#38750;&#24179;&#20961;&#30340;&#36951;&#25022;&#30028;&#65288;regret bound&#65289;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31639;&#27861;&#65292;&#26088;&#22312;&#20174;&#36825;&#20010;&#27169;&#22411;&#19979;&#30340;&#35266;&#23519;&#20449;&#24687;&#20013;&#23454;&#29616;&#36125;&#21494;&#26031;&#31070;&#35861;&#65292;&#24403;&#26377;&#22823;&#37327;&#25163;&#33218;&#26102;&#65292;&#21487;&#20197;&#23454;&#29616;$\tilde{O}(d\sqrt{T})$&#36951;&#25022;&#30028;&#12290;&#25105;&#20204;&#20351;&#29992;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#28436;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study contextual linear bandit problems under feature uncertainty; they are noisy with missing entries. To address the challenges of the noise, we analyze Bayesian oracles given observed noisy features. Our Bayesian analysis finds that the optimal hypothesis can be far from the underlying realizability function, depending on the noise characteristics, which are highly non-intuitive and do not occur for classical noiseless setups. This implies that classical approaches cannot guarantee a non-trivial regret bound. Therefore, we propose an algorithm that aims at the Bayesian oracle from observed information under this model, achieving $\tilde{O}(d\sqrt{T})$ regret bound when there is a large number of arms. We demonstrate the proposed algorithm using synthetic and real-world datasets.
&lt;/p&gt;</description></item></channel></rss>