<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;$L^1$&#20445;&#30495;&#24230;&#26465;&#20214;&#19979;&#65292;&#20174;&#22122;&#22768;&#35266;&#27979;&#20013;&#20272;&#35745;&#38543;&#26426;&#21464;&#37327;$X$&#30340;&#38382;&#39064;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#21807;&#19968;&#33021;&#22815;&#24341;&#20837;&#32447;&#24615;&#26465;&#20214;&#20013;&#20301;&#25968;&#30340;&#20808;&#39564;&#20998;&#24067;&#26159;&#39640;&#26031;&#20998;&#24067;&#12290;&#27492;&#22806;&#65292;&#36824;&#30740;&#31350;&#20102;&#20854;&#20182;$L^p$&#25439;&#22833;&#65292;&#24182;&#35266;&#23519;&#21040;&#23545;&#20110;$p \in [1,2]$&#65292;&#39640;&#26031;&#20998;&#24067;&#26159;&#21807;&#19968;&#24341;&#20837;&#32447;&#24615;&#26368;&#20248;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;&#30340;&#20808;&#39564;&#20998;&#24067;&#12290;&#25193;&#23637;&#36824;&#28085;&#30422;&#20102;&#29305;&#23450;&#25351;&#25968;&#26063;&#26465;&#20214;&#20998;&#24067;&#30340;&#22122;&#22768;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2309.09129</link><description>&lt;p&gt;
$L^1$&#20272;&#35745;&#65306;&#32447;&#24615;&#20272;&#35745;&#22120;&#30340;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
$L^1$ Estimation: On the Optimality of Linear Estimators. (arXiv:2309.09129v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09129
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;$L^1$&#20445;&#30495;&#24230;&#26465;&#20214;&#19979;&#65292;&#20174;&#22122;&#22768;&#35266;&#27979;&#20013;&#20272;&#35745;&#38543;&#26426;&#21464;&#37327;$X$&#30340;&#38382;&#39064;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#21807;&#19968;&#33021;&#22815;&#24341;&#20837;&#32447;&#24615;&#26465;&#20214;&#20013;&#20301;&#25968;&#30340;&#20808;&#39564;&#20998;&#24067;&#26159;&#39640;&#26031;&#20998;&#24067;&#12290;&#27492;&#22806;&#65292;&#36824;&#30740;&#31350;&#20102;&#20854;&#20182;$L^p$&#25439;&#22833;&#65292;&#24182;&#35266;&#23519;&#21040;&#23545;&#20110;$p \in [1,2]$&#65292;&#39640;&#26031;&#20998;&#24067;&#26159;&#21807;&#19968;&#24341;&#20837;&#32447;&#24615;&#26368;&#20248;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;&#30340;&#20808;&#39564;&#20998;&#24067;&#12290;&#25193;&#23637;&#36824;&#28085;&#30422;&#20102;&#29305;&#23450;&#25351;&#25968;&#26063;&#26465;&#20214;&#20998;&#24067;&#30340;&#22122;&#22768;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;$L^1$&#20445;&#30495;&#24230;&#26465;&#20214;&#19979;&#65292;&#32771;&#34385;&#20174;&#22122;&#22768;&#35266;&#27979;$Y=X+Z$&#20013;&#20272;&#35745;&#38543;&#26426;&#21464;&#37327;$X$&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;$Z$&#26159;&#26631;&#20934;&#27491;&#24577;&#20998;&#24067;&#12290;&#20247;&#25152;&#21608;&#30693;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#26368;&#20248;&#30340;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;&#26159;&#26465;&#20214;&#20013;&#20301;&#25968;&#12290;&#26412;&#25991;&#34920;&#26126;&#65292;&#22312;&#26465;&#20214;&#20013;&#20301;&#25968;&#20013;&#24341;&#20837;&#32447;&#24615;&#30340;&#21807;&#19968;&#20808;&#39564;&#20998;&#24067;&#26159;&#39640;&#26031;&#20998;&#24067;&#12290;&#21516;&#26102;&#65292;&#36824;&#25552;&#20379;&#20102;&#20854;&#20182;&#20960;&#20010;&#32467;&#26524;&#12290;&#29305;&#21035;&#22320;&#65292;&#35777;&#26126;&#20102;&#22914;&#26524;&#23545;&#20110;&#25152;&#26377;$y$&#65292;&#26465;&#20214;&#20998;&#24067;$P_{X|Y=y}$&#37117;&#26159;&#23545;&#31216;&#30340;&#65292;&#21017;$X$&#24517;&#39035;&#26381;&#20174;&#39640;&#26031;&#20998;&#24067;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#20854;&#20182;&#30340;$L^p$&#25439;&#22833;&#65292;&#24182;&#35266;&#23519;&#21040;&#20197;&#19979;&#29616;&#35937;&#65306;&#23545;&#20110;$p \in [1,2]$&#65292;&#39640;&#26031;&#20998;&#24067;&#26159;&#21807;&#19968;&#24341;&#20837;&#32447;&#24615;&#26368;&#20248;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;&#30340;&#20808;&#39564;&#20998;&#24067;&#65292;&#23545;&#20110;$p \in (2,\infty)$&#65292;&#26377;&#26080;&#31351;&#22810;&#20010;&#20808;&#39564;&#20998;&#24067;&#21487;&#20197;&#24341;&#20837;&#32447;&#24615;&#24615;&#12290;&#26368;&#21518;&#65292;&#36824;&#25552;&#20379;&#20102;&#25193;&#23637;&#65292;&#20197;&#28085;&#30422;&#23548;&#33268;&#29305;&#23450;&#25351;&#25968;&#26063;&#26465;&#20214;&#20998;&#24067;&#30340;&#22122;&#22768;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Consider the problem of estimating a random variable $X$ from noisy observations $Y = X+ Z$, where $Z$ is standard normal, under the $L^1$ fidelity criterion. It is well known that the optimal Bayesian estimator in this setting is the conditional median. This work shows that the only prior distribution on $X$ that induces linearity in the conditional median is Gaussian.  Along the way, several other results are presented. In particular, it is demonstrated that if the conditional distribution $P_{X|Y=y}$ is symmetric for all $y$, then $X$ must follow a Gaussian distribution. Additionally, we consider other $L^p$ losses and observe the following phenomenon: for $p \in [1,2]$, Gaussian is the only prior distribution that induces a linear optimal Bayesian estimator, and for $p \in (2,\infty)$, infinitely many prior distributions on $X$ can induce linearity. Finally, extensions are provided to encompass noise models leading to conditional distributions from certain exponential families.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#31639;&#27861;&#38598;&#20307;&#34892;&#21160;&#30340;&#29702;&#35770;&#27169;&#22411;&#65292;&#24182;&#22312;&#22823;&#37327;&#23454;&#39564;&#20013;&#39564;&#35777;&#20102;&#35813;&#31639;&#27861;&#21487;&#20197;&#22823;&#22823;&#25552;&#39640;&#20998;&#31867;&#20934;&#30830;&#24615;&#65292;&#29305;&#21035;&#26159;&#22312;&#25968;&#25454;&#32467;&#26500;&#22797;&#26434;&#21644;&#38598;&#20307;&#35268;&#27169;&#22823;&#30340;&#24773;&#20917;&#19979;&#12290;</title><link>http://arxiv.org/abs/2302.04262</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#31639;&#27861;&#38598;&#20307;&#34892;&#21160;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Algorithmic Collective Action in Machine Learning. (arXiv:2302.04262v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.04262
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#31639;&#27861;&#38598;&#20307;&#34892;&#21160;&#30340;&#29702;&#35770;&#27169;&#22411;&#65292;&#24182;&#22312;&#22823;&#37327;&#23454;&#39564;&#20013;&#39564;&#35777;&#20102;&#35813;&#31639;&#27861;&#21487;&#20197;&#22823;&#22823;&#25552;&#39640;&#20998;&#31867;&#20934;&#30830;&#24615;&#65292;&#29305;&#21035;&#26159;&#22312;&#25968;&#25454;&#32467;&#26500;&#22797;&#26434;&#21644;&#38598;&#20307;&#35268;&#27169;&#22823;&#30340;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23545;&#22312;&#37319;&#29992;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#25968;&#23383;&#24179;&#21488;&#19978;&#36827;&#34892;&#31639;&#27861;&#38598;&#20307;&#34892;&#21160;&#36827;&#34892;&#20102;&#21407;&#21017;&#24615;&#30740;&#31350;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#29702;&#35770;&#27169;&#22411;&#65292;&#25551;&#36848;&#20102;&#19968;&#32676;&#20154;&#19982;&#20844;&#21496;&#30340;&#23398;&#20064;&#31639;&#27861;&#36827;&#34892;&#20132;&#20114;&#30340;&#24773;&#20917;&#12290;&#38598;&#20307;&#27719;&#32858;&#21442;&#19982;&#20010;&#20307;&#30340;&#25968;&#25454;&#24182;&#36890;&#36807;&#19968;&#31181;&#31639;&#27861;&#31574;&#30053;&#25351;&#23548;&#21442;&#19982;&#32773;&#20462;&#25913;&#33258;&#24049;&#30340;&#25968;&#25454;&#20197;&#23454;&#29616;&#38598;&#20307;&#30446;&#26631;&#12290;&#25105;&#20204;&#22312;&#19977;&#31181;&#22522;&#26412;&#30340;&#23398;&#20064;&#29702;&#35770;&#35774;&#32622;&#19979;&#30740;&#31350;&#20102;&#36825;&#31181;&#27169;&#22411;&#30340;&#32467;&#26524;&#65306;&#38750;&#21442;&#25968;&#26368;&#20248;&#23398;&#20064;&#31639;&#27861;&#65292;&#21442;&#25968;&#39118;&#38505;&#26368;&#23567;&#21270;&#21644;&#26799;&#24230;&#19979;&#38477;&#20248;&#21270;&#12290;&#22312;&#27599;&#20010;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21327;&#35843;&#30340;&#31639;&#27861;&#31574;&#30053;&#65292;&#24182;&#26681;&#25454;&#38598;&#20307;&#35268;&#27169;&#30340;&#22823;&#23567;&#26469;&#34920;&#24449;&#33258;&#28982;&#30340;&#25104;&#21151;&#26631;&#20934;&#12290;&#20026;&#20102;&#34917;&#20805;&#25105;&#20204;&#30340;&#29702;&#35770;&#65292;&#25105;&#20204;&#23545;&#28041;&#21450;&#25968;&#20197;&#19975;&#35745;&#33258;&#30001;&#32844;&#19994;&#24179;&#21488;&#31616;&#21382;&#30340;&#25216;&#33021;&#20998;&#31867;&#20219;&#21153;&#36827;&#34892;&#20102;&#31995;&#32479;&#23454;&#39564;&#12290;&#36890;&#36807; BERT &#27169;&#22411;&#30340;&#20004;&#21315;&#22810;&#27425;&#35757;&#32451;&#36816;&#34892;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#38598;&#20307;&#34892;&#21160;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#20998;&#31867;&#20934;&#30830;&#24615;&#65292;&#27604;&#38598;&#20013;&#24335;&#23398;&#20064;&#31639;&#27861;&#21644;&#29420;&#31435;&#20462;&#25913;&#25968;&#25454;&#30340;&#38750;&#21327;&#35843;&#26041;&#27861;&#35201;&#22909;&#24471;&#22810;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#31639;&#27861;&#38598;&#20307;&#34892;&#21160;&#30340;&#26377;&#25928;&#24615;&#33267;&#20851;&#37325;&#35201;&#30340;&#20381;&#36182;&#20110;&#38598;&#20307;&#30340;&#35268;&#27169;&#21644;&#25968;&#25454;&#30340;&#22522;&#26412;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
We initiate a principled study of algorithmic collective action on digital platforms that deploy machine learning algorithms. We propose a simple theoretical model of a collective interacting with a firm's learning algorithm. The collective pools the data of participating individuals and executes an algorithmic strategy by instructing participants how to modify their own data to achieve a collective goal. We investigate the consequences of this model in three fundamental learning-theoretic settings: the case of a nonparametric optimal learning algorithm, a parametric risk minimizer, and gradient-based optimization. In each setting, we come up with coordinated algorithmic strategies and characterize natural success criteria as a function of the collective's size. Complementing our theory, we conduct systematic experiments on a skill classification task involving tens of thousands of resumes from a gig platform for freelancers. Through more than two thousand model training runs of a BERT
&lt;/p&gt;</description></item></channel></rss>