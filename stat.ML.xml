<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;Moment Pooling&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;Deep Sets&#20013;&#30340;&#27714;&#21644;&#27867;&#21270;&#20026;&#20219;&#24847;&#30340;&#22810;&#21464;&#37327;&#30697;&#65292;&#26174;&#33879;&#38477;&#20302;&#26426;&#22120;&#23398;&#20064;&#32593;&#32476;&#30340;&#28508;&#22312;&#31354;&#38388;&#32500;&#24230;&#65292;&#22312;&#22266;&#23450;&#30340;&#28508;&#22312;&#32500;&#24230;&#19979;&#23454;&#29616;&#26356;&#39640;&#30340;&#26377;&#25928;&#28508;&#22312;&#32500;&#24230;&#65292;&#20174;&#32780;&#21487;&#20197;&#30452;&#25509;&#21487;&#35270;&#21270;&#21644;&#35299;&#37322;&#20869;&#37096;&#34920;&#31034;&#12290;</title><link>https://arxiv.org/abs/2403.08854</link><description>&lt;p&gt;
&#28165;&#26224;&#30636;&#38388;&#65306;&#20351;&#29992;Moment Pooling&#31616;&#21270;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#28508;&#22312;&#31354;&#38388;
&lt;/p&gt;
&lt;p&gt;
Moments of Clarity: Streamlining Latent Spaces in Machine Learning using Moment Pooling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08854
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;Moment Pooling&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;Deep Sets&#20013;&#30340;&#27714;&#21644;&#27867;&#21270;&#20026;&#20219;&#24847;&#30340;&#22810;&#21464;&#37327;&#30697;&#65292;&#26174;&#33879;&#38477;&#20302;&#26426;&#22120;&#23398;&#20064;&#32593;&#32476;&#30340;&#28508;&#22312;&#31354;&#38388;&#32500;&#24230;&#65292;&#22312;&#22266;&#23450;&#30340;&#28508;&#22312;&#32500;&#24230;&#19979;&#23454;&#29616;&#26356;&#39640;&#30340;&#26377;&#25928;&#28508;&#22312;&#32500;&#24230;&#65292;&#20174;&#32780;&#21487;&#20197;&#30452;&#25509;&#21487;&#35270;&#21270;&#21644;&#35299;&#37322;&#20869;&#37096;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#28041;&#21450;&#23398;&#20064;&#25968;&#25454;&#30340;&#28508;&#22312;&#34920;&#31034;&#65292;&#36890;&#24120;&#26159;&#39640;&#32500;&#19988;&#38590;&#20197;&#30452;&#25509;&#35299;&#37322;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#8220;Moment Pooling&#8221;&#65292;&#36825;&#26159;Deep Sets&#32593;&#32476;&#30340;&#19968;&#20010;&#33258;&#28982;&#24310;&#20280;&#65292;&#21487;&#22823;&#24133;&#20943;&#23569;&#36825;&#20123;&#32593;&#32476;&#30340;&#28508;&#22312;&#31354;&#38388;&#32500;&#24230;&#65292;&#21516;&#26102;&#32500;&#25345;&#29978;&#33267;&#25552;&#39640;&#24615;&#33021;&#12290;Moment Pooling&#23558;Deep Sets&#20013;&#30340;&#27714;&#21644;&#27867;&#21270;&#20026;&#20219;&#24847;&#30340;&#22810;&#21464;&#37327;&#30697;&#65292;&#20351;&#27169;&#22411;&#33021;&#22815;&#22312;&#22266;&#23450;&#30340;&#28508;&#22312;&#32500;&#24230;&#19979;&#23454;&#29616;&#26356;&#39640;&#30340;&#26377;&#25928;&#28508;&#22312;&#32500;&#24230;&#12290;&#25105;&#20204;&#23558;Moment Pooling&#24212;&#29992;&#20110;&#22840;&#20811;/&#33014;&#23376;&#21943;&#27880;&#20998;&#31867;&#30340;&#23545;&#25758;&#26426;&#29289;&#29702;&#20219;&#21153;&#65292;&#36890;&#36807;&#23558;Energy Flow Networks&#65288;EFNs&#65289;&#25193;&#23637;&#20026;Moment EFNs&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#20855;&#26377;&#23567;&#33267;1&#30340;&#28508;&#22312;&#32500;&#24230;&#30340;Moment EFNs&#34920;&#29616;&#19982;&#20855;&#26377;&#36739;&#39640;&#28508;&#22312;&#32500;&#24230;&#30340;&#26222;&#36890;EFNs&#31867;&#20284;&#12290;&#36825;&#31181;&#23567;&#28508;&#22312;&#32500;&#24230;&#20351;&#20869;&#37096;&#34920;&#31034;&#21487;&#20197;&#30452;&#25509;&#21487;&#35270;&#21270;&#21644;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08854v1 Announce Type: cross  Abstract: Many machine learning applications involve learning a latent representation of data, which is often high-dimensional and difficult to directly interpret. In this work, we propose "Moment Pooling", a natural extension of Deep Sets networks which drastically decrease latent space dimensionality of these networks while maintaining or even improving performance. Moment Pooling generalizes the summation in Deep Sets to arbitrary multivariate moments, which enables the model to achieve a much higher effective latent dimensionality for a fixed latent dimension. We demonstrate Moment Pooling on the collider physics task of quark/gluon jet classification by extending Energy Flow Networks (EFNs) to Moment EFNs. We find that Moment EFNs with latent dimensions as small as 1 perform similarly to ordinary EFNs with higher latent dimension. This small latent dimension allows for the internal representation to be directly visualized and interpreted, w
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;Bellman&#27531;&#24046;&#26368;&#23567;&#21270;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#20998;&#24067;&#24335;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#33021;&#37327;Bellman&#27531;&#24046;&#26368;&#23567;&#21270;&#65288;EBRM&#65289;&#30340;&#26041;&#27861;&#26469;&#20272;&#35745;&#36820;&#22238;&#20998;&#24067;&#12290;&#22312;&#21487;&#23454;&#29616;&#24615;&#20551;&#35774;&#19979;&#65292;&#24314;&#31435;&#20102;EBRM&#20272;&#35745;&#22120;&#30340;&#26377;&#38480;&#26679;&#26412;&#35823;&#24046;&#30028;&#12290;</title><link>https://arxiv.org/abs/2402.01900</link><description>&lt;p&gt;
&#20351;&#29992;Bellman&#27531;&#24046;&#26368;&#23567;&#21270;&#30340;&#20998;&#24067;&#24335;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Distributional Off-policy Evaluation with Bellman Residual Minimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01900
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;Bellman&#27531;&#24046;&#26368;&#23567;&#21270;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#20998;&#24067;&#24335;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#33021;&#37327;Bellman&#27531;&#24046;&#26368;&#23567;&#21270;&#65288;EBRM&#65289;&#30340;&#26041;&#27861;&#26469;&#20272;&#35745;&#36820;&#22238;&#20998;&#24067;&#12290;&#22312;&#21487;&#23454;&#29616;&#24615;&#20551;&#35774;&#19979;&#65292;&#24314;&#31435;&#20102;EBRM&#20272;&#35745;&#22120;&#30340;&#26377;&#38480;&#26679;&#26412;&#35823;&#24046;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20998;&#24067;&#24335;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#30340;&#38382;&#39064;&#65292;&#23427;&#26159;&#35768;&#22810;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#65288;DRL&#65289;&#31639;&#27861;&#30340;&#22522;&#30784;&#12290;&#19982;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#26041;&#27861;&#65288;&#20381;&#36182;&#20110;&#26368;&#22823;&#20540;-&#25193;&#23637;&#30340;&#32479;&#35745;&#36317;&#31163;&#65292;&#22914;&#26368;&#22823;&#20540;Wasserstein&#36317;&#31163;&#65289;&#19981;&#21516;&#65292;&#25105;&#20204;&#30740;&#31350;&#29992;&#20110;&#37327;&#21270;&#20998;&#24067;&#24335;Bellman&#27531;&#24046;&#30340;&#26399;&#26395;-&#25193;&#23637;&#30340;&#32479;&#35745;&#36317;&#31163;&#65292;&#24182;&#19988;&#35777;&#26126;&#23427;&#21487;&#20197;&#19978;&#30028;&#20272;&#35745;&#36820;&#22238;&#20998;&#24067;&#30340;&#26399;&#26395;&#35823;&#24046;&#12290;&#22522;&#20110;&#36825;&#20010;&#26377;&#21560;&#24341;&#21147;&#30340;&#24615;&#36136;&#65292;&#36890;&#36807;&#23558;Bellman&#27531;&#24046;&#26368;&#23567;&#21270;&#26694;&#26550;&#25512;&#24191;&#21040;DRL&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#33021;&#37327;Bellman&#27531;&#24046;&#26368;&#23567;&#21270;&#65288;EBRM&#65289;&#30340;&#26041;&#27861;&#26469;&#20272;&#35745;&#36820;&#22238;&#20998;&#24067;&#12290;&#25105;&#20204;&#22312;&#21487;&#23454;&#29616;&#24615;&#20551;&#35774;&#19979;&#24314;&#31435;&#20102;EBRM&#20272;&#35745;&#22120;&#30340;&#26377;&#38480;&#26679;&#26412;&#35823;&#24046;&#30028;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#27493;&#24341;&#23548;&#36807;&#31243;&#30340;&#26041;&#27861;&#30340;&#21464;&#20307;&#65292;&#20197;&#23454;&#29616;&#22810;&#27493;&#25193;&#23637;&#12290;&#36890;&#36807;&#36873;&#25321;&#36866;&#24403;&#30340;&#27493;&#38271;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#26356;&#22909;&#30340;&#35823;&#24046;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of distributional off-policy evaluation which serves as the foundation of many distributional reinforcement learning (DRL) algorithms. In contrast to most existing works (that rely on supremum-extended statistical distances such as supremum-Wasserstein distance), we study the expectation-extended statistical distance for quantifying the distributional Bellman residuals and show that it can upper bound the expected error of estimating the return distribution. Based on this appealing property, by extending the framework of Bellman residual minimization to DRL, we propose a method called Energy Bellman Residual Minimizer (EBRM) to estimate the return distribution. We establish a finite-sample error bound for the EBRM estimator under the realizability assumption. Furthermore, we introduce a variant of our method based on a multi-step bootstrapping procedure to enable multi-step extension. By selecting an appropriate step level, we obtain a better error bound for thi
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#21160;&#24577;&#27835;&#30103;&#30340;&#38454;&#27573;&#24863;&#30693;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#20272;&#35745;DTR&#24182;&#20248;&#20808;&#32771;&#34385;&#27835;&#30103;&#36712;&#36857;&#19982;&#26368;&#20339;&#27835;&#30103;&#26041;&#26696;&#22312;&#20915;&#31574;&#38454;&#27573;&#19978;&#30340;&#19968;&#33268;&#24615;&#65292;&#22312;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#21644;&#31283;&#23450;&#24615;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#35201;&#36827;&#23637;&#12290;</title><link>http://arxiv.org/abs/2310.19300</link><description>&lt;p&gt;
&#38024;&#23545;&#21160;&#24577;&#27835;&#30103;&#30340;&#38454;&#27573;&#24863;&#30693;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Stage-Aware Learning for Dynamic Treatments. (arXiv:2310.19300v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19300
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#21160;&#24577;&#27835;&#30103;&#30340;&#38454;&#27573;&#24863;&#30693;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#20272;&#35745;DTR&#24182;&#20248;&#20808;&#32771;&#34385;&#27835;&#30103;&#36712;&#36857;&#19982;&#26368;&#20339;&#27835;&#30103;&#26041;&#26696;&#22312;&#20915;&#31574;&#38454;&#27573;&#19978;&#30340;&#19968;&#33268;&#24615;&#65292;&#22312;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#21644;&#31283;&#23450;&#24615;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#35201;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#23545;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;&#65288;DTRs&#65289;&#30340;&#30740;&#31350;&#21462;&#24471;&#20102;&#37325;&#35201;&#36827;&#23637;&#65292;&#25552;&#20986;&#20102;&#24378;&#22823;&#30340;&#20248;&#21270;&#27835;&#30103;&#25628;&#32034;&#31639;&#27861;&#65292;&#26681;&#25454;&#20010;&#20307;&#20855;&#20307;&#38656;&#27714;&#37327;&#36523;&#23450;&#21046;&#65292;&#24182;&#33021;&#26368;&#22823;&#21270;&#20854;&#39044;&#26399;&#30340;&#20020;&#24202;&#25928;&#30410;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#31639;&#27861;&#22312;&#20248;&#21270;&#27835;&#30103;&#19979;&#21487;&#33021;&#20250;&#21463;&#21040;&#26679;&#26412;&#37327;&#19981;&#36275;&#30340;&#22256;&#25200;&#65292;&#23588;&#20854;&#26159;&#22312;&#28041;&#21450;&#38271;&#26102;&#38388;&#20915;&#31574;&#38454;&#27573;&#30340;&#24930;&#24615;&#30142;&#30149;&#20013;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20010;&#20307;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#37325;&#28857;&#26159;&#20272;&#35745;DTR&#65292;&#24182;&#20248;&#20808;&#32771;&#34385;&#35266;&#23519;&#21040;&#30340;&#27835;&#30103;&#36712;&#36857;&#19982;&#26368;&#20339;&#27835;&#30103;&#26041;&#26696;&#22312;&#20915;&#31574;&#38454;&#27573;&#19978;&#30340;&#19968;&#33268;&#24615;&#12290;&#36890;&#36807;&#25918;&#23485;&#35266;&#23519;&#21040;&#30340;&#36712;&#36857;&#24517;&#39035;&#23436;&#20840;&#19982;&#26368;&#20339;&#27835;&#30103;&#19968;&#33268;&#30340;&#38480;&#21046;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22823;&#22823;&#25552;&#39640;&#20102;&#22522;&#20110;&#20498;&#25968;&#27010;&#29575;&#21152;&#26435;&#26041;&#27861;&#30340;&#26679;&#26412;&#25928;&#29575;&#21644;&#31283;&#23450;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25152;&#25552;&#20986;&#30340;&#23398;&#20064;&#26041;&#26696;&#26500;&#24314;&#20102;&#19968;&#20010;&#26356;&#36890;&#29992;&#30340;&#26694;&#26550;&#65292;&#21253;&#25324;&#20102;&#27969;&#34892;&#30340;&#32467;&#26524;&#21152;&#26435;&#23398;&#20064;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advances in dynamic treatment regimes (DTRs) provide powerful optimal treatment searching algorithms, which are tailored to individuals' specific needs and able to maximize their expected clinical benefits. However, existing algorithms could suffer from insufficient sample size under optimal treatments, especially for chronic diseases involving long stages of decision-making. To address these challenges, we propose a novel individualized learning method which estimates the DTR with a focus on prioritizing alignment between the observed treatment trajectory and the one obtained by the optimal regime across decision stages. By relaxing the restriction that the observed trajectory must be fully aligned with the optimal treatments, our approach substantially improves the sample efficiency and stability of inverse probability weighted based methods. In particular, the proposed learning scheme builds a more general framework which includes the popular outcome weighted learning framewo
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#39640;&#32500;&#32447;&#24615;&#36807;&#31243;&#30340;&#20855;&#26377;&#30456;&#20851;&#21019;&#26032;&#30340;&#38598;&#20013;&#24230;&#19981;&#31561;&#24335;&#65292;&#24182;&#21033;&#29992;&#35813;&#19981;&#31561;&#24335;&#33719;&#24471;&#20102;&#32447;&#24615;&#36807;&#31243;&#28382;&#21518;&#33258;&#21327;&#26041;&#24046;&#30697;&#38453;&#26368;&#22823;&#20998;&#37327;&#33539;&#25968;&#30340;&#38598;&#20013;&#24230;&#30028;&#38480;&#12290;&#36825;&#20123;&#32467;&#26524;&#22312;&#20272;&#35745;&#39640;&#32500;&#21521;&#37327;&#33258;&#22238;&#24402;&#36807;&#31243;&#12289;&#26102;&#38388;&#24207;&#21015;&#24341;&#23548;&#21644;&#38271;&#26399;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#20013;&#20855;&#26377;&#37325;&#35201;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2307.12395</link><description>&lt;p&gt;
&#39640;&#32500;&#32447;&#24615;&#36807;&#31243;&#20013;&#20855;&#26377;&#30456;&#20851;&#21019;&#26032;&#30340;&#38598;&#20013;&#24230;
&lt;/p&gt;
&lt;p&gt;
Concentration for high-dimensional linear processes with dependent innovations. (arXiv:2307.12395v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12395
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#39640;&#32500;&#32447;&#24615;&#36807;&#31243;&#30340;&#20855;&#26377;&#30456;&#20851;&#21019;&#26032;&#30340;&#38598;&#20013;&#24230;&#19981;&#31561;&#24335;&#65292;&#24182;&#21033;&#29992;&#35813;&#19981;&#31561;&#24335;&#33719;&#24471;&#20102;&#32447;&#24615;&#36807;&#31243;&#28382;&#21518;&#33258;&#21327;&#26041;&#24046;&#30697;&#38453;&#26368;&#22823;&#20998;&#37327;&#33539;&#25968;&#30340;&#38598;&#20013;&#24230;&#30028;&#38480;&#12290;&#36825;&#20123;&#32467;&#26524;&#22312;&#20272;&#35745;&#39640;&#32500;&#21521;&#37327;&#33258;&#22238;&#24402;&#36807;&#31243;&#12289;&#26102;&#38388;&#24207;&#21015;&#24341;&#23548;&#21644;&#38271;&#26399;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#20013;&#20855;&#26377;&#37325;&#35201;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#38024;&#23545;&#20855;&#26377;&#23376;&#38886;&#24067;&#23572;&#23614;&#30340;&#28151;&#21512;&#24207;&#21015;&#19978;&#30340;&#32447;&#24615;&#36807;&#31243;&#30340;$l_\infty$&#33539;&#25968;&#24320;&#21457;&#20102;&#38598;&#20013;&#19981;&#31561;&#24335;&#12290;&#36825;&#20123;&#19981;&#31561;&#24335;&#21033;&#29992;&#20102;Beveridge-Nelson&#20998;&#35299;&#65292;&#23558;&#38382;&#39064;&#31616;&#21270;&#20026;&#21521;&#37327;&#28151;&#21512;&#24207;&#21015;&#25110;&#20854;&#21152;&#26435;&#21644;&#30340;&#19978;&#30830;&#30028;&#33539;&#25968;&#30340;&#38598;&#20013;&#24230;&#12290;&#36825;&#20010;&#19981;&#31561;&#24335;&#29992;&#20110;&#24471;&#21040;&#32447;&#24615;&#36807;&#31243;&#30340;&#28382;&#21518;$h$&#33258;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#26368;&#22823;&#20998;&#37327;&#33539;&#25968;&#30340;&#38598;&#20013;&#24230;&#30028;&#38480;&#12290;&#36825;&#20123;&#32467;&#26524;&#23545;&#20110;&#20351;&#29992;$l_1$&#27491;&#21017;&#21270;&#20272;&#35745;&#30340;&#39640;&#32500;&#21521;&#37327;&#33258;&#22238;&#24402;&#36807;&#31243;&#30340;&#20272;&#35745;&#30028;&#38480;&#12289;&#26102;&#38388;&#24207;&#21015;&#30340;&#39640;&#32500;&#39640;&#26031;&#24341;&#23548;&#12289;&#20197;&#21450;&#38271;&#26399;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#38750;&#24120;&#26377;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop concentration inequalities for the $l_\infty$ norm of a vector linear processes on mixingale sequences with sub-Weibull tails. These inequalities make use of the Beveridge-Nelson decomposition, which reduces the problem to concentration for sup-norm of a vector-mixingale or its weighted sum. This inequality is used to obtain a concentration bound for the maximum entrywise norm of the lag-$h$ autocovariance matrices of linear processes. These results are useful for estimation bounds for high-dimensional vector-autoregressive processes estimated using $l_1$ regularisation, high-dimensional Gaussian bootstrap for time series, and long-run covariance matrix estimation.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#32447;&#23398;&#20064;&#28216;&#25103;&#8220;&#27867;&#21270;&#28216;&#25103;&#8221;&#30340;&#26694;&#26550;&#65292;&#23558;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#30340;&#34920;&#29616;&#21644;&#32479;&#35745;&#23398;&#20064;&#31639;&#27861;&#30340;&#27867;&#21270;&#30028;&#38480;&#32852;&#31995;&#20102;&#36215;&#26469;&#65292;&#24182;&#24471;&#20986;&#20102;&#19968;&#20123;&#26631;&#20934;&#30340;&#27867;&#21270;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2305.19674</link><description>&lt;p&gt;
&#22312;&#32447;&#21040;PAC&#30340;&#36716;&#25442;: &#36890;&#36807;&#36951;&#25022;&#20998;&#26512;&#24471;&#20986;&#27867;&#21270;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Online-to-PAC Conversions: Generalization Bounds via Regret Analysis. (arXiv:2305.19674v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19674
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#32447;&#23398;&#20064;&#28216;&#25103;&#8220;&#27867;&#21270;&#28216;&#25103;&#8221;&#30340;&#26694;&#26550;&#65292;&#23558;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#30340;&#34920;&#29616;&#21644;&#32479;&#35745;&#23398;&#20064;&#31639;&#27861;&#30340;&#27867;&#21270;&#30028;&#38480;&#32852;&#31995;&#20102;&#36215;&#26469;&#65292;&#24182;&#24471;&#20986;&#20102;&#19968;&#20123;&#26631;&#20934;&#30340;&#27867;&#21270;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#22312;&#32447;&#23398;&#20064;&#30340;&#35270;&#35282;&#25512;&#23548;&#20986;&#32479;&#35745;&#23398;&#20064;&#31639;&#27861;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#22312;&#32447;&#23398;&#20064;&#28216;&#25103;&#31216;&#20026;&#8220;&#27867;&#21270;&#28216;&#25103;&#8221;&#65292;&#20854;&#20013;&#22312;&#32447;&#23398;&#20064;&#22120;&#35797;&#22270;&#19982;&#22266;&#23450;&#30340;&#32479;&#35745;&#23398;&#20064;&#31639;&#27861;&#31454;&#20105;&#65292;&#39044;&#27979;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#28857;&#35757;&#32451;&#38598;&#19978;&#30340;&#27867;&#21270;&#38388;&#38553;&#24207;&#21015;&#12290;&#25105;&#20204;&#36890;&#36807;&#23637;&#31034;&#22312;&#36825;&#20010;&#28216;&#25103;&#20013;&#23384;&#22312;&#26377;&#30028;&#36951;&#25022;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#19982;&#32479;&#35745;&#23398;&#20064;&#35774;&#32622;&#20043;&#38388;&#30340;&#32852;&#31995;&#26469;&#24314;&#31435;&#36825;&#31181;&#20851;&#32852;&#65292;&#36825;&#24847;&#21619;&#30528;&#32479;&#35745;&#23398;&#20064;&#31639;&#27861;&#30340;&#27867;&#21270;&#38169;&#35823;&#23384;&#22312;&#19968;&#20010;&#30028;&#38480;&#65292;&#30452;&#21040;&#19982;&#32479;&#35745;&#23398;&#20064;&#26041;&#27861;&#30340;&#22797;&#26434;&#24615;&#26080;&#20851;&#30340;&#38789;&#27987;&#24230;&#39033;&#12290;&#36825;&#31181;&#25216;&#26415;&#20801;&#35768;&#25105;&#20204;&#24674;&#22797;&#20960;&#20010;&#26631;&#20934;&#30340;&#27867;&#21270;&#38480;&#21046;&#65292;&#21253;&#25324;&#19968;&#31995;&#21015;&#30340;PAC-Bayesian&#20445;&#35777;&#21644;&#20449;&#24687;&#29702;&#35770;&#20445;&#35777;&#65292;&#20197;&#21450;&#23427;&#20204;&#30340;&#25512;&#24191;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a new framework for deriving bounds on the generalization bound of statistical learning algorithms from the perspective of online learning. Specifically, we construct an online learning game called the "generalization game", where an online learner is trying to compete with a fixed statistical learning algorithm in predicting the sequence of generalization gaps on a training set of i.i.d. data points. We establish a connection between the online and statistical learning setting by showing that the existence of an online learning algorithm with bounded regret in this game implies a bound on the generalization error of the statistical learning algorithm, up to a martingale concentration term that is independent of the complexity of the statistical learning method. This technique allows us to recover several standard generalization bounds including a range of PAC-Bayesian and information-theoretic guarantees, as well as generalizations thereof.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#31616;&#21333;&#30340;&#28151;&#27788;&#26144;&#23556;&#19978;&#35777;&#26126;&#20102;&#25193;&#23637;&#21160;&#24577;&#27169;&#24577;&#20998;&#35299;&#65288;EDMD&#65289;&#23545;&#20110;&#22810;&#39033;&#24335;&#21487;&#35266;&#27979;&#23383;&#20856;&#26377;&#25351;&#25968;&#25928;&#29575;&#65292;&#20174;&#32780;&#26377;&#25928;&#22788;&#29702;&#20102;&#28151;&#27788;&#21160;&#21147;&#23398;&#20013;&#30340;&#27491;&#21017;&#20989;&#25968;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#20351;&#29992;EDMD&#20135;&#29983;&#30340;&#39044;&#27979;&#21644;Koopman&#35889;&#25968;&#25454;&#25910;&#25947;&#33267;&#29289;&#29702;&#19978;&#26377;&#24847;&#20041;&#30340;&#26497;&#38480;&#12290;</title><link>http://arxiv.org/abs/2305.08074</link><description>&lt;p&gt;
&#27491;&#20132;&#22810;&#39033;&#24335;&#36924;&#36817;&#21644;&#25193;&#23637;&#21160;&#24577;&#27169;&#24577;&#20998;&#35299;&#22312;&#28151;&#27788;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Orthogonal polynomial approximation and Extended Dynamic Mode Decomposition in chaos. (arXiv:2305.08074v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08074
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#31616;&#21333;&#30340;&#28151;&#27788;&#26144;&#23556;&#19978;&#35777;&#26126;&#20102;&#25193;&#23637;&#21160;&#24577;&#27169;&#24577;&#20998;&#35299;&#65288;EDMD&#65289;&#23545;&#20110;&#22810;&#39033;&#24335;&#21487;&#35266;&#27979;&#23383;&#20856;&#26377;&#25351;&#25968;&#25928;&#29575;&#65292;&#20174;&#32780;&#26377;&#25928;&#22788;&#29702;&#20102;&#28151;&#27788;&#21160;&#21147;&#23398;&#20013;&#30340;&#27491;&#21017;&#20989;&#25968;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#20351;&#29992;EDMD&#20135;&#29983;&#30340;&#39044;&#27979;&#21644;Koopman&#35889;&#25968;&#25454;&#25910;&#25947;&#33267;&#29289;&#29702;&#19978;&#26377;&#24847;&#20041;&#30340;&#26497;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#23637;&#21160;&#24577;&#27169;&#24577;&#20998;&#35299;&#65288;EDMD&#65289;&#26159;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#24037;&#20855;&#65292;&#29992;&#20110;&#21160;&#24577;&#30340;&#39044;&#27979;&#21644;&#27169;&#22411;&#31616;&#21270;&#65292;&#22312;&#29289;&#29702;&#31185;&#23398;&#39046;&#22495;&#24471;&#21040;&#24191;&#27867;&#24212;&#29992;&#12290;&#34429;&#28982;&#36825;&#31181;&#26041;&#27861;&#22312;&#27010;&#24565;&#19978;&#24456;&#31616;&#21333;&#65292;&#20294;&#22312;&#30830;&#23450;&#24615;&#28151;&#27788;&#20013;&#65292;&#23427;&#30340;&#24615;&#36136;&#25110;&#32773;&#23427;&#30340;&#25910;&#25947;&#24615;&#36824;&#19981;&#28165;&#26970;&#12290;&#29305;&#21035;&#26159;&#65292;EDMD&#30340;&#26368;&#23567;&#20108;&#20056;&#36924;&#36817;&#22914;&#20309;&#22788;&#29702;&#38656;&#35201;&#25551;&#32472;&#28151;&#27788;&#21160;&#21147;&#23398;&#21547;&#20041;&#30340;&#27491;&#21017;&#20989;&#25968;&#30340;&#31867;&#21035;&#65292;&#36825;&#20063;&#26159;&#19981;&#28165;&#26970;&#30340;&#12290;&#26412;&#25991;&#22312;&#20998;&#26512;&#19978;&#31616;&#21333;&#30340;&#19968;&#20010;&#22278;&#29615;&#23637;&#24320;&#26144;&#23556;&#30340;&#26368;&#31616;&#21333;&#20363;&#23376;&#19978;&#65292;&#21457;&#23637;&#20102;&#20851;&#20110;EDMD&#30340;&#19968;&#33324;&#30340;&#12289;&#20005;&#26684;&#30340;&#29702;&#35770;&#12290;&#35777;&#26126;&#20102;&#19968;&#20010;&#26032;&#30340;&#20851;&#20110;&#22312;&#21333;&#20301;&#22278;&#19978;&#30340;&#27491;&#20132;&#22810;&#39033;&#24335;&#65288;OPUC&#65289;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#26080;&#38480;&#25968;&#25454;&#26497;&#38480;&#26102;&#65292;&#38024;&#23545;&#22810;&#39033;&#24335;&#30340;&#21487;&#35266;&#27979;&#23383;&#20856;&#30340;&#26368;&#23567;&#20108;&#20056;&#25237;&#24433;&#20855;&#26377;&#25351;&#25968;&#25928;&#29575;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#20351;&#29992;EDMD&#20135;&#29983;&#30340;&#39044;&#27979;&#21644;Koopman&#35889;&#25968;&#25454;&#25910;&#25947;&#21040;&#29289;&#29702;&#19978;&#26377;&#24847;&#20041;&#30340;&#26497;&#38480;&#30340;&#25351;&#25968;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Extended Dynamic Mode Decomposition (EDMD) is a data-driven tool for forecasting and model reduction of dynamics, which has been extensively taken up in the physical sciences. While the method is conceptually simple, in deterministic chaos it is unclear what its properties are or even what it converges to. In particular, it is not clear how EDMD's least-squares approximation treats the classes of regular functions needed to make sense of chaotic dynamics.  In this paper we develop a general, rigorous theory of EDMD on the simplest examples of chaotic maps: analytic expanding maps of the circle. Proving a new result in the theory of orthogonal polynomials on the unit circle (OPUC), we show that in the infinite-data limit, the least-squares projection is exponentially efficient for polynomial observable dictionaries. As a result, we show that the forecasts and Koopman spectral data produced using EDMD in this setting converge to the physically meaningful limits, at an exponential rate.  
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#36866;&#24212;&#26041;&#27861;FAStEN&#65292;&#29992;&#20110;&#22312;&#39640;&#32500;&#20989;&#25968;&#22238;&#24402;&#38382;&#39064;&#20013;&#25191;&#34892;&#29305;&#24449;&#36873;&#25321;&#21644;&#21442;&#25968;&#20272;&#35745;&#65292;&#36890;&#36807;&#21033;&#29992;&#20989;&#25968;&#20027;&#25104;&#20998;&#21644;&#23545;&#20598;&#22686;&#24191;Lagrangian&#38382;&#39064;&#30340;&#31232;&#30095;&#24615;&#36136;&#65292;&#20855;&#26377;&#26174;&#33879;&#30340;&#35745;&#31639;&#25928;&#29575;&#21644;&#36873;&#25321;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.14801</link><description>&lt;p&gt;
&#39640;&#32500;&#20989;&#25968;&#22238;&#24402;&#20013;&#29305;&#24449;&#36873;&#25321;&#21644;&#20272;&#35745;&#30340;&#19968;&#31181;&#39640;&#25928;&#33258;&#36866;&#24212;&#26041;&#27861;--FAStEN
&lt;/p&gt;
&lt;p&gt;
FAStEN: an efficient adaptive method for feature selection and estimation in high-dimensional functional regressions. (arXiv:2303.14801v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14801
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#36866;&#24212;&#26041;&#27861;FAStEN&#65292;&#29992;&#20110;&#22312;&#39640;&#32500;&#20989;&#25968;&#22238;&#24402;&#38382;&#39064;&#20013;&#25191;&#34892;&#29305;&#24449;&#36873;&#25321;&#21644;&#21442;&#25968;&#20272;&#35745;&#65292;&#36890;&#36807;&#21033;&#29992;&#20989;&#25968;&#20027;&#25104;&#20998;&#21644;&#23545;&#20598;&#22686;&#24191;Lagrangian&#38382;&#39064;&#30340;&#31232;&#30095;&#24615;&#36136;&#65292;&#20855;&#26377;&#26174;&#33879;&#30340;&#35745;&#31639;&#25928;&#29575;&#21644;&#36873;&#25321;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20989;&#25968;&#22238;&#24402;&#20998;&#26512;&#26159;&#35768;&#22810;&#24403;&#20195;&#31185;&#23398;&#24212;&#29992;&#30340;&#24050;&#24314;&#31435;&#24037;&#20855;&#12290;&#28041;&#21450;&#22823;&#35268;&#27169;&#21644;&#22797;&#26434;&#25968;&#25454;&#38598;&#30340;&#22238;&#24402;&#38382;&#39064;&#26159;&#26222;&#36941;&#23384;&#22312;&#30340;&#65292;&#29305;&#24449;&#36873;&#25321;&#23545;&#20110;&#36991;&#20813;&#36807;&#24230;&#25311;&#21512;&#21644;&#23454;&#29616;&#20934;&#30830;&#39044;&#27979;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#12289;&#28789;&#27963;&#30340;&#12289;&#36229;&#39640;&#25928;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#31232;&#30095;&#39640;&#32500;&#20989;&#25968;&#22238;&#24402;&#38382;&#39064;&#20013;&#25191;&#34892;&#29305;&#24449;&#36873;&#25321;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#20854;&#25193;&#23637;&#21040;&#26631;&#37327;&#23545;&#20989;&#25968;&#26694;&#26550;&#20013;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#20989;&#25968;&#25968;&#25454;&#12289;&#20248;&#21270;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#20197;&#21516;&#26102;&#25191;&#34892;&#29305;&#24449;&#36873;&#25321;&#21644;&#21442;&#25968;&#20272;&#35745;&#12290;&#25105;&#20204;&#21033;&#29992;&#20989;&#25968;&#20027;&#25104;&#20998;&#30340;&#29305;&#24615;&#20197;&#21450;&#23545;&#20598;&#22686;&#24191;Lagrangian&#38382;&#39064;&#30340;&#31232;&#30095;&#24615;&#36136;&#65292;&#26174;&#33879;&#38477;&#20302;&#20102;&#35745;&#31639;&#25104;&#26412;&#65292;&#24182;&#24341;&#20837;&#20102;&#33258;&#36866;&#24212;&#26041;&#26696;&#26469;&#25552;&#39640;&#36873;&#25321;&#20934;&#30830;&#24615;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#27169;&#25311;&#30740;&#31350;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#26368;&#20339;&#29616;&#26377;&#31454;&#20105;&#23545;&#25163;&#36827;&#34892;&#20102;&#22522;&#20934;&#27979;&#35797;&#65292;&#24182;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#39640;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Functional regression analysis is an established tool for many contemporary scientific applications. Regression problems involving large and complex data sets are ubiquitous, and feature selection is crucial for avoiding overfitting and achieving accurate predictions. We propose a new, flexible, and ultra-efficient approach to perform feature selection in a sparse high dimensional function-on-function regression problem, and we show how to extend it to the scalar-on-function framework. Our method combines functional data, optimization, and machine learning techniques to perform feature selection and parameter estimation simultaneously. We exploit the properties of Functional Principal Components, and the sparsity inherent to the Dual Augmented Lagrangian problem to significantly reduce computational cost, and we introduce an adaptive scheme to improve selection accuracy. Through an extensive simulation study, we benchmark our approach to the best existing competitors and demonstrate a 
&lt;/p&gt;</description></item></channel></rss>