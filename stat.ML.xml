<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#12289;&#23436;&#20840;&#38750;&#21442;&#25968;&#30340;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#35774;&#32622;&#65292;&#26088;&#22312;&#22312;&#22810;&#20010;&#20998;&#24067;&#20043;&#38388;&#23398;&#20064;&#22240;&#26524;&#20851;&#31995;&#65292;&#26080;&#38656;&#20551;&#35774;&#30828;&#24178;&#39044;&#12290;&#36890;&#36807;&#31232;&#30095;&#24615;&#32422;&#26463;&#65292;&#21487;&#20197;&#20174;&#22810;&#20010;&#20998;&#24067;&#20013;&#24674;&#22797;&#20986;&#22240;&#26524;&#20851;&#31995;&#12290;</title><link>https://arxiv.org/abs/2402.05052</link><description>&lt;p&gt;
&#20174;&#22810;&#20010;&#20998;&#24067;&#20013;&#36827;&#34892;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#65306;&#19968;&#20010;&#36890;&#29992;&#35774;&#32622;
&lt;/p&gt;
&lt;p&gt;
Causal Representation Learning from Multiple Distributions: A General Setting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05052
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#12289;&#23436;&#20840;&#38750;&#21442;&#25968;&#30340;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#35774;&#32622;&#65292;&#26088;&#22312;&#22312;&#22810;&#20010;&#20998;&#24067;&#20043;&#38388;&#23398;&#20064;&#22240;&#26524;&#20851;&#31995;&#65292;&#26080;&#38656;&#20551;&#35774;&#30828;&#24178;&#39044;&#12290;&#36890;&#36807;&#31232;&#30095;&#24615;&#32422;&#26463;&#65292;&#21487;&#20197;&#20174;&#22810;&#20010;&#20998;&#24067;&#20013;&#24674;&#22797;&#20986;&#22240;&#26524;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#38382;&#39064;&#20013;&#65292;&#27979;&#37327;&#21464;&#37327;&#65288;&#20363;&#22914;&#22270;&#20687;&#20687;&#32032;&#65289;&#21482;&#26159;&#38544;&#34255;&#30340;&#22240;&#26524;&#21464;&#37327;&#65288;&#20363;&#22914;&#28508;&#22312;&#30340;&#27010;&#24565;&#25110;&#23545;&#35937;&#65289;&#30340;&#25968;&#23398;&#20989;&#25968;&#12290;&#20026;&#20102;&#22312;&#19981;&#26029;&#21464;&#21270;&#30340;&#29615;&#22659;&#20013;&#36827;&#34892;&#39044;&#27979;&#25110;&#23545;&#31995;&#32479;&#36827;&#34892;&#36866;&#24403;&#30340;&#26356;&#25913;&#65292;&#24674;&#22797;&#38544;&#34255;&#30340;&#22240;&#26524;&#21464;&#37327;$Z_i$&#20197;&#21450;&#30001;&#22270;$\mathcal{G}_Z$&#34920;&#31034;&#30340;&#23427;&#20204;&#30340;&#22240;&#26524;&#20851;&#31995;&#26159;&#26377;&#24110;&#21161;&#30340;&#12290;&#36825;&#20010;&#38382;&#39064;&#26368;&#36817;&#34987;&#31216;&#20026;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#12290;&#26412;&#25991;&#20851;&#27880;&#26469;&#33258;&#22810;&#20010;&#20998;&#24067;&#65288;&#26469;&#33258;&#24322;&#26500;&#25968;&#25454;&#25110;&#38750;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#65289;&#30340;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#30340;&#36890;&#29992;&#12289;&#23436;&#20840;&#38750;&#21442;&#25968;&#30340;&#35774;&#32622;&#65292;&#19981;&#38656;&#35201;&#20551;&#35774;&#20998;&#24067;&#25913;&#21464;&#32972;&#21518;&#23384;&#22312;&#30828;&#24178;&#39044;&#12290;&#25105;&#20204;&#26088;&#22312;&#22312;&#36825;&#20010;&#22522;&#26412;&#24773;&#20917;&#19979;&#24320;&#21457;&#36890;&#29992;&#35299;&#20915;&#26041;&#26696;&#65307;&#20316;&#20026;&#21103;&#20135;&#21697;&#65292;&#36825;&#26377;&#21161;&#20110;&#30475;&#21040;&#20854;&#20182;&#20551;&#35774;&#65288;&#22914;&#21442;&#25968;&#22240;&#26524;&#27169;&#22411;&#25110;&#30828;&#24178;&#39044;&#65289;&#25552;&#20379;&#30340;&#29420;&#29305;&#22909;&#22788;&#12290;&#25105;&#20204;&#35777;&#26126;&#22312;&#24674;&#22797;&#36807;&#31243;&#20013;&#23545;&#22270;&#30340;&#31232;&#30095;&#24615;&#32422;&#26463;&#19979;&#65292;&#21487;&#20197;&#20174;&#22810;&#20010;&#20998;&#24067;&#20013;&#23398;&#20064;&#20986;&#22240;&#26524;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many problems, the measured variables (e.g., image pixels) are just mathematical functions of the hidden causal variables (e.g., the underlying concepts or objects). For the purpose of making predictions in changing environments or making proper changes to the system, it is helpful to recover the hidden causal variables $Z_i$ and their causal relations represented by graph $\mathcal{G}_Z$. This problem has recently been known as causal representation learning. This paper is concerned with a general, completely nonparametric setting of causal representation learning from multiple distributions (arising from heterogeneous data or nonstationary time series), without assuming hard interventions behind distribution changes. We aim to develop general solutions in this fundamental case; as a by product, this helps see the unique benefit offered by other assumptions such as parametric causal models or hard interventions. We show that under the sparsity constraint on the recovered graph over
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#21644;&#32479;&#19968;&#31163;&#25955;&#21644;&#36830;&#32493;&#26102;&#38388;&#31163;&#25955;&#21435;&#22122;&#25193;&#25955;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#25968;&#23398;&#31616;&#21270;&#21644;&#25512;&#23548;&#65292;&#20351;&#24471;&#31163;&#25955;&#25193;&#25955;&#30340;&#35757;&#32451;&#26356;&#20934;&#30830;&#26131;&#20248;&#21270;&#65292;&#24182;&#19988;&#23454;&#29616;&#20102;&#31934;&#30830;&#21644;&#21152;&#36895;&#30340;&#37319;&#26679;&#12290;&#21516;&#26102;&#65292;&#25104;&#21151;&#22320;&#32479;&#19968;&#20102;&#31163;&#25955;&#26102;&#38388;&#21644;&#36830;&#32493;&#26102;&#38388;&#31163;&#25955;&#25193;&#25955;&#12290;</title><link>https://arxiv.org/abs/2402.03701</link><description>&lt;p&gt;
&#25913;&#36827;&#21644;&#32479;&#19968;&#31163;&#25955;&#21644;&#36830;&#32493;&#26102;&#38388;&#31163;&#25955;&#21435;&#22122;&#25193;&#25955;
&lt;/p&gt;
&lt;p&gt;
Improving and Unifying Discrete&amp;Continuous-time Discrete Denoising Diffusion
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03701
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#21644;&#32479;&#19968;&#31163;&#25955;&#21644;&#36830;&#32493;&#26102;&#38388;&#31163;&#25955;&#21435;&#22122;&#25193;&#25955;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#25968;&#23398;&#31616;&#21270;&#21644;&#25512;&#23548;&#65292;&#20351;&#24471;&#31163;&#25955;&#25193;&#25955;&#30340;&#35757;&#32451;&#26356;&#20934;&#30830;&#26131;&#20248;&#21270;&#65292;&#24182;&#19988;&#23454;&#29616;&#20102;&#31934;&#30830;&#21644;&#21152;&#36895;&#30340;&#37319;&#26679;&#12290;&#21516;&#26102;&#65292;&#25104;&#21151;&#22320;&#32479;&#19968;&#20102;&#31163;&#25955;&#26102;&#38388;&#21644;&#36830;&#32493;&#26102;&#38388;&#31163;&#25955;&#25193;&#25955;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#25955;&#25193;&#25955;&#27169;&#22411;&#22312;&#33258;&#28982;&#31163;&#25955;&#25968;&#25454;&#22914;&#35821;&#35328;&#21644;&#22270;&#24418;&#19978;&#24471;&#21040;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#34429;&#28982;&#31163;&#25955;&#26102;&#38388;&#31163;&#25955;&#25193;&#25955;&#24050;&#32463;&#24314;&#31435;&#20102;&#19968;&#27573;&#26102;&#38388;&#65292;&#20294;&#30452;&#21040;&#26368;&#36817;Campbell&#31561;&#20154;&#65288;2022&#65289;&#25165;&#24341;&#20837;&#20102;&#36830;&#32493;&#26102;&#38388;&#31163;&#25955;&#25193;&#25955;&#30340;&#31532;&#19968;&#20010;&#26694;&#26550;&#12290;&#28982;&#32780;&#65292;&#20182;&#20204;&#30340;&#35757;&#32451;&#21644;&#37319;&#26679;&#36807;&#31243;&#19982;&#31163;&#25955;&#26102;&#38388;&#29256;&#26412;&#26377;&#24456;&#22823;&#24046;&#24322;&#65292;&#38656;&#35201;&#38750;&#24179;&#20961;&#30340;&#36817;&#20284;&#25165;&#33021;&#36827;&#34892;&#21487;&#34892;&#24615;&#20998;&#26512;&#12290;&#26412;&#25991;&#39318;&#20808;&#20171;&#32461;&#20102;&#19968;&#31995;&#21015;&#23545;&#21464;&#20998;&#19979;&#30028;&#30340;&#25968;&#23398;&#31616;&#21270;&#65292;&#36825;&#20123;&#31616;&#21270;&#20351;&#31163;&#25955;&#25193;&#25955;&#30340;&#35757;&#32451;&#26356;&#21152;&#20934;&#30830;&#21644;&#26131;&#20110;&#20248;&#21270;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#21453;&#21521;&#21435;&#22122;&#20844;&#24335;&#65292;&#33021;&#22815;&#23454;&#29616;&#31934;&#30830;&#21644;&#21152;&#36895;&#30340;&#37319;&#26679;&#65292;&#26356;&#37325;&#35201;&#30340;&#26159;&#33021;&#22815;&#20248;&#38597;&#22320;&#32479;&#19968;&#31163;&#25955;&#26102;&#38388;&#21644;&#36830;&#32493;&#26102;&#38388;&#31163;&#25955;&#25193;&#25955;&#12290;&#36890;&#36807;&#26356;&#31616;&#21333;&#30340;&#20998;&#26512;&#20844;&#24335;&#65292;&#21069;&#21521;&#21644;&#29616;&#22312;&#20063;&#21253;&#25324;&#20102;&#21518;&#21521;&#27010;&#29575;&#21487;&#20197;&#28789;&#27963;&#22320;&#36866;&#24212;&#20219;&#20309;&#22122;&#22768;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
Discrete diffusion models have seen a surge of attention with applications on naturally discrete data such as language and graphs. Although discrete-time discrete diffusion has been established for a while, only recently Campbell et al. (2022) introduced the first framework for continuous-time discrete diffusion. However, their training and sampling processes differ significantly from the discrete-time version, necessitating nontrivial approximations for tractability. In this paper, we first present a series of mathematical simplifications of the variational lower bound that enable more accurate and easy-to-optimize training for discrete diffusion. In addition, we derive a simple formulation for backward denoising that enables exact and accelerated sampling, and importantly, an elegant unification of discrete-time and continuous-time discrete diffusion. Thanks to simpler analytical formulations, both forward and now also backward probabilities can flexibly accommodate any noise distrib
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21629;&#21517;&#20026;FKMD&#30340;&#20808;&#36827;KMD&#25216;&#26415;&#65292;&#36890;&#36807;&#26102;&#38388;&#23884;&#20837;&#21644;&#39532;&#27663;&#36317;&#31163;&#32553;&#25918;&#65292;&#21487;&#20197;&#22686;&#24378;&#23545;&#39640;&#32500;&#21160;&#21147;&#31995;&#32479;&#30340;&#20998;&#26512;&#21644;&#39044;&#27979;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#29305;&#24449;&#26410;&#30693;&#30340;&#24773;&#20917;&#65292;&#24182;&#22312;&#19993;&#27688;&#37240;&#20108;&#32957;&#25968;&#25454;&#38477;&#32500;&#21644;&#20998;&#26512;Lorenz&#21560;&#24341;&#23376;&#21644;&#30284;&#30151;&#30740;&#31350;&#20013;&#32454;&#32990;&#20449;&#21495;&#38382;&#39064;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2312.09146</link><description>&lt;p&gt;
&#23545;Koopman&#27169;&#24577;&#20998;&#35299;&#36827;&#34892;&#29305;&#24449;&#21270;&#22788;&#29702;
&lt;/p&gt;
&lt;p&gt;
Featurizing Koopman Mode Decomposition
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.09146
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21629;&#21517;&#20026;FKMD&#30340;&#20808;&#36827;KMD&#25216;&#26415;&#65292;&#36890;&#36807;&#26102;&#38388;&#23884;&#20837;&#21644;&#39532;&#27663;&#36317;&#31163;&#32553;&#25918;&#65292;&#21487;&#20197;&#22686;&#24378;&#23545;&#39640;&#32500;&#21160;&#21147;&#31995;&#32479;&#30340;&#20998;&#26512;&#21644;&#39044;&#27979;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#29305;&#24449;&#26410;&#30693;&#30340;&#24773;&#20917;&#65292;&#24182;&#22312;&#19993;&#27688;&#37240;&#20108;&#32957;&#25968;&#25454;&#38477;&#32500;&#21644;&#20998;&#26512;Lorenz&#21560;&#24341;&#23376;&#21644;&#30284;&#30151;&#30740;&#31350;&#20013;&#32454;&#32990;&#20449;&#21495;&#38382;&#39064;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20808;&#36827;&#30340;Koopman&#27169;&#24577;&#20998;&#35299;&#65288;KMD&#65289;&#25216;&#26415;&#65306;&#21629;&#21517;&#20026;&#29305;&#24449;&#21270;Koopman&#27169;&#24577;&#20998;&#35299;&#65288;FKMD&#65289;&#65292;&#35813;&#25216;&#26415;&#21033;&#29992;&#26102;&#38388;&#23884;&#20837;&#21644;&#39532;&#27663;&#36317;&#31163;&#32553;&#25918;&#26469;&#22686;&#24378;&#23545;&#39640;&#32500;&#21160;&#21147;&#31995;&#32479;&#30340;&#20998;&#26512;&#21644;&#39044;&#27979;&#12290;&#26102;&#38388;&#23884;&#20837;&#25193;&#23637;&#20102;&#35266;&#27979;&#31354;&#38388;&#65292;&#26356;&#22909;&#22320;&#25429;&#25417;&#22522;&#30784;&#27969;&#24418;&#32467;&#26500;&#65292;&#32780;&#24212;&#29992;&#20110;&#26680;&#20989;&#25968;&#25110;&#38543;&#26426;&#20613;&#37324;&#21494;&#29305;&#24449;&#30340;&#39532;&#27663;&#36317;&#31163;&#32553;&#25918;&#65292;&#21017;&#26681;&#25454;&#31995;&#32479;&#30340;&#21160;&#24577;&#35843;&#25972;&#35266;&#27979;&#20540;&#12290;&#36825;&#26377;&#21161;&#20110;&#22312;&#19981;&#20107;&#20808;&#30693;&#36947;&#33391;&#22909;&#29305;&#24449;&#30340;&#24773;&#20917;&#19979;&#23545;KMD&#36827;&#34892;&#29305;&#24449;&#21270;&#22788;&#29702;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;FKMD&#20013;&#30340;&#39532;&#27663;&#36317;&#31163;&#32553;&#25918;&#21487;&#29992;&#20110;&#23545;&#19993;&#27688;&#37240;&#20108;&#32957;&#25968;&#25454;&#36827;&#34892;&#26377;&#25928;&#30340;&#38477;&#32500;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;FKMD&#22914;&#20309;&#25913;&#21892;&#23545;&#39640;&#32500;Lorenz&#21560;&#24341;&#23376;&#21644;&#30284;&#30151;&#30740;&#31350;&#20013;&#30340;&#32454;&#32990;&#20449;&#21495;&#38382;&#39064;&#30340;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.09146v3 Announce Type: replace-cross  Abstract: This article introduces an advanced Koopman mode decomposition (KMD) technique -- coined Featurized Koopman Mode Decomposition (FKMD) -- that uses time embedding and Mahalanobis scaling to enhance analysis and prediction of high dimensional dynamical systems. The time embedding expands the observation space to better capture underlying manifold structure, while the Mahalanobis scaling, applied to kernel or random Fourier features, adjusts observations based on the system's dynamics. This aids in featurizing KMD in cases where good features are not a priori known. We find that the Mahalanobis scaling from FKMD can be used for effective dimensionality reduction of alanine dipeptide data. We also show that FKMD improves predictions for a high-dimensional Lorenz attractor and a cell signaling problem from cancer research.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#31181;&#23454;&#29992;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#28145;&#24230;&#29983;&#25104;&#32452;&#20214;&#30340;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#20013;&#35745;&#31639;&#22238;&#28335;&#21453;&#20107;&#23454;&#12290;&#36890;&#36807;&#22312;&#22240;&#26524;&#27169;&#22411;&#30340;&#32467;&#26500;&#21270;&#28508;&#22312;&#31354;&#38388;&#20013;&#35299;&#20915;&#20248;&#21270;&#38382;&#39064;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#29983;&#25104;&#21453;&#20107;&#23454;&#65292;&#24182;&#19988;&#19982;&#20854;&#20182;&#26041;&#27861;&#30456;&#27604;&#20855;&#22791;&#20102;&#22810;&#21151;&#33021;&#12289;&#27169;&#22359;&#21270;&#21644;&#31526;&#21512;&#22240;&#26524;&#20851;&#31995;&#30340;&#29305;&#28857;&#12290;</title><link>http://arxiv.org/abs/2310.07665</link><description>&lt;p&gt;
&#28145;&#24230;&#22238;&#28335;&#23545;&#22240;&#26524;&#19968;&#33268;&#35299;&#37322;&#30340;&#21453;&#20107;&#23454;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Deep Backtracking Counterfactuals for Causally Compliant Explanations. (arXiv:2310.07665v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07665
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#31181;&#23454;&#29992;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#28145;&#24230;&#29983;&#25104;&#32452;&#20214;&#30340;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#20013;&#35745;&#31639;&#22238;&#28335;&#21453;&#20107;&#23454;&#12290;&#36890;&#36807;&#22312;&#22240;&#26524;&#27169;&#22411;&#30340;&#32467;&#26500;&#21270;&#28508;&#22312;&#31354;&#38388;&#20013;&#35299;&#20915;&#20248;&#21270;&#38382;&#39064;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#29983;&#25104;&#21453;&#20107;&#23454;&#65292;&#24182;&#19988;&#19982;&#20854;&#20182;&#26041;&#27861;&#30456;&#27604;&#20855;&#22791;&#20102;&#22810;&#21151;&#33021;&#12289;&#27169;&#22359;&#21270;&#21644;&#31526;&#21512;&#22240;&#26524;&#20851;&#31995;&#30340;&#29305;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21453;&#20107;&#23454;&#25512;&#29702;&#21487;&#20197;&#36890;&#36807;&#22238;&#31572;&#22312;&#25913;&#21464;&#24773;&#20917;&#19979;&#20250;&#35266;&#23519;&#21040;&#20160;&#20040;&#26469;&#25552;&#20379;&#26377;&#20215;&#20540;&#30340;&#35265;&#35299;&#65292;&#26465;&#20214;&#26159;&#26681;&#25454;&#23454;&#38469;&#35266;&#23519;&#12290;&#34429;&#28982;&#32463;&#20856;&#30340;&#20171;&#20837;&#24335;&#35299;&#37322;&#24050;&#32463;&#24471;&#21040;&#20102;&#24191;&#27867;&#30740;&#31350;&#65292;&#22238;&#28335;&#21407;&#21017;&#34987;&#25552;&#20986;&#20316;&#20026;&#19968;&#31181;&#20445;&#25345;&#25152;&#26377;&#22240;&#26524;&#23450;&#24459;&#23436;&#25972;&#24615;&#30340;&#26367;&#20195;&#21746;&#23398;&#65292;&#20294;&#20854;&#30740;&#31350;&#36739;&#23569;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#22312;&#30001;&#28145;&#24230;&#29983;&#25104;&#32452;&#20214;&#32452;&#25104;&#30340;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#20013;&#35745;&#31639;&#22238;&#28335;&#21453;&#20107;&#23454;&#30340;&#23454;&#29992;&#26041;&#27861;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#23545;&#32467;&#26500;&#20998;&#37197;&#26045;&#21152;&#20102;&#26465;&#20214;&#65292;&#36890;&#36807;&#22312;&#22240;&#26524;&#27169;&#22411;&#30340;&#32467;&#26500;&#21270;&#28508;&#22312;&#31354;&#38388;&#20013;&#35299;&#20915;&#19968;&#20010;&#21487;&#34892;&#30340;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#26469;&#29983;&#25104;&#21453;&#20107;&#23454;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36824;&#21487;&#20197;&#19982;&#21453;&#20107;&#23454;&#35299;&#37322;&#39046;&#22495;&#30340;&#26041;&#27861;&#36827;&#34892;&#27604;&#36739;&#12290;&#19982;&#36825;&#20123;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20195;&#34920;&#20102;&#19968;&#31181;&#22810;&#21151;&#33021;&#12289;&#27169;&#22359;&#21270;&#21644;&#36981;&#23432;&#22240;&#26524;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Counterfactuals can offer valuable insights by answering what would have been observed under altered circumstances, conditional on a factual observation. Whereas the classical interventional interpretation of counterfactuals has been studied extensively, backtracking constitutes a less studied alternative the backtracking principle has emerged as an alternative philosophy where all causal laws are kept intact. In the present work, we introduce a practical method for computing backtracking counterfactuals in structural causal models that consist of deep generative components. To this end, we impose conditions on the structural assignments that enable the generation of counterfactuals by solving a tractable constrained optimization problem in the structured latent space of a causal model. Our formulation also facilitates a comparison with methods in the field of counterfactual explanations. Compared to these, our method represents a versatile, modular and causally compliant alternative. 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#21033;&#29992;&#36827;&#21270;&#31526;&#21495;&#22238;&#24402;&#20316;&#20026;&#20027;&#21160;&#23398;&#20064;&#20013;&#30340;&#26041;&#27861;&#26469;&#25552;&#20986;&#21738;&#20123;&#25968;&#25454;&#24212;&#35813;&#34987;&#37319;&#38598;&#65292;&#36890;&#36807;&#8220;&#22996;&#21592;&#20250;&#26597;&#35810;&#8221;&#26469;&#20943;&#23569;&#25152;&#38656;&#25968;&#25454;&#65292;&#24182;&#22312;&#37325;&#26032;&#21457;&#29616;&#24050;&#30693;&#26041;&#31243;&#25152;&#38656;&#30340;&#25968;&#25454;&#26041;&#38754;&#23454;&#29616;&#26368;&#26032;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2305.10379</link><description>&lt;p&gt;
&#22522;&#20110;&#29289;&#29702;&#32422;&#26463;&#30340;&#31526;&#21495;&#22238;&#24402;&#20013;&#20027;&#21160;&#23398;&#20064;&#30340;&#34920;&#29616;
&lt;/p&gt;
&lt;p&gt;
Active Learning in Symbolic Regression Performance with Physical Constraints. (arXiv:2305.10379v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10379
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#21033;&#29992;&#36827;&#21270;&#31526;&#21495;&#22238;&#24402;&#20316;&#20026;&#20027;&#21160;&#23398;&#20064;&#20013;&#30340;&#26041;&#27861;&#26469;&#25552;&#20986;&#21738;&#20123;&#25968;&#25454;&#24212;&#35813;&#34987;&#37319;&#38598;&#65292;&#36890;&#36807;&#8220;&#22996;&#21592;&#20250;&#26597;&#35810;&#8221;&#26469;&#20943;&#23569;&#25152;&#38656;&#25968;&#25454;&#65292;&#24182;&#22312;&#37325;&#26032;&#21457;&#29616;&#24050;&#30693;&#26041;&#31243;&#25152;&#38656;&#30340;&#25968;&#25454;&#26041;&#38754;&#23454;&#29616;&#26368;&#26032;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36827;&#21270;&#31526;&#21495;&#22238;&#24402;&#65288;SR&#65289;&#26159;&#19968;&#31181;&#23558;&#31526;&#21495;&#26041;&#31243;&#25311;&#21512;&#21040;&#25968;&#25454;&#20013;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#24471;&#21040;&#31616;&#27905;&#26131;&#25026;&#30340;&#27169;&#22411;&#12290;&#26412;&#25991;&#25506;&#35752;&#20351;&#29992;SR&#20316;&#20026;&#20027;&#21160;&#23398;&#20064;&#20013;&#30340;&#26041;&#27861;&#26469;&#25552;&#20986;&#21738;&#20123;&#25968;&#25454;&#24212;&#35813;&#34987;&#37319;&#38598;&#65292;&#22312;&#27492;&#36807;&#31243;&#20013;&#32771;&#34385;&#29289;&#29702;&#32422;&#26463;&#12290;&#22522;&#20110;&#20027;&#21160;&#23398;&#20064;&#30340;SR&#36890;&#36807;&#8220;&#22996;&#21592;&#20250;&#26597;&#35810;&#8221;&#26469;&#25552;&#20986;&#19979;&#19968;&#27493;&#23454;&#39564;&#12290;&#29289;&#29702;&#32422;&#26463;&#21487;&#20197;&#22312;&#38750;&#24120;&#20302;&#30340;&#25968;&#25454;&#24773;&#20917;&#19979;&#25913;&#21892;&#25152;&#24314;&#35758;&#30340;&#26041;&#31243;&#12290;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#20943;&#23569;SR&#25152;&#38656;&#30340;&#25968;&#25454;&#65292;&#24182;&#22312;&#37325;&#26032;&#21457;&#29616;&#24050;&#30693;&#26041;&#31243;&#25152;&#38656;&#30340;&#25968;&#25454;&#26041;&#38754;&#23454;&#29616;&#26368;&#26032;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Evolutionary symbolic regression (SR) fits a symbolic equation to data, which gives a concise interpretable model. We explore using SR as a method to propose which data to gather in an active learning setting with physical constraints. SR with active learning proposes which experiments to do next. Active learning is done with query by committee, where the Pareto frontier of equations is the committee. The physical constraints improve proposed equations in very low data settings. These approaches reduce the data required for SR and achieves state of the art results in data required to rediscover known equations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#28151;&#21512;VAE&#27169;&#22411;&#23398;&#20064;&#27969;&#24418;&#30340;&#26041;&#27861;&#65292;&#24182;&#23558;&#20854;&#29992;&#20110;&#35299;&#20915;&#36870;&#38382;&#39064;&#65292;&#32467;&#26524;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#65292;&#21487;&#29992;&#20110;&#27169;&#31946;&#21644;&#30005;&#38459;&#25239;&#23618;&#26512;&#25104;&#20687;&#12290;</title><link>http://arxiv.org/abs/2303.15244</link><description>&lt;p&gt;
&#29992;&#28151;&#21512;VAE&#27169;&#22411;&#23398;&#20064;&#27969;&#24418;&#26469;&#35299;&#20915;&#36870;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Manifold Learning by Mixture Models of VAEs for Inverse Problems. (arXiv:2303.15244v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15244
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#28151;&#21512;VAE&#27169;&#22411;&#23398;&#20064;&#27969;&#24418;&#30340;&#26041;&#27861;&#65292;&#24182;&#23558;&#20854;&#29992;&#20110;&#35299;&#20915;&#36870;&#38382;&#39064;&#65292;&#32467;&#26524;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#65292;&#21487;&#29992;&#20110;&#27169;&#31946;&#21644;&#30005;&#38459;&#25239;&#23618;&#26512;&#25104;&#20687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#36341;&#20013;&#65292;&#20351;&#29992;&#29983;&#25104;&#27169;&#22411;&#34920;&#31034;&#39640;&#32500;&#25968;&#25454;&#30340;&#27969;&#24418;&#24050;&#34987;&#35777;&#26126;&#20855;&#26377;&#35745;&#31639;&#25928;&#29575;&#12290;&#28982;&#32780;&#65292;&#36825;&#35201;&#27714;&#25968;&#25454;&#27969;&#24418;&#20855;&#26377;&#20840;&#23616;&#21442;&#25968;&#21270;&#12290;&#20026;&#20102;&#34920;&#31034;&#20219;&#24847;&#25299;&#25169;&#30340;&#27969;&#24418;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23398;&#20064;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;&#28151;&#21512;&#27169;&#22411;&#12290;&#36825;&#37324;&#65292;&#27599;&#20010;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#23545;&#34920;&#31034;&#27969;&#24418;&#30340;&#19968;&#20010;&#22270;&#34920;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25439;&#22833;&#20989;&#25968;&#26469;&#26368;&#22823;&#21270;&#20284;&#28982;&#20272;&#35745;&#27169;&#22411;&#26435;&#37325;&#65292;&#24182;&#36873;&#25321;&#19968;&#20010;&#26550;&#26500;&#65292;&#20026;&#25105;&#20204;&#25552;&#20379;&#22270;&#34920;&#21450;&#20854;&#36870;&#30340;&#35299;&#26512;&#34920;&#36798;&#24335;&#12290;&#19968;&#26086;&#23398;&#20064;&#20102;&#27969;&#24418;&#65292;&#25105;&#20204;&#23558;&#20854;&#29992;&#20110;&#36890;&#36807;&#23558;&#25968;&#25454;&#25311;&#21512;&#39033;&#38480;&#21046;&#22312;&#23398;&#20064;&#30340;&#27969;&#24418;&#19978;&#26469;&#35299;&#20915;&#36870;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#25152;&#20135;&#29983;&#30340;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#25105;&#20204;&#22312;&#23398;&#20064;&#30340;&#27969;&#24418;&#19978;&#25552;&#20986;&#20102;&#19968;&#31181;&#40654;&#26364;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20302;&#32500;&#29609;&#20855;&#20363;&#23376;&#20197;&#21450;&#27169;&#31946;&#21644;&#30005;&#38459;&#25239;&#23618;&#26512;&#25104;&#20687;&#26041;&#38754;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Representing a manifold of very high-dimensional data with generative models has been shown to be computationally efficient in practice. However, this requires that the data manifold admits a global parameterization. In order to represent manifolds of arbitrary topology, we propose to learn a mixture model of variational autoencoders. Here, every encoder-decoder pair represents one chart of a manifold. We propose a loss function for maximum likelihood estimation of the model weights and choose an architecture that provides us the analytical expression of the charts and of their inverses. Once the manifold is learned, we use it for solving inverse problems by minimizing a data fidelity term restricted to the learned manifold. To solve the arising minimization problem we propose a Riemannian gradient descent algorithm on the learned manifold. We demonstrate the performance of our method for low-dimensional toy examples as well as for deblurring and electrical impedance tomography on cert
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#22312;&#20960;&#20046;&#32447;&#24615;&#20108;&#27425;&#22411;&#35843;&#33410;&#22120;&#31995;&#32479;&#20013;&#25214;&#21040;&#26368;&#20248;&#31574;&#30053;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31574;&#30053;&#26799;&#24230;&#31639;&#27861;&#65292;&#21487;&#20197;&#20197;&#32447;&#24615;&#36895;&#29575;&#25910;&#25947;&#20110;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;</title><link>http://arxiv.org/abs/2303.08431</link><description>&lt;p&gt;
&#25919;&#31574;&#26799;&#24230;&#31639;&#27861;&#25910;&#25947;&#20110;&#20960;&#20046;&#32447;&#24615;&#20108;&#27425;&#22411;&#35843;&#33410;&#22120;&#30340;&#20840;&#23616;&#26368;&#20248;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Policy Gradient Converges to the Globally Optimal Policy for Nearly Linear-Quadratic Regulators. (arXiv:2303.08431v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08431
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#22312;&#20960;&#20046;&#32447;&#24615;&#20108;&#27425;&#22411;&#35843;&#33410;&#22120;&#31995;&#32479;&#20013;&#25214;&#21040;&#26368;&#20248;&#31574;&#30053;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31574;&#30053;&#26799;&#24230;&#31639;&#27861;&#65292;&#21487;&#20197;&#20197;&#32447;&#24615;&#36895;&#29575;&#25910;&#25947;&#20110;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20915;&#31574;&#32773;&#21482;&#33719;&#24471;&#20102;&#38750;&#23436;&#25972;&#20449;&#24687;&#30340;&#38750;&#32447;&#24615;&#25511;&#21046;&#31995;&#32479;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#26222;&#36941;&#23384;&#22312;&#12290;&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#20197;&#25214;&#21040;&#20960;&#20046;&#32447;&#24615;&#20108;&#27425;&#22411;&#35843;&#33410;&#22120;&#31995;&#32479;&#20013;&#26368;&#20248;&#31574;&#30053;&#12290;&#25105;&#20204;&#32771;&#34385;&#19968;&#20010;&#21160;&#24577;&#31995;&#32479;&#65292;&#32467;&#21512;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#32452;&#25104;&#37096;&#20998;&#65292;&#24182;&#30001;&#30456;&#21516;&#32467;&#26500;&#30340;&#31574;&#30053;&#36827;&#34892;&#31649;&#29702;&#12290;&#22312;&#20551;&#35774;&#38750;&#32447;&#24615;&#32452;&#25104;&#37096;&#20998;&#21253;&#21547;&#20855;&#26377;&#23567;&#22411;Lipschitz&#31995;&#25968;&#30340;&#20869;&#26680;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#23545;&#25104;&#26412;&#20989;&#25968;&#30340;&#20248;&#21270;&#36827;&#34892;&#20102;&#34920;&#24449;&#12290;&#34429;&#28982;&#25104;&#26412;&#20989;&#25968;&#36890;&#24120;&#26159;&#38750;&#20984;&#30340;&#65292;&#20294;&#25105;&#20204;&#30830;&#31435;&#20102;&#20840;&#23616;&#26368;&#20248;&#35299;&#38468;&#36817;&#23616;&#37096;&#30340;&#24378;&#20984;&#24615;&#21644;&#20809;&#28369;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21021;&#22987;&#21270;&#26426;&#21046;&#65292;&#20197;&#21033;&#29992;&#36825;&#20123;&#23646;&#24615;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#31574;&#30053;&#26799;&#24230;&#31639;&#27861;&#65292;&#21487;&#20197;&#20445;&#35777;&#20197;&#32447;&#24615;&#36895;&#29575;&#25910;&#25947;&#20110;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nonlinear control systems with partial information to the decision maker are prevalent in a variety of applications. As a step toward studying such nonlinear systems, this work explores reinforcement learning methods for finding the optimal policy in the nearly linear-quadratic regulator systems. In particular, we consider a dynamic system that combines linear and nonlinear components, and is governed by a policy with the same structure. Assuming that the nonlinear component comprises kernels with small Lipschitz coefficients, we characterize the optimization landscape of the cost function. Although the cost function is nonconvex in general, we establish the local strong convexity and smoothness in the vicinity of the global optimizer. Additionally, we propose an initialization mechanism to leverage these properties. Building on the developments, we design a policy gradient algorithm that is guaranteed to converge to the globally optimal policy with a linear rate.
&lt;/p&gt;</description></item></channel></rss>