<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#28378;&#21160;&#25193;&#25955;&#27169;&#22411;&#65292;&#29992;&#20110;&#22788;&#29702;&#26102;&#38388;&#25968;&#25454;&#65292;&#36890;&#36807;&#28369;&#21160;&#31383;&#21475;&#21435;&#22122;&#24182;&#26681;&#25454;&#24103;&#22312;&#24207;&#21015;&#20013;&#30340;&#26102;&#38388;&#20808;&#21518;&#20998;&#37197;&#19981;&#21516;&#30340;&#22122;&#22768;&#37327;&#65292;&#26356;&#22909;&#22320;&#25429;&#25417;&#21040;&#22797;&#26434;&#30340;&#26102;&#38388;&#21160;&#24577;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#35270;&#39057;&#39044;&#27979;&#21644;&#28151;&#27788;&#27969;&#20307;&#21160;&#21147;&#23398;&#39044;&#27979;&#20219;&#21153;&#20013;&#65292;&#35813;&#27169;&#22411;&#20248;&#20110;&#20256;&#32479;&#25193;&#25955;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.09470</link><description>&lt;p&gt;
&#28378;&#21160;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Rolling Diffusion Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09470
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#28378;&#21160;&#25193;&#25955;&#27169;&#22411;&#65292;&#29992;&#20110;&#22788;&#29702;&#26102;&#38388;&#25968;&#25454;&#65292;&#36890;&#36807;&#28369;&#21160;&#31383;&#21475;&#21435;&#22122;&#24182;&#26681;&#25454;&#24103;&#22312;&#24207;&#21015;&#20013;&#30340;&#26102;&#38388;&#20808;&#21518;&#20998;&#37197;&#19981;&#21516;&#30340;&#22122;&#22768;&#37327;&#65292;&#26356;&#22909;&#22320;&#25429;&#25417;&#21040;&#22797;&#26434;&#30340;&#26102;&#38388;&#21160;&#24577;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#35270;&#39057;&#39044;&#27979;&#21644;&#28151;&#27788;&#27969;&#20307;&#21160;&#21147;&#23398;&#39044;&#27979;&#20219;&#21153;&#20013;&#65292;&#35813;&#27169;&#22411;&#20248;&#20110;&#20256;&#32479;&#25193;&#25955;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#25193;&#25955;&#27169;&#22411;&#36234;&#26469;&#36234;&#22810;&#22320;&#24212;&#29992;&#20110;&#26102;&#38388;&#25968;&#25454;&#65292;&#22914;&#35270;&#39057;&#12289;&#27969;&#20307;&#21147;&#23398;&#27169;&#25311;&#25110;&#27668;&#20505;&#25968;&#25454;&#12290;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#23558;&#21518;&#32493;&#24103;&#22312;&#25193;&#25955;&#36807;&#31243;&#20013;&#30340;&#22122;&#22768;&#37327;&#35270;&#20026;&#30456;&#31561;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#28378;&#21160;&#25193;&#25955;&#65306;&#19968;&#31181;&#20351;&#29992;&#28369;&#21160;&#31383;&#21475;&#21435;&#22122;&#30340;&#26032;&#26041;&#27861;&#12290;&#23427;&#30830;&#20445;&#25193;&#25955;&#36807;&#31243;&#36880;&#28176;&#36890;&#36807;&#26102;&#38388;&#36827;&#34892;&#30772;&#22351;&#65292;&#36890;&#36807;&#23558;&#26356;&#22810;&#30340;&#22122;&#22768;&#20998;&#37197;&#32473;&#24207;&#21015;&#20013;&#20986;&#29616;&#36739;&#26202;&#30340;&#24103;&#65292;&#21453;&#26144;&#20986;&#38543;&#30528;&#29983;&#25104;&#36807;&#31243;&#30340;&#23637;&#24320;&#65292;&#23545;&#26410;&#26469;&#30340;&#19981;&#30830;&#23450;&#24615;&#36234;&#26469;&#36234;&#22823;&#12290;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#65292;&#25105;&#20204;&#34920;&#26126;&#24403;&#26102;&#38388;&#21160;&#24577;&#22797;&#26434;&#26102;&#65292;&#28378;&#21160;&#25193;&#25955;&#20248;&#20110;&#26631;&#20934;&#25193;&#25955;&#12290;&#29305;&#21035;&#26159;&#22312;&#20351;&#29992;Kinetics-600&#35270;&#39057;&#25968;&#25454;&#38598;&#36827;&#34892;&#35270;&#39057;&#39044;&#27979;&#20219;&#21153;&#21644;&#28151;&#27788;&#27969;&#20307;&#21160;&#21147;&#23398;&#39044;&#27979;&#23454;&#39564;&#20013;&#35777;&#26126;&#20102;&#36825;&#19968;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09470v1 Announce Type: new  Abstract: Diffusion models have recently been increasingly applied to temporal data such as video, fluid mechanics simulations, or climate data. These methods generally treat subsequent frames equally regarding the amount of noise in the diffusion process. This paper explores Rolling Diffusion: a new approach that uses a sliding window denoising process. It ensures that the diffusion process progressively corrupts through time by assigning more noise to frames that appear later in a sequence, reflecting greater uncertainty about the future as the generation process unfolds. Empirically, we show that when the temporal dynamics are complex, Rolling Diffusion is superior to standard diffusion. In particular, this result is demonstrated in a video prediction task using the Kinetics-600 video dataset and in a chaotic fluid dynamics forecasting experiment.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#30697;&#38453;&#20540;&#26102;&#38388;&#24207;&#21015;&#30340;&#32479;&#35745;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#22312;&#32447;&#22270;&#25299;&#25169;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;&#39318;&#20808;&#65292;&#23558;VAR&#27169;&#22411;&#25193;&#23637;&#20026;&#30697;&#38453;&#21464;&#37327;&#27169;&#22411;&#20197;&#36866;&#29992;&#20110;&#22270;&#24418;&#23398;&#20064;&#12290;&#20854;&#27425;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#22312;&#32447;&#36807;&#31243;&#65292;&#38024;&#23545;&#20302;&#32500;&#21644;&#39640;&#32500;&#24773;&#20917;&#24555;&#36895;&#26356;&#26032;&#31995;&#25968;&#30340;&#20272;&#35745;&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;Lasso-type&#36827;&#34892;&#25299;&#25169;&#22788;&#29702;&#12290;</title><link>https://arxiv.org/abs/2107.08020</link><description>&lt;p&gt;
&#22522;&#20110;&#30697;&#38453;&#20540;&#26102;&#38388;&#24207;&#21015;&#30340;&#22312;&#32447;&#22270;&#25299;&#25169;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Online Graph Topology Learning from Matrix-valued Time Series
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2107.08020
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#30697;&#38453;&#20540;&#26102;&#38388;&#24207;&#21015;&#30340;&#32479;&#35745;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#22312;&#32447;&#22270;&#25299;&#25169;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;&#39318;&#20808;&#65292;&#23558;VAR&#27169;&#22411;&#25193;&#23637;&#20026;&#30697;&#38453;&#21464;&#37327;&#27169;&#22411;&#20197;&#36866;&#29992;&#20110;&#22270;&#24418;&#23398;&#20064;&#12290;&#20854;&#27425;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#22312;&#32447;&#36807;&#31243;&#65292;&#38024;&#23545;&#20302;&#32500;&#21644;&#39640;&#32500;&#24773;&#20917;&#24555;&#36895;&#26356;&#26032;&#31995;&#25968;&#30340;&#20272;&#35745;&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;Lasso-type&#36827;&#34892;&#25299;&#25169;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#30697;&#38453;&#20540;&#26102;&#38388;&#24207;&#21015;&#30340;&#32479;&#35745;&#20998;&#26512;&#12290;&#36825;&#20123;&#25968;&#25454;&#26159;&#22312;&#19968;&#20010;&#20256;&#24863;&#22120;&#32593;&#32476;&#19978;&#25910;&#38598;&#30340;&#65288;&#36890;&#24120;&#26159;&#19968;&#32452;&#31354;&#38388;&#20301;&#32622;&#65289;&#65292;&#35266;&#27979;&#21040;&#27599;&#20010;&#20256;&#24863;&#22120;&#30340;&#27599;&#20010;&#26102;&#38388;&#28857;&#30340;&#29305;&#24449;&#21521;&#37327;&#12290;&#22240;&#27492;&#65292;&#27599;&#20010;&#20256;&#24863;&#22120;&#30001;&#19968;&#20010;&#21521;&#37327;&#26102;&#24207;&#21015;&#26469;&#25551;&#36848;&#12290;&#25105;&#20204;&#24076;&#26395;&#35782;&#21035;&#36825;&#20123;&#20256;&#24863;&#22120;&#20043;&#38388;&#30340;&#20381;&#36182;&#32467;&#26500;&#65292;&#24182;&#29992;&#22270;&#24418;&#26469;&#34920;&#31034;&#23427;&#12290;&#24403;&#27599;&#20010;&#20256;&#24863;&#22120;&#21482;&#26377;&#19968;&#20010;&#29305;&#24449;&#26102;&#65292;&#30690;&#37327;&#33258;&#22238;&#24402;&#27169;&#22411;&#24050;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#25512;&#26029;&#26684;&#20848;&#26480;&#22240;&#26524;&#20851;&#31995;&#30340;&#32467;&#26500;&#12290;&#25152;&#24471;&#21040;&#30340;&#22270;&#34987;&#31216;&#20026;&#22240;&#26524;&#22270;&#12290;&#25105;&#20204;&#30340;&#31532;&#19968;&#20010;&#36129;&#29486;&#26159;&#23558;VAR&#27169;&#22411;&#25193;&#23637;&#20026;&#30697;&#38453;&#21464;&#37327;&#27169;&#22411;&#65292;&#20197;&#29992;&#20110;&#22270;&#24418;&#23398;&#20064;&#30340;&#30446;&#30340;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#22312;&#32447;&#36807;&#31243;&#65292;&#20998;&#21035;&#36866;&#29992;&#20110;&#20302;&#32500;&#21644;&#39640;&#32500;&#24773;&#20917;&#65292;&#22312;&#26032;&#26679;&#26412;&#21040;&#36798;&#26102;&#21487;&#20197;&#24555;&#36895;&#26356;&#26032;&#31995;&#25968;&#30340;&#20272;&#35745;&#12290;&#29305;&#21035;&#26159;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;Lasso-type&#65292;&#24182;&#23545;&#20854;&#36827;&#34892;&#20102;&#25299;&#25169;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper is concerned with the statistical analysis of matrix-valued time series. These are data collected over a network of sensors (typically a set of spatial locations) along time, where a vector of features is observed per time instant per sensor. Thus each sensor is characterized by a vectorial time series. We would like to identify the dependency structure among these sensors and represent it by a graph. When there is only one feature per sensor, the vector auto-regressive models have been widely adapted to infer the structure of Granger causality. The resulting graph is referred to as causal graph. Our first contribution is then extending VAR models to matrix-variate models to serve the purpose of graph learning. Secondly, we propose two online procedures respectively in low and high dimensions, which can update quickly the estimates of coefficients when new samples arrive. In particular in high dimensional regime, a novel Lasso-type is introduced and we develop its homotopy a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;CA-PCA&#31639;&#27861;&#65292;&#23427;&#22522;&#20110;&#26354;&#29575;&#26657;&#20934;&#30340;&#23616;&#37096;PCA&#29256;&#26412;&#65292;&#36890;&#36807;&#32771;&#34385;&#24213;&#23618;&#27969;&#24418;&#30340;&#26354;&#29575;&#65292;&#25913;&#36827;&#20102;&#32500;&#24230;&#20272;&#35745;&#22120;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.13478</link><description>&lt;p&gt;
CA-PCA: &#27979;&#37327;&#26354;&#29575;&#30340;&#27969;&#24418;&#32500;&#24230;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
CA-PCA: Manifold Dimension Estimation, Adapted for Curvature. (arXiv:2309.13478v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13478
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;CA-PCA&#31639;&#27861;&#65292;&#23427;&#22522;&#20110;&#26354;&#29575;&#26657;&#20934;&#30340;&#23616;&#37096;PCA&#29256;&#26412;&#65292;&#36890;&#36807;&#32771;&#34385;&#24213;&#23618;&#27969;&#24418;&#30340;&#26354;&#29575;&#65292;&#25913;&#36827;&#20102;&#32500;&#24230;&#20272;&#35745;&#22120;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#32500;&#25968;&#25454;&#20998;&#26512;&#31639;&#27861;&#30340;&#25104;&#21151;&#24120;&#24402;&#22240;&#20110;&#27969;&#24418;&#20551;&#35774;&#65292;&#21363;&#20551;&#35774;&#25968;&#25454;&#20998;&#24067;&#22312;&#25110;&#25509;&#36817;&#20302;&#32500;&#27969;&#24418;&#19978;&#12290;&#22312;&#36827;&#34892;&#32500;&#24230;&#32422;&#31616;&#20043;&#21069;&#65292;&#30830;&#23450;&#25110;&#20272;&#35745;&#35813;&#27969;&#24418;&#30340;&#32500;&#24230;&#36890;&#24120;&#26159;&#26377;&#29992;&#30340;&#12290;&#29616;&#26377;&#30340;&#32500;&#24230;&#20272;&#35745;&#26041;&#27861;&#20351;&#29992;&#24179;&#22374;&#21333;&#20301;&#29699;&#36827;&#34892;&#26657;&#20934;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;CA-PCA&#65292;&#19968;&#31181;&#22522;&#20110;&#20108;&#27425;&#23884;&#20837;&#26657;&#20934;&#30340;&#23616;&#37096;PCA&#29256;&#26412;&#65292;&#20197;&#32771;&#34385;&#24213;&#23618;&#27969;&#24418;&#30340;&#26354;&#29575;&#12290;&#22823;&#37327;&#30340;&#31934;&#24515;&#23454;&#39564;&#34920;&#26126;&#65292;&#36825;&#31181;&#36866;&#24212;&#24615;&#25913;&#36827;&#20102;&#20272;&#35745;&#22120;&#22312;&#21508;&#31181;&#35774;&#32622;&#19979;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The success of algorithms in the analysis of high-dimensional data is often attributed to the manifold hypothesis, which supposes that this data lie on or near a manifold of much lower dimension. It is often useful to determine or estimate the dimension of this manifold before performing dimension reduction, for instance. Existing methods for dimension estimation are calibrated using a flat unit ball. In this paper, we develop CA-PCA, a version of local PCA based instead on a calibration of a quadratic embedding, acknowledging the curvature of the underlying manifold. Numerous careful experiments show that this adaptation improves the estimator in a wide range of settings.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#23545;&#28151;&#21512;&#27169;&#22411;&#20013;&#28151;&#21512;&#27979;&#24230;&#30340;Wasserstein&#36317;&#31163;&#30340;&#26032;&#30340;&#35268;&#33539;&#35299;&#37322;&#65292;&#24182;&#25552;&#20379;&#20102;&#22312;&#20027;&#39064;&#27169;&#22411;&#20013;&#36827;&#34892;&#27492;&#36317;&#31163;&#25512;&#26029;&#30340;&#24037;&#20855;&#12290;</title><link>http://arxiv.org/abs/2206.12768</link><description>&lt;p&gt;
&#20027;&#39064;&#27169;&#22411;&#20013;&#28151;&#21512;&#27979;&#24230;&#30340;Wasserstein&#36317;&#31163;&#30340;&#20272;&#35745;&#21644;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Estimation and inference for the Wasserstein distance between mixing measures in topic models. (arXiv:2206.12768v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.12768
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#23545;&#28151;&#21512;&#27169;&#22411;&#20013;&#28151;&#21512;&#27979;&#24230;&#30340;Wasserstein&#36317;&#31163;&#30340;&#26032;&#30340;&#35268;&#33539;&#35299;&#37322;&#65292;&#24182;&#25552;&#20379;&#20102;&#22312;&#20027;&#39064;&#27169;&#22411;&#20013;&#36827;&#34892;&#27492;&#36317;&#31163;&#25512;&#26029;&#30340;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28151;&#21512;&#27169;&#22411;&#30340;&#32479;&#35745;&#20998;&#26512;&#20013;&#65292;&#28151;&#21512;&#27979;&#24230;&#30340;Wasserstein&#36317;&#31163;&#24050;&#32463;&#25104;&#20026;&#20102;&#19968;&#20010;&#26680;&#24515;&#38382;&#39064;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#36825;&#31181;&#36317;&#31163;&#30340;&#26032;&#30340;&#35268;&#33539;&#35299;&#37322;&#65292;&#24182;&#25552;&#20379;&#20102;&#22312;&#20027;&#39064;&#27169;&#22411;&#20013;&#36827;&#34892;&#28151;&#21512;&#27979;&#24230;&#30340;Wasserstein&#36317;&#31163;&#25512;&#26029;&#30340;&#24037;&#20855;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#33324;&#21487;&#35782;&#21035;&#28151;&#21512;&#27169;&#22411;&#30340;&#24773;&#20917;&#65292;&#20854;&#20013;&#21253;&#25324;&#20102;&#22810;&#20010;&#26469;&#33258;&#38598;&#21512;$\mathcal{A}$&#20869;&#24102;&#26377;&#20219;&#24847;&#24230;&#37327;$d$&#30340;&#20998;&#24067;&#30340;&#28151;&#21512;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#28151;&#21512;&#27979;&#24230;&#30340;Wasserstein&#36317;&#31163;&#26159;&#21807;&#19968;&#22320;&#34920;&#24449;&#20986;&#28151;&#21512;&#20803;&#32032;&#38598;&#21512;$\mathcal{A}$&#19978;&#24230;&#37327;$d$&#30340;&#26368;&#26377;&#21306;&#20998;&#24615;&#30340;&#20984;&#25193;&#23637;&#12290;&#34429;&#28982;Wasserstein&#36317;&#31163;&#22312;&#28151;&#21512;&#27169;&#22411;&#30340;&#30740;&#31350;&#20013;&#24050;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20294;&#32570;&#20047;&#20844;&#29702;&#35777;&#26126;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#30830;&#31435;&#20102;&#36825;&#20010;&#24230;&#37327;&#20316;&#20026;&#19968;&#20010;&#35268;&#33539;&#36873;&#25321;&#12290;&#29305;&#20934;&#21270;&#36825;&#20010;&#24230;&#37327;&#21040;&#20027;&#39064;&#27169;&#22411;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#36825;&#20010;&#36317;&#31163;&#30340;&#20272;&#35745;&#21644;&#25512;&#26029;&#12290;&#34429;&#28982;$i$
&lt;/p&gt;
&lt;p&gt;
The Wasserstein distance between mixing measures has come to occupy a central place in the statistical analysis of mixture models. This work proposes a new canonical interpretation of this distance and provides tools to perform inference on the Wasserstein distance between mixing measures in topic models.  We consider the general setting of an identifiable mixture model consisting of mixtures of distributions from a set $\mathcal{A}$ equipped with an arbitrary metric $d$, and show that the Wasserstein distance between mixing measures is uniquely characterized as the most discriminative convex extension of the metric $d$ to the set of mixtures of elements of $\mathcal{A}$. The Wasserstein distance between mixing measures has been widely used in the study of such models, but without axiomatic justification. Our results establish this metric to be a canonical choice.  Specializing our results to topic models, we consider estimation and inference of this distance. Though upper bounds for i
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#27010;&#29575;&#35823;&#24046;&#27169;&#22411;&#23545;&#22270;&#21367;&#31215;&#32593;&#32476;&#65288;GCN&#65289;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#24182;&#35777;&#26126;&#20102;&#35823;&#24046;&#27169;&#22411;&#19979;&#37051;&#25509;&#30697;&#38453;&#30340;&#21463;&#38480;&#24615;&#12290;&#36890;&#36807;&#23454;&#39564;&#39564;&#35777;&#20102;&#36825;&#31181;&#35823;&#24046;&#30028;&#38480;&#65292;&#24182;&#30740;&#31350;&#20102;GCN&#22312;&#36825;&#31181;&#27010;&#29575;&#35823;&#24046;&#27169;&#22411;&#19979;&#30340;&#20934;&#30830;&#24615;&#25935;&#24863;&#24615;&#12290;</title><link>http://arxiv.org/abs/2203.07831</link><description>&lt;p&gt;
&#22270;&#24418;&#31070;&#32463;&#32593;&#32476;&#22312;&#27010;&#29575;&#35823;&#24046;&#27169;&#22411;&#19979;&#30340;&#25935;&#24863;&#24615;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Network Sensitivity Under Probabilistic Error Model. (arXiv:2203.07831v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.07831
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#27010;&#29575;&#35823;&#24046;&#27169;&#22411;&#23545;&#22270;&#21367;&#31215;&#32593;&#32476;&#65288;GCN&#65289;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#24182;&#35777;&#26126;&#20102;&#35823;&#24046;&#27169;&#22411;&#19979;&#37051;&#25509;&#30697;&#38453;&#30340;&#21463;&#38480;&#24615;&#12290;&#36890;&#36807;&#23454;&#39564;&#39564;&#35777;&#20102;&#36825;&#31181;&#35823;&#24046;&#30028;&#38480;&#65292;&#24182;&#30740;&#31350;&#20102;GCN&#22312;&#36825;&#31181;&#27010;&#29575;&#35823;&#24046;&#27169;&#22411;&#19979;&#30340;&#20934;&#30830;&#24615;&#25935;&#24863;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#21367;&#31215;&#32593;&#32476;&#65288;GCN&#65289;&#21487;&#20197;&#36890;&#36807;&#22270;&#21367;&#31215;&#25104;&#21151;&#23398;&#20064;&#22270;&#20449;&#21495;&#34920;&#31034;&#12290;&#22270;&#21367;&#31215;&#20381;&#36182;&#20110;&#22270;&#28388;&#27874;&#22120;&#65292;&#20854;&#20013;&#21253;&#21547;&#25968;&#25454;&#30340;&#25299;&#25169;&#20381;&#36182;&#20851;&#31995;&#24182;&#20256;&#25773;&#25968;&#25454;&#29305;&#24449;&#12290;&#28982;&#32780;&#65292;&#22312;&#20256;&#25773;&#30697;&#38453;&#65288;&#20363;&#22914;&#37051;&#25509;&#30697;&#38453;&#65289;&#20013;&#30340;&#20272;&#35745;&#35823;&#24046;&#21487;&#33021;&#23545;&#22270;&#28388;&#27874;&#22120;&#21644;GCNs&#20135;&#29983;&#37325;&#22823;&#24433;&#21709;&#12290;&#26412;&#25991;&#30740;&#31350;&#27010;&#29575;&#22270;&#35823;&#24046;&#27169;&#22411;&#23545;GCN&#24615;&#33021;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#35823;&#24046;&#27169;&#22411;&#19979;&#30340;&#37051;&#25509;&#30697;&#38453;&#21463;&#21040;&#22270;&#22823;&#23567;&#21644;&#35823;&#24046;&#27010;&#29575;&#20989;&#25968;&#30340;&#38480;&#21046;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#20998;&#26512;&#20102;&#24102;&#26377;&#33258;&#24490;&#29615;&#30340;&#24402;&#19968;&#21270;&#37051;&#25509;&#30697;&#38453;&#30340;&#19978;&#30028;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#36816;&#34892;&#23454;&#39564;&#26469;&#35828;&#26126;&#35823;&#24046;&#30028;&#38480;&#65292;&#24182;&#30740;&#31350;&#31616;&#21333;GCN&#22312;&#36825;&#31181;&#27010;&#29575;&#35823;&#24046;&#27169;&#22411;&#19979;&#30340;&#20934;&#30830;&#24615;&#25935;&#24863;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph convolutional networks (GCNs) can successfully learn the graph signal representation by graph convolution. The graph convolution depends on the graph filter, which contains the topological dependency of data and propagates data features. However, the estimation errors in the propagation matrix (e.g., the adjacency matrix) can have a significant impact on graph filters and GCNs. In this paper, we study the effect of a probabilistic graph error model on the performance of the GCNs. We prove that the adjacency matrix under the error model is bounded by a function of graph size and error probability. We further analytically specify the upper bound of a normalized adjacency matrix with self-loop added. Finally, we illustrate the error bounds by running experiments on a synthetic dataset and study the sensitivity of a simple GCN under this probabilistic error model on accuracy.
&lt;/p&gt;</description></item></channel></rss>