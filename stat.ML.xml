<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#35777;&#26126;&#20102;&#24403;&#23398;&#20064;&#36895;&#29575;&#25353;&#29031;&#36870;&#26102;&#38388;&#34928;&#20943;&#35268;&#21017;&#26102;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#24212;&#29992;&#20110;&#20462;&#25913;&#30340;&#24102;&#26377;L2&#27491;&#21017;&#21270;&#30340;&#31574;&#30053;&#26799;&#24230;&#22810;&#33218;&#36172;&#21338;&#26426;&#65288;MAB&#65289;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;</title><link>https://arxiv.org/abs/2402.06388</link><description>&lt;p&gt;
&#20851;&#20110;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#25910;&#25947;&#36895;&#24230;&#21450;&#20854;&#22312;&#20462;&#25913;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#19978;&#30340;&#31574;&#30053;&#26799;&#24230;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
On the Convergence Rate of the Stochastic Gradient Descent (SGD) and application to a modified policy gradient for the Multi Armed Bandit
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06388
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35777;&#26126;&#20102;&#24403;&#23398;&#20064;&#36895;&#29575;&#25353;&#29031;&#36870;&#26102;&#38388;&#34928;&#20943;&#35268;&#21017;&#26102;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#24212;&#29992;&#20110;&#20462;&#25913;&#30340;&#24102;&#26377;L2&#27491;&#21017;&#21270;&#30340;&#31574;&#30053;&#26799;&#24230;&#22810;&#33218;&#36172;&#21338;&#26426;&#65288;MAB&#65289;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#33258;&#21253;&#21547;&#30340;&#35777;&#26126;&#65292;&#35777;&#26126;&#20102;&#24403;&#23398;&#20064;&#36895;&#29575;&#36981;&#24490;&#36870;&#26102;&#38388;&#34928;&#20943;&#35268;&#21017;&#26102;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#25910;&#25947;&#36895;&#24230;&#65307;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#23558;&#36825;&#20123;&#32467;&#26524;&#24212;&#29992;&#20110;&#24102;&#26377;L2&#27491;&#21017;&#21270;&#30340;&#20462;&#25913;&#30340;&#31574;&#30053;&#26799;&#24230;&#22810;&#33218;&#36172;&#21338;&#26426;&#65288;MAB&#65289;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a self-contained proof of the convergence rate of the Stochastic Gradient Descent (SGD) when the learning rate follows an inverse time decays schedule; we next apply the results to the convergence of a modified form of policy gradient Multi-Armed Bandit (MAB) with $L2$ regularization.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20132;&#26367;&#26497;&#23567;&#21270;&#22312;&#38750;&#20984;&#20248;&#21270;&#20013;&#30340;&#28176;&#36817;&#21160;&#21147;&#23398;&#29305;&#24615;&#65292;&#36890;&#36807;&#22797;&#21046;&#26041;&#27861;&#36861;&#36394;&#28436;&#21270;&#36807;&#31243;&#65292;&#21457;&#29616;&#20854;&#21487;&#29992;&#20108;&#32500;&#31163;&#25955;&#38543;&#26426;&#36807;&#31243;&#26377;&#25928;&#25551;&#36848;&#65292;&#23384;&#22312;&#35760;&#24518;&#20381;&#36182;&#24615;&#12290;&#35813;&#29702;&#35770;&#26694;&#26550;&#36866;&#29992;&#20110;&#20998;&#26512;&#21508;&#31181;&#36845;&#20195;&#31639;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.04751</link><description>&lt;p&gt;
&#38750;&#20984;&#20248;&#21270;&#20013;Alternating Minimization&#30340;&#28176;&#36817;&#21160;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
Asymptotic Dynamics of Alternating Minimization for Non-Convex Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04751
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20132;&#26367;&#26497;&#23567;&#21270;&#22312;&#38750;&#20984;&#20248;&#21270;&#20013;&#30340;&#28176;&#36817;&#21160;&#21147;&#23398;&#29305;&#24615;&#65292;&#36890;&#36807;&#22797;&#21046;&#26041;&#27861;&#36861;&#36394;&#28436;&#21270;&#36807;&#31243;&#65292;&#21457;&#29616;&#20854;&#21487;&#29992;&#20108;&#32500;&#31163;&#25955;&#38543;&#26426;&#36807;&#31243;&#26377;&#25928;&#25551;&#36848;&#65292;&#23384;&#22312;&#35760;&#24518;&#20381;&#36182;&#24615;&#12290;&#35813;&#29702;&#35770;&#26694;&#26550;&#36866;&#29992;&#20110;&#20998;&#26512;&#21508;&#31181;&#36845;&#20195;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#20855;&#26377;&#27491;&#24577;&#20998;&#24067;&#21327;&#21464;&#37327;&#30340;&#21452;&#32447;&#24615;&#38750;&#20984;&#20989;&#25968;&#20248;&#21270;&#20013;&#24212;&#29992;&#20132;&#26367;&#26497;&#23567;&#21270;&#30340;&#28176;&#36817;&#21160;&#21147;&#23398;&#12290;&#25105;&#20204;&#37319;&#29992;&#32479;&#35745;&#29289;&#29702;&#23398;&#20013;&#30340;&#22797;&#21046;&#26041;&#27861;&#65292;&#36890;&#36807;&#22810;&#27493;&#26041;&#27861;&#31934;&#30830;&#36861;&#36394;&#31639;&#27861;&#30340;&#28436;&#21464;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#21160;&#21147;&#23398;&#21487;&#20197;&#26377;&#25928;&#22320;&#29992;&#19968;&#20010;&#20108;&#32500;&#31163;&#25955;&#38543;&#26426;&#36807;&#31243;&#26469;&#25551;&#36848;&#65292;&#27599;&#19968;&#27493;&#37117;&#20381;&#36182;&#20110;&#25152;&#26377;&#20808;&#21069;&#30340;&#26102;&#38388;&#27493;&#38271;&#65292;&#25581;&#31034;&#20102;&#36807;&#31243;&#20013;&#30340;&#35760;&#24518;&#20381;&#36182;&#24615;&#12290;&#26412;&#25991;&#24320;&#21457;&#30340;&#29702;&#35770;&#26694;&#26550;&#24191;&#27867;&#36866;&#29992;&#20110;&#21508;&#31181;&#36845;&#20195;&#31639;&#27861;&#30340;&#20998;&#26512;&#65292;&#36229;&#36234;&#20102;&#20132;&#26367;&#26497;&#23567;&#21270;&#30340;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study investigates the asymptotic dynamics of alternating minimization applied to optimize a bilinear non-convex function with normally distributed covariates. We employ the replica method from statistical physics in a multi-step approach to precisely trace the algorithm's evolution. Our findings indicate that the dynamics can be described effectively by a two--dimensional discrete stochastic process, where each step depends on all previous time steps, revealing a memory dependency in the procedure. The theoretical framework developed in this work is broadly applicable for the analysis of various iterative algorithms, extending beyond the scope of alternating minimization.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#35843;&#26597;&#39044;&#27979;&#27169;&#22411;&#30340;&#37096;&#32626;&#23545;&#20915;&#31574;&#20135;&#29983;&#26377;&#23475;&#24433;&#21709;&#30340;&#24773;&#20917;&#65292;&#21457;&#29616;&#36825;&#20123;&#27169;&#22411;&#21487;&#33021;&#20250;&#25104;&#20026;&#26377;&#23475;&#30340;&#33258;&#25105;&#23454;&#29616;&#39044;&#35328;&#12290;&#36825;&#20123;&#27169;&#22411;&#19981;&#20250;&#22240;&#20026;&#23545;&#26576;&#20123;&#24739;&#32773;&#36896;&#25104;&#26356;&#31967;&#31957;&#30340;&#32467;&#26524;&#32780;&#20351;&#20854;&#39044;&#27979;&#33021;&#21147;&#21464;&#26080;&#25928;&#12290;</title><link>https://arxiv.org/abs/2312.01210</link><description>&lt;p&gt;
&#24403;&#20934;&#30830;&#30340;&#39044;&#27979;&#27169;&#22411;&#23548;&#33268;&#26377;&#23475;&#30340;&#33258;&#25105;&#23454;&#29616;&#39044;&#35328;
&lt;/p&gt;
&lt;p&gt;
When accurate prediction models yield harmful self-fulfilling prophecies
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.01210
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#35843;&#26597;&#39044;&#27979;&#27169;&#22411;&#30340;&#37096;&#32626;&#23545;&#20915;&#31574;&#20135;&#29983;&#26377;&#23475;&#24433;&#21709;&#30340;&#24773;&#20917;&#65292;&#21457;&#29616;&#36825;&#20123;&#27169;&#22411;&#21487;&#33021;&#20250;&#25104;&#20026;&#26377;&#23475;&#30340;&#33258;&#25105;&#23454;&#29616;&#39044;&#35328;&#12290;&#36825;&#20123;&#27169;&#22411;&#19981;&#20250;&#22240;&#20026;&#23545;&#26576;&#20123;&#24739;&#32773;&#36896;&#25104;&#26356;&#31967;&#31957;&#30340;&#32467;&#26524;&#32780;&#20351;&#20854;&#39044;&#27979;&#33021;&#21147;&#21464;&#26080;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#26631;&#65306;&#39044;&#27979;&#27169;&#22411;&#22312;&#21307;&#23398;&#30740;&#31350;&#21644;&#23454;&#36341;&#20013;&#38750;&#24120;&#21463;&#27426;&#36814;&#12290;&#36890;&#36807;&#20026;&#29305;&#23450;&#24739;&#32773;&#39044;&#27979;&#24863;&#20852;&#36259;&#30340;&#32467;&#26524;&#65292;&#36825;&#20123;&#27169;&#22411;&#21487;&#20197;&#24110;&#21161;&#20915;&#31574;&#22256;&#38590;&#30340;&#27835;&#30103;&#20915;&#31574;&#65292;&#24182;&#19988;&#36890;&#24120;&#34987;&#35465;&#20026;&#20010;&#24615;&#21270;&#30340;&#12289;&#25968;&#25454;&#39537;&#21160;&#30340;&#21307;&#30103;&#20445;&#20581;&#30340;&#26480;&#20986;&#20195;&#34920;&#12290;&#35768;&#22810;&#39044;&#27979;&#27169;&#22411;&#22312;&#39564;&#35777;&#30740;&#31350;&#20013;&#22522;&#20110;&#20854;&#39044;&#27979;&#20934;&#30830;&#24615;&#32780;&#37096;&#32626;&#29992;&#20110;&#20915;&#31574;&#25903;&#25345;&#12290;&#25105;&#20204;&#35843;&#26597;&#36825;&#26159;&#21542;&#26159;&#19968;&#31181;&#23433;&#20840;&#21644;&#26377;&#25928;&#30340;&#26041;&#27861;&#12290;&#26448;&#26009;&#21644;&#26041;&#27861;&#65306;&#25105;&#20204;&#23637;&#31034;&#20102;&#20351;&#29992;&#39044;&#27979;&#27169;&#22411;&#36827;&#34892;&#20915;&#31574;&#21487;&#20197;&#23548;&#33268;&#26377;&#23475;&#30340;&#20915;&#31574;&#65292;&#21363;&#20351;&#22312;&#37096;&#32626;&#21518;&#36825;&#20123;&#39044;&#27979;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#21306;&#20998;&#24230;&#12290;&#36825;&#20123;&#27169;&#22411;&#26159;&#26377;&#23475;&#30340;&#33258;&#25105;&#23454;&#29616;&#39044;&#35328;&#65306;&#23427;&#20204;&#30340;&#37096;&#32626;&#25439;&#23475;&#20102;&#19968;&#32676;&#24739;&#32773;&#65292;&#20294;&#36825;&#20123;&#24739;&#32773;&#30340;&#26356;&#31967;&#31957;&#30340;&#32467;&#26524;&#24182;&#19981;&#20351;&#27169;&#22411;&#30340;&#39044;&#27979;&#33021;&#21147;&#26080;&#25928;&#12290;&#32467;&#26524;&#65306;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;&#23545;&#36825;&#20123;&#39044;&#27979;&#27169;&#22411;&#38598;&#21512;&#30340;&#24418;&#24335;&#21270;&#25551;&#36848;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#37096;&#32626;&#21069;&#21518;&#37117;&#36827;&#34892;&#20102;&#33391;&#22909;&#26657;&#20934;&#30340;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Objective: Prediction models are popular in medical research and practice. By predicting an outcome of interest for specific patients, these models may help inform difficult treatment decisions, and are often hailed as the poster children for personalized, data-driven healthcare. Many prediction models are deployed for decision support based on their prediction accuracy in validation studies. We investigate whether this is a safe and valid approach.   Materials and Methods: We show that using prediction models for decision making can lead to harmful decisions, even when the predictions exhibit good discrimination after deployment. These models are harmful self-fulfilling prophecies: their deployment harms a group of patients but the worse outcome of these patients does not invalidate the predictive power of the model.   Results: Our main result is a formal characterization of a set of such prediction models. Next we show that models that are well calibrated before and after deployment 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#20110;&#36830;&#32493;&#20989;&#25968;&#22312;&#32039;&#33268;&#22495;&#19978;&#30340;&#36890;&#29992;&#36924;&#36817;&#22120;&#30340;&#20005;&#26684;&#35777;&#26126;&#65292;&#22635;&#34917;&#20102;&#21333;&#23618;&#31070;&#32463;&#32593;&#32476;&#38543;&#26426;&#21521;&#37327;&#21151;&#33021;&#38142;&#25509;&#32593;&#32476;&#22312;&#23454;&#36341;&#20013;&#25104;&#21151;&#30340;&#29702;&#35770;&#32570;&#21475;</title><link>https://arxiv.org/abs/2007.15776</link><description>&lt;p&gt;
&#29992;&#20110;&#27969;&#24418;&#19978;&#20989;&#25968;&#36924;&#36817;&#30340;&#38543;&#26426;&#21521;&#37327;&#21151;&#33021;&#38142;&#25509;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Random Vector Functional Link Networks for Function Approximation on Manifolds
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2007.15776
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#20110;&#36830;&#32493;&#20989;&#25968;&#22312;&#32039;&#33268;&#22495;&#19978;&#30340;&#36890;&#29992;&#36924;&#36817;&#22120;&#30340;&#20005;&#26684;&#35777;&#26126;&#65292;&#22635;&#34917;&#20102;&#21333;&#23618;&#31070;&#32463;&#32593;&#32476;&#38543;&#26426;&#21521;&#37327;&#21151;&#33021;&#38142;&#25509;&#32593;&#32476;&#22312;&#23454;&#36341;&#20013;&#25104;&#21151;&#30340;&#29702;&#35770;&#32570;&#21475;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
feed-forward&#31070;&#32463;&#32593;&#32476;&#30340;&#23398;&#20064;&#36895;&#24230;&#22240;&#24930;&#32780;&#33879;&#21517;&#65292;&#22312;&#28145;&#24230;&#23398;&#20064;&#24212;&#29992;&#20013;&#24050;&#32463;&#25104;&#20026;&#29942;&#39048;&#25968;&#21313;&#24180;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#19968;&#38382;&#39064;&#65292;&#30740;&#31350;&#20154;&#21592;&#21644;&#23454;&#36341;&#32773;&#23581;&#35797;&#24341;&#20837;&#38543;&#26426;&#24615;&#26469;&#20943;&#23569;&#23398;&#20064;&#38656;&#27714;&#12290;&#22522;&#20110;Igelnik&#21644;Pao&#30340;&#21407;&#22987;&#26500;&#36896;&#65292;&#20855;&#26377;&#38543;&#26426;&#36755;&#20837;&#21040;&#38544;&#34255;&#23618;&#26435;&#37325;&#21644;&#20559;&#32622;&#30340;&#21333;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#23454;&#36341;&#20013;&#21462;&#24471;&#25104;&#21151;&#65292;&#20294;&#32570;&#20047;&#24517;&#35201;&#30340;&#29702;&#35770;&#35777;&#26126;&#12290;&#26412;&#25991;&#22635;&#34917;&#20102;&#36825;&#19968;&#29702;&#35770;&#31354;&#30333;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#65288;&#26356;&#27491;&#30340;&#65289;&#20005;&#26684;&#35777;&#26126;&#65292;&#35777;&#26126;Igelnik&#21644;Pao&#30340;&#26500;&#36896;&#26159;&#19968;&#20010;&#36830;&#32493;&#20989;&#25968;&#22312;&#32039;&#33268;&#22495;&#19978;&#30340;&#36890;&#29992;&#36924;&#36817;&#22120;&#65292;&#36924;&#36817;&#35823;&#24046;&#20687;&#28176;&#36817;&#34928;&#20943;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2007.15776v3 Announce Type: replace-cross  Abstract: The learning speed of feed-forward neural networks is notoriously slow and has presented a bottleneck in deep learning applications for several decades. For instance, gradient-based learning algorithms, which are used extensively to train neural networks, tend to work slowly when all of the network parameters must be iteratively tuned. To counter this, both researchers and practitioners have tried introducing randomness to reduce the learning requirement. Based on the original construction of Igelnik and Pao, single layer neural-networks with random input-to-hidden layer weights and biases have seen success in practice, but the necessary theoretical justification is lacking. In this paper, we begin to fill this theoretical gap. We provide a (corrected) rigorous proof that the Igelnik and Pao construction is a universal approximator for continuous functions on compact domains, with approximation error decaying asymptotically lik
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21521;&#38543;&#26426;Kaczmarz&#31639;&#27861;&#20013;&#28155;&#21152;&#20960;&#20309;&#24179;&#28369;&#21160;&#37327;&#30340;&#25928;&#26524;&#65292;&#24182;&#35777;&#26126;&#20102;&#20851;&#20110;&#26368;&#23567;&#20108;&#20056;&#25439;&#22833;&#30697;&#38453;&#22855;&#24322;&#21521;&#37327;&#26041;&#21521;&#19978;&#30340;&#26399;&#26395;&#35823;&#24046;&#12290;&#25968;&#20540;&#31034;&#20363;&#35777;&#26126;&#20102;&#32467;&#26524;&#30340;&#23454;&#29992;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#20960;&#20010;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.09415</link><description>&lt;p&gt;
&#20855;&#26377;&#20960;&#20309;&#24179;&#28369;&#21160;&#37327;&#30340;&#38543;&#26426;Kaczmarz&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Randomized Kaczmarz with geometrically smoothed momentum. (arXiv:2401.09415v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09415
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21521;&#38543;&#26426;Kaczmarz&#31639;&#27861;&#20013;&#28155;&#21152;&#20960;&#20309;&#24179;&#28369;&#21160;&#37327;&#30340;&#25928;&#26524;&#65292;&#24182;&#35777;&#26126;&#20102;&#20851;&#20110;&#26368;&#23567;&#20108;&#20056;&#25439;&#22833;&#30697;&#38453;&#22855;&#24322;&#21521;&#37327;&#26041;&#21521;&#19978;&#30340;&#26399;&#26395;&#35823;&#24046;&#12290;&#25968;&#20540;&#31034;&#20363;&#35777;&#26126;&#20102;&#32467;&#26524;&#30340;&#23454;&#29992;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#20960;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21521;&#38543;&#26426;Kaczmarz&#31639;&#27861;&#20013;&#28155;&#21152;&#20960;&#20309;&#24179;&#28369;&#21160;&#37327;&#30340;&#25928;&#26524;&#65292;&#35813;&#31639;&#27861;&#26159;&#32447;&#24615;&#26368;&#23567;&#20108;&#20056;&#25439;&#22833;&#20989;&#25968;&#19978;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#23454;&#20363;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20851;&#20110;&#23450;&#20041;&#26368;&#23567;&#20108;&#20056;&#25439;&#22833;&#30340;&#30697;&#38453;&#30340;&#22855;&#24322;&#21521;&#37327;&#26041;&#21521;&#19978;&#26399;&#26395;&#35823;&#24046;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#20960;&#20010;&#25968;&#20540;&#31034;&#20363;&#26469;&#35828;&#26126;&#25105;&#20204;&#32467;&#26524;&#30340;&#23454;&#29992;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#20960;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the effect of adding geometrically smoothed momentum to the randomized Kaczmarz algorithm, which is an instance of stochastic gradient descent on a linear least squares loss function. We prove a result about the expected error in the direction of singular vectors of the matrix defining the least squares loss. We present several numerical examples illustrating the utility of our result and pose several questions.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20174;&#25968;&#25454;&#20113;&#20013;&#26500;&#24314;&#30340;&#38543;&#26426;&#20960;&#20309;&#22270;&#19982;&#27969;&#24418;&#20043;&#38388;&#30340;&#26354;&#29575;&#20851;&#31995;&#65292;&#24182;&#36890;&#36807;&#27010;&#29575;&#20998;&#26512;&#35777;&#26126;&#20102;&#28857;&#24577;&#19968;&#33268;&#24615;&#20197;&#21450;&#20840;&#23616;&#32467;&#26500;&#29305;&#24615;&#20256;&#25215;&#12290;&#30740;&#31350;&#32467;&#26524;&#23545;&#22270;&#19978;&#28909;&#26680;&#30340;&#25910;&#25947;&#24615;&#21644;&#20174;&#25968;&#25454;&#20113;&#20013;&#23398;&#20064;&#27969;&#24418;&#20855;&#26377;&#37325;&#35201;&#30340;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2307.02378</link><description>&lt;p&gt;
&#22312;&#25968;&#25454;&#20113;&#20013;Ollivier&#30340;Ricci&#26354;&#29575;&#30340;&#36830;&#32493;&#26497;&#38480;&#65306;&#28857;&#24577;&#19968;&#33268;&#24615;&#21644;&#20840;&#23616;&#19979;&#30028;
&lt;/p&gt;
&lt;p&gt;
Continuum Limits of Ollivier's Ricci Curvature on data clouds: pointwise consistency and global lower bounds. (arXiv:2307.02378v1 [math.DG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02378
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20174;&#25968;&#25454;&#20113;&#20013;&#26500;&#24314;&#30340;&#38543;&#26426;&#20960;&#20309;&#22270;&#19982;&#27969;&#24418;&#20043;&#38388;&#30340;&#26354;&#29575;&#20851;&#31995;&#65292;&#24182;&#36890;&#36807;&#27010;&#29575;&#20998;&#26512;&#35777;&#26126;&#20102;&#28857;&#24577;&#19968;&#33268;&#24615;&#20197;&#21450;&#20840;&#23616;&#32467;&#26500;&#29305;&#24615;&#20256;&#25215;&#12290;&#30740;&#31350;&#32467;&#26524;&#23545;&#22270;&#19978;&#28909;&#26680;&#30340;&#25910;&#25947;&#24615;&#21644;&#20174;&#25968;&#25454;&#20113;&#20013;&#23398;&#20064;&#27969;&#24418;&#20855;&#26377;&#37325;&#35201;&#30340;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35753;$\mathcal{M} \subseteq \mathbb{R}^d$&#34920;&#31034;&#19968;&#20010;&#20302;&#32500;&#27969;&#24418;&#65292;$\mathcal{X}= \{ x_1, \dots, x_n \}$&#34920;&#31034;&#20174;$\mathcal{M}$&#22343;&#21248;&#37319;&#26679;&#24471;&#21040;&#30340;&#19968;&#32452;&#28857;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#20174;$\mathcal{X}$&#26500;&#24314;&#30340;&#38543;&#26426;&#20960;&#20309;&#22270;&#19982;&#27969;&#24418;$\mathcal{M}$&#30340;&#26354;&#29575;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#36890;&#36807;Ollivier&#30340;&#31163;&#25955;Ricci&#26354;&#29575;&#30340;&#36830;&#32493;&#26497;&#38480;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#28857;&#24577;&#12289;&#38750;&#28176;&#36817;&#19968;&#33268;&#24615;&#32467;&#26524;&#65292;&#24182;&#19988;&#36824;&#34920;&#26126;&#65292;&#22914;&#26524;$\mathcal{M}$&#30340;Ricci&#26354;&#29575;&#20174;&#19979;&#38754;&#20005;&#26684;&#22320;&#34987;&#19968;&#20010;&#27491;&#24120;&#25968;&#30028;&#20303;&#65292;&#37027;&#20040;&#38543;&#26426;&#20960;&#20309;&#22270;&#23558;&#20197;&#39640;&#27010;&#29575;&#32487;&#25215;&#27492;&#20840;&#23616;&#32467;&#26500;&#29305;&#24615;&#12290;&#25105;&#20204;&#35752;&#35770;&#20840;&#23616;&#31163;&#25955;&#26354;&#29575;&#30028;&#38480;&#22312;&#22270;&#19978;&#28909;&#26680;&#30340;&#25910;&#25947;&#24615;&#36136;&#20197;&#21450;&#23545;&#25968;&#25454;&#20113;&#19978;&#27969;&#24418;&#23398;&#20064;&#30340;&#24433;&#21709;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#33268;&#24615;&#32467;&#26524;&#20801;&#35768;&#36890;&#36807;&#22806;&#31104;&#26354;&#29575;&#34920;&#24449;&#27969;&#24418;&#30340;&#20869;&#22312;&#26354;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Let $\mathcal{M} \subseteq \mathbb{R}^d$ denote a low-dimensional manifold and let $\mathcal{X}= \{ x_1, \dots, x_n \}$ be a collection of points uniformly sampled from $\mathcal{M}$. We study the relationship between the curvature of a random geometric graph built from $\mathcal{X}$ and the curvature of the manifold $\mathcal{M}$ via continuum limits of Ollivier's discrete Ricci curvature. We prove pointwise, non-asymptotic consistency results and also show that if $\mathcal{M}$ has Ricci curvature bounded from below by a positive constant, then the random geometric graph will inherit this global structural property with high probability. We discuss applications of the global discrete curvature bounds to contraction properties of heat kernels on graphs, as well as implications for manifold learning from data clouds. In particular, we show that the consistency results allow for characterizing the intrinsic curvature of a manifold from extrinsic curvature.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23450;&#20041;&#29420;&#31435;&#22240;&#26524;&#26426;&#21046;&#65292;&#25552;&#20986;&#20102;ICM-VAE&#26694;&#26550;&#65292;&#20351;&#24471;&#23398;&#20064;&#22240;&#26524;&#35299;&#32544;&#32469;&#34920;&#31034;&#26356;&#20934;&#30830;</title><link>http://arxiv.org/abs/2306.01213</link><description>&lt;p&gt;
&#22522;&#20110;&#29420;&#31435;&#22240;&#26524;&#26426;&#21046;&#21407;&#21017;&#23398;&#20064;&#22240;&#26524;&#35299;&#32544;&#32469;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Learning Causally Disentangled Representations via the Principle of Independent Causal Mechanisms. (arXiv:2306.01213v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01213
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23450;&#20041;&#29420;&#31435;&#22240;&#26524;&#26426;&#21046;&#65292;&#25552;&#20986;&#20102;ICM-VAE&#26694;&#26550;&#65292;&#20351;&#24471;&#23398;&#20064;&#22240;&#26524;&#35299;&#32544;&#32469;&#34920;&#31034;&#26356;&#20934;&#30830;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#35299;&#32544;&#32469;&#30340;&#22240;&#26524;&#34920;&#31034;&#26159;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#65292;&#36817;&#24180;&#26469;&#22240;&#20854;&#23545;&#25552;&#21462;&#19979;&#28216;&#20219;&#21153;&#30340;&#26377;&#24847;&#20041;&#20449;&#24687;&#32780;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#26412;&#25991;&#20174;&#29420;&#31435;&#22240;&#26524;&#26426;&#21046;&#30340;&#35282;&#24230;&#23450;&#20041;&#20102;&#19968;&#31181;&#26032;&#30340;&#22240;&#26524;&#35299;&#32544;&#32469;&#27010;&#24565;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;ICM-VAE&#26694;&#26550;&#65292;&#36890;&#36807;&#22240;&#22240;&#26524;&#20851;&#31995;&#35266;&#23519;&#26631;&#31614;&#26469;&#30417;&#30563;&#23398;&#20064;&#22240;&#26524;&#35299;&#32544;&#32469;&#34920;&#31034;&#12290;&#25105;&#20204;&#20351;&#29992;&#21487;&#23398;&#20064;&#30340;&#22522;&#20110;&#27969;&#30340;&#24494;&#20998;&#21516;&#32986;&#20989;&#25968;&#23558;&#22122;&#22768;&#21464;&#37327;&#26144;&#23556;&#21040;&#28508;&#22312;&#22240;&#26524;&#21464;&#37327;&#20013;&#26469;&#24314;&#27169;&#22240;&#26524;&#26426;&#21046;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#20419;&#36827;&#22240;&#26524;&#35201;&#32032;&#30340;&#35299;&#32544;&#32469;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#26524;&#35299;&#32544;&#32469;&#20808;&#39564;&#65292;&#21033;&#29992;&#24050;&#30693;&#30340;&#22240;&#26524;&#32467;&#26500;&#26469;&#40723;&#21169;&#22312;&#28508;&#22312;&#31354;&#38388;&#20013;&#23398;&#20064;&#22240;&#26524;&#20998;&#35299;&#20998;&#24067;&#12290;&#22312;&#30456;&#23545;&#28201;&#21644;&#30340;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#32467;&#26524;&#65292;&#26174;&#31034;&#20102;&#22240;&#26524;&#35201;&#32032;&#21644;&#26426;&#21046;&#30340;&#21487;&#35782;&#21035;&#24615;&#65292;&#30452;&#21040;&#25490;&#21015;&#21644;&#36880;&#20803;&#37325;&#21442;&#25968;&#21270;&#30340;&#38480;&#24230;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#23454;&#35777;&#30740;&#31350;...
&lt;/p&gt;
&lt;p&gt;
Learning disentangled causal representations is a challenging problem that has gained significant attention recently due to its implications for extracting meaningful information for downstream tasks. In this work, we define a new notion of causal disentanglement from the perspective of independent causal mechanisms. We propose ICM-VAE, a framework for learning causally disentangled representations supervised by causally related observed labels. We model causal mechanisms using learnable flow-based diffeomorphic functions to map noise variables to latent causal variables. Further, to promote the disentanglement of causal factors, we propose a causal disentanglement prior that utilizes the known causal structure to encourage learning a causally factorized distribution in the latent space. Under relatively mild conditions, we provide theoretical results showing the identifiability of causal factors and mechanisms up to permutation and elementwise reparameterization. We empirically demons
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20026;ResNets&#23548;&#20986;&#31995;&#32479;&#30340;&#26377;&#38480;&#23610;&#23544;&#29702;&#35770;&#65292;&#25351;&#20986;&#23545;&#20110;&#28145;&#23618;&#32593;&#32476;&#26550;&#26500;&#65292;&#32553;&#25918;&#21442;&#25968;&#26159;&#20248;&#21270;&#20449;&#21495;&#20256;&#25773;&#21644;&#30830;&#20445;&#26377;&#25928;&#21033;&#29992;&#32593;&#32476;&#28145;&#24230;&#26041;&#38754;&#30340;&#20851;&#38190;&#12290;</title><link>http://arxiv.org/abs/2305.07715</link><description>&lt;p&gt;
&#36890;&#36807;&#27531;&#24046;&#32553;&#25918;&#23454;&#29616;ResNets&#30340;&#20449;&#21495;&#26368;&#20248;&#20256;&#36882;
&lt;/p&gt;
&lt;p&gt;
Optimal signal propagation in ResNets through residual scaling. (arXiv:2305.07715v1 [cond-mat.dis-nn])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07715
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20026;ResNets&#23548;&#20986;&#31995;&#32479;&#30340;&#26377;&#38480;&#23610;&#23544;&#29702;&#35770;&#65292;&#25351;&#20986;&#23545;&#20110;&#28145;&#23618;&#32593;&#32476;&#26550;&#26500;&#65292;&#32553;&#25918;&#21442;&#25968;&#26159;&#20248;&#21270;&#20449;&#21495;&#20256;&#25773;&#21644;&#30830;&#20445;&#26377;&#25928;&#21033;&#29992;&#32593;&#32476;&#28145;&#24230;&#26041;&#38754;&#30340;&#20851;&#38190;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Residual&#32593;&#32476;&#65288;ResNets&#65289;&#22312;&#22823;&#28145;&#24230;&#19978;&#27604;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#20855;&#26377;&#26356;&#22909;&#30340;&#35757;&#32451;&#33021;&#21147;&#21644;&#24615;&#33021;&#12290;&#24341;&#20837;&#36339;&#36807;&#36830;&#25509;&#21487;&#20197;&#20419;&#36827;&#20449;&#21495;&#21521;&#26356;&#28145;&#23618;&#30340;&#20256;&#36882;&#12290;&#27492;&#22806;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#21457;&#29616;&#20026;&#27531;&#24046;&#20998;&#25903;&#28155;&#21152;&#32553;&#25918;&#21442;&#25968;&#21487;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#12290;&#23613;&#31649;&#20182;&#20204;&#32463;&#39564;&#24615;&#22320;&#30830;&#23450;&#20102;&#36825;&#31181;&#32553;&#25918;&#21442;&#25968;&#29305;&#21035;&#26377;&#21033;&#30340;&#21462;&#20540;&#33539;&#22260;&#65292;&#20294;&#20854;&#30456;&#20851;&#30340;&#24615;&#33021;&#25552;&#21319;&#21450;&#20854;&#22312;&#32593;&#32476;&#36229;&#21442;&#25968;&#19978;&#30340;&#26222;&#36866;&#24615;&#20173;&#38656;&#35201;&#36827;&#19968;&#27493;&#29702;&#35299;&#12290;&#23545;&#20110;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#65288;FFNets&#65289;&#65292;&#26377;&#38480;&#23610;&#23544;&#29702;&#35770;&#22312;&#20449;&#21495;&#20256;&#25773;&#21644;&#36229;&#21442;&#25968;&#35843;&#33410;&#26041;&#38754;&#33719;&#24471;&#20102;&#37325;&#35201;&#27934;&#35265;&#12290;&#25105;&#20204;&#22312;&#36825;&#37324;&#20026;ResNets&#23548;&#20986;&#20102;&#19968;&#20010;&#31995;&#32479;&#30340;&#26377;&#38480;&#23610;&#23544;&#29702;&#35770;&#65292;&#20197;&#30740;&#31350;&#20449;&#21495;&#20256;&#25773;&#21450;&#20854;&#23545;&#27531;&#24046;&#20998;&#25903;&#32553;&#25918;&#30340;&#20381;&#36182;&#24615;&#12290;&#25105;&#20204;&#23548;&#20986;&#21709;&#24212;&#20989;&#25968;&#30340;&#20998;&#26512;&#34920;&#36798;&#24335;&#65292;&#36825;&#26159;&#34913;&#37327;&#32593;&#32476;&#23545;&#36755;&#20837;&#25935;&#24863;&#24615;&#30340;&#19968;&#31181;&#25351;&#26631;&#65292;&#24182;&#34920;&#26126;&#23545;&#20110;&#28145;&#23618;&#32593;&#32476;&#26550;&#26500;&#65292;&#32553;&#25918;&#21442;&#25968;&#22312;&#20248;&#21270;&#20449;&#21495;&#20256;&#25773;&#21644;&#30830;&#20445;&#26377;&#25928;&#21033;&#29992;&#32593;&#32476;&#28145;&#24230;&#26041;&#38754;&#21457;&#25381;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Residual networks (ResNets) have significantly better trainability and thus performance than feed-forward networks at large depth. Introducing skip connections facilitates signal propagation to deeper layers. In addition, previous works found that adding a scaling parameter for the residual branch further improves generalization performance. While they empirically identified a particularly beneficial range of values for this scaling parameter, the associated performance improvement and its universality across network hyperparameters yet need to be understood. For feed-forward networks (FFNets), finite-size theories have led to important insights with regard to signal propagation and hyperparameter tuning. We here derive a systematic finite-size theory for ResNets to study signal propagation and its dependence on the scaling for the residual branch. We derive analytical expressions for the response function, a measure for the network's sensitivity to inputs, and show that for deep netwo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#22522;&#20110;Python&#30340;&#25945;&#31243;&#65292;&#20171;&#32461;&#20102;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;MCMC&#26041;&#27861;&#24212;&#29992;&#65292;&#36890;&#36807;&#25945;&#31243;&#20351;&#24471;&#28145;&#24230;&#23398;&#20064;&#24320;&#21457;&#32773;&#33021;&#22815;&#26356;&#22909;&#22320;&#24212;&#29992;&#36125;&#21494;&#26031;&#25512;&#26029;&#36827;&#34892;&#21442;&#25968;&#20272;&#35745;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;</title><link>http://arxiv.org/abs/2304.02595</link><description>&lt;p&gt;
&#22522;&#20110;MCMC&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65306;&#22522;&#20110;Python&#30340;&#25945;&#31243;
&lt;/p&gt;
&lt;p&gt;
Bayesian neural networks via MCMC: a Python-based tutorial. (arXiv:2304.02595v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02595
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#22522;&#20110;Python&#30340;&#25945;&#31243;&#65292;&#20171;&#32461;&#20102;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;MCMC&#26041;&#27861;&#24212;&#29992;&#65292;&#36890;&#36807;&#25945;&#31243;&#20351;&#24471;&#28145;&#24230;&#23398;&#20064;&#24320;&#21457;&#32773;&#33021;&#22815;&#26356;&#22909;&#22320;&#24212;&#29992;&#36125;&#21494;&#26031;&#25512;&#26029;&#36827;&#34892;&#21442;&#25968;&#20272;&#35745;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#25512;&#26029;&#20026;&#26426;&#22120;&#23398;&#20064;&#21644;&#28145;&#24230;&#23398;&#20064;&#25552;&#20379;&#20102;&#21442;&#25968;&#20272;&#35745;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#26041;&#27861;&#12290;&#21464;&#20998;&#25512;&#26029;&#21644;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#65288;MCMC&#65289;&#37319;&#26679;&#25216;&#26415;&#29992;&#20110;&#23454;&#29616;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;&#22312;&#36807;&#21435;&#19977;&#21313;&#24180;&#20013;&#65292;MCMC&#26041;&#27861;&#22312;&#36866;&#24212;&#26356;&#22823;&#30340;&#27169;&#22411;&#65288;&#22914;&#28145;&#24230;&#23398;&#20064;&#65289;&#21644;&#22823;&#25968;&#25454;&#38382;&#39064;&#26041;&#38754;&#38754;&#20020;&#20102;&#35768;&#22810;&#25361;&#25112;&#12290;&#21253;&#25324;&#26799;&#24230;&#30340;&#39640;&#32423;&#25552;&#35758;&#65288;&#20363;&#22914;Langevin&#25552;&#35758;&#20998;&#24067;&#65289;&#25552;&#20379;&#20102;&#19968;&#31181;&#35299;&#20915;MCMC&#37319;&#26679;&#20013;&#30340;&#19968;&#20123;&#38480;&#21046;&#30340;&#26041;&#27861;&#65292;&#27492;&#22806;&#65292;MCMC&#26041;&#27861;&#36890;&#24120;&#34987;&#38480;&#21046;&#22312;&#32479;&#35745;&#23398;&#23478;&#30340;&#20351;&#29992;&#33539;&#22260;&#20869;&#65292;&#24182;&#19988;&#20173;&#19981;&#26159;&#28145;&#24230;&#23398;&#20064;&#30740;&#31350;&#20154;&#21592;&#30340;&#20027;&#27969;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;MCMC&#26041;&#27861;&#30340;&#25945;&#31243;&#65292;&#28085;&#30422;&#20102;&#31616;&#21333;&#30340;&#36125;&#21494;&#26031;&#32447;&#24615;&#21644;&#36923;&#36753;&#27169;&#22411;&#65292;&#20197;&#21450;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#12290;&#36825;&#20010;&#25945;&#31243;&#30340;&#30446;&#30340;&#26159;&#36890;&#36807;&#32534;&#30721;&#26469;&#24357;&#21512;&#29702;&#35770;&#21644;&#23454;&#29616;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#37492;&#20110;&#24403;&#21069;MCMC&#26041;&#27861;&#30340;&#26222;&#21450;&#31243;&#24230;&#20173;&#28982;&#36739;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian inference provides a methodology for parameter estimation and uncertainty quantification in machine learning and deep learning methods. Variational inference and Markov Chain Monte-Carlo (MCMC) sampling techniques are used to implement Bayesian inference. In the past three decades, MCMC methods have faced a number of challenges in being adapted to larger models (such as in deep learning) and big data problems. Advanced proposals that incorporate gradients, such as a Langevin proposal distribution, provide a means to address some of the limitations of MCMC sampling for Bayesian neural networks. Furthermore, MCMC methods have typically been constrained to use by statisticians and are still not prominent among deep learning researchers. We present a tutorial for MCMC methods that covers simple Bayesian linear and logistic models, and Bayesian neural networks. The aim of this tutorial is to bridge the gap between theory and implementation via coding, given a general sparsity of li
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#35889;&#23398;&#20064;&#20013;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#35299;&#20915;&#26041;&#26696;&#65292;&#21253;&#25324;&#25552;&#20379;&#20102;SHMM&#20284;&#28982;&#20272;&#35745;&#30340;&#35823;&#24046;&#28176;&#36817;&#20998;&#24067;&#12289;&#25552;&#20986;&#25237;&#24433;SHMM&#31639;&#27861;&#21487;&#20197;&#20943;&#36731;&#35823;&#24046;&#20256;&#25773;&#38382;&#39064;&#12289;&#24182;&#24320;&#21457;&#20102;SHMM&#21644;PSHMM&#30340;&#22312;&#32447;&#23398;&#20064;&#21464;&#20307;&#20197;&#36866;&#24212;&#28508;&#22312;&#30340;&#38750;&#24179;&#31283;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;PSHMM&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2302.07437</link><description>&lt;p&gt;
&#32553;&#23567;&#21487;&#29992;&#24615;&#24046;&#36317;&#65306;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#35889;&#23398;&#20064;&#30340;&#29702;&#35770;&#19982;&#26041;&#27861;&#23398;&#36827;&#23637;
&lt;/p&gt;
&lt;p&gt;
Bridging the Usability Gap: Theoretical and Methodological Advances for Spectral Learning of Hidden Markov Models. (arXiv:2302.07437v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.07437
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#35889;&#23398;&#20064;&#20013;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#35299;&#20915;&#26041;&#26696;&#65292;&#21253;&#25324;&#25552;&#20379;&#20102;SHMM&#20284;&#28982;&#20272;&#35745;&#30340;&#35823;&#24046;&#28176;&#36817;&#20998;&#24067;&#12289;&#25552;&#20986;&#25237;&#24433;SHMM&#31639;&#27861;&#21487;&#20197;&#20943;&#36731;&#35823;&#24046;&#20256;&#25773;&#38382;&#39064;&#12289;&#24182;&#24320;&#21457;&#20102;SHMM&#21644;PSHMM&#30340;&#22312;&#32447;&#23398;&#20064;&#21464;&#20307;&#20197;&#36866;&#24212;&#28508;&#22312;&#30340;&#38750;&#24179;&#31283;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;PSHMM&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Baum-Welch&#65288;B-W&#65289;&#31639;&#27861;&#26159;&#25512;&#26029;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;(HMM)&#26368;&#24191;&#27867;&#25509;&#21463;&#30340;&#26041;&#27861;&#12290; &#28982;&#32780;&#65292;&#23427;&#24456;&#23481;&#26131;&#38519;&#20837;&#23616;&#37096;&#26368;&#20248;&#65292;&#32780;&#19988;&#23545;&#20110;&#35768;&#22810;&#23454;&#26102;&#24212;&#29992;&#26469;&#35828;&#36895;&#24230;&#22826;&#24930;&#12290;&#25991;&#29486;&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30697;&#27861;&#65288;MOM&#65289;&#30340;HMM&#30340;&#35889;&#23398;&#20064;&#65288;SHMM&#65289;&#65292;&#26088;&#22312;&#20811;&#26381;&#36825;&#20123;&#38556;&#30861;&#12290;&#23613;&#31649;&#26377;&#36825;&#26679;&#30340;&#25215;&#35834;&#65292;&#20294;SHMM&#30340;&#28176;&#36817;&#29702;&#35770;&#19968;&#30452;&#24456;&#38590;&#24471;&#21040;&#65292;&#32780;SHMM&#30340;&#38271;&#26399;&#24615;&#33021;&#21487;&#33021;&#20250;&#30001;&#20110;&#35823;&#24046;&#30340;&#26080;&#38480;&#20256;&#25773;&#32780;&#38477;&#20302;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;(1)&#25552;&#20379;&#20102;SHMM&#20284;&#28982;&#20272;&#35745;&#30340;&#36817;&#20284;&#35823;&#24046;&#30340;&#28176;&#36817;&#20998;&#24067;&#65292;(2)&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#31216;&#20026;&#25237;&#24433;SHMM&#65288;PSHMM&#65289;&#65292;&#23427;&#21487;&#20197;&#20943;&#36731;&#35823;&#24046;&#20256;&#25773;&#38382;&#39064;&#65292;(3)&#24320;&#21457;&#20102;SHMM&#21644;PSHMM&#30340;&#22312;&#32447;&#23398;&#20064;&#21464;&#20307;&#65292;&#20197;&#36866;&#24212;&#28508;&#22312;&#30340;&#38750;&#24179;&#31283;&#24615;&#12290;&#25105;&#20204;&#22312;&#27169;&#25311;&#25968;&#25454;&#21644;&#26469;&#33258;&#30495;&#23454;&#19990;&#30028;&#24212;&#29992;&#30340;&#25968;&#25454;&#19978;&#27604;&#36739;&#20102;SHMM&#12289;PSHMM&#21644;B-W&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Baum-Welch (B-W) algorithm is the most widely accepted method for inferring hidden Markov models (HMM). However, it is prone to getting stuck in local optima, and can be too slow for many real-time applications. Spectral learning of HMMs (SHMM), based on the method of moments (MOM) has been proposed in the literature to overcome these obstacles. Despite its promises, asymptotic theory for SHMM has been elusive, and the long-run performance of SHMM can degrade due to unchecked propagation of error. In this paper, we (1) provide an asymptotic distribution for the approximate error of the likelihood estimated by SHMM, (2) propose a novel algorithm called projected SHMM (PSHMM) that mitigates the problem of error propagation, and (3) develop online learning variants of both SHMM and PSHMM that accommodate potential nonstationarity. We compare the performance of SHMM with PSHMM and estimation through the B-W algorithm on both simulated data and data from real world applications, and fin
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65292;&#21033;&#29992;&#20854;&#29702;&#35770;&#22522;&#30784;&#21644;&#23454;&#26045;&#30340;&#21487;&#34892;&#24615;&#65292;&#20174;&#32780;&#20272;&#35745;&#36830;&#32493;&#26292;&#38706;/&#27835;&#30103;&#30340;&#20998;&#24067;&#23545;&#25919;&#31574;&#30456;&#20851;&#32467;&#26524;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#25105;&#20204;&#23558;&#27492;&#26041;&#27861;&#24212;&#29992;&#20110;&#21253;&#21547;6800&#19975;&#20010;&#20010;&#20307;&#21644;2700&#19975;&#20010;&#32654;&#22269;&#22659;&#20869;&#27515;&#20129;&#20107;&#20214;&#30340;&#25968;&#25454;&#20013;&#65292;&#36890;&#36807;&#35780;&#20272;&#32654;&#22269;&#22269;&#23478;&#29615;&#22659;&#20445;&#25252;&#23616;&#65288;EPA&#65289;&#23545;PM2.5&#30340;&#22269;&#23478;&#29615;&#22659;&#31354;&#27668;&#36136;&#37327;&#26631;&#20934;&#65288;NAAQS&#65289;&#36827;&#34892;&#20462;&#35746;&#21518;&#30340;&#20581;&#24247;&#25928;&#30410;&#12290;</title><link>http://arxiv.org/abs/2302.02560</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#22312;&#22240;&#26524;&#20272;&#35745;&#20013;&#30340;&#24212;&#29992;: &#22312;&#32654;&#22269;&#35780;&#20272;&#26356;&#20005;&#26684;&#30340;&#31354;&#27668;&#36136;&#37327;&#26631;&#20934;&#30340;&#20581;&#24247;&#25928;&#30410;
&lt;/p&gt;
&lt;p&gt;
Causal Estimation of Exposure Shifts with Neural Networks: Evaluating the Health Benefits of Stricter Air Quality Standards in the US. (arXiv:2302.02560v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.02560
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65292;&#21033;&#29992;&#20854;&#29702;&#35770;&#22522;&#30784;&#21644;&#23454;&#26045;&#30340;&#21487;&#34892;&#24615;&#65292;&#20174;&#32780;&#20272;&#35745;&#36830;&#32493;&#26292;&#38706;/&#27835;&#30103;&#30340;&#20998;&#24067;&#23545;&#25919;&#31574;&#30456;&#20851;&#32467;&#26524;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#25105;&#20204;&#23558;&#27492;&#26041;&#27861;&#24212;&#29992;&#20110;&#21253;&#21547;6800&#19975;&#20010;&#20010;&#20307;&#21644;2700&#19975;&#20010;&#32654;&#22269;&#22659;&#20869;&#27515;&#20129;&#20107;&#20214;&#30340;&#25968;&#25454;&#20013;&#65292;&#36890;&#36807;&#35780;&#20272;&#32654;&#22269;&#22269;&#23478;&#29615;&#22659;&#20445;&#25252;&#23616;&#65288;EPA&#65289;&#23545;PM2.5&#30340;&#22269;&#23478;&#29615;&#22659;&#31354;&#27668;&#36136;&#37327;&#26631;&#20934;&#65288;NAAQS&#65289;&#36827;&#34892;&#20462;&#35746;&#21518;&#30340;&#20581;&#24247;&#25928;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25919;&#31574;&#30740;&#31350;&#20013;&#65292;&#20272;&#35745;&#36830;&#32493;&#24615;&#26292;&#38706;/&#27835;&#30103;&#30340;&#20998;&#24067;&#23545;&#24863;&#20852;&#36259;&#30340;&#32467;&#26524;&#30340;&#22240;&#26524;&#25928;&#24212;&#26159;&#26368;&#20851;&#38190;&#30340;&#20998;&#26512;&#20219;&#21153;&#20043;&#19968;&#12290;&#25105;&#20204;&#31216;&#20043;&#20026;&#20559;&#31227;-&#21709;&#24212;&#20989;&#25968;&#65288;SRF&#65289;&#20272;&#35745;&#38382;&#39064;&#12290;&#29616;&#26377;&#30340;&#28041;&#21450;&#24378;&#20581;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#22120;&#30340;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#32570;&#20047;&#29702;&#35770;&#20445;&#35777;&#21644;&#23454;&#38469;&#23454;&#29616;&#65292;&#29992;&#20110;SRF&#20272;&#35745;&#12290;&#21463;&#20844;&#20849;&#21355;&#29983;&#20013;&#30340;&#20851;&#38190;&#25919;&#31574;&#38382;&#39064;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#21450;&#20854;&#29702;&#35770;&#22522;&#30784;&#65292;&#20197;&#25552;&#20379;&#20855;&#26377;&#24378;&#20581;&#24615;&#21644;&#25928;&#29575;&#20445;&#35777;&#30340;SRF&#20272;&#35745;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#21253;&#21547;6800&#19975;&#20010;&#20010;&#20307;&#21644;2700&#19975;&#20010;&#32654;&#22269;&#22659;&#20869;&#27515;&#20129;&#20107;&#20214;&#30340;&#25968;&#25454;&#20013;&#65292;&#20197;&#20272;&#35745;&#23558;&#32654;&#22269;&#22269;&#23478;&#29615;&#22659;&#20445;&#25252;&#23616;&#65288;EPA&#65289;&#26368;&#36817;&#25552;&#35758;&#20174;12 &#956;g/m&#179;&#25913;&#20026;9 &#956;g/m&#179;&#30340;PM2.5&#30340;&#32654;&#22269;&#22269;&#23478;&#29615;&#22659;&#31354;&#27668;&#36136;&#37327;&#26631;&#20934;&#65288;NAAQS&#65289;&#30340;&#20462;&#35746;&#23545;&#32467;&#26524;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#39318;&#27425;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
In policy research, one of the most critical analytic tasks is to estimate the causal effect of a policy-relevant shift to the distribution of a continuous exposure/treatment on an outcome of interest. We call this problem shift-response function (SRF) estimation. Existing neural network methods involving robust causal-effect estimators lack theoretical guarantees and practical implementations for SRF estimation. Motivated by a key policy-relevant question in public health, we develop a neural network method and its theoretical underpinnings to estimate SRFs with robustness and efficiency guarantees. We then apply our method to data consisting of 68 million individuals and 27 million deaths across the U.S. to estimate the causal effect from revising the US National Ambient Air Quality Standards (NAAQS) for PM 2.5 from 12 $\mu g/m^3$ to 9 $\mu g/m^3$. This change has been recently proposed by the US Environmental Protection Agency (EPA). Our goal is to estimate, for the first time, the 
&lt;/p&gt;</description></item></channel></rss>