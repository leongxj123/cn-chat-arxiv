<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>skscope&#26159;&#19968;&#20010;Python&#24211;&#65292;&#36890;&#36807;&#21482;&#38656;&#32534;&#20889;&#30446;&#26631;&#20989;&#25968;&#65292;&#23601;&#33021;&#24555;&#36895;&#23454;&#29616;&#31232;&#30095;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#30340;&#35299;&#20915;&#65292;&#24182;&#19988;&#22312;&#39640;&#32500;&#21442;&#25968;&#31354;&#38388;&#19979;&#65292;&#20854;&#39640;&#25928;&#23454;&#29616;&#20351;&#24471;&#27714;&#35299;&#22120;&#33021;&#22815;&#36805;&#36895;&#33719;&#24471;&#31232;&#30095;&#35299;&#65292;&#36895;&#24230;&#27604;&#22522;&#20934;&#20984;&#27714;&#35299;&#22120;&#24555;80&#20493;&#12290;</title><link>https://arxiv.org/abs/2403.18540</link><description>&lt;p&gt;
skscope&#65306;Python&#20013;&#30340;&#24555;&#36895;&#31232;&#30095;&#32422;&#26463;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
skscope: Fast Sparsity-Constrained Optimization in Python
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18540
&lt;/p&gt;
&lt;p&gt;
skscope&#26159;&#19968;&#20010;Python&#24211;&#65292;&#36890;&#36807;&#21482;&#38656;&#32534;&#20889;&#30446;&#26631;&#20989;&#25968;&#65292;&#23601;&#33021;&#24555;&#36895;&#23454;&#29616;&#31232;&#30095;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#30340;&#35299;&#20915;&#65292;&#24182;&#19988;&#22312;&#39640;&#32500;&#21442;&#25968;&#31354;&#38388;&#19979;&#65292;&#20854;&#39640;&#25928;&#23454;&#29616;&#20351;&#24471;&#27714;&#35299;&#22120;&#33021;&#22815;&#36805;&#36895;&#33719;&#24471;&#31232;&#30095;&#35299;&#65292;&#36895;&#24230;&#27604;&#22522;&#20934;&#20984;&#27714;&#35299;&#22120;&#24555;80&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31232;&#30095;&#32422;&#26463;&#20248;&#21270;&#65288;SCO&#65289;&#19978;&#24212;&#29992;&#36845;&#20195;&#27714;&#35299;&#22120;&#38656;&#35201;&#32321;&#29712;&#30340;&#25968;&#23398;&#25512;&#23548;&#21644;&#20180;&#32454;&#30340;&#32534;&#31243;/&#35843;&#35797;&#65292;&#36825;&#38480;&#21046;&#20102;&#36825;&#20123;&#27714;&#35299;&#22120;&#30340;&#24191;&#27867;&#24433;&#21709;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#24211;skscope&#65292;&#20197;&#20811;&#26381;&#27492;&#38556;&#30861;&#12290;&#20511;&#21161;skscope&#65292;&#29992;&#25143;&#21482;&#38656;&#32534;&#20889;&#30446;&#26631;&#20989;&#25968;&#21363;&#21487;&#35299;&#20915;SCO&#38382;&#39064;&#12290;&#26412;&#25991;&#36890;&#36807;&#20004;&#20010;&#20363;&#23376;&#28436;&#31034;&#20102;skscope&#30340;&#26041;&#20415;&#20043;&#22788;&#65292;&#20854;&#20013;&#21482;&#38656;&#22235;&#34892;&#20195;&#30721;&#23601;&#21487;&#20197;&#35299;&#20915;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#21644;&#36235;&#21183;&#36807;&#28388;&#12290;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;skscope&#30340;&#39640;&#25928;&#23454;&#29616;&#20351;&#24471;&#26368;&#20808;&#36827;&#30340;&#27714;&#35299;&#22120;&#21487;&#20197;&#24555;&#36895;&#33719;&#24471;&#31232;&#30095;&#35299;&#65292;&#32780;&#26080;&#38656;&#32771;&#34385;&#21442;&#25968;&#31354;&#38388;&#30340;&#39640;&#32500;&#24230;&#12290;&#25968;&#20540;&#23454;&#39564;&#26174;&#31034;&#65292;skscope&#20013;&#30340;&#21487;&#29992;&#27714;&#35299;&#22120;&#21487;&#20197;&#23454;&#29616;&#27604;&#22522;&#20934;&#20984;&#27714;&#35299;&#22120;&#33719;&#24471;&#30340;&#31454;&#20105;&#26494;&#24347;&#35299;&#39640;&#36798;80&#20493;&#30340;&#21152;&#36895;&#24230;&#12290;skscope&#24050;&#32463;&#21457;&#24067;&#22312;Python&#36719;&#20214;&#21253;&#32034;&#24341;&#65288;PyPI&#65289;&#21644;Conda&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18540v1 Announce Type: cross  Abstract: Applying iterative solvers on sparsity-constrained optimization (SCO) requires tedious mathematical deduction and careful programming/debugging that hinders these solvers' broad impact. In the paper, the library skscope is introduced to overcome such an obstacle. With skscope, users can solve the SCO by just programming the objective function. The convenience of skscope is demonstrated through two examples in the paper, where sparse linear regression and trend filtering are addressed with just four lines of code. More importantly, skscope's efficient implementation allows state-of-the-art solvers to quickly attain the sparse solution regardless of the high dimensionality of parameter space. Numerical experiments reveal the available solvers in skscope can achieve up to 80x speedup on the competing relaxation solutions obtained via the benchmarked convex solver. skscope is published on the Python Package Index (PyPI) and Conda, and its 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#27491;&#21017;&#21270;&#22238;&#24402;&#65292;&#22312;&#36229;&#21442;&#25968;&#21270;&#33539;&#22260;&#20869;&#65292;&#26681;&#25454;&#29305;&#23450;&#36873;&#25321;&#30340;&#20984;&#20989;&#25968;&#24182;&#36866;&#24403;&#22686;&#21152;&#19968;&#20010;&#27491;&#21017;&#21270;&#39033;&#65292;&#21487;&#20197;&#23454;&#29616;&#31232;&#30095;&#21644;&#19968;&#20301;&#35299;&#20915;&#26041;&#26696;&#65292;&#20854;&#24615;&#33021;&#20960;&#20046;&#19982;&#26368;&#20339;&#20998;&#31867;&#24615;&#33021;&#30456;&#21516;&#12290;</title><link>https://arxiv.org/abs/2402.10474</link><description>&lt;p&gt;
&#19968;&#20301;&#37327;&#21270;&#21644;&#31232;&#30095;&#21270;&#29992;&#20110;&#22810;&#31867;&#32447;&#24615;&#20998;&#31867;&#30340;&#27491;&#21017;&#21270;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
One-Bit Quantization and Sparsification for Multiclass Linear Classification via Regularized Regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10474
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#27491;&#21017;&#21270;&#22238;&#24402;&#65292;&#22312;&#36229;&#21442;&#25968;&#21270;&#33539;&#22260;&#20869;&#65292;&#26681;&#25454;&#29305;&#23450;&#36873;&#25321;&#30340;&#20984;&#20989;&#25968;&#24182;&#36866;&#24403;&#22686;&#21152;&#19968;&#20010;&#27491;&#21017;&#21270;&#39033;&#65292;&#21487;&#20197;&#23454;&#29616;&#31232;&#30095;&#21644;&#19968;&#20301;&#35299;&#20915;&#26041;&#26696;&#65292;&#20854;&#24615;&#33021;&#20960;&#20046;&#19982;&#26368;&#20339;&#20998;&#31867;&#24615;&#33021;&#30456;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32447;&#24615;&#22238;&#24402;&#20013;&#29992;&#20110;&#22810;&#31867;&#20998;&#31867;&#30340;&#38382;&#39064;&#65292;&#36825;&#20123;&#38382;&#39064;&#22312;&#36229;&#21442;&#25968;&#21270;&#33539;&#22260;&#20869;&#65292;&#35757;&#32451;&#25968;&#25454;&#20013;&#19968;&#20123;&#26631;&#35760;&#38169;&#35823;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#20026;&#20102;&#36991;&#20813;&#36807;&#24230;&#25311;&#21512;&#38169;&#35823;&#26631;&#35760;&#30340;&#25968;&#25454;&#65292;&#38656;&#35201;&#28155;&#21152;&#19968;&#20010;&#26174;&#24335;&#30340;&#27491;&#21017;&#21270;&#39033;&#65292;$\lambda f(w)$&#65292;&#20854;&#20013;$f(\cdot)$&#26159;&#26576;&#20010;&#20984;&#20989;&#25968;&#12290;&#22312;&#25105;&#20204;&#30340;&#20998;&#26512;&#20013;&#65292;&#25105;&#20204;&#20551;&#35774;&#25968;&#25454;&#26159;&#20174;&#19968;&#20010;&#20855;&#26377;&#30456;&#31561;&#31867;&#22823;&#23567;&#30340;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#20013;&#37319;&#26679;&#30340;&#65292;&#24182;&#19988;&#27599;&#20010;&#31867;&#21035;&#30340;&#35757;&#32451;&#26631;&#31614;&#20013;&#26377;&#19968;&#37096;&#20998;&#27604;&#20363;&#20026;$c$&#26159;&#38169;&#35823;&#30340;&#12290;&#22312;&#36825;&#20123;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;$f(\cdot) = \|\cdot\|^2_2$&#19988;$\lambda \to \infty$&#26102;&#65292;&#21487;&#20197;&#33719;&#24471;&#26368;&#20339;&#30340;&#20998;&#31867;&#24615;&#33021;&#12290;&#28982;&#21518;&#25105;&#20204;&#32487;&#32493;&#20998;&#26512;&#20102;&#22312;&#22823;$\lambda$&#33539;&#22260;&#20869;$f(\cdot) = \|\cdot\|_1$&#21644;$f(\cdot) = \|\cdot\|_\infty$&#30340;&#20998;&#31867;&#38169;&#35823;&#65292;&#24182;&#19988;&#27880;&#24847;&#21040;&#36890;&#24120;&#21487;&#20197;&#25214;&#21040;&#31232;&#30095;&#21644;&#19968;&#20301;&#35299;&#20915;&#26041;&#26696;&#65292;&#20998;&#21035;&#34920;&#29616;&#20960;&#20046;&#19982;$f(\cdot) = \|\cdot\|^2_2$&#30456;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10474v1 Announce Type: new  Abstract: We study the use of linear regression for multiclass classification in the over-parametrized regime where some of the training data is mislabeled. In such scenarios it is necessary to add an explicit regularization term, $\lambda f(w)$, for some convex function $f(\cdot)$, to avoid overfitting the mislabeled data. In our analysis, we assume that the data is sampled from a Gaussian Mixture Model with equal class sizes, and that a proportion $c$ of the training labels is corrupted for each class. Under these assumptions, we prove that the best classification performance is achieved when $f(\cdot) = \|\cdot\|^2_2$ and $\lambda \to \infty$. We then proceed to analyze the classification errors for $f(\cdot) = \|\cdot\|_1$ and $f(\cdot) = \|\cdot\|_\infty$ in the large $\lambda$ regime and notice that it is often possible to find sparse and one-bit solutions, respectively, that perform almost as well as the one corresponding to $f(\cdot) = \|\
&lt;/p&gt;</description></item><item><title>SMOTE&#26159;&#19968;&#31181;&#22788;&#29702;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#30340;&#24120;&#29992;&#37325;&#26032;&#24179;&#34913;&#31574;&#30053;&#65292;&#23427;&#36890;&#36807;&#22797;&#21046;&#21407;&#22987;&#23569;&#25968;&#26679;&#26412;&#26469;&#37325;&#26032;&#29983;&#25104;&#21407;&#22987;&#20998;&#24067;&#12290;&#26412;&#30740;&#31350;&#35777;&#26126;&#20102;SMOTE&#30340;&#23494;&#24230;&#22312;&#23569;&#25968;&#26679;&#26412;&#20998;&#24067;&#30340;&#36793;&#30028;&#38468;&#36817;&#36880;&#28176;&#20943;&#23567;&#65292;&#20174;&#32780;&#39564;&#35777;&#20102;BorderLine SMOTE&#31574;&#30053;&#30340;&#21512;&#29702;&#24615;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#36824;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;SMOTE&#30456;&#20851;&#31574;&#30053;&#65292;&#24182;&#19982;&#20854;&#20182;&#37325;&#26032;&#24179;&#34913;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#26368;&#32456;&#21457;&#29616;&#65292;&#22312;&#25968;&#25454;&#38598;&#26497;&#24230;&#19981;&#24179;&#34913;&#30340;&#24773;&#20917;&#19979;&#65292;SMOTE&#12289;&#25552;&#20986;&#30340;&#26041;&#27861;&#25110;&#27424;&#37319;&#26679;&#31243;&#24207;&#26159;&#26368;&#20339;&#30340;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2402.03819</link><description>&lt;p&gt;
SMOTE&#30340;&#29702;&#35770;&#21644;&#23454;&#39564;&#30740;&#31350;&#65306;&#20851;&#20110;&#37325;&#26032;&#24179;&#34913;&#31574;&#30053;&#30340;&#38480;&#21046;&#21644;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Theoretical and experimental study of SMOTE: limitations and comparisons of rebalancing strategies
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03819
&lt;/p&gt;
&lt;p&gt;
SMOTE&#26159;&#19968;&#31181;&#22788;&#29702;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#30340;&#24120;&#29992;&#37325;&#26032;&#24179;&#34913;&#31574;&#30053;&#65292;&#23427;&#36890;&#36807;&#22797;&#21046;&#21407;&#22987;&#23569;&#25968;&#26679;&#26412;&#26469;&#37325;&#26032;&#29983;&#25104;&#21407;&#22987;&#20998;&#24067;&#12290;&#26412;&#30740;&#31350;&#35777;&#26126;&#20102;SMOTE&#30340;&#23494;&#24230;&#22312;&#23569;&#25968;&#26679;&#26412;&#20998;&#24067;&#30340;&#36793;&#30028;&#38468;&#36817;&#36880;&#28176;&#20943;&#23567;&#65292;&#20174;&#32780;&#39564;&#35777;&#20102;BorderLine SMOTE&#31574;&#30053;&#30340;&#21512;&#29702;&#24615;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#36824;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;SMOTE&#30456;&#20851;&#31574;&#30053;&#65292;&#24182;&#19982;&#20854;&#20182;&#37325;&#26032;&#24179;&#34913;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#26368;&#32456;&#21457;&#29616;&#65292;&#22312;&#25968;&#25454;&#38598;&#26497;&#24230;&#19981;&#24179;&#34913;&#30340;&#24773;&#20917;&#19979;&#65292;SMOTE&#12289;&#25552;&#20986;&#30340;&#26041;&#27861;&#25110;&#27424;&#37319;&#26679;&#31243;&#24207;&#26159;&#26368;&#20339;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
SMOTE&#65288;Synthetic Minority Oversampling Technique&#65289;&#26159;&#22788;&#29702;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#24120;&#29992;&#30340;&#37325;&#26032;&#24179;&#34913;&#31574;&#30053;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#28176;&#36827;&#24773;&#20917;&#19979;&#65292;SMOTE&#65288;&#40664;&#35748;&#21442;&#25968;&#65289;&#36890;&#36807;&#31616;&#21333;&#22797;&#21046;&#21407;&#22987;&#23569;&#25968;&#26679;&#26412;&#26469;&#37325;&#26032;&#29983;&#25104;&#21407;&#22987;&#20998;&#24067;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#22312;&#23569;&#25968;&#26679;&#26412;&#20998;&#24067;&#30340;&#25903;&#25345;&#36793;&#30028;&#38468;&#36817;&#65292;SMOTE&#30340;&#23494;&#24230;&#20250;&#20943;&#23567;&#65292;&#20174;&#32780;&#39564;&#35777;&#20102;&#24120;&#35265;&#30340;BorderLine SMOTE&#31574;&#30053;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;SMOTE&#30456;&#20851;&#31574;&#30053;&#65292;&#24182;&#23558;&#23427;&#20204;&#19982;&#29616;&#26377;&#30340;&#37325;&#26032;&#24179;&#34913;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#21482;&#26377;&#24403;&#25968;&#25454;&#38598;&#26497;&#24230;&#19981;&#24179;&#34913;&#26102;&#25165;&#38656;&#35201;&#37325;&#26032;&#24179;&#34913;&#31574;&#30053;&#12290;&#23545;&#20110;&#36825;&#31181;&#25968;&#25454;&#38598;&#65292;SMOTE&#12289;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#25110;&#27424;&#37319;&#26679;&#31243;&#24207;&#26159;&#26368;&#20339;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Synthetic Minority Oversampling Technique (SMOTE) is a common rebalancing strategy for handling imbalanced data sets. Asymptotically, we prove that SMOTE (with default parameter) regenerates the original distribution by simply copying the original minority samples. We also prove that SMOTE density vanishes near the boundary of the support of the minority distribution, therefore justifying the common BorderLine SMOTE strategy. Then we introduce two new SMOTE-related strategies, and compare them with state-of-the-art rebalancing procedures. We show that rebalancing strategies are only required when the data set is highly imbalanced. For such data sets, SMOTE, our proposals, or undersampling procedures are the best strategies.
&lt;/p&gt;</description></item><item><title>&#23637;&#31034;&#20102;&#26925;&#22278;&#23545;&#31216;&#20998;&#24067;&#28151;&#21512;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#19968;&#33268;&#24615;&#65292;&#20026;&#22522;&#20110;&#38750;&#21442;&#25968;&#20998;&#24067;&#30340;&#32858;&#31867;&#25552;&#20379;&#20102;&#29702;&#35770;&#20381;&#25454;&#12290;</title><link>https://arxiv.org/abs/2311.06108</link><description>&lt;p&gt;
&#22522;&#20110;&#26925;&#22278;&#23545;&#31216;&#20998;&#24067;&#28151;&#21512;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#21644;&#32858;&#31867;&#30340;&#38750;&#21442;&#25968;&#19968;&#33268;&#24615;
&lt;/p&gt;
&lt;p&gt;
Nonparametric consistency for maximum likelihood estimation and clustering based on mixtures of elliptically-symmetric distributions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.06108
&lt;/p&gt;
&lt;p&gt;
&#23637;&#31034;&#20102;&#26925;&#22278;&#23545;&#31216;&#20998;&#24067;&#28151;&#21512;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#19968;&#33268;&#24615;&#65292;&#20026;&#22522;&#20110;&#38750;&#21442;&#25968;&#20998;&#24067;&#30340;&#32858;&#31867;&#25552;&#20379;&#20102;&#29702;&#35770;&#20381;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#23637;&#31034;&#20102;&#26925;&#22278;&#23545;&#31216;&#20998;&#24067;&#28151;&#21512;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#23545;&#20854;&#24635;&#20307;&#29256;&#26412;&#30340;&#19968;&#33268;&#24615;&#65292;&#20854;&#20013;&#28508;&#22312;&#20998;&#24067;P&#26159;&#38750;&#21442;&#25968;&#30340;&#65292;&#24182;&#19981;&#19968;&#23450;&#23646;&#20110;&#20272;&#35745;&#22120;&#25152;&#22522;&#20110;&#30340;&#28151;&#21512;&#31867;&#21035;&#12290;&#24403;P&#26159;&#36275;&#22815;&#20998;&#31163;&#20294;&#38750;&#21442;&#25968;&#30340;&#20998;&#24067;&#28151;&#21512;&#26102;&#65292;&#34920;&#26126;&#20102;&#20272;&#35745;&#22120;&#30340;&#24635;&#20307;&#29256;&#26412;&#30340;&#32452;&#20998;&#23545;&#24212;&#20110;P&#30340;&#33391;&#22909;&#20998;&#31163;&#32452;&#20998;&#12290;&#36825;&#20026;&#22312;P&#20855;&#26377;&#33391;&#22909;&#20998;&#31163;&#23376;&#24635;&#20307;&#30340;&#24773;&#20917;&#19979;&#20351;&#29992;&#36825;&#26679;&#30340;&#20272;&#35745;&#22120;&#36827;&#34892;&#32858;&#31867;&#20998;&#26512;&#25552;&#20379;&#20102;&#19968;&#20123;&#29702;&#35770;&#19978;&#30340;&#29702;&#25454;&#65292;&#21363;&#20351;&#36825;&#20123;&#23376;&#24635;&#20307;&#19982;&#28151;&#21512;&#27169;&#22411;&#25152;&#20551;&#35774;&#30340;&#19981;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.06108v2 Announce Type: replace-cross  Abstract: The consistency of the maximum likelihood estimator for mixtures of elliptically-symmetric distributions for estimating its population version is shown, where the underlying distribution $P$ is nonparametric and does not necessarily belong to the class of mixtures on which the estimator is based. In a situation where $P$ is a mixture of well enough separated but nonparametric distributions it is shown that the components of the population version of the estimator correspond to the well separated components of $P$. This provides some theoretical justification for the use of such estimators for cluster analysis in case that $P$ has well separated subpopulations even if these subpopulations differ from what the mixture model assumes.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#36866;&#24212;Hui-Walter&#33539;&#24335;&#65292;&#23558;&#20256;&#32479;&#24212;&#29992;&#20110;&#27969;&#34892;&#30149;&#23398;&#21644;&#21307;&#23398;&#30340;&#26041;&#27861;&#24341;&#20837;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#65292;&#35299;&#20915;&#20102;&#35757;&#32451;&#21644;&#35780;&#20272;&#26102;&#26080;&#27861;&#33719;&#24471;&#26631;&#31614;&#25968;&#25454;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#23558;&#25968;&#25454;&#21010;&#20998;&#20026;&#28508;&#22312;&#31867;&#21035;&#65292;&#24182;&#22312;&#22810;&#20010;&#27979;&#35797;&#20013;&#29420;&#31435;&#35757;&#32451;&#27169;&#22411;&#65292;&#33021;&#22815;&#22312;&#27809;&#26377;&#30495;&#23454;&#20540;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#20851;&#38190;&#24615;&#33021;&#25351;&#26631;&#65292;&#24182;&#22312;&#22788;&#29702;&#22312;&#32447;&#25968;&#25454;&#26102;&#25552;&#20379;&#20102;&#26032;&#30340;&#21487;&#33021;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.09376</link><description>&lt;p&gt;
&#35299;&#38145;&#26080;&#26631;&#31614;&#25968;&#25454;: Hui-Walter&#33539;&#24335;&#22312;&#22312;&#32447;&#21644;&#38745;&#24577;&#29615;&#22659;&#20013;&#30340;&#24615;&#33021;&#35780;&#20272;&#20013;&#30340;&#38598;&#25104;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Unlocking Unlabeled Data: Ensemble Learning with the Hui- Walter Paradigm for Performance Estimation in Online and Static Settings. (arXiv:2401.09376v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09376
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#36866;&#24212;Hui-Walter&#33539;&#24335;&#65292;&#23558;&#20256;&#32479;&#24212;&#29992;&#20110;&#27969;&#34892;&#30149;&#23398;&#21644;&#21307;&#23398;&#30340;&#26041;&#27861;&#24341;&#20837;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#65292;&#35299;&#20915;&#20102;&#35757;&#32451;&#21644;&#35780;&#20272;&#26102;&#26080;&#27861;&#33719;&#24471;&#26631;&#31614;&#25968;&#25454;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#23558;&#25968;&#25454;&#21010;&#20998;&#20026;&#28508;&#22312;&#31867;&#21035;&#65292;&#24182;&#22312;&#22810;&#20010;&#27979;&#35797;&#20013;&#29420;&#31435;&#35757;&#32451;&#27169;&#22411;&#65292;&#33021;&#22815;&#22312;&#27809;&#26377;&#30495;&#23454;&#20540;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#20851;&#38190;&#24615;&#33021;&#25351;&#26631;&#65292;&#24182;&#22312;&#22788;&#29702;&#22312;&#32447;&#25968;&#25454;&#26102;&#25552;&#20379;&#20102;&#26032;&#30340;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#24314;&#27169;&#39046;&#22495;&#65292;&#20174;&#19994;&#20154;&#21592;&#24120;&#24120;&#22312;&#21487;&#35780;&#20272;&#21644;&#35757;&#32451;&#30340;&#20551;&#35774;&#19979;&#24037;&#20316;&#65292;&#21363;&#21487;&#35775;&#38382;&#30340;&#12289;&#38745;&#24577;&#30340;&#12289;&#24102;&#26377;&#26631;&#31614;&#30340;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#36825;&#20010;&#20551;&#35774;&#24448;&#24448;&#20559;&#31163;&#20102;&#29616;&#23454;&#65292;&#20854;&#20013;&#30340;&#25968;&#25454;&#21487;&#33021;&#26159;&#31169;&#26377;&#30340;&#12289;&#21152;&#23494;&#30340;&#12289;&#38590;&#20197;&#27979;&#37327;&#30340;&#25110;&#32773;&#27809;&#26377;&#26631;&#31614;&#12290;&#26412;&#25991;&#36890;&#36807;&#23558;&#20256;&#32479;&#24212;&#29992;&#20110;&#27969;&#34892;&#30149;&#23398;&#21644;&#21307;&#23398;&#30340;Hui-Walter&#33539;&#24335;&#35843;&#25972;&#21040;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#26469;&#24357;&#21512;&#36825;&#20010;&#24046;&#36317;&#12290;&#36825;&#31181;&#26041;&#27861;&#20351;&#25105;&#20204;&#33021;&#22815;&#22312;&#27809;&#26377;&#30495;&#23454;&#20540;&#21487;&#29992;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#20851;&#38190;&#24615;&#33021;&#25351;&#26631;&#65292;&#22914;&#20551;&#38451;&#24615;&#29575;&#12289;&#20551;&#38452;&#24615;&#29575;&#21644;&#20808;&#39564;&#27010;&#29575;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25193;&#23637;&#20102;&#36825;&#31181;&#33539;&#24335;&#26469;&#22788;&#29702;&#22312;&#32447;&#25968;&#25454;&#65292;&#24320;&#36767;&#20102;&#21160;&#24577;&#25968;&#25454;&#29615;&#22659;&#30340;&#26032;&#21487;&#33021;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#28041;&#21450;&#23558;&#25968;&#25454;&#21010;&#20998;&#20026;&#28508;&#22312;&#31867;&#21035;&#65292;&#20197;&#27169;&#25311;&#22810;&#20010;&#25968;&#25454;&#32676;&#20307;&#65288;&#22914;&#26524;&#27809;&#26377;&#33258;&#28982;&#32676;&#20307;&#21487;&#29992;&#65289;&#65292;&#24182;&#29420;&#31435;&#35757;&#32451;&#27169;&#22411;&#26469;&#22797;&#21046;&#22810;&#27425;&#27979;&#35797;&#12290;&#36890;&#36807;&#22312;&#19981;&#21516;&#25968;&#25454;&#23376;&#38598;&#20043;&#38388;&#20132;&#21449;&#21046;&#34920;&#65292;&#25105;&#20204;&#33021;&#22815;&#27604;&#36739;&#20108;&#20803;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the realm of machine learning and statistical modeling, practitioners often work under the assumption of accessible, static, labeled data for evaluation and training. However, this assumption often deviates from reality where data may be private, encrypted, difficult- to-measure, or unlabeled. In this paper, we bridge this gap by adapting the Hui-Walter paradigm, a method traditionally applied in epidemiology and medicine, to the field of machine learning. This approach enables us to estimate key performance metrics such as false positive rate, false negative rate, and priors in scenarios where no ground truth is available. We further extend this paradigm for handling online data, opening up new possibilities for dynamic data environments. Our methodology involves partitioning data into latent classes to simulate multiple data populations (if natural populations are unavailable) and independently training models to replicate multiple tests. By cross-tabulating binary outcomes across
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#37325;&#26032;&#23457;&#35270;&#21644;&#37325;&#26032;&#35774;&#35745;&#20102;&#36923;&#36753;-softmax&#20284;&#28982;&#65292;&#36890;&#36807;&#28201;&#24230;&#21442;&#25968;&#25511;&#21046;&#20808;&#39564;&#32622;&#20449;&#27700;&#24179;&#65292;&#20174;&#32780;&#25913;&#21892;&#20102;&#36125;&#21494;&#26031;&#20803;&#23398;&#20064;&#20013;&#30340;&#23569;&#26679;&#26412;&#20998;&#31867;&#38382;&#39064;&#12290;&#21516;&#26102;&#35777;&#26126;softmax&#26159;&#36923;&#36753;-softmax&#30340;&#19968;&#31181;&#29305;&#27530;&#24773;&#20917;&#65292;&#36923;&#36753;-softmax&#33021;&#22815;&#24341;&#23548;&#26356;&#22823;&#30340;&#25968;&#25454;&#20998;&#24067;&#23478;&#26063;&#12290;</title><link>http://arxiv.org/abs/2310.10379</link><description>&lt;p&gt;
&#37325;&#26032;&#23457;&#35270;&#36125;&#21494;&#26031;&#20803;&#23398;&#20064;&#20013;&#36923;&#36753;-softmax&#20284;&#28982;&#29992;&#20110;&#23569;&#26679;&#26412;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Revisiting Logistic-softmax Likelihood in Bayesian Meta-Learning for Few-Shot Classification. (arXiv:2310.10379v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10379
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#26032;&#23457;&#35270;&#21644;&#37325;&#26032;&#35774;&#35745;&#20102;&#36923;&#36753;-softmax&#20284;&#28982;&#65292;&#36890;&#36807;&#28201;&#24230;&#21442;&#25968;&#25511;&#21046;&#20808;&#39564;&#32622;&#20449;&#27700;&#24179;&#65292;&#20174;&#32780;&#25913;&#21892;&#20102;&#36125;&#21494;&#26031;&#20803;&#23398;&#20064;&#20013;&#30340;&#23569;&#26679;&#26412;&#20998;&#31867;&#38382;&#39064;&#12290;&#21516;&#26102;&#35777;&#26126;softmax&#26159;&#36923;&#36753;-softmax&#30340;&#19968;&#31181;&#29305;&#27530;&#24773;&#20917;&#65292;&#36923;&#36753;-softmax&#33021;&#22815;&#24341;&#23548;&#26356;&#22823;&#30340;&#25968;&#25454;&#20998;&#24067;&#23478;&#26063;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20803;&#23398;&#20064;&#36890;&#36807;&#23398;&#20064;&#20351;&#29992;&#20808;&#21069;&#30340;&#30693;&#35782;&#35299;&#20915;&#26032;&#38382;&#39064;&#65292;&#22312;&#23569;&#26679;&#26412;&#20998;&#31867;&#20013;&#21462;&#24471;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;&#36125;&#21494;&#26031;&#26041;&#27861;&#33021;&#22815;&#26377;&#25928;&#22320;&#34920;&#24449;&#23569;&#26679;&#26412;&#20998;&#31867;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#36825;&#22312;&#39640;&#39118;&#38505;&#39046;&#22495;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#22312;&#22810;&#31867;&#21035;&#39640;&#26031;&#36807;&#31243;&#20998;&#31867;&#20013;&#65292;&#36923;&#36753;-softmax&#20284;&#28982;&#19968;&#30452;&#34987;&#29992;&#20316;softmax&#20284;&#28982;&#30340;&#26367;&#20195;&#26041;&#27861;&#65292;&#22240;&#20026;&#20854;&#20855;&#26377;&#26465;&#20214;&#20849;&#36717;&#24615;&#36136;&#12290;&#28982;&#32780;&#65292;&#36923;&#36753;-softmax&#30340;&#29702;&#35770;&#29305;&#24615;&#19981;&#28165;&#26970;&#65292;&#20197;&#21069;&#30340;&#30740;&#31350;&#34920;&#26126;&#36923;&#36753;-softmax&#30340;&#22266;&#26377;&#19981;&#30830;&#23450;&#24615;&#23548;&#33268;&#20102;&#27425;&#20248;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#21644;&#37325;&#26032;&#35774;&#35745;&#20102;&#36923;&#36753;-softmax&#20284;&#28982;&#65292;&#36890;&#36807;&#19968;&#20010;&#28201;&#24230;&#21442;&#25968;&#23454;&#29616;&#23545;&#20808;&#39564;&#32622;&#20449;&#27700;&#24179;&#30340;&#25511;&#21046;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20174;&#29702;&#35770;&#21644;&#23454;&#36341;&#30340;&#35282;&#24230;&#35777;&#26126;&#20102;softmax&#21487;&#20197;&#34987;&#35270;&#20026;&#36923;&#36753;-softmax&#30340;&#19968;&#31181;&#29305;&#27530;&#24773;&#20917;&#65292;&#24182;&#19988;&#36923;&#36753;-softmax&#24341;&#23548;&#20102;&#27604;softmax&#26356;&#22823;&#30340;&#25968;&#25454;&#20998;&#24067;&#23478;&#26063;&#12290;
&lt;/p&gt;
&lt;p&gt;
Meta-learning has demonstrated promising results in few-shot classification (FSC) by learning to solve new problems using prior knowledge. Bayesian methods are effective at characterizing uncertainty in FSC, which is crucial in high-risk fields. In this context, the logistic-softmax likelihood is often employed as an alternative to the softmax likelihood in multi-class Gaussian process classification due to its conditional conjugacy property. However, the theoretical property of logistic-softmax is not clear and previous research indicated that the inherent uncertainty of logistic-softmax leads to suboptimal performance. To mitigate these issues, we revisit and redesign the logistic-softmax likelihood, which enables control of the \textit{a priori} confidence level through a temperature parameter. Furthermore, we theoretically and empirically show that softmax can be viewed as a special case of logistic-softmax and logistic-softmax induces a larger family of data distribution than soft
&lt;/p&gt;</description></item><item><title>Continuous Sweep&#26159;&#19968;&#31181;&#25913;&#36827;&#30340;&#20108;&#20803;&#37327;&#21270;&#22120;&#65292;&#36890;&#36807;&#20351;&#29992;&#21442;&#25968;&#21270;&#31867;&#21035;&#20998;&#24067;&#12289;&#20248;&#21270;&#20915;&#31574;&#36793;&#30028;&#20197;&#21450;&#35745;&#31639;&#22343;&#20540;&#31561;&#26041;&#27861;&#65292;&#23427;&#22312;&#37327;&#21270;&#23398;&#20064;&#20013;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.08387</link><description>&lt;p&gt;
Continuous Sweep: &#19968;&#31181;&#25913;&#36827;&#30340;&#20108;&#20803;&#37327;&#21270;&#22120;
&lt;/p&gt;
&lt;p&gt;
Continuous Sweep: an improved, binary quantifier. (arXiv:2308.08387v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08387
&lt;/p&gt;
&lt;p&gt;
Continuous Sweep&#26159;&#19968;&#31181;&#25913;&#36827;&#30340;&#20108;&#20803;&#37327;&#21270;&#22120;&#65292;&#36890;&#36807;&#20351;&#29992;&#21442;&#25968;&#21270;&#31867;&#21035;&#20998;&#24067;&#12289;&#20248;&#21270;&#20915;&#31574;&#36793;&#30028;&#20197;&#21450;&#35745;&#31639;&#22343;&#20540;&#31561;&#26041;&#27861;&#65292;&#23427;&#22312;&#37327;&#21270;&#23398;&#20064;&#20013;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#21270;&#26159;&#19968;&#31181;&#30417;&#30563;&#24335;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#65292;&#20854;&#20851;&#27880;&#30340;&#26159;&#20272;&#35745;&#25968;&#25454;&#38598;&#20013;&#31867;&#21035;&#30340;&#26222;&#36941;&#24615;&#65292;&#32780;&#19981;&#26159;&#26631;&#35760;&#20854;&#20010;&#20307;&#35266;&#27979;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;Continuous Sweep&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#30340;&#21442;&#25968;&#21270;&#20108;&#20803;&#37327;&#21270;&#22120;&#65292;&#21463;&#21040;&#34920;&#29616;&#33391;&#22909;&#30340;Median Sweep&#30340;&#21551;&#21457;&#12290;Median Sweep&#30446;&#21069;&#26159;&#26368;&#22909;&#30340;&#20108;&#20803;&#37327;&#21270;&#22120;&#20043;&#19968;&#65292;&#20294;&#25105;&#20204;&#22312;&#19977;&#20010;&#26041;&#38754;&#25913;&#21464;&#20102;&#36825;&#20010;&#37327;&#21270;&#22120;&#65292;&#21363;1&#65289;&#20351;&#29992;&#21442;&#25968;&#21270;&#30340;&#31867;&#21035;&#20998;&#24067;&#32780;&#19981;&#26159;&#32463;&#39564;&#20998;&#24067;&#65292;2&#65289;&#20248;&#21270;&#20915;&#31574;&#36793;&#30028;&#32780;&#19981;&#26159;&#24212;&#29992;&#31163;&#25955;&#30340;&#20915;&#31574;&#35268;&#21017;&#65292;3&#65289;&#35745;&#31639;&#22343;&#20540;&#32780;&#19981;&#26159;&#20013;&#20301;&#25968;&#12290;&#22312;&#19968;&#33324;&#27169;&#22411;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;Continuous Sweep&#30340;&#20559;&#24046;&#21644;&#26041;&#24046;&#30340;&#35299;&#26512;&#34920;&#36798;&#24335;&#12290;&#36825;&#26159;&#37327;&#21270;&#23398;&#20064;&#39046;&#22495;&#20013;&#30340;&#39318;&#27425;&#29702;&#35770;&#36129;&#29486;&#20043;&#19968;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#25512;&#23548;&#20351;&#25105;&#20204;&#33021;&#22815;&#25214;&#21040;&#26368;&#20248;&#30340;&#20915;&#31574;&#36793;&#30028;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#30340;&#27169;&#25311;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#24191;&#27867;&#30340;&#24773;&#20917;&#19979;&#65292;Continuous Sweep&#20248;&#20110;Median Sweep&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantification is a supervised machine learning task, focused on estimating the class prevalence of a dataset rather than labeling its individual observations. We introduce Continuous Sweep, a new parametric binary quantifier inspired by the well-performing Median Sweep. Median Sweep is currently one of the best binary quantifiers, but we have changed this quantifier on three points, namely 1) using parametric class distributions instead of empirical distributions, 2) optimizing decision boundaries instead of applying discrete decision rules, and 3) calculating the mean instead of the median. We derive analytic expressions for the bias and variance of Continuous Sweep under general model assumptions. This is one of the first theoretical contributions in the field of quantification learning. Moreover, these derivations enable us to find the optimal decision boundaries. Finally, our simulation study shows that Continuous Sweep outperforms Median Sweep in a wide range of situations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#35748;&#35777;&#30340;&#22810;&#27969;&#31243;&#38646;&#38454;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;MFDOO&#31639;&#27861;&#30340;&#35748;&#35777;&#21464;&#20307;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#20855;&#26377;&#36817;&#20284;&#26368;&#20248;&#30340;&#20195;&#20215;&#22797;&#26434;&#24230;&#12290;&#21516;&#26102;&#65292;&#36824;&#32771;&#34385;&#20102;&#26377;&#22122;&#22768;&#35780;&#20272;&#30340;&#29305;&#27530;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2308.00978</link><description>&lt;p&gt;
&#35748;&#35777;&#30340;&#22810;&#27969;&#31243;&#38646;&#38454;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Certified Multi-Fidelity Zeroth-Order Optimization. (arXiv:2308.00978v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00978
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#35748;&#35777;&#30340;&#22810;&#27969;&#31243;&#38646;&#38454;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;MFDOO&#31639;&#27861;&#30340;&#35748;&#35777;&#21464;&#20307;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#20855;&#26377;&#36817;&#20284;&#26368;&#20248;&#30340;&#20195;&#20215;&#22797;&#26434;&#24230;&#12290;&#21516;&#26102;&#65292;&#36824;&#32771;&#34385;&#20102;&#26377;&#22122;&#22768;&#35780;&#20272;&#30340;&#29305;&#27530;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22810;&#27969;&#31243;&#38646;&#38454;&#20248;&#21270;&#30340;&#38382;&#39064;&#65292;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#65292;&#21487;&#20197;&#22312;&#19981;&#21516;&#30340;&#36817;&#20284;&#27700;&#24179;&#65288;&#20195;&#20215;&#19981;&#21516;&#65289;&#19978;&#35780;&#20272;&#20989;&#25968;$f$&#65292;&#30446;&#26631;&#26159;&#20197;&#23613;&#21487;&#33021;&#20302;&#30340;&#20195;&#20215;&#20248;&#21270;$f$&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;\emph{&#35748;&#35777;}&#31639;&#27861;&#65292;&#23427;&#20204;&#39069;&#22806;&#35201;&#27714;&#36755;&#20986;&#19968;&#20010;&#23545;&#20248;&#21270;&#35823;&#24046;&#30340;&#25968;&#25454;&#39537;&#21160;&#19978;&#30028;&#12290;&#25105;&#20204;&#39318;&#20808;&#20197;&#31639;&#27861;&#21644;&#35780;&#20272;&#29615;&#22659;&#20043;&#38388;&#30340;&#26497;&#23567;&#26497;&#22823;&#21338;&#24328;&#24418;&#24335;&#26469;&#24418;&#24335;&#21270;&#38382;&#39064;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;MFDOO&#31639;&#27861;&#30340;&#35748;&#35777;&#21464;&#20307;&#65292;&#24182;&#25512;&#23548;&#20986;&#20854;&#22312;&#20219;&#24847;Lipschitz&#20989;&#25968;$f$&#19978;&#30340;&#20195;&#20215;&#22797;&#26434;&#24230;&#19978;&#30028;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#19968;&#20010;&#20381;&#36182;&#20110;$f$&#30340;&#19979;&#30028;&#65292;&#34920;&#26126;&#35813;&#31639;&#27861;&#20855;&#26377;&#36817;&#20284;&#26368;&#20248;&#30340;&#20195;&#20215;&#22797;&#26434;&#24230;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#30452;&#25509;&#31034;&#20363;&#35299;&#20915;&#20102;&#26377;&#22122;&#22768;&#65288;&#38543;&#26426;&#65289;&#35780;&#20272;&#30340;&#29305;&#27530;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of multi-fidelity zeroth-order optimization, where one can evaluate a function $f$ at various approximation levels (of varying costs), and the goal is to optimize $f$ with the cheapest evaluations possible. In this paper, we study \emph{certified} algorithms, which are additionally required to output a data-driven upper bound on the optimization error. We first formalize the problem in terms of a min-max game between an algorithm and an evaluation environment. We then propose a certified variant of the MFDOO algorithm and derive a bound on its cost complexity for any Lipschitz function $f$. We also prove an $f$-dependent lower bound showing that this algorithm has a near-optimal cost complexity. We close the paper by addressing the special case of noisy (stochastic) evaluations as a direct example.
&lt;/p&gt;</description></item><item><title>&#23545;&#25239;&#35757;&#32451;&#26159;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#25239;&#20987;&#23545;&#25239;&#25200;&#21160;&#30340;&#26631;&#20934;&#26041;&#27861;, &#20854;&#23398;&#20064;&#26426;&#21046;&#23548;&#33268;&#24178;&#20928;&#27867;&#21270;&#21644;&#24378;&#20581;&#36807;&#25311;&#21512;&#29616;&#35937;&#21516;&#26102;&#21457;&#29983;&#12290;</title><link>http://arxiv.org/abs/2306.01271</link><description>&lt;p&gt;
&#20026;&#20160;&#20040;&#22312;&#23545;&#25239;&#35757;&#32451;&#20013;&#20250;&#21516;&#26102;&#20986;&#29616;&#24178;&#20928;&#27867;&#21270;&#21644;&#24378;&#20581;&#36807;&#25311;&#21512;&#29616;&#35937;&#65311;
&lt;/p&gt;
&lt;p&gt;
Why Clean Generalization and Robust Overfitting Both Happen in Adversarial Training. (arXiv:2306.01271v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01271
&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#35757;&#32451;&#26159;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#25239;&#20987;&#23545;&#25239;&#25200;&#21160;&#30340;&#26631;&#20934;&#26041;&#27861;, &#20854;&#23398;&#20064;&#26426;&#21046;&#23548;&#33268;&#24178;&#20928;&#27867;&#21270;&#21644;&#24378;&#20581;&#36807;&#25311;&#21512;&#29616;&#35937;&#21516;&#26102;&#21457;&#29983;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#35757;&#32451;&#26159;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#25239;&#20987;&#23545;&#25239;&#25200;&#21160;&#30340;&#26631;&#20934;&#26041;&#27861;&#12290;&#19982;&#22312;&#26631;&#20934;&#28145;&#24230;&#23398;&#20064;&#29615;&#22659;&#20013;&#20986;&#29616;&#24778;&#20154;&#30340;&#24178;&#20928;&#27867;&#21270;&#33021;&#21147;&#31867;&#20284;&#65292;&#36890;&#36807;&#23545;&#25239;&#35757;&#32451;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#20063;&#33021;&#24456;&#22909;&#22320;&#27867;&#21270;&#21040;&#26410;&#35265;&#36807;&#30340;&#24178;&#20928;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#19982;&#24178;&#20928;&#27867;&#21270;&#19981;&#21516;&#30340;&#26159;&#65292;&#23613;&#31649;&#23545;&#25239;&#35757;&#32451;&#33021;&#22815;&#23454;&#29616;&#20302;&#40065;&#26834;&#35757;&#32451;&#35823;&#24046;&#65292;&#20173;&#23384;&#22312;&#26174;&#33879;&#30340;&#40065;&#26834;&#27867;&#21270;&#36317;&#31163;&#65292;&#36825;&#20419;&#20351;&#25105;&#20204;&#25506;&#32034;&#22312;&#23398;&#20064;&#36807;&#31243;&#20013;&#23548;&#33268;&#24178;&#20928;&#27867;&#21270;&#21644;&#24378;&#20581;&#36807;&#25311;&#21512;&#29616;&#35937;&#21516;&#26102;&#21457;&#29983;&#30340;&#26426;&#21046;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#25239;&#35757;&#32451;&#20013;&#36825;&#31181;&#29616;&#35937;&#30340;&#29702;&#35770;&#29702;&#35299;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#25239;&#35757;&#32451;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#20998;&#26512;&#20102;&#29305;&#24449;&#23398;&#20064;&#36807;&#31243;&#65292;&#35299;&#37322;&#20102;&#23545;&#25239;&#35757;&#32451;&#22914;&#20309;&#23548;&#33268;&#32593;&#32476;&#23398;&#20064;&#32773;&#36827;&#20837;&#21040;&#24178;&#20928;&#27867;&#21270;&#21644;&#24378;&#20581;&#36807;&#25311;&#21512;&#29366;&#24577;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#65292;&#36890;&#36807;&#36843;&#20351;&#23398;&#20064;&#22120;&#25104;&#20026;&#24378;&#39044;&#27979;&#32593;&#32476;&#65292;&#23545;&#25239;&#35757;&#32451;&#23558;&#23548;&#33268;&#24178;&#20928;&#27867;&#21270;&#21644;&#40065;&#26834;&#36807;&#25311;&#21512;&#29616;&#35937;&#21516;&#26102;&#21457;&#29983;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adversarial training is a standard method to train deep neural networks to be robust to adversarial perturbation. Similar to surprising $\textit{clean generalization}$ ability in the standard deep learning setting, neural networks trained by adversarial training also generalize well for $\textit{unseen clean data}$. However, in constrast with clean generalization, while adversarial training method is able to achieve low $\textit{robust training error}$, there still exists a significant $\textit{robust generalization gap}$, which promotes us exploring what mechanism leads to both $\textit{clean generalization and robust overfitting (CGRO)}$ during learning process. In this paper, we provide a theoretical understanding of this CGRO phenomenon in adversarial training. First, we propose a theoretical framework of adversarial training, where we analyze $\textit{feature learning process}$ to explain how adversarial training leads network learner to CGRO regime. Specifically, we prove that, u
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24322;&#26500;&#25968;&#25454;&#28304;&#30340;&#32852;&#37030;&#25919;&#31574;&#23398;&#20064;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22522;&#20110;&#26412;&#22320;&#31574;&#30053;&#32858;&#21512;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#21452;&#37325;&#31283;&#20581;&#32447;&#19979;&#31574;&#30053;&#35780;&#20272;&#21644;&#23398;&#20064;&#31574;&#30053;&#36827;&#34892;&#35757;&#32451;&#65292;&#21487;&#20197;&#22312;&#19981;&#20132;&#25442;&#21407;&#22987;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#20010;&#24615;&#21270;&#20915;&#31574;&#25919;&#31574;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#20840;&#23616;&#21644;&#23616;&#37096;&#21518;&#24724;&#19978;&#38480;&#30340;&#29702;&#35770;&#27169;&#22411;&#65292;&#24182;&#29992;&#23454;&#39564;&#32467;&#26524;&#25903;&#25345;&#20102;&#29702;&#35770;&#21457;&#29616;&#12290;</title><link>http://arxiv.org/abs/2305.12407</link><description>&lt;p&gt;
&#24322;&#26500;&#35266;&#27979;&#25968;&#25454;&#19979;&#30340;&#32852;&#37030;&#24369;&#21270;&#25919;&#31574;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Federated Offline Policy Learning with Heterogeneous Observational Data. (arXiv:2305.12407v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12407
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24322;&#26500;&#25968;&#25454;&#28304;&#30340;&#32852;&#37030;&#25919;&#31574;&#23398;&#20064;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22522;&#20110;&#26412;&#22320;&#31574;&#30053;&#32858;&#21512;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#21452;&#37325;&#31283;&#20581;&#32447;&#19979;&#31574;&#30053;&#35780;&#20272;&#21644;&#23398;&#20064;&#31574;&#30053;&#36827;&#34892;&#35757;&#32451;&#65292;&#21487;&#20197;&#22312;&#19981;&#20132;&#25442;&#21407;&#22987;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#20010;&#24615;&#21270;&#20915;&#31574;&#25919;&#31574;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#20840;&#23616;&#21644;&#23616;&#37096;&#21518;&#24724;&#19978;&#38480;&#30340;&#29702;&#35770;&#27169;&#22411;&#65292;&#24182;&#29992;&#23454;&#39564;&#32467;&#26524;&#25903;&#25345;&#20102;&#29702;&#35770;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#22522;&#20110;&#24322;&#26500;&#25968;&#25454;&#28304;&#30340;&#35266;&#27979;&#25968;&#25454;&#23398;&#20064;&#20010;&#24615;&#21270;&#20915;&#31574;&#25919;&#31574;&#30340;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22312;&#32852;&#37030;&#35774;&#32622;&#20013;&#30740;&#31350;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#20854;&#20013;&#20013;&#22830;&#26381;&#21153;&#22120;&#26088;&#22312;&#22312;&#20998;&#24067;&#22312;&#24322;&#26500;&#28304;&#19978;&#30340;&#25968;&#25454;&#19978;&#23398;&#20064;&#19968;&#20010;&#25919;&#31574;&#65292;&#32780;&#19981;&#20132;&#25442;&#23427;&#20204;&#30340;&#21407;&#22987;&#25968;&#25454;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32852;&#37030;&#25919;&#31574;&#23398;&#20064;&#31639;&#27861;&#65292;&#23427;&#22522;&#20110;&#20351;&#29992;&#21452;&#37325;&#31283;&#20581;&#32447;&#19979;&#31574;&#30053;&#35780;&#20272;&#21644;&#23398;&#20064;&#31574;&#30053;&#35757;&#32451;&#30340;&#26412;&#22320;&#31574;&#30053;&#32858;&#21512;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#21518;&#24724;&#20998;&#26512;&#26041;&#27861;&#26469;&#30830;&#31435;&#23545;&#20840;&#23616;&#21518;&#24724;&#27010;&#24565;&#30340;&#26377;&#38480;&#26679;&#26412;&#19978;&#30028;&#65292;&#36825;&#20010;&#20840;&#23616;&#21518;&#24724;&#27010;&#24565;&#36328;&#36234;&#20102;&#23458;&#25143;&#31471;&#30340;&#20998;&#24067;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#38024;&#23545;&#27599;&#20010;&#21333;&#29420;&#30340;&#23458;&#25143;&#31471;&#24314;&#31435;&#20102;&#30456;&#24212;&#30340;&#23616;&#37096;&#21518;&#24724;&#19978;&#30028;&#65292;&#35813;&#19978;&#30028;&#30001;&#30456;&#23545;&#20110;&#25152;&#26377;&#20854;&#20182;&#23458;&#25143;&#31471;&#30340;&#20998;&#24067;&#21464;&#21270;&#29305;&#24449;&#24615;&#22320;&#25551;&#36848;&#12290;&#25105;&#20204;&#29992;&#23454;&#39564;&#32467;&#26524;&#25903;&#25345;&#25105;&#20204;&#30340;&#29702;&#35770;&#21457;&#29616;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#21644;&#23454;&#39564;&#25552;&#20379;&#20102;&#24322;&#26500;&#23458;&#25143;&#31471;&#21442;&#19982;&#32852;&#37030;&#23398;&#20064;&#30340;&#20215;&#20540;&#27934;&#23519;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of learning personalized decision policies on observational data from heterogeneous data sources. Moreover, we examine this problem in the federated setting where a central server aims to learn a policy on the data distributed across the heterogeneous sources without exchanging their raw data. We present a federated policy learning algorithm based on aggregation of local policies trained with doubly robust offline policy evaluation and learning strategies. We provide a novel regret analysis for our approach that establishes a finite-sample upper bound on a notion of global regret across a distribution of clients. In addition, for any individual client, we establish a corresponding local regret upper bound characterized by the presence of distribution shift relative to all other clients. We support our theoretical findings with experimental results. Our analysis and experiments provide insights into the value of heterogeneous client participation in federation fo
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#20915;&#31574;&#26862;&#26519;&#26500;&#24314;&#21487;&#35299;&#37322;&#30340;&#29305;&#24449;&#26680;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#22522;&#20110;&#21494;&#33410;&#28857;&#30456;&#20284;&#24615;&#30340;&#26680;&#24179;&#22343;&#23884;&#20837;&#38543;&#26426;&#26862;&#26519;&#65288;KMERF&#65289;&#65292;&#24182;&#35777;&#26126;&#20854;&#22312;&#31163;&#25955;&#21644;&#36830;&#32493;&#25968;&#25454;&#19978;&#37117;&#34920;&#29616;&#20986;&#28176;&#36827;&#29305;&#24449;&#12290;&#23454;&#39564;&#35777;&#26126;KMERF&#22312;&#22810;&#31181;&#39640;&#32500;&#25968;&#25454;&#27979;&#35797;&#20013;&#20248;&#20110;&#30446;&#21069;&#30340;&#26368;&#20808;&#36827;&#30340;&#22522;&#20110;&#26680;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/1812.00029</link><description>&lt;p&gt;
&#36890;&#36807;&#20915;&#31574;&#26862;&#26519;&#23398;&#20064;&#21487;&#35299;&#37322;&#30340;&#29305;&#24449;&#26680;
&lt;/p&gt;
&lt;p&gt;
Learning Interpretable Characteristic Kernels via Decision Forests. (arXiv:1812.00029v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1812.00029
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#20915;&#31574;&#26862;&#26519;&#26500;&#24314;&#21487;&#35299;&#37322;&#30340;&#29305;&#24449;&#26680;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#22522;&#20110;&#21494;&#33410;&#28857;&#30456;&#20284;&#24615;&#30340;&#26680;&#24179;&#22343;&#23884;&#20837;&#38543;&#26426;&#26862;&#26519;&#65288;KMERF&#65289;&#65292;&#24182;&#35777;&#26126;&#20854;&#22312;&#31163;&#25955;&#21644;&#36830;&#32493;&#25968;&#25454;&#19978;&#37117;&#34920;&#29616;&#20986;&#28176;&#36827;&#29305;&#24449;&#12290;&#23454;&#39564;&#35777;&#26126;KMERF&#22312;&#22810;&#31181;&#39640;&#32500;&#25968;&#25454;&#27979;&#35797;&#20013;&#20248;&#20110;&#30446;&#21069;&#30340;&#26368;&#20808;&#36827;&#30340;&#22522;&#20110;&#26680;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20915;&#31574;&#26862;&#26519;&#34987;&#24191;&#27867;&#29992;&#20110;&#20998;&#31867;&#21644;&#22238;&#24402;&#20219;&#21153;&#12290;&#26641;&#26041;&#27861;&#30340;&#19968;&#20010;&#36739;&#23569;&#34987;&#30693;&#26195;&#30340;&#29305;&#24615;&#26159;&#21487;&#20197;&#20174;&#26641;&#26500;&#24314;&#30456;&#20284;&#24615;&#30697;&#38453;&#65292;&#24182;&#19988;&#36825;&#20123;&#30456;&#20284;&#24615;&#30697;&#38453;&#26159;&#30001;&#26680;&#35825;&#23548;&#30340;&#12290;&#23613;&#31649;&#23545;&#20110;&#26680;&#30340;&#24212;&#29992;&#21644;&#24615;&#36136;&#36827;&#34892;&#20102;&#24191;&#27867;&#30740;&#31350;&#65292;&#20294;&#23545;&#20110;&#30001;&#20915;&#31574;&#26862;&#26519;&#35825;&#23548;&#30340;&#26680;&#30340;&#30740;&#31350;&#30456;&#23545;&#36739;&#23569;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#22522;&#20110;&#21494;&#33410;&#28857;&#30456;&#20284;&#24615;&#30340;&#26680;&#24179;&#22343;&#23884;&#20837;&#38543;&#26426;&#26862;&#26519;&#65288;KMERF&#65289;&#65292;&#23427;&#21487;&#20197;&#20174;&#38543;&#26426;&#26641;&#25110;&#26862;&#26519;&#20013;&#35825;&#23548;&#26680;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#28176;&#36827;&#29305;&#24449;&#26680;&#30340;&#27010;&#24565;&#65292;&#24182;&#35777;&#26126;KMERF&#26680;&#23545;&#20110;&#31163;&#25955;&#21644;&#36830;&#32493;&#25968;&#25454;&#37117;&#26159;&#28176;&#36827;&#29305;&#24449;&#30340;&#12290;&#30001;&#20110;KMERF&#26159;&#25968;&#25454;&#33258;&#36866;&#24212;&#30340;&#65292;&#25105;&#20204;&#24576;&#30097;&#23427;&#23558;&#22312;&#26377;&#38480;&#26679;&#26412;&#25968;&#25454;&#19978;&#32988;&#36807;&#39044;&#20808;&#36873;&#25321;&#30340;&#26680;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;KMERF&#22312;&#21508;&#31181;&#39640;&#32500;&#20004;&#26679;&#26412;&#21644;&#29420;&#31435;&#24615;&#27979;&#35797;&#22330;&#26223;&#20013;&#20960;&#20046;&#21344;&#25454;&#20102;&#30446;&#21069;&#30340;&#26368;&#20808;&#36827;&#30340;&#22522;&#20110;&#26680;&#30340;&#27979;&#35797;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Decision forests are widely used for classification and regression tasks. A lesser known property of tree-based methods is that one can construct a proximity matrix from the tree(s), and these proximity matrices are induced kernels. While there has been extensive research on the applications and properties of kernels, there is relatively little research on kernels induced by decision forests. We construct Kernel Mean Embedding Random Forests (KMERF), which induce kernels from random trees and/or forests using leaf-node proximity. We introduce the notion of an asymptotically characteristic kernel, and prove that KMERF kernels are asymptotically characteristic for both discrete and continuous data. Because KMERF is data-adaptive, we suspected it would outperform kernels selected a priori on finite sample data. We illustrate that KMERF nearly dominates current state-of-the-art kernel-based tests across a diverse range of high-dimensional two-sample and independence testing settings. Furth
&lt;/p&gt;</description></item></channel></rss>