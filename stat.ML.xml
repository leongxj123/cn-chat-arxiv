<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#20174;&#39640;&#32500;&#20960;&#20309;&#30340;&#35282;&#24230;&#65292;&#36890;&#36807;&#22312;&#21407;&#22987;&#25439;&#22833;&#20989;&#25968;&#20013;&#24378;&#21046;&#26045;&#21152;&#31232;&#30095;&#24615;&#32422;&#26463;&#65292;&#25551;&#36848;&#20102;&#28145;&#24230;&#32593;&#32476;&#21098;&#26525;&#27604;&#29575;&#30340;&#30456;&#21464;&#28857;&#65292;&#35813;&#28857;&#31561;&#20110;&#26576;&#20123;&#20984;&#20307;&#30340;&#24179;&#26041;&#39640;&#26031;&#23485;&#24230;&#38500;&#20197;&#21442;&#25968;&#30340;&#21407;&#22987;&#32500;&#24230;&#12290;</title><link>http://arxiv.org/abs/2306.05857</link><description>&lt;p&gt;
&#28145;&#24230;&#32593;&#32476;&#21487;&#20197;&#34987;&#21098;&#26525;&#21040;&#22810;&#20040;&#31232;&#30095;&#65306;&#20960;&#20309;&#35270;&#35282;&#19979;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
How Sparse Can We Prune A Deep Network: A Geometric Viewpoint. (arXiv:2306.05857v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05857
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#39640;&#32500;&#20960;&#20309;&#30340;&#35282;&#24230;&#65292;&#36890;&#36807;&#22312;&#21407;&#22987;&#25439;&#22833;&#20989;&#25968;&#20013;&#24378;&#21046;&#26045;&#21152;&#31232;&#30095;&#24615;&#32422;&#26463;&#65292;&#25551;&#36848;&#20102;&#28145;&#24230;&#32593;&#32476;&#21098;&#26525;&#27604;&#29575;&#30340;&#30456;&#21464;&#28857;&#65292;&#35813;&#28857;&#31561;&#20110;&#26576;&#20123;&#20984;&#20307;&#30340;&#24179;&#26041;&#39640;&#26031;&#23485;&#24230;&#38500;&#20197;&#21442;&#25968;&#30340;&#21407;&#22987;&#32500;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#24230;&#21442;&#25968;&#21270;&#26159;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26368;&#37325;&#35201;&#30340;&#29305;&#24449;&#20043;&#19968;&#12290;&#34429;&#28982;&#23427;&#21487;&#20197;&#25552;&#20379;&#20986;&#33394;&#30340;&#27867;&#21270;&#24615;&#33021;&#65292;&#20294;&#21516;&#26102;&#20063;&#24378;&#21152;&#20102;&#37325;&#22823;&#30340;&#23384;&#20648;&#36127;&#25285;&#65292;&#22240;&#27492;&#26377;&#24517;&#35201;&#30740;&#31350;&#32593;&#32476;&#21098;&#26525;&#12290;&#19968;&#20010;&#33258;&#28982;&#32780;&#22522;&#26412;&#30340;&#38382;&#39064;&#26159;&#65306;&#25105;&#20204;&#33021;&#21098;&#26525;&#19968;&#20010;&#28145;&#24230;&#32593;&#32476;&#21040;&#22810;&#20040;&#31232;&#30095;&#65288;&#20960;&#20046;&#19981;&#24433;&#21709;&#24615;&#33021;&#65289;&#65311;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#37319;&#29992;&#20102;&#31532;&#19968;&#21407;&#29702;&#26041;&#27861;&#65292;&#20855;&#20307;&#22320;&#65292;&#21482;&#36890;&#36807;&#22312;&#21407;&#22987;&#25439;&#22833;&#20989;&#25968;&#20013;&#24378;&#21046;&#26045;&#21152;&#31232;&#30095;&#24615;&#32422;&#26463;&#65292;&#25105;&#20204;&#33021;&#22815;&#20174;&#39640;&#32500;&#20960;&#20309;&#30340;&#35282;&#24230;&#25551;&#36848;&#21098;&#26525;&#27604;&#29575;&#30340;&#23574;&#38160;&#30456;&#21464;&#28857;&#65292;&#35813;&#28857;&#23545;&#24212;&#20110;&#21487;&#34892;&#21644;&#19981;&#21487;&#34892;&#20043;&#38388;&#30340;&#36793;&#30028;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#21098;&#26525;&#27604;&#29575;&#30340;&#30456;&#21464;&#28857;&#31561;&#20110;&#26576;&#20123;&#20984;&#20307;&#30340;&#24179;&#26041;&#39640;&#26031;&#23485;&#24230;&#65292;&#36825;&#20123;&#20984;&#20307;&#26159;&#30001;$l_1$-&#35268;&#21017;&#21270;&#25439;&#22833;&#20989;&#25968;&#24471;&#20986;&#30340;&#65292;&#38500;&#20197;&#21442;&#25968;&#30340;&#21407;&#22987;&#32500;&#24230;&#12290;&#20316;&#20026;&#21103;&#20135;&#21697;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21098;&#26525;&#36807;&#31243;&#20013;&#21442;&#25968;&#30340;&#20998;&#24067;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
Overparameterization constitutes one of the most significant hallmarks of deep neural networks. Though it can offer the advantage of outstanding generalization performance, it meanwhile imposes substantial storage burden, thus necessitating the study of network pruning. A natural and fundamental question is: How sparse can we prune a deep network (with almost no hurt on the performance)? To address this problem, in this work we take a first principles approach, specifically, by merely enforcing the sparsity constraint on the original loss function, we're able to characterize the sharp phase transition point of pruning ratio, which corresponds to the boundary between the feasible and the infeasible, from the perspective of high-dimensional geometry. It turns out that the phase transition point of pruning ratio equals the squared Gaussian width of some convex body resulting from the $l_1$-regularized loss function, normalized by the original dimension of parameters. As a byproduct, we pr
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;Huber&#33021;&#37327;&#37327;&#21270;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#25214;&#21040;&#30446;&#26631;&#27010;&#29575;&#23450;&#24459;&#30340;&#26368;&#20339;&#36924;&#36817;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#21407;&#27979;&#24230;&#19982;&#37327;&#21270;&#29256;&#26412;&#20043;&#38388;&#30340;&#32479;&#35745;&#36317;&#31163;&#26469;&#23454;&#29616;&#12290;&#35813;&#31639;&#27861;&#24050;&#22312;&#22810;&#32500;&#39640;&#26031;&#28151;&#21512;&#29289;&#12289;&#32500;&#32435;&#31354;&#38388;&#39764;&#26041;&#31561;&#20960;&#20010;&#25968;&#25454;&#24211;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#12290;</title><link>http://arxiv.org/abs/2212.08162</link><description>&lt;p&gt;
Huber&#33021;&#37327;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Huber-energy measure quantization. (arXiv:2212.08162v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.08162
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;Huber&#33021;&#37327;&#37327;&#21270;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#25214;&#21040;&#30446;&#26631;&#27010;&#29575;&#23450;&#24459;&#30340;&#26368;&#20339;&#36924;&#36817;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#21407;&#27979;&#24230;&#19982;&#37327;&#21270;&#29256;&#26412;&#20043;&#38388;&#30340;&#32479;&#35745;&#36317;&#31163;&#26469;&#23454;&#29616;&#12290;&#35813;&#31639;&#27861;&#24050;&#22312;&#22810;&#32500;&#39640;&#26031;&#28151;&#21512;&#29289;&#12289;&#32500;&#32435;&#31354;&#38388;&#39764;&#26041;&#31561;&#20960;&#20010;&#25968;&#25454;&#24211;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#31181;&#27979;&#37327;&#37327;&#21270;&#36807;&#31243;&#65292;&#21363;&#19968;&#31181;&#31639;&#27861;&#65292;&#23427;&#36890;&#36807;$Q$&#20010;&#29380;&#25289;&#20811;&#20989;&#25968;&#30340;&#24635;&#21644;&#65288;$Q$&#20026;&#37327;&#21270;&#21442;&#25968;&#65289;&#65292;&#25214;&#21040;&#30446;&#26631;&#27010;&#29575;&#23450;&#24459;&#65288;&#26356;&#19968;&#33324;&#22320;&#65292;&#20026;&#26377;&#38480;&#21464;&#24046;&#27979;&#24230;&#65289;&#30340;&#26368;&#20339;&#36924;&#36817;&#12290;&#35813;&#36807;&#31243;&#36890;&#36807;&#23558;&#21407;&#27979;&#24230;&#19982;&#20854;&#37327;&#21270;&#29256;&#26412;&#20043;&#38388;&#30340;&#32479;&#35745;&#36317;&#31163;&#26368;&#23567;&#21270;&#26469;&#23454;&#29616;&#65307;&#35813;&#36317;&#31163;&#22522;&#20110;&#36127;&#23450;&#26680;&#26500;&#24314;&#65292;&#24182;&#19988;&#22914;&#26524;&#24517;&#35201;&#65292;&#21487;&#20197;&#23454;&#26102;&#35745;&#31639;&#24182;&#36755;&#20837;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#65288;&#22914;SGD&#65292;Adam&#31561;&#65289;&#12290;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#30740;&#31350;&#20102;&#26368;&#20248;&#27979;&#37327;&#37327;&#21270;&#22120;&#30340;&#23384;&#22312;&#30340;&#22522;&#26412;&#38382;&#39064;&#65292;&#24182;&#30830;&#23450;&#20102;&#38656;&#35201;&#20445;&#35777;&#21512;&#36866;&#34892;&#20026;&#30340;&#26680;&#23646;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;&#26368;&#20339;&#32447;&#24615;&#26080;&#20559;&#65288;BLUE&#65289;&#20272;&#35745;&#22120;&#65292;&#29992;&#20110;&#24179;&#26041;&#32479;&#35745;&#36317;&#31163;&#65292;&#24182;&#23558;&#23427;&#20204;&#29992;&#20110;&#26080;&#20559;&#31243;&#24207;HEMQ&#20013;&#65292;&#20197;&#25214;&#21040;&#26368;&#20339;&#37327;&#21270;&#12290;&#25105;&#20204;&#22312;&#22810;&#32500;&#39640;&#26031;&#28151;&#21512;&#29289;&#12289;&#32500;&#32435;&#31354;&#38388;&#39764;&#26041;&#31561;&#20960;&#20010;&#25968;&#25454;&#24211;&#19978;&#27979;&#35797;&#20102;HEMQ
&lt;/p&gt;
&lt;p&gt;
We describe a measure quantization procedure i.e., an algorithm which finds the best approximation of a target probability law (and more generally signed finite variation measure) by a sum of $Q$ Dirac masses ($Q$ being the quantization parameter). The procedure is implemented by minimizing the statistical distance between the original measure and its quantized version; the distance is built from a negative definite kernel and, if necessary, can be computed on the fly and feed to a stochastic optimization algorithm (such as SGD, Adam, ...). We investigate theoretically the fundamental questions of existence of the optimal measure quantizer and identify what are the required kernel properties that guarantee suitable behavior. We propose two best linear unbiased (BLUE) estimators for the squared statistical distance and use them in an unbiased procedure, called HEMQ, to find the optimal quantization. We test HEMQ on several databases: multi-dimensional Gaussian mixtures, Wiener space cub
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36830;&#32493;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;(CGNN)&#30340;&#27169;&#22411;&#65292;&#20351;&#29992;&#26465;&#20214;&#20445;&#35777;CGNN&#26159;&#21333;&#23556;&#30340;&#65292;&#20854;&#29983;&#25104;&#27969;&#24418;&#34987;&#29992;&#20110;&#27714;&#35299;&#21453;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#31283;&#20581;&#24615;&#12290;</title><link>http://arxiv.org/abs/2205.14627</link><description>&lt;p&gt;
&#36830;&#32493;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Continuous Generative Neural Networks. (arXiv:2205.14627v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.14627
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36830;&#32493;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;(CGNN)&#30340;&#27169;&#22411;&#65292;&#20351;&#29992;&#26465;&#20214;&#20445;&#35777;CGNN&#26159;&#21333;&#23556;&#30340;&#65292;&#20854;&#29983;&#25104;&#27969;&#24418;&#34987;&#29992;&#20110;&#27714;&#35299;&#21453;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#31283;&#20581;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#24182;&#30740;&#31350;&#20102;&#19968;&#31181;&#36830;&#32493;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;&#65288;CGNN&#65289;&#65292;&#21363;&#36830;&#32493;&#24773;&#22659;&#19979;&#30340;&#29983;&#25104;&#27169;&#22411;&#65306;CGNN&#30340;&#36755;&#20986;&#23646;&#20110;&#26080;&#38480;&#32500;&#20989;&#25968;&#31354;&#38388;&#12290;&#35813;&#26550;&#26500;&#21463;DCGAN&#30340;&#21551;&#21457;&#65292;&#37319;&#29992;&#19968;&#20010;&#20840;&#36830;&#25509;&#23618;&#65292;&#22810;&#20010;&#21367;&#31215;&#23618;&#21644;&#38750;&#32447;&#24615;&#28608;&#27963;&#20989;&#25968;&#12290;&#22312;&#36830;&#32493;&#30340;$L^2$&#24773;&#22659;&#19979;&#65292;&#27599;&#23618;&#31354;&#38388;&#30340;&#32500;&#24230;&#34987;&#32039;&#25903;&#23567;&#27874;&#30340;&#22810;&#37325;&#20998;&#36776;&#29575;&#20998;&#26512;&#30340;&#23610;&#24230;&#25152;&#20195;&#26367;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20851;&#20110;&#21367;&#31215;&#28388;&#27874;&#22120;&#21644;&#38750;&#32447;&#24615;&#30340;&#26465;&#20214;&#65292;&#20445;&#35777;CGNN&#26159;&#21333;&#23556;&#30340;&#12290;&#35813;&#29702;&#35770;&#24212;&#29992;&#20110;&#21453;&#38382;&#39064;&#65292;&#24182;&#20801;&#35768;&#23548;&#20986;&#19968;&#20010;CGNN&#29983;&#25104;&#27969;&#24418;&#30340;&#65288;&#21487;&#33021;&#38750;&#32447;&#24615;&#30340;&#65289;&#26080;&#38480;&#32500;&#21453;&#38382;&#39064;&#30340;Lipschitz&#31283;&#23450;&#24615;&#20272;&#35745;&#12290;&#21253;&#25324;&#20449;&#21495;&#21435;&#27169;&#31946;&#22312;&#20869;&#30340;&#22810;&#20010;&#25968;&#20540;&#27169;&#25311;&#35777;&#26126;&#24182;&#39564;&#35777;&#20102;&#36825;&#19968;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we present and study Continuous Generative Neural Networks (CGNNs), namely, generative models in the continuous setting: the output of a CGNN belongs to an infinite-dimensional function space. The architecture is inspired by DCGAN, with one fully connected layer, several convolutional layers and nonlinear activation functions. In the continuous $L^2$ setting, the dimensions of the spaces of each layer are replaced by the scales of a multiresolution analysis of a compactly supported wavelet. We present conditions on the convolutional filters and on the nonlinearity that guarantee that a CGNN is injective. This theory finds applications to inverse problems, and allows for deriving Lipschitz stability estimates for (possibly nonlinear) infinite-dimensional inverse problems with unknowns belonging to the manifold generated by a CGNN. Several numerical simulations, including signal deblurring, illustrate and validate this approach.
&lt;/p&gt;</description></item></channel></rss>