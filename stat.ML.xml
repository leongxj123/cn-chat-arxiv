<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#22522;&#20110;&#25130;&#26029;ANOVA&#20998;&#35299;&#30340;&#24555;&#36895;&#21487;&#35299;&#37322;&#25903;&#25345;&#21521;&#37327;&#20998;&#31867;&#27861;&#33021;&#22815;&#36890;&#36807;&#20351;&#29992;&#29305;&#24449;&#26144;&#23556;&#21644;&#23569;&#37327;&#32500;&#24230;&#30340;&#22810;&#21464;&#37327;&#22522;&#20989;&#25968;&#26469;&#24555;&#36895;&#19988;&#20934;&#30830;&#22320;&#36827;&#34892;&#39640;&#32500;&#25955;&#20081;&#25968;&#25454;&#30340;&#20998;&#31867;&#12290;</title><link>https://arxiv.org/abs/2402.02438</link><description>&lt;p&gt;
&#22522;&#20110;&#25130;&#26029;ANOVA&#20998;&#35299;&#30340;&#24555;&#36895;&#21487;&#35299;&#37322;&#25903;&#25345;&#21521;&#37327;&#20998;&#31867;&#27861;
&lt;/p&gt;
&lt;p&gt;
Fast and interpretable Support Vector Classification based on the truncated ANOVA decomposition
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02438
&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#25130;&#26029;ANOVA&#20998;&#35299;&#30340;&#24555;&#36895;&#21487;&#35299;&#37322;&#25903;&#25345;&#21521;&#37327;&#20998;&#31867;&#27861;&#33021;&#22815;&#36890;&#36807;&#20351;&#29992;&#29305;&#24449;&#26144;&#23556;&#21644;&#23569;&#37327;&#32500;&#24230;&#30340;&#22810;&#21464;&#37327;&#22522;&#20989;&#25968;&#26469;&#24555;&#36895;&#19988;&#20934;&#30830;&#22320;&#36827;&#34892;&#39640;&#32500;&#25955;&#20081;&#25968;&#25454;&#30340;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25903;&#25345;&#21521;&#37327;&#26426;&#65288;SVM&#65289;&#26159;&#22312;&#25955;&#20081;&#25968;&#25454;&#19978;&#36827;&#34892;&#20998;&#31867;&#30340;&#37325;&#35201;&#24037;&#20855;&#65292;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#36890;&#24120;&#38656;&#35201;&#22788;&#29702;&#35768;&#22810;&#25968;&#25454;&#28857;&#12290;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#22522;&#20110;&#19977;&#35282;&#20989;&#25968;&#25110;&#23567;&#27874;&#30340;&#29305;&#24449;&#26144;&#23556;&#26469;&#35299;&#20915;SVM&#30340;&#21407;&#22987;&#24418;&#24335;&#12290;&#22312;&#23567;&#32500;&#24230;&#35774;&#32622;&#20013;&#65292;&#24555;&#36895;&#20613;&#37324;&#21494;&#21464;&#25442;&#65288;FFT&#65289;&#21644;&#30456;&#20851;&#26041;&#27861;&#26159;&#22788;&#29702;&#25152;&#32771;&#34385;&#22522;&#20989;&#25968;&#30340;&#24378;&#22823;&#24037;&#20855;&#12290;&#38543;&#30528;&#32500;&#24230;&#30340;&#22686;&#38271;&#65292;&#30001;&#20110;&#32500;&#25968;&#28798;&#38590;&#65292;&#20256;&#32479;&#30340;&#22522;&#20110;FFT&#30340;&#26041;&#27861;&#21464;&#24471;&#20302;&#25928;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#38480;&#21046;&#33258;&#24049;&#20351;&#29992;&#22810;&#21464;&#37327;&#22522;&#20989;&#25968;&#65292;&#27599;&#20010;&#22522;&#20989;&#25968;&#21482;&#20381;&#36182;&#20110;&#23569;&#25968;&#20960;&#20010;&#32500;&#24230;&#12290;&#36825;&#26159;&#30001;&#20110;&#25928;&#24212;&#30340;&#31232;&#30095;&#24615;&#21644;&#26368;&#36817;&#20851;&#20110;&#20989;&#25968;&#20174;&#25955;&#20081;&#25968;&#25454;&#20013;&#30340;&#25130;&#26029;&#26041;&#24046;&#20998;&#35299;&#30340;&#37325;&#24314;&#30340;&#32467;&#26524;&#25152;&#24102;&#26469;&#30340;&#21160;&#26426;&#65292;&#20351;&#24471;&#29983;&#25104;&#30340;&#27169;&#22411;&#22312;&#29305;&#24449;&#30340;&#37325;&#35201;&#24615;&#20197;&#21450;&#23427;&#20204;&#30340;&#32806;&#21512;&#26041;&#38754;&#20855;&#26377;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Support Vector Machines (SVMs) are an important tool for performing classification on scattered data, where one usually has to deal with many data points in high-dimensional spaces. We propose solving SVMs in primal form using feature maps based on trigonometric functions or wavelets. In small dimensional settings the Fast Fourier Transform (FFT) and related methods are a powerful tool in order to deal with the considered basis functions. For growing dimensions the classical FFT-based methods become inefficient due to the curse of dimensionality. Therefore, we restrict ourselves to multivariate basis functions, each one of them depends only on a small number of dimensions. This is motivated by the well-known sparsity of effects and recent results regarding the reconstruction of functions from scattered data in terms of truncated analysis of variance (ANOVA) decomposition, which makes the resulting model even interpretable in terms of importance of the features as well as their coupling
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#25805;&#20316;&#21592;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;&#36138;&#23146;&#31639;&#27861;&#36873;&#25321;&#33258;&#36866;&#24212;&#28857;&#23545;&#39044;&#35757;&#32451;&#30340;&#36817;&#20284;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#65292;&#36880;&#28176;&#20943;&#23569;&#24314;&#27169;&#35823;&#24046;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#22312;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#20043;&#38388;&#21462;&#24471;&#24179;&#34913;&#65292;&#26377;&#21161;&#20110;&#26377;&#25928;&#35299;&#20915;&#36125;&#21494;&#26031;&#36870;&#38382;&#39064;&#20013;&#30340;&#35745;&#31639;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.17844</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#25805;&#20316;&#21592;&#23398;&#20064;&#29992;&#20110;&#26080;&#38480;&#32500;&#36125;&#21494;&#26031;&#36870;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Adaptive operator learning for infinite-dimensional Bayesian inverse problems. (arXiv:2310.17844v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17844
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#25805;&#20316;&#21592;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;&#36138;&#23146;&#31639;&#27861;&#36873;&#25321;&#33258;&#36866;&#24212;&#28857;&#23545;&#39044;&#35757;&#32451;&#30340;&#36817;&#20284;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#65292;&#36880;&#28176;&#20943;&#23569;&#24314;&#27169;&#35823;&#24046;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#22312;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#20043;&#38388;&#21462;&#24471;&#24179;&#34913;&#65292;&#26377;&#21161;&#20110;&#26377;&#25928;&#35299;&#20915;&#36125;&#21494;&#26031;&#36870;&#38382;&#39064;&#20013;&#30340;&#35745;&#31639;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#36870;&#38382;&#39064;(BIPs)&#20013;&#30340;&#22522;&#26412;&#35745;&#31639;&#38382;&#39064;&#28304;&#20110;&#38656;&#35201;&#37325;&#22797;&#36827;&#34892;&#27491;&#21521;&#27169;&#22411;&#35780;&#20272;&#30340;&#35201;&#27714;&#12290;&#20943;&#23569;&#36825;&#31181;&#25104;&#26412;&#30340;&#19968;&#31181;&#24120;&#35265;&#31574;&#30053;&#26159;&#36890;&#36807;&#25805;&#20316;&#21592;&#23398;&#20064;&#20351;&#29992;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#36817;&#20284;&#26041;&#27861;&#26367;&#20195;&#26114;&#36149;&#30340;&#27169;&#22411;&#27169;&#25311;&#65292;&#36825;&#21463;&#21040;&#20102;&#28145;&#24230;&#23398;&#20064;&#30340;&#26368;&#26032;&#36827;&#23637;&#30340;&#21551;&#21457;&#12290;&#28982;&#32780;&#65292;&#30452;&#25509;&#20351;&#29992;&#36817;&#20284;&#27169;&#22411;&#21487;&#33021;&#24341;&#20837;&#24314;&#27169;&#35823;&#24046;&#65292;&#21152;&#21095;&#20102;&#36870;&#38382;&#39064;&#24050;&#32463;&#23384;&#22312;&#30340;&#30149;&#24577;&#24615;&#12290;&#22240;&#27492;&#65292;&#22312;&#26377;&#25928;&#23454;&#26045;&#36825;&#20123;&#26041;&#27861;&#20013;&#65292;&#24179;&#34913;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#33267;&#20851;&#37325;&#35201;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#33258;&#36866;&#24212;&#25805;&#20316;&#21592;&#23398;&#20064;&#26694;&#26550;&#65292;&#21487;&#20197;&#36890;&#36807;&#24378;&#21046;&#22312;&#23616;&#37096;&#21306;&#22495;&#20013;&#20934;&#30830;&#25311;&#21512;&#30340;&#20195;&#29702;&#36880;&#28176;&#20943;&#23569;&#24314;&#27169;&#35823;&#24046;&#12290;&#36825;&#26159;&#36890;&#36807;&#20351;&#29992;&#36138;&#23146;&#31639;&#27861;&#36873;&#25321;&#30340;&#33258;&#36866;&#24212;&#28857;&#22312;&#21453;&#28436;&#36807;&#31243;&#20013;&#23545;&#39044;&#35757;&#32451;&#30340;&#36817;&#20284;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#26469;&#23454;&#29616;&#30340;&#65292;&#35813;&#31639;&#27861;&#21482;&#38656;&#35201;&#23569;&#37327;&#30340;&#27491;&#21521;&#27169;&#22411;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
The fundamental computational issues in Bayesian inverse problems (BIPs) governed by partial differential equations (PDEs) stem from the requirement of repeated forward model evaluations. A popular strategy to reduce such cost is to replace expensive model simulations by computationally efficient approximations using operator learning, motivated by recent progresses in deep learning. However, using the approximated model directly may introduce a modeling error, exacerbating the already ill-posedness of inverse problems. Thus, balancing between accuracy and efficiency is essential for the effective implementation of such approaches. To this end, we develop an adaptive operator learning framework that can reduce modeling error gradually by forcing the surrogate to be accurate in local areas. This is accomplished by fine-tuning the pre-trained approximate model during the inversion process with adaptive points selected by a greedy algorithm, which requires only a few forward model evaluat
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#25968;&#25454;&#39640;&#25928;&#30340;&#22810;&#27169;&#24577;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#25506;&#32034;&#20102;&#29420;&#31435;&#38477;&#32500;&#21644;&#21516;&#26102;&#38477;&#32500;&#20004;&#31181;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#29983;&#25104;&#32447;&#24615;&#27169;&#22411;&#35780;&#20272;&#20102;&#20854;&#30456;&#23545;&#20934;&#30830;&#24615;&#21644;&#25968;&#25454;&#38598;&#22823;&#23567;&#35201;&#27714;&#12290;</title><link>http://arxiv.org/abs/2310.04458</link><description>&lt;p&gt;
&#21516;&#26102;&#38477;&#32500;&#65306;&#19968;&#31181;&#25968;&#25454;&#39640;&#25928;&#30340;&#22810;&#27169;&#24577;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Simultaneous Dimensionality Reduction: A Data Efficient Approach for Multimodal Representations Learning. (arXiv:2310.04458v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04458
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#25968;&#25454;&#39640;&#25928;&#30340;&#22810;&#27169;&#24577;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#25506;&#32034;&#20102;&#29420;&#31435;&#38477;&#32500;&#21644;&#21516;&#26102;&#38477;&#32500;&#20004;&#31181;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#29983;&#25104;&#32447;&#24615;&#27169;&#22411;&#35780;&#20272;&#20102;&#20854;&#30456;&#23545;&#20934;&#30830;&#24615;&#21644;&#25968;&#25454;&#38598;&#22823;&#23567;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#32034;&#20102;&#20004;&#31181;&#20027;&#35201;&#30340;&#38477;&#32500;&#26041;&#27861;&#65306;&#29420;&#31435;&#38477;&#32500;(IDR)&#21644;&#21516;&#26102;&#38477;&#32500;(SDR)&#12290;&#22312;IDR&#26041;&#27861;&#20013;&#65292;&#27599;&#20010;&#27169;&#24577;&#37117;&#34987;&#29420;&#31435;&#21387;&#32553;&#65292;&#21147;&#22270;&#20445;&#30041;&#27599;&#20010;&#27169;&#24577;&#20869;&#30340;&#23613;&#21487;&#33021;&#22810;&#30340;&#21464;&#21270;&#12290;&#30456;&#21453;&#65292;&#22312;SDR&#20013;&#65292;&#21516;&#26102;&#21387;&#32553;&#27169;&#24577;&#20197;&#26368;&#22823;&#21270;&#20943;&#23569;&#25551;&#36848;&#20043;&#38388;&#30340;&#21327;&#21464;&#24615;&#65292;&#21516;&#26102;&#23545;&#20445;&#30041;&#21333;&#20010;&#21464;&#21270;&#30340;&#31243;&#24230;&#19981;&#22826;&#20851;&#27880;&#12290;&#20856;&#22411;&#30340;&#20363;&#23376;&#21253;&#25324;&#20559;&#26368;&#23567;&#20108;&#20056;&#27861;&#21644;&#20856;&#22411;&#30456;&#20851;&#20998;&#26512;&#12290;&#34429;&#28982;&#36825;&#20123;&#38477;&#32500;&#26041;&#27861;&#26159;&#32479;&#35745;&#23398;&#30340;&#20027;&#35201;&#26041;&#27861;&#65292;&#20294;&#23427;&#20204;&#30340;&#30456;&#23545;&#31934;&#24230;&#21644;&#25968;&#25454;&#38598;&#22823;&#23567;&#35201;&#27714;&#23578;&#19981;&#28165;&#26970;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#29983;&#25104;&#32447;&#24615;&#27169;&#22411;&#26469;&#21512;&#25104;&#20855;&#26377;&#24050;&#30693;&#26041;&#24046;&#21644;&#21327;&#26041;&#24046;&#32467;&#26500;&#30340;&#22810;&#27169;&#24577;&#25968;&#25454;&#65292;&#20197;&#30740;&#31350;&#36825;&#20123;&#38382;&#39064;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#21327;&#26041;&#24046;&#30340;&#37325;&#26500;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We explore two primary classes of approaches to dimensionality reduction (DR): Independent Dimensionality Reduction (IDR) and Simultaneous Dimensionality Reduction (SDR). In IDR methods, of which Principal Components Analysis is a paradigmatic example, each modality is compressed independently, striving to retain as much variation within each modality as possible. In contrast, in SDR, one simultaneously compresses the modalities to maximize the covariation between the reduced descriptions while paying less attention to how much individual variation is preserved. Paradigmatic examples include Partial Least Squares and Canonical Correlations Analysis. Even though these DR methods are a staple of statistics, their relative accuracy and data set size requirements are poorly understood. We introduce a generative linear model to synthesize multimodal data with known variance and covariance structures to examine these questions. We assess the accuracy of the reconstruction of the covariance s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#39062;&#30340;&#26080;&#27169;&#22411;&#31639;&#27861;&#65292;&#20026;&#21160;&#24577;&#20915;&#31574;&#38754;&#23545;&#20998;&#24067;&#21464;&#21270;&#38382;&#39064;&#25552;&#20379;&#20102;&#40065;&#26834;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#36890;&#36807;&#23558;Q-learning&#19982;&#26041;&#24046;&#20943;&#23569;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#26377;&#25928;&#25511;&#21046;&#12290;</title><link>http://arxiv.org/abs/2305.18420</link><description>&lt;p&gt;
&#26041;&#24046;&#20943;&#23569;&#30340;&#20998;&#24067;&#24335;&#40065;&#26834;Q-learning&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;
&lt;/p&gt;
&lt;p&gt;
Sample Complexity of Variance-reduced Distributionally Robust Q-learning. (arXiv:2305.18420v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18420
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#39062;&#30340;&#26080;&#27169;&#22411;&#31639;&#27861;&#65292;&#20026;&#21160;&#24577;&#20915;&#31574;&#38754;&#23545;&#20998;&#24067;&#21464;&#21270;&#38382;&#39064;&#25552;&#20379;&#20102;&#40065;&#26834;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#36890;&#36807;&#23558;Q-learning&#19982;&#26041;&#24046;&#20943;&#23569;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#26377;&#25928;&#25511;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24378;&#21270;&#23398;&#20064;&#30340;&#29702;&#35770;&#21644;&#24212;&#29992;&#20013;&#65292;&#38754;&#23545;&#20998;&#24067;&#36716;&#31227;&#30340;&#21160;&#24577;&#20915;&#31574;&#26159;&#22522;&#26412;&#38382;&#39064;&#65292;&#22240;&#20026;&#25968;&#25454;&#25910;&#38598;&#25152;&#22522;&#20110;&#30340;&#29615;&#22659;&#20998;&#24067;&#21487;&#33021;&#20250;&#19981;&#21516;&#20110;&#27169;&#22411;&#37096;&#32626;&#25152;&#22522;&#20110;&#30340;&#20998;&#24067;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#39062;&#30340;&#26080;&#27169;&#22411;&#31639;&#27861;&#65292;&#21363;&#20998;&#24067;&#24335;&#40065;&#26834;Q-learning&#21644;&#23427;&#30340;&#26041;&#24046;&#20943;&#23569;&#23545;&#24212;&#31639;&#27861;&#65292;&#33021;&#22815;&#39640;&#25928;&#22320;&#23398;&#20064;&#40065;&#26834;&#31574;&#30053;&#65292;&#23613;&#31649;&#20250;&#38754;&#23545;&#20998;&#24067;&#21464;&#21270;&#12290;&#36825;&#20123;&#31639;&#27861;&#26088;&#22312;&#23558;&#24102;&#26377;Kullback-Leibler&#19981;&#30830;&#23450;&#24615;&#38598;&#30340;&#26080;&#38480;&#26102;&#22495;$\gamma$-&#25240;&#25187;&#40065;&#26834;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;$q$-&#20989;&#25968;&#20197;&#20803;&#32032;$\epsilon$-&#31934;&#24230;&#26377;&#25928;&#36924;&#36817;&#12290;&#36827;&#19968;&#27493;&#22320;&#65292;&#26041;&#24046;&#20943;&#23569;&#30340;&#20998;&#24067;&#24335;&#40065;&#26834;Q-learning&#23558;&#21516;&#27493;Q-learning&#19982;&#26041;&#24046;&#20943;&#23569;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#20197;&#22686;&#24378;&#20854;&#24615;&#33021;&#65292;&#24182;&#19988;&#25105;&#20204;&#24314;&#31435;&#20102;&#23427;&#36798;&#21040;$ \tilde O(|S||A|(1-\gamma)^{-4}\epsilon^{-4}$&#30340;&#26368;&#23567;&#26368;&#22823;&#26679;&#26412;&#22797;&#26434;&#24230;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dynamic decision making under distributional shifts is of fundamental interest in theory and applications of reinforcement learning: The distribution of the environment on which the data is collected can differ from that of the environment on which the model is deployed. This paper presents two novel model-free algorithms, namely the distributionally robust Q-learning and its variance-reduced counterpart, that can effectively learn a robust policy despite distributional shifts. These algorithms are designed to efficiently approximate the $q$-function of an infinite-horizon $\gamma$-discounted robust Markov decision process with Kullback-Leibler uncertainty set to an entry-wise $\epsilon$-degree of precision. Further, the variance-reduced distributionally robust Q-learning combines the synchronous Q-learning with variance-reduction techniques to enhance its performance. Consequently, we establish that it attains a minmax sample complexity upper bound of $\tilde O(|S||A|(1-\gamma)^{-4}\e
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#24314;&#31435;&#20102;&#19968;&#20010;&#23567;&#22122;&#22768;&#20998;&#26512;&#26694;&#26550;&#65292;&#25581;&#31034;&#20102;&#20256;&#32479;L2&#27491;&#21017;&#21270;&#33539;&#25968;&#30340;&#28508;&#22312;&#19981;&#31283;&#23450;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#20998;&#25968;&#38454;RKHS&#27491;&#21017;&#21270;&#22120;&#31867;&#26469;&#35299;&#20915;&#19981;&#31283;&#23450;&#24615;&#65292;&#36825;&#20123;&#27491;&#21017;&#21270;&#22120;&#22987;&#32456;&#20135;&#29983;&#26368;&#20339;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2305.11055</link><description>&lt;p&gt;
Tikhonov&#21644;RKHS&#27491;&#21017;&#21270;&#30340;&#23567;&#22122;&#22768;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Small noise analysis for Tikhonov and RKHS regularizations. (arXiv:2305.11055v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11055
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#24314;&#31435;&#20102;&#19968;&#20010;&#23567;&#22122;&#22768;&#20998;&#26512;&#26694;&#26550;&#65292;&#25581;&#31034;&#20102;&#20256;&#32479;L2&#27491;&#21017;&#21270;&#33539;&#25968;&#30340;&#28508;&#22312;&#19981;&#31283;&#23450;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#20998;&#25968;&#38454;RKHS&#27491;&#21017;&#21270;&#22120;&#31867;&#26469;&#35299;&#20915;&#19981;&#31283;&#23450;&#24615;&#65292;&#36825;&#20123;&#27491;&#21017;&#21270;&#22120;&#22987;&#32456;&#20135;&#29983;&#26368;&#20339;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27491;&#21017;&#21270;&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#21453;&#38382;&#39064;&#20013;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#21508;&#31181;&#27491;&#21017;&#21270;&#33539;&#25968;&#30340;&#22522;&#26412;&#27604;&#36739;&#20998;&#26512;&#20173;&#28982;&#26410;&#35299;&#20915;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#23567;&#22122;&#22768;&#20998;&#26512;&#26694;&#26550;&#65292;&#20197;&#35780;&#20272;Tikhonov&#21644;RKHS&#27491;&#21017;&#21270;&#33539;&#25968;&#22312;&#39640;&#26031;&#22122;&#22768;&#30340;&#19981;&#36866;&#23450;&#32447;&#24615;&#21453;&#38382;&#39064;&#20013;&#30340;&#25928;&#26524;&#12290;&#35813;&#26694;&#26550;&#30740;&#31350;&#20102;&#27491;&#21017;&#21270;&#20272;&#35745;&#22120;&#22312;&#23567;&#22122;&#22768;&#26497;&#38480;&#19979;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#24182;&#25581;&#31034;&#20102;&#20256;&#32479;L2&#27491;&#21017;&#21270;&#30340;&#28508;&#22312;&#19981;&#31283;&#23450;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#21019;&#26032;&#30340;&#33258;&#36866;&#24212;&#20998;&#25968;&#38454;RKHS&#27491;&#21017;&#21270;&#22120;&#31867;&#26469;&#35299;&#20915;&#36825;&#31181;&#19981;&#31283;&#23450;&#24615;&#65292;&#36890;&#36807;&#35843;&#25972;&#20998;&#25968;&#20809;&#28369;&#24230;&#21442;&#25968;&#65292;&#35813;&#31867;&#35206;&#30422;&#20102;L2 Tikhonov&#21644;RKHS&#27491;&#21017;&#21270;&#22120;&#12290;&#19968;&#20010;&#20196;&#20154;&#24778;&#22855;&#30340;&#35266;&#28857;&#26159;&#65292;&#36890;&#36807;&#36825;&#20123;&#20998;&#25968;&#38454;RKHS&#36827;&#34892;&#36807;&#24230;&#24179;&#28369;&#22987;&#32456;&#20135;&#29983;&#26368;&#20339;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#20294;&#26368;&#20339;&#30340;&#36229;&#21442;&#25968;&#21487;&#33021;&#34928;&#20943;&#24471;&#22826;&#24555;&#32780;&#26080;&#27861;&#22312;&#23454;&#36341;&#20013;&#36827;&#34892;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;
Regularization plays a pivotal role in ill-posed machine learning and inverse problems. However, the fundamental comparative analysis of various regularization norms remains open. We establish a small noise analysis framework to assess the effects of norms in Tikhonov and RKHS regularizations, in the context of ill-posed linear inverse problems with Gaussian noise. This framework studies the convergence rates of regularized estimators in the small noise limit and reveals the potential instability of the conventional L2-regularizer. We solve such instability by proposing an innovative class of adaptive fractional RKHS regularizers, which covers the L2 Tikhonov and RKHS regularizations by adjusting the fractional smoothness parameter. A surprising insight is that over-smoothing via these fractional RKHSs consistently yields optimal convergence rates, but the optimal hyper-parameter may decay too fast to be selected in practice.
&lt;/p&gt;</description></item></channel></rss>