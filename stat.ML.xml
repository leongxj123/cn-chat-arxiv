<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36890;&#36807;&#20004;&#27493;&#24418;&#24335;&#39044;&#27979;&#26041;&#27861;&#65292;&#26412;&#25991;&#23454;&#29616;&#20102;&#33258;&#36866;&#24212;&#36793;&#30028;&#26694;&#19981;&#30830;&#23450;&#24615;&#30340;&#37327;&#21270;&#65292;&#20445;&#35777;&#20102;&#23545;&#35937;&#36793;&#30028;&#26694;&#19981;&#30830;&#23450;&#24615;&#21306;&#38388;&#30340;&#35206;&#30422;&#29575;&#65292;&#21253;&#25324;&#20102;&#38169;&#35823;&#20998;&#31867;&#30340;&#23545;&#35937;&#65292;&#21516;&#26102;&#30830;&#20445;&#36793;&#30028;&#26694;&#21306;&#38388;&#33021;&#22815;&#36866;&#24212;&#29289;&#20307;&#22823;&#23567;&#65292;&#23454;&#29616;&#26356;&#24179;&#34913;&#30340;&#35206;&#30422;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.07263</link><description>&lt;p&gt;
&#36890;&#36807;&#20004;&#27493;&#24418;&#24335;&#39044;&#27979;&#23454;&#29616;&#33258;&#36866;&#24212;&#36793;&#30028;&#26694;&#19981;&#30830;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
Adaptive Bounding Box Uncertainties via Two-Step Conformal Prediction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07263
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20004;&#27493;&#24418;&#24335;&#39044;&#27979;&#26041;&#27861;&#65292;&#26412;&#25991;&#23454;&#29616;&#20102;&#33258;&#36866;&#24212;&#36793;&#30028;&#26694;&#19981;&#30830;&#23450;&#24615;&#30340;&#37327;&#21270;&#65292;&#20445;&#35777;&#20102;&#23545;&#35937;&#36793;&#30028;&#26694;&#19981;&#30830;&#23450;&#24615;&#21306;&#38388;&#30340;&#35206;&#30422;&#29575;&#65292;&#21253;&#25324;&#20102;&#38169;&#35823;&#20998;&#31867;&#30340;&#23545;&#35937;&#65292;&#21516;&#26102;&#30830;&#20445;&#36793;&#30028;&#26694;&#21306;&#38388;&#33021;&#22815;&#36866;&#24212;&#29289;&#20307;&#22823;&#23567;&#65292;&#23454;&#29616;&#26356;&#24179;&#34913;&#30340;&#35206;&#30422;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#21270;&#27169;&#22411;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#23545;&#20110;&#20687;&#33258;&#21160;&#39550;&#39542;&#36825;&#26679;&#30340;&#23433;&#20840;&#20851;&#38190;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#32771;&#34385;&#20026;&#22810;&#29289;&#20307;&#26816;&#27979;&#37327;&#21270;&#36825;&#31181;&#19981;&#30830;&#23450;&#24615;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#21033;&#29992;&#24418;&#24335;&#39044;&#27979;&#26469;&#33719;&#24471;&#20855;&#26377;&#20445;&#35777;&#35206;&#30422;&#29575;&#30340;&#29289;&#20307;&#36793;&#30028;&#26694;&#19981;&#30830;&#23450;&#24615;&#21306;&#38388;&#12290;&#36825;&#26679;&#20570;&#30340;&#19968;&#20010;&#25361;&#25112;&#26159;&#36793;&#30028;&#26694;&#30340;&#39044;&#27979;&#21462;&#20915;&#20110;&#29289;&#20307;&#30340;&#31867;&#21035;&#26631;&#31614;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20004;&#27493;&#24418;&#24335;&#26041;&#27861;&#65292;&#23558;&#23545;&#39044;&#27979;&#31867;&#21035;&#26631;&#31614;&#30340;&#19981;&#30830;&#23450;&#24615;&#20256;&#25773;&#21040;&#36793;&#30028;&#26694;&#30340;&#19981;&#30830;&#23450;&#24615;&#21306;&#38388;&#20013;&#12290;&#36825;&#26679;&#65292;&#25105;&#20204;&#30340;&#24418;&#24335;&#35206;&#30422;&#20445;&#35777;&#30340;&#26377;&#25928;&#24615;&#26356;&#24191;&#27867;&#65292;&#21253;&#25324;&#20102;&#34987;&#38169;&#35823;&#20998;&#31867;&#30340;&#29289;&#20307;&#65292;&#30830;&#20445;&#23427;&#20204;&#22312;&#38656;&#35201;&#26368;&#22823;&#23433;&#20840;&#20445;&#35777;&#26102;&#30340;&#23454;&#29992;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#26032;&#39062;&#30340;&#38598;&#25104;&#21644;&#20998;&#20301;&#25968;&#22238;&#24402;&#24418;&#24335;&#65292;&#20197;&#30830;&#20445;&#36793;&#30028;&#26694;&#21306;&#38388;&#33021;&#22815;&#36866;&#24212;&#29289;&#20307;&#22823;&#23567;&#65292;&#20174;&#32780;&#23454;&#29616;&#26356;&#24179;&#34913;&#30340;&#35206;&#30422;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07263v1 Announce Type: cross  Abstract: Quantifying a model's predictive uncertainty is essential for safety-critical applications such as autonomous driving. We consider quantifying such uncertainty for multi-object detection. In particular, we leverage conformal prediction to obtain uncertainty intervals with guaranteed coverage for object bounding boxes. One challenge in doing so is that bounding box predictions are conditioned on the object's class label. Thus, we develop a novel two-step conformal approach that propagates uncertainty in predicted class labels into the uncertainty intervals for the bounding boxes. This broadens the validity of our conformal coverage guarantees to include incorrectly classified objects, ensuring their usefulness when maximal safety assurances are required. Moreover, we investigate novel ensemble and quantile regression formulations to ensure the bounding box intervals are adaptive to object size, leading to a more balanced coverage across
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#27169;&#22411;&#65292;&#21516;&#26102;&#32771;&#34385;&#20102;&#23454;&#39564;&#20869;&#37096;&#24615;&#33021;&#21644;&#23454;&#39564;&#21518;&#32467;&#26524;&#65292;&#22312;&#20248;&#21270;&#22823;&#35268;&#27169;&#20154;&#32676;&#20013;&#30340;&#34920;&#29616;&#26041;&#38754;&#25552;&#20379;&#20102;&#23574;&#38160;&#29702;&#35770;&#65292;&#25581;&#31034;&#20102;&#26032;&#39062;&#30340;&#35265;&#35299;</title><link>https://arxiv.org/abs/2402.10592</link><description>&lt;p&gt;
&#20248;&#21270;&#33258;&#36866;&#24212;&#23454;&#39564;&#65306;&#26368;&#23567;&#21270;&#21518;&#24724;&#21644;&#26368;&#20339;&#33218;&#35782;&#21035;&#30340;&#32479;&#19968;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Optimizing Adaptive Experiments: A Unified Approach to Regret Minimization and Best-Arm Identification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10592
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#27169;&#22411;&#65292;&#21516;&#26102;&#32771;&#34385;&#20102;&#23454;&#39564;&#20869;&#37096;&#24615;&#33021;&#21644;&#23454;&#39564;&#21518;&#32467;&#26524;&#65292;&#22312;&#20248;&#21270;&#22823;&#35268;&#27169;&#20154;&#32676;&#20013;&#30340;&#34920;&#29616;&#26041;&#38754;&#25552;&#20379;&#20102;&#23574;&#38160;&#29702;&#35770;&#65292;&#25581;&#31034;&#20102;&#26032;&#39062;&#30340;&#35265;&#35299;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36827;&#34892;&#33258;&#36866;&#24212;&#23454;&#39564;&#30340;&#20174;&#19994;&#32773;&#36890;&#24120;&#38754;&#20020;&#20004;&#20010;&#31454;&#20105;&#24615;&#20248;&#20808;&#32423;&#65306;&#36890;&#36807;&#22312;&#23454;&#39564;&#36807;&#31243;&#20013;&#26377;&#25928;&#22320;&#20998;&#37197;&#27835;&#30103;&#26469;&#38477;&#20302;&#23454;&#39564;&#25104;&#26412;&#65292;&#20197;&#21450;&#36805;&#36895;&#25910;&#38598;&#20449;&#24687;&#20197;&#32467;&#26463;&#23454;&#39564;&#24182;&#22312;&#25972;&#20010;&#20154;&#32676;&#20013;&#23454;&#26045;&#27835;&#30103;&#12290;&#24403;&#21069;&#65292;&#25991;&#29486;&#24847;&#35265;&#20998;&#27495;&#65292;&#26377;&#20851;&#26368;&#23567;&#21270;&#21518;&#24724;&#30340;&#30740;&#31350;&#29420;&#31435;&#22320;&#22788;&#29702;&#21069;&#32773;&#30340;&#20248;&#20808;&#32423;&#65292;&#32780;&#26377;&#20851;&#26368;&#20339;&#33218;&#35782;&#21035;&#30340;&#30740;&#31350;&#21017;&#19987;&#27880;&#20110;&#21518;&#32773;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#27169;&#22411;&#65292;&#32771;&#34385;&#21040;&#23454;&#39564;&#20869;&#37096;&#24615;&#33021;&#21644;&#23454;&#39564;&#21518;&#32467;&#26524;&#12290;&#25105;&#20204;&#38543;&#21518;&#25552;&#20379;&#20102;&#19968;&#20010;&#38024;&#23545;&#22823;&#35268;&#27169;&#20154;&#32676;&#30340;&#26368;&#20339;&#24615;&#33021;&#30340;&#23574;&#38160;&#29702;&#35770;&#65292;&#23558;&#25991;&#29486;&#20013;&#30340;&#32463;&#20856;&#32467;&#26524;&#32479;&#19968;&#36215;&#26469;&#12290;&#36825;&#31181;&#32479;&#19968;&#36824;&#25581;&#31034;&#20102;&#26032;&#30340;&#35265;&#35299;&#12290;&#20363;&#22914;&#65292;&#29702;&#35770;&#25581;&#31034;&#20102;&#31867;&#20284;&#26368;&#36817;&#25552;&#20986;&#30340;&#39030;&#37096;&#20004;&#20010;Thompson&#25277;&#26679;&#31639;&#27861;&#31561;&#29087;&#24713;&#31639;&#27861;&#21487;&#34987;&#35843;&#25972;&#20197;&#20248;&#21270;&#24191;&#27867;&#31867;&#21035;&#30340;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10592v1 Announce Type: new  Abstract: Practitioners conducting adaptive experiments often encounter two competing priorities: reducing the cost of experimentation by effectively assigning treatments during the experiment itself, and gathering information swiftly to conclude the experiment and implement a treatment across the population. Currently, the literature is divided, with studies on regret minimization addressing the former priority in isolation, and research on best-arm identification focusing solely on the latter. This paper proposes a unified model that accounts for both within-experiment performance and post-experiment outcomes. We then provide a sharp theory of optimal performance in large populations that unifies canonical results in the literature. This unification also uncovers novel insights. For example, the theory reveals that familiar algorithms, like the recently proposed top-two Thompson sampling algorithm, can be adapted to optimize a broad class of obj
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#20351;&#29992;Nystr\"om&#36817;&#20284;&#26041;&#27861;&#35299;&#20915;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#26680;&#36923;&#36753;&#22238;&#24402;&#30340;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#12290;&#30740;&#31350;&#25552;&#20379;&#20102;&#29702;&#35770;&#20998;&#26512;&#24182;&#39564;&#35777;&#20102;&#19981;&#21516;&#30340;&#22320;&#26631;&#36873;&#25321;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.06763</link><description>&lt;p&gt;
&#20351;&#29992;Nystr\"om&#36817;&#20284;&#30340;&#21487;&#25193;&#23637;&#26680;&#36923;&#36753;&#22238;&#24402;&#65306;&#29702;&#35770;&#20998;&#26512;&#21644;&#31163;&#25955;&#36873;&#25321;&#24314;&#27169;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Scalable Kernel Logistic Regression with Nystr\"om Approximation: Theoretical Analysis and Application to Discrete Choice Modelling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06763
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#20351;&#29992;Nystr\"om&#36817;&#20284;&#26041;&#27861;&#35299;&#20915;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#26680;&#36923;&#36753;&#22238;&#24402;&#30340;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#12290;&#30740;&#31350;&#25552;&#20379;&#20102;&#29702;&#35770;&#20998;&#26512;&#24182;&#39564;&#35777;&#20102;&#19981;&#21516;&#30340;&#22320;&#26631;&#36873;&#25321;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#22522;&#20110;&#26680;&#30340;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#24212;&#29992;&#20110;&#20351;&#29992;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#30340;&#31163;&#25955;&#36873;&#25321;&#24314;&#27169;&#26102;&#65292;&#32463;&#24120;&#38754;&#20020;&#23384;&#20648;&#38656;&#27714;&#21644;&#27169;&#22411;&#20013;&#28041;&#21450;&#30340;&#22823;&#37327;&#21442;&#25968;&#30340;&#25361;&#25112;&#12290;&#36825;&#31181;&#22797;&#26434;&#24615;&#24433;&#21709;&#20102;&#22823;&#35268;&#27169;&#27169;&#22411;&#30340;&#39640;&#25928;&#35757;&#32451;&#12290;&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;Nystr\"om&#36817;&#20284;&#26041;&#27861;&#35299;&#20915;&#20102;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#65292;&#29992;&#20110;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#30340;&#26680;&#36923;&#36753;&#22238;&#24402;&#12290;&#30740;&#31350;&#39318;&#20808;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#20854;&#20013;&#65306;i) &#23545;KLR&#35299;&#30340;&#38598;&#21512;&#36827;&#34892;&#20102;&#25551;&#36848;&#65292;ii) &#32473;&#20986;&#20102;&#20351;&#29992;Nystr\"om&#36817;&#20284;&#30340;KLR&#35299;&#30340;&#19978;&#30028;&#65292;&#24182;&#26368;&#21518;&#25551;&#36848;&#20102;&#19987;&#38376;&#29992;&#20110;Nystr\"om KLR&#30340;&#20248;&#21270;&#31639;&#27861;&#30340;&#29305;&#21270;&#12290;&#20043;&#21518;&#65292;&#23545;Nystr\"om KLR&#36827;&#34892;&#20102;&#35745;&#31639;&#39564;&#35777;&#12290;&#27979;&#35797;&#20102;&#22235;&#31181;&#22320;&#26631;&#36873;&#25321;&#26041;&#27861;&#65292;&#21253;&#25324;&#22522;&#26412;&#22343;&#21248;&#37319;&#26679;&#12289;k-means&#37319;&#26679;&#31574;&#30053;&#21644;&#22522;&#20110;&#26464;&#26438;&#24471;&#20998;&#30340;&#20004;&#31181;&#38750;&#22343;&#21248;&#26041;&#27861;&#12290;&#36825;&#20123;&#31574;&#30053;&#30340;&#24615;&#33021;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
The application of kernel-based Machine Learning (ML) techniques to discrete choice modelling using large datasets often faces challenges due to memory requirements and the considerable number of parameters involved in these models. This complexity hampers the efficient training of large-scale models. This paper addresses these problems of scalability by introducing the Nystr\"om approximation for Kernel Logistic Regression (KLR) on large datasets. The study begins by presenting a theoretical analysis in which: i) the set of KLR solutions is characterised, ii) an upper bound to the solution of KLR with Nystr\"om approximation is provided, and finally iii) a specialisation of the optimisation algorithms to Nystr\"om KLR is described. After this, the Nystr\"om KLR is computationally validated. Four landmark selection methods are tested, including basic uniform sampling, a k-means sampling strategy, and two non-uniform methods grounded in leverage scores. The performance of these strategi
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#24314;&#31435;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#21033;&#29992;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#21644;&#20449;&#24687;&#35770;&#26469;&#20934;&#30830;&#37327;&#21270;&#21644;&#26816;&#27979;&#20449;&#24687;&#27844;&#28431;&#65292;&#36890;&#36807;&#36817;&#20284;&#36125;&#21494;&#26031;&#39044;&#27979;&#30340;&#23545;&#25968;&#25439;&#22833;&#21644;&#20934;&#30830;&#24615;&#26469;&#20934;&#30830;&#20272;&#35745;&#20114;&#20449;&#24687;&#12290;</title><link>http://arxiv.org/abs/2401.14283</link><description>&lt;p&gt;
&#36890;&#36807;&#36817;&#20284;&#36125;&#21494;&#26031;&#26368;&#20248;&#39044;&#27979;&#26816;&#27979;&#20449;&#24687;&#27844;&#28431;
&lt;/p&gt;
&lt;p&gt;
Information Leakage Detection through Approximate Bayes-optimal Prediction. (arXiv:2401.14283v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14283
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#24314;&#31435;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#21033;&#29992;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#21644;&#20449;&#24687;&#35770;&#26469;&#20934;&#30830;&#37327;&#21270;&#21644;&#26816;&#27979;&#20449;&#24687;&#27844;&#28431;&#65292;&#36890;&#36807;&#36817;&#20284;&#36125;&#21494;&#26031;&#39044;&#27979;&#30340;&#23545;&#25968;&#25439;&#22833;&#21644;&#20934;&#30830;&#24615;&#26469;&#20934;&#30830;&#20272;&#35745;&#20114;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20170;&#22825;&#30340;&#20197;&#25968;&#25454;&#39537;&#21160;&#30340;&#19990;&#30028;&#20013;&#65292;&#20844;&#24320;&#21487;&#33719;&#24471;&#30340;&#20449;&#24687;&#30340;&#22686;&#21152;&#21152;&#21095;&#20102;&#20449;&#24687;&#27844;&#28431;&#65288;IL&#65289;&#30340;&#25361;&#25112;&#65292;&#24341;&#21457;&#20102;&#23433;&#20840;&#38382;&#39064;&#12290;IL&#28041;&#21450;&#36890;&#36807;&#31995;&#32479;&#30340;&#21487;&#35266;&#23519;&#20449;&#24687;&#26080;&#24847;&#22320;&#23558;&#31192;&#23494;&#65288;&#25935;&#24863;&#65289;&#20449;&#24687;&#26292;&#38706;&#32473;&#26410;&#32463;&#25480;&#26435;&#30340;&#26041;&#65292;&#20256;&#32479;&#30340;&#32479;&#35745;&#26041;&#27861;&#36890;&#36807;&#20272;&#35745;&#21487;&#35266;&#23519;&#20449;&#24687;&#21644;&#31192;&#23494;&#20449;&#24687;&#20043;&#38388;&#30340;&#20114;&#20449;&#24687;&#65288;MI&#65289;&#26469;&#26816;&#27979;IL&#65292;&#38754;&#20020;&#32500;&#24230;&#28798;&#38590;&#12289;&#25910;&#25947;&#12289;&#35745;&#31639;&#22797;&#26434;&#24230;&#21644;MI&#20272;&#35745;&#38169;&#35823;&#31561;&#25361;&#25112;&#12290;&#27492;&#22806;&#65292;&#34429;&#28982;&#26032;&#20852;&#30340;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#26041;&#27861;&#22312;&#20108;&#36827;&#21046;&#31995;&#32479;&#25935;&#24863;&#20449;&#24687;&#30340;&#26816;&#27979;&#19978;&#26377;&#25928;&#65292;&#20294;&#32570;&#20047;&#19968;&#20010;&#20840;&#38754;&#30340;&#29702;&#35770;&#26694;&#26550;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#20351;&#29992;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#21644;&#20449;&#24687;&#35770;&#24314;&#31435;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#26469;&#20934;&#30830;&#37327;&#21270;&#21644;&#26816;&#27979;IL&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#21487;&#20197;&#36890;&#36807;&#36817;&#20284;&#36125;&#21494;&#26031;&#39044;&#27979;&#30340;&#23545;&#25968;&#25439;&#22833;&#21644;&#20934;&#30830;&#24615;&#26469;&#20934;&#30830;&#20272;&#35745;MI&#12290;
&lt;/p&gt;
&lt;p&gt;
In today's data-driven world, the proliferation of publicly available information intensifies the challenge of information leakage (IL), raising security concerns. IL involves unintentionally exposing secret (sensitive) information to unauthorized parties via systems' observable information. Conventional statistical approaches, which estimate mutual information (MI) between observable and secret information for detecting IL, face challenges such as the curse of dimensionality, convergence, computational complexity, and MI misestimation. Furthermore, emerging supervised machine learning (ML) methods, though effective, are limited to binary system-sensitive information and lack a comprehensive theoretical framework. To address these limitations, we establish a theoretical framework using statistical learning theory and information theory to accurately quantify and detect IL. We demonstrate that MI can be accurately estimated by approximating the log-loss and accuracy of the Bayes predict
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#27491;&#21487;&#20998;&#35299;&#26680;&#30340;&#20960;&#20309;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#22312;RKKS&#20013;&#23398;&#20064;&#32780;&#19981;&#38656;&#35201;&#35775;&#38382;&#26680;&#30340;&#20998;&#35299;&#65292;&#20026;&#38750;&#27431;&#20960;&#37324;&#24503;&#25968;&#25454;&#30340;&#26680;&#23398;&#20064;&#25552;&#20379;&#20102;&#19968;&#26465;&#36335;&#24452;&#65292;&#24182;&#20026;RKKS&#26041;&#27861;&#25552;&#20379;&#20102;&#29702;&#35770;&#22522;&#30784;&#12290;</title><link>http://arxiv.org/abs/2310.13821</link><description>&lt;p&gt;
&#20351;&#29992;&#27491;&#21487;&#20998;&#35299;&#26680;&#30340;&#20960;&#20309;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Geometric Learning with Positively Decomposable Kernels. (arXiv:2310.13821v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13821
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#27491;&#21487;&#20998;&#35299;&#26680;&#30340;&#20960;&#20309;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#22312;RKKS&#20013;&#23398;&#20064;&#32780;&#19981;&#38656;&#35201;&#35775;&#38382;&#26680;&#30340;&#20998;&#35299;&#65292;&#20026;&#38750;&#27431;&#20960;&#37324;&#24503;&#25968;&#25454;&#30340;&#26680;&#23398;&#20064;&#25552;&#20379;&#20102;&#19968;&#26465;&#36335;&#24452;&#65292;&#24182;&#20026;RKKS&#26041;&#27861;&#25552;&#20379;&#20102;&#29702;&#35770;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26680;&#26041;&#27861;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#24378;&#22823;&#30340;&#24037;&#20855;&#12290;&#32463;&#20856;&#30340;&#26680;&#26041;&#27861;&#22522;&#20110;&#27491;&#23450;&#26680;&#65292;&#23558;&#25968;&#25454;&#31354;&#38388;&#26144;&#23556;&#21040;&#37325;&#29616;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;(RKHS)&#12290;&#23545;&#20110;&#38750;&#27431;&#20960;&#37324;&#24503;&#25968;&#25454;&#31354;&#38388;&#65292;&#24456;&#38590;&#25214;&#21040;&#27491;&#23450;&#26680;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#22522;&#20110;&#37325;&#29616;&#26680;&#25511;&#21046;&#31354;&#38388;(RKKS)&#30340;&#26041;&#27861;&#65292;&#36825;&#20123;&#26041;&#27861;&#21482;&#38656;&#35201;&#20855;&#26377;&#27491;&#20998;&#35299;&#30340;&#26680;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;RKKS&#20013;&#23398;&#20064;&#26102;&#65292;&#24182;&#19981;&#38656;&#35201;&#35775;&#38382;&#36825;&#20010;&#20998;&#35299;&#12290;&#28982;&#21518;&#25105;&#20204;&#30740;&#31350;&#20102;&#20351;&#26680;&#27491;&#21487;&#20998;&#35299;&#30340;&#26465;&#20214;&#12290;&#25105;&#20204;&#35777;&#26126;&#22312;&#21487;&#22788;&#29702;&#30340;&#27491;&#21017;&#24615;&#20551;&#35774;&#19979;&#65292;&#19981;&#21464;&#26680;&#22312;&#40784;&#27425;&#31354;&#38388;&#19978;&#20801;&#35768;&#27491;&#20998;&#35299;&#12290;&#36825;&#20351;&#24471;&#23427;&#20204;&#27604;&#27491;&#23450;&#26680;&#26356;&#23481;&#26131;&#26500;&#36896;&#65292;&#20026;&#38750;&#27431;&#20960;&#37324;&#24503;&#25968;&#25454;&#30340;&#26680;&#23398;&#20064;&#25552;&#20379;&#20102;&#19968;&#26465;&#36335;&#24452;&#12290;&#21516;&#26679;&#65292;&#36825;&#20026;RKKS&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#33324;&#30340;&#29702;&#35770;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
Kernel methods are powerful tools in machine learning. Classical kernel methods are based on positive-definite kernels, which map data spaces into reproducing kernel Hilbert spaces (RKHS). For non-Euclidean data spaces, positive-definite kernels are difficult to come by. In this case, we propose the use of reproducing kernel Krein space (RKKS) based methods, which require only kernels that admit a positive decomposition. We show that one does not need to access this decomposition in order to learn in RKKS. We then investigate the conditions under which a kernel is positively decomposable. We show that invariant kernels admit a positive decomposition on homogeneous spaces under tractable regularity assumptions. This makes them much easier to construct than positive-definite kernels, providing a route for learning with kernels for non-Euclidean data. By the same token, this provides theoretical foundations for RKKS-based methods in general.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31616;&#21333;&#12289;&#36890;&#29992;&#21644;&#39640;&#25928;&#30340;&#21322;&#21442;&#25968;&#36125;&#21494;&#26031;&#22238;&#24402;&#30340;&#33945;&#29305;&#21345;&#27931;&#25512;&#26029;&#31574;&#30053;&#65292;&#21487;&#29992;&#20110;&#32852;&#21512;&#21518;&#39564;&#19968;&#33268;&#24615;&#65292;&#21363;&#20351;&#32463;&#20856;&#30340;&#20284;&#28982;&#20989;&#25968;&#26159;&#38590;&#20197;&#22788;&#29702;&#25110;&#26410;&#30693;&#30340;&#12290;</title><link>http://arxiv.org/abs/2306.05498</link><description>&lt;p&gt;
&#21322;&#21442;&#25968;&#36125;&#21494;&#26031;&#22238;&#24402;&#30340;&#33945;&#29305;&#21345;&#27931;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Monte Carlo inference for semiparametric Bayesian regression. (arXiv:2306.05498v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05498
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31616;&#21333;&#12289;&#36890;&#29992;&#21644;&#39640;&#25928;&#30340;&#21322;&#21442;&#25968;&#36125;&#21494;&#26031;&#22238;&#24402;&#30340;&#33945;&#29305;&#21345;&#27931;&#25512;&#26029;&#31574;&#30053;&#65292;&#21487;&#29992;&#20110;&#32852;&#21512;&#21518;&#39564;&#19968;&#33268;&#24615;&#65292;&#21363;&#20351;&#32463;&#20856;&#30340;&#20284;&#28982;&#20989;&#25968;&#26159;&#38590;&#20197;&#22788;&#29702;&#25110;&#26410;&#30693;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#36716;&#25442;&#23545;&#20110;&#21442;&#25968;&#22238;&#24402;&#27169;&#22411;&#30340;&#24191;&#27867;&#36866;&#29992;&#24615;&#33267;&#20851;&#37325;&#35201;&#65292;&#20294;&#23545;&#20110;&#36125;&#21494;&#26031;&#20998;&#26512;&#65292;&#32852;&#21512;&#25512;&#26029;&#36716;&#25442;&#21644;&#27169;&#22411;&#21442;&#25968;&#36890;&#24120;&#38656;&#35201;&#38480;&#21046;&#24615;&#21442;&#25968;&#36716;&#25442;&#25110;&#38750;&#21442;&#25968;&#34920;&#31034;&#65292;&#36825;&#23545;&#23454;&#29616;&#21644;&#29702;&#35770;&#20998;&#26512;&#26469;&#35828;&#35745;&#31639;&#25928;&#29575;&#20302;&#19979;&#19988;&#32321;&#29712;&#65292;&#38480;&#21046;&#20102;&#20182;&#20204;&#22312;&#23454;&#36341;&#20013;&#30340;&#21487;&#29992;&#24615;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31616;&#21333;&#12289;&#36890;&#29992;&#21644;&#39640;&#25928;&#30340;&#31574;&#30053;&#65292;&#30452;&#25509;&#36890;&#36807;&#23558;&#36716;&#25442;&#19982;&#29420;&#31435;&#21464;&#37327;&#21644;&#22240;&#21464;&#37327;&#30340;&#36793;&#32536;&#20998;&#24067;&#30456;&#36830;&#30340;&#26041;&#24335;&#26469;&#23450;&#20301;&#26410;&#30693;&#36716;&#25442;&#21644;&#25152;&#26377;&#22238;&#24402;&#27169;&#22411;&#21442;&#25968;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#24182;&#36890;&#36807;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#27169;&#22411;&#20351;&#29992;&#36125;&#21494;&#26031;&#33258;&#20030;&#26041;&#27861;&#12290;&#20851;&#38190;&#26159;&#65292;&#36825;&#31181;&#26041;&#27861;&#22312;&#24191;&#27867;&#30340;&#22238;&#24402;&#27169;&#22411;&#20013;&#37117;&#21487;&#20197;&#23454;&#29616;(1)&#32852;&#21512;&#21518;&#39564;&#19968;&#33268;&#24615;&#65292;&#21253;&#25324;&#22810;&#20010;&#27169;&#22411;&#38169;&#37197;&#24773;&#20917;&#65292;&#21644;(2)&#39640;&#25928;&#30340;&#33945;&#29305;&#21345;&#32599;&#31639;&#27861;&#65292;&#21363;&#20351;&#32463;&#20856;&#30340;&#20284;&#28982;&#20989;&#25968;&#26159;&#38590;&#20197;&#22788;&#29702;&#25110;&#26410;&#30693;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data transformations are essential for broad applicability of parametric regression models. However, for Bayesian analysis, joint inference of the transformation and model parameters typically involves restrictive parametric transformations or nonparametric representations that are computationally inefficient and cumbersome for implementation and theoretical analysis, which limits their usability in practice. This paper introduces a simple, general, and efficient strategy for joint posterior inference of an unknown transformation and all regression model parameters. The proposed approach directly targets the posterior distribution of the transformation by linking it with the marginal distributions of the independent and dependent variables, and then deploys a Bayesian nonparametric model via the Bayesian bootstrap. Crucially, this approach delivers (1) joint posterior consistency under general conditions, including multiple model misspecifications, and (2) efficient Monte Carlo (not Ma
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24207;&#21015; Knockoffs (SEEK)&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#24378;&#21270;&#23398;&#20064;&#31995;&#32479;&#20013;&#23454;&#29616;&#21464;&#37327;&#36873;&#25321;&#65292;&#35813;&#31639;&#27861;&#20272;&#35745;&#20102;&#26368;&#23567;&#20805;&#20998;&#29366;&#24577;&#65292;&#30830;&#20445;&#23398;&#20064;&#36827;&#31243;&#33391;&#22909;&#32780;&#19981;&#20250;&#20943;&#32531;&#12290;</title><link>http://arxiv.org/abs/2303.14281</link><description>&lt;p&gt;
&#22522;&#20110;&#24207;&#21015; Knockoffs &#30340;&#24378;&#21270;&#23398;&#20064;&#21464;&#37327;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Sequential Knockoffs for Variable Selection in Reinforcement Learning. (arXiv:2303.14281v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14281
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24207;&#21015; Knockoffs (SEEK)&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#24378;&#21270;&#23398;&#20064;&#31995;&#32479;&#20013;&#23454;&#29616;&#21464;&#37327;&#36873;&#25321;&#65292;&#35813;&#31639;&#27861;&#20272;&#35745;&#20102;&#26368;&#23567;&#20805;&#20998;&#29366;&#24577;&#65292;&#30830;&#20445;&#23398;&#20064;&#36827;&#31243;&#33391;&#22909;&#32780;&#19981;&#20250;&#20943;&#32531;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24378;&#21270;&#23398;&#20064;&#30340;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#36890;&#24120;&#24456;&#38590;&#33719;&#24471;&#19968;&#20010;&#26082;&#31616;&#27905;&#21448;&#28385;&#36275;&#39532;&#23572;&#21487;&#22827;&#23646;&#24615;&#30340;&#29366;&#24577;&#34920;&#31034;&#65292;&#32780;&#19981;&#38656;&#35201;&#20351;&#29992;&#20808;&#39564;&#30693;&#35782;&#12290;&#22240;&#27492;&#65292;&#24120;&#35268;&#20570;&#27861;&#26159;&#26500;&#36896;&#19968;&#20010;&#27604;&#24517;&#35201;&#30340;&#35201;&#22823;&#30340;&#29366;&#24577;&#65292;&#20363;&#22914;&#23558;&#36830;&#32493;&#26102;&#38388;&#28857;&#19978;&#30340;&#27979;&#37327;&#20018;&#32852;&#36215;&#26469;&#12290;&#28982;&#32780;&#65292;&#22686;&#21152;&#29366;&#24577;&#30340;&#32500;&#25968;&#21487;&#33021;&#20250;&#20943;&#32531;&#23398;&#20064;&#36827;&#31243;&#24182;&#20351;&#23398;&#20064;&#31574;&#30053;&#27169;&#31946;&#19981;&#28165;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#22312;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;(MDP)&#20013;&#30340;&#26368;&#23567;&#20805;&#20998;&#29366;&#24577;&#30340;&#27010;&#24565;&#65292;&#20316;&#20026;&#21407;&#22987;&#29366;&#24577;&#19979;&#26368;&#23567;&#30340;&#23376;&#21521;&#37327;&#65292;&#20351;&#35813;&#36807;&#31243;&#20173;&#28982;&#26159;MDP&#65292;&#24182;&#19988;&#19982;&#21407;&#22987;&#36807;&#31243;&#20849;&#20139;&#30456;&#21516;&#30340;&#26368;&#20248;&#31574;&#30053;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24207;&#21015; Knockoffs (SEEK)&#31639;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#39640;&#32500;&#22797;&#26434;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#31995;&#32479;&#20013;&#30340;&#26368;&#23567;&#20805;&#20998;&#29366;&#24577;&#12290;&#22312;&#22823;&#26679;&#26412;&#20013;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#25511;&#21046;&#20102;&#20551;&#21457;&#29616;&#29575;&#65292;&#24182;&#19988;&#36873;&#25321;&#25152;&#26377;&#20805;&#20998;&#30340;&#21464;&#37327;&#30340;&#27010;&#29575;&#36235;&#36817;&#20110;1&#12290;
&lt;/p&gt;
&lt;p&gt;
In real-world applications of reinforcement learning, it is often challenging to obtain a state representation that is parsimonious and satisfies the Markov property without prior knowledge. Consequently, it is common practice to construct a state which is larger than necessary, e.g., by concatenating measurements over contiguous time points. However, needlessly increasing the dimension of the state can slow learning and obfuscate the learned policy. We introduce the notion of a minimal sufficient state in a Markov decision process (MDP) as the smallest subvector of the original state under which the process remains an MDP and shares the same optimal policy as the original process. We propose a novel sequential knockoffs (SEEK) algorithm that estimates the minimal sufficient state in a system with high-dimensional complex nonlinear dynamics. In large samples, the proposed method controls the false discovery rate, and selects all sufficient variables with probability approaching one. As
&lt;/p&gt;</description></item></channel></rss>