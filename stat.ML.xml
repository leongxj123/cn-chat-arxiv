<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#26102;&#31354;&#28151;&#21512;&#31574;&#30053;&#29983;&#25104;&#29420;&#31435;&#21516;&#20998;&#24067;&#21512;&#25104;&#26679;&#26412;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#38543;&#26426;&#36807;&#31243;&#23454;&#29616;&#26368;&#20339;&#36716;&#36816;&#65292;&#36827;&#19968;&#27493;&#32454;&#21270;&#36890;&#36807;&#20998;&#25968;&#21305;&#37197;&#25216;&#26415;&#35757;&#32451;&#26041;&#27861;</title><link>https://arxiv.org/abs/2402.08847</link><description>&lt;p&gt;
&#26102;&#31354;&#26725;&#25193;&#25955;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Space-Time Bridge-Diffusion
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08847
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#26102;&#31354;&#28151;&#21512;&#31574;&#30053;&#29983;&#25104;&#29420;&#31435;&#21516;&#20998;&#24067;&#21512;&#25104;&#26679;&#26412;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#38543;&#26426;&#36807;&#31243;&#23454;&#29616;&#26368;&#20339;&#36716;&#36816;&#65292;&#36827;&#19968;&#27493;&#32454;&#21270;&#36890;&#36807;&#20998;&#25968;&#21305;&#37197;&#25216;&#26415;&#35757;&#32451;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#30001;&#19968;&#32452;&#22320;&#38754;&#30495;&#23454;&#26679;&#26412;&#65288;GT&#26679;&#26412;&#65289;&#38544;&#24335;&#23450;&#20041;&#30340;&#39640;&#32500;&#23454;&#20540;&#27010;&#29575;&#20998;&#24067;&#20013;&#29983;&#25104;&#29420;&#31435;&#21516;&#20998;&#24067;&#65288;i.i.d.&#65289;&#30340;&#26032;&#21512;&#25104;&#26679;&#26412;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26680;&#24515;&#26159;&#36890;&#36807;&#26102;&#31354;&#28151;&#21512;&#31574;&#30053;&#22312;&#26102;&#38388;&#21644;&#31354;&#38388;&#32500;&#24230;&#19978;&#36827;&#34892;&#25193;&#23637;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#19977;&#20010;&#30456;&#20114;&#20851;&#32852;&#30340;&#38543;&#26426;&#36807;&#31243;&#65292;&#26088;&#22312;&#23454;&#29616;&#20174;&#23481;&#26131;&#22788;&#29702;&#30340;&#21021;&#22987;&#27010;&#29575;&#20998;&#24067;&#21040;&#30001;GT&#26679;&#26412;&#34920;&#31034;&#30340;&#30446;&#26631;&#20998;&#24067;&#30340;&#26368;&#20339;&#36716;&#36816;&#65306;&#65288;a&#65289;&#21253;&#21547;&#26102;&#31354;&#28151;&#21512;&#30340;&#32447;&#24615;&#36807;&#31243;&#20135;&#29983;&#39640;&#26031;&#26465;&#20214;&#27010;&#29575;&#23494;&#24230;&#65292;&#65288;b&#65289;&#20854;&#26725;&#25193;&#25955;&#27169;&#25311;&#65292;&#26465;&#20214;&#20026;&#21021;&#22987;&#21644;&#26368;&#32456;&#29366;&#24577;&#21521;&#37327;&#65292;&#20197;&#21450;&#65288;c&#65289;&#36890;&#36807;&#20998;&#25968;&#21305;&#37197;&#25216;&#26415;&#36827;&#34892;&#32454;&#21270;&#30340;&#38750;&#32447;&#24615;&#38543;&#26426;&#36807;&#31243;&#12290;&#25105;&#20204;&#35757;&#32451;&#26041;&#27861;&#30340;&#20851;&#38190;&#22312;&#20110;&#31934;&#35843;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08847v1 Announce Type: cross Abstract: In this study, we introduce a novel method for generating new synthetic samples that are independent and identically distributed (i.i.d.) from high-dimensional real-valued probability distributions, as defined implicitly by a set of Ground Truth (GT) samples. Central to our method is the integration of space-time mixing strategies that extend across temporal and spatial dimensions. Our methodology is underpinned by three interrelated stochastic processes designed to enable optimal transport from an easily tractable initial probability distribution to the target distribution represented by the GT samples: (a) linear processes incorporating space-time mixing that yield Gaussian conditional probability densities, (b) their bridge-diffusion analogs that are conditioned to the initial and final state vectors, and (c) nonlinear stochastic processes refined through score-matching techniques. The crux of our training regime involves fine-tuning
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;PAC-Bayesian&#26694;&#26550;&#30340;&#26041;&#27861;&#65292;&#26469;&#30740;&#31350;&#23545;&#25239;&#40065;&#26834;&#24615;&#27867;&#21270;&#30028;&#38480;&#38382;&#39064;&#65292;&#38024;&#23545;&#20004;&#31181;&#27969;&#34892;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#32467;&#26524;&#21457;&#29616;&#22270;&#19978;&#25193;&#25955;&#30697;&#38453;&#30340;&#35889;&#33539;&#25968;&#12289;&#26435;&#37325;&#30340;&#35889;&#33539;&#25968;&#21644;&#25200;&#21160;&#22240;&#23376;&#23545;&#27169;&#22411;&#30340;&#40065;&#26834;&#27867;&#21270;&#30028;&#38480;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2402.04038</link><description>&lt;p&gt;
PAC-Bayesian Adversarially Robust Generalization Bounds for Graph Neural Network
&lt;/p&gt;
&lt;p&gt;
PAC-Bayesian Adversarially Robust Generalization Bounds for Graph Neural Network
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04038
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;PAC-Bayesian&#26694;&#26550;&#30340;&#26041;&#27861;&#65292;&#26469;&#30740;&#31350;&#23545;&#25239;&#40065;&#26834;&#24615;&#27867;&#21270;&#30028;&#38480;&#38382;&#39064;&#65292;&#38024;&#23545;&#20004;&#31181;&#27969;&#34892;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#32467;&#26524;&#21457;&#29616;&#22270;&#19978;&#25193;&#25955;&#30697;&#38453;&#30340;&#35889;&#33539;&#25968;&#12289;&#26435;&#37325;&#30340;&#35889;&#33539;&#25968;&#21644;&#25200;&#21160;&#22240;&#23376;&#23545;&#27169;&#22411;&#30340;&#40065;&#26834;&#27867;&#21270;&#30028;&#38480;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#22312;&#21508;&#31181;&#19982;&#22270;&#30456;&#20851;&#30340;&#20219;&#21153;&#20013;&#24191;&#21463;&#27426;&#36814;&#12290;&#28982;&#32780;&#65292;&#31867;&#20284;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;GNNs&#20063;&#23481;&#26131;&#21463;&#21040;&#23545;&#25239;&#25915;&#20987;&#12290;&#32463;&#39564;&#30740;&#31350;&#34920;&#26126;&#65292;&#23545;&#25239;&#40065;&#26834;&#24615;&#27867;&#21270;&#22312;&#24314;&#31435;&#26377;&#25928;&#30340;&#25269;&#24481;&#23545;&#25239;&#25915;&#20987;&#30340;&#38450;&#24481;&#31639;&#27861;&#26041;&#38754;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;PAC-Bayesian&#26694;&#26550;&#65292;&#20026;&#20004;&#31181;&#27969;&#34892;&#30340;GNNs&#65292;&#21363;&#22270;&#21367;&#31215;&#32593;&#32476;&#65288;GCN&#65289;&#21644;&#28040;&#24687;&#20256;&#36882;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#25552;&#20379;&#20102;&#23545;&#25239;&#40065;&#26834;&#27867;&#21270;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25581;&#31034;&#20102;&#22270;&#19978;&#25193;&#25955;&#30697;&#38453;&#30340;&#35889;&#33539;&#25968;&#12289;&#26435;&#37325;&#30340;&#35889;&#33539;&#25968;&#20197;&#21450;&#25200;&#21160;&#22240;&#23376;&#23545;&#20004;&#20010;&#27169;&#22411;&#30340;&#40065;&#26834;&#27867;&#21270;&#30028;&#38480;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#30028;&#38480;&#26159;&#65288;Liao&#31561;&#20154;&#65292;2020&#65289;&#20013;&#32467;&#26524;&#30340;&#38750;&#24179;&#20961;&#25512;&#24191;&#65292;&#20174;&#26631;&#20934;&#35774;&#32622;&#25193;&#23637;&#21040;&#23545;&#25239;&#35774;&#32622;&#65292;&#21516;&#26102;&#36991;&#20813;&#20102;&#26368;&#22823;&#33410;&#28857;&#24230;&#30340;&#25351;&#25968;&#20381;&#36182;&#12290;&#20316;&#20026;&#25512;&#35770;&#65292;&#25105;&#20204;&#24471;&#20986;&#26356;&#22909;&#30340;&#30028;&#38480;...
&lt;/p&gt;
&lt;p&gt;
Graph neural networks (GNNs) have gained popularity for various graph-related tasks. However, similar to deep neural networks, GNNs are also vulnerable to adversarial attacks. Empirical studies have shown that adversarially robust generalization has a pivotal role in establishing effective defense algorithms against adversarial attacks. In this paper, we contribute by providing adversarially robust generalization bounds for two kinds of popular GNNs, graph convolutional network (GCN) and message passing graph neural network, using the PAC-Bayesian framework. Our result reveals that spectral norm of the diffusion matrix on the graph and spectral norm of the weights as well as the perturbation factor govern the robust generalization bounds of both models. Our bounds are nontrivial generalizations of the results developed in (Liao et al., 2020) from the standard setting to adversarial setting while avoiding exponential dependence of the maximum node degree. As corollaries, we derive bette
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Variance-Reduced Sketching&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#39640;&#32500;&#24230;&#20013;&#20272;&#35745;&#23494;&#24230;&#20989;&#25968;&#21644;&#38750;&#21442;&#25968;&#22238;&#24402;&#20989;&#25968;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#23558;&#20989;&#25968;&#27010;&#24565;&#21270;&#20026;&#30697;&#38453;&#65292;&#24182;&#37319;&#29992;&#33609;&#22270;&#25216;&#26415;&#26469;&#38477;&#20302;&#32500;&#24230;&#28798;&#38590;&#24341;&#36215;&#30340;&#26041;&#24046;&#65292;&#23637;&#31034;&#20102;&#40065;&#26834;&#24615;&#33021;&#21644;&#26174;&#33879;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2401.11646</link><description>&lt;p&gt;
&#36890;&#36807;&#26041;&#24046;&#38477;&#20302;&#30340;&#33609;&#22270;&#36827;&#34892;&#38750;&#21442;&#25968;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Nonparametric Estimation via Variance-Reduced Sketching. (arXiv:2401.11646v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11646
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Variance-Reduced Sketching&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#39640;&#32500;&#24230;&#20013;&#20272;&#35745;&#23494;&#24230;&#20989;&#25968;&#21644;&#38750;&#21442;&#25968;&#22238;&#24402;&#20989;&#25968;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#23558;&#20989;&#25968;&#27010;&#24565;&#21270;&#20026;&#30697;&#38453;&#65292;&#24182;&#37319;&#29992;&#33609;&#22270;&#25216;&#26415;&#26469;&#38477;&#20302;&#32500;&#24230;&#28798;&#38590;&#24341;&#36215;&#30340;&#26041;&#24046;&#65292;&#23637;&#31034;&#20102;&#40065;&#26834;&#24615;&#33021;&#21644;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#21442;&#25968;&#27169;&#22411;&#22312;&#21508;&#20010;&#31185;&#23398;&#21644;&#24037;&#31243;&#39046;&#22495;&#20013;&#22791;&#21463;&#20851;&#27880;&#12290;&#32463;&#20856;&#30340;&#26680;&#26041;&#27861;&#22312;&#20302;&#32500;&#24773;&#20917;&#19979;&#20855;&#26377;&#25968;&#20540;&#31283;&#23450;&#24615;&#21644;&#32479;&#35745;&#21487;&#38752;&#24615;&#65292;&#20294;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#30001;&#20110;&#32500;&#24230;&#28798;&#38590;&#21464;&#24471;&#19981;&#22815;&#36866;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#21517;&#20026;Variance-Reduced Sketching&#65288;VRS&#65289;&#30340;&#26032;&#26694;&#26550;&#65292;&#19987;&#38376;&#29992;&#20110;&#22312;&#38477;&#20302;&#32500;&#24230;&#28798;&#38590;&#30340;&#21516;&#26102;&#22312;&#39640;&#32500;&#24230;&#20013;&#20272;&#35745;&#23494;&#24230;&#20989;&#25968;&#21644;&#38750;&#21442;&#25968;&#22238;&#24402;&#20989;&#25968;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#23558;&#22810;&#21464;&#37327;&#20989;&#25968;&#27010;&#24565;&#21270;&#20026;&#26080;&#38480;&#22823;&#23567;&#30340;&#30697;&#38453;&#65292;&#24182;&#20511;&#37492;&#20102;&#25968;&#20540;&#32447;&#24615;&#20195;&#25968;&#25991;&#29486;&#20013;&#30340;&#19968;&#31181;&#26032;&#30340;&#33609;&#22270;&#25216;&#26415;&#26469;&#38477;&#20302;&#20272;&#35745;&#38382;&#39064;&#20013;&#30340;&#26041;&#24046;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#31995;&#21015;&#30340;&#27169;&#25311;&#23454;&#39564;&#21644;&#30495;&#23454;&#25968;&#25454;&#24212;&#29992;&#23637;&#31034;&#20102;VRS&#30340;&#40065;&#26834;&#24615;&#33021;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#22312;&#35768;&#22810;&#23494;&#24230;&#20272;&#35745;&#38382;&#39064;&#20013;&#65292;VRS&#30456;&#36739;&#20110;&#29616;&#26377;&#30340;&#31070;&#32463;&#32593;&#32476;&#20272;&#35745;&#22120;&#21644;&#32463;&#20856;&#30340;&#26680;&#26041;&#27861;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nonparametric models are of great interest in various scientific and engineering disciplines. Classical kernel methods, while numerically robust and statistically sound in low-dimensional settings, become inadequate in higher-dimensional settings due to the curse of dimensionality. In this paper, we introduce a new framework called Variance-Reduced Sketching (VRS), specifically designed to estimate density functions and nonparametric regression functions in higher dimensions with a reduced curse of dimensionality. Our framework conceptualizes multivariable functions as infinite-size matrices, and facilitates a new sketching technique motivated by numerical linear algebra literature to reduce the variance in estimation problems. We demonstrate the robust numerical performance of VRS through a series of simulated experiments and real-world data applications. Notably, VRS shows remarkable improvement over existing neural network estimators and classical kernel methods in numerous density 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22522;&#20110;&#27169;&#22411;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#21709;&#24212;&#31867;&#22411;&#30340;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#19981;&#21464;&#24615;&#20551;&#35774;&#20174;&#24322;&#36136;&#29615;&#22659;&#30340;&#25968;&#25454;&#20013;&#36755;&#20986;&#19968;&#37096;&#20998;&#22240;&#26524;&#29305;&#24449;&#30340;&#23376;&#38598;&#65292;&#36866;&#29992;&#20110;&#19968;&#33324;&#30340;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#21644;&#38750;&#21442;&#25968;&#35774;&#32622;&#65292;&#35299;&#20915;&#20102;&#38750;&#21442;&#25968;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#20302;&#21151;&#29575;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.12833</link><description>&lt;p&gt;
&#22522;&#20110;&#27169;&#22411;&#30340;&#36890;&#29992;&#21709;&#24212;&#31867;&#22411;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Model-based causal feature selection for general response types. (arXiv:2309.12833v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12833
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22522;&#20110;&#27169;&#22411;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#21709;&#24212;&#31867;&#22411;&#30340;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#19981;&#21464;&#24615;&#20551;&#35774;&#20174;&#24322;&#36136;&#29615;&#22659;&#30340;&#25968;&#25454;&#20013;&#36755;&#20986;&#19968;&#37096;&#20998;&#22240;&#26524;&#29305;&#24449;&#30340;&#23376;&#38598;&#65292;&#36866;&#29992;&#20110;&#19968;&#33324;&#30340;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#21644;&#38750;&#21442;&#25968;&#35774;&#32622;&#65292;&#35299;&#20915;&#20102;&#38750;&#21442;&#25968;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#20302;&#21151;&#29575;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#21457;&#29616;&#22240;&#26524;&#20851;&#31995;&#26159;&#19968;&#39033;&#22522;&#26412;&#32780;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#22312;&#26576;&#20123;&#24212;&#29992;&#20013;&#65292;&#20165;&#23398;&#20064;&#32473;&#23450;&#21709;&#24212;&#21464;&#37327;&#30340;&#22240;&#26524;&#29305;&#24449;&#21487;&#33021;&#24050;&#32463;&#36275;&#22815;&#65292;&#32780;&#19981;&#26159;&#23398;&#20064;&#25972;&#20010;&#28508;&#22312;&#30340;&#22240;&#26524;&#32467;&#26500;&#12290;&#19981;&#21464;&#22240;&#26524;&#39044;&#27979;&#65288;ICP&#65289;&#26159;&#19968;&#31181;&#29992;&#20110;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;&#30340;&#26041;&#27861;&#65292;&#38656;&#35201;&#26469;&#33258;&#24322;&#36136;&#29615;&#22659;&#30340;&#25968;&#25454;&#12290;ICP&#20551;&#35774;&#20174;&#30452;&#25509;&#21407;&#22240;&#29983;&#25104;&#21709;&#24212;&#30340;&#26426;&#21046;&#22312;&#25152;&#26377;&#29615;&#22659;&#20013;&#37117;&#30456;&#21516;&#65292;&#24182;&#21033;&#29992;&#36825;&#31181;&#19981;&#21464;&#24615;&#36755;&#20986;&#19968;&#37096;&#20998;&#22240;&#26524;&#29305;&#24449;&#30340;&#23376;&#38598;&#12290;ICP&#30340;&#26694;&#26550;&#24050;&#32463;&#25193;&#23637;&#21040;&#19968;&#33324;&#30340;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#21644;&#38750;&#21442;&#25968;&#35774;&#32622;&#65292;&#20351;&#29992;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#12290;&#28982;&#32780;&#65292;&#38750;&#21442;&#25968;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#32463;&#24120;&#21463;&#21040;&#20302;&#21151;&#29575;&#65288;&#25110;&#36739;&#24046;&#30340;&#31867;&#22411;I&#38169;&#35823;&#25511;&#21046;&#65289;&#30340;&#22256;&#25200;&#65292;&#24182;&#19988;&#19978;&#36848;&#21442;&#25968;&#27169;&#22411;&#19981;&#36866;&#29992;&#20110;&#21709;&#24212;&#19981;&#26159;&#22312;&#36830;&#32493;&#21051;&#24230;&#19978;&#27979;&#37327;&#30340;&#24212;&#29992;&#24773;&#20917;&#65292;&#32780;&#26159;&#21453;&#26144;&#20102;&#20998;&#31867;&#20449;&#24687;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Discovering causal relationships from observational data is a fundamental yet challenging task. In some applications, it may suffice to learn the causal features of a given response variable, instead of learning the entire underlying causal structure. Invariant causal prediction (ICP, Peters et al., 2016) is a method for causal feature selection which requires data from heterogeneous settings. ICP assumes that the mechanism for generating the response from its direct causes is the same in all settings and exploits this invariance to output a subset of the causal features. The framework of ICP has been extended to general additive noise models and to nonparametric settings using conditional independence testing. However, nonparametric conditional independence testing often suffers from low power (or poor type I error control) and the aforementioned parametric models are not suitable for applications in which the response is not measured on a continuous scale, but rather reflects categor
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#39046;&#22495;&#33258;&#36866;&#24212;&#20013;&#26465;&#20214;&#19981;&#21464;&#32452;&#20214;&#30340;&#20316;&#29992;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26465;&#20214;&#19981;&#21464;&#24809;&#32602;&#30340;&#26032;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#30446;&#26631;&#39118;&#38505;&#20445;&#35777;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2309.10301</link><description>&lt;p&gt;
&#39046;&#22495;&#33258;&#36866;&#24212;&#20013;&#26465;&#20214;&#19981;&#21464;&#32452;&#20214;&#30340;&#31361;&#20986;&#20316;&#29992;&#65306;&#29702;&#35770;&#21644;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Prominent Roles of Conditionally Invariant Components in Domain Adaptation: Theory and Algorithms. (arXiv:2309.10301v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.10301
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#39046;&#22495;&#33258;&#36866;&#24212;&#20013;&#26465;&#20214;&#19981;&#21464;&#32452;&#20214;&#30340;&#20316;&#29992;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26465;&#20214;&#19981;&#21464;&#24809;&#32602;&#30340;&#26032;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#30446;&#26631;&#39118;&#38505;&#20445;&#35777;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39046;&#22495;&#33258;&#36866;&#24212;&#26159;&#19968;&#20010;&#32479;&#35745;&#23398;&#20064;&#38382;&#39064;&#65292;&#24403;&#29992;&#20110;&#35757;&#32451;&#27169;&#22411;&#30340;&#28304;&#25968;&#25454;&#20998;&#24067;&#19982;&#29992;&#20110;&#35780;&#20272;&#27169;&#22411;&#30340;&#30446;&#26631;&#25968;&#25454;&#20998;&#24067;&#19981;&#21516;&#26102;&#20986;&#29616;&#12290;&#34429;&#28982;&#35768;&#22810;&#39046;&#22495;&#33258;&#36866;&#24212;&#31639;&#27861;&#24050;&#32463;&#35777;&#26126;&#20102;&#30456;&#24403;&#22823;&#30340;&#23454;&#35777;&#25104;&#21151;&#65292;&#20294;&#26159;&#30450;&#30446;&#24212;&#29992;&#36825;&#20123;&#31639;&#27861;&#24448;&#24448;&#20250;&#23548;&#33268;&#22312;&#26032;&#30340;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#26356;&#24046;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#37325;&#35201;&#30340;&#26159;&#28548;&#28165;&#39046;&#22495;&#33258;&#36866;&#24212;&#31639;&#27861;&#22312;&#20855;&#22791;&#33391;&#22909;&#30446;&#26631;&#24615;&#33021;&#30340;&#20551;&#35774;&#19979;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20851;&#27880;&#22312;&#39044;&#27979;&#20013;&#20855;&#22791;&#26465;&#20214;&#19981;&#21464;&#30340;&#32452;&#20214;&#65288;CICs&#65289;&#30340;&#23384;&#22312;&#20551;&#35774;&#65292;&#36825;&#20123;&#32452;&#20214;&#22312;&#28304;&#25968;&#25454;&#21644;&#30446;&#26631;&#25968;&#25454;&#20043;&#38388;&#20445;&#25345;&#26465;&#20214;&#19981;&#21464;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;CICs&#65292;&#36890;&#36807;&#26465;&#20214;&#19981;&#21464;&#24809;&#32602;&#65288;CIP&#65289;&#21487;&#20197;&#20272;&#35745;&#65292;&#20855;&#22791;&#22312;&#39046;&#22495;&#33258;&#36866;&#24212;&#20013;&#25552;&#20379;&#30446;&#26631;&#39118;&#38505;&#20445;&#35777;&#30340;&#19977;&#20010;&#31361;&#20986;&#20316;&#29992;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;CICs&#30340;&#26032;&#31639;&#27861;&#65292;&#21363;&#37325;&#35201;&#24615;&#21152;&#26435;&#30340;&#26465;&#20214;&#19981;&#21464;&#24809;&#32602;&#65288;IW-CIP&#65289;&#65292;&#23427;&#22312;&#30446;&#26631;&#39118;&#38505;&#20445;&#35777;&#26041;&#38754;&#36229;&#36234;&#20102;&#31616;&#21333;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Domain adaptation (DA) is a statistical learning problem that arises when the distribution of the source data used to train a model differs from that of the target data used to evaluate the model. While many DA algorithms have demonstrated considerable empirical success, blindly applying these algorithms can often lead to worse performance on new datasets. To address this, it is crucial to clarify the assumptions under which a DA algorithm has good target performance. In this work, we focus on the assumption of the presence of conditionally invariant components (CICs), which are relevant for prediction and remain conditionally invariant across the source and target data. We demonstrate that CICs, which can be estimated through conditional invariant penalty (CIP), play three prominent roles in providing target risk guarantees in DA. First, we propose a new algorithm based on CICs, importance-weighted conditional invariant penalty (IW-CIP), which has target risk guarantees beyond simple 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22270;&#24494;&#20998;&#26041;&#31243;&#32593;&#32476;&#65288;GDeNet&#65289;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#28909;&#21644;&#27874;&#21160;&#26041;&#31243;&#21160;&#21147;&#23398;&#29305;&#24449;&#26469;&#24674;&#22797;&#22270;&#30340;&#25299;&#25169;&#23646;&#24615;&#65292;&#33021;&#22815;&#22312;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#20013;&#33719;&#24471;&#20248;&#31168;&#30340;&#34920;&#29616;&#65292;&#21516;&#26102;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#20063;&#23637;&#29616;&#20102;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.09924</link><description>&lt;p&gt;
&#22522;&#20110;&#28909;&#21644;&#27874;&#21160;&#21160;&#21147;&#23398;&#29305;&#24449;&#30340;&#22270;&#25299;&#25169;&#23646;&#24615;&#24674;&#22797;
&lt;/p&gt;
&lt;p&gt;
Graph topological property recovery with heat and wave dynamics-based features on graphsD. (arXiv:2309.09924v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09924
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22270;&#24494;&#20998;&#26041;&#31243;&#32593;&#32476;&#65288;GDeNet&#65289;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#28909;&#21644;&#27874;&#21160;&#26041;&#31243;&#21160;&#21147;&#23398;&#29305;&#24449;&#26469;&#24674;&#22797;&#22270;&#30340;&#25299;&#25169;&#23646;&#24615;&#65292;&#33021;&#22815;&#22312;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#20013;&#33719;&#24471;&#20248;&#31168;&#30340;&#34920;&#29616;&#65292;&#21516;&#26102;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#20063;&#23637;&#29616;&#20102;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22270;&#24494;&#20998;&#26041;&#31243;&#32593;&#32476;&#65288;GDeNet&#65289;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22270;&#19978;&#30340;PDE&#35299;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#20026;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#33719;&#24471;&#36830;&#32493;&#30340;&#33410;&#28857;&#21644;&#22270;&#32423;&#34920;&#31034;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#28909;&#21644;&#27874;&#21160;&#26041;&#31243;&#21160;&#21147;&#23398;&#19982;&#22270;&#30340;&#35889;&#29305;&#24615;&#20197;&#21450;&#36830;&#32493;&#26102;&#38388;&#38543;&#26426;&#28216;&#36208;&#22312;&#22270;&#19978;&#34892;&#20026;&#20043;&#38388;&#30340;&#29702;&#35770;&#32467;&#26524;&#12290;&#25105;&#20204;&#36890;&#36807;&#24674;&#22797;&#38543;&#26426;&#22270;&#29983;&#25104;&#21442;&#25968;&#12289;Ricci&#26354;&#29575;&#21644;&#25345;&#20037;&#21516;&#35843;&#31561;&#26041;&#24335;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#20123;&#21160;&#21147;&#23398;&#33021;&#22815;&#25429;&#25417;&#21040;&#22270;&#24418;&#20960;&#20309;&#21644;&#25299;&#25169;&#30340;&#26174;&#33879;&#26041;&#38754;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;GDeNet&#22312;&#21253;&#25324;&#24341;&#29992;&#22270;&#12289;&#33647;&#29289;&#20998;&#23376;&#21644;&#34507;&#30333;&#36136;&#22312;&#20869;&#30340;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose Graph Differential Equation Network (GDeNet), an approach that harnesses the expressive power of solutions to PDEs on a graph to obtain continuous node- and graph-level representations for various downstream tasks. We derive theoretical results connecting the dynamics of heat and wave equations to the spectral properties of the graph and to the behavior of continuous-time random walks on graphs. We demonstrate experimentally that these dynamics are able to capture salient aspects of graph geometry and topology by recovering generating parameters of random graphs, Ricci curvature, and persistent homology. Furthermore, we demonstrate the superior performance of GDeNet on real-world datasets including citation graphs, drug-like molecules, and proteins.
&lt;/p&gt;</description></item><item><title>&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#38656;&#35201;&#20351;&#29992;&#37327;&#23376;&#35745;&#31639;&#26426;&#36827;&#34892;&#35780;&#20272;&#65292;&#20294;&#25105;&#20204;&#25552;&#20986;&#22312;&#35757;&#32451;&#23436;&#21518;&#65292;&#20351;&#29992;&#37327;&#23376;&#35745;&#31639;&#26426;&#29983;&#25104;&#19968;&#20010;&#32463;&#20856;&#38452;&#24433;&#27169;&#22411;&#26469;&#35745;&#31639;&#20989;&#25968;&#30340;&#32463;&#20856;&#35745;&#31639;&#36817;&#20284;&#65292;&#36991;&#20813;&#20102;&#23545;&#37327;&#23376;&#35745;&#31639;&#26426;&#30340;&#38656;&#27714;&#12290;</title><link>http://arxiv.org/abs/2306.00061</link><description>&lt;p&gt;
&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#30340;&#38452;&#24433;
&lt;/p&gt;
&lt;p&gt;
Shadows of quantum machine learning. (arXiv:2306.00061v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00061
&lt;/p&gt;
&lt;p&gt;
&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#38656;&#35201;&#20351;&#29992;&#37327;&#23376;&#35745;&#31639;&#26426;&#36827;&#34892;&#35780;&#20272;&#65292;&#20294;&#25105;&#20204;&#25552;&#20986;&#22312;&#35757;&#32451;&#23436;&#21518;&#65292;&#20351;&#29992;&#37327;&#23376;&#35745;&#31639;&#26426;&#29983;&#25104;&#19968;&#20010;&#32463;&#20856;&#38452;&#24433;&#27169;&#22411;&#26469;&#35745;&#31639;&#20989;&#25968;&#30340;&#32463;&#20856;&#35745;&#31639;&#36817;&#20284;&#65292;&#36991;&#20813;&#20102;&#23545;&#37327;&#23376;&#35745;&#31639;&#26426;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#32463;&#24120;&#34987;&#35748;&#20026;&#26159;&#21033;&#29992;&#37327;&#23376;&#35745;&#31639;&#26426;&#35299;&#20915;&#23454;&#38469;&#38382;&#39064;&#30340;&#26368;&#26377;&#21069;&#36884;&#30340;&#24212;&#29992;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#38459;&#30861;&#20854;&#22312;&#23454;&#36341;&#20013;&#24191;&#27867;&#20351;&#29992;&#30340;&#20027;&#35201;&#38556;&#30861;&#26159;&#36825;&#20123;&#27169;&#22411;&#21363;&#20351;&#22312;&#35757;&#32451;&#36807;&#31243;&#21518;&#65292;&#20173;&#38656;&#35201;&#35775;&#38382;&#37327;&#23376;&#35745;&#31639;&#26426;&#25165;&#33021;&#23545;&#26032;&#25968;&#25454;&#36827;&#34892;&#35780;&#20272;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24314;&#35758;&#22312;&#37327;&#23376;&#27169;&#22411;&#30340;&#35757;&#32451;&#38454;&#27573;&#20043;&#21518;&#65292;&#37327;&#23376;&#35745;&#31639;&#26426;&#21487;&#20197;&#29992;&#26469;&#29983;&#25104;&#25105;&#20204;&#25152;&#35859;&#30340;&#35813;&#27169;&#22411;&#30340;&#8220;&#32463;&#20856;&#38452;&#24433;&#8221;&#65292;&#21363;&#24050;&#23398;&#20064;&#20989;&#25968;&#30340;&#32463;&#20856;&#35745;&#31639;&#36817;&#20284;&#12290;&#34429;&#28982;&#26368;&#36817;&#30340;&#30740;&#31350;&#24050;&#32463;&#25506;&#35752;&#20102;&#36825;&#20010;&#24819;&#27861;&#24182;&#25552;&#20986;&#20102;&#26500;&#24314;&#36825;&#31181;&#24433;&#23376;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#20294;&#23427;&#20204;&#20063;&#25552;&#20986;&#20102;&#19968;&#20010;&#23436;&#20840;&#32463;&#20856;&#27169;&#22411;&#21487;&#33021;&#20195;&#26367;&#30340;&#21487;&#33021;&#24615;&#65292;&#20174;&#32780;&#39318;&#20808;&#22238;&#36991;&#20102;&#37327;&#23376;&#35745;&#31639;&#26426;&#30340;&#38656;&#35201;&#12290;&#26412;&#25991;&#37319;&#29992;&#26032;&#30340;&#26041;&#27861;&#65292;&#22522;&#20110;&#37327;&#23376;&#32447;&#24615;&#27169;&#22411;&#21644;&#32463;&#20856;&#38452;&#24433;&#37325;&#26500;&#30340;&#26694;&#26550;&#26469;&#23450;&#20041;&#38452;&#24433;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantum machine learning is often highlighted as one of the most promising uses for a quantum computer to solve practical problems. However, a major obstacle to the widespread use of quantum machine learning models in practice is that these models, even once trained, still require access to a quantum computer in order to be evaluated on new data. To solve this issue, we suggest that following the training phase of a quantum model, a quantum computer could be used to generate what we call a classical shadow of this model, i.e., a classically computable approximation of the learned function. While recent works already explore this idea and suggest approaches to construct such shadow models, they also raise the possibility that a completely classical model could be trained instead, thus circumventing the need for a quantum computer in the first place. In this work, we take a novel approach to define shadow models based on the frameworks of quantum linear models and classical shadow tomogr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#25968;&#20540;&#27169;&#25311;&#26102;&#38388;&#28436;&#21270;&#34203;&#23450;&#35860;&#26041;&#31243;&#65292;&#21033;&#29992;&#39532;&#23572;&#21487;&#22827;&#25193;&#25955;&#37319;&#26679;&#26469;&#36866;&#24212;&#27874;&#20989;&#25968;&#30340;&#28508;&#22312;&#20302;&#32500;&#32467;&#26500;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#38543;&#26426;&#37327;&#23376;&#21147;&#23398;&#26041;&#31243;&#65292;&#20855;&#26377;&#32447;&#24615;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#25968;&#20540;&#27169;&#25311;&#26174;&#31034;&#20986;&#26174;&#30528;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2305.19685</link><description>&lt;p&gt;
&#28145;&#24230;&#38543;&#26426;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
Deep Stochastic Mechanics. (arXiv:2305.19685v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19685
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#25968;&#20540;&#27169;&#25311;&#26102;&#38388;&#28436;&#21270;&#34203;&#23450;&#35860;&#26041;&#31243;&#65292;&#21033;&#29992;&#39532;&#23572;&#21487;&#22827;&#25193;&#25955;&#37319;&#26679;&#26469;&#36866;&#24212;&#27874;&#20989;&#25968;&#30340;&#28508;&#22312;&#20302;&#32500;&#32467;&#26500;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#38543;&#26426;&#37327;&#23376;&#21147;&#23398;&#26041;&#31243;&#65292;&#20855;&#26377;&#32447;&#24615;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#25968;&#20540;&#27169;&#25311;&#26174;&#31034;&#20986;&#26174;&#30528;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#25968;&#20540;&#27169;&#25311;&#26102;&#38388;&#28436;&#21270;&#34203;&#23450;&#35860;&#26041;&#31243;&#65292;&#21463;&#38543;&#26426;&#21147;&#23398;&#21644;&#29983;&#25104;&#24615;&#25193;&#25955;&#27169;&#22411;&#30340;&#21551;&#21457;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20801;&#35768;&#25105;&#20204;&#36890;&#36807;&#20174;&#39532;&#23572;&#21487;&#22827;&#25193;&#25955;&#20013;&#37319;&#26679;&#26469;&#36866;&#24212;&#27874;&#20989;&#25968;&#28508;&#22312;&#30340;&#20302;&#32500;&#32467;&#26500;&#65292;&#22240;&#27492;&#21487;&#20197;&#22312;&#26356;&#39640;&#30340;&#32500;&#24230;&#19978;&#38477;&#20302;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26032;&#30340;&#38543;&#26426;&#37327;&#23376;&#21147;&#23398;&#26041;&#31243;&#65292;&#32467;&#26524;&#20855;&#26377;&#19982;&#32500;&#25968;&#25968;&#37327;&#32447;&#24615;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#25968;&#20540;&#27169;&#25311;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#21457;&#29616;&#65292;&#24182;&#26174;&#31034;&#20986;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#20854;&#20182;&#29992;&#20110;&#37327;&#23376;&#21147;&#23398;&#30340;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#30456;&#27604;&#20855;&#26377;&#26174;&#30528;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a novel deep-learning-based approach for numerical simulation of a time-evolving Schr\"odinger equation inspired by stochastic mechanics and generative diffusion models. Unlike existing approaches, which exhibit computational complexity that scales exponentially in the problem dimension, our method allows us to adapt to the latent low-dimensional structure of the wave function by sampling from the Markovian diffusion. Depending on the latent dimension, our method may have far lower computational complexity in higher dimensions. Moreover, we propose novel equations for stochastic quantum mechanics, resulting in linear computational complexity with respect to the number of dimensions. Numerical simulations verify our theoretical findings and show a significant advantage of our method compared to other deep-learning-based approaches used for quantum mechanics.
&lt;/p&gt;</description></item></channel></rss>