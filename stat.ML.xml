<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26657;&#20934;&#26041;&#27861;THERMOMETER&#65292;&#36890;&#36807;&#23398;&#20064;&#26469;&#33258;&#22810;&#20010;&#20219;&#21153;&#25968;&#25454;&#30340;&#36741;&#21161;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#35745;&#31639;&#25928;&#29575;&#39640;&#12289;&#20934;&#30830;&#24615;&#20445;&#25345;&#24182;&#20135;&#29983;&#26356;&#22909;&#26657;&#20934;&#21709;&#24212;&#30340;&#30446;&#26631;&#12290;</title><link>https://arxiv.org/abs/2403.08819</link><description>&lt;p&gt;
&#28201;&#24230;&#35745;&#65306;&#38754;&#21521;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#36890;&#29992;&#26657;&#20934;
&lt;/p&gt;
&lt;p&gt;
Thermometer: Towards Universal Calibration for Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08819
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26657;&#20934;&#26041;&#27861;THERMOMETER&#65292;&#36890;&#36807;&#23398;&#20064;&#26469;&#33258;&#22810;&#20010;&#20219;&#21153;&#25968;&#25454;&#30340;&#36741;&#21161;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#35745;&#31639;&#25928;&#29575;&#39640;&#12289;&#20934;&#30830;&#24615;&#20445;&#25345;&#24182;&#20135;&#29983;&#26356;&#22909;&#26657;&#20934;&#21709;&#24212;&#30340;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20013;&#30340;&#26657;&#20934;&#38382;&#39064;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#24120;&#35265;&#30340;&#24178;&#39044;&#25514;&#26045;&#22914;&#25351;&#20196;&#35843;&#25972;&#36890;&#24120;&#20250;&#23548;&#33268;&#26657;&#20934;&#19981;&#20339;&#30340;LLMs&#12290;&#23613;&#31649;&#26657;&#20934;&#22312;&#20256;&#32479;&#24212;&#29992;&#20013;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#25506;&#35752;&#65292;&#20294;&#23545;LLMs&#36827;&#34892;&#26657;&#20934;&#20855;&#26377;&#29420;&#29305;&#25361;&#25112;&#12290;&#36825;&#20123;&#25361;&#25112;&#19981;&#20165;&#26469;&#33258;LLMs&#30340;&#20005;&#26684;&#35745;&#31639;&#35201;&#27714;&#65292;&#20063;&#26469;&#33258;&#23427;&#20204;&#30340;&#22810;&#21151;&#33021;&#24615;&#65292;&#20351;&#23427;&#20204;&#21487;&#20197;&#24212;&#29992;&#20110;&#21508;&#31181;&#20219;&#21153;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;LLMs&#30340;&#26657;&#20934;&#26041;&#27861;THERMOMETER&#12290;THERMOMETER&#36890;&#36807;&#23398;&#20064;&#26469;&#33258;&#22810;&#20010;&#20219;&#21153;&#30340;&#25968;&#25454;&#30340;&#36741;&#21161;&#27169;&#22411;&#65292;&#29992;&#20110;&#26657;&#20934;LLM&#12290;&#23427;&#22312;&#35745;&#31639;&#19978;&#25928;&#29575;&#39640;&#65292;&#20445;&#25345;&#20102;LLM&#30340;&#20934;&#30830;&#24615;&#65292;&#24182;&#20026;&#26032;&#20219;&#21153;&#20135;&#29983;&#20102;&#26356;&#22909;&#30340;&#26657;&#20934;&#21709;&#24212;&#12290;&#23545;&#21508;&#31181;&#22522;&#20934;&#30340;&#24191;&#27867;&#23454;&#35777;&#35780;&#20272;&#26174;&#31034;&#20102;&#25152;&#25552;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08819v1 Announce Type: cross  Abstract: We consider the issue of calibration in large language models (LLM). Recent studies have found that common interventions such as instruction tuning often result in poorly calibrated LLMs. Although calibration is well-explored in traditional applications, calibrating LLMs is uniquely challenging. These challenges stem as much from the severe computational requirements of LLMs as from their versatility, which allows them to be applied to diverse tasks. Addressing these challenges, we propose THERMOMETER, a calibration approach tailored to LLMs. THERMOMETER learns an auxiliary model, given data from multiple tasks, for calibrating a LLM. It is computationally efficient, preserves the accuracy of the LLM, and produces better-calibrated responses for new tasks. Extensive empirical evaluations across various benchmarks demonstrate the effectiveness of the proposed method.
&lt;/p&gt;</description></item><item><title>&#32570;&#22833;&#25968;&#25454;&#22686;&#21152;&#20102;&#27169;&#22411;&#23545;&#28508;&#22312;&#21464;&#37327;&#21518;&#39564;&#20998;&#24067;&#30340;&#22797;&#26434;&#24615;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#31574;&#30053;&#8212;&#8212;&#22522;&#20110;&#26377;&#38480;&#21464;&#20998;&#28151;&#21512;&#21644;&#22522;&#20110;&#22635;&#34917;&#30340;&#21464;&#20998;&#28151;&#21512;&#20998;&#24067;&#65292;&#26377;&#25928;&#25913;&#21892;&#20102;&#20174;&#19981;&#23436;&#25972;&#25968;&#25454;&#20272;&#35745;VAE&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.03069</link><description>&lt;p&gt;
&#29992;&#28151;&#21512;&#21464;&#20998;&#23478;&#26063;&#25913;&#36827;&#20174;&#19981;&#23436;&#25972;&#25968;&#25454;&#20272;&#35745;&#30340;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;
&lt;/p&gt;
&lt;p&gt;
Improving Variational Autoencoder Estimation from Incomplete Data with Mixture Variational Families
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03069
&lt;/p&gt;
&lt;p&gt;
&#32570;&#22833;&#25968;&#25454;&#22686;&#21152;&#20102;&#27169;&#22411;&#23545;&#28508;&#22312;&#21464;&#37327;&#21518;&#39564;&#20998;&#24067;&#30340;&#22797;&#26434;&#24615;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#31574;&#30053;&#8212;&#8212;&#22522;&#20110;&#26377;&#38480;&#21464;&#20998;&#28151;&#21512;&#21644;&#22522;&#20110;&#22635;&#34917;&#30340;&#21464;&#20998;&#28151;&#21512;&#20998;&#24067;&#65292;&#26377;&#25928;&#25913;&#21892;&#20102;&#20174;&#19981;&#23436;&#25972;&#25968;&#25454;&#20272;&#35745;VAE&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#22312;&#35757;&#32451;&#25968;&#25454;&#19981;&#23436;&#25972;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;VAEs&#65289;&#30340;&#20219;&#21153;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#32570;&#22833;&#25968;&#25454;&#20250;&#22686;&#21152;&#27169;&#22411;&#23545;&#28508;&#22312;&#21464;&#37327;&#30340;&#21518;&#39564;&#20998;&#24067;&#30340;&#22797;&#26434;&#24615;&#65292;&#19982;&#23436;&#20840;&#35266;&#27979;&#30340;&#24773;&#20917;&#30456;&#27604;&#12290;&#22686;&#21152;&#30340;&#22797;&#26434;&#24615;&#21487;&#33021;&#20250;&#30001;&#20110;&#21464;&#20998;&#20998;&#24067;&#21644;&#27169;&#22411;&#21518;&#39564;&#20998;&#24067;&#20043;&#38388;&#30340;&#19981;&#21305;&#37197;&#32780;&#23545;&#27169;&#22411;&#25311;&#21512;&#20135;&#29983;&#19981;&#21033;&#24433;&#21709;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#31181;&#22522;&#20110;&#65288;i&#65289;&#26377;&#38480;&#21464;&#20998;&#28151;&#21512;&#21644;&#65288;ii&#65289;&#22522;&#20110;&#22635;&#34917;&#30340;&#21464;&#20998;&#28151;&#21512;&#20998;&#24067;&#30340;&#31574;&#30053;&#65292;&#20197;&#35299;&#20915;&#22686;&#21152;&#30340;&#21518;&#39564;&#22797;&#26434;&#24615;&#12290;&#36890;&#36807;&#23545;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#20840;&#38754;&#35780;&#20272;&#65292;&#25105;&#20204;&#34920;&#26126;&#21464;&#20998;&#28151;&#21512;&#22312;&#25913;&#36827;&#20174;&#19981;&#23436;&#25972;&#25968;&#25454;&#20272;&#35745;VAE&#30340;&#20934;&#30830;&#24615;&#26041;&#38754;&#26159;&#26377;&#25928;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03069v1 Announce Type: new  Abstract: We consider the task of estimating variational autoencoders (VAEs) when the training data is incomplete. We show that missing data increases the complexity of the model's posterior distribution over the latent variables compared to the fully-observed case. The increased complexity may adversely affect the fit of the model due to a mismatch between the variational and model posterior distributions. We introduce two strategies based on (i) finite variational-mixture and (ii) imputation-based variational-mixture distributions to address the increased posterior complexity. Through a comprehensive evaluation of the proposed approaches, we show that variational mixtures are effective at improving the accuracy of VAE estimation from incomplete data.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#35777;&#26126;&#20102;&#22312;&#38750;&#20809;&#28369;&#38543;&#26426;&#20984;&#20248;&#21270;&#20013;&#65292;&#36866;&#24212;&#24615;&#30340;&#20195;&#20215;&#26159;&#26080;&#27861;&#36991;&#20813;&#30340;&#65292;&#24182;&#19988;&#32473;&#20986;&#20102;&#20851;&#20110;&#19981;&#30830;&#23450;&#24615;&#21442;&#25968;&#30340;&#27425;&#20248;&#24615;&#20056;&#27861;&#22686;&#21152;&#30340;&#19979;&#30028;&#12290;</title><link>https://arxiv.org/abs/2402.10898</link><description>&lt;p&gt;
&#38543;&#26426;&#20984;&#20248;&#21270;&#20013;&#36866;&#24212;&#24615;&#30340;&#20195;&#20215;
&lt;/p&gt;
&lt;p&gt;
The Price of Adaptivity in Stochastic Convex Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10898
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35777;&#26126;&#20102;&#22312;&#38750;&#20809;&#28369;&#38543;&#26426;&#20984;&#20248;&#21270;&#20013;&#65292;&#36866;&#24212;&#24615;&#30340;&#20195;&#20215;&#26159;&#26080;&#27861;&#36991;&#20813;&#30340;&#65292;&#24182;&#19988;&#32473;&#20986;&#20102;&#20851;&#20110;&#19981;&#30830;&#23450;&#24615;&#21442;&#25968;&#30340;&#27425;&#20248;&#24615;&#20056;&#27861;&#22686;&#21152;&#30340;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#38750;&#20809;&#28369;&#38543;&#26426;&#20984;&#20248;&#21270;&#20013;&#36866;&#24212;&#24615;&#30340;&#19981;&#21487;&#33021;&#24615;&#32467;&#26524;&#12290;&#32473;&#23450;&#19968;&#32452;&#25105;&#20204;&#24076;&#26395;&#36866;&#24212;&#30340;&#38382;&#39064;&#21442;&#25968;&#65292;&#25105;&#20204;&#23450;&#20041;&#20102;&#8220;&#36866;&#24212;&#24615;&#30340;&#20195;&#20215;&#8221;&#65288;PoA&#65289;&#65292;&#31895;&#30053;&#22320;&#35828;&#65292;&#23427;&#34913;&#37327;&#20102;&#30001;&#20110;&#36825;&#20123;&#21442;&#25968;&#30340;&#19981;&#30830;&#23450;&#24615;&#32780;&#23548;&#33268;&#30340;&#27425;&#20248;&#24615;&#30340;&#20056;&#27861;&#22686;&#21152;&#12290;&#24403;&#21021;&#22987;&#36317;&#31163;&#26368;&#20248;&#35299;&#26410;&#30693;&#20294;&#26799;&#24230;&#33539;&#25968;&#26377;&#30028;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;PoA&#33267;&#23569;&#23545;&#20110;&#26399;&#26395;&#27425;&#20248;&#24615;&#26159;&#23545;&#25968;&#32423;&#21035;&#65292;&#23545;&#20110;&#20013;&#20301;&#25968;&#27425;&#20248;&#24615;&#26159;&#21452;&#23545;&#25968;&#32423;&#21035;&#12290;&#24403;&#36317;&#31163;&#21644;&#26799;&#24230;&#33539;&#25968;&#37117;&#23384;&#22312;&#19981;&#30830;&#23450;&#24615;&#26102;&#65292;&#25105;&#20204;&#34920;&#26126;PoA&#24517;&#39035;&#26159;&#19982;&#19981;&#30830;&#23450;&#24615;&#27700;&#24179;&#22810;&#39033;&#24335;&#30456;&#20851;&#30340;&#12290;&#25105;&#20204;&#30340;&#19979;&#30028;&#20960;&#20046;&#19982;&#29616;&#26377;&#30340;&#19978;&#30028;&#30456;&#21305;&#37197;&#65292;&#24182;&#19988;&#30830;&#23450;&#20102;&#27809;&#26377;&#26080;&#21442;&#25968;&#21320;&#39184;&#30340;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10898v1 Announce Type: cross  Abstract: We prove impossibility results for adaptivity in non-smooth stochastic convex optimization. Given a set of problem parameters we wish to adapt to, we define a "price of adaptivity" (PoA) that, roughly speaking, measures the multiplicative increase in suboptimality due to uncertainty in these parameters. When the initial distance to the optimum is unknown but a gradient norm bound is known, we show that the PoA is at least logarithmic for expected suboptimality, and double-logarithmic for median suboptimality. When there is uncertainty in both distance and gradient norm, we show that the PoA must be polynomial in the level of uncertainty. Our lower bounds nearly match existing upper bounds, and establish that there is no parameter-free lunch.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#23398;&#20064;&#38750;&#20998;&#31163;&#21704;&#23494;&#39039;&#31995;&#32479;&#30340;&#32467;&#26500;&#20445;&#25345;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#32479;&#35745;&#30456;&#20851;&#30340;&#21152;&#24615;&#21644;&#20056;&#24615;&#22122;&#22768;&#65292;&#24182;&#19988;&#36890;&#36807;&#23558;&#32467;&#26500;&#20445;&#25345;&#26041;&#27861;&#32435;&#20837;&#26694;&#26550;&#20013;&#65292;&#25552;&#20379;&#20102;&#23545;&#39640;&#32500;&#31995;&#32479;&#30340;&#39640;&#25928;&#35782;&#21035;&#12290;</title><link>http://arxiv.org/abs/2401.12476</link><description>&lt;p&gt;
&#29992;&#28145;&#24230;&#23398;&#20064;&#21644;&#38477;&#38454;&#24314;&#27169;&#36827;&#34892;&#36125;&#21494;&#26031;&#38750;&#20998;&#31163;&#21704;&#23494;&#39039;&#31995;&#32479;&#30340;&#35782;&#21035;&#21644;&#22810;&#39033;&#24335;&#22122;&#22768; (arXiv:2401.12476v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
Bayesian identification of nonseparable Hamiltonians with multiplicative noise using deep learning and reduced-order modeling. (arXiv:2401.12476v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12476
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#23398;&#20064;&#38750;&#20998;&#31163;&#21704;&#23494;&#39039;&#31995;&#32479;&#30340;&#32467;&#26500;&#20445;&#25345;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#32479;&#35745;&#30456;&#20851;&#30340;&#21152;&#24615;&#21644;&#20056;&#24615;&#22122;&#22768;&#65292;&#24182;&#19988;&#36890;&#36807;&#23558;&#32467;&#26500;&#20445;&#25345;&#26041;&#27861;&#32435;&#20837;&#26694;&#26550;&#20013;&#65292;&#25552;&#20379;&#20102;&#23545;&#39640;&#32500;&#31995;&#32479;&#30340;&#39640;&#25928;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#26500;&#20445;&#25345;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#20351;&#29992;&#38543;&#26426;&#21160;&#21147;&#27169;&#22411;&#30340;&#38750;&#20998;&#31163;&#21704;&#23494;&#39039;&#31995;&#32479;&#65292;&#35813;&#31995;&#32479;&#20801;&#35768;&#32479;&#35745;&#30456;&#20851;&#30340;&#65292;&#30690;&#37327;&#20540;&#30340;&#21152;&#24615;&#21644;&#20056;&#24615;&#27979;&#37327;&#22122;&#22768;&#12290;&#35813;&#26041;&#27861;&#30001;&#19977;&#20010;&#20027;&#35201;&#26041;&#38754;&#32452;&#25104;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;&#36125;&#21494;&#26031;&#21518;&#39564;&#20013;&#30340;&#20284;&#28982;&#20989;&#25968;&#25152;&#38656;&#30340;&#32479;&#35745;&#30456;&#20851;&#30340;&#65292;&#30690;&#37327;&#20540;&#30340;&#21152;&#24615;&#21644;&#20056;&#24615;&#22122;&#22768;&#27169;&#22411;&#30340;&#39640;&#26031;&#28388;&#27874;&#22120;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;&#29992;&#20110;&#23545;&#39640;&#32500;&#31995;&#32479;&#36827;&#34892;&#39640;&#25928;&#30340;&#36125;&#21494;&#26031;&#31995;&#32479;&#35782;&#21035;&#12290;&#31532;&#19977;&#65292;&#25105;&#20204;&#28436;&#31034;&#20102;&#22914;&#20309;&#23558;&#32467;&#26500;&#20445;&#25345;&#26041;&#27861;&#32435;&#20837;&#25152;&#25552;&#35758;&#30340;&#26694;&#26550;&#20013;&#65292;&#20351;&#29992;&#38750;&#20998;&#31163;&#21704;&#23494;&#39039;&#31995;&#32479;&#20316;&#20026;&#19968;&#20010;&#20030;&#20363;&#30340;&#31995;&#32479;&#31867;&#21035;&#12290;&#25105;&#20204;&#23558;&#36125;&#21494;&#26031;&#26041;&#27861;&#19982;&#19968;&#31181;&#26368;&#20808;&#36827;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#19968;&#20010;&#20856;&#22411;&#30340;&#38750;&#20998;&#31163;&#21704;&#23494;&#39039;&#27169;&#22411;&#21644;&#24102;&#26377;&#23567;&#22411;&#22122;&#22768;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#28151;&#27788;&#21452;&#25670;&#27169;&#22411;&#19978;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;
&lt;/p&gt;
&lt;p&gt;
This paper presents a structure-preserving Bayesian approach for learning nonseparable Hamiltonian systems using stochastic dynamic models allowing for statistically-dependent, vector-valued additive and multiplicative measurement noise. The approach is comprised of three main facets. First, we derive a Gaussian filter for a statistically-dependent, vector-valued, additive and multiplicative noise model that is needed to evaluate the likelihood within the Bayesian posterior. Second, we develop a novel algorithm for cost-effective application of Bayesian system identification to high-dimensional systems. Third, we demonstrate how structure-preserving methods can be incorporated into the proposed framework, using nonseparable Hamiltonians as an illustrative system class. We compare the Bayesian method to a state-of-the-art machine learning method on a canonical nonseparable Hamiltonian model and a chaotic double pendulum model with small, noisy training datasets. The results show that us
&lt;/p&gt;</description></item><item><title>MixerFlow&#26159;&#19968;&#31181;&#26032;&#22411;&#30340;&#22522;&#20110;MLP-Mixer&#26550;&#26500;&#30340;&#27491;&#21017;&#21270;&#27969;&#27169;&#22411;&#65292;&#36890;&#36807;&#25552;&#20379;&#26377;&#25928;&#30340;&#26435;&#37325;&#20849;&#20139;&#26426;&#21046;&#65292;&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#22270;&#20687;&#23494;&#24230;&#20272;&#35745;&#24615;&#33021;&#21644;&#26356;&#20016;&#23500;&#30340;&#23884;&#20837;&#34920;&#31034;&#12290;</title><link>http://arxiv.org/abs/2310.16777</link><description>&lt;p&gt;
&#22270;&#20687;&#24314;&#27169;&#30340;MixerFlow
&lt;/p&gt;
&lt;p&gt;
MixerFlow for Image Modelling. (arXiv:2310.16777v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16777
&lt;/p&gt;
&lt;p&gt;
MixerFlow&#26159;&#19968;&#31181;&#26032;&#22411;&#30340;&#22522;&#20110;MLP-Mixer&#26550;&#26500;&#30340;&#27491;&#21017;&#21270;&#27969;&#27169;&#22411;&#65292;&#36890;&#36807;&#25552;&#20379;&#26377;&#25928;&#30340;&#26435;&#37325;&#20849;&#20139;&#26426;&#21046;&#65292;&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#22270;&#20687;&#23494;&#24230;&#20272;&#35745;&#24615;&#33021;&#21644;&#26356;&#20016;&#23500;&#30340;&#23884;&#20837;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27491;&#21017;&#21270;&#27969;&#26159;&#19968;&#31181;&#32479;&#35745;&#27169;&#22411;&#65292;&#36890;&#36807;&#20351;&#29992;&#21452;&#23556;&#21464;&#25442;&#23558;&#22797;&#26434;&#23494;&#24230;&#36716;&#25442;&#20026;&#31616;&#21333;&#23494;&#24230;&#65292;&#23454;&#29616;&#20102;&#23494;&#24230;&#20272;&#35745;&#21644;&#20174;&#21333;&#20010;&#27169;&#22411;&#29983;&#25104;&#25968;&#25454;&#30340;&#21151;&#33021;&#12290;&#22312;&#22270;&#20687;&#24314;&#27169;&#30340;&#32972;&#26223;&#19979;&#65292;&#20027;&#35201;&#36873;&#25321;&#30340;&#26159;&#22522;&#20110;Glow&#30340;&#26550;&#26500;&#65292;&#32780;&#20854;&#20182;&#26550;&#26500;&#22312;&#30740;&#31350;&#30028;&#23578;&#26410;&#24471;&#21040;&#24191;&#27867;&#25506;&#32034;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;MLP-Mixer&#26550;&#26500;&#30340;&#26032;&#22411;&#26550;&#26500;MixerFlow&#65292;&#36827;&#19968;&#27493;&#32479;&#19968;&#20102;&#29983;&#25104;&#24615;&#21644;&#21028;&#21035;&#24615;&#24314;&#27169;&#26550;&#26500;&#12290;MixerFlow&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#26435;&#37325;&#20849;&#20139;&#26426;&#21046;&#65292;&#36866;&#29992;&#20110;&#22522;&#20110;&#27969;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#22266;&#23450;&#35745;&#31639;&#39044;&#31639;&#19979;&#65292;MixerFlow&#22312;&#22270;&#20687;&#25968;&#25454;&#38598;&#19978;&#20855;&#26377;&#26356;&#22909;&#30340;&#23494;&#24230;&#20272;&#35745;&#24615;&#33021;&#65292;&#24182;&#19988;&#38543;&#30528;&#22270;&#20687;&#20998;&#36776;&#29575;&#30340;&#22686;&#21152;&#65292;&#20854;&#24615;&#33021;&#20063;&#24471;&#21040;&#20102;&#33391;&#22909;&#30340;&#25193;&#23637;&#65292;&#20351;&#24471;MixerFlow&#25104;&#20026;Glow-based&#26550;&#26500;&#30340;&#19968;&#20010;&#24378;&#22823;&#32780;&#31616;&#21333;&#30340;&#26367;&#20195;&#21697;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;MixerFlow&#25552;&#20379;&#20102;&#27604;Glow-based&#26550;&#26500;&#26356;&#20016;&#23500;&#30340;&#23884;&#20837;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Normalising flows are statistical models that transform a complex density into a simpler density through the use of bijective transformations enabling both density estimation and data generation from a single model. In the context of image modelling, the predominant choice has been the Glow-based architecture, whereas alternative architectures remain largely unexplored in the research community. In this work, we propose a novel architecture called MixerFlow, based on the MLP-Mixer architecture, further unifying the generative and discriminative modelling architectures. MixerFlow offers an effective mechanism for weight sharing for flow-based models. Our results demonstrate better density estimation on image datasets under a fixed computational budget and scales well as the image resolution increases, making MixeFlow a powerful yet simple alternative to the Glow-based architectures. We also show that MixerFlow provides more informative embeddings than Glow-based architectures.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#23618;&#27010;&#24565;&#21457;&#29616;&#27169;&#22411;&#65292;&#36890;&#36807;&#21033;&#29992;&#22270;&#20687;&#25991;&#26412;&#27169;&#22411;&#21644;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#36125;&#21494;&#26031;&#21442;&#25968;&#65292;&#23454;&#29616;&#20102;&#22522;&#20110;&#20154;&#31867;&#21487;&#29702;&#35299;&#27010;&#24565;&#30340;&#39640;&#24230;&#21487;&#35299;&#37322;&#30340;&#20915;&#31574;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2310.02116</link><description>&lt;p&gt;
&#20998;&#23618;&#27010;&#24565;&#21457;&#29616;&#27169;&#22411;&#65306;&#19968;&#20010;&#27010;&#24565;&#37329;&#23383;&#22612;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
Hierarchical Concept Discovery Models: A Concept Pyramid Scheme. (arXiv:2310.02116v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02116
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#23618;&#27010;&#24565;&#21457;&#29616;&#27169;&#22411;&#65292;&#36890;&#36807;&#21033;&#29992;&#22270;&#20687;&#25991;&#26412;&#27169;&#22411;&#21644;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#36125;&#21494;&#26031;&#21442;&#25968;&#65292;&#23454;&#29616;&#20102;&#22522;&#20110;&#20154;&#31867;&#21487;&#29702;&#35299;&#27010;&#24565;&#30340;&#39640;&#24230;&#21487;&#35299;&#37322;&#30340;&#20915;&#31574;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#22240;&#20854;&#21331;&#36234;&#30340;&#24615;&#33021;&#32780;&#24341;&#36215;&#20102;&#22823;&#37327;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#39640;&#22797;&#26434;&#24615;&#21644;&#19981;&#21487;&#35299;&#37322;&#30340;&#25805;&#20316;&#26041;&#24335;&#38459;&#30861;&#20102;&#23427;&#20204;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#23433;&#20840;&#20851;&#38190;&#20219;&#21153;&#20013;&#30340;&#33258;&#20449;&#37096;&#32626;&#12290;&#26412;&#30740;&#31350;&#38024;&#23545;&#30340;&#26159;ante hoc&#21487;&#35299;&#37322;&#24615;&#65292;&#20855;&#20307; &#35828;&#26159;&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#65288;CBMs&#65289;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#35774;&#35745;&#19968;&#20010;&#26694;&#26550;&#65292;&#20197;&#22810;&#20010;&#23618;&#27425;&#31890;&#24230;&#19978;&#30340;&#20154;&#31867;&#21487;&#29702;&#35299;&#27010;&#24565;&#20026;&#22522;&#30784;&#65292;&#23454;&#29616;&#39640;&#24230;&#21487;&#35299;&#37322;&#30340;&#20915;&#31574;&#36807;&#31243;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#23618;&#27010;&#24565;&#21457;&#29616;&#26041;&#27861;&#65292;&#21033;&#29992;&#65306;&#65288;i&#65289;&#22270;&#20687;&#25991;&#26412;&#27169;&#22411;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#20197;&#21450;&#65288;ii&#65289;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#21644;&#31232;&#30095;&#35825;&#23548;&#30340;&#36125;&#21494;&#26031;&#21442;&#25968;&#36827;&#34892;&#22810;&#23618;&#27010;&#24565;&#36873;&#25321;&#30340;&#21019;&#26032;&#20844;&#24335;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#20013;&#65292;&#27010;&#24565;&#20449;&#24687;&#19981;&#20165;&#20165;&#20381;&#36182;&#20110;&#25972;&#20307;&#22270;&#20687;&#19982;&#19968;&#33324;&#38750;&#32467;&#26500;&#21270;&#27010;&#24565;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#65307;&#30456;&#21453;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#27010;&#24565;&#23618;&#27425;&#30340;&#27010;&#24565;&#65292;&#20197;&#25581;&#31034;&#21644;&#21033;&#29992;&#26356;&#22810;&#30340;&#32454;&#33410;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep Learning algorithms have recently gained significant attention due to their impressive performance. However, their high complexity and un-interpretable mode of operation hinders their confident deployment in real-world safety-critical tasks. This work targets ante hoc interpretability, and specifically Concept Bottleneck Models (CBMs). Our goal is to design a framework that admits a highly interpretable decision making process with respect to human understandable concepts, on multiple levels of granularity. To this end, we propose a novel hierarchical concept discovery formulation leveraging: (i) recent advances in image-text models, and (ii) an innovative formulation for multi-level concept selection via data-driven and sparsity inducing Bayesian arguments. Within this framework, concept information does not solely rely on the similarity between the whole image and general unstructured concepts; instead, we introduce the notion of concept hierarchy to uncover and exploit more gra
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26680;&#21270;&#24402;&#19968;&#21270;&#27969;&#33539;&#24335;&#65292;&#31216;&#20026;Ferumal&#27969;&#65292;&#23427;&#23558;&#26680;&#20989;&#25968;&#38598;&#25104;&#21040;&#24402;&#19968;&#21270;&#27969;&#30340;&#26694;&#26550;&#20013;&#12290;&#30456;&#23545;&#20110;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#27969;&#65292;&#26680;&#21270;&#27969;&#21487;&#20197;&#22312;&#20302;&#25968;&#25454;&#29615;&#22659;&#20013;&#20135;&#29983;&#31454;&#20105;&#21147;&#25110;&#20248;&#36234;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#20445;&#25345;&#21442;&#25968;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2307.14839</link><description>&lt;p&gt;
&#26680;&#21270;&#24402;&#19968;&#21270;&#27969;
&lt;/p&gt;
&lt;p&gt;
Kernelised Normalising Flows. (arXiv:2307.14839v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14839
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26680;&#21270;&#24402;&#19968;&#21270;&#27969;&#33539;&#24335;&#65292;&#31216;&#20026;Ferumal&#27969;&#65292;&#23427;&#23558;&#26680;&#20989;&#25968;&#38598;&#25104;&#21040;&#24402;&#19968;&#21270;&#27969;&#30340;&#26694;&#26550;&#20013;&#12290;&#30456;&#23545;&#20110;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#27969;&#65292;&#26680;&#21270;&#27969;&#21487;&#20197;&#22312;&#20302;&#25968;&#25454;&#29615;&#22659;&#20013;&#20135;&#29983;&#31454;&#20105;&#21147;&#25110;&#20248;&#36234;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#20445;&#25345;&#21442;&#25968;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24402;&#19968;&#21270;&#27969;&#26159;&#20197;&#20854;&#21487;&#36870;&#30340;&#26550;&#26500;&#32780;&#34987;&#25551;&#36848;&#30340;&#29983;&#25104;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#21487;&#36870;&#24615;&#35201;&#27714;&#23545;&#20854;&#34920;&#36798;&#33021;&#21147;&#26045;&#21152;&#38480;&#21046;&#65292;&#38656;&#35201;&#22823;&#37327;&#30340;&#21442;&#25968;&#21644;&#21019;&#26032;&#30340;&#26550;&#26500;&#35774;&#35745;&#26469;&#36798;&#21040;&#28385;&#24847;&#30340;&#32467;&#26524;&#12290;&#34429;&#28982;&#22522;&#20110;&#27969;&#30340;&#27169;&#22411;&#20027;&#35201;&#20381;&#36182;&#20110;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#36716;&#25442;&#26469;&#23454;&#29616;&#34920;&#36798;&#33021;&#21147;&#65292;&#20294;&#26367;&#20195;&#30340;&#36716;&#25442;&#26041;&#27861;&#21364;&#21463;&#21040;&#20102;&#26377;&#38480;&#30340;&#20851;&#27880;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26680;&#21270;&#24402;&#19968;&#21270;&#27969;&#33539;&#24335;&#65292;&#31216;&#20026;Ferumal&#27969;&#65292;&#23427;&#23558;&#26680;&#20989;&#25968;&#38598;&#25104;&#21040;&#26694;&#26550;&#20013;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#30456;&#27604;&#20110;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#27969;&#65292;&#26680;&#21270;&#27969;&#21487;&#20197;&#20135;&#29983;&#26377;&#31454;&#20105;&#21147;&#25110;&#20248;&#36234;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#20445;&#25345;&#21442;&#25968;&#25928;&#29575;&#12290;&#26680;&#21270;&#27969;&#22312;&#20302;&#25968;&#25454;&#29615;&#22659;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#21487;&#20197;&#22312;&#25968;&#25454;&#31232;&#32570;&#30340;&#24212;&#29992;&#20013;&#36827;&#34892;&#28789;&#27963;&#30340;&#38750;&#21442;&#25968;&#23494;&#24230;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Normalising Flows are generative models characterised by their invertible architecture. However, the requirement of invertibility imposes constraints on their expressiveness, necessitating a large number of parameters and innovative architectural designs to achieve satisfactory outcomes. Whilst flow-based models predominantly rely on neural-network-based transformations for expressive designs, alternative transformation methods have received limited attention. In this work, we present Ferumal flow, a novel kernelised normalising flow paradigm that integrates kernels into the framework. Our results demonstrate that a kernelised flow can yield competitive or superior results compared to neural network-based flows whilst maintaining parameter efficiency. Kernelised flows excel especially in the low-data regime, enabling flexible non-parametric density estimation in applications with sparse data availability.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#20110;&#21452;&#38543;&#26426;&#28857;&#36807;&#31243;&#30340;&#20272;&#35745;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#36827;&#34892;&#21327;&#21464;&#37327;&#25928;&#24212;&#20272;&#35745;&#26102;&#38750;&#24120;&#39640;&#25928;&#65292;&#19981;&#38656;&#35201;&#24378;&#28872;&#30340;&#38480;&#21046;&#24615;&#20551;&#35774;&#65292;&#19988;&#22312;&#29702;&#35770;&#21644;&#23454;&#36341;&#20013;&#22343;&#34920;&#29616;&#20986;&#20102;&#33391;&#22909;&#30340;&#20449;&#24230;&#20445;&#35777;&#21644;&#25928;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.06756</link><description>&lt;p&gt;
&#19968;&#31181;&#23545;&#20110;&#21452;&#38543;&#26426;&#28857;&#36807;&#31243;&#30340;&#39640;&#32500;&#21322;&#21442;&#25968;&#25512;&#29702;&#30340;&#24809;&#32602;&#27850;&#26494;&#20284;&#28982;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
A Penalized Poisson Likelihood Approach to High-Dimensional Semi-Parametric Inference for Doubly-Stochastic Point Processes. (arXiv:2306.06756v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06756
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#20110;&#21452;&#38543;&#26426;&#28857;&#36807;&#31243;&#30340;&#20272;&#35745;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#36827;&#34892;&#21327;&#21464;&#37327;&#25928;&#24212;&#20272;&#35745;&#26102;&#38750;&#24120;&#39640;&#25928;&#65292;&#19981;&#38656;&#35201;&#24378;&#28872;&#30340;&#38480;&#21046;&#24615;&#20551;&#35774;&#65292;&#19988;&#22312;&#29702;&#35770;&#21644;&#23454;&#36341;&#20013;&#22343;&#34920;&#29616;&#20986;&#20102;&#33391;&#22909;&#30340;&#20449;&#24230;&#20445;&#35777;&#21644;&#25928;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21452;&#38543;&#26426;&#28857;&#36807;&#31243;&#23558;&#31354;&#38388;&#22495;&#20869;&#20107;&#20214;&#30340;&#21457;&#29983;&#24314;&#27169;&#20026;&#22312;&#23454;&#29616;&#38543;&#26426;&#24378;&#24230;&#20989;&#25968;&#30340;&#26465;&#20214;&#19979;&#65292;&#19981;&#22343;&#21248;&#27850;&#26494;&#36807;&#31243;&#12290;&#23427;&#20204;&#26159;&#25429;&#25417;&#31354;&#38388;&#24322;&#36136;&#24615;&#21644;&#20381;&#36182;&#24615;&#30340;&#28789;&#27963;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#21452;&#38543;&#26426;&#31354;&#38388;&#27169;&#22411;&#30340;&#23454;&#29616;&#22312;&#35745;&#31639;&#19978;&#26159;&#26377;&#35201;&#27714;&#30340;&#65292;&#24448;&#24448;&#20855;&#26377;&#26377;&#38480;&#30340;&#29702;&#35770;&#20445;&#35777;&#21644;/&#25110;&#20381;&#36182;&#20110;&#20855;&#26377;&#38480;&#21046;&#24615;&#20551;&#35774;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24809;&#32602;&#22238;&#24402;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#21452;&#38543;&#26426;&#28857;&#36807;&#31243;&#20013;&#30340;&#21327;&#21464;&#37327;&#25928;&#24212;&#65292;&#20855;&#26377;&#35745;&#31639;&#25928;&#29575;&#19988;&#19981;&#38656;&#35201;&#22522;&#30784;&#24378;&#24230;&#30340;&#21442;&#25968;&#24418;&#24335;&#25110;&#24179;&#31283;&#24615;&#12290;&#25105;&#20204;&#35777;&#23454;&#20102;&#25152;&#25552;&#20986;&#20272;&#35745;&#22120;&#30340;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#21327;&#26041;&#24046;&#20272;&#35745;&#22120;&#65292;&#23548;&#33268;&#20445;&#23432;&#30340;&#32479;&#35745;&#25512;&#26029;&#31243;&#24207;&#12290;&#27169;&#25311;&#30740;&#31350;&#26174;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#30340;&#38480;&#21046;&#24615;&#36739;&#23567;&#30340;&#24773;&#20917;&#19979;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#19988;&#22312;&#35199;&#38597;&#22270;&#29359;&#32618;&#20107;&#20214;&#30340;&#24212;&#29992;&#20013;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#23454;&#36341;&#20013;&#30340;&#33391;&#22909;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Doubly-stochastic point processes model the occurrence of events over a spatial domain as an inhomogeneous Poisson process conditioned on the realization of a random intensity function. They are flexible tools for capturing spatial heterogeneity and dependence. However, implementations of doubly-stochastic spatial models are computationally demanding, often have limited theoretical guarantee, and/or rely on restrictive assumptions. We propose a penalized regression method for estimating covariate effects in doubly-stochastic point processes that is computationally efficient and does not require a parametric form or stationarity of the underlying intensity. We establish the consistency and asymptotic normality of the proposed estimator, and develop a covariance estimator that leads to a conservative statistical inference procedure. A simulation study shows the validity of our approach under less restrictive assumptions on the data generating mechanism, and an application to Seattle crim
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#28459;&#25193;&#25193;&#25955;&#27169;&#22411;&#21644;&#37319;&#26679;&#22120;&#26041;&#38754;&#36827;&#34892;&#20102;&#34920;&#36798;&#33021;&#21147;&#30340;&#30740;&#31350;&#65292;&#36890;&#36807;&#23558;&#24050;&#30693;&#30340;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#32467;&#26524;&#25193;&#23637;&#21040;&#28459;&#25193;&#25193;&#25955;&#27169;&#22411;&#21644;&#37319;&#26679;&#22120;&#26469;&#23454;&#29616;&#12290;</title><link>http://arxiv.org/abs/2305.09605</link><description>&lt;p&gt;
&#28459;&#25193;&#25193;&#25955;&#27169;&#22411;&#21644;&#37319;&#26679;&#22120;&#30340;&#34920;&#36798;&#33021;&#21147;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Expressiveness Remarks for Denoising Diffusion Models and Samplers. (arXiv:2305.09605v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09605
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#28459;&#25193;&#25193;&#25955;&#27169;&#22411;&#21644;&#37319;&#26679;&#22120;&#26041;&#38754;&#36827;&#34892;&#20102;&#34920;&#36798;&#33021;&#21147;&#30340;&#30740;&#31350;&#65292;&#36890;&#36807;&#23558;&#24050;&#30693;&#30340;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#32467;&#26524;&#25193;&#23637;&#21040;&#28459;&#25193;&#25193;&#25955;&#27169;&#22411;&#21644;&#37319;&#26679;&#22120;&#26469;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28459;&#25193;&#25193;&#25955;&#27169;&#22411;&#26159;&#19968;&#31867;&#29983;&#25104;&#27169;&#22411;&#65292;&#22312;&#35768;&#22810;&#39046;&#22495;&#26368;&#36817;&#24050;&#32463;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;&#36890;&#36807;&#28459;&#25193;&#36807;&#31243;&#36880;&#28176;&#21521;&#25968;&#25454;&#20013;&#28155;&#21152;&#22122;&#22768;&#65292;&#23558;&#25968;&#25454;&#20998;&#24067;&#36716;&#21270;&#20026;&#39640;&#26031;&#20998;&#24067;&#12290;&#28982;&#21518;&#65292;&#36890;&#36807;&#27169;&#25311;&#35813;&#28459;&#25193;&#30340;&#26102;&#38388;&#21453;&#28436;&#30340;&#36924;&#36817;&#26469;&#33719;&#21462;&#29983;&#25104;&#27169;&#22411;&#30340;&#26679;&#26412;&#65292;&#21018;&#24320;&#22987;&#36825;&#20010;&#28459;&#25193;&#27169;&#25311;&#30340;&#21021;&#22987;&#20540;&#26159;&#39640;&#26031;&#26679;&#26412;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#25506;&#32034;&#20102;&#23558;&#28459;&#25193;&#27169;&#22411;&#36866;&#24212;&#20110;&#37319;&#26679;&#21644;&#25512;&#26029;&#20219;&#21153;&#12290;&#26412;&#25991;&#22522;&#20110;&#20247;&#25152;&#21608;&#30693;&#30340;&#19982;F\"ollmer&#28418;&#31227;&#31867;&#20284;&#30340;&#38543;&#26426;&#25511;&#21046;&#32852;&#31995;&#65292;&#23558;&#38024;&#23545;F\"ollmer&#28418;&#31227;&#30340;&#24050;&#30693;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#32467;&#26524;&#25193;&#23637;&#21040;&#28459;&#25193;&#25193;&#25955;&#27169;&#22411;&#21644;&#37319;&#26679;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Denoising diffusion models are a class of generative models which have recently achieved state-of-the-art results across many domains. Gradual noise is added to the data using a diffusion process, which transforms the data distribution into a Gaussian. Samples from the generative model are then obtained by simulating an approximation of the time reversal of this diffusion initialized by Gaussian samples. Recent research has explored adapting diffusion models for sampling and inference tasks. In this paper, we leverage known connections to stochastic control akin to the F\"ollmer drift to extend established neural network approximation results for the F\"ollmer drift to denoising diffusion models and samplers.
&lt;/p&gt;</description></item></channel></rss>