<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#22823;&#25968;&#25454;&#20013;&#23398;&#20064;&#39033;&#30446;&#21453;&#24212;&#29702;&#35770;&#27169;&#22411;&#20013;&#30340;&#28508;&#22312;&#21464;&#37327;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#36825;&#20123;&#27169;&#22411;&#19982;&#36923;&#36753;&#22238;&#24402;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#26469;&#25552;&#39640;&#35745;&#31639;&#30340;&#25928;&#29575;&#21644;&#21487;&#20280;&#32553;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.00680</link><description>&lt;p&gt;
&#21487;&#25193;&#23637;&#30340;&#39033;&#30446;&#21453;&#24212;&#29702;&#35770;&#27169;&#22411;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Scalable Learning of Item Response Theory Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00680
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#22823;&#25968;&#25454;&#20013;&#23398;&#20064;&#39033;&#30446;&#21453;&#24212;&#29702;&#35770;&#27169;&#22411;&#20013;&#30340;&#28508;&#22312;&#21464;&#37327;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#36825;&#20123;&#27169;&#22411;&#19982;&#36923;&#36753;&#22238;&#24402;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#26469;&#25552;&#39640;&#35745;&#31639;&#30340;&#25928;&#29575;&#21644;&#21487;&#20280;&#32553;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39033;&#30446;&#21453;&#24212;&#29702;&#35770;&#65288;IRT&#65289;&#27169;&#22411;&#26088;&#22312;&#35780;&#20272; $n$ &#21517;&#32771;&#29983;&#30340;&#28508;&#22312;&#33021;&#21147;&#20197;&#21450; $m$ &#20010;&#27979;&#39564;&#39033;&#30446;&#30340;&#38544;&#21547;&#38590;&#24230;&#29305;&#24449;&#65292;&#36825;&#20123;&#39033;&#30446;&#26159;&#20174;&#34920;&#26126;&#20854;&#23545;&#24212;&#31572;&#26696;&#36136;&#37327;&#30340;&#20998;&#31867;&#25968;&#25454;&#20013;&#24471;&#20986;&#30340;&#12290;&#20256;&#32479;&#30340;&#24515;&#29702;&#27979;&#37327;&#35780;&#20272;&#22522;&#20110;&#30456;&#23545;&#36739;&#23569;&#30340;&#32771;&#29983;&#21644;&#39033;&#30446;&#65292;&#20363;&#22914;&#19968;&#20010;&#30001; $200$ &#21517;&#23398;&#29983;&#35299;&#20915;&#21253;&#21547; $10$ &#36947;&#39064;&#30446;&#30340;&#32771;&#35797;&#30340;&#29677;&#32423;&#12290;&#32780;&#36817;&#24180;&#26469;&#30340;&#20840;&#29699;&#22823;&#35268;&#27169;&#35780;&#20272;&#65292;&#22914;PISA&#65292;&#25110;&#20114;&#32852;&#32593;&#30740;&#31350;&#65292;&#21487;&#33021;&#23548;&#33268;&#21442;&#19982;&#32773;&#25968;&#37327;&#26174;&#33879;&#22686;&#21152;&#12290;&#27492;&#22806;&#65292;&#22312;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#65292;&#31639;&#27861;&#25198;&#28436;&#32771;&#29983;&#35282;&#33394;&#65292;&#25968;&#25454;&#20998;&#26512;&#38382;&#39064;&#25198;&#28436;&#39033;&#30446;&#35282;&#33394;&#65292;$n$ &#21644; $m$ &#37117;&#21487;&#33021;&#21464;&#24471;&#38750;&#24120;&#22823;&#65292;&#25361;&#25112;&#35745;&#31639;&#30340;&#25928;&#29575;&#21644;&#21487;&#20280;&#32553;&#24615;&#12290;&#20026;&#20102;&#20174;&#22823;&#25968;&#25454;&#20013;&#23398;&#20064;IRT&#27169;&#22411;&#20013;&#30340;&#28508;&#22312;&#21464;&#37327;&#65292;&#25105;&#20204;&#21033;&#29992;&#36825;&#20123;&#27169;&#22411;&#19982;&#36923;&#36753;&#22238;&#24402;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#65292;&#21518;&#32773;&#21487;&#20197;&#20351;&#29992;s&#20934;&#30830;&#22320;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00680v1 Announce Type: new  Abstract: Item Response Theory (IRT) models aim to assess latent abilities of $n$ examinees along with latent difficulty characteristics of $m$ test items from categorical data that indicates the quality of their corresponding answers. Classical psychometric assessments are based on a relatively small number of examinees and items, say a class of $200$ students solving an exam comprising $10$ problems. More recent global large scale assessments such as PISA, or internet studies, may lead to significantly increased numbers of participants. Additionally, in the context of Machine Learning where algorithms take the role of examinees and data analysis problems take the role of items, both $n$ and $m$ may become very large, challenging the efficiency and scalability of computations. To learn the latent variables in IRT models from large data, we leverage the similarity of these models to logistic regression, which can be approximated accurately using s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;&#22240;&#26524;&#35780;&#20998;&#20316;&#20026;&#19968;&#31181;&#26032;&#22411;&#26041;&#27861;&#65292;&#25903;&#25345;&#20915;&#31574;&#21046;&#23450;&#65292;&#25552;&#20379;&#27934;&#23519;&#21147;&#65292;&#24182;&#21487;&#29992;&#20110;&#25928;&#24212;&#20272;&#35745;&#12289;&#25928;&#24212;&#25490;&#24207;&#21644;&#25928;&#24212;&#20998;&#31867;&#12290;</title><link>https://arxiv.org/abs/2206.12532</link><description>&lt;p&gt;
&#22240;&#26524;&#35780;&#20998;&#65306;&#25928;&#24212;&#20272;&#35745;&#12289;&#25928;&#24212;&#25490;&#24207;&#21644;&#25928;&#24212;&#20998;&#31867;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Causal Scoring: A Framework for Effect Estimation, Effect Ordering, and Effect Classification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2206.12532
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#22240;&#26524;&#35780;&#20998;&#20316;&#20026;&#19968;&#31181;&#26032;&#22411;&#26041;&#27861;&#65292;&#25903;&#25345;&#20915;&#31574;&#21046;&#23450;&#65292;&#25552;&#20379;&#27934;&#23519;&#21147;&#65292;&#24182;&#21487;&#29992;&#20110;&#25928;&#24212;&#20272;&#35745;&#12289;&#25928;&#24212;&#25490;&#24207;&#21644;&#25928;&#24212;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#22240;&#26524;&#35780;&#20998;&#24341;&#20837;&#21040;&#20915;&#31574;&#21046;&#23450;&#30340;&#32972;&#26223;&#20013;&#20316;&#20026;&#19968;&#31181;&#26032;&#39062;&#26041;&#27861;&#65292;&#28041;&#21450;&#20272;&#35745;&#25903;&#25345;&#20915;&#31574;&#21046;&#23450;&#30340;&#24471;&#20998;&#65292;&#20174;&#32780;&#25552;&#20379;&#22240;&#26524;&#25928;&#24212;&#30340;&#27934;&#23519;&#21147;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#36825;&#20123;&#35780;&#20998;&#30340;&#19977;&#31181;&#26377;&#20215;&#20540;&#30340;&#22240;&#26524;&#35299;&#37322;&#65306;&#25928;&#24212;&#20272;&#35745;&#65288;EE&#65289;&#12289;&#25928;&#24212;&#25490;&#24207;&#65288;EO&#65289;&#21644;&#25928;&#24212;&#20998;&#31867;&#65288;EC&#65289;&#12290;&#22312;EE&#35299;&#37322;&#20013;&#65292;&#22240;&#26524;&#35780;&#20998;&#20195;&#34920;&#20102;&#25928;&#24212;&#26412;&#36523;&#12290;EO&#35299;&#37322;&#26263;&#31034;&#35780;&#20998;&#21487;&#20197;&#20316;&#20026;&#25928;&#24212;&#22823;&#23567;&#30340;&#20195;&#29702;&#65292;&#21487;&#20197;&#26681;&#25454;&#20854;&#22240;&#26524;&#25928;&#24212;&#23545;&#20010;&#20307;&#36827;&#34892;&#25490;&#24207;&#12290;EC&#35299;&#37322;&#36890;&#36807;&#39044;&#23450;&#20041;&#30340;&#38408;&#20540;&#65292;&#20351;&#20010;&#20307;&#20998;&#20026;&#39640;&#25928;&#24212;&#21644;&#20302;&#25928;&#24212;&#31867;&#21035;&#12290;&#25105;&#20204;&#36890;&#36807;&#20004;&#20010;&#20851;&#38190;&#32467;&#26524;&#23637;&#31034;&#20102;&#36825;&#20123;&#26367;&#20195;&#22240;&#26524;&#35299;&#37322;&#65288;EO&#21644;EC&#65289;&#30340;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2206.12532v4 Announce Type: replace-cross  Abstract: This paper introduces causal scoring as a novel approach to frame causal estimation in the context of decision making. Causal scoring entails the estimation of scores that support decision making by providing insights into causal effects. We present three valuable causal interpretations of these scores: effect estimation (EE), effect ordering (EO), and effect classification (EC). In the EE interpretation, the causal score represents the effect itself. The EO interpretation implies that the score can serve as a proxy for the magnitude of the effect, enabling the sorting of individuals based on their causal effects. The EC interpretation enables the classification of individuals into high- and low-effect categories using a predefined threshold. We demonstrate the value of these alternative causal interpretations (EO and EC) through two key results. First, we show that aligning the statistical modeling with the desired causal inte
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21453;&#36716;&#20272;&#35745;&#26041;&#31243;&#30340;&#36890;&#29992;&#26041;&#27861;&#65292;&#23558;&#20174;&#20272;&#35745;&#28508;&#22312;&#32467;&#26524;&#22343;&#20540;&#30340;&#22240;&#26524;&#25512;&#26029;&#35299;&#20915;&#26041;&#26696;&#25512;&#24191;&#21040;&#20854;&#20998;&#20301;&#25968;&#65292;&#21516;&#26102;&#32473;&#20986;&#20102;&#28508;&#22312;&#32467;&#26524;&#22343;&#20540;&#21644;&#20998;&#20301;&#25968;&#30340;&#26377;&#25928;&#24433;&#21709;&#20989;&#25968;&#30340;&#19968;&#33324;&#26500;&#36896;&#21644;&#32852;&#31995;&#12290;</title><link>http://arxiv.org/abs/2401.00987</link><description>&lt;p&gt;
&#21453;&#36716;&#20272;&#35745;&#26041;&#31243;&#23545;&#28508;&#22312;&#32467;&#26524;&#20998;&#20301;&#25968;&#30340;&#22240;&#26524;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Inverting estimating equations for causal inference on quantiles. (arXiv:2401.00987v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.00987
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21453;&#36716;&#20272;&#35745;&#26041;&#31243;&#30340;&#36890;&#29992;&#26041;&#27861;&#65292;&#23558;&#20174;&#20272;&#35745;&#28508;&#22312;&#32467;&#26524;&#22343;&#20540;&#30340;&#22240;&#26524;&#25512;&#26029;&#35299;&#20915;&#26041;&#26696;&#25512;&#24191;&#21040;&#20854;&#20998;&#20301;&#25968;&#65292;&#21516;&#26102;&#32473;&#20986;&#20102;&#28508;&#22312;&#32467;&#26524;&#22343;&#20540;&#21644;&#20998;&#20301;&#25968;&#30340;&#26377;&#25928;&#24433;&#21709;&#20989;&#25968;&#30340;&#19968;&#33324;&#26500;&#36896;&#21644;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#25512;&#26029;&#25991;&#29486;&#32463;&#24120;&#20851;&#27880;&#28508;&#22312;&#32467;&#26524;&#30340;&#22343;&#20540;&#20272;&#35745;&#65292;&#32780;&#28508;&#22312;&#32467;&#26524;&#30340;&#20998;&#20301;&#25968;&#21487;&#33021;&#21253;&#21547;&#37325;&#35201;&#30340;&#39069;&#22806;&#20449;&#24687;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21453;&#36716;&#20272;&#35745;&#26041;&#31243;&#30340;&#36890;&#29992;&#26041;&#27861;&#65292;&#23558;&#20174;&#20272;&#35745;&#28508;&#22312;&#32467;&#26524;&#22343;&#20540;&#30340;&#24191;&#27867;&#31867;&#21035;&#30340;&#22240;&#26524;&#25512;&#26029;&#35299;&#20915;&#26041;&#26696;&#25512;&#24191;&#21040;&#20854;&#20998;&#20301;&#25968;&#12290;&#25105;&#20204;&#20551;&#35774;&#23384;&#22312;&#19968;&#20010;&#21487;&#29992;&#26469;&#30830;&#23450;&#22522;&#20110;&#38408;&#20540;&#21464;&#25442;&#30340;&#28508;&#22312;&#32467;&#26524;&#22343;&#20540;&#30340;&#30830;&#23450;&#30697;&#20989;&#25968;&#65292;&#24182;&#22312;&#27492;&#22522;&#30784;&#19978;&#25552;&#20986;&#20102;&#28508;&#22312;&#32467;&#26524;&#20998;&#20301;&#25968;&#30340;&#20272;&#35745;&#26041;&#31243;&#30340;&#20415;&#21033;&#26500;&#36896;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#32473;&#20986;&#20102;&#28508;&#22312;&#32467;&#26524;&#22343;&#20540;&#21644;&#20998;&#20301;&#25968;&#30340;&#26377;&#25928;&#24433;&#21709;&#20989;&#25968;&#30340;&#19968;&#33324;&#26500;&#36896;&#65292;&#24182;&#30830;&#23450;&#20102;&#23427;&#20204;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;&#25105;&#20204;&#36890;&#36807;&#26377;&#25928;&#24433;&#21709;&#20989;&#25968;&#25512;&#23548;&#20986;&#20998;&#20301;&#25968;&#30446;&#26631;&#30340;&#20272;&#35745;&#22120;&#65292;&#24182;&#22312;&#20351;&#29992;&#21442;&#25968;&#27169;&#22411;&#25110;&#25968;&#25454;&#33258;&#36866;&#24212;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#26102;&#24320;&#21457;&#20854;&#28176;&#36817;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
The causal inference literature frequently focuses on estimating the mean of the potential outcome, whereas the quantiles of the potential outcome may carry important additional information. We propose a universal approach, based on the inverse estimating equations, to generalize a wide class of causal inference solutions from estimating the mean of the potential outcome to its quantiles. We assume that an identifying moment function is available to identify the mean of the threshold-transformed potential outcome, based on which a convenient construction of the estimating equation of quantiles of potential outcome is proposed. In addition, we also give a general construction of the efficient influence functions of the mean and quantiles of potential outcomes, and identify their connection. We motivate estimators for the quantile estimands with the efficient influence function, and develop their asymptotic properties when either parametric models or data-adaptive machine learners are us
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25581;&#31034;&#20102;&#28145;&#24230;&#23398;&#20064;&#31070;&#32463;&#32593;&#36335;&#23398;&#20064;&#36755;&#20837;&#20302;&#32500;&#24230;&#34920;&#31034;&#21644;&#26368;&#23567;&#21270;&#29305;&#24449;&#26144;&#23556;&#20013;&#30340;&#22797;&#26434;&#24615;/&#19981;&#35268;&#21017;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#25511;&#21046;&#20102;&#35268;&#24459;&#24615;&#65292;&#24182;&#21033;&#29992;&#29702;&#35770;&#24037;&#20855;&#35777;&#26126;&#20102;&#29942;&#39048;&#32467;&#26500;&#30340;&#23384;&#22312;&#12290;</title><link>http://arxiv.org/abs/2305.19008</link><description>&lt;p&gt;
&#23398;&#20064;&#29305;&#24449;&#20013;&#30340;&#29942;&#39048;&#32467;&#26500;&#65306;&#20302;&#32500;&#24230;&#19982;&#35268;&#24459;&#24615;&#30340;&#26435;&#34913;
&lt;/p&gt;
&lt;p&gt;
Bottleneck Structure in Learned Features: Low-Dimension vs Regularity Tradeoff. (arXiv:2305.19008v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19008
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25581;&#31034;&#20102;&#28145;&#24230;&#23398;&#20064;&#31070;&#32463;&#32593;&#36335;&#23398;&#20064;&#36755;&#20837;&#20302;&#32500;&#24230;&#34920;&#31034;&#21644;&#26368;&#23567;&#21270;&#29305;&#24449;&#26144;&#23556;&#20013;&#30340;&#22797;&#26434;&#24615;/&#19981;&#35268;&#21017;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#25511;&#21046;&#20102;&#35268;&#24459;&#24615;&#65292;&#24182;&#21033;&#29992;&#29702;&#35770;&#24037;&#20855;&#35777;&#26126;&#20102;&#29942;&#39048;&#32467;&#26500;&#30340;&#23384;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#21069;&#30740;&#31350;&#34920;&#26126;&#65292;&#20855;&#26377;&#22823;&#28145;&#24230;$L$&#21644;$L_{2}$&#27491;&#21017;&#21270;&#30340;DNN&#20559;&#21521;&#20110;&#23398;&#20064;&#36755;&#20837;&#30340;&#20302;&#32500;&#34920;&#31034;&#65292;&#21487;&#20197;&#35299;&#37322;&#20026;&#26368;&#23567;&#21270;&#23398;&#20064;&#20989;&#25968;$f$&#30340;&#31209;$R^{(0)}(f)$&#30340;&#27010;&#24565;&#65292;&#20854;&#34987;&#25512;&#27979;&#20026;&#29942;&#39048;&#31209;&#12290;&#25105;&#20204;&#35745;&#31639;&#20102;&#36825;&#20010;&#32467;&#26524;&#30340;&#26377;&#38480;&#28145;&#24230;&#20462;&#27491;&#65292;&#25581;&#31034;&#20102;&#19968;&#20010;&#24230;&#37327;$R^{(1)}$&#30340;&#35268;&#24459;&#24615;&#65292;&#23427;&#25511;&#21046;&#20102;&#38597;&#21487;&#27604;&#30697;&#38453;$\left|Jf(x)\right|_{+}$&#30340;&#20266;&#34892;&#21015;&#24335;&#24182;&#22312;&#32452;&#21512;&#21644;&#21152;&#27861;&#19979;&#26159;&#27425;&#21487;&#21152;&#30340;&#12290;&#36825;&#20351;&#24471;&#32593;&#32476;&#21487;&#20197;&#22312;&#23398;&#20064;&#20302;&#32500;&#34920;&#31034;&#21644;&#26368;&#23567;&#21270;&#29305;&#24449;&#26144;&#23556;&#20013;&#30340;&#22797;&#26434;&#24615;/&#19981;&#35268;&#21017;&#24615;&#20043;&#38388;&#20445;&#25345;&#24179;&#34913;&#65292;&#20174;&#32780;&#23398;&#20064;&#8220;&#27491;&#30830;&#8221;&#30340;&#20869;&#37096;&#23610;&#23544;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22823;&#23398;&#20064;&#36895;&#29575;&#22914;&#20309;&#25511;&#21046;&#23398;&#20064;&#20989;&#25968;&#30340;&#35268;&#24459;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#36825;&#20123;&#29702;&#35770;&#24037;&#20855;&#35777;&#26126;&#20102;&#29942;&#39048;&#32467;&#26500;&#22312;$L\to\infty$&#26102;&#22312;&#23398;&#20064;&#29305;&#24449;&#20013;&#30340;&#29468;&#24819;&#65306;&#23545;&#20110;&#22823;&#28145;&#24230;&#65292;&#20960;&#20046;&#25152;&#26377;&#30340;&#38544;&#34255;&#34920;&#31034;&#37117;&#38598;&#20013;&#22312;...
&lt;/p&gt;
&lt;p&gt;
Previous work has shown that DNNs with large depth $L$ and $L_{2}$-regularization are biased towards learning low-dimensional representations of the inputs, which can be interpreted as minimizing a notion of rank $R^{(0)}(f)$ of the learned function $f$, conjectured to be the Bottleneck rank. We compute finite depth corrections to this result, revealing a measure $R^{(1)}$ of regularity which bounds the pseudo-determinant of the Jacobian $\left|Jf(x)\right|_{+}$ and is subadditive under composition and addition. This formalizes a balance between learning low-dimensional representations and minimizing complexity/irregularity in the feature maps, allowing the network to learn the `right' inner dimension. We also show how large learning rates also control the regularity of the learned function. Finally, we use these theoretical tools to prove the conjectured bottleneck structure in the learned features as $L\to\infty$: for large depths, almost all hidden representations concentrates aroun
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;Wasserstein&#39640;&#26031;&#21270;&#36716;&#25442;&#30340;&#36716;&#25442;&#26041;&#27861;&#65292;&#29992;&#20110;&#38024;&#23545;&#36125;&#21494;&#26031;&#21512;&#25104;&#20284;&#28982;(BSL)&#20013;&#27719;&#24635;&#32479;&#35745;&#37327;&#30340;&#20998;&#24067;&#38382;&#39064;&#12290;&#23558;Wasserstein&#39640;&#26031;&#21270;&#36716;&#25442;&#19982;&#40065;&#26834;BSL&#21644;&#39640;&#25928;&#30340;&#21464;&#20998;&#36125;&#21494;&#26031;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#39640;&#25928;&#21487;&#38752;&#30340;&#36866;&#29992;&#20110;&#26080;&#20284;&#28982;&#38382;&#39064;&#30340;&#36817;&#20284;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.14746</link><description>&lt;p&gt;
Wasserstein&#39640;&#26031;&#36716;&#25442;&#21644;&#40065;&#26834;&#36125;&#21494;&#26031;&#21512;&#25104;&#20284;&#28982;&#30340;&#39640;&#25928;&#21464;&#20998;&#36125;&#21494;&#26031;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Wasserstein Gaussianization and Efficient Variational Bayes for Robust Bayesian Synthetic Likelihood. (arXiv:2305.14746v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14746
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;Wasserstein&#39640;&#26031;&#21270;&#36716;&#25442;&#30340;&#36716;&#25442;&#26041;&#27861;&#65292;&#29992;&#20110;&#38024;&#23545;&#36125;&#21494;&#26031;&#21512;&#25104;&#20284;&#28982;(BSL)&#20013;&#27719;&#24635;&#32479;&#35745;&#37327;&#30340;&#20998;&#24067;&#38382;&#39064;&#12290;&#23558;Wasserstein&#39640;&#26031;&#21270;&#36716;&#25442;&#19982;&#40065;&#26834;BSL&#21644;&#39640;&#25928;&#30340;&#21464;&#20998;&#36125;&#21494;&#26031;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#39640;&#25928;&#21487;&#38752;&#30340;&#36866;&#29992;&#20110;&#26080;&#20284;&#28982;&#38382;&#39064;&#30340;&#36817;&#20284;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#21512;&#25104;&#20284;&#28982;(BSL)&#26041;&#27861;&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#26080;&#20284;&#28982;&#36125;&#21494;&#26031;&#25512;&#26029;&#24037;&#20855;&#12290;&#35813;&#26041;&#27861;&#20551;&#23450;&#26576;&#20123;&#27719;&#24635;&#32479;&#35745;&#37327;&#26381;&#20174;&#27491;&#24577;&#20998;&#24067;&#65292;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#21487;&#33021;&#26159;&#19981;&#27491;&#30830;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;Wasserstein&#39640;&#26031;&#21270;&#36716;&#25442;&#30340;&#36716;&#25442;&#26041;&#27861;&#65292;&#20351;&#29992;Wasserstein&#26799;&#24230;&#27969;&#23558;&#27719;&#24635;&#32479;&#35745;&#37327;&#30340;&#20998;&#24067;&#36817;&#20284;&#36716;&#25442;&#20026;&#27491;&#24577;&#20998;&#24067;&#12290;BSL&#38544;&#21547;&#22320;&#35201;&#27714;&#27169;&#25311;&#27719;&#24635;&#32479;&#35745;&#37327;&#22312;&#24037;&#20316;&#27169;&#22411;&#19979;&#19982;&#35266;&#23519;&#21040;&#30340;&#27719;&#24635;&#32479;&#35745;&#37327;&#20860;&#23481;&#12290;&#36817;&#26399;&#24050;&#24320;&#21457;&#20102;&#19968;&#31181;&#40065;&#26834;&#30340;BSL&#21464;&#20307;&#26469;&#23454;&#29616;&#36825;&#19968;&#28857;&#12290;&#25105;&#20204;&#23558;Wasserstein&#39640;&#26031;&#21270;&#36716;&#25442;&#19982;&#40065;&#26834;BSL&#20197;&#21450;&#39640;&#25928;&#30340;&#21464;&#20998;&#36125;&#21494;&#26031;&#36807;&#31243;&#32467;&#21512;&#36215;&#26469;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#39640;&#25928;&#21487;&#38752;&#30340;&#36866;&#29992;&#20110;&#26080;&#20284;&#28982;&#38382;&#39064;&#30340;&#36817;&#20284;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Bayesian Synthetic Likelihood (BSL) method is a widely-used tool for likelihood-free Bayesian inference. This method assumes that some summary statistics are normally distributed, which can be incorrect in many applications. We propose a transformation, called the Wasserstein Gaussianization transformation, that uses a Wasserstein gradient flow to approximately transform the distribution of the summary statistics into a Gaussian distribution. BSL also implicitly requires compatibility between simulated summary statistics under the working model and the observed summary statistics. A robust BSL variant which achieves this has been developed in the recent literature. We combine the Wasserstein Gaussianization transformation with robust BSL, and an efficient Variational Bayes procedure for posterior approximation, to develop a highly efficient and reliable approximate Bayesian inference method for likelihood-free problems.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#21644;&#31639;&#27861;&#65292;&#20174;&#38750;&#20984;&#20248;&#21270;&#30340;&#35282;&#24230;&#26469;&#36827;&#34892;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#21387;&#32553;&#12290;&#31639;&#27861;&#35299;&#20915;&#20102;&#26799;&#24230;&#28040;&#22833;/&#29190;&#28856;&#38382;&#39064;&#65292;&#24182;&#20445;&#35777;&#20102;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.06815</link><description>&lt;p&gt;
&#20851;&#20110;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#21387;&#32553;&#30340;&#26694;&#26550;&#12289;&#31639;&#27861;&#21644;&#25910;&#25947;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
On Model Compression for Neural Networks: Framework, Algorithm, and Convergence Guarantee. (arXiv:2303.06815v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06815
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#21644;&#31639;&#27861;&#65292;&#20174;&#38750;&#20984;&#20248;&#21270;&#30340;&#35282;&#24230;&#26469;&#36827;&#34892;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#21387;&#32553;&#12290;&#31639;&#27861;&#35299;&#20915;&#20102;&#26799;&#24230;&#28040;&#22833;/&#29190;&#28856;&#38382;&#39064;&#65292;&#24182;&#20445;&#35777;&#20102;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#22411;&#21387;&#32553;&#23545;&#20110;&#37096;&#32626;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#33267;&#20851;&#37325;&#35201;&#65292;&#29305;&#21035;&#26159;&#22312;&#35768;&#22810;&#24212;&#29992;&#31243;&#24207;&#20013;&#35745;&#31639;&#35774;&#22791;&#30340;&#20869;&#23384;&#21644;&#23384;&#20648;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#12290;&#26412;&#25991;&#20851;&#27880;&#20004;&#31181;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#21387;&#32553;&#25216;&#26415;&#65306;&#20302;&#31209;&#36924;&#36817;&#21644;&#26435;&#37325;&#35009;&#21098;&#65292;&#36825;&#20123;&#25216;&#26415;&#30446;&#21069;&#38750;&#24120;&#27969;&#34892;&#12290;&#28982;&#32780;&#65292;&#20351;&#29992;&#20302;&#31209;&#36924;&#36817;&#21644;&#26435;&#37325;&#35009;&#21098;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#24635;&#26159;&#20250;&#36973;&#21463;&#26174;&#33879;&#30340;&#20934;&#30830;&#24615;&#25439;&#22833;&#21644;&#25910;&#25947;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#26694;&#26550;&#65292;&#20174;&#38750;&#20984;&#20248;&#21270;&#30340;&#26032;&#35270;&#35282;&#35774;&#35745;&#20102;&#36866;&#24403;&#30340;&#30446;&#26631;&#20989;&#25968;&#26469;&#36827;&#34892;&#27169;&#22411;&#21387;&#32553;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22359;&#22352;&#26631;&#19979;&#38477;&#65288;BCD&#65289;&#31639;&#27861;NN-BCD&#26469;&#35299;&#20915;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#31639;&#27861;&#30340;&#19968;&#20010;&#20248;&#28857;&#26159;&#21487;&#20197;&#33719;&#24471;&#20855;&#26377;&#38381;&#24335;&#24418;&#24335;&#30340;&#39640;&#25928;&#36845;&#20195;&#26041;&#26696;&#65292;&#20174;&#32780;&#36991;&#20813;&#20102;&#26799;&#24230;&#28040;&#22833;/&#29190;&#28856;&#30340;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#21033;&#29992;&#20102;Kurdyka-{\L}ojasiewicz (K{\L})&#24615;&#36136;&#65292;&#20445;&#35777;&#20102;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model compression is a crucial part of deploying neural networks (NNs), especially when the memory and storage of computing devices are limited in many applications. This paper focuses on two model compression techniques: low-rank approximation and weight pruning in neural networks, which are very popular nowadays. However, training NN with low-rank approximation and weight pruning always suffers significant accuracy loss and convergence issues. In this paper, a holistic framework is proposed for model compression from a novel perspective of nonconvex optimization by designing an appropriate objective function. Then, we introduce NN-BCD, a block coordinate descent (BCD) algorithm to solve the nonconvex optimization. One advantage of our algorithm is that an efficient iteration scheme can be derived with closed-form, which is gradient-free. Therefore, our algorithm will not suffer from vanishing/exploding gradient problems. Furthermore, with the Kurdyka-{\L}ojasiewicz (K{\L}) property o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#28145;&#24230;&#36864;&#21270;&#29616;&#35937;&#65292;&#22312;&#20840;&#36830;&#25509;ReLU&#32593;&#32476;&#21021;&#22987;&#21270;&#26102;&#65292;&#20004;&#20010;&#36755;&#20837;&#20043;&#38388;&#30340;&#35282;&#24230;&#20250;&#36235;&#36817;&#20110;0&#12290;&#36890;&#36807;&#20351;&#29992;&#32452;&#21512;&#23637;&#24320;&#65292;&#24471;&#21040;&#20102;&#20854;&#36235;&#21521;&#20110;0&#30340;&#36895;&#24230;&#30340;&#31934;&#30830;&#20844;&#24335;&#65292;&#24182;&#39564;&#35777;&#20102;&#36825;&#20123;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2302.09712</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#28145;&#24230;&#36864;&#21270;&#65306;&#20840;&#36830;&#25509;ReLU&#32593;&#32476;&#21021;&#22987;&#21270;&#26102;&#65292;&#28040;&#22833;&#35282;&#24230;&#30340;&#29616;&#35937; (arXiv:2302.09712v2 [stat.ML] &#26356;&#26032;&#29256;)
&lt;/p&gt;
&lt;p&gt;
Depth Degeneracy in Neural Networks: Vanishing Angles in Fully Connected ReLU Networks on Initialization. (arXiv:2302.09712v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09712
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#28145;&#24230;&#36864;&#21270;&#29616;&#35937;&#65292;&#22312;&#20840;&#36830;&#25509;ReLU&#32593;&#32476;&#21021;&#22987;&#21270;&#26102;&#65292;&#20004;&#20010;&#36755;&#20837;&#20043;&#38388;&#30340;&#35282;&#24230;&#20250;&#36235;&#36817;&#20110;0&#12290;&#36890;&#36807;&#20351;&#29992;&#32452;&#21512;&#23637;&#24320;&#65292;&#24471;&#21040;&#20102;&#20854;&#36235;&#21521;&#20110;0&#30340;&#36895;&#24230;&#30340;&#31934;&#30830;&#20844;&#24335;&#65292;&#24182;&#39564;&#35777;&#20102;&#36825;&#20123;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#21508;&#31181;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#35768;&#22810;&#20854;&#24615;&#36136;&#20173;&#26410;&#34987;&#29702;&#35770;&#19978;&#29702;&#35299;&#65292;&#20854;&#20013;&#19968;&#20010;&#35868;&#22242;&#26159;&#28145;&#24230;&#36864;&#21270;&#29616;&#35937;&#65306;&#32593;&#32476;&#23618;&#25968;&#36234;&#28145;&#65292;&#21021;&#22987;&#21270;&#26102;&#32593;&#32476;&#36234;&#25509;&#36817;&#20110;&#24120;&#25968;&#20989;&#25968;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;ReLU&#31070;&#32463;&#32593;&#32476;&#20004;&#20010;&#36755;&#20837;&#20043;&#38388;&#38543;&#30528;&#23618;&#25968;&#21464;&#21270;&#30340;&#35282;&#24230;&#28436;&#21464;&#24773;&#20917;&#12290;&#36890;&#36807;&#20351;&#29992;&#32452;&#21512;&#23637;&#24320;&#65292;&#25105;&#20204;&#25214;&#21040;&#20102;&#23427;&#38543;&#28145;&#24230;&#22686;&#21152;&#36235;&#21521;&#20110;0&#30340;&#36895;&#24230;&#30340;&#31934;&#30830;&#20844;&#24335;&#65292;&#36825;&#20123;&#20844;&#24335;&#25429;&#25417;&#20102;&#24494;&#35266;&#27874;&#21160;&#12290;&#25105;&#20204;&#29992;Monte Carlo&#23454;&#39564;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#24182;&#35777;&#26126;&#20102;&#32467;&#26524;&#20934;&#30830;&#22320;&#36817;&#20284;&#20102;&#26377;&#38480;&#32593;&#32476;&#30340;&#34892;&#20026;&#12290;&#36825;&#20123;&#20844;&#24335;&#20197;&#36890;&#36807;ReLU&#20989;&#25968;&#30340;&#30456;&#20851;&#39640;&#26031;&#21464;&#37327;&#30340;&#28151;&#21512;&#30697;&#24418;&#24335;&#32473;&#20986;&#12290;&#25105;&#20204;&#36824;&#21457;&#29616;&#20102;&#19968;&#20010;&#20196;&#20154;&#24778;&#35766;&#30340;&#32452;&#21512;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite remarkable performance on a variety of tasks, many properties of deep neural networks are not yet theoretically understood. One such mystery is the depth degeneracy phenomenon: the deeper you make your network, the closer your network is to a constant function on initialization. In this paper, we examine the evolution of the angle between two inputs to a ReLU neural network as a function of the number of layers. By using combinatorial expansions, we find precise formulas for how fast this angle goes to zero as depth increases. These formulas capture microscopic fluctuations that are not visible in the popular framework of infinite width limits, and leads to qualitatively different predictions. We validate our theoretical results with Monte Carlo experiments and show that our results accurately approximate finite network behaviour. The formulas are given in terms of the mixed moments of correlated Gaussians passed through the ReLU function. We also find a surprising combinatoria
&lt;/p&gt;</description></item></channel></rss>