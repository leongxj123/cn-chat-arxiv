<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26426;&#22120;&#23398;&#20064;&#36741;&#21161;&#35843;&#25972;&#30340;&#25512;&#26029;&#31243;&#24207;&#65292;&#21487;&#20197;&#25552;&#39640;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#30340;&#25512;&#26029;&#25928;&#29575;&#65292;&#24182;&#22312;&#26679;&#26412;&#37327;&#21644;&#25104;&#26412;&#26041;&#38754;&#26377;&#26174;&#33879;&#30340;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2403.03058</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#36741;&#21161;&#35843;&#25972;&#25552;&#21319;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#30340;&#25512;&#26029;&#25928;&#29575;
&lt;/p&gt;
&lt;p&gt;
Machine Learning Assisted Adjustment Boosts Inferential Efficiency of Randomized Controlled Trials
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03058
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26426;&#22120;&#23398;&#20064;&#36741;&#21161;&#35843;&#25972;&#30340;&#25512;&#26029;&#31243;&#24207;&#65292;&#21487;&#20197;&#25552;&#39640;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#30340;&#25512;&#26029;&#25928;&#29575;&#65292;&#24182;&#22312;&#26679;&#26412;&#37327;&#21644;&#25104;&#26412;&#26041;&#38754;&#26377;&#26174;&#33879;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25512;&#26029;&#31243;&#24207;&#65292;&#35813;&#31243;&#24207;&#37319;&#29992;&#20102;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#35843;&#25972;&#26041;&#27861;&#65292;&#29992;&#20110;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#12290;&#35813;&#26041;&#27861;&#26159;&#22312;&#32599;&#26862;&#40077;&#22982;&#30340;&#22522;&#20110;&#21327;&#21464;&#37327;&#35843;&#25972;&#30340;&#38543;&#26426;&#23454;&#39564;&#30340;&#30830;&#20999;&#26816;&#39564;&#26694;&#26550;&#19979;&#24320;&#21457;&#30340;&#12290;&#36890;&#36807;&#22823;&#37327;&#30340;&#27169;&#25311;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#31283;&#20581;&#22320;&#25511;&#21046;&#31532;&#19968;&#31867;&#38169;&#35823;&#65292;&#24182;&#21487;&#20197;&#25552;&#39640;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;(RCT)&#30340;&#25512;&#26029;&#25928;&#29575;&#12290;&#36825;&#19968;&#20248;&#21183;&#22312;&#19968;&#20010;&#30495;&#23454;&#26696;&#20363;&#20013;&#36827;&#19968;&#27493;&#24471;&#21040;&#20102;&#35777;&#26126;&#12290;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#31616;&#21333;&#24615;&#21644;&#31283;&#20581;&#24615;&#20351;&#20854;&#25104;&#20026;&#19968;&#31181;&#31454;&#20105;&#24615;&#20505;&#36873;&#20316;&#20026;RCT&#30340;&#24120;&#35268;&#25512;&#26029;&#31243;&#24207;&#65292;&#29305;&#21035;&#26159;&#24403;&#22522;&#32447;&#21327;&#21464;&#37327;&#30340;&#25968;&#37327;&#36739;&#22810;&#65292;&#19988;&#39044;&#35745;&#23384;&#22312;&#38750;&#32447;&#24615;&#20851;&#32852;&#25110;&#21327;&#21464;&#37327;&#20043;&#38388;&#30340;&#20132;&#20114;&#20316;&#29992;&#26102;&#12290;&#20854;&#24212;&#29992;&#21487;&#20197;&#26174;&#33879;&#38477;&#20302;RCT&#30340;&#25152;&#38656;&#26679;&#26412;&#37327;&#21644;&#25104;&#26412;&#65292;&#20363;&#22914;&#19977;&#26399;&#20020;&#24202;&#35797;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03058v1 Announce Type: cross  Abstract: In this work, we proposed a novel inferential procedure assisted by machine learning based adjustment for randomized control trials. The method was developed under the Rosenbaum's framework of exact tests in randomized experiments with covariate adjustments. Through extensive simulation experiments, we showed the proposed method can robustly control the type I error and can boost the inference efficiency for a randomized controlled trial (RCT). This advantage was further demonstrated in a real world example. The simplicity and robustness of the proposed method makes it a competitive candidate as a routine inference procedure for RCTs, especially when the number of baseline covariates is large, and when nonlinear association or interaction among covariates is expected. Its application may remarkably reduce the required sample size and cost of RCTs, such as phase III clinical trials.
&lt;/p&gt;</description></item><item><title>CoLoRA&#36890;&#36807;&#36830;&#32493;&#20302;&#31209;&#33258;&#36866;&#24212;&#25552;&#20379;&#20102;&#19968;&#31181;&#24555;&#36895;&#39044;&#27979;&#21442;&#25968;&#21270;&#20559;&#24494;&#20998;&#26041;&#31243;&#35299;&#28436;&#21464;&#30340;&#31616;&#21270;&#31070;&#32463;&#32593;&#32476;&#24314;&#27169;&#26041;&#27861;</title><link>https://arxiv.org/abs/2402.14646</link><description>&lt;p&gt;
CoLoRA:&#29992;&#20110;&#21442;&#25968;&#21270;&#20559;&#24494;&#20998;&#26041;&#31243;&#31616;&#21270;&#38544;&#24335;&#31070;&#32463;&#24314;&#27169;&#30340;&#36830;&#32493;&#20302;&#31209;&#33258;&#36866;&#24212;
&lt;/p&gt;
&lt;p&gt;
CoLoRA: Continuous low-rank adaptation for reduced implicit neural modeling of parameterized partial differential equations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14646
&lt;/p&gt;
&lt;p&gt;
CoLoRA&#36890;&#36807;&#36830;&#32493;&#20302;&#31209;&#33258;&#36866;&#24212;&#25552;&#20379;&#20102;&#19968;&#31181;&#24555;&#36895;&#39044;&#27979;&#21442;&#25968;&#21270;&#20559;&#24494;&#20998;&#26041;&#31243;&#35299;&#28436;&#21464;&#30340;&#31616;&#21270;&#31070;&#32463;&#32593;&#32476;&#24314;&#27169;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35813;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#36830;&#32493;&#20302;&#31209;&#33258;&#36866;&#24212;&#65288;CoLoRA&#65289;&#30340;&#31616;&#21270;&#27169;&#22411;&#65292;&#23427;&#39044;&#20808;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#36866;&#29992;&#20110;&#32473;&#23450;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#65292;&#28982;&#21518;&#22312;&#26102;&#38388;&#19978;&#36830;&#32493;&#22320;&#35843;&#25972;&#20302;&#31209;&#26435;&#37325;&#65292;&#20197;&#24555;&#36895;&#39044;&#27979;&#26032;&#29289;&#29702;&#21442;&#25968;&#21644;&#26032;&#21021;&#22987;&#26465;&#20214;&#19979;&#35299;&#22330;&#30340;&#28436;&#21464;&#12290;&#33258;&#36866;&#24212;&#21487;&#20197;&#26159;&#32431;&#31929;&#25968;&#25454;&#39537;&#21160;&#30340;&#65292;&#20063;&#21487;&#20197;&#36890;&#36807;&#19968;&#20010;&#26041;&#31243;&#39537;&#21160;&#30340;&#21464;&#20998;&#26041;&#27861;&#65292;&#25552;&#20379;Galerkin&#26368;&#20248;&#30340;&#36924;&#36817;&#12290;&#30001;&#20110;CoLoRA&#22312;&#26102;&#38388;&#19978;&#23616;&#37096;&#36924;&#36817;&#35299;&#22330;&#65292;&#26435;&#37325;&#30340;&#31209;&#21487;&#20197;&#20445;&#25345;&#36739;&#23567;&#65292;&#36825;&#24847;&#21619;&#30528;&#21482;&#38656;&#35201;&#31163;&#32447;&#35757;&#32451;&#20960;&#26465;&#36712;&#36857;&#65292;&#22240;&#27492;CoLoRA&#38750;&#24120;&#36866;&#29992;&#20110;&#25968;&#25454;&#31232;&#32570;&#30340;&#24773;&#20917;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#27604;&#65292;CoLoRA&#30340;&#39044;&#27979;&#36895;&#24230;&#24555;&#19978;&#20960;&#20010;&#25968;&#37327;&#32423;&#65292;&#20854;&#20934;&#30830;&#24230;&#21644;&#21442;&#25968;&#25928;&#29575;&#20063;&#27604;&#20854;&#20182;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#26356;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14646v1 Announce Type: new  Abstract: This work introduces reduced models based on Continuous Low Rank Adaptation (CoLoRA) that pre-train neural networks for a given partial differential equation and then continuously adapt low-rank weights in time to rapidly predict the evolution of solution fields at new physics parameters and new initial conditions. The adaptation can be either purely data-driven or via an equation-driven variational approach that provides Galerkin-optimal approximations. Because CoLoRA approximates solution fields locally in time, the rank of the weights can be kept small, which means that only few training trajectories are required offline so that CoLoRA is well suited for data-scarce regimes. Predictions with CoLoRA are orders of magnitude faster than with classical methods and their accuracy and parameter efficiency is higher compared to other neural network approaches.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#23545;&#25239;&#24615;&#20581;&#22766;&#30340;&#20048;&#35266;MLE&#65288;CR-OMLE&#65289;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#27169;&#22411;&#39537;&#21160;&#24378;&#21270;&#23398;&#20064;&#20013;&#23545;&#25239;&#24615;&#30772;&#22351;&#30340;&#25361;&#25112;&#65292;&#23454;&#29616;&#20102;&#23545;&#36716;&#31227;&#27169;&#22411;&#30340;&#20581;&#22766;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2402.08991</link><description>&lt;p&gt;
&#38754;&#21521;&#23545;&#25239;&#24615;&#30772;&#22351;&#30340;&#20581;&#22766;&#27169;&#22411;&#39537;&#21160;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Towards Robust Model-Based Reinforcement Learning Against Adversarial Corruption
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08991
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#23545;&#25239;&#24615;&#20581;&#22766;&#30340;&#20048;&#35266;MLE&#65288;CR-OMLE&#65289;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#27169;&#22411;&#39537;&#21160;&#24378;&#21270;&#23398;&#20064;&#20013;&#23545;&#25239;&#24615;&#30772;&#22351;&#30340;&#25361;&#25112;&#65292;&#23454;&#29616;&#20102;&#23545;&#36716;&#31227;&#27169;&#22411;&#30340;&#20581;&#22766;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35299;&#20915;&#20102;&#27169;&#22411;&#39537;&#21160;&#24378;&#21270;&#23398;&#20064;&#20013;&#23545;&#25239;&#24615;&#30772;&#22351;&#30340;&#25361;&#25112;&#65292;&#20854;&#20013;&#36716;&#31227;&#21160;&#21147;&#23398;&#21487;&#20197;&#34987;&#23545;&#25163;&#30772;&#22351;&#12290;&#29616;&#26377;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#27169;&#22411;&#26080;&#20851;&#24378;&#21270;&#23398;&#20064;&#30340;&#24773;&#26223;&#19979;&#65292;&#36890;&#24120;&#37319;&#29992;&#20581;&#22766;&#30340;&#26368;&#23567;&#20108;&#20056;&#22238;&#24402;&#26469;&#36827;&#34892;&#20540;&#20989;&#25968;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#25216;&#26415;&#19981;&#33021;&#30452;&#25509;&#24212;&#29992;&#20110;&#27169;&#22411;&#39537;&#21160;&#30340;&#24378;&#21270;&#23398;&#20064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#27169;&#22411;&#39537;&#21160;&#30340;&#24378;&#21270;&#23398;&#20064;&#65292;&#24182;&#37319;&#29992;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65288;MLE&#65289;&#26041;&#27861;&#26469;&#23398;&#20064;&#36716;&#31227;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#28085;&#30422;&#20102;&#22312;&#32447;&#21644;&#31163;&#32447;&#20004;&#31181;&#24773;&#20917;&#12290;&#22312;&#22312;&#32447;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;&#23545;&#25239;&#24615;&#20581;&#22766;&#30340;&#20048;&#35266;MLE&#65288;CR-OMLE&#65289;&#30340;&#31639;&#27861;&#65292;&#23427;&#21033;&#29992;&#22522;&#20110;&#24635;&#21464;&#24046;&#65288;TV&#65289;&#30340;&#20449;&#24687;&#27604;&#29575;&#20316;&#20026;MLE&#30340;&#19981;&#30830;&#23450;&#26435;&#37325;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;CR-OMLE&#30340;&#36951;&#25022;&#24230;&#20026;$ \tilde {\mathcal {O}}&#65288;\sqrt {T} + C&#65289;$&#65292;&#20854;&#20013;$ C $&#34920;&#31034;&#32463;&#36807;$ T $&#20010;&#22238;&#21512;&#21518;&#30340;&#32047;&#35745;&#30772;&#22351;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08991v1 Announce Type: cross Abstract: This study tackles the challenges of adversarial corruption in model-based reinforcement learning (RL), where the transition dynamics can be corrupted by an adversary. Existing studies on corruption-robust RL mostly focus on the setting of model-free RL, where robust least-square regression is often employed for value function estimation. However, these techniques cannot be directly applied to model-based RL. In this paper, we focus on model-based RL and take the maximum likelihood estimation (MLE) approach to learn transition model. Our work encompasses both online and offline settings. In the online setting, we introduce an algorithm called corruption-robust optimistic MLE (CR-OMLE), which leverages total-variation (TV)-based information ratios as uncertainty weights for MLE. We prove that CR-OMLE achieves a regret of $\tilde{\mathcal{O}}(\sqrt{T} + C)$, where $C$ denotes the cumulative corruption level after $T$ episodes. We also pro
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32771;&#34385;&#20102;&#22312;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#20013;&#36827;&#34892; IV &#22238;&#24402;&#30340;&#22256;&#38590;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#26500;&#24314;&#35782;&#21035;&#26041;&#31243;&#30340;&#26041;&#27861;&#65292;&#20197;&#23454;&#29616;&#23545;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#22240;&#26524;&#25928;&#24212;&#30340;&#19968;&#33268;&#24615;&#21442;&#25968;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2203.06056</link><description>&lt;p&gt;
&#20351;&#29992;&#24037;&#20855;&#26102;&#38388;&#24207;&#21015;&#35782;&#21035;&#22240;&#26524;&#25928;&#24212;&#65306;&#26080;&#20851; IV &#21644;&#32416;&#27491;&#21382;&#21490;
&lt;/p&gt;
&lt;p&gt;
Identifying Causal Effects using Instrumental Time Series: Nuisance IV and Correcting for the Past
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2203.06056
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#22312;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#20013;&#36827;&#34892; IV &#22238;&#24402;&#30340;&#22256;&#38590;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#26500;&#24314;&#35782;&#21035;&#26041;&#31243;&#30340;&#26041;&#27861;&#65292;&#20197;&#23454;&#29616;&#23545;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#22240;&#26524;&#25928;&#24212;&#30340;&#19968;&#33268;&#24615;&#21442;&#25968;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20202;&#22120;&#21464;&#37327;&#65288;IV&#65289;&#22238;&#24402;&#20381;&#36182;&#20110;&#24037;&#20855;&#26469;&#25512;&#26029;&#35266;&#27979;&#25968;&#25454;&#20013;&#30340;&#22240;&#26524;&#25928;&#24212;&#65292;&#20854;&#20013;&#23384;&#22312;&#26410;&#35266;&#27979;&#30340;&#28151;&#28102;&#22240;&#32032;&#12290;&#25105;&#20204;&#32771;&#34385;&#22312;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#20013;&#36827;&#34892; IV &#22238;&#24402;&#65292;&#20363;&#22914;&#30690;&#37327;&#33258;&#22238;&#24402;&#65288;VAR&#65289;&#36807;&#31243;&#12290;&#30452;&#25509;&#24212;&#29992;&#29420;&#31435;&#21516;&#20998;&#24067;&#25216;&#26415;&#36890;&#24120;&#19981;&#19968;&#33268;&#65292;&#22240;&#20026;&#23427;&#20204;&#19981;&#33021;&#27491;&#30830;&#35843;&#25972;&#36807;&#21435;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#26412;&#25991;&#27010;&#36848;&#20102;&#30001;&#20110;&#26102;&#38388;&#32467;&#26500;&#32780;&#24341;&#36215;&#30340;&#22256;&#38590;&#65292;&#24182;&#25552;&#20986;&#20102;&#29992;&#20110;&#26500;&#24314;&#21487;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#22240;&#26524;&#25928;&#24212;&#19968;&#33268;&#21442;&#25968;&#20272;&#35745;&#30340;&#30830;&#35748;&#26041;&#31243;&#30340;&#26041;&#27861;&#12290;&#19968;&#31181;&#26041;&#27861;&#20351;&#29992;&#39069;&#22806;&#30340;&#26080;&#20851;&#21327;&#21464;&#37327;&#26469;&#33719;&#24471;&#21487;&#35782;&#21035;&#24615;&#65288;&#21363;&#20351;&#22312;&#29420;&#31435;&#21516;&#20998;&#24067;&#24773;&#20917;&#19979;&#20063;&#26159;&#26377;&#36259;&#30340;&#24819;&#27861;&#65289;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#20010;&#22270;&#36793;&#32536;&#21270;&#26694;&#26550;&#65292;&#20801;&#35768;&#25105;&#20204;&#20197;&#21407;&#21017;&#24615;&#30340;&#26041;&#24335;&#23545;&#26102;&#38388;&#24207;&#21015;&#24212;&#29992;&#26080;&#20851; IV &#21644;&#20854;&#20182; IV &#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#20102;&#20840;&#23616;&#39532;&#23572;&#21487;&#22827;&#24615;&#36136;&#30340;&#19968;&#20010;&#29256;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2203.06056v2 Announce Type: replace-cross  Abstract: Instrumental variable (IV) regression relies on instruments to infer causal effects from observational data with unobserved confounding. We consider IV regression in time series models, such as vector auto-regressive (VAR) processes. Direct applications of i.i.d. techniques are generally inconsistent as they do not correctly adjust for dependencies in the past. In this paper, we outline the difficulties that arise due to time structure and propose methodology for constructing identifying equations that can be used for consistent parametric estimation of causal effects in time series data. One method uses extra nuisance covariates to obtain identifiability (an idea that can be of interest even in the i.i.d. case). We further propose a graph marginalization framework that allows us to apply nuisance IV and other IV methods in a principled way to time series. Our methods make use of a version of the global Markov property, which w
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#25512;&#29702;&#30340;&#21160;&#21147;&#31995;&#32479;&#35782;&#21035;&#26041;&#27861;&#65292;&#21487;&#20197;&#20272;&#35745;&#27169;&#22411;&#31995;&#25968;&#65292;&#36827;&#34892;&#27169;&#22411;&#25490;&#24207;&#21644;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#24182;&#23637;&#31034;&#20102;&#19982;&#20854;&#20182;&#31639;&#27861;&#30340;&#27604;&#36739;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2401.16943</link><description>&lt;p&gt;
&#21160;&#21147;&#31995;&#32479;&#35782;&#21035;&#12289;&#27169;&#22411;&#36873;&#25321;&#21644;&#36125;&#21494;&#26031;&#25512;&#29702;&#20013;&#30340;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Dynamical System Identification, Model Selection and Model Uncertainty Quantification by Bayesian Inference. (arXiv:2401.16943v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16943
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#25512;&#29702;&#30340;&#21160;&#21147;&#31995;&#32479;&#35782;&#21035;&#26041;&#27861;&#65292;&#21487;&#20197;&#20272;&#35745;&#27169;&#22411;&#31995;&#25968;&#65292;&#36827;&#34892;&#27169;&#22411;&#25490;&#24207;&#21644;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#24182;&#23637;&#31034;&#20102;&#19982;&#20854;&#20182;&#31639;&#27861;&#30340;&#27604;&#36739;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#26368;&#22823;&#21518;&#39564;&#27010;&#29575; (MAP) &#26694;&#26550;&#30340;&#21160;&#21147;&#31995;&#32479;&#35782;&#21035;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#24674;&#22797;&#31995;&#32479;&#27169;&#22411;&#12290;&#23454;&#39564;&#35777;&#26126;&#36825;&#31561;&#20215;&#20110;&#24191;&#20041;&#30340;&#38646;&#38454; Tikhonov &#27491;&#21017;&#21270;&#65292;&#36890;&#36807;&#36127;&#23545;&#25968;&#20284;&#28982;&#21644;&#20808;&#39564;&#20998;&#24067;&#26469;&#21512;&#29702;&#36873;&#25321;&#27531;&#24046;&#21644;&#27491;&#21017;&#21270;&#39033;&#12290;&#38500;&#20102;&#20272;&#35745;&#27169;&#22411;&#31995;&#25968;&#22806;&#65292;&#36125;&#21494;&#26031;&#35299;&#37322;&#36824;&#25552;&#20379;&#20102;&#23436;&#25972;&#30340;&#36125;&#21494;&#26031;&#25512;&#29702;&#24037;&#20855;&#65292;&#21253;&#25324;&#27169;&#22411;&#25490;&#24207;&#12289;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#26410;&#30693;&#36229;&#21442;&#25968;&#30340;&#20272;&#35745;&#12290;&#36890;&#36807;&#24212;&#29992;&#20110;&#24102;&#26377;&#22122;&#22768;&#30340;&#20960;&#20010;&#21160;&#21147;&#31995;&#32479;&#65292;&#27604;&#36739;&#20102;&#20004;&#31181;&#36125;&#21494;&#26031;&#31639;&#27861;&#65292;&#21363;&#32852;&#21512;&#26368;&#22823;&#21518;&#39564;&#27010;&#29575; (JMAP) &#21644;&#21464;&#20998;&#36125;&#21494;&#26031;&#36817;&#20284; (VBA)&#65292;&#19982;&#27969;&#34892;&#30340;&#38408;&#20540;&#26368;&#23567;&#20108;&#20056;&#22238;&#24402;&#31639;&#27861;SINDy&#12290;&#23545;&#20110;&#22810;&#20803;&#39640;&#26031;&#20284;&#28982;&#21644;&#20808;&#39564;&#20998;&#24067;&#65292;
&lt;/p&gt;
&lt;p&gt;
This study presents a Bayesian maximum \textit{a~posteriori} (MAP) framework for dynamical system identification from time-series data. This is shown to be equivalent to a generalized zeroth-order Tikhonov regularization, providing a rational justification for the choice of the residual and regularization terms, respectively, from the negative logarithms of the likelihood and prior distributions. In addition to the estimation of model coefficients, the Bayesian interpretation gives access to the full apparatus for Bayesian inference, including the ranking of models, the quantification of model uncertainties and the estimation of unknown (nuisance) hyperparameters. Two Bayesian algorithms, joint maximum \textit{a~posteriori} (JMAP) and variational Bayesian approximation (VBA), are compared to the popular SINDy algorithm for thresholded least-squares regression, by application to several dynamical systems with added noise. For multivariate Gaussian likelihood and prior distributions, the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#23398;&#20064;&#38750;&#20998;&#31163;&#21704;&#23494;&#39039;&#31995;&#32479;&#30340;&#32467;&#26500;&#20445;&#25345;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#32479;&#35745;&#30456;&#20851;&#30340;&#21152;&#24615;&#21644;&#20056;&#24615;&#22122;&#22768;&#65292;&#24182;&#19988;&#36890;&#36807;&#23558;&#32467;&#26500;&#20445;&#25345;&#26041;&#27861;&#32435;&#20837;&#26694;&#26550;&#20013;&#65292;&#25552;&#20379;&#20102;&#23545;&#39640;&#32500;&#31995;&#32479;&#30340;&#39640;&#25928;&#35782;&#21035;&#12290;</title><link>http://arxiv.org/abs/2401.12476</link><description>&lt;p&gt;
&#29992;&#28145;&#24230;&#23398;&#20064;&#21644;&#38477;&#38454;&#24314;&#27169;&#36827;&#34892;&#36125;&#21494;&#26031;&#38750;&#20998;&#31163;&#21704;&#23494;&#39039;&#31995;&#32479;&#30340;&#35782;&#21035;&#21644;&#22810;&#39033;&#24335;&#22122;&#22768; (arXiv:2401.12476v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
Bayesian identification of nonseparable Hamiltonians with multiplicative noise using deep learning and reduced-order modeling. (arXiv:2401.12476v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12476
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#23398;&#20064;&#38750;&#20998;&#31163;&#21704;&#23494;&#39039;&#31995;&#32479;&#30340;&#32467;&#26500;&#20445;&#25345;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#32479;&#35745;&#30456;&#20851;&#30340;&#21152;&#24615;&#21644;&#20056;&#24615;&#22122;&#22768;&#65292;&#24182;&#19988;&#36890;&#36807;&#23558;&#32467;&#26500;&#20445;&#25345;&#26041;&#27861;&#32435;&#20837;&#26694;&#26550;&#20013;&#65292;&#25552;&#20379;&#20102;&#23545;&#39640;&#32500;&#31995;&#32479;&#30340;&#39640;&#25928;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#26500;&#20445;&#25345;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#20351;&#29992;&#38543;&#26426;&#21160;&#21147;&#27169;&#22411;&#30340;&#38750;&#20998;&#31163;&#21704;&#23494;&#39039;&#31995;&#32479;&#65292;&#35813;&#31995;&#32479;&#20801;&#35768;&#32479;&#35745;&#30456;&#20851;&#30340;&#65292;&#30690;&#37327;&#20540;&#30340;&#21152;&#24615;&#21644;&#20056;&#24615;&#27979;&#37327;&#22122;&#22768;&#12290;&#35813;&#26041;&#27861;&#30001;&#19977;&#20010;&#20027;&#35201;&#26041;&#38754;&#32452;&#25104;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;&#36125;&#21494;&#26031;&#21518;&#39564;&#20013;&#30340;&#20284;&#28982;&#20989;&#25968;&#25152;&#38656;&#30340;&#32479;&#35745;&#30456;&#20851;&#30340;&#65292;&#30690;&#37327;&#20540;&#30340;&#21152;&#24615;&#21644;&#20056;&#24615;&#22122;&#22768;&#27169;&#22411;&#30340;&#39640;&#26031;&#28388;&#27874;&#22120;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;&#29992;&#20110;&#23545;&#39640;&#32500;&#31995;&#32479;&#36827;&#34892;&#39640;&#25928;&#30340;&#36125;&#21494;&#26031;&#31995;&#32479;&#35782;&#21035;&#12290;&#31532;&#19977;&#65292;&#25105;&#20204;&#28436;&#31034;&#20102;&#22914;&#20309;&#23558;&#32467;&#26500;&#20445;&#25345;&#26041;&#27861;&#32435;&#20837;&#25152;&#25552;&#35758;&#30340;&#26694;&#26550;&#20013;&#65292;&#20351;&#29992;&#38750;&#20998;&#31163;&#21704;&#23494;&#39039;&#31995;&#32479;&#20316;&#20026;&#19968;&#20010;&#20030;&#20363;&#30340;&#31995;&#32479;&#31867;&#21035;&#12290;&#25105;&#20204;&#23558;&#36125;&#21494;&#26031;&#26041;&#27861;&#19982;&#19968;&#31181;&#26368;&#20808;&#36827;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#19968;&#20010;&#20856;&#22411;&#30340;&#38750;&#20998;&#31163;&#21704;&#23494;&#39039;&#27169;&#22411;&#21644;&#24102;&#26377;&#23567;&#22411;&#22122;&#22768;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#28151;&#27788;&#21452;&#25670;&#27169;&#22411;&#19978;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;
&lt;/p&gt;
&lt;p&gt;
This paper presents a structure-preserving Bayesian approach for learning nonseparable Hamiltonian systems using stochastic dynamic models allowing for statistically-dependent, vector-valued additive and multiplicative measurement noise. The approach is comprised of three main facets. First, we derive a Gaussian filter for a statistically-dependent, vector-valued, additive and multiplicative noise model that is needed to evaluate the likelihood within the Bayesian posterior. Second, we develop a novel algorithm for cost-effective application of Bayesian system identification to high-dimensional systems. Third, we demonstrate how structure-preserving methods can be incorporated into the proposed framework, using nonseparable Hamiltonians as an illustrative system class. We compare the Bayesian method to a state-of-the-art machine learning method on a canonical nonseparable Hamiltonian model and a chaotic double pendulum model with small, noisy training datasets. The results show that us
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#65292;&#35777;&#26126;&#20102;&#23545;&#20110;&#38750;&#20984;&#12289;&#21487;&#33021;&#19981;&#20809;&#28369;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#22312;&#19968;&#33324;&#30340;&#32463;&#24120;&#24615;&#25277;&#26679;&#26041;&#26696;&#19979;&#65292;&#21487;&#20197;&#20197;&#26368;&#20339;&#36895;&#29575;&#25910;&#25947;&#65307;&#21516;&#26102;&#25351;&#20986;&#20102;&#25910;&#25947;&#36895;&#24230;&#19982;"&#32463;&#24120;&#24615;&#30340;&#36895;&#24230;"&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2401.07694</link><description>&lt;p&gt;
&#20855;&#26377;&#20219;&#24847;&#32463;&#24120;&#24615;&#25968;&#25454;&#25277;&#26679;&#30340;&#38543;&#26426;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Stochastic optimization with arbitrary recurrent data sampling. (arXiv:2401.07694v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.07694
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#65292;&#35777;&#26126;&#20102;&#23545;&#20110;&#38750;&#20984;&#12289;&#21487;&#33021;&#19981;&#20809;&#28369;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#22312;&#19968;&#33324;&#30340;&#32463;&#24120;&#24615;&#25277;&#26679;&#26041;&#26696;&#19979;&#65292;&#21487;&#20197;&#20197;&#26368;&#20339;&#36895;&#29575;&#25910;&#25947;&#65307;&#21516;&#26102;&#25351;&#20986;&#20102;&#25910;&#25947;&#36895;&#24230;&#19982;"&#32463;&#24120;&#24615;&#30340;&#36895;&#24230;"&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#33719;&#24471;&#38543;&#26426;&#20248;&#21270;&#30340;&#26368;&#20339;&#19968;&#38454;&#25910;&#25947;&#20445;&#35777;&#65292;&#38656;&#35201;&#20351;&#29992;&#19968;&#20010;&#32463;&#24120;&#24615;&#25968;&#25454;&#25277;&#26679;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20197;&#36275;&#22815;&#30340;&#39057;&#29575;&#23545;&#27599;&#20010;&#25968;&#25454;&#28857;&#36827;&#34892;&#25277;&#26679;&#12290;&#22823;&#22810;&#25968;&#24120;&#29992;&#30340;&#25968;&#25454;&#25277;&#26679;&#31639;&#27861;&#65288;&#22914;i.i.d.&#65292;MCMC&#65292;&#38543;&#26426;&#37325;&#25490;&#65289;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#30830;&#23454;&#26159;&#32463;&#24120;&#24615;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#34920;&#26126;&#23545;&#20110;&#19968;&#31867;&#29305;&#27530;&#30340;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#65292;&#25105;&#20204;&#26080;&#38656;&#38500;&#20102;&#25968;&#25454;&#25277;&#26679;&#31639;&#27861;&#20013;&#30340;&#32463;&#24120;&#24615;&#20043;&#22806;&#30340;&#20219;&#20309;&#20854;&#20182;&#23646;&#24615;&#65288;&#22914;&#29420;&#31435;&#24615;&#65292;&#25351;&#25968;&#28151;&#21512;&#21644;&#37325;&#25490;&#65289;&#26469;&#20445;&#35777;&#26368;&#20339;&#30340;&#19968;&#38454;&#25910;&#25947;&#36895;&#29575;&#12290;&#20063;&#23601;&#26159;&#35828;&#65292;&#20351;&#29992;Minimization by Incremental Surrogate Optimization (MISO)&#30340;&#27491;&#21017;&#21270;&#29256;&#26412;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#38750;&#20984;&#30340;&#12289;&#21487;&#33021;&#19981;&#20809;&#28369;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#26399;&#26395;&#30340;&#26368;&#20248;&#24615;&#24046;&#24322;&#22312;&#19968;&#33324;&#30340;&#32463;&#24120;&#24615;&#25277;&#26679;&#26041;&#26696;&#19979;&#25910;&#25947;&#20110;&#26368;&#20339;&#36895;&#29575;$O(n^{-1/2})$&#12290;&#27492;&#22806;&#65292;&#26263;&#31034;&#30340;&#24120;&#25968;&#26126;&#30830;&#21462;&#20915;&#20110;"&#32463;&#24120;&#24615;&#30340;&#36895;&#24230;"&#65292;&#30001;&#25351;&#25968;&#27979;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
For obtaining optimal first-order convergence guarantee for stochastic optimization, it is necessary to use a recurrent data sampling algorithm that samples every data point with sufficient frequency. Most commonly used data sampling algorithms (e.g., i.i.d., MCMC, random reshuffling) are indeed recurrent under mild assumptions. In this work, we show that for a particular class of stochastic optimization algorithms, we do not need any other property (e.g., independence, exponential mixing, and reshuffling) than recurrence in data sampling algorithms to guarantee the optimal rate of first-order convergence. Namely, using regularized versions of Minimization by Incremental Surrogate Optimization (MISO), we show that for non-convex and possibly non-smooth objective functions, the expected optimality gap converges at an optimal rate $O(n^{-1/2})$ under general recurrent sampling schemes. Furthermore, the implied constant depends explicitly on the `speed of recurrence', measured by the expe
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#25311;&#25512;&#26029;&#21644;&#20998;&#20301;&#25968;&#22238;&#24402;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#20010;&#20307;&#21270;&#30340;&#20998;&#20301;&#25968;&#26469;&#20272;&#35745;&#21518;&#39564;&#26679;&#26412;&#65292;&#24182;&#20351;&#29992;&#23616;&#37096;&#32047;&#31215;&#23494;&#24230;&#20989;&#25968;&#23450;&#20041;&#36125;&#21494;&#26031;&#21487;&#20449;&#21306;&#38388;&#65292;&#20855;&#26377;&#26356;&#24555;&#30340;&#35780;&#20272;&#36895;&#24230;&#12290;&#21516;&#26102;&#65292;&#36824;&#21487;&#20197;&#38598;&#25104;&#21518;&#22788;&#29702;&#25193;&#23637;&#27493;&#39588;&#20197;&#20445;&#35777;&#21518;&#39564;&#20272;&#35745;&#30340;&#26080;&#20559;&#24615;&#65292;&#32780;&#35745;&#31639;&#25104;&#26412;&#20960;&#20046;&#21487;&#20197;&#24573;&#30053;&#19981;&#35745;&#12290;</title><link>http://arxiv.org/abs/2401.02413</link><description>&lt;p&gt;
&#22522;&#20110;&#20998;&#20301;&#25968;&#22238;&#24402;&#30340;&#27169;&#25311;&#25512;&#26029;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Simulation-Based Inference with Quantile Regression. (arXiv:2401.02413v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02413
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#25311;&#25512;&#26029;&#21644;&#20998;&#20301;&#25968;&#22238;&#24402;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#20010;&#20307;&#21270;&#30340;&#20998;&#20301;&#25968;&#26469;&#20272;&#35745;&#21518;&#39564;&#26679;&#26412;&#65292;&#24182;&#20351;&#29992;&#23616;&#37096;&#32047;&#31215;&#23494;&#24230;&#20989;&#25968;&#23450;&#20041;&#36125;&#21494;&#26031;&#21487;&#20449;&#21306;&#38388;&#65292;&#20855;&#26377;&#26356;&#24555;&#30340;&#35780;&#20272;&#36895;&#24230;&#12290;&#21516;&#26102;&#65292;&#36824;&#21487;&#20197;&#38598;&#25104;&#21518;&#22788;&#29702;&#25193;&#23637;&#27493;&#39588;&#20197;&#20445;&#35777;&#21518;&#39564;&#20272;&#35745;&#30340;&#26080;&#20559;&#24615;&#65292;&#32780;&#35745;&#31639;&#25104;&#26412;&#20960;&#20046;&#21487;&#20197;&#24573;&#30053;&#19981;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26465;&#20214;&#20998;&#20301;&#25968;&#22238;&#24402;&#30340;&#26032;&#22411;&#27169;&#25311;&#25512;&#26029;&#65288;Simulation-Based Inference&#65292;SBI&#65289;&#26041;&#27861;&#8212;&#8212;&#31070;&#32463;&#20998;&#20301;&#25968;&#20272;&#35745;&#65288;Neural Quantile Estimation&#65292;NQE&#65289;&#12290;NQE&#36890;&#36807;&#33258;&#22238;&#24402;&#26041;&#24335;&#23398;&#20064;&#27599;&#20010;&#21518;&#39564;&#32500;&#24230;&#30340;&#21333;&#19968;&#32500;&#24230;&#20998;&#20301;&#25968;&#65292;&#20197;&#25968;&#25454;&#21644;&#20043;&#21069;&#30340;&#21518;&#39564;&#32500;&#24230;&#20026;&#26465;&#20214;&#12290;&#21518;&#39564;&#26679;&#26412;&#36890;&#36807;&#20351;&#29992;&#21333;&#35843;&#19977;&#27425;&#22467;&#23572;&#31859;&#29305;&#26679;&#26465;&#25554;&#20540;&#39044;&#27979;&#20998;&#20301;&#25968;&#36827;&#34892;&#33719;&#21462;&#65292;&#24182;&#23545;&#23614;&#37096;&#34892;&#20026;&#21644;&#22810;&#27169;&#24577;&#20998;&#24067;&#36827;&#34892;&#20102;&#29305;&#27530;&#22788;&#29702;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#20351;&#29992;&#23616;&#37096;&#32047;&#31215;&#23494;&#24230;&#20989;&#25968;&#65288;CDF&#65289;&#30340;&#36125;&#21494;&#26031;&#21487;&#20449;&#21306;&#38388;&#30340;&#26367;&#20195;&#23450;&#20041;&#65292;&#20854;&#35780;&#20272;&#36895;&#24230;&#27604;&#20256;&#32479;&#30340;&#26368;&#39640;&#21518;&#39564;&#23494;&#24230;&#21306;&#22495;&#65288;HPDR&#65289;&#24555;&#24471;&#22810;&#12290;&#22312;&#27169;&#25311;&#39044;&#31639;&#26377;&#38480;&#21644;/&#25110;&#24050;&#30693;&#27169;&#22411;&#38169;&#35823;&#35268;&#33539;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#23558;&#21518;&#22788;&#29702;&#25193;&#23637;&#27493;&#39588;&#38598;&#25104;&#21040;NQE&#20013;&#65292;&#20197;&#30830;&#20445;&#21518;&#39564;&#20272;&#35745;&#30340;&#26080;&#20559;&#24615;&#65292;&#19988;&#38468;&#21152;&#30340;&#35745;&#31639;&#25104;&#26412;&#21487;&#20197;&#24573;&#30053;&#19981;&#35745;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;NQE&#26041;&#27861;&#36798;&#21040;&#20102;&#26368;&#26032;&#30340;&#30740;&#31350;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present Neural Quantile Estimation (NQE), a novel Simulation-Based Inference (SBI) method based on conditional quantile regression. NQE autoregressively learns individual one dimensional quantiles for each posterior dimension, conditioned on the data and previous posterior dimensions. Posterior samples are obtained by interpolating the predicted quantiles using monotonic cubic Hermite spline, with specific treatment for the tail behavior and multi-modal distributions. We introduce an alternative definition for the Bayesian credible region using the local Cumulative Density Function (CDF), offering substantially faster evaluation than the traditional Highest Posterior Density Region (HPDR). In case of limited simulation budget and/or known model misspecification, a post-processing broadening step can be integrated into NQE to ensure the unbiasedness of the posterior estimation with negligible additional computational cost. We demonstrate that the proposed NQE method achieves state-of
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#38598;&#21512;&#21345;&#23572;&#26364;&#28388;&#27874;&#24341;&#20837;&#21464;&#20998;&#25512;&#29702;&#26694;&#26550;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#36817;&#20284;&#39640;&#26031;&#36807;&#31243;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#24182;&#19988;&#26377;&#25928;&#22320;&#21033;&#29992;&#20102;&#28508;&#22312;&#29366;&#24577;&#21644;&#21160;&#21147;&#23398;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#20943;&#23569;&#20102;&#21464;&#20998;&#21442;&#25968;&#30340;&#25968;&#37327;&#12290;</title><link>http://arxiv.org/abs/2312.05910</link><description>&lt;p&gt;
&#38598;&#21512;&#21345;&#23572;&#26364;&#28388;&#27874;&#19982;&#39640;&#26031;&#36807;&#31243;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#22312;&#38750;&#22343;&#22330;&#21644;&#22312;&#32447;&#25512;&#29702;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Ensemble Kalman Filtering Meets Gaussian Process SSM for Non-Mean-Field and Online Inference. (arXiv:2312.05910v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.05910
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#38598;&#21512;&#21345;&#23572;&#26364;&#28388;&#27874;&#24341;&#20837;&#21464;&#20998;&#25512;&#29702;&#26694;&#26550;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#36817;&#20284;&#39640;&#26031;&#36807;&#31243;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#24182;&#19988;&#26377;&#25928;&#22320;&#21033;&#29992;&#20102;&#28508;&#22312;&#29366;&#24577;&#21644;&#21160;&#21147;&#23398;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#20943;&#23569;&#20102;&#21464;&#20998;&#21442;&#25968;&#30340;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65288;GPSSMs&#65289;&#26159;&#19968;&#31181;&#22810;&#21151;&#33021;&#21644;&#21407;&#21017;&#24615;&#30340;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;GPSSMs&#21464;&#20998;&#23398;&#20064;&#21644;&#25512;&#29702;&#26041;&#27861;&#36890;&#24120;&#38656;&#35201;&#20248;&#21270;&#22823;&#37327;&#21464;&#20998;&#21442;&#25968;&#65292;&#23548;&#33268;&#24615;&#33021;&#21644;&#25928;&#29575;&#19981;&#36275;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#23558;&#38598;&#21512;&#21345;&#23572;&#26364;&#28388;&#27874;&#65288;EnKF&#65289;&#65292;&#19968;&#31181;&#25104;&#29087;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#28388;&#27874;&#25216;&#26415;&#65292;&#32435;&#20837;&#21464;&#20998;&#25512;&#29702;&#26694;&#26550;&#20013;&#65292;&#20197;&#36817;&#20284;&#28508;&#22312;&#29366;&#24577;&#30340;&#21518;&#39564;&#20998;&#24067;&#12290;&#36825;&#31181;&#21033;&#29992;EnKF&#30340;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#22320;&#21033;&#29992;&#28508;&#22312;&#29366;&#24577;&#21644;GP&#21160;&#21147;&#23398;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#21516;&#26102;&#28040;&#38500;&#20102;&#23545;&#21464;&#20998;&#20998;&#24067;&#36827;&#34892;&#21442;&#25968;&#21270;&#30340;&#38656;&#27714;&#65292;&#20174;&#32780;&#26174;&#33879;&#20943;&#23569;&#20102;&#21464;&#20998;&#21442;&#25968;&#30340;&#25968;&#37327;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#21487;&#20197;&#36890;&#36807;&#31616;&#21333;&#22320;&#23545;&#22810;&#20010;&#39033;&#36827;&#34892;&#27714;&#21644;&#26469;&#30452;&#25509;&#35780;&#20272;&#21464;&#20998;&#25512;&#29702;&#20013;&#30340;&#36817;&#20284;&#35777;&#25454;&#19979;&#30028;&#65288;ELBO&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian process state-space models (GPSSMs) are a versatile and principled family of nonlinear dynamical system models. However, existing variational learning and inference methods for GPSSMs often necessitate optimizing a substantial number of variational parameters, leading to inadequate performance and efficiency. To overcome this issue, we propose incorporating the ensemble Kalman filter (EnKF), a well-established model-based filtering technique, into the variational inference framework to approximate the posterior distribution of latent states. This utilization of EnKF can effectively exploit the dependencies between latent states and GP dynamics, while eliminating the need for parameterizing the variational distribution, thereby significantly reducing the number of variational parameters. Moreover, we show that our proposed algorithm allows straightforward evaluation of an approximated evidence lower bound (ELBO) in variational inference via simply summating multiple terms with 
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#32467;&#26500;&#21270;&#26080;&#26631;&#31614;&#25968;&#25454;&#20998;&#24067;&#19979;&#65292;&#23545;&#20110;&#20855;&#26377;Tsybakov&#22122;&#22768;&#30340;$d$&#32500;&#21322;&#31354;&#38388;&#65292;&#35745;&#31639;&#21644;&#26631;&#31614;&#30340;&#39640;&#25928;PAC&#20027;&#21160;&#23398;&#20064;&#38382;&#39064;&#12290;&#36890;&#36807;&#35774;&#35745;&#19968;&#31181;&#22522;&#20110;&#38750;&#20984;&#20248;&#21270;&#30340;&#31639;&#27861;&#65292;&#23427;&#33021;&#22815;&#22312;&#19968;&#23450;&#30340;&#22122;&#22768;&#21442;&#25968;&#33539;&#22260;&#20869;&#36798;&#21040;&#36739;&#20302;&#30340;&#26631;&#31614;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.15411</link><description>&lt;p&gt;
&#39640;&#25928;&#30340;&#24102;&#26377;Tsybakov&#22122;&#22768;&#30340;&#21322;&#31354;&#38388;&#20027;&#21160;&#23398;&#20064;&#65306;&#19968;&#31181;&#38750;&#20984;&#20248;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Efficient Active Learning Halfspaces with Tsybakov Noise: A Non-convex Optimization Approach. (arXiv:2310.15411v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15411
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#32467;&#26500;&#21270;&#26080;&#26631;&#31614;&#25968;&#25454;&#20998;&#24067;&#19979;&#65292;&#23545;&#20110;&#20855;&#26377;Tsybakov&#22122;&#22768;&#30340;$d$&#32500;&#21322;&#31354;&#38388;&#65292;&#35745;&#31639;&#21644;&#26631;&#31614;&#30340;&#39640;&#25928;PAC&#20027;&#21160;&#23398;&#20064;&#38382;&#39064;&#12290;&#36890;&#36807;&#35774;&#35745;&#19968;&#31181;&#22522;&#20110;&#38750;&#20984;&#20248;&#21270;&#30340;&#31639;&#27861;&#65292;&#23427;&#33021;&#22815;&#22312;&#19968;&#23450;&#30340;&#22122;&#22768;&#21442;&#25968;&#33539;&#22260;&#20869;&#36798;&#21040;&#36739;&#20302;&#30340;&#26631;&#31614;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32467;&#26500;&#21270;&#26080;&#26631;&#31614;&#25968;&#25454;&#20998;&#24067;&#19979;&#65292;&#23545;&#20110;&#20855;&#26377;Tsybakov&#22122;&#22768;&#30340;$d$&#32500;&#21322;&#31354;&#38388;&#65292;&#35745;&#31639;&#21644;&#26631;&#31614;&#30340;&#39640;&#25928;PAC&#20027;&#21160;&#23398;&#20064;&#38382;&#39064;&#12290;&#21463;&#21040;\cite{diakonikolas2020learning}&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#24179;&#28369;&#38750;&#20984;&#25439;&#22833;&#20989;&#25968;&#30340;&#20219;&#20309;&#36817;&#20284;&#19968;&#38454;&#31283;&#23450;&#28857;&#37117;&#20250;&#20135;&#29983;&#19968;&#20010;&#20855;&#26377;&#20302;&#36807;&#37327;&#35823;&#24046;&#20445;&#35777;&#30340;&#21322;&#31354;&#38388;&#12290;&#26681;&#25454;&#19978;&#36848;&#32467;&#26500;&#24615;&#32467;&#26524;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#22522;&#20110;&#38750;&#20984;&#20248;&#21270;&#30340;&#31639;&#27861;&#65292;&#20854;&#26631;&#31614;&#22797;&#26434;&#24230;&#20026;$\tilde{O}(d (\frac{1}{\epsilon})^{\frac{8-6\alpha}{3\alpha-1}})$&#65292;&#22312;Tsybakov&#22122;&#22768;&#21442;&#25968;$\alpha \in (\frac13, 1]$&#30340;&#20551;&#35774;&#19979;&#65292;&#36825;&#32553;&#23567;&#20102;&#20808;&#21069;&#24050;&#30693;&#30340;&#39640;&#25928;&#34987;&#21160;&#25110;&#20027;&#21160;&#31639;&#27861;&#30340;&#26631;&#31614;&#22797;&#26434;&#24230;&#38388;&#38548;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of computationally and label efficient PAC active learning $d$-dimensional halfspaces with Tsybakov Noise~\citep{tsybakov2004optimal} under structured unlabeled data distributions. Inspired by~\cite{diakonikolas2020learning}, we prove that any approximate first-order stationary point of a smooth nonconvex loss function yields a halfspace with a low excess error guarantee. In light of the above structural result, we design a nonconvex optimization-based algorithm with a label complexity of $\tilde{O}(d (\frac{1}{\epsilon})^{\frac{8-6\alpha}{3\alpha-1}})$\footnote{In the main body of this work, we use $\tilde{O}(\cdot), \tilde{\Theta}(\cdot)$ to hide factors of the form $\polylog(d, \frac{1}{\epsilon}, \frac{1}{\delta})$}, under the assumption that the Tsybakov noise parameter $\alpha \in (\frac13, 1]$, which narrows down the gap between the label complexities of the previously known efficient passive or active algorithms~\citep{diakonikolas2020polynomial,zhang2021im
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#29616;&#26377;&#25216;&#26415;&#23545;&#21327;&#21464;&#37327;&#20998;&#24067;&#30340;&#38480;&#21046;&#38382;&#39064;&#12290;&#30740;&#31350;&#32773;&#20204;&#21457;&#29616;&#65292;&#29616;&#26377;&#26041;&#27861;&#22312;&#22788;&#29702;&#38750;&#39640;&#26031;&#20998;&#24067;&#12289;&#24322;&#36136;&#24615;&#35774;&#35745;&#30697;&#38453;&#21644;&#32570;&#20047;&#21487;&#38752;&#29305;&#24449;&#21327;&#26041;&#24046;&#20272;&#35745;&#26102;&#36935;&#21040;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#20182;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#21033;&#29992;&#32553;&#25918;&#30340;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#36827;&#34892;&#21435;&#20559;&#26657;&#27491;&#12290;</title><link>http://arxiv.org/abs/2309.07810</link><description>&lt;p&gt;
Spectrum-Aware Adjustment: &#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#21450;&#20854;&#22312;&#20027;&#25104;&#20998;&#22238;&#24402;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Spectrum-Aware Adjustment: A New Debiasing Framework with Applications to Principal Components Regression. (arXiv:2309.07810v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07810
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#29616;&#26377;&#25216;&#26415;&#23545;&#21327;&#21464;&#37327;&#20998;&#24067;&#30340;&#38480;&#21046;&#38382;&#39064;&#12290;&#30740;&#31350;&#32773;&#20204;&#21457;&#29616;&#65292;&#29616;&#26377;&#26041;&#27861;&#22312;&#22788;&#29702;&#38750;&#39640;&#26031;&#20998;&#24067;&#12289;&#24322;&#36136;&#24615;&#35774;&#35745;&#30697;&#38453;&#21644;&#32570;&#20047;&#21487;&#38752;&#29305;&#24449;&#21327;&#26041;&#24046;&#20272;&#35745;&#26102;&#36935;&#21040;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#20182;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#21033;&#29992;&#32553;&#25918;&#30340;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#36827;&#34892;&#21435;&#20559;&#26657;&#27491;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#29616;&#20195;&#21435;&#20559;&#25216;&#26415;&#23545;&#21327;&#21464;&#37327;&#20998;&#24067;&#30340;&#32422;&#26463;&#38382;&#39064;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#29305;&#24449;&#25968;&#21644;&#26679;&#26412;&#25968;&#37117;&#24456;&#22823;&#19988;&#30456;&#36817;&#30340;&#26222;&#36941;&#24773;&#20917;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#29616;&#20195;&#21435;&#20559;&#25216;&#26415;&#20351;&#29992;&#33258;&#30001;&#24230;&#26657;&#27491;&#26469;&#38500;&#21435;&#27491;&#21017;&#21270;&#20272;&#35745;&#37327;&#30340;&#25910;&#32553;&#20559;&#24046;&#24182;&#36827;&#34892;&#25512;&#26029;&#12290;&#28982;&#32780;&#65292;&#35813;&#26041;&#27861;&#35201;&#27714;&#35266;&#27979;&#26679;&#26412;&#26159;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#65292;&#21327;&#21464;&#37327;&#36981;&#24490;&#22343;&#20540;&#20026;&#38646;&#30340;&#39640;&#26031;&#20998;&#24067;&#65292;&#24182;&#19988;&#33021;&#22815;&#33719;&#24471;&#21487;&#38752;&#30340;&#29305;&#24449;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#12290;&#24403;&#65288;i&#65289;&#21327;&#21464;&#37327;&#20855;&#26377;&#38750;&#39640;&#26031;&#20998;&#24067;&#12289;&#37325;&#23614;&#25110;&#38750;&#23545;&#31216;&#20998;&#24067;&#65292;&#65288;ii&#65289;&#35774;&#35745;&#30697;&#38453;&#30340;&#34892;&#21576;&#24322;&#36136;&#24615;&#25110;&#23384;&#22312;&#20381;&#36182;&#24615;&#65292;&#20197;&#21450;&#65288;iii&#65289;&#32570;&#20047;&#21487;&#38752;&#30340;&#29305;&#24449;&#21327;&#26041;&#24046;&#20272;&#35745;&#26102;&#65292;&#36825;&#31181;&#26041;&#27861;&#23601;&#20250;&#36935;&#21040;&#22256;&#38590;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#20854;&#20013;&#21435;&#20559;&#26657;&#27491;&#26159;&#19968;&#27493;&#32553;&#25918;&#30340;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#65288;&#36866;&#24403;&#32553;&#25918;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new debiasing framework for high-dimensional linear regression that bypasses the restrictions on covariate distributions imposed by modern debiasing technology. We study the prevalent setting where the number of features and samples are both large and comparable. In this context, state-of-the-art debiasing technology uses a degrees-of-freedom correction to remove shrinkage bias of regularized estimators and conduct inference. However, this method requires that the observed samples are i.i.d., the covariates follow a mean zero Gaussian distribution, and reliable covariance matrix estimates for observed features are available. This approach struggles when (i) covariates are non-Gaussian with heavy tails or asymmetric distributions, (ii) rows of the design exhibit heterogeneity or dependencies, and (iii) reliable feature covariance estimates are lacking.  To address these, we develop a new strategy where the debiasing correction is a rescaled gradient descent step (suitably
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20174;&#22810;&#20219;&#21153;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#20013;&#24674;&#22797;&#32447;&#24615;&#25805;&#20316;&#31526;&#30340;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#29616;&#26377;&#30340;&#21508;&#21521;&#21516;&#24615;&#26080;&#20851;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;&#20250;&#23545;&#34920;&#31034;&#26356;&#26032;&#36896;&#25104;&#20559;&#24046;&#65292;&#38480;&#21046;&#20102;&#34920;&#31034;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;&#20026;&#27492;&#65292;&#24341;&#20837;&#20102;&#21435;&#20559;&#24046;&#21644;&#29305;&#24449;&#30333;&#21270;&#30340;&#36866;&#24212;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2308.04428</link><description>&lt;p&gt;
&#20174;&#22810;&#20219;&#21153;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#20013;&#20803;&#23398;&#20064;&#25805;&#20316;&#31526;&#21040;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
Meta-Learning Operators to Optimality from Multi-Task Non-IID Data. (arXiv:2308.04428v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04428
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20174;&#22810;&#20219;&#21153;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#20013;&#24674;&#22797;&#32447;&#24615;&#25805;&#20316;&#31526;&#30340;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#29616;&#26377;&#30340;&#21508;&#21521;&#21516;&#24615;&#26080;&#20851;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;&#20250;&#23545;&#34920;&#31034;&#26356;&#26032;&#36896;&#25104;&#20559;&#24046;&#65292;&#38480;&#21046;&#20102;&#34920;&#31034;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;&#20026;&#27492;&#65292;&#24341;&#20837;&#20102;&#21435;&#20559;&#24046;&#21644;&#29305;&#24449;&#30333;&#21270;&#30340;&#36866;&#24212;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#36817;&#21462;&#24471;&#36827;&#23637;&#30340;&#19968;&#20010;&#24378;&#22823;&#27010;&#24565;&#26159;&#20174;&#24322;&#26500;&#26469;&#28304;&#25110;&#20219;&#21153;&#30340;&#25968;&#25454;&#20013;&#25552;&#21462;&#20849;&#21516;&#29305;&#24449;&#12290;&#30452;&#35266;&#22320;&#35828;&#65292;&#23558;&#25152;&#26377;&#25968;&#25454;&#29992;&#20110;&#23398;&#20064;&#20849;&#21516;&#30340;&#34920;&#31034;&#20989;&#25968;&#65292;&#26082;&#26377;&#21161;&#20110;&#35745;&#31639;&#25928;&#29575;&#65292;&#21448;&#26377;&#21161;&#20110;&#32479;&#35745;&#27867;&#21270;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#20943;&#23569;&#35201;&#22312;&#32473;&#23450;&#20219;&#21153;&#19978;&#36827;&#34892;&#24494;&#35843;&#30340;&#21442;&#25968;&#25968;&#37327;&#12290;&#20026;&#20102;&#22312;&#29702;&#35770;&#19978;&#20570;&#20986;&#36825;&#20123;&#20248;&#28857;&#30340;&#26681;&#28304;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20174;&#22122;&#22768;&#21521;&#37327;&#27979;&#37327;$y = Mx + w$&#20013;&#22238;&#22797;&#32447;&#24615;&#25805;&#20316;&#31526;$M$&#30340;&#19968;&#33324;&#27169;&#22411;&#12290;&#20854;&#20013;&#65292;&#21327;&#21464;&#37327;$x$&#26082;&#21487;&#20197;&#26159;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#65292;&#20063;&#21487;&#20197;&#26159;&#38750;&#21508;&#21521;&#21516;&#24615;&#30340;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#29616;&#26377;&#30340;&#21508;&#21521;&#21516;&#24615;&#26080;&#20851;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;&#20250;&#23545;&#34920;&#31034;&#26356;&#26032;&#36896;&#25104;&#20559;&#24046;&#65292;&#36825;&#23548;&#33268;&#22122;&#22768;&#39033;&#30340;&#32553;&#25918;&#19981;&#20877;&#26377;&#21033;&#20110;&#28304;&#20219;&#21153;&#25968;&#37327;&#12290;&#36825;&#21453;&#36807;&#26469;&#20250;&#23548;&#33268;&#34920;&#31034;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#21463;&#21040;&#21333;&#20219;&#21153;&#25968;&#25454;&#35268;&#27169;&#30340;&#38480;&#21046;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#31216;&#20026;&#21435;&#20559;&#24046;&#21644;&#29305;&#24449;&#30333;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
A powerful concept behind much of the recent progress in machine learning is the extraction of common features across data from heterogeneous sources or tasks. Intuitively, using all of one's data to learn a common representation function benefits both computational effort and statistical generalization by leaving a smaller number of parameters to fine-tune on a given task. Toward theoretically grounding these merits, we propose a general setting of recovering linear operators $M$ from noisy vector measurements $y = Mx + w$, where the covariates $x$ may be both non-i.i.d. and non-isotropic. We demonstrate that existing isotropy-agnostic meta-learning approaches incur biases on the representation update, which causes the scaling of the noise terms to lose favorable dependence on the number of source tasks. This in turn can cause the sample complexity of representation learning to be bottlenecked by the single-task data size. We introduce an adaptation, $\texttt{De-bias &amp; Feature-Whiten}
&lt;/p&gt;</description></item><item><title>VITS&#26159;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#21464;&#20998;&#25512;&#29702;&#30340;&#26032;&#31639;&#27861;&#65292;&#29992;&#20110;&#24773;&#22659;&#32972;&#31163;&#38382;&#39064;&#30340;&#27748;&#26222;&#26862;&#25277;&#26679;&#12290;&#23427;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#21518;&#39564;&#36817;&#20284;&#65292;&#35745;&#31639;&#25928;&#29575;&#39640;&#65292;&#24182;&#19988;&#22312;&#32447;&#24615;&#24773;&#22659;&#32972;&#31163;&#38382;&#39064;&#20013;&#36798;&#21040;&#19982;&#20256;&#32479;TS&#30456;&#21516;&#38454;&#25968;&#30340;&#27425;&#32447;&#24615;&#36951;&#25022;&#19978;&#30028;&#12290;</title><link>http://arxiv.org/abs/2307.10167</link><description>&lt;p&gt;
VITS: &#22522;&#20110;&#21464;&#20998;&#25512;&#29702;&#30340;&#27748;&#26222;&#26862;&#25277;&#26679;&#29992;&#20110;&#24773;&#22659;&#32972;&#31163;&#38382;&#39064;&#30340;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
VITS : Variational Inference Thomson Sampling for contextual bandits. (arXiv:2307.10167v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10167
&lt;/p&gt;
&lt;p&gt;
VITS&#26159;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#21464;&#20998;&#25512;&#29702;&#30340;&#26032;&#31639;&#27861;&#65292;&#29992;&#20110;&#24773;&#22659;&#32972;&#31163;&#38382;&#39064;&#30340;&#27748;&#26222;&#26862;&#25277;&#26679;&#12290;&#23427;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#21518;&#39564;&#36817;&#20284;&#65292;&#35745;&#31639;&#25928;&#29575;&#39640;&#65292;&#24182;&#19988;&#22312;&#32447;&#24615;&#24773;&#22659;&#32972;&#31163;&#38382;&#39064;&#20013;&#36798;&#21040;&#19982;&#20256;&#32479;TS&#30456;&#21516;&#38454;&#25968;&#30340;&#27425;&#32447;&#24615;&#36951;&#25022;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#24182;&#20998;&#26512;&#20102;&#19968;&#31181;&#29992;&#20110;&#24773;&#22659;&#32972;&#31163;&#38382;&#39064;&#30340;&#27748;&#26222;&#26862;&#25277;&#26679;&#65288;TS&#65289;&#31639;&#27861;&#30340;&#21464;&#20307;&#12290;&#20256;&#32479;&#30340;TS&#31639;&#27861;&#22312;&#27599;&#36718;&#38656;&#35201;&#20174;&#24403;&#21069;&#30340;&#21518;&#39564;&#20998;&#24067;&#20013;&#25277;&#26679;&#65292;&#32780;&#36825;&#36890;&#24120;&#26159;&#38590;&#20197;&#35745;&#31639;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#21487;&#20197;&#20351;&#29992;&#36817;&#20284;&#25512;&#29702;&#25216;&#26415;&#24182;&#25552;&#20379;&#25509;&#36817;&#21518;&#39564;&#20998;&#24067;&#30340;&#26679;&#26412;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#36817;&#20284;&#25216;&#26415;&#35201;&#20040;&#20272;&#35745;&#19981;&#20934;&#30830;&#65288;&#25289;&#26222;&#25289;&#26031;&#36817;&#20284;&#65289;&#65292;&#35201;&#20040;&#35745;&#31639;&#24320;&#38144;&#36739;&#22823;&#65288;MCMC&#26041;&#27861;&#65292;&#38598;&#25104;&#25277;&#26679;...&#65289;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#22522;&#20110;&#39640;&#26031;&#21464;&#20998;&#25512;&#29702;&#30340;&#21464;&#20998;&#25512;&#29702;&#27748;&#26222;&#26862;&#25277;&#26679;&#65288;VITS&#65289;&#12290;&#36825;&#31181;&#26041;&#27861;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#21518;&#39564;&#36817;&#20284;&#65292;&#24182;&#19988;&#23481;&#26131;&#20174;&#20013;&#25277;&#26679;&#65292;&#32780;&#19988;&#35745;&#31639;&#25928;&#29575;&#39640;&#65292;&#26159;TS&#30340;&#29702;&#24819;&#36873;&#25321;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#22312;&#32447;&#24615;&#24773;&#22659;&#32972;&#31163;&#38382;&#39064;&#20013;&#65292;VITS&#23454;&#29616;&#20102;&#19982;&#20256;&#32479;TS&#30456;&#21516;&#38454;&#25968;&#30340;&#27425;&#32447;&#24615;&#36951;&#25022;&#19978;&#30028;&#65292;&#19982;&#32500;&#24230;&#21644;&#22238;&#21512;&#25968;&#25104;&#27491;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce and analyze a variant of the Thompson sampling (TS) algorithm for contextual bandits. At each round, traditional TS requires samples from the current posterior distribution, which is usually intractable. To circumvent this issue, approximate inference techniques can be used and provide samples with distribution close to the posteriors. However, current approximate techniques yield to either poor estimation (Laplace approximation) or can be computationally expensive (MCMC methods, Ensemble sampling...). In this paper, we propose a new algorithm, Varational Inference Thompson sampling VITS, based on Gaussian Variational Inference. This scheme provides powerful posterior approximations which are easy to sample from, and is computationally efficient, making it an ideal choice for TS. In addition, we show that VITS achieves a sub-linear regret bound of the same order in the dimension and number of round as traditional TS for linear contextual bandit. Finally, we 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#21019;&#26032;&#30340;&#25628;&#32034;&#31639;&#27861;&#65292;&#22312;&#39640;&#32500;&#22270;&#32467;&#26500;&#23398;&#20064;&#20013;&#20351;&#29992;&#36793;&#38469;&#20266;&#20284;&#28982;&#20989;&#25968;&#35299;&#20915;&#35745;&#31639;&#22797;&#26434;&#24615;&#38382;&#39064;&#65292;&#24182;&#19988;&#33021;&#22815;&#22312;&#30701;&#26102;&#38388;&#20869;&#29983;&#25104;&#21487;&#38752;&#30340;&#20272;&#35745;&#12290;&#35813;&#26041;&#27861;&#25552;&#20379;&#20102;R&#36719;&#20214;&#21253;BDgraph&#30340;&#20195;&#30721;&#23454;&#29616;&#12290;</title><link>http://arxiv.org/abs/2307.00127</link><description>&lt;p&gt;
&#39640;&#32500;&#36125;&#21494;&#26031;&#39640;&#26031;&#22270;&#27169;&#22411;&#20013;&#30340;&#32467;&#26500;&#23398;&#20064;&#26041;&#27861;&#8212;&#8212;&#21033;&#29992;&#36793;&#38469;&#20266;&#20284;&#28982;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
High-Dimensional Bayesian Structure Learning in Gaussian Graphical Models using Marginal Pseudo-Likelihood. (arXiv:2307.00127v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00127
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#21019;&#26032;&#30340;&#25628;&#32034;&#31639;&#27861;&#65292;&#22312;&#39640;&#32500;&#22270;&#32467;&#26500;&#23398;&#20064;&#20013;&#20351;&#29992;&#36793;&#38469;&#20266;&#20284;&#28982;&#20989;&#25968;&#35299;&#20915;&#35745;&#31639;&#22797;&#26434;&#24615;&#38382;&#39064;&#65292;&#24182;&#19988;&#33021;&#22815;&#22312;&#30701;&#26102;&#38388;&#20869;&#29983;&#25104;&#21487;&#38752;&#30340;&#20272;&#35745;&#12290;&#35813;&#26041;&#27861;&#25552;&#20379;&#20102;R&#36719;&#20214;&#21253;BDgraph&#30340;&#20195;&#30721;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#22270;&#27169;&#22411;&#20197;&#22270;&#24418;&#24418;&#24335;&#25551;&#32472;&#20102;&#22810;&#20803;&#27491;&#24577;&#20998;&#24067;&#20013;&#21464;&#37327;&#20043;&#38388;&#30340;&#26465;&#20214;&#20381;&#36182;&#20851;&#31995;&#12290;&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#21019;&#26032;&#30340;&#25628;&#32034;&#31639;&#27861;&#65292;&#21033;&#29992;&#36793;&#38469;&#20266;&#20284;&#28982;&#20989;&#25968;&#26469;&#24212;&#23545;&#39640;&#32500;&#22270;&#32467;&#26500;&#23398;&#20064;&#20013;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#38382;&#39064;&#12290;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#22312;&#26631;&#20934;&#35745;&#31639;&#26426;&#19978;&#22312;&#20960;&#20998;&#38047;&#20869;&#24555;&#36895;&#29983;&#25104;&#23545;&#21253;&#21547;1000&#20010;&#21464;&#37327;&#30340;&#38382;&#39064;&#30340;&#21487;&#38752;&#20272;&#35745;&#12290;&#23545;&#20110;&#23545;&#23454;&#38469;&#24212;&#29992;&#24863;&#20852;&#36259;&#30340;&#20154;&#65292;&#25903;&#25345;&#36825;&#31181;&#26032;&#26041;&#27861;&#30340;&#20195;&#30721;&#36890;&#36807;R&#36719;&#20214;&#21253;BDgraph&#25552;&#20379;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian graphical models depict the conditional dependencies between variables within a multivariate normal distribution in a graphical format. The identification of these graph structures is an area known as structure learning. However, when utilizing Bayesian methodologies in structure learning, computational complexities can arise, especially with high-dimensional graphs surpassing 250 nodes. This paper introduces two innovative search algorithms that employ marginal pseudo-likelihood to address this computational challenge. These methods can swiftly generate reliable estimations for problems encompassing 1000 variables in just a few minutes on standard computers. For those interested in practical applications, the code supporting this new approach is made available through the R package BDgraph.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#32034;&#20102;&#21033;&#29992;&#23494;&#24230;&#20989;&#25968;&#30340;&#38750;&#32447;&#24615;&#21464;&#25442;&#23545;&#23725;&#30340;&#20272;&#35745;&#65292;&#24182;&#21457;&#29616;&#20854;&#21487;&#20197;&#25913;&#36827;&#23545;&#20999;&#31354;&#38388;&#30340;&#20272;&#35745;&#20197;&#21450;&#22312;&#36817;&#20284;&#24213;&#23618;&#30495;&#23454;&#27969;&#24418;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#27969;&#24418;&#25311;&#21512;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.05722</link><description>&lt;p&gt;
&#21033;&#29992;&#23494;&#24230;&#20989;&#25968;&#30340;&#38750;&#32447;&#24615;&#21464;&#25442;&#20272;&#35745;&#23725;
&lt;/p&gt;
&lt;p&gt;
Estimation of Ridge Using Nonlinear Transformation on Density Function. (arXiv:2306.05722v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05722
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#32034;&#20102;&#21033;&#29992;&#23494;&#24230;&#20989;&#25968;&#30340;&#38750;&#32447;&#24615;&#21464;&#25442;&#23545;&#23725;&#30340;&#20272;&#35745;&#65292;&#24182;&#21457;&#29616;&#20854;&#21487;&#20197;&#25913;&#36827;&#23545;&#20999;&#31354;&#38388;&#30340;&#20272;&#35745;&#20197;&#21450;&#22312;&#36817;&#20284;&#24213;&#23618;&#30495;&#23454;&#27969;&#24418;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#27969;&#24418;&#25311;&#21512;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23725;&#22312;&#20934;&#30830;&#36817;&#20284;&#27969;&#24418;&#30340;&#22522;&#30784;&#32467;&#26500;&#26041;&#38754;&#21457;&#25381;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#26412;&#25991;&#36890;&#36807;&#23558;&#20985;&#38750;&#32447;&#24615;&#21464;&#25442;&#24212;&#29992;&#20110;&#23494;&#24230;&#20989;&#25968;&#20197;&#25506;&#32034;&#23725;&#30340;&#21464;&#21270;&#12290;&#36890;&#36807;&#23545;Hessian&#30697;&#38453;&#30340;&#25512;&#23548;&#21644;&#20998;&#26512;&#65292;&#25105;&#20204;&#21457;&#29616;&#38750;&#32447;&#24615;&#21464;&#25442;&#20135;&#29983;&#20102;Hessian&#30697;&#38453;&#30340;&#31209;&#19968;&#20462;&#25913;&#12290;&#21033;&#29992;&#29305;&#24449;&#20540;&#38382;&#39064;&#30340;&#21464;&#20998;&#24615;&#36136;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#30456;&#24212;&#23725;&#20043;&#38388;&#30340;&#20559;&#24207;&#21253;&#21547;&#20851;&#31995;&#12290;&#25105;&#20204;&#30452;&#35266;&#22320;&#21457;&#29616;&#65292;&#36890;&#36807;Hessian&#30697;&#38453;&#30340;&#31209;&#19968;&#20462;&#25913;&#65292;&#21464;&#25442;&#21487;&#20197;&#23548;&#33268;&#23545;&#20999;&#31354;&#38388;&#30340;&#20272;&#35745;&#25913;&#36827;&#12290;&#20026;&#39564;&#35777;&#25105;&#20204;&#30340;&#29702;&#35770;&#65292;&#25105;&#20204;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#22823;&#37327;&#25968;&#20540;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#19982;&#20854;&#20182;&#27969;&#24418;&#25311;&#21512;&#31639;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#21464;&#25442;&#26041;&#27861;&#24471;&#21040;&#30340;&#23725;&#22312;&#36817;&#20284;&#24213;&#23618;&#30495;&#23454;&#27969;&#24418;&#26041;&#38754;&#26356;&#21152;&#20248;&#36234;&#12290;
&lt;/p&gt;
&lt;p&gt;
Ridges play a vital role in accurately approximating the underlying structure of manifolds. In this paper, we explore the ridge's variation by applying a concave nonlinear transformation to the density function. Through the derivation of the Hessian matrix, we observe that nonlinear transformations yield a rank-one modification of the Hessian matrix. Leveraging the variational properties of eigenvalue problems, we establish a partial order inclusion relationship among the corresponding ridges. We intuitively discover that the transformation can lead to improved estimation of the tangent space via rank-one modification of the Hessian matrix. To validate our theories, we conduct extensive numerical experiments on synthetic and real-world datasets that demonstrate the superiority of the ridges obtained from our transformed approach in approximating the underlying truth manifold compared to other manifold fitting algorithms.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20989;&#25968;&#25968;&#25454;&#30340;&#20998;&#24067;&#24335;&#26799;&#24230;&#19979;&#38477;&#20989;&#25968;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#26694;&#26550;&#19979;&#36890;&#36807;&#31215;&#20998;&#31639;&#23376;&#26041;&#27861;&#24471;&#21040;&#20102;&#35813;&#31639;&#27861;&#30340;&#29702;&#35770;&#29702;&#35299;&#65292;&#24182;&#21462;&#24471;&#20102;&#19981;&#39281;&#21644;&#36793;&#30028;&#30340;&#32622;&#20449;&#24230;&#26368;&#20248;&#23398;&#20064;&#29575;&#12290;</title><link>http://arxiv.org/abs/2305.07408</link><description>&lt;p&gt;
&#38754;&#21521;&#20989;&#25968;&#23398;&#20064;&#30340;&#20998;&#24067;&#24335;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Distributed Gradient Descent for Functional Learning. (arXiv:2305.07408v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07408
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20989;&#25968;&#25968;&#25454;&#30340;&#20998;&#24067;&#24335;&#26799;&#24230;&#19979;&#38477;&#20989;&#25968;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#26694;&#26550;&#19979;&#36890;&#36807;&#31215;&#20998;&#31639;&#23376;&#26041;&#27861;&#24471;&#21040;&#20102;&#35813;&#31639;&#27861;&#30340;&#29702;&#35770;&#29702;&#35299;&#65292;&#24182;&#21462;&#24471;&#20102;&#19981;&#39281;&#21644;&#36793;&#30028;&#30340;&#32622;&#20449;&#24230;&#26368;&#20248;&#23398;&#20064;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#19981;&#21516;&#31867;&#22411;&#30340;&#20998;&#24067;&#24335;&#23398;&#20064;&#26041;&#26696;&#22240;&#20854;&#22312;&#22788;&#29702;&#22823;&#35268;&#27169;&#25968;&#25454;&#20449;&#24687;&#26041;&#38754;&#30340;&#24040;&#22823;&#20248;&#21183;&#32780;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#38024;&#23545;&#26368;&#36817;&#20174;&#20989;&#25968;&#25968;&#25454;&#20998;&#26512;&#20013;&#20135;&#29983;&#30340;&#22823;&#25968;&#25454;&#25361;&#25112;&#65292;&#25105;&#20204;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#26694;&#26550;&#19979;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#24067;&#24335;&#26799;&#24230;&#19979;&#38477;&#20989;&#25968;&#23398;&#20064;&#65288;DGDFL&#65289;&#31639;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#26469;&#33258;&#20247;&#22810;&#26412;&#22320;&#26426;&#22120;&#65288;&#22788;&#29702;&#22120;&#65289;&#30340;&#20989;&#25968;&#25968;&#25454;&#12290;&#22522;&#20110;&#31215;&#20998;&#31639;&#23376;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;DGDFL&#31639;&#27861;&#22312;&#25991;&#29486;&#20013;&#30340;&#35768;&#22810;&#26041;&#38754;&#30340;&#31532;&#19968;&#20010;&#29702;&#35770;&#29702;&#35299;&#12290;&#22312;&#29702;&#35299;DGDFL&#30340;&#36807;&#31243;&#20013;&#65292;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#24182;&#20840;&#38754;&#30740;&#31350;&#20102;&#22522;&#20110;&#25968;&#25454;&#30340;&#28176;&#36827;&#24335;&#19979;&#38477;&#20989;&#25968;&#23398;&#20064;&#65288;GDFL&#65289;&#31639;&#27861;&#19982;&#21333;&#26426;&#27169;&#22411;&#30456;&#20851;&#32852;&#12290;&#22312;&#28201;&#21644;&#30340;&#26465;&#20214;&#19979;&#65292;&#24471;&#21040;&#20102;DGDFL&#30340;&#32622;&#20449;&#24230;&#26368;&#20248;&#23398;&#20064;&#29575;&#65292;&#36991;&#20813;&#20102;&#20808;&#21069;&#22312;&#27491;&#21017;&#24615;&#32034;&#24341;&#19978;&#36973;&#21463;&#30340;&#39281;&#21644;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, different types of distributed learning schemes have received increasing attention for their strong advantages in handling large-scale data information. In the information era, to face the big data challenges which stem from functional data analysis very recently, we propose a novel distributed gradient descent functional learning (DGDFL) algorithm to tackle functional data across numerous local machines (processors) in the framework of reproducing kernel Hilbert space. Based on integral operator approaches, we provide the first theoretical understanding of the DGDFL algorithm in many different aspects in the literature. On the way of understanding DGDFL, firstly, a data-based gradient descent functional learning (GDFL) algorithm associated with a single-machine model is proposed and comprehensively studied. Under mild conditions, confidence-based optimal learning rates of DGDFL are obtained without the saturation boundary on the regularity index suffered in previous w
&lt;/p&gt;</description></item></channel></rss>