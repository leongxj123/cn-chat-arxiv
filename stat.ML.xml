<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>GLAD&#26159;&#19968;&#20010;&#22312;&#31163;&#25955;&#28508;&#22312;&#31354;&#38388;&#19978;&#25805;&#20316;&#30340;&#22270;&#29983;&#25104;&#27169;&#22411;&#65292;&#36890;&#36807;&#36866;&#24212;&#25193;&#25955;&#26725;&#32467;&#26500;&#23398;&#20064;&#20854;&#31163;&#25955;&#28508;&#22312;&#31354;&#38388;&#30340;&#20808;&#39564;&#65292;&#36991;&#20813;&#20102;&#20381;&#36182;&#20110;&#21407;&#22987;&#25968;&#25454;&#31354;&#38388;&#30340;&#20998;&#35299;&#65292;&#22312;&#22270;&#29983;&#25104;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.16883</link><description>&lt;p&gt;
&#24102;&#25193;&#25955;&#26725;&#30340;&#31163;&#25955;&#28508;&#22312;&#22270;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Discrete Latent Graph Generative Modeling with Diffusion Bridges
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16883
&lt;/p&gt;
&lt;p&gt;
GLAD&#26159;&#19968;&#20010;&#22312;&#31163;&#25955;&#28508;&#22312;&#31354;&#38388;&#19978;&#25805;&#20316;&#30340;&#22270;&#29983;&#25104;&#27169;&#22411;&#65292;&#36890;&#36807;&#36866;&#24212;&#25193;&#25955;&#26725;&#32467;&#26500;&#23398;&#20064;&#20854;&#31163;&#25955;&#28508;&#22312;&#31354;&#38388;&#30340;&#20808;&#39564;&#65292;&#36991;&#20813;&#20102;&#20381;&#36182;&#20110;&#21407;&#22987;&#25968;&#25454;&#31354;&#38388;&#30340;&#20998;&#35299;&#65292;&#22312;&#22270;&#29983;&#25104;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#28508;&#22312;&#31354;&#38388;&#20013;&#30340;&#22270;&#29983;&#25104;&#27169;&#22411;&#30456;&#27604;&#20110;&#22312;&#21407;&#22987;&#25968;&#25454;&#31354;&#38388;&#19978;&#25805;&#20316;&#30340;&#27169;&#22411;&#21463;&#21040;&#36739;&#23569;&#20851;&#27880;&#65292;&#36804;&#20170;&#34920;&#29616;&#20986;&#30340;&#24615;&#33021;&#20047;&#21892;&#21487;&#38472;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;GLAD&#65292;&#19968;&#20010;&#28508;&#22312;&#31354;&#38388;&#22270;&#29983;&#25104;&#27169;&#22411;&#12290;&#19982;&#22823;&#22810;&#25968;&#20808;&#21069;&#30340;&#28508;&#22312;&#31354;&#38388;&#22270;&#29983;&#25104;&#27169;&#22411;&#19981;&#21516;&#65292;GLAD&#22312;&#20445;&#30041;&#22270;&#32467;&#26500;&#30340;&#31163;&#25955;&#24615;&#36136;&#26041;&#38754;&#36816;&#34892;&#65292;&#26080;&#38656;&#36827;&#34892;&#35832;&#22914;&#28508;&#22312;&#31354;&#38388;&#36830;&#32493;&#24615;&#31561;&#19981;&#33258;&#28982;&#30340;&#20551;&#35774;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#25193;&#25955;&#26725;&#35843;&#25972;&#21040;&#20854;&#32467;&#26500;&#65292;&#26469;&#23398;&#20064;&#25105;&#20204;&#31163;&#25955;&#28508;&#22312;&#31354;&#38388;&#30340;&#20808;&#39564;&#12290;&#36890;&#36807;&#22312;&#36866;&#24403;&#26500;&#24314;&#30340;&#28508;&#22312;&#31354;&#38388;&#19978;&#25805;&#20316;&#65292;&#25105;&#20204;&#36991;&#20813;&#20381;&#36182;&#20110;&#24120;&#29992;&#20110;&#22312;&#21407;&#22987;&#25968;&#25454;&#31354;&#38388;&#25805;&#20316;&#30340;&#27169;&#22411;&#20013;&#30340;&#20998;&#35299;&#12290;&#25105;&#20204;&#22312;&#19968;&#31995;&#21015;&#22270;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#23454;&#39564;&#65292;&#26126;&#26174;&#23637;&#31034;&#20102;&#31163;&#25955;&#28508;&#22312;&#31354;&#38388;&#30340;&#20248;&#36234;&#24615;&#65292;&#24182;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#22270;&#29983;&#25104;&#24615;&#33021;&#65292;&#20351;GLA
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16883v1 Announce Type: new  Abstract: Learning graph generative models over latent spaces has received less attention compared to models that operate on the original data space and has so far demonstrated lacklustre performance. We present GLAD a latent space graph generative model. Unlike most previous latent space graph generative models, GLAD operates on a discrete latent space that preserves to a significant extent the discrete nature of the graph structures making no unnatural assumptions such as latent space continuity. We learn the prior of our discrete latent space by adapting diffusion bridges to its structure. By operating over an appropriately constructed latent space we avoid relying on decompositions that are often used in models that operate in the original data space. We present experiments on a series of graph benchmark datasets which clearly show the superiority of the discrete latent space and obtain state of the art graph generative performance, making GLA
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#36716;&#23548;&#30340;&#27010;&#24565;&#65292;&#25552;&#20986;&#20102;PARMESAN&#65292;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#23494;&#38598;&#39044;&#27979;&#20219;&#21153;&#30340;&#26080;&#21442;&#25968;&#20869;&#23384;&#25628;&#32034;&#21644;&#36716;&#23548;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#28789;&#27963;&#24615;&#21644;&#26080;&#38656;&#36830;&#32493;&#35757;&#32451;&#30340;&#23398;&#20064;&#12290;</title><link>https://arxiv.org/abs/2403.11743</link><description>&lt;p&gt;
PARMESAN: &#29992;&#20110;&#23494;&#38598;&#39044;&#27979;&#20219;&#21153;&#30340;&#26080;&#21442;&#25968;&#20869;&#23384;&#25628;&#32034;&#19982;&#36716;&#23548;
&lt;/p&gt;
&lt;p&gt;
PARMESAN: Parameter-Free Memory Search and Transduction for Dense Prediction Tasks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11743
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#36716;&#23548;&#30340;&#27010;&#24565;&#65292;&#25552;&#20986;&#20102;PARMESAN&#65292;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#23494;&#38598;&#39044;&#27979;&#20219;&#21153;&#30340;&#26080;&#21442;&#25968;&#20869;&#23384;&#25628;&#32034;&#21644;&#36716;&#23548;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#28789;&#27963;&#24615;&#21644;&#26080;&#38656;&#36830;&#32493;&#35757;&#32451;&#30340;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#36716;&#23548;&#25512;&#29702;&#26469;&#35299;&#20915;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#28789;&#27963;&#24615;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;PARMESAN&#65288;&#26080;&#21442;&#25968;&#20869;&#23384;&#25628;&#32034;&#19982;&#36716;&#23548;&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#36716;&#23548;&#26041;&#27861;&#65292;&#21033;&#29992;&#20869;&#23384;&#27169;&#22359;&#26469;&#35299;&#20915;&#23494;&#38598;&#39044;&#27979;&#20219;&#21153;&#12290;&#22312;&#25512;&#26029;&#36807;&#31243;&#20013;&#65292;&#20869;&#23384;&#20013;&#30340;&#38544;&#34255;&#34920;&#31034;&#34987;&#25628;&#32034;&#20197;&#25214;&#21040;&#30456;&#24212;&#30340;&#31034;&#20363;&#12290;&#19982;&#20854;&#20182;&#26041;&#27861;&#19981;&#21516;&#65292;PARMESAN&#36890;&#36807;&#20462;&#25913;&#20869;&#23384;&#20869;&#23481;&#23398;&#20064;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#20219;&#20309;&#36830;&#32493;&#35757;&#32451;&#25110;&#24494;&#35843;&#21487;&#23398;&#20064;&#21442;&#25968;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#24120;&#29992;&#30340;&#31070;&#32463;&#32467;&#26500;&#20860;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11743v1 Announce Type: new  Abstract: In this work we address flexibility in deep learning by means of transductive reasoning. For adaptation to new tasks or new data, existing methods typically involve tuning of learnable parameters or even complete re-training from scratch, rendering such approaches unflexible in practice. We argue that the notion of separating computation from memory by the means of transduction can act as a stepping stone for solving these issues. We therefore propose PARMESAN (parameter-free memory search and transduction), a scalable transduction method which leverages a memory module for solving dense prediction tasks. At inference, hidden representations in memory are being searched to find corresponding examples. In contrast to other methods, PARMESAN learns without the requirement for any continuous training or fine-tuning of learnable parameters simply by modifying the memory content. Our method is compatible with commonly used neural architecture
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21453;&#39304;&#39640;&#25928;&#30340;&#22312;&#32447;&#24494;&#35843;&#25193;&#25955;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#31243;&#24207;</title><link>https://arxiv.org/abs/2402.16359</link><description>&lt;p&gt;
&#21453;&#39304;&#39640;&#25928;&#22312;&#32447;&#24494;&#35843;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Feedback Efficient Online Fine-Tuning of Diffusion Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16359
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21453;&#39304;&#39640;&#25928;&#30340;&#22312;&#32447;&#24494;&#35843;&#25193;&#25955;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#31243;&#24207;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#22312;&#24314;&#27169;&#22797;&#26434;&#25968;&#25454;&#20998;&#24067;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#21253;&#25324;&#22270;&#20687;&#65292;&#34507;&#30333;&#36136;&#21644;&#23567;&#20998;&#23376;&#30340;&#20998;&#24067;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#27169;&#25311;&#26368;&#22823;&#21270;&#26576;&#20123;&#23646;&#24615;&#30340;&#20998;&#24067;&#30340;&#37096;&#20998;&#65306;&#20363;&#22914;&#65292;&#25105;&#20204;&#21487;&#33021;&#24076;&#26395;&#29983;&#25104;&#20855;&#26377;&#39640;&#23457;&#32654;&#36136;&#37327;&#30340;&#22270;&#20687;&#65292;&#25110;&#20855;&#26377;&#39640;&#29983;&#29289;&#27963;&#24615;&#30340;&#20998;&#23376;&#12290;&#33258;&#28982;&#22320;&#65292;&#25105;&#20204;&#21487;&#20197;&#23558;&#36825;&#35270;&#20026;&#19968;&#20010;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#38382;&#39064;&#65292;&#20854;&#30446;&#26631;&#26159;&#24494;&#35843;&#25193;&#25955;&#27169;&#22411;&#20197;&#26368;&#22823;&#21270;&#19982;&#26576;&#20123;&#23646;&#24615;&#23545;&#24212;&#30340;&#22870;&#21169;&#20989;&#25968;&#12290;&#21363;&#20351;&#21487;&#20197;&#35775;&#38382;&#22320;&#38754;&#30495;&#23454;&#22870;&#21169;&#20989;&#25968;&#30340;&#22312;&#32447;&#26597;&#35810;&#65292;&#26377;&#25928;&#22320;&#21457;&#29616;&#39640;&#22870;&#21169;&#26679;&#26412;&#20063;&#21487;&#33021;&#20855;&#26377;&#25361;&#25112;&#24615;&#65306;&#23427;&#20204;&#22312;&#21021;&#22987;&#20998;&#24067;&#20013;&#30340;&#27010;&#29575;&#21487;&#33021;&#24456;&#20302;&#65292;&#24182;&#19988;&#21487;&#33021;&#23384;&#22312;&#35768;&#22810;&#19981;&#21487;&#34892;&#30340;&#26679;&#26412;&#65292;&#29978;&#33267;&#27809;&#26377;&#23450;&#20041;&#33391;&#22909;&#30340;&#22870;&#21169;&#65288;&#20363;&#22914;&#65292;&#19981;&#33258;&#28982;&#30340;&#22270;&#20687;&#25110;&#29289;&#29702;&#19978;&#19981;&#21487;&#33021;&#30340;&#20998;&#23376;&#65289;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24378;&#21270;&#23398;&#20064;&#31243;&#24207;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#21457;&#29616;&#39640;&#22870;&#21169;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16359v1 Announce Type: cross  Abstract: Diffusion models excel at modeling complex data distributions, including those of images, proteins, and small molecules. However, in many cases, our goal is to model parts of the distribution that maximize certain properties: for example, we may want to generate images with high aesthetic quality, or molecules with high bioactivity. It is natural to frame this as a reinforcement learning (RL) problem, in which the objective is to fine-tune a diffusion model to maximize a reward function that corresponds to some property. Even with access to online queries of the ground-truth reward function, efficiently discovering high-reward samples can be challenging: they might have a low probability in the initial distribution, and there might be many infeasible samples that do not even have a well-defined reward (e.g., unnatural images or physically impossible molecules). In this work, we propose a novel reinforcement learning procedure that effi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#19968;&#20010;&#26080;&#32447;&#31995;&#32479;&#20013;&#65292;&#32771;&#34385;&#21040;&#20449;&#24687;&#35770;&#38544;&#31169;&#30340;&#26465;&#20214;&#19979;&#65292;&#36890;&#36807;&#22522;&#31449;&#36830;&#25509;&#21040;&#32852;&#21512;&#22120;&#30340;&#23458;&#25143;&#31471;&#65292;&#22914;&#20309;&#35299;&#20915;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#38544;&#31169;&#25968;&#25454;&#32858;&#21512;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.14088</link><description>&lt;p&gt;
&#38750;&#21516;&#36136;&#21270;&#38598;&#32676;&#19979;&#30340;&#26080;&#32447;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#31169;&#26377;&#25968;&#25454;&#32858;&#21512;
&lt;/p&gt;
&lt;p&gt;
Private Aggregation in Wireless Federated Learning with Heterogeneous Clusters. (arXiv:2306.14088v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14088
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#19968;&#20010;&#26080;&#32447;&#31995;&#32479;&#20013;&#65292;&#32771;&#34385;&#21040;&#20449;&#24687;&#35770;&#38544;&#31169;&#30340;&#26465;&#20214;&#19979;&#65292;&#36890;&#36807;&#22522;&#31449;&#36830;&#25509;&#21040;&#32852;&#21512;&#22120;&#30340;&#23458;&#25143;&#31471;&#65292;&#22914;&#20309;&#35299;&#20915;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#38544;&#31169;&#25968;&#25454;&#32858;&#21512;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#26159;&#36890;&#36807;&#22810;&#20010;&#21442;&#19982;&#23458;&#25143;&#31471;&#31169;&#26377;&#25968;&#25454;&#30340;&#21327;&#21516;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#12290;&#22312;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#30340;&#36807;&#31243;&#20013;&#65292;&#20351;&#29992;&#19968;&#31181;&#33879;&#21517;&#24182;&#24191;&#27867;&#20351;&#29992;&#30340;&#36845;&#20195;&#20248;&#21270;&#31639;&#27861;&#8212;&#8212;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#12290;&#27599;&#20010;&#23458;&#25143;&#31471;&#20351;&#29992;&#26412;&#22320;&#25968;&#25454;&#35745;&#31639;&#23616;&#37096;&#26799;&#24230;&#24182;&#23558;&#20854;&#21457;&#36865;&#32473;&#32852;&#21512;&#22120;&#20197;&#36827;&#34892;&#32858;&#21512;&#12290;&#23458;&#25143;&#31471;&#25968;&#25454;&#30340;&#38544;&#31169;&#26159;&#19968;&#20010;&#20027;&#35201;&#38382;&#39064;&#12290;&#23454;&#38469;&#19978;&#65292;&#35266;&#23519;&#21040;&#23616;&#37096;&#26799;&#24230;&#23601;&#36275;&#20197;&#27844;&#38706;&#23458;&#25143;&#31471;&#30340;&#25968;&#25454;&#12290;&#24050;&#30740;&#31350;&#20102;&#29992;&#20110;&#24212;&#23545;&#32852;&#37030;&#23398;&#20064;&#20013;&#38544;&#31169;&#38382;&#39064;&#30340;&#31169;&#26377;&#32858;&#21512;&#26041;&#26696;&#65292;&#20854;&#20013;&#25152;&#26377;&#29992;&#25143;&#37117;&#24444;&#27492;&#36830;&#25509;&#24182;&#19982;&#32852;&#21512;&#22120;&#36830;&#25509;&#12290;&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#20010;&#26080;&#32447;&#31995;&#32479;&#26550;&#26500;&#65292;&#20854;&#20013;&#23458;&#25143;&#31471;&#20165;&#36890;&#36807;&#22522;&#31449;&#36830;&#25509;&#21040;&#32852;&#21512;&#22120;&#12290;&#24403;&#38656;&#35201;&#20449;&#24687;&#35770;&#38544;&#31169;&#26102;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#36890;&#20449;&#25104;&#26412;&#30340;&#22522;&#26412;&#26497;&#38480;&#65292;&#24182;&#24341;&#20837;&#21644;&#20998;&#26512;&#20102;&#19968;&#31181;&#38024;&#23545;&#36825;&#31181;&#24773;&#20917;&#37327;&#36523;&#23450;&#21046;&#30340;&#31169;&#26377;&#32858;&#21512;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated learning collaboratively trains a neural network on privately owned data held by several participating clients. The gradient descent algorithm, a well-known and popular iterative optimization procedure, is run to train the neural network. Every client uses its local data to compute partial gradients and sends it to the federator which aggregates the results. Privacy of the clients' data is a major concern. In fact, observing the partial gradients can be enough to reveal the clients' data. Private aggregation schemes have been investigated to tackle the privacy problem in federated learning where all the users are connected to each other and to the federator. In this paper, we consider a wireless system architecture where clients are only connected to the federator via base stations. We derive fundamental limits on the communication cost when information-theoretic privacy is required, and introduce and analyze a private aggregation scheme tailored for this setting.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#31574;&#30053;&#30340;&#37327;&#21270;&#38598;&#21453;&#28436;&#26041;&#27861;&#65292;&#36890;&#36807;&#39640;&#26031;&#36807;&#31243;&#24314;&#27169;&#21644;&#36880;&#27493;&#19981;&#30830;&#23450;&#24615;&#20943;&#23569;&#21407;&#29702;&#65292;&#39034;&#24207;&#36873;&#25321;&#35780;&#20272;&#20989;&#25968;&#30340;&#28857;&#65292;&#20174;&#32780;&#26377;&#25928;&#36817;&#20284;&#24863;&#20852;&#36259;&#30340;&#38598;&#21512;&#12290;</title><link>http://arxiv.org/abs/2211.01008</link><description>&lt;p&gt;
&#22522;&#20110;&#36125;&#21494;&#26031;&#24207;&#36143;&#35774;&#35745;&#30340;&#35745;&#31639;&#26426;&#23454;&#39564;&#37327;&#21270;&#38598;&#21453;&#28436;
&lt;/p&gt;
&lt;p&gt;
Bayesian sequential design of computer experiments for quantile set inversion. (arXiv:2211.01008v2 [stat.ML] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.01008
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#31574;&#30053;&#30340;&#37327;&#21270;&#38598;&#21453;&#28436;&#26041;&#27861;&#65292;&#36890;&#36807;&#39640;&#26031;&#36807;&#31243;&#24314;&#27169;&#21644;&#36880;&#27493;&#19981;&#30830;&#23450;&#24615;&#20943;&#23569;&#21407;&#29702;&#65292;&#39034;&#24207;&#36873;&#25321;&#35780;&#20272;&#20989;&#25968;&#30340;&#28857;&#65292;&#20174;&#32780;&#26377;&#25928;&#36817;&#20284;&#24863;&#20852;&#36259;&#30340;&#38598;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#19968;&#20010;&#26410;&#30693;&#30340;&#22810;&#20803;&#20989;&#25968;&#65292;&#23427;&#20195;&#34920;&#30528;&#19968;&#20010;&#31995;&#32479;&#65292;&#22914;&#19968;&#20010;&#22797;&#26434;&#30340;&#25968;&#20540;&#27169;&#25311;&#22120;&#65292;&#21516;&#26102;&#20855;&#26377;&#30830;&#23450;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#30340;&#36755;&#20837;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#20272;&#35745;&#30830;&#23450;&#24615;&#36755;&#20837;&#38598;&#65292;&#36825;&#20123;&#36755;&#20837;&#23548;&#33268;&#30340;&#36755;&#20986;&#65288;&#23601;&#19981;&#30830;&#23450;&#24615;&#36755;&#20837;&#30340;&#20998;&#24067;&#32780;&#35328;&#65289;&#23646;&#20110;&#32473;&#23450;&#38598;&#21512;&#30340;&#27010;&#29575;&#23567;&#20110;&#32473;&#23450;&#38408;&#20540;&#12290;&#36825;&#20010;&#38382;&#39064;&#34987;&#31216;&#20026;&#37327;&#21270;&#38598;&#21453;&#28436;&#65288;QSI&#65289;&#65292;&#20363;&#22914;&#22312;&#31283;&#20581;&#65288;&#22522;&#20110;&#21487;&#38752;&#24615;&#65289;&#20248;&#21270;&#38382;&#39064;&#30340;&#32972;&#26223;&#19979;&#65292;&#24403;&#23547;&#25214;&#28385;&#36275;&#32422;&#26463;&#26465;&#20214;&#19988;&#20855;&#26377;&#36275;&#22815;&#22823;&#27010;&#29575;&#30340;&#35299;&#38598;&#26102;&#20250;&#21457;&#29983;&#12290;&#20026;&#20102;&#35299;&#20915;QSI&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#24314;&#27169;&#21644;&#36880;&#27493;&#19981;&#30830;&#23450;&#24615;&#20943;&#23569;&#65288;SUR&#65289;&#21407;&#29702;&#30340;&#36125;&#21494;&#26031;&#31574;&#30053;&#65292;&#20197;&#39034;&#24207;&#36873;&#25321;&#24212;&#35813;&#35780;&#20272;&#20989;&#25968;&#30340;&#28857;&#65292;&#20197;&#20415;&#39640;&#25928;&#36817;&#20284;&#24863;&#20852;&#36259;&#30340;&#38598;&#21512;&#12290;&#36890;&#36807;&#20960;&#20010;&#25968;&#20540;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;SUR&#31574;&#30053;&#30340;&#24615;&#33021;&#21644;&#20215;&#20540;
&lt;/p&gt;
&lt;p&gt;
We consider an unknown multivariate function representing a system-such as a complex numerical simulator-taking both deterministic and uncertain inputs. Our objective is to estimate the set of deterministic inputs leading to outputs whose probability (with respect to the distribution of the uncertain inputs) of belonging to a given set is less than a given threshold. This problem, which we call Quantile Set Inversion (QSI), occurs for instance in the context of robust (reliability-based) optimization problems, when looking for the set of solutions that satisfy the constraints with sufficiently large probability. To solve the QSI problem, we propose a Bayesian strategy based on Gaussian process modeling and the Stepwise Uncertainty Reduction (SUR) principle, to sequentially choose the points at which the function should be evaluated to efficiently approximate the set of interest. We illustrate the performance and interest of the proposed SUR strategy through several numerical experiment
&lt;/p&gt;</description></item></channel></rss>