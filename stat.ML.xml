<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;MA-COPP&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#35299;&#20915;&#28041;&#21450;&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#30340;&#31163;&#31574;&#30053;&#39044;&#27979;&#38382;&#39064;&#30340;&#19968;&#33268;&#39044;&#27979;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.16871</link><description>&lt;p&gt;
&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#30340;&#19968;&#33268;&#31163;&#31574;&#30053;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Conformal Off-Policy Prediction for Multi-Agent Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16871
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;MA-COPP&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#35299;&#20915;&#28041;&#21450;&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#30340;&#31163;&#31574;&#30053;&#39044;&#27979;&#38382;&#39064;&#30340;&#19968;&#33268;&#39044;&#27979;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#31574;&#30053;&#39044;&#27979;&#65288;OPP&#65289;&#65292;&#21363;&#20165;&#20351;&#29992;&#22312;&#19968;&#20010;&#27491;&#24120;&#65288;&#34892;&#20026;&#65289;&#31574;&#30053;&#19979;&#25910;&#38598;&#30340;&#25968;&#25454;&#26469;&#39044;&#27979;&#30446;&#26631;&#31574;&#30053;&#30340;&#32467;&#26524;&#65292;&#22312;&#25968;&#25454;&#39537;&#21160;&#30340;&#23433;&#20840;&#20851;&#38190;&#31995;&#32479;&#20998;&#26512;&#20013;&#26159;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#65292;&#22312;&#36825;&#31181;&#31995;&#32479;&#20013;&#65292;&#37096;&#32626;&#26032;&#31574;&#30053;&#21487;&#33021;&#26159;&#19981;&#23433;&#20840;&#30340;&#12290;&#20026;&#20102;&#23454;&#29616;&#21487;&#20449;&#30340;&#31163;&#31574;&#30053;&#39044;&#27979;&#65292;&#26368;&#36817;&#20851;&#20110;&#19968;&#33268;&#31163;&#31574;&#30053;&#39044;&#27979;&#65288;COPP&#65289;&#30340;&#24037;&#20316;&#21033;&#29992;&#19968;&#33268;&#39044;&#27979;&#26694;&#26550;&#26469;&#22312;&#30446;&#26631;&#36807;&#31243;&#19979;&#25512;&#23548;&#24102;&#26377;&#27010;&#29575;&#20445;&#35777;&#30340;&#39044;&#27979;&#21306;&#22495;&#12290;&#29616;&#26377;&#30340;COPP&#26041;&#27861;&#21487;&#20197;&#32771;&#34385;&#30001;&#31574;&#30053;&#20999;&#25442;&#24341;&#36215;&#30340;&#20998;&#24067;&#20559;&#31227;&#65292;&#20294;&#20165;&#38480;&#20110;&#21333;&#26234;&#33021;&#20307;&#31995;&#32479;&#21644;&#26631;&#37327;&#32467;&#26524;&#65288;&#20363;&#22914;&#65292;&#22870;&#21169;&#65289;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;MA-COPP&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#35299;&#20915;&#28041;&#21450;&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#30340;OPP&#38382;&#39064;&#30340;&#19968;&#33268;&#39044;&#27979;&#26041;&#27861;&#65292;&#22312;&#19968;&#20010;&#25110;&#22810;&#20010;&#8220;&#33258;&#25105;&#8221;&#26234;&#33021;&#20307;&#25913;&#21464;&#31574;&#30053;&#26102;&#20026;&#25152;&#26377;&#26234;&#33021;&#20307;&#36712;&#36857;&#25512;&#23548;&#32852;&#21512;&#39044;&#27979;&#21306;&#22495;&#12290;&#19982;&#21333;&#26234;&#33021;&#20307;&#22330;&#26223;&#19981;&#21516;&#65292;&#36825;&#31181;&#24773;&#20917;&#19979;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16871v1 Announce Type: cross  Abstract: Off-Policy Prediction (OPP), i.e., predicting the outcomes of a target policy using only data collected under a nominal (behavioural) policy, is a paramount problem in data-driven analysis of safety-critical systems where the deployment of a new policy may be unsafe. To achieve dependable off-policy predictions, recent work on Conformal Off-Policy Prediction (COPP) leverage the conformal prediction framework to derive prediction regions with probabilistic guarantees under the target process. Existing COPP methods can account for the distribution shifts induced by policy switching, but are limited to single-agent systems and scalar outcomes (e.g., rewards). In this work, we introduce MA-COPP, the first conformal prediction method to solve OPP problems involving multi-agent systems, deriving joint prediction regions for all agents' trajectories when one or more "ego" agents change their policies. Unlike the single-agent scenario, this se
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#31181;&#20551;&#35774;&#31616;&#21270;&#21644;&#25968;&#25454;&#33258;&#36866;&#24212;&#30340;&#21518;&#39044;&#27979;&#25512;&#26029;&#65288;POP-Inf&#65289;&#36807;&#31243;&#65292;&#21487;&#20197;&#26377;&#25928;&#19988;&#26377;&#21147;&#22320;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#39044;&#27979;&#32467;&#26524;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#12290;</title><link>https://arxiv.org/abs/2311.14220</link><description>&lt;p&gt;
&#20551;&#35774;&#31616;&#21270;&#21644;&#25968;&#25454;&#33258;&#36866;&#24212;&#30340;&#21518;&#39044;&#27979;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Assumption-lean and Data-adaptive Post-Prediction Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.14220
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#31181;&#20551;&#35774;&#31616;&#21270;&#21644;&#25968;&#25454;&#33258;&#36866;&#24212;&#30340;&#21518;&#39044;&#27979;&#25512;&#26029;&#65288;POP-Inf&#65289;&#36807;&#31243;&#65292;&#21487;&#20197;&#26377;&#25928;&#19988;&#26377;&#21147;&#22320;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#39044;&#27979;&#32467;&#26524;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#31185;&#23398;&#30740;&#31350;&#38754;&#20020;&#30340;&#20027;&#35201;&#25361;&#25112;&#26159;&#40644;&#37329;&#26631;&#20934;&#25968;&#25454;&#30340;&#26377;&#38480;&#21487;&#29992;&#24615;&#65292;&#32780;&#33719;&#21462;&#36825;&#20123;&#25968;&#25454;&#26082;&#32791;&#36153;&#26102;&#38388;&#21448;&#36153;&#21147;&#12290;&#38543;&#30528;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#30340;&#24555;&#36895;&#21457;&#23637;&#65292;&#31185;&#23398;&#23478;&#20204;&#20381;&#36182;&#20110;ML&#31639;&#27861;&#20351;&#29992;&#26131;&#24471;&#30340;&#21327;&#21464;&#37327;&#26469;&#39044;&#27979;&#36825;&#20123;&#40644;&#37329;&#26631;&#20934;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#39044;&#27979;&#32467;&#26524;&#24120;&#24120;&#30452;&#25509;&#29992;&#20110;&#21518;&#32493;&#30340;&#32479;&#35745;&#20998;&#26512;&#20013;&#65292;&#24573;&#30053;&#20102;&#39044;&#27979;&#36807;&#31243;&#24341;&#20837;&#30340;&#19981;&#31934;&#30830;&#24615;&#21644;&#24322;&#36136;&#24615;&#12290;&#36825;&#21487;&#33021;&#23548;&#33268;&#34394;&#20551;&#30340;&#27491;&#38754;&#32467;&#26524;&#21644;&#26080;&#25928;&#30340;&#31185;&#23398;&#32467;&#35770;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#20551;&#35774;&#31616;&#21270;&#21644;&#25968;&#25454;&#33258;&#36866;&#24212;&#30340;&#21518;&#39044;&#27979;&#25512;&#26029;&#65288;POP-Inf&#65289;&#36807;&#31243;&#65292;&#23427;&#20801;&#35768;&#22522;&#20110;ML&#39044;&#27979;&#32467;&#26524;&#36827;&#34892;&#26377;&#25928;&#21644;&#26377;&#21147;&#30340;&#25512;&#26029;&#12290;&#23427;&#30340;&#8220;&#20551;&#35774;&#31616;&#21270;&#8221;&#23646;&#24615;&#20445;&#35777;&#22312;&#24191;&#27867;&#30340;&#32479;&#35745;&#37327;&#19978;&#19981;&#22522;&#20110;ML&#39044;&#27979;&#20570;&#20986;&#21487;&#38752;&#30340;&#32479;&#35745;&#25512;&#26029;&#12290;&#23427;&#30340;&#8220;&#25968;&#25454;&#33258;&#36866;&#24212;&#8221;&#29305;&#24615;&#20445;&#35777;&#20102;&#30456;&#36739;&#20110;&#29616;&#26377;&#26041;&#27861;&#30340;&#25928;&#29575;&#25552;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
A primary challenge facing modern scientific research is the limited availability of gold-standard data which can be both costly and labor-intensive to obtain. With the rapid development of machine learning (ML), scientists have relied on ML algorithms to predict these gold-standard outcomes with easily obtained covariates. However, these predicted outcomes are often used directly in subsequent statistical analyses, ignoring imprecision and heterogeneity introduced by the prediction procedure. This will likely result in false positive findings and invalid scientific conclusions. In this work, we introduce an assumption-lean and data-adaptive Post-Prediction Inference (POP-Inf) procedure that allows valid and powerful inference based on ML-predicted outcomes. Its "assumption-lean" property guarantees reliable statistical inference without assumptions on the ML-prediction, for a wide range of statistical quantities. Its "data-adaptive'" feature guarantees an efficiency gain over existing
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#32508;&#36848;&#20102;&#28145;&#24230;&#23398;&#20064;&#30340;&#32479;&#35745;&#29702;&#35770;&#65292;&#21253;&#25324;&#36817;&#20284;&#26041;&#27861;&#12289;&#35757;&#32451;&#21160;&#24577;&#21644;&#29983;&#25104;&#27169;&#22411;&#12290;&#22312;&#38750;&#21442;&#25968;&#26694;&#26550;&#20013;&#65292;&#32467;&#26524;&#25581;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#36807;&#24230;&#39118;&#38505;&#30340;&#24555;&#36895;&#25910;&#25947;&#36895;&#29575;&#65292;&#20197;&#21450;&#22914;&#20309;&#36890;&#36807;&#26799;&#24230;&#26041;&#27861;&#35757;&#32451;&#32593;&#32476;&#20197;&#25214;&#21040;&#33391;&#22909;&#30340;&#27867;&#21270;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2401.07187</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#30340;&#32479;&#35745;&#29702;&#35770;&#32508;&#36848;&#65306;&#36817;&#20284;&#65292;&#35757;&#32451;&#21160;&#24577;&#21644;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Survey on Statistical Theory of Deep Learning: Approximation, Training Dynamics, and Generative Models. (arXiv:2401.07187v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.07187
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#32508;&#36848;&#20102;&#28145;&#24230;&#23398;&#20064;&#30340;&#32479;&#35745;&#29702;&#35770;&#65292;&#21253;&#25324;&#36817;&#20284;&#26041;&#27861;&#12289;&#35757;&#32451;&#21160;&#24577;&#21644;&#29983;&#25104;&#27169;&#22411;&#12290;&#22312;&#38750;&#21442;&#25968;&#26694;&#26550;&#20013;&#65292;&#32467;&#26524;&#25581;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#36807;&#24230;&#39118;&#38505;&#30340;&#24555;&#36895;&#25910;&#25947;&#36895;&#29575;&#65292;&#20197;&#21450;&#22914;&#20309;&#36890;&#36807;&#26799;&#24230;&#26041;&#27861;&#35757;&#32451;&#32593;&#32476;&#20197;&#25214;&#21040;&#33391;&#22909;&#30340;&#27867;&#21270;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#25991;&#31456;&#20013;&#65292;&#25105;&#20204;&#20174;&#19977;&#20010;&#35282;&#24230;&#22238;&#39038;&#20102;&#20851;&#20110;&#31070;&#32463;&#32593;&#32476;&#32479;&#35745;&#29702;&#35770;&#30340;&#25991;&#29486;&#12290;&#31532;&#19968;&#37096;&#20998;&#22238;&#39038;&#20102;&#22312;&#22238;&#24402;&#25110;&#20998;&#31867;&#30340;&#38750;&#21442;&#25968;&#26694;&#26550;&#19979;&#20851;&#20110;&#31070;&#32463;&#32593;&#32476;&#36807;&#24230;&#39118;&#38505;&#30340;&#32467;&#26524;&#12290;&#36825;&#20123;&#32467;&#26524;&#20381;&#36182;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26174;&#24335;&#26500;&#36896;&#65292;&#20197;&#21450;&#37319;&#29992;&#20102;&#36817;&#20284;&#29702;&#35770;&#30340;&#24037;&#20855;&#65292;&#23548;&#33268;&#36807;&#24230;&#39118;&#38505;&#30340;&#24555;&#36895;&#25910;&#25947;&#36895;&#29575;&#12290;&#36890;&#36807;&#36825;&#20123;&#26500;&#36896;&#65292;&#21487;&#20197;&#29992;&#26679;&#26412;&#22823;&#23567;&#12289;&#25968;&#25454;&#32500;&#24230;&#21644;&#20989;&#25968;&#24179;&#28369;&#24615;&#26469;&#34920;&#36798;&#32593;&#32476;&#30340;&#23485;&#24230;&#21644;&#28145;&#24230;&#12290;&#28982;&#32780;&#65292;&#20182;&#20204;&#30340;&#22522;&#26412;&#20998;&#26512;&#20165;&#36866;&#29992;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#39640;&#24230;&#38750;&#20984;&#30340;&#20840;&#23616;&#26497;&#23567;&#20540;&#28857;&#12290;&#36825;&#20419;&#20351;&#25105;&#20204;&#22312;&#31532;&#20108;&#37096;&#20998;&#22238;&#39038;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#21160;&#24577;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#22238;&#39038;&#20102;&#37027;&#20123;&#35797;&#22270;&#22238;&#31572;&#8220;&#22522;&#20110;&#26799;&#24230;&#26041;&#27861;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#22914;&#20309;&#25214;&#21040;&#33021;&#22815;&#22312;&#26410;&#35265;&#25968;&#25454;&#19978;&#26377;&#33391;&#22909;&#27867;&#21270;&#24615;&#33021;&#30340;&#35299;&#8221;&#30340;&#35770;&#25991;&#12290;&#23588;&#20854;&#26159;&#20004;&#20010;&#30693;&#21517;&#30340;
&lt;/p&gt;
&lt;p&gt;
In this article, we review the literature on statistical theories of neural networks from three perspectives. In the first part, results on excess risks for neural networks are reviewed in the nonparametric framework of regression or classification. These results rely on explicit constructions of neural networks, leading to fast convergence rates of excess risks, in that tools from the approximation theory are adopted. Through these constructions, the width and depth of the networks can be expressed in terms of sample size, data dimension, and function smoothness. Nonetheless, their underlying analysis only applies to the global minimizer in the highly non-convex landscape of deep neural networks. This motivates us to review the training dynamics of neural networks in the second part. Specifically, we review papers that attempt to answer ``how the neural network trained via gradient-based methods finds the solution that can generalize well on unseen data.'' In particular, two well-know
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#21033;&#29992;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;&#27169;&#25311;&#29305;&#24449;&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#26500;&#24314;&#19968;&#20010;&#26222;&#36866;&#19988;&#26080;&#38656;&#20551;&#35774;&#30340;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;&#26469;&#35299;&#20915;&#12290;&#30740;&#31350;&#22522;&#20110;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#24230;&#37327;&#65292;&#24182;&#25552;&#20986;&#20102;&#26377;&#20851;&#36924;&#36817;&#36136;&#37327;&#30340;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2401.04778</link><description>&lt;p&gt;
&#21033;&#29992;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;&#27169;&#25311;&#29305;&#24449;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Generative neural networks for characteristic functions. (arXiv:2401.04778v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04778
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#21033;&#29992;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;&#27169;&#25311;&#29305;&#24449;&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#26500;&#24314;&#19968;&#20010;&#26222;&#36866;&#19988;&#26080;&#38656;&#20551;&#35774;&#30340;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;&#26469;&#35299;&#20915;&#12290;&#30740;&#31350;&#22522;&#20110;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#24230;&#37327;&#65292;&#24182;&#25552;&#20986;&#20102;&#26377;&#20851;&#36924;&#36817;&#36136;&#37327;&#30340;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#27169;&#25311;&#31639;&#27861;&#26469;&#20174;&#19968;&#20010;&#65288;&#22810;&#20803;&#65289;&#29305;&#24449;&#20989;&#25968;&#20013;&#27169;&#25311;&#65292;&#35813;&#29305;&#24449;&#20989;&#25968;&#20165;&#20197;&#40657;&#30418;&#26684;&#24335;&#21487;&#35775;&#38382;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;&#65292;&#20854;&#25439;&#22833;&#20989;&#25968;&#21033;&#29992;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#24230;&#37327;&#30340;&#29305;&#23450;&#34920;&#31034;&#65292;&#30452;&#25509;&#32467;&#21512;&#30446;&#26631;&#29305;&#24449;&#20989;&#25968;&#12290;&#36825;&#31181;&#26500;&#36896;&#20855;&#26377;&#26222;&#36941;&#24615;&#65292;&#19981;&#20381;&#36182;&#20110;&#32500;&#24230;&#65292;&#24182;&#19988;&#19981;&#38656;&#35201;&#23545;&#32473;&#23450;&#29305;&#24449;&#20989;&#25968;&#36827;&#34892;&#20219;&#20309;&#20551;&#35774;&#12290;&#27492;&#22806;&#65292;&#36824;&#24471;&#20986;&#20102;&#20851;&#20110;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#24230;&#37327;&#30340;&#36924;&#36817;&#36136;&#37327;&#30340;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#12290;&#35813;&#26041;&#27861;&#22312;&#19968;&#20010;&#30701;&#26399;&#27169;&#25311;&#30740;&#31350;&#20013;&#36827;&#34892;&#20102;&#35828;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we provide a simulation algorithm to simulate from a (multivariate) characteristic function, which is only accessible in a black-box format. We construct a generative neural network, whose loss function exploits a specific representation of the Maximum-Mean-Discrepancy metric to directly incorporate the targeted characteristic function. The construction is universal in the sense that it is independent of the dimension and that it does not require any assumptions on the given characteristic function. Furthermore, finite sample guarantees on the approximation quality in terms of the Maximum-Mean Discrepancy metric are derived. The method is illustrated in a short simulation study.
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#22522;&#20110;&#33021;&#37327;&#30340;&#25193;&#25955;&#29983;&#25104;&#22120;&#30340;&#26032;&#22411;&#37319;&#26679;&#22120;&#65292;&#29992;&#20110;&#20174;&#20219;&#24847;&#30446;&#26631;&#20998;&#24067;&#20013;&#29983;&#25104;&#26679;&#26412;&#65292;&#24182;&#36890;&#36807;&#25193;&#25955;&#27169;&#22411;&#21644;&#24191;&#20041;&#21704;&#23494;&#39039;&#21160;&#21147;&#23398;&#25552;&#39640;&#37319;&#26679;&#24615;&#33021;&#12290;&#22312;&#21508;&#31181;&#22797;&#26434;&#20998;&#24067;&#20989;&#25968;&#19978;&#30340;&#23454;&#35777;&#35780;&#20272;&#20013;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.02080</link><description>&lt;p&gt;
&#22522;&#20110;&#33021;&#37327;&#30340;&#25193;&#25955;&#29983;&#25104;&#22120;&#29992;&#20110;&#39640;&#25928;&#37319;&#26679;Boltzmann&#20998;&#24067;
&lt;/p&gt;
&lt;p&gt;
Energy based diffusion generator for efficient sampling of Boltzmann distributions. (arXiv:2401.02080v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02080
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#22522;&#20110;&#33021;&#37327;&#30340;&#25193;&#25955;&#29983;&#25104;&#22120;&#30340;&#26032;&#22411;&#37319;&#26679;&#22120;&#65292;&#29992;&#20110;&#20174;&#20219;&#24847;&#30446;&#26631;&#20998;&#24067;&#20013;&#29983;&#25104;&#26679;&#26412;&#65292;&#24182;&#36890;&#36807;&#25193;&#25955;&#27169;&#22411;&#21644;&#24191;&#20041;&#21704;&#23494;&#39039;&#21160;&#21147;&#23398;&#25552;&#39640;&#37319;&#26679;&#24615;&#33021;&#12290;&#22312;&#21508;&#31181;&#22797;&#26434;&#20998;&#24067;&#20989;&#25968;&#19978;&#30340;&#23454;&#35777;&#35780;&#20272;&#20013;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#22522;&#20110;&#33021;&#37327;&#30340;&#25193;&#25955;&#29983;&#25104;&#22120;&#30340;&#26032;&#22411;&#37319;&#26679;&#22120;&#65292;&#29992;&#20110;&#20174;&#20219;&#24847;&#30446;&#26631;&#20998;&#24067;&#20013;&#29983;&#25104;&#26679;&#26412;&#12290;&#37319;&#26679;&#27169;&#22411;&#37319;&#29992;&#31867;&#20284;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;&#32467;&#26500;&#65292;&#21033;&#29992;&#35299;&#30721;&#22120;&#23558;&#26469;&#33258;&#31616;&#21333;&#20998;&#24067;&#30340;&#28508;&#22312;&#21464;&#37327;&#36716;&#25442;&#20026;&#36924;&#36817;&#30446;&#26631;&#20998;&#24067;&#30340;&#38543;&#26426;&#21464;&#37327;&#65292;&#24182;&#35774;&#35745;&#20102;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#32534;&#30721;&#22120;&#12290;&#21033;&#29992;&#25193;&#25955;&#27169;&#22411;&#23545;&#22797;&#26434;&#20998;&#24067;&#30340;&#24378;&#22823;&#24314;&#27169;&#33021;&#21147;&#65292;&#25105;&#20204;&#21487;&#20197;&#33719;&#24471;&#29983;&#25104;&#26679;&#26412;&#21644;&#30446;&#26631;&#20998;&#24067;&#20043;&#38388;&#30340;Kullback-Leibler&#25955;&#24230;&#30340;&#20934;&#30830;&#21464;&#20998;&#20272;&#35745;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#24191;&#20041;&#21704;&#23494;&#39039;&#21160;&#21147;&#23398;&#30340;&#35299;&#30721;&#22120;&#65292;&#36827;&#19968;&#27493;&#25552;&#39640;&#37319;&#26679;&#24615;&#33021;&#12290;&#36890;&#36807;&#23454;&#35777;&#35780;&#20272;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21508;&#31181;&#22797;&#26434;&#20998;&#24067;&#20989;&#25968;&#19978;&#30340;&#26377;&#25928;&#24615;&#65292;&#23637;&#31034;&#20102;&#20854;&#30456;&#23545;&#20110;&#29616;&#26377;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a novel sampler called the energy based diffusion generator for generating samples from arbitrary target distributions. The sampling model employs a structure similar to a variational autoencoder, utilizing a decoder to transform latent variables from a simple distribution into random variables approximating the target distribution, and we design an encoder based on the diffusion model. Leveraging the powerful modeling capacity of the diffusion model for complex distributions, we can obtain an accurate variational estimate of the Kullback-Leibler divergence between the distributions of the generated samples and the target. Moreover, we propose a decoder based on generalized Hamiltonian dynamics to further enhance sampling performance. Through empirical evaluation, we demonstrate the effectiveness of our method across various complex distribution functions, showcasing its superiority compared to existing methods.
&lt;/p&gt;</description></item><item><title>&#23398;&#20064;&#33021;&#21147;&#26159;&#19968;&#31181;&#24230;&#37327;&#27169;&#22411;&#26377;&#25928;&#32500;&#24230;&#30340;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#24110;&#21161;&#25105;&#20204;&#21028;&#26029;&#26159;&#21542;&#38656;&#35201;&#33719;&#21462;&#26356;&#22810;&#25968;&#25454;&#25110;&#32773;&#23547;&#25214;&#26032;&#30340;&#20307;&#31995;&#32467;&#26500;&#20197;&#25552;&#39640;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.17332</link><description>&lt;p&gt;
&#23398;&#20064;&#33021;&#21147;&#65306;&#27169;&#22411;&#26377;&#25928;&#32500;&#24230;&#30340;&#24230;&#37327;&#26041;&#24335;
&lt;/p&gt;
&lt;p&gt;
Learning Capacity: A Measure of the Effective Dimensionality of a Model. (arXiv:2305.17332v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17332
&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#33021;&#21147;&#26159;&#19968;&#31181;&#24230;&#37327;&#27169;&#22411;&#26377;&#25928;&#32500;&#24230;&#30340;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#24110;&#21161;&#25105;&#20204;&#21028;&#26029;&#26159;&#21542;&#38656;&#35201;&#33719;&#21462;&#26356;&#22810;&#25968;&#25454;&#25110;&#32773;&#23547;&#25214;&#26032;&#30340;&#20307;&#31995;&#32467;&#26500;&#20197;&#25552;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#21033;&#29992;&#28909;&#21147;&#23398;&#21644;&#25512;&#29702;&#20043;&#38388;&#30340;&#27491;&#24335;&#23545;&#24212;&#20851;&#31995;&#65292;&#23558;&#26679;&#26412;&#25968;&#37327;&#35270;&#20026;&#21453;&#28201;&#24230;&#65292;&#23450;&#20041;&#20102;&#19968;&#31181;&#8220;&#23398;&#20064;&#33021;&#21147;&#8221;&#65292;&#36825;&#26159;&#27169;&#22411;&#26377;&#25928;&#32500;&#24230;&#30340;&#24230;&#37327;&#26041;&#24335;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#23545;&#20110;&#35768;&#22810;&#22312;&#20856;&#22411;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#28145;&#24230;&#32593;&#32476;&#65292;&#23398;&#20064;&#33021;&#21147;&#20165;&#21344;&#21442;&#25968;&#25968;&#37327;&#30340;&#19968;&#23567;&#37096;&#20998;&#65292;&#21462;&#20915;&#20110;&#29992;&#20110;&#35757;&#32451;&#30340;&#26679;&#26412;&#25968;&#37327;&#65292;&#24182;&#19988;&#22312;&#25968;&#20540;&#19978;&#19982;&#20174;PAC-Bayesian&#26694;&#26550;&#33719;&#24471;&#30340;&#33021;&#21147;&#27010;&#24565;&#19968;&#33268;&#12290;&#23398;&#20064;&#33021;&#21147;&#20316;&#20026;&#27979;&#35797;&#35823;&#24046;&#30340;&#20989;&#25968;&#19981;&#20250;&#20986;&#29616;&#21452;&#23792;&#19979;&#38477;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#27169;&#22411;&#30340;&#23398;&#20064;&#33021;&#21147;&#22312;&#38750;&#24120;&#23567;&#21644;&#38750;&#24120;&#22823;&#30340;&#26679;&#26412;&#22823;&#23567;&#22788;&#39281;&#21644;&#65292;&#36825;&#25552;&#20379;&#20102;&#25351;&#23548;&#65292;&#35828;&#26126;&#26159;&#21542;&#24212;&#35813;&#33719;&#21462;&#26356;&#22810;&#25968;&#25454;&#25110;&#32773;&#23547;&#25214;&#26032;&#30340;&#20307;&#31995;&#32467;&#26500;&#20197;&#25552;&#39640;&#24615;&#33021;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#23398;&#20064;&#33021;&#21147;&#26469;&#29702;&#35299;&#26377;&#25928;&#32500;&#25968;&#65292;&#21363;&#20351;&#26159;&#38750;&#21442;&#25968;&#27169;&#22411;&#65292;&#22914;&#38543;&#26426;&#26862;&#26519;&#12290;
&lt;/p&gt;
&lt;p&gt;
We exploit a formal correspondence between thermodynamics and inference, where the number of samples can be thought of as the inverse temperature, to define a "learning capacity'' which is a measure of the effective dimensionality of a model. We show that the learning capacity is a tiny fraction of the number of parameters for many deep networks trained on typical datasets, depends upon the number of samples used for training, and is numerically consistent with notions of capacity obtained from the PAC-Bayesian framework. The test error as a function of the learning capacity does not exhibit double descent. We show that the learning capacity of a model saturates at very small and very large sample sizes; this provides guidelines, as to whether one should procure more data or whether one should search for new architectures, to improve performance. We show how the learning capacity can be used to understand the effective dimensionality, even for non-parametric models such as random fores
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#26032;&#30340;&#38543;&#26426;FW&#26377;&#38480;&#21644;&#26368;&#23567;&#21270;&#31639;&#27861;&#21464;&#20307;&#65292;&#36866;&#29992;&#20110;&#20984;&#20989;&#25968;&#21644;&#38750;&#20984;&#20989;&#25968;&#65292;&#19988;&#20855;&#26377;&#26368;&#20339;&#25910;&#25947;&#20445;&#35777;&#12290;&#21516;&#26102;&#20004;&#31181;&#26041;&#27861;&#19981;&#38656;&#35201;&#27704;&#20037;&#25910;&#38598;&#22823;&#25209;&#25968;&#25454;&#21644;&#20840;&#30830;&#23450;&#24615;&#26799;&#24230;&#12290;</title><link>http://arxiv.org/abs/2304.11737</link><description>&lt;p&gt;
Sarah Frank-Wolfe&#65306;&#20855;&#26377;&#26368;&#20339;&#36895;&#29575;&#21644;&#23454;&#29992;&#29305;&#28857;&#30340;&#32422;&#26463;&#20248;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Sarah Frank-Wolfe: Methods for Constrained Optimization with Best Rates and Practical Features. (arXiv:2304.11737v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11737
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#26032;&#30340;&#38543;&#26426;FW&#26377;&#38480;&#21644;&#26368;&#23567;&#21270;&#31639;&#27861;&#21464;&#20307;&#65292;&#36866;&#29992;&#20110;&#20984;&#20989;&#25968;&#21644;&#38750;&#20984;&#20989;&#25968;&#65292;&#19988;&#20855;&#26377;&#26368;&#20339;&#25910;&#25947;&#20445;&#35777;&#12290;&#21516;&#26102;&#20004;&#31181;&#26041;&#27861;&#19981;&#38656;&#35201;&#27704;&#20037;&#25910;&#38598;&#22823;&#25209;&#25968;&#25454;&#21644;&#20840;&#30830;&#23450;&#24615;&#26799;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Frank-Wolfe&#65288;FW&#65289;&#26041;&#27861;&#26159;&#35299;&#20915;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#20986;&#29616;&#30340;&#32467;&#26500;&#21270;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#30340;&#27969;&#34892;&#26041;&#27861;&#12290;&#36817;&#24180;&#26469;&#65292;&#21463;&#21040;&#22823;&#25968;&#25454;&#38598;&#30340;&#21551;&#21457;&#65292;FW&#30340;&#38543;&#26426;&#29256;&#26412;&#21464;&#24471;&#26356;&#21152;&#27969;&#34892;&#65292;&#22240;&#20026;&#35745;&#31639;&#20840;&#26799;&#24230;&#20195;&#20215;&#36807;&#39640;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#26032;&#30340;FW&#38543;&#26426;&#26377;&#38480;&#21644;&#26368;&#23567;&#21270;&#31639;&#27861;&#21464;&#20307;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#26082;&#36866;&#29992;&#20110;&#20984;&#20989;&#25968;&#21448;&#36866;&#29992;&#20110;&#38750;&#20984;&#20989;&#25968;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#23384;&#22312;&#27704;&#20037;&#25910;&#38598;&#22823;&#25209;&#25968;&#25454;&#30340;&#38382;&#39064;&#65292;&#36825;&#26159;&#35768;&#22810;&#25237;&#24433;&#26080;&#32422;&#26463;&#38543;&#26426;&#26041;&#27861;&#30340;&#20849;&#21516;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#31532;&#20108;&#31181;&#26041;&#27861;&#26082;&#19981;&#38656;&#35201;&#22823;&#25209;&#37327;&#30340;&#25968;&#25454;&#20063;&#19981;&#38656;&#35201;&#20840;&#30830;&#23450;&#24615;&#26799;&#24230;&#65292;&#36825;&#26159;&#35768;&#22810;&#26377;&#38480;&#21644;&#38382;&#39064;&#25216;&#26415;&#30340;&#20856;&#22411;&#24369;&#28857;&#12290;&#25105;&#20204;&#26041;&#27861;&#30340;&#26356;&#24555;&#25910;&#25947;&#36895;&#24230;&#22312;&#23454;&#36341;&#20013;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Frank-Wolfe (FW) method is a popular approach for solving optimization problems with structured constraints that arise in machine learning applications. In recent years, stochastic versions of FW have gained popularity, motivated by large datasets for which the computation of the full gradient is prohibitively expensive. In this paper, we present two new variants of the FW algorithms for stochastic finite-sum minimization. Our algorithms have the best convergence guarantees of existing stochastic FW approaches for both convex and non-convex objective functions. Our methods do not have the issue of permanently collecting large batches, which is common to many stochastic projection-free approaches. Moreover, our second approach does not require either large batches or full deterministic gradients, which is a typical weakness of many techniques for finite-sum problems. The faster theoretical rates of our approaches are confirmed experimentally.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#29420;&#31435;&#24615;&#27979;&#35797;&#23454;&#29616;&#20102;&#26222;&#36941;&#19968;&#33268;&#30340;k&#26679;&#26412;&#26816;&#39564;&#65292;&#24182;&#19988;&#21457;&#29616;&#38750;&#21442;&#25968;&#29420;&#31435;&#24615;&#27979;&#35797;&#36890;&#24120;&#27604;&#22810;&#20803;&#26041;&#24046;&#20998;&#26512;(MANOVA)&#27979;&#35797;&#22312;&#39640;&#26031;&#20998;&#24067;&#24773;&#20917;&#19979;&#34920;&#29616;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/1910.08883</link><description>&lt;p&gt;
&#39640;&#32500;&#24230;&#21644;&#26222;&#36941;&#19968;&#33268;&#30340;k&#26679;&#26412;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
High-dimensional and universally consistent k-sample tests. (arXiv:1910.08883v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1910.08883
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#29420;&#31435;&#24615;&#27979;&#35797;&#23454;&#29616;&#20102;&#26222;&#36941;&#19968;&#33268;&#30340;k&#26679;&#26412;&#26816;&#39564;&#65292;&#24182;&#19988;&#21457;&#29616;&#38750;&#21442;&#25968;&#29420;&#31435;&#24615;&#27979;&#35797;&#36890;&#24120;&#27604;&#22810;&#20803;&#26041;&#24046;&#20998;&#26512;(MANOVA)&#27979;&#35797;&#22312;&#39640;&#26031;&#20998;&#24067;&#24773;&#20917;&#19979;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
k&#26679;&#26412;&#26816;&#39564;&#38382;&#39064;&#28041;&#21450;&#30830;&#23450;$k$&#32452;&#25968;&#25454;&#28857;&#26159;&#21542;&#37117;&#26469;&#33258;&#21516;&#19968;&#20010;&#20998;&#24067;&#12290;&#23613;&#31649;&#22810;&#20803;&#26041;&#24046;&#20998;&#26512;(MANOVA)&#26159;&#29983;&#29289;&#21307;&#23398;&#20013;&#24120;&#29992;&#30340;k&#26679;&#26412;&#26816;&#39564;&#26041;&#27861;&#65292;&#20294;&#23427;&#20381;&#36182;&#20110;&#24378;&#22823;&#19988;&#36890;&#24120;&#19981;&#21512;&#36866;&#30340;&#21442;&#25968;&#20551;&#35774;&#12290;&#27492;&#22806;&#65292;&#29420;&#31435;&#24615;&#27979;&#35797;&#21644;k&#26679;&#26412;&#27979;&#35797;&#23494;&#20999;&#30456;&#20851;&#65292;&#19968;&#20123;&#26222;&#36941;&#19968;&#33268;&#30340;&#39640;&#32500;&#29420;&#31435;&#24615;&#27979;&#35797;&#65292;&#22914;&#36317;&#31163;&#30456;&#20851;(Discrepancy)&#21644;Hilbert-Schmidt&#29420;&#31435;&#24615;&#20934;&#21017;(Hsic)&#65292;&#20855;&#26377;&#22362;&#23454;&#30340;&#29702;&#35770;&#21644;&#23454;&#35777;&#24615;&#36136;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#29420;&#31435;&#24615;&#27979;&#35797;&#23454;&#29616;&#20102;&#26222;&#36941;&#19968;&#33268;&#30340;k&#26679;&#26412;&#26816;&#39564;&#65292;&#24182;&#19988;k&#26679;&#26412;&#32479;&#35745;&#37327;&#65292;&#22914;Energy&#21644;Maximum Mean Discrepancy(MMD)&#65292;&#19982;Discrepancy&#23436;&#20840;&#31561;&#20215;&#12290;&#23545;&#38750;&#21442;&#25968;&#29420;&#31435;&#24615;&#27979;&#35797;&#30340;&#23454;&#35777;&#35780;&#20272;&#34920;&#26126;&#65292;&#23427;&#20204;&#36890;&#24120;&#27604;&#27969;&#34892;&#30340;MANOVA&#27979;&#35797;&#34920;&#29616;&#26356;&#22909;&#65292;&#21363;&#20351;&#22312;&#39640;&#26031;&#20998;&#24067;&#30340;&#22330;&#26223;&#20013;&#20063;&#26159;&#22914;&#27492;&#12290;
&lt;/p&gt;
&lt;p&gt;
The k-sample testing problem involves determining whether $k$ groups of data points are each drawn from the same distribution. The standard method for k-sample testing in biomedicine is Multivariate analysis of variance (MANOVA), despite that it depends on strong, and often unsuitable, parametric assumptions. Moreover, independence testing and k-sample testing are closely related, and several universally consistent high-dimensional independence tests such as distance correlation (Dcorr) and Hilbert-Schmidt-Independence-Criterion (Hsic) enjoy solid theoretical and empirical properties. In this paper, we prove that independence tests achieve universally consistent k-sample testing and that k-sample statistics such as Energy and Maximum Mean Discrepancy (MMD) are precisely equivalent to Dcorr. An empirical evaluation of nonparametric independence tests showed that they generally perform better than the popular MANOVA test, even in Gaussian distributed scenarios. The evaluation included se
&lt;/p&gt;</description></item></channel></rss>