<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#32676;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#20004;&#32423;&#26377;&#38480;&#21644;&#20985;&#20984;&#26368;&#23567;&#26368;&#22823;&#20248;&#21270;&#32467;&#26500;&#21644;&#38543;&#26426;&#26041;&#24046;&#20943;&#23567;&#38236;&#20687;Prox&#31639;&#27861;&#65292;&#23454;&#29616;&#23545;&#25152;&#26377;&#32452;&#30340;&#26041;&#24046;&#20943;&#23569;&#65292;&#24182;&#25903;&#25345;&#38750;&#24658;&#23450;&#23398;&#20064;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.03562</link><description>&lt;p&gt;
&#39640;&#25928;&#31639;&#27861;&#29992;&#20110;&#32463;&#39564;&#32676;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#21450;&#26356;&#22810;
&lt;/p&gt;
&lt;p&gt;
Efficient Algorithms for Empirical Group Distributional Robust Optimization and Beyond
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03562
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#32676;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#20004;&#32423;&#26377;&#38480;&#21644;&#20985;&#20984;&#26368;&#23567;&#26368;&#22823;&#20248;&#21270;&#32467;&#26500;&#21644;&#38543;&#26426;&#26041;&#24046;&#20943;&#23567;&#38236;&#20687;Prox&#31639;&#27861;&#65292;&#23454;&#29616;&#23545;&#25152;&#26377;&#32452;&#30340;&#26041;&#24046;&#20943;&#23569;&#65292;&#24182;&#25903;&#25345;&#38750;&#24658;&#23450;&#23398;&#20064;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#32676;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65288;GDRO&#65289;&#30340;&#32463;&#39564;&#23545;&#24212;&#38382;&#39064;&#65292;&#26088;&#22312;&#26368;&#23567;&#21270;$m$&#20010;&#19981;&#21516;&#32452;&#20013;&#30340;&#26368;&#22823;&#32463;&#39564;&#39118;&#38505;&#12290;&#25105;&#20204;&#23558;&#32463;&#39564;GDRO&#34920;&#36848;&#20026;$\textit{&#20004;&#32423;}$&#26377;&#38480;&#21644;&#20985;&#20984;&#26368;&#23567;&#26368;&#22823;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#38543;&#26426;&#26041;&#24046;&#20943;&#23567;&#38236;&#20687;Prox&#31639;&#27861;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#36890;&#36807;&#36880;&#32452;&#25277;&#26679;&#25216;&#26415;&#26500;&#24314;&#20102;&#38543;&#26426;&#26799;&#24230;&#65292;&#24182;&#20026;&#25152;&#26377;&#32452;&#25191;&#34892;&#26041;&#24046;&#20943;&#23569;&#65292;&#20805;&#20998;&#21033;&#29992;&#20102;&#32463;&#39564;GDRO&#30340;$\textit{&#20004;&#32423;}$&#26377;&#38480;&#21644;&#32467;&#26500;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#19968;&#20010;&#19968;&#32034;&#24341;&#20559;&#31227;&#21152;&#26435;&#24179;&#22343;&#26469;&#35745;&#31639;&#24555;&#29031;&#21644;&#38236;&#20687;&#24555;&#29031;&#28857;&#65292;&#36825;&#20351;&#25105;&#20204;&#19982;&#26420;&#32032;&#30340;&#36941;&#21382;&#24179;&#22343;&#26041;&#27861;&#26377;&#25152;&#19981;&#21516;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#36824;&#25903;&#25345;&#38750;&#24658;&#23450;&#23398;&#20064;&#29575;&#65292;&#36825;&#19982;&#29616;&#26377;&#25991;&#29486;&#19981;&#21516;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#26399;&#26395;&#21644;&#39640;&#27010;&#29575;&#25910;&#25947;&#20445;&#35777;&#65292;&#23637;&#31034;&#20986;$\m
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03562v1 Announce Type: new  Abstract: We investigate the empirical counterpart of group distributionally robust optimization (GDRO), which aims to minimize the maximal empirical risk across $m$ distinct groups. We formulate empirical GDRO as a $\textit{two-level}$ finite-sum convex-concave minimax optimization problem and develop a stochastic variance reduced mirror prox algorithm. Unlike existing methods, we construct the stochastic gradient by per-group sampling technique and perform variance reduction for all groups, which fully exploits the $\textit{two-level}$ finite-sum structure of empirical GDRO. Furthermore, we compute the snapshot and mirror snapshot point by a one-index-shifted weighted average, which distinguishes us from the naive ergodic average. Our algorithm also supports non-constant learning rates, which is different from existing literature. We establish convergence guarantees both in expectation and with high probability, demonstrating a complexity of $\m
&lt;/p&gt;</description></item><item><title>&#19968;&#31867;&#36793;&#30028;&#21093;&#31163;&#26159;&#19968;&#31181;&#26080;&#30417;&#30563;&#30340;&#24322;&#24120;&#26816;&#27979;&#31639;&#27861;&#65292;&#20351;&#29992;&#20102;&#24179;&#22343;&#26377;&#31526;&#21495;&#36317;&#31163;&#21644;&#28789;&#27963;&#30340;&#36793;&#30028;&#29983;&#25104;&#26041;&#27861;&#12290;&#22312;&#26080;&#24322;&#24120;&#20540;&#21644;&#26377;&#24322;&#24120;&#20540;&#30340;&#24773;&#20917;&#19979;&#65292;&#19968;&#31867;&#36793;&#30028;&#21093;&#31163;&#34920;&#29616;&#20986;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.05630</link><description>&lt;p&gt;
&#36793;&#30028;&#21093;&#31163;&#65306;&#20351;&#29992;&#19968;&#31867;&#21093;&#31163;&#30340;&#24322;&#24120;&#26816;&#27979;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Boundary Peeling: Outlier Detection Method Using One-Class Peeling. (arXiv:2309.05630v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05630
&lt;/p&gt;
&lt;p&gt;
&#19968;&#31867;&#36793;&#30028;&#21093;&#31163;&#26159;&#19968;&#31181;&#26080;&#30417;&#30563;&#30340;&#24322;&#24120;&#26816;&#27979;&#31639;&#27861;&#65292;&#20351;&#29992;&#20102;&#24179;&#22343;&#26377;&#31526;&#21495;&#36317;&#31163;&#21644;&#28789;&#27963;&#30340;&#36793;&#30028;&#29983;&#25104;&#26041;&#27861;&#12290;&#22312;&#26080;&#24322;&#24120;&#20540;&#21644;&#26377;&#24322;&#24120;&#20540;&#30340;&#24773;&#20917;&#19979;&#65292;&#19968;&#31867;&#36793;&#30028;&#21093;&#31163;&#34920;&#29616;&#20986;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#24322;&#24120;&#26816;&#27979;&#22312;&#25968;&#25454;&#20998;&#26512;&#20013;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#38454;&#27573;&#65292;&#20173;&#28982;&#26159;&#19968;&#20010;&#20805;&#28385;&#27963;&#21147;&#30340;&#30740;&#31350;&#39046;&#22495;&#12290;&#19968;&#20010;&#22909;&#30340;&#24322;&#24120;&#26816;&#27979;&#31639;&#27861;&#24212;&#35813;&#20855;&#22791;&#35745;&#31639;&#25928;&#29575;&#39640;&#12289;&#23545;&#35843;&#21442;&#36873;&#25321;&#40065;&#26834;&#12289;&#22312;&#19981;&#21516;&#30340;&#25968;&#25454;&#20998;&#24067;&#19979;&#34920;&#29616;&#31283;&#23450;&#31561;&#29305;&#28857;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31867;&#36793;&#30028;&#21093;&#31163;&#65292;&#19968;&#31181;&#26080;&#30417;&#30563;&#24322;&#24120;&#26816;&#27979;&#31639;&#27861;&#12290;&#19968;&#31867;&#36793;&#30028;&#21093;&#31163;&#20351;&#29992;&#20102;&#19968;&#31867;&#25903;&#25345;&#21521;&#37327;&#26426;&#19981;&#26029;&#21093;&#31163;&#30340;&#12289;&#28789;&#27963;&#30340;&#36793;&#30028;&#29983;&#25104;&#30340;&#24179;&#22343;&#26377;&#31526;&#21495;&#36317;&#31163;&#12290;&#19968;&#31867;&#36793;&#30028;&#21093;&#31163;&#20855;&#26377;&#40065;&#26834;&#30340;&#36229;&#21442;&#25968;&#35774;&#32622;&#65292;&#24182;&#19988;&#20026;&#20102;&#22686;&#21152;&#28789;&#27963;&#24615;&#65292;&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;&#19968;&#20010;&#38598;&#25104;&#26041;&#27861;&#12290;&#22312;&#21512;&#25104;&#25968;&#25454;&#27169;&#25311;&#20013;&#65292;&#19968;&#31867;&#36793;&#30028;&#21093;&#31163;&#22312;&#27809;&#26377;&#24322;&#24120;&#20540;&#30340;&#24773;&#20917;&#19979;&#20248;&#20110;&#25152;&#26377;&#20808;&#36827;&#26041;&#27861;&#65292;&#24182;&#19988;&#22312;&#26377;&#24322;&#24120;&#20540;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#19982;&#22522;&#20934;&#26041;&#27861;&#30456;&#27604;&#65292;&#22312;&#27491;&#30830;&#20998;&#31867;&#26041;&#38754;&#34920;&#29616;&#20986;&#21487;&#27604;&#25110;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Unsupervised outlier detection constitutes a crucial phase within data analysis and remains a dynamic realm of research. A good outlier detection algorithm should be computationally efficient, robust to tuning parameter selection, and perform consistently well across diverse underlying data distributions. We introduce One-Class Boundary Peeling, an unsupervised outlier detection algorithm. One-class Boundary Peeling uses the average signed distance from iteratively-peeled, flexible boundaries generated by one-class support vector machines. One-class Boundary Peeling has robust hyperparameter settings and, for increased flexibility, can be cast as an ensemble method. In synthetic data simulations One-Class Boundary Peeling outperforms all state of the art methods when no outliers are present while maintaining comparable or superior performance in the presence of outliers, as compared to benchmark methods. One-Class Boundary Peeling performs competitively in terms of correct classificati
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#26500;&#21270;&#24452;&#21521;&#22522;&#20989;&#25968;&#32593;&#32476;&#65292;&#29992;&#20110;&#35299;&#20915;&#22810;&#27169;&#24577;&#22238;&#24402;&#38382;&#39064;&#12290;&#35813;&#32593;&#32476;&#33021;&#22815;&#26377;&#25928;&#22320;&#32452;&#21512;&#22810;&#20010;&#20551;&#35774;&#39044;&#27979;&#22120;&#65292;&#24182;&#36890;&#36807;&#25554;&#20540;&#36924;&#36817;&#22810;&#20010;&#20551;&#35774;&#30446;&#26631;&#20998;&#24067;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.00781</link><description>&lt;p&gt;
&#32467;&#26500;&#21270;&#24452;&#21521;&#22522;&#20989;&#25968;&#32593;&#32476;&#65306;&#29992;&#20110;&#22810;&#20551;&#35774;&#39044;&#27979;&#30340;&#22810;&#26679;&#24615;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Structured Radial Basis Function Network: Modelling Diversity for Multiple Hypotheses Prediction. (arXiv:2309.00781v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00781
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#26500;&#21270;&#24452;&#21521;&#22522;&#20989;&#25968;&#32593;&#32476;&#65292;&#29992;&#20110;&#35299;&#20915;&#22810;&#27169;&#24577;&#22238;&#24402;&#38382;&#39064;&#12290;&#35813;&#32593;&#32476;&#33021;&#22815;&#26377;&#25928;&#22320;&#32452;&#21512;&#22810;&#20010;&#20551;&#35774;&#39044;&#27979;&#22120;&#65292;&#24182;&#36890;&#36807;&#25554;&#20540;&#36924;&#36817;&#22810;&#20010;&#20551;&#35774;&#30446;&#26631;&#20998;&#24067;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24577;&#22238;&#24402;&#23545;&#20110;&#39044;&#27979;&#38750;&#24179;&#31283;&#36807;&#31243;&#25110;&#20855;&#26377;&#22797;&#26434;&#20998;&#24067;&#30340;&#38382;&#39064;&#38750;&#24120;&#37325;&#35201;&#12290;&#21487;&#20197;&#36890;&#36807;&#22810;&#20551;&#35774;&#26694;&#26550;&#26469;&#22788;&#29702;&#65292;&#20294;&#22312;&#23398;&#20064;&#27169;&#22411;&#20013;&#26377;&#25928;&#22320;&#32452;&#21512;&#23427;&#20204;&#26159;&#26377;&#22256;&#38590;&#30340;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#26500;&#21270;&#24452;&#21521;&#22522;&#20989;&#25968;&#32593;&#32476;&#65292;&#20316;&#20026;&#22810;&#20551;&#35774;&#39044;&#27979;&#22120;&#30340;&#38598;&#21512;&#65292;&#29992;&#20110;&#22238;&#24402;&#38382;&#39064;&#12290;&#36825;&#20123;&#39044;&#27979;&#22120;&#26159;&#20219;&#20309;&#31867;&#22411;&#30340;&#22238;&#24402;&#27169;&#22411;&#65292;&#21487;&#20197;&#24418;&#25104;&#20197;&#23427;&#20204;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#30340;&#25439;&#22833;&#20026;&#20989;&#25968;&#30340;&#37325;&#24515;&#32500;&#35834;&#22270;&#20998;&#21106;&#12290;&#35777;&#26126;&#20102;&#36825;&#20010;&#32467;&#26500;&#21270;&#27169;&#22411;&#33021;&#22815;&#26377;&#25928;&#22320;&#25554;&#20540;&#36825;&#20010;&#20998;&#21106;&#65292;&#24182;&#19988;&#36924;&#36817;&#22810;&#20010;&#20551;&#35774;&#30446;&#26631;&#20998;&#24067;&#65292;&#24182;&#19988;&#31561;&#20215;&#20110;&#25554;&#20540;&#39044;&#27979;&#22120;&#30340;&#20803;&#25439;&#22833;&#65292;&#25439;&#22833;&#26159;&#25554;&#20540;&#35823;&#24046;&#30340;&#38646;&#38598;&#12290;&#35813;&#27169;&#22411;&#22312;&#39044;&#27979;&#22120;&#21644;&#22522;&#20989;&#25968;&#20013;&#24515;&#20043;&#38388;&#20855;&#26377;&#22266;&#23450;&#28857;&#36845;&#20195;&#31639;&#27861;&#12290;&#21487;&#20197;&#36890;&#36807;&#25130;&#26029;&#20998;&#21106;&#26684;&#24335;&#26469;&#21442;&#25968;&#21270;&#22320;&#25511;&#21046;&#23398;&#20064;&#20013;&#30340;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-modal regression is important in forecasting nonstationary processes or with a complex mixture of distributions. It can be tackled with multiple hypotheses frameworks but with the difficulty of combining them efficiently in a learning model. A Structured Radial Basis Function Network is presented as an ensemble of multiple hypotheses predictors for regression problems. The predictors are regression models of any type that can form centroidal Voronoi tessellations which are a function of their losses during training. It is proved that this structured model can efficiently interpolate this tessellation and approximate the multiple hypotheses target distribution and is equivalent to interpolating the meta-loss of the predictors, the loss being a zero set of the interpolation error. This model has a fixed-point iteration algorithm between the predictors and the centers of the basis functions. Diversity in learning can be controlled parametrically by truncating the tessellation format
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#30340;&#26631;&#23450;&#26041;&#27861;&#65292;&#20351;&#29992;&#28909;&#24230;&#22270;&#22238;&#24402;&#26469;&#28040;&#38500;&#26364;&#21704;&#39039;&#19990;&#30028;&#20551;&#35774;&#19979;&#40060;&#30524;&#22270;&#29255;&#20013;&#27178;&#21521;&#35282;&#24230;&#27495;&#20041;&#65292;&#21516;&#26102;&#24674;&#22797;&#26059;&#36716;&#21644;&#28040;&#38500;&#40060;&#30524;&#22833;&#30495;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;&#20248;&#21270;&#30340;&#23545;&#35282;&#32447;&#28857;&#32531;&#35299;&#22270;&#20687;&#20013;&#32570;&#20047;&#28040;&#22833;&#28857;&#30340;&#24773;&#20917;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#26126;&#20854;&#24615;&#33021;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#12290;</title><link>http://arxiv.org/abs/2303.17166</link><description>&lt;p&gt;
&#20351;&#29992;&#28909;&#24230;&#22270;&#22238;&#24402;&#36827;&#34892;&#28145;&#24230;&#21333;&#24352;&#22270;&#29255;&#25668;&#20687;&#26426;&#26631;&#23450;&#65292;&#22312;&#26364;&#21704;&#39039;&#19990;&#30028;&#20551;&#35774;&#19979;&#22312;&#19981;&#27169;&#31946;&#30340;&#24773;&#20917;&#19979;&#36824;&#21407;&#40060;&#30524;&#22270;&#29255;
&lt;/p&gt;
&lt;p&gt;
Deep Single Image Camera Calibration by Heatmap Regression to Recover Fisheye Images Under ManhattanWorld AssumptionWithout Ambiguity. (arXiv:2303.17166v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.17166
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#30340;&#26631;&#23450;&#26041;&#27861;&#65292;&#20351;&#29992;&#28909;&#24230;&#22270;&#22238;&#24402;&#26469;&#28040;&#38500;&#26364;&#21704;&#39039;&#19990;&#30028;&#20551;&#35774;&#19979;&#40060;&#30524;&#22270;&#29255;&#20013;&#27178;&#21521;&#35282;&#24230;&#27495;&#20041;&#65292;&#21516;&#26102;&#24674;&#22797;&#26059;&#36716;&#21644;&#28040;&#38500;&#40060;&#30524;&#22833;&#30495;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;&#20248;&#21270;&#30340;&#23545;&#35282;&#32447;&#28857;&#32531;&#35299;&#22270;&#20687;&#20013;&#32570;&#20047;&#28040;&#22833;&#28857;&#30340;&#24773;&#20917;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#26126;&#20854;&#24615;&#33021;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#27491;&#20132;&#19990;&#30028;&#22352;&#26631;&#31995;&#20013;&#65292;&#26364;&#21704;&#39039;&#19990;&#30028;&#27839;&#30528;&#38271;&#26041;&#20307;&#24314;&#31569;&#29289;&#24191;&#27867;&#29992;&#20110;&#21508;&#31181;&#35745;&#31639;&#26426;&#35270;&#35273;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#26364;&#21704;&#39039;&#19990;&#30028;&#38656;&#35201;&#25913;&#36827;&#65292;&#22240;&#20026;&#22270;&#20687;&#20013;&#30340;&#27178;&#21521;&#35282;&#24230;&#30340;&#21407;&#28857;&#26159;&#20219;&#24847;&#30340;&#65292;&#21363;&#20855;&#26377;&#22235;&#20493;&#36718;&#25442;&#23545;&#31216;&#30340;&#27178;&#21521;&#35282;&#24230;&#30340;&#27495;&#20041;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#25668;&#20687;&#26426;&#21644;&#34892;&#39542;&#26041;&#21521;&#30340;&#36947;&#36335;&#26041;&#21521;&#30340;&#24179;&#35282;&#23450;&#20041;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#30340;&#26631;&#23450;&#26041;&#27861;&#65292;&#23427;&#20351;&#29992;&#28909;&#24230;&#22270;&#22238;&#24402;&#26469;&#28040;&#38500;&#27495;&#20041;&#65292;&#31867;&#20284;&#20110;&#23039;&#24577;&#20272;&#35745;&#20851;&#38190;&#28857;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#25105;&#20204;&#30340;&#20004;&#20010;&#20998;&#25903;&#32593;&#32476;&#24674;&#22797;&#26059;&#36716;&#24182;&#20174;&#19968;&#33324;&#22330;&#26223;&#22270;&#20687;&#20013;&#28040;&#38500;&#40060;&#30524;&#22833;&#30495;&#12290;&#20026;&#20102;&#32531;&#35299;&#22270;&#20687;&#20013;&#32570;&#20047;&#28040;&#22833;&#28857;&#30340;&#24773;&#20917;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20855;&#26377;&#31354;&#38388;&#22343;&#21248;&#24615;&#26368;&#20339;&#30340;&#23545;&#35282;&#32447;&#28857;&#12290;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#26364;&#21704;&#39039;&#19990;&#30028;&#20551;&#35774;&#19979;&#23545;&#40060;&#30524;&#22270;&#20687;&#30340;&#28145;&#24230;&#21333;&#24352;&#22270;&#29255;&#25668;&#20687;&#26426;&#26631;&#23450;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#65292;&#27809;&#26377;&#27495;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;
In orthogonal world coordinates, a Manhattan world lying along cuboid buildings is widely useful for various computer vision tasks. However, the Manhattan world has much room for improvement because the origin of pan angles from an image is arbitrary, that is, four-fold rotational symmetric ambiguity of pan angles. To address this problem, we propose a definition for the pan-angle origin based on the directions of the roads with respect to a camera and the direction of travel. We propose a learning-based calibration method that uses heatmap regression to remove the ambiguity by each direction of labeled image coordinates, similar to pose estimation keypoints. Simultaneously, our two-branched network recovers the rotation and removes fisheye distortion from a general scene image. To alleviate the lack of vanishing points in images, we introduce auxiliary diagonal points that have the optimal 3D arrangement of spatial uniformity. Extensive experiments demonstrated that our method outperf
&lt;/p&gt;</description></item></channel></rss>