<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;Ising&#27169;&#22411;&#20013;&#30340;&#24352;&#37327;&#23398;&#20064;&#20013;&#65292;&#36890;&#36807;&#20266;&#20284;&#28982;&#26041;&#27861;&#21644;&#30456;&#20114;&#20316;&#29992;&#31579;&#36873;&#26041;&#27861;&#21487;&#20197;&#24674;&#22797;&#20986;&#24213;&#23618;&#30340;&#36229;&#32593;&#32476;&#32467;&#26500;&#65292;&#24182;&#19988;&#24615;&#33021;&#27604;&#36739;&#34920;&#26126;&#24352;&#37327;&#24674;&#22797;&#36895;&#29575;&#19982;&#26368;&#22823;&#32806;&#21512;&#24378;&#24230;&#21576;&#25351;&#25968;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2310.13232</link><description>&lt;p&gt;
Ising&#27169;&#22411;&#20013;&#30340;&#24352;&#37327;&#23398;&#20064;&#30340;&#30456;&#20114;&#20316;&#29992;&#31579;&#36873;&#21644;&#20266;&#20284;&#28982;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Interaction Screening and Pseudolikelihood Approaches for Tensor Learning in Ising Models. (arXiv:2310.13232v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13232
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;Ising&#27169;&#22411;&#20013;&#30340;&#24352;&#37327;&#23398;&#20064;&#20013;&#65292;&#36890;&#36807;&#20266;&#20284;&#28982;&#26041;&#27861;&#21644;&#30456;&#20114;&#20316;&#29992;&#31579;&#36873;&#26041;&#27861;&#21487;&#20197;&#24674;&#22797;&#20986;&#24213;&#23618;&#30340;&#36229;&#32593;&#32476;&#32467;&#26500;&#65292;&#24182;&#19988;&#24615;&#33021;&#27604;&#36739;&#34920;&#26126;&#24352;&#37327;&#24674;&#22797;&#36895;&#29575;&#19982;&#26368;&#22823;&#32806;&#21512;&#24378;&#24230;&#21576;&#25351;&#25968;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;$k$-spin Ising&#27169;&#22411;&#20013;&#30340;&#24352;&#37327;&#24674;&#22797;&#20013;&#65292;&#20266;&#20284;&#28982;&#26041;&#27861;&#21644;&#30456;&#20114;&#20316;&#29992;&#31579;&#36873;&#26041;&#27861;&#20004;&#31181;&#24050;&#30693;&#30340;Ising&#32467;&#26500;&#23398;&#20064;&#26041;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#36866;&#24403;&#30340;&#27491;&#21017;&#21270;&#19979;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#21487;&#20197;&#20351;&#29992;&#26679;&#26412;&#25968;&#23545;&#25968;&#32423;&#21035;&#22823;&#23567;&#30340;&#26679;&#26412;&#24674;&#22797;&#20986;&#24213;&#23618;&#30340;&#36229;&#32593;&#32476;&#32467;&#26500;&#65292;&#19988;&#19982;&#26368;&#22823;&#30456;&#20114;&#20316;&#29992;&#24378;&#24230;&#21644;&#26368;&#22823;&#33410;&#28857;&#24230;&#25351;&#25968;&#32423;&#20381;&#36182;&#12290;&#25105;&#20204;&#36824;&#23545;&#36825;&#20004;&#31181;&#26041;&#27861;&#30340;&#24352;&#37327;&#24674;&#22797;&#36895;&#29575;&#19982;&#20132;&#20114;&#38454;&#25968;$k$&#30340;&#30830;&#20999;&#20851;&#31995;&#36827;&#34892;&#20102;&#36319;&#36394;&#65292;&#24182;&#20801;&#35768;$k$&#38543;&#26679;&#26412;&#25968;&#21644;&#33410;&#28857;&#25968;&#22686;&#38271;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#20223;&#30495;&#30740;&#31350;&#23545;&#36825;&#20004;&#31181;&#26041;&#27861;&#30340;&#24615;&#33021;&#36827;&#34892;&#20102;&#27604;&#36739;&#35752;&#35770;&#65292;&#32467;&#26524;&#20063;&#26174;&#31034;&#20102;&#24352;&#37327;&#24674;&#22797;&#36895;&#29575;&#19982;&#26368;&#22823;&#32806;&#21512;&#24378;&#24230;&#20043;&#38388;&#30340;&#25351;&#25968;&#20381;&#36182;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study two well known methods of Ising structure learning, namely the pseudolikelihood approach and the interaction screening approach, in the context of tensor recovery in $k$-spin Ising models. We show that both these approaches, with proper regularization, retrieve the underlying hypernetwork structure using a sample size logarithmic in the number of network nodes, and exponential in the maximum interaction strength and maximum node-degree. We also track down the exact dependence of the rate of tensor recovery on the interaction order $k$, that is allowed to grow with the number of samples and nodes, for both the approaches. Finally, we provide a comparative discussion of the performance of the two approaches based on simulation studies, which also demonstrate the exponential dependence of the tensor recovery rate on the maximum coupling strength.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#23376;&#39640;&#26031;&#28151;&#21512;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65292;&#29992;&#20110;&#22810;&#23610;&#24230;&#32858;&#31867;&#21644;&#28304;&#20998;&#31163;&#65292;&#36890;&#36807;&#21033;&#29992;&#23567;&#27874;&#25955;&#23556;&#21327;&#26041;&#24046;&#26469;&#25552;&#20379;&#38543;&#26426;&#36807;&#31243;&#30340;&#20302;&#32500;&#34920;&#31034;&#65292;&#33021;&#22815;&#21306;&#20998;&#19981;&#21516;&#30340;&#38750;&#39640;&#26031;&#38543;&#26426;&#36807;&#31243;&#65292;&#24182;&#22312;MRO&#25968;&#25454;&#38598;&#19978;&#23637;&#29616;&#20102;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.16189</link><description>&lt;p&gt;
&#28779;&#26143;&#26102;&#38388;&#24207;&#21015;&#20998;&#35299;&#65306;&#19968;&#31181;&#22810;&#23610;&#24230;&#23884;&#22871;&#26041;&#27861;&#20013;&#30340;&#22240;&#23376;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;
&lt;/p&gt;
&lt;p&gt;
Martian time-series unraveled: A multi-scale nested approach with factorial variational autoencoders. (arXiv:2305.16189v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16189
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#23376;&#39640;&#26031;&#28151;&#21512;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65292;&#29992;&#20110;&#22810;&#23610;&#24230;&#32858;&#31867;&#21644;&#28304;&#20998;&#31163;&#65292;&#36890;&#36807;&#21033;&#29992;&#23567;&#27874;&#25955;&#23556;&#21327;&#26041;&#24046;&#26469;&#25552;&#20379;&#38543;&#26426;&#36807;&#31243;&#30340;&#20302;&#32500;&#34920;&#31034;&#65292;&#33021;&#22815;&#21306;&#20998;&#19981;&#21516;&#30340;&#38750;&#39640;&#26031;&#38543;&#26426;&#36807;&#31243;&#65292;&#24182;&#22312;MRO&#25968;&#25454;&#38598;&#19978;&#23637;&#29616;&#20102;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#30340;&#28304;&#20998;&#31163;&#28041;&#21450;&#36890;&#36807;&#28151;&#21512;&#25805;&#20316;&#35760;&#24405;&#30340;&#26410;&#30693;&#28304;&#20449;&#21495;&#30340;&#20998;&#35299;&#65292;&#20854;&#20013;&#23545;&#28304;&#30340;&#20808;&#39564;&#30693;&#35782;&#26377;&#38480;&#65292;&#20165;&#21487;&#20197;&#35775;&#38382;&#20449;&#21495;&#28151;&#21512;&#25968;&#25454;&#38598;&#12290;&#36825;&#20010;&#38382;&#39064;&#26412;&#36136;&#19978;&#26159;&#19981;&#36866;&#29992;&#30340;&#65292;&#24182;&#19988;&#36827;&#19968;&#27493;&#21463;&#21040;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#28304;&#23637;&#29616;&#20986;&#30340;&#22810;&#31181;&#26102;&#38388;&#23610;&#24230;&#30340;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#30340;&#22810;&#23610;&#24230;&#32858;&#31867;&#21644;&#28304;&#20998;&#31163;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#23567;&#27874;&#25955;&#23556;&#21327;&#26041;&#24046;&#26469;&#25552;&#20379;&#38543;&#26426;&#36807;&#31243;&#30340;&#20302;&#32500;&#34920;&#31034;&#65292;&#33021;&#22815;&#21306;&#20998;&#19981;&#21516;&#30340;&#38750;&#39640;&#26031;&#38543;&#26426;&#36807;&#31243;&#12290;&#22312;&#36825;&#20010;&#34920;&#31034;&#31354;&#38388;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#22240;&#23376;&#39640;&#26031;&#28151;&#21512;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65292;&#23427;&#34987;&#35757;&#32451;&#29992;&#20110;(1)&#27010;&#29575;&#22320;&#23545;&#19981;&#21516;&#26102;&#38388;&#23610;&#24230;&#19978;&#30340;&#28304;&#36827;&#34892;&#32858;&#31867;&#21644;&#36880;&#23618;&#38750;&#30417;&#30563;&#28304;&#20998;&#31163;&#65292;(2)&#22312;&#27599;&#20010;&#26102;&#38388;&#23610;&#24230;&#19978;&#25552;&#21462;&#20302;&#32500;&#34920;&#31034;&#65292;(3)&#23398;&#20064;&#28304;&#20449;&#21495;&#30340;&#22240;&#23376;&#34920;&#31034;&#65292;(4)&#22312;&#34920;&#31034;&#31354;&#38388;&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#20197;&#29983;&#25104;&#26410;&#30693;&#28304;&#20449;&#21495;&#12290;&#25105;&#20204;&#22312;MRO&#19978;&#30340;&#19977;&#20010;&#39057;&#36947;&#30340;&#21487;&#35265;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#32467;&#26524;&#34920;&#26126;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#27604;&#30446;&#21069;&#26368;&#20808;&#36827;&#30340;&#25216;&#26415;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Unsupervised source separation involves unraveling an unknown set of source signals recorded through a mixing operator, with limited prior knowledge about the sources, and only access to a dataset of signal mixtures. This problem is inherently ill-posed and is further challenged by the variety of time-scales exhibited by sources in time series data. Existing methods typically rely on a preselected window size that limits their capacity to handle multi-scale sources. To address this issue, instead of operating in the time domain, we propose an unsupervised multi-scale clustering and source separation framework by leveraging wavelet scattering covariances that provide a low-dimensional representation of stochastic processes, capable of distinguishing between different non-Gaussian stochastic processes. Nested within this representation space, we develop a factorial Gaussian-mixture variational autoencoder that is trained to (1) probabilistically cluster sources at different time-scales a
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#26816;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#38750;&#21442;&#25968;&#20202;&#22120;&#21464;&#37327;&#27169;&#22411;&#20013;&#30340;&#32467;&#26500;&#20989;&#25968;&#30340;&#19981;&#31561;&#24335;&#21644;&#31561;&#24335;&#38480;&#21046;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#36866;&#24212;&#26410;&#30693;&#30340;&#24179;&#28369;&#24230;&#21644;&#24037;&#20855;&#24378;&#24230;&#65292;&#24182;&#36798;&#21040;&#20102;&#26368;&#23567;&#20540;&#29575;&#30340;&#33258;&#36866;&#24212;&#26368;&#20248;&#26816;&#39564;&#29575;&#12290;</title><link>http://arxiv.org/abs/2006.09587</link><description>&lt;p&gt;
&#38750;&#21442;&#25968;IV&#27169;&#22411;&#20013;&#30340;&#33258;&#36866;&#24212;&#39640;&#25928;&#20551;&#35774;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Adaptive, Rate-Optimal Hypothesis Testing in Nonparametric IV Models. (arXiv:2006.09587v3 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.09587
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#26816;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#38750;&#21442;&#25968;&#20202;&#22120;&#21464;&#37327;&#27169;&#22411;&#20013;&#30340;&#32467;&#26500;&#20989;&#25968;&#30340;&#19981;&#31561;&#24335;&#21644;&#31561;&#24335;&#38480;&#21046;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#36866;&#24212;&#26410;&#30693;&#30340;&#24179;&#28369;&#24230;&#21644;&#24037;&#20855;&#24378;&#24230;&#65292;&#24182;&#36798;&#21040;&#20102;&#26368;&#23567;&#20540;&#29575;&#30340;&#33258;&#36866;&#24212;&#26368;&#20248;&#26816;&#39564;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#36866;&#24212;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#38750;&#21442;&#25968;&#20202;&#22120;&#21464;&#37327;&#65288;NPIV&#65289;&#27169;&#22411;&#20013;&#32467;&#26500;&#20989;&#25968;&#30340;&#19981;&#31561;&#24335;&#65288;&#22914;&#21333;&#35843;&#24615;&#12289;&#20984;&#24615;&#65289;&#21644;&#31561;&#24335;&#65288;&#22914;&#21442;&#25968;&#12289;&#21322;&#21442;&#25968;&#65289;&#38480;&#21046;&#12290;&#25105;&#20204;&#30340;&#26816;&#39564;&#32479;&#35745;&#37327;&#22522;&#20110;&#20462;&#25913;&#29256;&#30340;&#30041;&#19968;&#27861;&#26679;&#26412;&#27169;&#25311;&#65292;&#35745;&#31639;&#21463;&#38480;&#21644;&#19981;&#21463;&#38480;&#31579;&#23376;NPIV&#20272;&#35745;&#37327;&#38388;&#30340;&#20108;&#27425;&#36317;&#31163;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#35745;&#31639;&#31616;&#21333;&#12289;&#25968;&#25454;&#39537;&#21160;&#30340;&#31579;&#23376;&#35843;&#21442;&#21644;Bonferroni&#35843;&#25972;&#21345;&#26041;&#20020;&#30028;&#20540;&#30340;&#36873;&#25321;&#12290;&#25105;&#20204;&#30340;&#26816;&#39564;&#36866;&#24212;&#26410;&#30693;&#30340;&#20869;&#29983;&#24615;&#24179;&#28369;&#24230;&#21644;&#24037;&#20855;&#24378;&#24230;&#65292;&#36798;&#21040;&#20102;$L^2$&#26368;&#23567;&#20540;&#29575;&#30340;&#33258;&#36866;&#24212;&#26368;&#20248;&#26816;&#39564;&#29575;&#12290;&#20063;&#23601;&#26159;&#35828;&#65292;&#22312;&#22797;&#21512;&#38646;&#20551;&#35774;&#19979;&#20854;&#31867;&#22411;I&#35823;&#24046;&#30340;&#24635;&#20307;&#21644;&#20854;&#31867;&#22411;II&#35823;&#24046;&#30340;&#24635;&#20307;&#22343;&#19981;&#33021;&#34987;&#20219;&#20309;&#20854;&#20182;NPIV&#27169;&#22411;&#30340;&#20551;&#35774;&#26816;&#39564;&#25152;&#25552;&#39640;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#22522;&#20110;&#25968;&#25454;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new adaptive hypothesis test for inequality (e.g., monotonicity, convexity) and equality (e.g., parametric, semiparametric) restrictions on a structural function in a nonparametric instrumental variables (NPIV) model. Our test statistic is based on a modified leave-one-out sample analog of a quadratic distance between the restricted and unrestricted sieve NPIV estimators. We provide computationally simple, data-driven choices of sieve tuning parameters and Bonferroni adjusted chi-squared critical values. Our test adapts to the unknown smoothness of alternative functions in the presence of unknown degree of endogeneity and unknown strength of the instruments. It attains the adaptive minimax rate of testing in $L^2$.  That is, the sum of its type I error uniformly over the composite null and its type II error uniformly over nonparametric alternative models cannot be improved by any other hypothesis test for NPIV models of unknown regularities. Data-driven confidence sets in 
&lt;/p&gt;</description></item></channel></rss>