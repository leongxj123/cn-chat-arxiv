<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>GLAD&#26159;&#19968;&#20010;&#22312;&#31163;&#25955;&#28508;&#22312;&#31354;&#38388;&#19978;&#25805;&#20316;&#30340;&#22270;&#29983;&#25104;&#27169;&#22411;&#65292;&#36890;&#36807;&#36866;&#24212;&#25193;&#25955;&#26725;&#32467;&#26500;&#23398;&#20064;&#20854;&#31163;&#25955;&#28508;&#22312;&#31354;&#38388;&#30340;&#20808;&#39564;&#65292;&#36991;&#20813;&#20102;&#20381;&#36182;&#20110;&#21407;&#22987;&#25968;&#25454;&#31354;&#38388;&#30340;&#20998;&#35299;&#65292;&#22312;&#22270;&#29983;&#25104;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.16883</link><description>&lt;p&gt;
&#24102;&#25193;&#25955;&#26725;&#30340;&#31163;&#25955;&#28508;&#22312;&#22270;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Discrete Latent Graph Generative Modeling with Diffusion Bridges
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16883
&lt;/p&gt;
&lt;p&gt;
GLAD&#26159;&#19968;&#20010;&#22312;&#31163;&#25955;&#28508;&#22312;&#31354;&#38388;&#19978;&#25805;&#20316;&#30340;&#22270;&#29983;&#25104;&#27169;&#22411;&#65292;&#36890;&#36807;&#36866;&#24212;&#25193;&#25955;&#26725;&#32467;&#26500;&#23398;&#20064;&#20854;&#31163;&#25955;&#28508;&#22312;&#31354;&#38388;&#30340;&#20808;&#39564;&#65292;&#36991;&#20813;&#20102;&#20381;&#36182;&#20110;&#21407;&#22987;&#25968;&#25454;&#31354;&#38388;&#30340;&#20998;&#35299;&#65292;&#22312;&#22270;&#29983;&#25104;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#28508;&#22312;&#31354;&#38388;&#20013;&#30340;&#22270;&#29983;&#25104;&#27169;&#22411;&#30456;&#27604;&#20110;&#22312;&#21407;&#22987;&#25968;&#25454;&#31354;&#38388;&#19978;&#25805;&#20316;&#30340;&#27169;&#22411;&#21463;&#21040;&#36739;&#23569;&#20851;&#27880;&#65292;&#36804;&#20170;&#34920;&#29616;&#20986;&#30340;&#24615;&#33021;&#20047;&#21892;&#21487;&#38472;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;GLAD&#65292;&#19968;&#20010;&#28508;&#22312;&#31354;&#38388;&#22270;&#29983;&#25104;&#27169;&#22411;&#12290;&#19982;&#22823;&#22810;&#25968;&#20808;&#21069;&#30340;&#28508;&#22312;&#31354;&#38388;&#22270;&#29983;&#25104;&#27169;&#22411;&#19981;&#21516;&#65292;GLAD&#22312;&#20445;&#30041;&#22270;&#32467;&#26500;&#30340;&#31163;&#25955;&#24615;&#36136;&#26041;&#38754;&#36816;&#34892;&#65292;&#26080;&#38656;&#36827;&#34892;&#35832;&#22914;&#28508;&#22312;&#31354;&#38388;&#36830;&#32493;&#24615;&#31561;&#19981;&#33258;&#28982;&#30340;&#20551;&#35774;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#25193;&#25955;&#26725;&#35843;&#25972;&#21040;&#20854;&#32467;&#26500;&#65292;&#26469;&#23398;&#20064;&#25105;&#20204;&#31163;&#25955;&#28508;&#22312;&#31354;&#38388;&#30340;&#20808;&#39564;&#12290;&#36890;&#36807;&#22312;&#36866;&#24403;&#26500;&#24314;&#30340;&#28508;&#22312;&#31354;&#38388;&#19978;&#25805;&#20316;&#65292;&#25105;&#20204;&#36991;&#20813;&#20381;&#36182;&#20110;&#24120;&#29992;&#20110;&#22312;&#21407;&#22987;&#25968;&#25454;&#31354;&#38388;&#25805;&#20316;&#30340;&#27169;&#22411;&#20013;&#30340;&#20998;&#35299;&#12290;&#25105;&#20204;&#22312;&#19968;&#31995;&#21015;&#22270;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#23454;&#39564;&#65292;&#26126;&#26174;&#23637;&#31034;&#20102;&#31163;&#25955;&#28508;&#22312;&#31354;&#38388;&#30340;&#20248;&#36234;&#24615;&#65292;&#24182;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#22270;&#29983;&#25104;&#24615;&#33021;&#65292;&#20351;GLA
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16883v1 Announce Type: new  Abstract: Learning graph generative models over latent spaces has received less attention compared to models that operate on the original data space and has so far demonstrated lacklustre performance. We present GLAD a latent space graph generative model. Unlike most previous latent space graph generative models, GLAD operates on a discrete latent space that preserves to a significant extent the discrete nature of the graph structures making no unnatural assumptions such as latent space continuity. We learn the prior of our discrete latent space by adapting diffusion bridges to its structure. By operating over an appropriately constructed latent space we avoid relying on decompositions that are often used in models that operate in the original data space. We present experiments on a series of graph benchmark datasets which clearly show the superiority of the discrete latent space and obtain state of the art graph generative performance, making GLA
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25506;&#35752;&#20102;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#35745;&#31639;&#32479;&#35745;&#24046;&#36317;&#38382;&#39064;&#65292;&#20026;&#20102;&#39640;&#25928;&#22320;&#25214;&#21040;&#21487;&#20197;&#22312;&#26679;&#26412;&#19978;&#23454;&#29616;&#38750;&#24179;&#20961;&#39044;&#27979;&#35823;&#24046;&#30340;&#28508;&#22312;&#23494;&#38598;&#20272;&#35745;&#30340;&#22238;&#24402;&#21521;&#37327;&#65292;&#38656;&#35201;&#33267;&#23569; $\Omega(k \log (d/k))$ &#20010;&#26679;&#26412;&#12290;</title><link>https://arxiv.org/abs/2402.14103</link><description>&lt;p&gt;
&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#20013;&#19981;&#24403;&#23398;&#20064;&#30340;&#35745;&#31639;&#32479;&#35745;&#24046;&#36317;
&lt;/p&gt;
&lt;p&gt;
Computational-Statistical Gaps for Improper Learning in Sparse Linear Regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14103
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25506;&#35752;&#20102;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#35745;&#31639;&#32479;&#35745;&#24046;&#36317;&#38382;&#39064;&#65292;&#20026;&#20102;&#39640;&#25928;&#22320;&#25214;&#21040;&#21487;&#20197;&#22312;&#26679;&#26412;&#19978;&#23454;&#29616;&#38750;&#24179;&#20961;&#39044;&#27979;&#35823;&#24046;&#30340;&#28508;&#22312;&#23494;&#38598;&#20272;&#35745;&#30340;&#22238;&#24402;&#21521;&#37327;&#65292;&#38656;&#35201;&#33267;&#23569; $\Omega(k \log (d/k))$ &#20010;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#20013;&#19981;&#24403;&#23398;&#20064;&#30340;&#35745;&#31639;&#32479;&#35745;&#24046;&#36317;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#32473;&#23450;&#26469;&#33258;&#32500;&#24230;&#20026; $d$ &#30340; $k$-&#31232;&#30095;&#32447;&#24615;&#27169;&#22411;&#30340; $n$ &#20010;&#26679;&#26412;&#65292;&#25105;&#20204;&#35810;&#38382;&#20102;&#22312;&#26102;&#38388;&#22810;&#39033;&#24335;&#20013;&#30340;&#26368;&#23567;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#20197;&#20415;&#39640;&#25928;&#22320;&#25214;&#21040;&#19968;&#20010;&#23545;&#36825; $n$ &#20010;&#26679;&#26412;&#36798;&#21040;&#38750;&#24179;&#20961;&#39044;&#27979;&#35823;&#24046;&#30340;&#28508;&#22312;&#23494;&#38598;&#20272;&#35745;&#30340;&#22238;&#24402;&#21521;&#37327;&#12290;&#20449;&#24687;&#29702;&#35770;&#19978;&#65292;&#36825;&#21487;&#20197;&#29992; $\Theta(k \log (d/k))$ &#20010;&#26679;&#26412;&#23454;&#29616;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#22312;&#25991;&#29486;&#20013;&#24456;&#26174;&#33879;&#65292;&#20294;&#27809;&#26377;&#24050;&#30693;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#21487;&#20197;&#22312;&#19981;&#38468;&#21152;&#23545;&#27169;&#22411;&#30340;&#20854;&#20182;&#38480;&#21046;&#30340;&#24773;&#20917;&#19979;&#20351;&#29992;&#23569;&#20110; $\Theta(d)$ &#20010;&#26679;&#26412;&#36798;&#21040;&#30456;&#21516;&#30340;&#20445;&#35777;&#12290;&#31867;&#20284;&#22320;&#65292;&#29616;&#26377;&#30340;&#22256;&#38590;&#32467;&#26524;&#35201;&#20040;&#20165;&#38480;&#20110;&#36866;&#24403;&#35774;&#32622;&#65292;&#22312;&#35813;&#35774;&#32622;&#20013;&#20272;&#35745;&#20540;&#20063;&#24517;&#39035;&#26159;&#31232;&#30095;&#30340;&#65292;&#35201;&#20040;&#20165;&#36866;&#29992;&#20110;&#29305;&#23450;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14103v1 Announce Type: new  Abstract: We study computational-statistical gaps for improper learning in sparse linear regression. More specifically, given $n$ samples from a $k$-sparse linear model in dimension $d$, we ask what is the minimum sample complexity to efficiently (in time polynomial in $d$, $k$, and $n$) find a potentially dense estimate for the regression vector that achieves non-trivial prediction error on the $n$ samples. Information-theoretically this can be achieved using $\Theta(k \log (d/k))$ samples. Yet, despite its prominence in the literature, there is no polynomial-time algorithm known to achieve the same guarantees using less than $\Theta(d)$ samples without additional restrictions on the model. Similarly, existing hardness results are either restricted to the proper setting, in which the estimate must be sparse as well, or only apply to specific algorithms.   We give evidence that efficient algorithms for this task require at least (roughly) $\Omega(
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#31070;&#32463;&#32593;&#32476;&#21644;&#20449;&#21495;&#26102;&#38388;&#36923;&#36753;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22810;&#31867;&#21035;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#20998;&#31867;&#65292;&#20851;&#38190;&#36129;&#29486;&#21253;&#25324;&#24341;&#20837;&#36793;&#30028;&#27010;&#24565;&#21644;&#21033;&#29992;STL&#23646;&#24615;&#22686;&#24378;&#32467;&#26524;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.12397</link><description>&lt;p&gt;
&#22810;&#31867;&#21035;&#26102;&#38388;&#36923;&#36753;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Multi-class Temporal Logic Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12397
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#31070;&#32463;&#32593;&#32476;&#21644;&#20449;&#21495;&#26102;&#38388;&#36923;&#36753;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22810;&#31867;&#21035;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#20998;&#31867;&#65292;&#20851;&#38190;&#36129;&#29486;&#21253;&#25324;&#24341;&#20837;&#36793;&#30028;&#27010;&#24565;&#21644;&#21033;&#29992;STL&#23646;&#24615;&#22686;&#24378;&#32467;&#26524;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#21487;&#20197;&#20195;&#34920;&#26080;&#20154;&#31995;&#32479;&#65288;&#22914;&#26080;&#20154;&#26426;&#21644;&#33258;&#21160;&#39550;&#39542;&#27773;&#36710;&#65289;&#30340;&#34892;&#20026;&#12290;&#22312;&#36825;&#19968;&#39046;&#22495;&#65292;&#20108;&#20803;&#21644;&#22810;&#31867;&#21035;&#20998;&#31867;&#38382;&#39064;&#21463;&#21040;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#31070;&#32463;&#32593;&#32476;&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#20998;&#31867;&#25968;&#25454;&#30340;&#26041;&#27861;&#65307;&#28982;&#32780;&#65292;&#23427;&#20204;&#32570;&#20047;&#21487;&#35299;&#37322;&#24615;&#65292;&#36825;&#22312;&#20174;&#20013;&#25552;&#21462;&#26377;&#24847;&#20041;&#30340;&#20449;&#24687;&#26041;&#38754;&#26500;&#25104;&#20102;&#37325;&#35201;&#25361;&#25112;&#12290;&#20449;&#21495;&#26102;&#38388;&#36923;&#36753;&#65288;STL&#65289;&#26159;&#19968;&#31181;&#25551;&#36848;&#23450;&#26102;&#34892;&#20026;&#23646;&#24615;&#30340;&#24418;&#24335;&#21270;&#35821;&#35328;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#25152;&#26377;&#36825;&#20123;&#20803;&#32032;&#32467;&#21512;&#22312;&#19968;&#36215;&#30340;&#26041;&#27861;&#65306;&#20351;&#29992;&#34920;&#31034;STL&#35268;&#33539;&#30340;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#22810;&#31867;&#21035;&#20998;&#31867;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20004;&#20010;&#20851;&#38190;&#36129;&#29486;&#65306;1&#65289;&#25105;&#20204;&#24341;&#20837;&#20102;&#22810;&#31867;&#21035;&#20998;&#31867;&#30340;&#36793;&#30028;&#27010;&#24565;&#65292;2&#65289;&#25105;&#20204;&#24341;&#20837;&#20102;&#22522;&#20110;STL&#30340;&#23646;&#24615;&#26469;&#22686;&#24378;&#32467;&#26524;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#24182;&#19982;&#26368;&#20808;&#36827;&#30340;&#22522;&#20934;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12397v1 Announce Type: cross  Abstract: Time-series data can represent the behaviors of autonomous systems, such as drones and self-driving cars. The problem of binary and multi-class classification has received a lot of attention in this field. Neural networks represent a popular approach to classifying data; However, they lack interpretability, which poses a significant challenge in extracting meaningful information from them. Signal Temporal Logic (STL) is a formalism to describe the properties of timed behaviors. We propose a method that combines all of the above: neural networks that represent STL specifications for multi-class classification of time-series data. We offer two key contributions: 1) We introduce a notion of margin for multi-class classification, and 2) we introduce the use of STL-based attributes for enhancing the interpretability of the results. We evaluate our method on two datasets and compare with state-of-the-art baselines.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#22810;&#23618;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#21152;&#36895;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#21069;&#30651;&#36807;&#31243;&#65292;&#24182;&#35777;&#26126;&#22312;&#28041;&#21450;&#23884;&#22871;&#26399;&#26395;&#21644;&#26368;&#22823;&#21270;&#30340;&#38382;&#39064;&#20013;&#20855;&#26377;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2402.02111</link><description>&lt;p&gt;
&#21152;&#36895;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#21069;&#30651;&#65306;&#22810;&#23618;&#33945;&#29305;&#21345;&#27931;&#23601;&#22815;&#20102;
&lt;/p&gt;
&lt;p&gt;
Accelerating Look-ahead in Bayesian Optimization: Multilevel Monte Carlo is All you Need
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02111
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#22810;&#23618;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#21152;&#36895;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#21069;&#30651;&#36807;&#31243;&#65292;&#24182;&#35777;&#26126;&#22312;&#28041;&#21450;&#23884;&#22871;&#26399;&#26395;&#21644;&#26368;&#22823;&#21270;&#30340;&#38382;&#39064;&#20013;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#21033;&#29992;&#22810;&#23618;&#33945;&#29305;&#21345;&#27931;(MLMC)&#26469;&#25552;&#39640;&#28041;&#21450;&#23884;&#22871;&#26399;&#26395;&#21644;&#26368;&#22823;&#21270;&#30340;&#22810;&#27493;&#21069;&#30651;&#36125;&#21494;&#26031;&#20248;&#21270;(BO)&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;&#26222;&#36890;&#33945;&#29305;&#21345;&#27931;&#30340;&#22797;&#26434;&#24230;&#22312;&#23884;&#22871;&#25805;&#20316;&#20013;&#20250;&#38477;&#20302;&#65292;&#32780;MLMC&#33021;&#22815;&#20197;&#35268;&#33539;&#33945;&#29305;&#21345;&#27931;&#25910;&#25947;&#36895;&#24230;&#35299;&#20915;&#36825;&#31867;&#38382;&#39064;&#65292;&#32780;&#19988;&#19981;&#20381;&#36182;&#20110;&#32500;&#24230;&#21644;&#24179;&#28369;&#24615;&#20551;&#35774;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#30740;&#31350;&#20027;&#35201;&#20851;&#27880;&#19968;&#27493;&#21644;&#20004;&#27493;&#21069;&#30651;&#37319;&#38598;&#20989;&#25968;&#30340;&#36817;&#20284;&#25913;&#36827;&#65292;&#20294;&#27491;&#22914;&#25105;&#20204;&#25152;&#35752;&#35770;&#30340;&#65292;&#36825;&#31181;&#26041;&#27861;&#22312;&#22810;&#31181;&#26041;&#38754;&#26159;&#21487;&#25512;&#24191;&#30340;&#65292;&#21253;&#25324;&#36229;&#36234;BO&#30340;&#32972;&#26223;&#12290;&#25105;&#20204;&#36890;&#36807;&#25968;&#20540;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#21457;&#29616;&#65292;&#24182;&#22312;&#20960;&#20010;&#22522;&#20934;&#31034;&#20363;&#20013;&#23637;&#31034;&#20102;MLMC&#22312;BO&#20013;&#30340;&#20248;&#21183;&#12290;&#20195;&#30721;&#22312;&#36825;&#37324;&#33719;&#21462;&#65306;https://github.com/Shangda-Yang/MLMCBO&#12290;
&lt;/p&gt;
&lt;p&gt;
We leverage multilevel Monte Carlo (MLMC) to improve the performance of multi-step look-ahead Bayesian optimization (BO) methods that involve nested expectations and maximizations. The complexity rate of naive Monte Carlo degrades for nested operations, whereas MLMC is capable of achieving the canonical Monte Carlo convergence rate for this type of problem, independently of dimension and without any smoothness assumptions. Our theoretical study focuses on the approximation improvements for one- and two-step look-ahead acquisition functions, but, as we discuss, the approach is generalizable in various ways, including beyond the context of BO. Findings are verified numerically and the benefits of MLMC for BO are illustrated on several benchmark examples. Code is available here https://github.com/Shangda-Yang/MLMCBO.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28041;&#21450;&#38750;&#24179;&#28369;MaxPool&#25805;&#20316;&#30340;&#31070;&#32463;&#32593;&#32476;&#33258;&#21160;&#24494;&#20998;&#30340;&#25968;&#20540;&#21487;&#38752;&#24615;&#65292;&#24182;&#21457;&#29616;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;AD&#20960;&#20046;&#22312;&#27599;&#20010;&#22320;&#26041;&#37117;&#19982;&#23548;&#25968;&#30456;&#31526;&#65292;&#21363;&#20351;&#22312;&#23384;&#22312;&#38750;&#24179;&#28369;&#25805;&#20316;&#30340;&#24773;&#20917;&#19979;&#20063;&#26159;&#22914;&#27492;&#12290;&#20294;&#22312;&#23454;&#36341;&#20013;&#65292;AD&#20351;&#29992;&#30340;&#26159;&#28014;&#28857;&#25968;&#65292;&#38656;&#35201;&#25506;&#32034;&#21487;&#33021;&#23548;&#33268;AD&#25968;&#20540;&#19981;&#27491;&#30830;&#30340;&#24773;&#20917;&#12290;&#36890;&#36807;&#30740;&#31350;&#19981;&#21516;&#36873;&#25321;&#30340;&#38750;&#24179;&#28369;MaxPool&#38597;&#21487;&#27604;&#30697;&#38453;&#23545;&#35757;&#32451;&#36807;&#31243;&#30340;&#24433;&#21709;&#65292;&#25105;&#20204;&#25214;&#21040;&#20102;&#20998;&#27495;&#21306;&#21644;&#34917;&#20607;&#21306;&#20004;&#20010;&#21487;&#33021;&#23548;&#33268;AD&#25968;&#20540;&#19981;&#27491;&#30830;&#30340;&#23376;&#38598;&#12290;</title><link>http://arxiv.org/abs/2401.02736</link><description>&lt;p&gt;
&#20851;&#20110;&#38750;&#24179;&#28369;&#33258;&#21160;&#24494;&#20998;&#30340;&#25968;&#20540;&#21487;&#38752;&#24615;&#65306;MaxPool&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the numerical reliability of nonsmooth autodiff: a MaxPool case study. (arXiv:2401.02736v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02736
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28041;&#21450;&#38750;&#24179;&#28369;MaxPool&#25805;&#20316;&#30340;&#31070;&#32463;&#32593;&#32476;&#33258;&#21160;&#24494;&#20998;&#30340;&#25968;&#20540;&#21487;&#38752;&#24615;&#65292;&#24182;&#21457;&#29616;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;AD&#20960;&#20046;&#22312;&#27599;&#20010;&#22320;&#26041;&#37117;&#19982;&#23548;&#25968;&#30456;&#31526;&#65292;&#21363;&#20351;&#22312;&#23384;&#22312;&#38750;&#24179;&#28369;&#25805;&#20316;&#30340;&#24773;&#20917;&#19979;&#20063;&#26159;&#22914;&#27492;&#12290;&#20294;&#22312;&#23454;&#36341;&#20013;&#65292;AD&#20351;&#29992;&#30340;&#26159;&#28014;&#28857;&#25968;&#65292;&#38656;&#35201;&#25506;&#32034;&#21487;&#33021;&#23548;&#33268;AD&#25968;&#20540;&#19981;&#27491;&#30830;&#30340;&#24773;&#20917;&#12290;&#36890;&#36807;&#30740;&#31350;&#19981;&#21516;&#36873;&#25321;&#30340;&#38750;&#24179;&#28369;MaxPool&#38597;&#21487;&#27604;&#30697;&#38453;&#23545;&#35757;&#32451;&#36807;&#31243;&#30340;&#24433;&#21709;&#65292;&#25105;&#20204;&#25214;&#21040;&#20102;&#20998;&#27495;&#21306;&#21644;&#34917;&#20607;&#21306;&#20004;&#20010;&#21487;&#33021;&#23548;&#33268;AD&#25968;&#20540;&#19981;&#27491;&#30830;&#30340;&#23376;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#28041;&#21450;&#38750;&#24179;&#28369;MaxPool&#25805;&#20316;&#30340;&#31070;&#32463;&#32593;&#32476;&#33258;&#21160;&#24494;&#20998;&#65288;AD&#65289;&#30340;&#21487;&#38752;&#24615;&#38382;&#39064;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#19981;&#21516;&#31934;&#24230;&#32423;&#21035;&#65288;16&#20301;&#12289;32&#20301;&#12289;64&#20301;&#65289;&#21644;&#21367;&#31215;&#26550;&#26500;&#65288;LeNet&#12289;VGG&#21644;ResNet&#65289;&#20197;&#21450;&#19981;&#21516;&#25968;&#25454;&#38598;&#65288;MNIST&#12289;CIFAR10&#12289;SVHN&#21644;ImageNet&#65289;&#19978;&#30340;AD&#34892;&#20026;&#12290;&#23613;&#31649;AD&#21487;&#33021;&#26159;&#38169;&#35823;&#30340;&#65292;&#20294;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#23427;&#22312;&#20960;&#20046;&#27599;&#20010;&#22320;&#26041;&#37117;&#19982;&#23548;&#25968;&#30456;&#31526;&#65292;&#21363;&#20351;&#22312;&#23384;&#22312;&#38750;&#24179;&#28369;&#25805;&#20316;&#65288;&#22914;MaxPool&#21644;ReLU&#65289;&#30340;&#24773;&#20917;&#19979;&#20063;&#26159;&#22914;&#27492;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;AD&#20351;&#29992;&#30340;&#26159;&#28014;&#28857;&#25968;&#65288;&#32780;&#19981;&#26159;&#23454;&#25968;&#65289;&#65292;&#22240;&#27492;&#38656;&#35201;&#25506;&#32034;AD&#21487;&#33021;&#22312;&#25968;&#20540;&#19978;&#19981;&#27491;&#30830;&#30340;&#23376;&#38598;&#12290;&#36825;&#20123;&#23376;&#38598;&#21253;&#25324;&#20998;&#27495;&#21306;&#65288;AD&#22312;&#23454;&#25968;&#19978;&#19981;&#27491;&#30830;&#65289;&#21644;&#34917;&#20607;&#21306;&#65288;AD&#22312;&#28014;&#28857;&#25968;&#19978;&#19981;&#27491;&#30830;&#20294;&#22312;&#23454;&#25968;&#19978;&#27491;&#30830;&#65289;&#12290;&#25105;&#20204;&#20351;&#29992;SGD&#36827;&#34892;&#35757;&#32451;&#36807;&#31243;&#65292;&#24182;&#30740;&#31350;&#20102;MaxPool&#38750;&#24179;&#28369;&#38597;&#21487;&#27604;&#30697;&#38453;&#30340;&#19981;&#21516;&#36873;&#25321;&#23545;&#35757;&#32451;&#36807;&#31243;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper considers the reliability of automatic differentiation (AD) for neural networks involving the nonsmooth MaxPool operation. We investigate the behavior of AD across different precision levels (16, 32, 64 bits) and convolutional architectures (LeNet, VGG, and ResNet) on various datasets (MNIST, CIFAR10, SVHN, and ImageNet). Although AD can be incorrect, recent research has shown that it coincides with the derivative almost everywhere, even in the presence of nonsmooth operations (such as MaxPool and ReLU). On the other hand, in practice, AD operates with floating-point numbers (not real numbers), and there is, therefore, a need to explore subsets on which AD can be numerically incorrect. These subsets include a bifurcation zone (where AD is incorrect over reals) and a compensation zone (where AD is incorrect over floating-point numbers but correct over reals). Using SGD for the training process, we study the impact of different choices of the nonsmooth Jacobian for the MaxPool
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#20998;&#26512;&#20102;&#20174;&#26377;&#38480;&#26679;&#26412;&#22797;&#26434;&#24230;&#20013;&#35757;&#32451;&#22522;&#20110;&#27969;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#23574;&#38160;&#30340;&#31471;&#21040;&#31471;&#20998;&#26512;&#12290;&#25105;&#20204;&#25214;&#21040;&#20102;&#23398;&#20064;&#21040;&#30340;&#36895;&#24230;&#22330;&#30340;&#32039;&#20945;&#29305;&#24615;&#65292;&#24182;&#25551;&#36848;&#20102;&#29983;&#25104;&#27969;&#30340;&#36817;&#20284;&#65292;&#35813;&#36817;&#20284;&#23558;&#22522;&#26412;&#39640;&#26031;&#23494;&#24230;&#25512;&#21521;&#30446;&#26631;&#23494;&#24230;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#29983;&#25104;&#28151;&#21512;&#29289;&#22343;&#20540;&#19982;&#30446;&#26631;&#28151;&#21512;&#29289;&#22343;&#20540;&#20043;&#38388;&#36317;&#31163;&#30340;&#38381;&#24335;&#20844;&#24335;&#65292;&#24182;&#35777;&#26126;&#20854;&#34928;&#20943;&#36895;&#24230;&#20026;$\Theta_n(\frac{1}{n})$&#65292;&#36825;&#23454;&#38469;&#19978;&#26159;&#36125;&#21494;&#26031;&#26368;&#20248;&#30340;&#12290;</title><link>http://arxiv.org/abs/2310.03575</link><description>&lt;p&gt;
&#20174;&#26377;&#38480;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20013;&#23398;&#20064;&#22522;&#20110;&#27969;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Analysis of learning a flow-based generative model from limited sample complexity. (arXiv:2310.03575v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03575
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20998;&#26512;&#20102;&#20174;&#26377;&#38480;&#26679;&#26412;&#22797;&#26434;&#24230;&#20013;&#35757;&#32451;&#22522;&#20110;&#27969;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#23574;&#38160;&#30340;&#31471;&#21040;&#31471;&#20998;&#26512;&#12290;&#25105;&#20204;&#25214;&#21040;&#20102;&#23398;&#20064;&#21040;&#30340;&#36895;&#24230;&#22330;&#30340;&#32039;&#20945;&#29305;&#24615;&#65292;&#24182;&#25551;&#36848;&#20102;&#29983;&#25104;&#27969;&#30340;&#36817;&#20284;&#65292;&#35813;&#36817;&#20284;&#23558;&#22522;&#26412;&#39640;&#26031;&#23494;&#24230;&#25512;&#21521;&#30446;&#26631;&#23494;&#24230;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#29983;&#25104;&#28151;&#21512;&#29289;&#22343;&#20540;&#19982;&#30446;&#26631;&#28151;&#21512;&#29289;&#22343;&#20540;&#20043;&#38388;&#36317;&#31163;&#30340;&#38381;&#24335;&#20844;&#24335;&#65292;&#24182;&#35777;&#26126;&#20854;&#34928;&#20943;&#36895;&#24230;&#20026;$\Theta_n(\frac{1}{n})$&#65292;&#36825;&#23454;&#38469;&#19978;&#26159;&#36125;&#21494;&#26031;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#35757;&#32451;&#19968;&#20010;&#30001;&#20004;&#23618;&#33258;&#32534;&#30721;&#22120;&#21442;&#25968;&#21270;&#30340;&#27969;&#24335;&#29983;&#25104;&#27169;&#22411;&#65292;&#20197;&#20174;&#39640;&#32500;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#20013;&#25277;&#26679;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#23545;&#36825;&#20010;&#38382;&#39064;&#36827;&#34892;&#20102;&#23574;&#38160;&#30340;&#31471;&#21040;&#31471;&#20998;&#26512;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#32039;&#23494;&#30340;&#38381;&#24335;&#29305;&#24449;&#21270;&#23398;&#20064;&#21040;&#30340;&#36895;&#24230;&#22330;&#65292;&#24403;&#21442;&#25968;&#21270;&#20026;&#19968;&#20010;&#22312;&#30446;&#26631;&#20998;&#24067;&#19978;&#20174;&#26377;&#38480;&#25968;&#37327;&#30340;&#26679;&#26412;$ n $&#20013;&#36827;&#34892;&#35757;&#32451;&#30340;&#27973;&#23618;&#21435;&#22122;&#33258;&#32534;&#30721;&#22120;&#26102;&#12290;&#22312;&#27492;&#20998;&#26512;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#24212;&#30340;&#29983;&#25104;&#27969;&#30340;&#23574;&#38160;&#25551;&#36848;&#65292;&#23558;&#22522;&#26412;&#39640;&#26031;&#23494;&#24230;&#25512;&#21521;&#30446;&#26631;&#23494;&#24230;&#30340;&#36817;&#20284;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#29983;&#25104;&#28151;&#21512;&#29289;&#30340;&#22343;&#20540;&#19982;&#30446;&#26631;&#28151;&#21512;&#29289;&#22343;&#20540;&#20043;&#38388;&#30340;&#36317;&#31163;&#30340;&#38381;&#24335;&#20844;&#24335;&#65292;&#25105;&#20204;&#35777;&#26126;&#36825;&#20010;&#36317;&#31163;&#20250;&#34928;&#20943;&#20026;$\Theta_n(\frac{1}{n})$&#12290;&#26368;&#21518;&#65292;&#36825;&#20010;&#36895;&#29575;&#34987;&#35777;&#26126;&#23454;&#38469;&#19978;&#26159;&#36125;&#21494;&#26031;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of training a flow-based generative model, parametrized by a two-layer autoencoder, to sample from a high-dimensional Gaussian mixture. We provide a sharp end-to-end analysis of the problem. First, we provide a tight closed-form characterization of the learnt velocity field, when parametrized by a shallow denoising auto-encoder trained on a finite number $n$ of samples from the target distribution. Building on this analysis, we provide a sharp description of the corresponding generative flow, which pushes the base Gaussian density forward to an approximation of the target density. In particular, we provide closed-form formulae for the distance between the mean of the generated mixture and the mean of the target mixture, which we show decays as $\Theta_n(\frac{1}{n})$. Finally, this rate is shown to be in fact Bayes-optimal.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#26088;&#22312;&#30740;&#31350;&#27491;&#21017;&#21270;&#22312;&#22810;&#31867;&#21035;&#23398;&#20064;&#20013;&#30340;&#20316;&#29992;&#65292;&#20197;&#21450;&#20854;&#22312;&#19968;&#20123;&#29305;&#23450;&#24773;&#26223;&#19979;&#30340;&#26368;&#20248;&#23398;&#20064;&#31639;&#27861;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#23545;&#19968;&#21253;&#21547;&#22270;(OIGs)&#23637;&#31034;&#20102;&#32467;&#26500;&#39118;&#38505;&#26368;&#23567;&#21270;&#12289;&#26368;&#22823;&#29109;&#21407;&#21017;&#21644;&#36125;&#21494;&#26031;&#25512;&#29702;&#31561;&#31639;&#27861;&#21407;&#21017;&#30340;&#26368;&#20248;&#23398;&#20064;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2309.13692</link><description>&lt;p&gt;
&#27491;&#21017;&#21270;&#19982;&#26368;&#20248;&#22810;&#31867;&#21035;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Regularization and Optimal Multiclass Learning. (arXiv:2309.13692v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13692
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#26088;&#22312;&#30740;&#31350;&#27491;&#21017;&#21270;&#22312;&#22810;&#31867;&#21035;&#23398;&#20064;&#20013;&#30340;&#20316;&#29992;&#65292;&#20197;&#21450;&#20854;&#22312;&#19968;&#20123;&#29305;&#23450;&#24773;&#26223;&#19979;&#30340;&#26368;&#20248;&#23398;&#20064;&#31639;&#27861;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#23545;&#19968;&#21253;&#21547;&#22270;(OIGs)&#23637;&#31034;&#20102;&#32467;&#26500;&#39118;&#38505;&#26368;&#23567;&#21270;&#12289;&#26368;&#22823;&#29109;&#21407;&#21017;&#21644;&#36125;&#21494;&#26031;&#25512;&#29702;&#31561;&#31639;&#27861;&#21407;&#21017;&#30340;&#26368;&#20248;&#23398;&#20064;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20197;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;ERM&#65289;&#20026;&#20195;&#34920;&#30340;&#20856;&#22411;&#23398;&#20064;&#31639;&#27861;&#24050;&#34987;&#21457;&#29616;&#22312;&#19968;&#20123;&#23398;&#20064;&#38750;&#22343;&#21248;&#25910;&#25947;&#30340;&#24773;&#26223;&#20013;&#26080;&#27861;&#25104;&#21151;&#24212;&#29992;&#12290;&#22240;&#27492;&#65292;&#22312;&#26426;&#22120;&#23398;&#20064;&#23454;&#36341;&#20013;&#23384;&#22312;&#35768;&#22810;&#26356;&#20016;&#23500;&#30340;&#31639;&#27861;&#25216;&#26415;&#26469;&#25511;&#21046;&#27169;&#22411;&#23481;&#37327;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#20123;&#26356;&#19968;&#33324;&#30340;&#24773;&#22659;&#20013;&#65292;&#27809;&#26377;&#19968;&#31181;&#25216;&#26415;&#25110;&#21407;&#21017;&#33021;&#22815;&#33073;&#39062;&#32780;&#20986;&#26469;&#25551;&#36848;&#26368;&#20248;&#23398;&#20064;&#30340;&#29305;&#24449;&#12290;&#26412;&#25991;&#26088;&#22312;&#34920;&#24449;&#27491;&#21017;&#21270;&#22312;&#22810;&#31867;&#21035;&#23398;&#20064;&#20013;&#30340;&#20316;&#29992;&#65292;&#36825;&#21487;&#33021;&#26159;ERM&#22833;&#36133;&#30340;&#26368;&#31616;&#21333;&#24773;&#26223;&#65292;&#32780;&#26631;&#31614;&#38598;&#26159;&#20219;&#24847;&#30340;&#12290;&#25105;&#20204;&#21033;&#29992;&#19968;&#23545;&#19968;&#21253;&#21547;&#22270;&#65288;OIGs&#65289;&#23637;&#31034;&#20102;&#19982;&#20256;&#32479;&#31639;&#27861;&#21407;&#21017;&#30456;&#32467;&#21512;&#30340;&#26368;&#20248;&#23398;&#20064;&#31639;&#27861;&#65306;&#22885;&#21345;&#22982;&#21059;&#20992;&#21407;&#21017;&#25152;&#20307;&#29616;&#30340;&#32467;&#26500;&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;SRM&#65289;&#65292;&#26368;&#22823;&#29109;&#21407;&#21017;&#21644;&#36125;&#21494;&#26031;&#25512;&#29702;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22312;&#32467;&#26500;&#39118;&#38505;&#26368;&#23567;&#21270;&#19978;&#36827;&#34892;&#25918;&#26494;&#30340;&#26368;&#20248;&#23398;&#20064;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
The quintessential learning algorithm of empirical risk minimization (ERM) is known to fail in various settings for which uniform convergence does not characterize learning. It is therefore unsurprising that the practice of machine learning is rife with considerably richer algorithmic techniques for successfully controlling model capacity. Nevertheless, no such technique or principle has broken away from the pack to characterize optimal learning in these more general settings.  The purpose of this work is to characterize the role of regularization in perhaps the simplest setting for which ERM fails: multiclass learning with arbitrary label sets. Using one-inclusion graphs (OIGs), we exhibit optimal learning algorithms that dovetail with tried-and-true algorithmic principles: Occam's Razor as embodied by structural risk minimization (SRM), the principle of maximum entropy, and Bayesian reasoning. Most notably, we introduce an optimal learner which relaxes structural risk minimization on
&lt;/p&gt;</description></item><item><title>&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;Wasserstein&#32479;&#35745;&#22312;&#20223;&#23556;&#21464;&#24418;&#32479;&#35745;&#27169;&#22411;&#20013;&#30340;&#20449;&#24687;&#20960;&#20309;&#29305;&#24449;&#65292;&#27604;&#36739;&#20102;&#20449;&#24687;&#20960;&#20309;&#21644;Wasserstein&#20960;&#20309;&#30340;&#20272;&#35745;&#22120;&#30340;&#20248;&#32570;&#28857;&#65292;&#24182;&#21457;&#29616;Wasserstein&#20272;&#35745;&#37327;&#22312;&#26925;&#22278;&#23545;&#31216;&#20223;&#23556;&#21464;&#24418;&#27169;&#22411;&#20013;&#26159;&#30697;&#20272;&#35745;&#37327;&#65292;&#22312;&#27874;&#24418;&#20026;&#39640;&#26031;&#20998;&#24067;&#26102;&#19982;&#20449;&#24687;&#20960;&#20309;&#20272;&#35745;&#37327;&#37325;&#21512;&#12290;</title><link>http://arxiv.org/abs/2307.12508</link><description>&lt;p&gt;
&#24418;&#29366;&#21644;&#20223;&#23556;&#21464;&#24418;&#30340;Wasserstein&#32479;&#35745;&#30340;&#20449;&#24687;&#20960;&#20309;
&lt;/p&gt;
&lt;p&gt;
Information Geometry of Wasserstein Statistics on Shapes and Affine Deformations. (arXiv:2307.12508v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12508
&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;Wasserstein&#32479;&#35745;&#22312;&#20223;&#23556;&#21464;&#24418;&#32479;&#35745;&#27169;&#22411;&#20013;&#30340;&#20449;&#24687;&#20960;&#20309;&#29305;&#24449;&#65292;&#27604;&#36739;&#20102;&#20449;&#24687;&#20960;&#20309;&#21644;Wasserstein&#20960;&#20309;&#30340;&#20272;&#35745;&#22120;&#30340;&#20248;&#32570;&#28857;&#65292;&#24182;&#21457;&#29616;Wasserstein&#20272;&#35745;&#37327;&#22312;&#26925;&#22278;&#23545;&#31216;&#20223;&#23556;&#21464;&#24418;&#27169;&#22411;&#20013;&#26159;&#30697;&#20272;&#35745;&#37327;&#65292;&#22312;&#27874;&#24418;&#20026;&#39640;&#26031;&#20998;&#24067;&#26102;&#19982;&#20449;&#24687;&#20960;&#20309;&#20272;&#35745;&#37327;&#37325;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20449;&#24687;&#20960;&#20309;&#21644;Wasserstein&#20960;&#20309;&#26159;&#20171;&#32461;&#27010;&#29575;&#20998;&#24067;&#27969;&#24418;&#20013;&#30340;&#20004;&#20010;&#20027;&#35201;&#32467;&#26500;&#65292;&#23427;&#20204;&#25429;&#25417;&#20102;&#19981;&#21516;&#30340;&#29305;&#24449;&#12290;&#25105;&#20204;&#22312;&#20223;&#23556;&#21464;&#24418;&#32479;&#35745;&#27169;&#22411;&#30340;Li&#21644;Zhao&#65288;2023&#65289;&#26694;&#26550;&#20013;&#30740;&#31350;&#20102;Wasserstein&#20960;&#20309;&#30340;&#29305;&#24449;&#65292;&#23427;&#26159;&#20301;&#32622;-&#23610;&#24230;&#27169;&#22411;&#30340;&#22810;&#32500;&#27867;&#21270;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#22522;&#20110;&#20449;&#24687;&#20960;&#20309;&#21644;Wasserstein&#20960;&#20309;&#30340;&#20272;&#35745;&#22120;&#30340;&#20248;&#28857;&#21644;&#32570;&#28857;&#12290;&#22312;Wasserstein&#20960;&#20309;&#20013;&#65292;&#27010;&#29575;&#20998;&#24067;&#30340;&#24418;&#29366;&#21644;&#20223;&#23556;&#21464;&#24418;&#26159;&#20998;&#31163;&#30340;&#65292;&#34920;&#26126;&#22312;&#23545;&#27874;&#24418;&#25200;&#21160;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#21516;&#26102;&#65292;&#20250;&#25439;&#22833;Fisher&#25928;&#29575;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#26925;&#22278;&#23545;&#31216;&#20223;&#23556;&#21464;&#24418;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;Wasserstein&#20272;&#35745;&#37327;&#26159;&#30697;&#20272;&#35745;&#37327;&#12290;&#23427;&#19982;&#20449;&#24687;&#20960;&#20309;&#20272;&#35745;&#37327;&#65288;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#37327;&#65289;&#20165;&#22312;&#27874;&#24418;&#20026;&#39640;&#26031;&#20998;&#24067;&#26102;&#37325;&#21512;&#12290;Wasserstein&#25928;&#29575;&#30340;&#20316;&#29992;&#26159;...
&lt;/p&gt;
&lt;p&gt;
Information geometry and Wasserstein geometry are two main structures introduced in a manifold of probability distributions, and they capture its different characteristics. We study characteristics of Wasserstein geometry in the framework of Li and Zhao (2023) for the affine deformation statistical model, which is a multi-dimensional generalization of the location-scale model. We compare merits and demerits of estimators based on information geometry and Wasserstein geometry. The shape of a probability distribution and its affine deformation are separated in the Wasserstein geometry, showing its robustness against the waveform perturbation in exchange for the loss in Fisher efficiency. We show that the Wasserstein estimator is the moment estimator in the case of the elliptically symmetric affine deformation model. It coincides with the information-geometrical estimator (maximum-likelihood estimator) when and only when the waveform is Gaussian. The role of the Wasserstein efficiency is 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20351;&#29992;&#21160;&#24577;&#35268;&#21010;&#21644;Gumbel&#20256;&#25773;&#22312;VAE&#30340;&#28508;&#22312;&#31354;&#38388;&#20013;&#33719;&#24471;&#32467;&#26500;&#21270;&#31232;&#30095;&#26368;&#20248;&#36335;&#24452;&#65292;&#20174;&#32780;&#20351;&#24471;&#27169;&#22411;&#21487;&#20197;&#20381;&#36182;&#20110;&#26410;&#35266;&#23519;&#21040;&#30340;&#32467;&#26500;&#29305;&#24449;&#20449;&#24687;&#65292;&#24182;&#25104;&#21151;&#23454;&#29616;&#20102;&#25991;&#26412;&#36716;&#35821;&#38899;&#21644;&#27468;&#22768;&#21512;&#25104;&#12290;</title><link>http://arxiv.org/abs/2306.02568</link><description>&lt;p&gt;
Gumbel&#20256;&#25773;&#19979;&#30340;&#28508;&#22312;&#26368;&#20248;&#36335;&#24452;&#21464;&#20998;&#36125;&#21494;&#26031;&#21160;&#24577;&#35268;&#21010;
&lt;/p&gt;
&lt;p&gt;
Latent Optimal Paths by Gumbel Propagation for Variational Bayesian Dynamic Programming. (arXiv:2306.02568v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02568
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20351;&#29992;&#21160;&#24577;&#35268;&#21010;&#21644;Gumbel&#20256;&#25773;&#22312;VAE&#30340;&#28508;&#22312;&#31354;&#38388;&#20013;&#33719;&#24471;&#32467;&#26500;&#21270;&#31232;&#30095;&#26368;&#20248;&#36335;&#24452;&#65292;&#20174;&#32780;&#20351;&#24471;&#27169;&#22411;&#21487;&#20197;&#20381;&#36182;&#20110;&#26410;&#35266;&#23519;&#21040;&#30340;&#32467;&#26500;&#29305;&#24449;&#20449;&#24687;&#65292;&#24182;&#25104;&#21151;&#23454;&#29616;&#20102;&#25991;&#26412;&#36716;&#35821;&#38899;&#21644;&#27468;&#22768;&#21512;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#26041;&#27861;&#65292;&#20351;&#29992;&#21160;&#24577;&#35268;&#21010;&#21644;Gumbel&#20256;&#25773;&#22312;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#30340;&#28508;&#22312;&#31354;&#38388;&#20013;&#33719;&#21462;&#32467;&#26500;&#21270;&#31232;&#30095;&#26368;&#20248;&#36335;&#24452;&#12290;&#25105;&#20204;&#36890;&#36807;&#27010;&#29575;&#36719;&#21270;&#35299;&#65292;&#21363;&#38543;&#26426;&#26368;&#20248;&#36335;&#24452;&#65292;&#26469;&#35299;&#20915;&#32463;&#20856;&#26368;&#20248;&#36335;&#24452;&#38382;&#39064;&#65292;&#24182;&#23558;&#24191;&#27867;&#30340;DP&#38382;&#39064;&#36716;&#21270;&#20026;&#26377;&#21521;&#26080;&#29615;&#22270;&#65292;&#20854;&#20013;&#25152;&#26377;&#21487;&#33021;&#30340;&#36335;&#24452;&#36981;&#24490;Gibbs&#20998;&#24067;&#12290;&#25105;&#20204;&#36890;&#36807;Gumbel&#20998;&#24067;&#30340;&#23646;&#24615;&#26174;&#31034;Gibbs&#20998;&#24067;&#19982;&#28040;&#24687;&#20256;&#36882;&#31639;&#27861;&#30340;&#31561;&#20215;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#21464;&#20998;&#36125;&#21494;&#26031;&#25512;&#29702;&#25152;&#38656;&#30340;&#25152;&#26377;&#35201;&#32032;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#33719;&#21462;&#20102;&#28508;&#22312;&#26368;&#20248;&#36335;&#24452;&#65292;&#20351;&#29983;&#25104;&#20219;&#21153;&#30340;&#31471;&#21040;&#31471;&#35757;&#32451;&#25104;&#20026;&#21487;&#33021;&#65292;&#20854;&#20013;&#27169;&#22411;&#20381;&#36182;&#20110;&#26410;&#35266;&#23519;&#21040;&#30340;&#32467;&#26500;&#29305;&#24449;&#30340;&#20449;&#24687;&#12290;&#25105;&#20204;&#39564;&#35777;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#34892;&#20026;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;&#20004;&#20010;&#30495;&#23454;&#19990;&#30028;&#24212;&#29992;&#20013;&#30340;&#36866;&#29992;&#24615;&#65306;&#25991;&#26412;&#36716;&#35821;&#38899;&#21644;&#27468;&#22768;&#21512;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a unified approach to obtain structured sparse optimal paths in the latent space of a variational autoencoder (VAE) using dynamic programming and Gumbel propagation. We solve the classical optimal path problem by a probability softening solution, called the stochastic optimal path, and transform a wide range of DP problems into directed acyclic graphs in which all possible paths follow a Gibbs distribution. We show the equivalence of the Gibbs distribution to a message-passing algorithm by the properties of the Gumbel distribution and give all the ingredients required for variational Bayesian inference. Our approach obtaining latent optimal paths enables end-to-end training for generative tasks in which models rely on the information of unobserved structural features. We validate the behavior of our approach and showcase its applicability in two real-world applications: text-to-speech and singing voice synthesis.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#32467;&#21512;&#31867;&#20013;&#24515;&#36317;&#31163;&#21644;&#24322;&#24120;&#20540;&#25240;&#25187;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#22312;&#23384;&#22312;&#22122;&#22768;&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615; &#12290;</title><link>http://arxiv.org/abs/2303.09470</link><description>&lt;p&gt;
&#32467;&#21512;&#31867;&#20013;&#24515;&#36317;&#31163;&#21644;&#24322;&#24120;&#20540;&#25240;&#25187;&#30340;&#26041;&#27861;&#65292;&#25552;&#39640;&#22312;&#23384;&#22312;&#22122;&#22768;&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#25928;&#26524;
&lt;/p&gt;
&lt;p&gt;
Combining Distance to Class Centroids and Outlier Discounting for Improved Learning with Noisy Labels. (arXiv:2303.09470v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.09470
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#32467;&#21512;&#31867;&#20013;&#24515;&#36317;&#31163;&#21644;&#24322;&#24120;&#20540;&#25240;&#25187;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#22312;&#23384;&#22312;&#22122;&#22768;&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615; &#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#22312;&#23384;&#22312;&#22122;&#22768;&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#25361;&#25112;&#12290;&#36890;&#36807;&#22312;&#29289;&#21697;&#30340;&#28508;&#22312;&#31354;&#38388;&#20013;&#24039;&#22937;&#22320;&#20351;&#29992;&#36317;&#31163;&#31867;&#20013;&#24515;&#30340;&#26041;&#27861;&#65292;&#20877;&#32467;&#21512;&#25240;&#25187;&#31574;&#30053;&#20197;&#20943;&#23569;&#36317;&#31163;&#25152;&#26377;&#31867;&#20013;&#24515;&#65288;&#21363;&#24322;&#24120;&#20540;&#65289;&#36828;&#30340;&#26679;&#26412;&#30340;&#37325;&#35201;&#24615;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26377;&#25928;&#35299;&#20915;&#20102;&#22122;&#22768;&#26631;&#31614;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#22522;&#20110;&#36825;&#26679;&#30340;&#24819;&#27861;&#65306;&#22312;&#35757;&#32451;&#30340;&#26089;&#26399;&#38454;&#27573;&#65292;&#36317;&#31163;&#21508;&#33258;&#31867;&#20013;&#24515;&#26356;&#36828;&#30340;&#26679;&#26412;&#26356;&#21487;&#33021;&#26159;&#22122;&#22768;&#12290;&#36890;&#36807;&#22312;&#20960;&#20010;&#27969;&#34892;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#24191;&#27867;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#23384;&#22312;&#22122;&#22768;&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#26126;&#26174;&#25552;&#39640;&#20998;&#31867;&#20934;&#30830;&#24615;&#65292;&#34920;&#29616;&#20248;&#20110;&#24403;&#21069;&#39046;&#22495;&#30340;&#26368;&#20248;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a new approach for addressing the challenge of training machine learning models in the presence of noisy labels. By combining a clever usage of distance to class centroids in the items' latent space with a discounting strategy to reduce the importance of samples far away from all the class centroids (i.e., outliers), our method effectively addresses the issue of noisy labels. Our approach is based on the idea that samples farther away from their respective class centroid in the early stages of training are more likely to be noisy. We demonstrate the effectiveness of our method through extensive experiments on several popular benchmark datasets. Our results show that our approach outperforms the state-of-the-art in this area, achieving significant improvements in classification accuracy when the dataset contains noisy labels.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#26680;&#26031;&#22374;&#31163;&#24046;&#65288;KSD&#65289;&#25511;&#21046;&#24615;&#36136;&#65292;&#21457;&#29616;&#26631;&#20934;KSD&#26080;&#27861;&#25511;&#21046;&#30697;&#30340;&#25910;&#25947;&#65292;&#25552;&#20986;&#20102;&#21487;&#25511;&#21046;&#30697;&#21644;&#24369;&#25910;&#25947;&#30340;&#19979;&#28216;&#25193;&#25955;KSD&#65292;&#24182;&#19988;&#21457;&#23637;&#20102;&#21487;&#20197;&#20934;&#30830;&#25551;&#36848;$q$-Wasserstein&#25910;&#25947;&#30340;KSD&#12290;</title><link>http://arxiv.org/abs/2211.05408</link><description>&lt;p&gt;
&#29992;&#26680;&#26031;&#22374;&#31163;&#24046;&#25511;&#21046;&#30697;
&lt;/p&gt;
&lt;p&gt;
Controlling Moments with Kernel Stein Discrepancies. (arXiv:2211.05408v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.05408
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#26680;&#26031;&#22374;&#31163;&#24046;&#65288;KSD&#65289;&#25511;&#21046;&#24615;&#36136;&#65292;&#21457;&#29616;&#26631;&#20934;KSD&#26080;&#27861;&#25511;&#21046;&#30697;&#30340;&#25910;&#25947;&#65292;&#25552;&#20986;&#20102;&#21487;&#25511;&#21046;&#30697;&#21644;&#24369;&#25910;&#25947;&#30340;&#19979;&#28216;&#25193;&#25955;KSD&#65292;&#24182;&#19988;&#21457;&#23637;&#20102;&#21487;&#20197;&#20934;&#30830;&#25551;&#36848;$q$-Wasserstein&#25910;&#25947;&#30340;KSD&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26680;&#26031;&#22374;&#31163;&#24046;&#65288;KSD&#65289;&#29992;&#20110;&#34913;&#37327;&#20998;&#24067;&#36924;&#36817;&#30340;&#36136;&#37327;&#65292;&#24182;&#19988;&#21487;&#20197;&#22312;&#30446;&#26631;&#23494;&#24230;&#20855;&#26377;&#19981;&#21487;&#35745;&#31639;&#30340;&#24402;&#19968;&#21270;&#24120;&#25968;&#26102;&#35745;&#31639;&#12290;&#26174;&#33879;&#30340;&#24212;&#29992;&#21253;&#25324;&#35786;&#26029;&#36817;&#20284;MCMC&#37319;&#26679;&#22120;&#21644;&#38750;&#24402;&#19968;&#21270;&#32479;&#35745;&#27169;&#22411;&#30340;&#36866;&#37197;&#24230;&#26816;&#39564;&#12290;&#26412;&#25991;&#20998;&#26512;&#20102;KSD&#30340;&#25910;&#25947;&#25511;&#21046;&#24615;&#36136;&#12290;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#20102;&#29992;&#20110;&#24369;&#25910;&#25947;&#25511;&#21046;&#30340;&#26631;&#20934;KSD&#26080;&#27861;&#25511;&#21046;&#30697;&#30340;&#25910;&#25947;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#32452;&#20805;&#20998;&#26465;&#20214;&#65292;&#19979;&#28216;&#25193;&#25955;KSD&#21487;&#20197;&#21516;&#26102;&#25511;&#21046;&#30697;&#21644;&#24369;&#25910;&#25947;&#12290;&#20316;&#20026;&#19968;&#20010;&#30452;&#25509;&#30340;&#32467;&#26524;&#65292;&#25105;&#20204;&#21457;&#23637;&#20102;&#23545;&#20110;&#27599;&#20010;$q&gt;0$&#65292;&#31532;&#19968;&#32452;&#24050;&#30693;&#21487;&#20197;&#20934;&#30830;&#25551;&#36848;$q$-Wasserstein&#25910;&#25947;&#30340;KSD&#12290;
&lt;/p&gt;
&lt;p&gt;
Kernel Stein discrepancies (KSDs) measure the quality of a distributional approximation and can be computed even when the target density has an intractable normalizing constant. Notable applications include the diagnosis of approximate MCMC samplers and goodness-of-fit tests for unnormalized statistical models. The present work analyzes the convergence control properties of KSDs. We first show that standard KSDs used for weak convergence control fail to control moment convergence. To address this limitation, we next provide sufficient conditions under which alternative diffusion KSDs control both moment and weak convergence. As an immediate consequence we develop, for each $q &gt; 0$, the first KSDs known to exactly characterize $q$-Wasserstein convergence.
&lt;/p&gt;</description></item></channel></rss>