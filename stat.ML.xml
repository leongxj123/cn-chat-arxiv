<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#30740;&#31350;&#24314;&#31435;&#20102;&#39318;&#20010;&#22312;&#23545;&#25239;&#24615;&#22810;&#33218;&#32769;&#34382;&#26426;&#20013;&#20248;&#21270;&#19988;&#33258;&#36866;&#24212;&#30340;&#27874;&#36798;&#21160;&#24577;&#36951;&#25022;&#19978;&#30028;&#65292;&#25581;&#31034;&#20102;&#22312;Condorcet&#21644;Borda&#20043;&#38388;&#20005;&#37325;&#38750;&#24179;&#31283;&#24615;&#21487;&#23398;&#20064;&#24615;&#30340;&#22522;&#26412;&#24046;&#24322;</title><link>https://arxiv.org/abs/2403.12950</link><description>&lt;p&gt;
&#20248;&#21270;&#30340;&#33258;&#36866;&#24212;&#38750;&#24179;&#31283;&#23545;&#25239;&#24615;&#22810;&#33218;&#32769;&#34382;&#26426;&#22312;&#24191;&#20041;&#27874;&#36798;&#20934;&#21017;&#19979;
&lt;/p&gt;
&lt;p&gt;
Optimal and Adaptive Non-Stationary Dueling Bandits Under a Generalized Borda Criterion
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12950
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#24314;&#31435;&#20102;&#39318;&#20010;&#22312;&#23545;&#25239;&#24615;&#22810;&#33218;&#32769;&#34382;&#26426;&#20013;&#20248;&#21270;&#19988;&#33258;&#36866;&#24212;&#30340;&#27874;&#36798;&#21160;&#24577;&#36951;&#25022;&#19978;&#30028;&#65292;&#25581;&#31034;&#20102;&#22312;Condorcet&#21644;Borda&#20043;&#38388;&#20005;&#37325;&#38750;&#24179;&#31283;&#24615;&#21487;&#23398;&#20064;&#24615;&#30340;&#22522;&#26412;&#24046;&#24322;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23545;&#25239;&#24615;&#22810;&#33218;&#32769;&#34382;&#26426;&#20013;&#65292;&#23398;&#20064;&#32773;&#25509;&#25910;&#33218;&#20043;&#38388;&#30340;&#20559;&#22909;&#21453;&#39304;&#65292;&#24182;&#23558;&#26576;&#20010;&#33218;&#30340;&#36951;&#25022;&#23450;&#20041;&#20026;&#20854;&#30456;&#23545;&#20110;&#20248;&#32988;&#33218;&#30340;&#27425;&#20248;&#24615;&#12290;&#26356;&#20855;&#25361;&#25112;&#24615;&#21644;&#23454;&#36341;&#21160;&#26426;&#30340;&#38750;&#24179;&#31283;&#23545;&#25239;&#24615;&#22810;&#33218;&#32769;&#34382;&#26426;&#21464;&#20307;&#65292;&#22312;&#36825;&#31181;&#21464;&#20307;&#20013;&#65292;&#20559;&#22909;&#38543;&#26102;&#38388;&#21464;&#21270;&#65292;&#24050;&#32463;&#25104;&#20026;&#36817;&#26399;&#22810;&#39033;&#24037;&#20316;&#30340;&#28966;&#28857;&#12290;&#30446;&#26631;&#26159;&#35774;&#35745;&#20986;&#31639;&#27861;&#65292;&#32780;&#26080;&#38656;&#25552;&#21069;&#20102;&#35299;&#21464;&#21270;&#37327;&#12290;&#24050;&#30693;&#32467;&#26524;&#30340;&#22823;&#37096;&#20998;&#30740;&#31350;&#20102;&#23380;&#22810;&#22622;&#20248;&#32988;&#32773;&#35774;&#32622;&#65292;&#20854;&#20013;&#20248;&#20808;&#20110;&#20854;&#20182;&#20219;&#20309;&#33218;&#30340;&#33218;&#22312;&#20219;&#20309;&#26102;&#20505;&#37117;&#23384;&#22312;&#12290;&#28982;&#32780;&#65292;&#36825;&#26679;&#30340;&#20248;&#32988;&#32773;&#21487;&#33021;&#24182;&#19981;&#23384;&#22312;&#65292;&#20026;&#20102;&#23545;&#27604;&#65292;&#27492;&#38382;&#39064;&#30340;&#27874;&#36798;&#29256;&#26412;&#65288;&#22987;&#32456;&#26377;&#26126;&#30830;&#23450;&#20041;&#65289;&#21364;&#21463;&#21040;&#20102;&#24456;&#23569;&#20851;&#27880;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#31532;&#19968;&#20010;&#26368;&#20248;&#21644;&#33258;&#36866;&#24212;&#30340;&#27874;&#36798;&#21160;&#24577;&#36951;&#25022;&#19978;&#30028;&#65292;&#31361;&#26174;&#20102;&#22312;&#23380;&#22810;&#22622;&#21644;&#27874;&#36798;&#20043;&#38388;&#30340;&#20005;&#37325;&#38750;&#24179;&#31283;&#24615;&#21487;&#23398;&#20064;&#24615;&#30340;&#22522;&#26412;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12950v1 Announce Type: new  Abstract: In dueling bandits, the learner receives preference feedback between arms, and the regret of an arm is defined in terms of its suboptimality to a winner arm. The more challenging and practically motivated non-stationary variant of dueling bandits, where preferences change over time, has been the focus of several recent works (Saha and Gupta, 2022; Buening and Saha, 2023; Suk and Agarwal, 2023). The goal is to design algorithms without foreknowledge of the amount of change.   The bulk of known results here studies the Condorcet winner setting, where an arm preferred over any other exists at all times. Yet, such a winner may not exist and, to contrast, the Borda version of this problem (which is always well-defined) has received little attention. In this work, we establish the first optimal and adaptive Borda dynamic regret upper bound, which highlights fundamental differences in the learnability of severe non-stationarity between Condorce
&lt;/p&gt;</description></item><item><title>&#39640;&#26031;&#27169;&#22411;&#38598;&#25104;&#32622;&#20449;&#20256;&#25773;&#31639;&#27861;&#65288;GEnBP&#65289;&#26159;&#19968;&#31181;&#29992;&#20110;&#39640;&#32500;&#31995;&#32479;&#20013;&#39640;&#25928;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#38598;&#25104;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#21644;&#39640;&#26031;&#32622;&#20449;&#20256;&#25773;&#31561;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#33021;&#26377;&#25928;&#22788;&#29702;&#39640;&#32500;&#29366;&#24577;&#12289;&#21442;&#25968;&#21644;&#22797;&#26434;&#30340;&#20381;&#36182;&#32467;&#26500;&#12290;</title><link>https://arxiv.org/abs/2402.08193</link><description>&lt;p&gt;
&#39640;&#26031;&#27169;&#22411;&#38598;&#25104;&#32622;&#20449;&#20256;&#25773;&#29992;&#20110;&#39640;&#32500;&#31995;&#32479;&#20013;&#30340;&#39640;&#25928;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Gaussian Ensemble Belief Propagation for Efficient Inference in High-Dimensional Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08193
&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#27169;&#22411;&#38598;&#25104;&#32622;&#20449;&#20256;&#25773;&#31639;&#27861;&#65288;GEnBP&#65289;&#26159;&#19968;&#31181;&#29992;&#20110;&#39640;&#32500;&#31995;&#32479;&#20013;&#39640;&#25928;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#38598;&#25104;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#21644;&#39640;&#26031;&#32622;&#20449;&#20256;&#25773;&#31561;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#33021;&#26377;&#25928;&#22788;&#29702;&#39640;&#32500;&#29366;&#24577;&#12289;&#21442;&#25968;&#21644;&#22797;&#26434;&#30340;&#20381;&#36182;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#32500;&#27169;&#22411;&#20013;&#30340;&#39640;&#25928;&#25512;&#26029;&#20173;&#28982;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#26680;&#24515;&#25361;&#25112;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#39640;&#26031;&#27169;&#22411;&#38598;&#25104;&#32622;&#20449;&#20256;&#25773;&#65288;GEnBP&#65289;&#31639;&#27861;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#26159;&#38598;&#25104;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#21644;&#39640;&#26031;&#32622;&#20449;&#20256;&#25773;&#65288;GaBP&#65289;&#26041;&#27861;&#30340;&#32467;&#21512;&#12290;GEnBP&#36890;&#36807;&#22312;&#22270;&#27169;&#22411;&#32467;&#26500;&#20013;&#20256;&#36882;&#20302;&#31209;&#26412;&#22320;&#20449;&#24687;&#26469;&#26356;&#26032;&#38598;&#25104;&#27169;&#22411;&#12290;&#36825;&#31181;&#32452;&#21512;&#32487;&#25215;&#20102;&#27599;&#31181;&#26041;&#27861;&#30340;&#26377;&#21033;&#29305;&#24615;&#12290;&#38598;&#25104;&#25216;&#26415;&#20351;&#24471;GEnBP&#33021;&#22815;&#22788;&#29702;&#39640;&#32500;&#29366;&#24577;&#12289;&#21442;&#25968;&#21644;&#22797;&#26434;&#30340;&#12289;&#22024;&#26434;&#30340;&#40657;&#31665;&#29983;&#25104;&#36807;&#31243;&#12290;&#22312;&#22270;&#27169;&#22411;&#32467;&#26500;&#20013;&#20351;&#29992;&#26412;&#22320;&#20449;&#24687;&#30830;&#20445;&#20102;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#20998;&#24067;&#24335;&#35745;&#31639;&#65292;&#24182;&#33021;&#39640;&#25928;&#22320;&#22788;&#29702;&#22797;&#26434;&#30340;&#20381;&#36182;&#32467;&#26500;&#12290;&#24403;&#38598;&#25104;&#22823;&#23567;&#36828;&#23567;&#20110;&#25512;&#26029;&#32500;&#24230;&#26102;&#65292;GEnBP&#29305;&#21035;&#26377;&#20248;&#21183;&#12290;&#36825;&#31181;&#24773;&#20917;&#22312;&#31354;&#26102;&#24314;&#27169;&#12289;&#22270;&#20687;&#22788;&#29702;&#21644;&#29289;&#29702;&#27169;&#22411;&#21453;&#28436;&#31561;&#39046;&#22495;&#32463;&#24120;&#20986;&#29616;&#12290;GEnBP&#21487;&#20197;&#24212;&#29992;&#20110;&#19968;&#33324;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Efficient inference in high-dimensional models remains a central challenge in machine learning. This paper introduces the Gaussian Ensemble Belief Propagation (GEnBP) algorithm, a fusion of the Ensemble Kalman filter and Gaussian belief propagation (GaBP) methods. GEnBP updates ensembles by passing low-rank local messages in a graphical model structure. This combination inherits favourable qualities from each method. Ensemble techniques allow GEnBP to handle high-dimensional states, parameters and intricate, noisy, black-box generation processes. The use of local messages in a graphical model structure ensures that the approach is suited to distributed computing and can efficiently handle complex dependence structures. GEnBP is particularly advantageous when the ensemble size is considerably smaller than the inference dimension. This scenario often arises in fields such as spatiotemporal modelling, image processing and physical model inversion. GEnBP can be applied to general problem s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#20013;&#20934;&#30830;&#22320;&#27979;&#37327;&#39640;&#36798;1&#20159;&#21442;&#25968;&#30340;&#23616;&#37096;&#23398;&#20064;&#31995;&#25968;(LLC)&#65292;&#24182;&#35777;&#26126;&#20102;&#20272;&#35745;&#24471;&#21040;&#30340;LLC&#20855;&#26377;&#37325;&#32553;&#25918;&#19981;&#21464;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.03698</link><description>&lt;p&gt;
&#22312;&#22823;&#35268;&#27169;&#24773;&#20917;&#19979;&#20272;&#35745;&#23616;&#37096;&#23398;&#20064;&#31995;&#25968;
&lt;/p&gt;
&lt;p&gt;
Estimating the Local Learning Coefficient at Scale
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03698
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#20013;&#20934;&#30830;&#22320;&#27979;&#37327;&#39640;&#36798;1&#20159;&#21442;&#25968;&#30340;&#23616;&#37096;&#23398;&#20064;&#31995;&#25968;(LLC)&#65292;&#24182;&#35777;&#26126;&#20102;&#20272;&#35745;&#24471;&#21040;&#30340;LLC&#20855;&#26377;&#37325;&#32553;&#25918;&#19981;&#21464;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23616;&#37096;&#23398;&#20064;&#31995;&#25968;(LLC)&#26159;&#19968;&#31181;&#37327;&#21270;&#27169;&#22411;&#22797;&#26434;&#24615;&#30340;&#21407;&#21017;&#24615;&#26041;&#27861;&#65292;&#26368;&#21021;&#26159;&#22312;&#36125;&#21494;&#26031;&#32479;&#35745;&#20013;&#20351;&#29992;&#22855;&#24322;&#23398;&#20064;&#29702;&#35770;(SLT)&#25512;&#23548;&#20986;&#26469;&#30340;&#12290;&#24050;&#30693;&#26377;&#20960;&#31181;&#25968;&#20540;&#20272;&#35745;&#23616;&#37096;&#23398;&#20064;&#31995;&#25968;&#30340;&#26041;&#27861;&#65292;&#20294;&#36804;&#20170;&#20026;&#27490;&#36825;&#20123;&#26041;&#27861;&#23578;&#26410;&#25193;&#23637;&#21040;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#25110;&#25968;&#25454;&#38598;&#30340;&#35268;&#27169;&#12290;&#36890;&#36807;&#22312;arXiv:2308.12108 [stat.ML]&#20013;&#24320;&#21457;&#30340;&#19968;&#31181;&#26041;&#27861;&#65292;&#25105;&#20204;&#32463;&#39564;&#35777;&#26126;&#21487;&#20197;&#20934;&#30830;&#21644;&#33258;&#27965;&#22320;&#27979;&#37327;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;(DLN)&#20013;&#39640;&#36798;1&#20159;&#21442;&#25968;&#30340;&#23616;&#37096;&#23398;&#20064;&#31995;&#25968;(LLC)&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#20272;&#35745;&#24471;&#21040;&#30340;LLC&#20855;&#26377;&#29702;&#35770;&#25968;&#37327;&#25152;&#20855;&#22791;&#30340;&#37325;&#32553;&#25918;&#19981;&#21464;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The \textit{local learning coefficient} (LLC) is a principled way of quantifying model complexity, originally derived in the context of Bayesian statistics using singular learning theory (SLT). Several methods are known for numerically estimating the local learning coefficient, but so far these methods have not been extended to the scale of modern deep learning architectures or data sets. Using a method developed in {\tt arXiv:2308.12108 [stat.ML]} we empirically show how the LLC may be measured accurately and self-consistently for deep linear networks (DLNs) up to 100M parameters. We also show that the estimated LLC has the rescaling invariance that holds for the theoretical quantity.
&lt;/p&gt;</description></item><item><title>&#22522;&#20110;&#33021;&#37327;&#30340;&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#32479;&#19968;&#20102;&#39044;&#27979;&#12289;&#27010;&#24565;&#24178;&#39044;&#21644;&#26465;&#20214;&#35299;&#37322;&#30340;&#21151;&#33021;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#22312;&#39640;&#38454;&#38750;&#32447;&#24615;&#30456;&#20114;&#20316;&#29992;&#21644;&#22797;&#26434;&#26465;&#20214;&#20381;&#36182;&#20851;&#31995;&#19978;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2401.14142</link><description>&lt;p&gt;
&#22522;&#20110;&#33021;&#37327;&#30340;&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#65306;&#32479;&#19968;&#39044;&#27979;&#12289;&#27010;&#24565;&#24178;&#39044;&#21644;&#26465;&#20214;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Energy-Based Concept Bottleneck Models: Unifying Prediction, Concept Intervention, and Conditional Interpretations. (arXiv:2401.14142v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14142
&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#33021;&#37327;&#30340;&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#32479;&#19968;&#20102;&#39044;&#27979;&#12289;&#27010;&#24565;&#24178;&#39044;&#21644;&#26465;&#20214;&#35299;&#37322;&#30340;&#21151;&#33021;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#22312;&#39640;&#38454;&#38750;&#32447;&#24615;&#30456;&#20114;&#20316;&#29992;&#21644;&#22797;&#26434;&#26465;&#20214;&#20381;&#36182;&#20851;&#31995;&#19978;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#26041;&#27861;&#65292;&#22914;&#27010;&#24565;&#29942;&#39048;&#27169;&#22411; (CBM)&#65292;&#22312;&#20026;&#40657;&#30418;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#25552;&#20379;&#22522;&#20110;&#27010;&#24565;&#30340;&#35299;&#37322;&#26041;&#38754;&#21462;&#24471;&#20102;&#25104;&#21151;&#12290;&#23427;&#20204;&#36890;&#24120;&#36890;&#36807;&#22312;&#32473;&#23450;&#36755;&#20837;&#30340;&#24773;&#20917;&#19979;&#39044;&#27979;&#27010;&#24565;&#65292;&#28982;&#21518;&#22312;&#32473;&#23450;&#39044;&#27979;&#30340;&#27010;&#24565;&#30340;&#24773;&#20917;&#19979;&#39044;&#27979;&#26368;&#32456;&#30340;&#31867;&#21035;&#26631;&#31614;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#32463;&#24120;&#26080;&#27861;&#25429;&#25417;&#21040;&#27010;&#24565;&#20043;&#38388;&#30340;&#39640;&#38454;&#38750;&#32447;&#24615;&#30456;&#20114;&#20316;&#29992;&#65292;&#20363;&#22914;&#32416;&#27491;&#19968;&#20010;&#39044;&#27979;&#30340;&#27010;&#24565;&#65288;&#20363;&#22914;&#8220;&#40644;&#33394;&#33016;&#37096;&#8221;&#65289;&#26080;&#27861;&#24110;&#21161;&#32416;&#27491;&#39640;&#24230;&#30456;&#20851;&#30340;&#27010;&#24565;&#65288;&#20363;&#22914;&#8220;&#40644;&#33394;&#33145;&#37096;&#8221;&#65289;&#65292;&#23548;&#33268;&#26368;&#32456;&#20934;&#30830;&#29575;&#19981;&#29702;&#24819;&#65307;&#23427;&#20204;&#26080;&#27861;&#33258;&#28982;&#22320;&#37327;&#21270;&#19981;&#21516;&#27010;&#24565;&#21644;&#31867;&#21035;&#26631;&#31614;&#20043;&#38388;&#30340;&#22797;&#26434;&#26465;&#20214;&#20381;&#36182;&#20851;&#31995;&#65288;&#20363;&#22914;&#23545;&#20110;&#19968;&#20010;&#24102;&#26377;&#31867;&#21035;&#26631;&#31614;&#8220;Kentucky Warbler&#8221;&#21644;&#27010;&#24565;&#8220;&#40657;&#33394;&#22068;&#24052;&#8221;&#30340;&#22270;&#20687;&#65292;&#27169;&#22411;&#33021;&#22815;&#27491;&#30830;&#39044;&#27979;&#21478;&#19968;&#20010;&#27010;&#24565;&#8220;&#40657;&#33394;&#20896;&#8221;&#30340;&#27010;&#29575;&#26159;&#22810;&#23569;&#65289;&#65292;&#22240;&#27492;&#26080;&#27861;&#25552;&#20379;&#20851;&#20110;&#40657;&#30418;&#27169;&#22411;&#24037;&#20316;&#21407;&#29702;&#26356;&#28145;&#23618;&#27425;&#30340;&#27934;&#23519;&#12290;&#38024;&#23545;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#33021;&#37327;&#30340;&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#65288;Energy-based Concept Bottleneck Models&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing methods, such as concept bottleneck models (CBMs), have been successful in providing concept-based interpretations for black-box deep learning models. They typically work by predicting concepts given the input and then predicting the final class label given the predicted concepts. However, (1) they often fail to capture the high-order, nonlinear interaction between concepts, e.g., correcting a predicted concept (e.g., "yellow breast") does not help correct highly correlated concepts (e.g., "yellow belly"), leading to suboptimal final accuracy; (2) they cannot naturally quantify the complex conditional dependencies between different concepts and class labels (e.g., for an image with the class label "Kentucky Warbler" and a concept "black bill", what is the probability that the model correctly predicts another concept "black crown"), therefore failing to provide deeper insight into how a black-box model works. In response to these limitations, we propose Energy-based Concept Bot
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#22312;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#31354;&#38388;&#20013;&#30340;Gromov-Wasserstein&#31867;&#22411;&#36317;&#31163;&#65292;&#20998;&#21035;&#29992;&#20110;&#35780;&#20272;&#20998;&#24067;&#20043;&#38388;&#30340;&#36317;&#31163;&#21644;&#25512;&#23548;&#26368;&#20248;&#30340;&#28857;&#20998;&#37197;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2310.11256</link><description>&lt;p&gt;
&#22312;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#31354;&#38388;&#20013;&#24341;&#20837;&#20102;&#31867;&#20284;&#20110;Gromov-Wassertein&#30340;&#36317;&#31163;
&lt;/p&gt;
&lt;p&gt;
Gromov-Wassertein-like Distances in the Gaussian Mixture Models Space. (arXiv:2310.11256v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11256
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#22312;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#31354;&#38388;&#20013;&#30340;Gromov-Wasserstein&#31867;&#22411;&#36317;&#31163;&#65292;&#20998;&#21035;&#29992;&#20110;&#35780;&#20272;&#20998;&#24067;&#20043;&#38388;&#30340;&#36317;&#31163;&#21644;&#25512;&#23548;&#26368;&#20248;&#30340;&#28857;&#20998;&#37197;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#22312;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#38598;&#21512;&#19978;&#30340;Gromov-Wasserstein&#31867;&#22411;&#36317;&#31163;&#12290;&#31532;&#19968;&#31181;&#36317;&#31163;&#26159;&#22312;&#39640;&#26031;&#27979;&#24230;&#31354;&#38388;&#19978;&#20004;&#20010;&#31163;&#25955;&#20998;&#24067;&#30340;Gromov-Wasserstein&#36317;&#31163;&#12290;&#35813;&#36317;&#31163;&#21487;&#20197;&#20316;&#20026;Gromov-Wasserstein&#30340;&#26367;&#20195;&#65292;&#29992;&#20110;&#35780;&#20272;&#20998;&#24067;&#20043;&#38388;&#30340;&#36317;&#31163;&#65292;&#20294;&#19981;&#33021;&#30452;&#25509;&#25512;&#23548;&#20986;&#26368;&#20248;&#30340;&#36816;&#36755;&#26041;&#26696;&#12290;&#20026;&#20102;&#35774;&#35745;&#20986;&#36825;&#26679;&#30340;&#36816;&#36755;&#26041;&#26696;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#21478;&#19968;&#31181;&#22312;&#19981;&#21487;&#27604;&#36739;&#30340;&#31354;&#38388;&#20013;&#30340;&#27979;&#24230;&#20043;&#38388;&#30340;&#36317;&#31163;&#65292;&#35813;&#36317;&#31163;&#19982;Gromov-Wasserstein&#23494;&#20999;&#30456;&#20851;&#12290;&#24403;&#23558;&#20801;&#35768;&#30340;&#36816;&#36755;&#32806;&#21512;&#38480;&#21046;&#20026;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#26102;&#65292;&#36825;&#23450;&#20041;&#20102;&#21478;&#19968;&#31181;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#20043;&#38388;&#30340;&#36317;&#31163;&#65292;&#21487;&#20197;&#20316;&#20026;Gromov-Wasserstein&#30340;&#21478;&#19968;&#31181;&#26367;&#20195;&#65292;&#24182;&#20801;&#35768;&#25512;&#23548;&#20986;&#26368;&#20248;&#30340;&#28857;&#20998;&#37197;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce two Gromov-Wasserstein-type distances on the set of Gaussian mixture models. The first one takes the form of a Gromov-Wasserstein distance between two discrete distributionson the space of Gaussian measures. This distance can be used as an alternative to Gromov-Wasserstein for applications which only require to evaluate how far the distributions are from each other but does not allow to derive directly an optimal transportation plan between clouds of points. To design a way to define such a transportation plan, we introduce another distance between measures living in incomparable spaces that turns out to be closely related to Gromov-Wasserstein. When restricting the set of admissible transportation couplings to be themselves Gaussian mixture models in this latter, this defines another distance between Gaussian mixture models that can be used as another alternative to Gromov-Wasserstein and which allows to derive an optimal assignment between points. Finally,
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23545;&#20110;&#23545;&#25239;&#29983;&#25104;&#30340;&#31034;&#20363;&#32570;&#20047;&#40065;&#26834;&#24615;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#20960;&#20309;&#35282;&#24230;&#20986;&#21457;&#30340;&#26032;&#39062;&#35270;&#35282;&#65292;&#20171;&#32461;&#19968;&#26063;&#27010;&#29575;&#38750;&#23616;&#37096;&#21608;&#38271;&#20989;&#25968;&#26469;&#20248;&#21270;&#27010;&#29575;&#40065;&#26834;&#23398;&#20064;&#65288;PRL&#65289;&#30340;&#21407;&#22987;&#34920;&#36848;&#65292;&#20197;&#25552;&#39640;&#20854;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.18779</link><description>&lt;p&gt;
&#20174;&#20960;&#20309;&#35282;&#24230;&#30475;&#24453;&#27010;&#29575;&#40065;&#26834;&#23398;&#20064;&#20013;&#30340;&#36793;&#30028;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
It begins with a boundary: A geometric view on probabilistically robust learning. (arXiv:2305.18779v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18779
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23545;&#20110;&#23545;&#25239;&#29983;&#25104;&#30340;&#31034;&#20363;&#32570;&#20047;&#40065;&#26834;&#24615;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#20960;&#20309;&#35282;&#24230;&#20986;&#21457;&#30340;&#26032;&#39062;&#35270;&#35282;&#65292;&#20171;&#32461;&#19968;&#26063;&#27010;&#29575;&#38750;&#23616;&#37096;&#21608;&#38271;&#20989;&#25968;&#26469;&#20248;&#21270;&#27010;&#29575;&#40065;&#26834;&#23398;&#20064;&#65288;PRL&#65289;&#30340;&#21407;&#22987;&#34920;&#36848;&#65292;&#20197;&#25552;&#39640;&#20854;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#35768;&#22810;&#20998;&#31867;&#20219;&#21153;&#19978;&#24050;&#32463;&#23454;&#29616;&#20102;&#36229;&#20154;&#31867;&#30340;&#34920;&#29616;&#65292;&#20294;&#23427;&#20204;&#24448;&#24448;&#23545;&#20110;&#23545;&#25239;&#29983;&#25104;&#30340;&#31034;&#20363;&#32570;&#20047;&#40065;&#26834;&#24615;&#65292;&#22240;&#27492;&#38656;&#35201;&#23558;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;ERM&#65289;&#37325;&#26500;&#20026;&#23545;&#25239;&#24615;&#40065;&#26834;&#30340;&#26694;&#26550;&#12290;&#26368;&#36817;&#65292;&#20851;&#27880;&#28857;&#24050;&#32463;&#36716;&#21521;&#20102;&#20171;&#20110;&#23545;&#25239;&#24615;&#35757;&#32451;&#25552;&#20379;&#30340;&#40065;&#26834;&#24615;&#21644;ERM&#25552;&#20379;&#30340;&#26356;&#39640;&#24178;&#20928;&#20934;&#30830;&#24615;&#21644;&#26356;&#24555;&#35757;&#32451;&#26102;&#38388;&#20043;&#38388;&#30340;&#26041;&#27861;&#12290;&#26412;&#25991;&#20174;&#20960;&#20309;&#35282;&#24230;&#20986;&#21457;&#65292;&#23545;&#19968;&#31181;&#36825;&#26679;&#30340;&#26041;&#27861;&#8212;&#8212;&#27010;&#29575;&#40065;&#26834;&#23398;&#20064;&#65288;PRL&#65289;&#65288;Robey&#31561;&#20154;&#65292;ICML&#65292;2022&#65289;&#36827;&#34892;&#20102;&#26032;&#39062;&#30340;&#20960;&#20309;&#35270;&#35282;&#30340;&#25506;&#35752;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20960;&#20309;&#26694;&#26550;&#26469;&#29702;&#35299;PRL&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#30830;&#23450;&#20854;&#21407;&#22987;&#34920;&#36848;&#20013;&#30340;&#24494;&#22937;&#32570;&#38519;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#26063;&#27010;&#29575;&#38750;&#23616;&#37096;&#21608;&#38271;&#20989;&#25968;&#26469;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#12290;&#25105;&#20204;&#20351;&#29992;&#26032;&#39062;&#30340;&#26494;&#24347;&#26041;&#27861;&#35777;&#26126;&#20102;&#35299;&#30340;&#23384;&#22312;&#65292;&#24182;&#30740;&#31350;&#20102;&#24341;&#20837;&#30340;&#38750;&#23616;&#37096;&#21608;&#38271;&#20989;&#25968;&#30340;&#29305;&#24615;&#20197;&#21450;&#23616;&#37096;&#26497;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
Although deep neural networks have achieved super-human performance on many classification tasks, they often exhibit a worrying lack of robustness towards adversarially generated examples. Thus, considerable effort has been invested into reformulating Empirical Risk Minimization (ERM) into an adversarially robust framework. Recently, attention has shifted towards approaches which interpolate between the robustness offered by adversarial training and the higher clean accuracy and faster training times of ERM. In this paper, we take a fresh and geometric view on one such method -- Probabilistically Robust Learning (PRL) (Robey et al., ICML, 2022). We propose a geometric framework for understanding PRL, which allows us to identify a subtle flaw in its original formulation and to introduce a family of probabilistic nonlocal perimeter functionals to address this. We prove existence of solutions using novel relaxation methods and study properties as well as local limits of the introduced per
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20108;&#20540;&#19968;&#33324;&#22240;&#26524;&#27169;&#22411;&#21644;BGLMs&#19978;&#19981;&#32771;&#34385;&#22270;&#39592;&#26550;&#30340;&#32452;&#21512;&#22240;&#26524;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#21487;&#22312;BGLMs&#19978;&#23454;&#29616;&#30340;&#26080;&#38656;&#22270;&#39592;&#26550;&#30340;&#36951;&#25022;&#26368;&#23567;&#21270;&#31639;&#27861;&#65292;&#36798;&#21040;&#20102;&#19982;&#20381;&#36182;&#20110;&#22270;&#32467;&#26500;&#30340;&#26368;&#20808;&#36827;&#31639;&#27861;&#30456;&#21516;&#30340;&#28176;&#36827;&#36951;&#25022;&#29575;$O(\sqrt{T}\ln T)$&#12290;</title><link>http://arxiv.org/abs/2301.13392</link><description>&lt;p&gt;
&#19981;&#32771;&#34385;&#22270;&#39592;&#26550;&#30340;&#32452;&#21512;&#22240;&#26524;&#36172;&#21338;&#26426;
&lt;/p&gt;
&lt;p&gt;
Combinatorial Causal Bandits without Graph Skeleton. (arXiv:2301.13392v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.13392
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20108;&#20540;&#19968;&#33324;&#22240;&#26524;&#27169;&#22411;&#21644;BGLMs&#19978;&#19981;&#32771;&#34385;&#22270;&#39592;&#26550;&#30340;&#32452;&#21512;&#22240;&#26524;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#21487;&#22312;BGLMs&#19978;&#23454;&#29616;&#30340;&#26080;&#38656;&#22270;&#39592;&#26550;&#30340;&#36951;&#25022;&#26368;&#23567;&#21270;&#31639;&#27861;&#65292;&#36798;&#21040;&#20102;&#19982;&#20381;&#36182;&#20110;&#22270;&#32467;&#26500;&#30340;&#26368;&#20808;&#36827;&#31639;&#27861;&#30456;&#21516;&#30340;&#28176;&#36827;&#36951;&#25022;&#29575;$O(\sqrt{T}\ln T)$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32452;&#21512;&#22240;&#26524;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#65292;&#23398;&#20064;&#20195;&#29702;&#22312;&#27599;&#19968;&#36718;&#36873;&#25321;&#19968;&#32452;&#21464;&#37327;&#36827;&#34892;&#24178;&#39044;&#65292;&#25910;&#38598;&#35266;&#27979;&#21464;&#37327;&#30340;&#21453;&#39304;&#20197;&#26368;&#23567;&#21270;&#26399;&#26395;&#36951;&#25022;&#25110;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#20808;&#21069;&#30340;&#24037;&#20316;&#30740;&#31350;&#20102;&#19968;&#33324;&#22240;&#26524;&#27169;&#22411;&#21644;&#20108;&#20540;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#65288;BGLMs&#65289;&#20013;&#30340;&#38382;&#39064;&#12290;&#20294;&#26159;&#65292;&#23427;&#20204;&#37117;&#38656;&#35201;&#20808;&#39564;&#30693;&#35782;&#26469;&#26500;&#24314;&#22240;&#26524;&#20851;&#31995;&#22270;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20108;&#20540;&#19968;&#33324;&#22240;&#26524;&#27169;&#22411;&#21644;BGLMs&#19978;&#19981;&#32771;&#34385;&#22270;&#39592;&#26550;&#30340;&#32452;&#21512;&#22240;&#26524;&#36172;&#21338;&#26426;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#22312;&#19968;&#33324;&#22240;&#26524;&#27169;&#22411;&#19978;&#25552;&#20379;&#20102;&#32047;&#31215;&#36951;&#25022;&#30340;&#25351;&#25968;&#19979;&#38480;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26080;&#38656;&#22270;&#39592;&#26550;&#26469;&#23454;&#29616;BGLMs&#30340;&#36951;&#25022;&#26368;&#23567;&#21270;&#31639;&#27861;&#65292;&#34920;&#26126;&#23427;&#20173;&#28982;&#36798;&#21040;$O(\sqrt{T}\ln T)$&#30340;&#26399;&#26395;&#36951;&#25022;&#12290;&#36825;&#20010;&#28176;&#36827;&#30340;&#36951;&#25022;&#29575;&#19982;&#20381;&#36182;&#20110;&#22270;&#32467;&#26500;&#30340;&#26368;&#20808;&#36827;&#31639;&#27861;&#30456;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;
In combinatorial causal bandits (CCB), the learning agent chooses a subset of variables in each round to intervene and collects feedback from the observed variables to minimize expected regret or sample complexity. Previous works study this problem in both general causal models and binary generalized linear models (BGLMs). However, all of them require prior knowledge of causal graph structure. This paper studies the CCB problem without the graph structure on binary general causal models and BGLMs. We first provide an exponential lower bound of cumulative regrets for the CCB problem on general causal models. To overcome the exponentially large space of parameters, we then consider the CCB problem on BGLMs. We design a regret minimization algorithm for BGLMs even without the graph skeleton and show that it still achieves $O(\sqrt{T}\ln T)$ expected regret. This asymptotic regret is the same as the state-of-art algorithms relying on the graph structure. Moreover, we sacrifice the regret t
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#26680;&#26031;&#22374;&#31163;&#24046;&#65288;KSD&#65289;&#25511;&#21046;&#24615;&#36136;&#65292;&#21457;&#29616;&#26631;&#20934;KSD&#26080;&#27861;&#25511;&#21046;&#30697;&#30340;&#25910;&#25947;&#65292;&#25552;&#20986;&#20102;&#21487;&#25511;&#21046;&#30697;&#21644;&#24369;&#25910;&#25947;&#30340;&#19979;&#28216;&#25193;&#25955;KSD&#65292;&#24182;&#19988;&#21457;&#23637;&#20102;&#21487;&#20197;&#20934;&#30830;&#25551;&#36848;$q$-Wasserstein&#25910;&#25947;&#30340;KSD&#12290;</title><link>http://arxiv.org/abs/2211.05408</link><description>&lt;p&gt;
&#29992;&#26680;&#26031;&#22374;&#31163;&#24046;&#25511;&#21046;&#30697;
&lt;/p&gt;
&lt;p&gt;
Controlling Moments with Kernel Stein Discrepancies. (arXiv:2211.05408v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.05408
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#26680;&#26031;&#22374;&#31163;&#24046;&#65288;KSD&#65289;&#25511;&#21046;&#24615;&#36136;&#65292;&#21457;&#29616;&#26631;&#20934;KSD&#26080;&#27861;&#25511;&#21046;&#30697;&#30340;&#25910;&#25947;&#65292;&#25552;&#20986;&#20102;&#21487;&#25511;&#21046;&#30697;&#21644;&#24369;&#25910;&#25947;&#30340;&#19979;&#28216;&#25193;&#25955;KSD&#65292;&#24182;&#19988;&#21457;&#23637;&#20102;&#21487;&#20197;&#20934;&#30830;&#25551;&#36848;$q$-Wasserstein&#25910;&#25947;&#30340;KSD&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26680;&#26031;&#22374;&#31163;&#24046;&#65288;KSD&#65289;&#29992;&#20110;&#34913;&#37327;&#20998;&#24067;&#36924;&#36817;&#30340;&#36136;&#37327;&#65292;&#24182;&#19988;&#21487;&#20197;&#22312;&#30446;&#26631;&#23494;&#24230;&#20855;&#26377;&#19981;&#21487;&#35745;&#31639;&#30340;&#24402;&#19968;&#21270;&#24120;&#25968;&#26102;&#35745;&#31639;&#12290;&#26174;&#33879;&#30340;&#24212;&#29992;&#21253;&#25324;&#35786;&#26029;&#36817;&#20284;MCMC&#37319;&#26679;&#22120;&#21644;&#38750;&#24402;&#19968;&#21270;&#32479;&#35745;&#27169;&#22411;&#30340;&#36866;&#37197;&#24230;&#26816;&#39564;&#12290;&#26412;&#25991;&#20998;&#26512;&#20102;KSD&#30340;&#25910;&#25947;&#25511;&#21046;&#24615;&#36136;&#12290;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#20102;&#29992;&#20110;&#24369;&#25910;&#25947;&#25511;&#21046;&#30340;&#26631;&#20934;KSD&#26080;&#27861;&#25511;&#21046;&#30697;&#30340;&#25910;&#25947;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#32452;&#20805;&#20998;&#26465;&#20214;&#65292;&#19979;&#28216;&#25193;&#25955;KSD&#21487;&#20197;&#21516;&#26102;&#25511;&#21046;&#30697;&#21644;&#24369;&#25910;&#25947;&#12290;&#20316;&#20026;&#19968;&#20010;&#30452;&#25509;&#30340;&#32467;&#26524;&#65292;&#25105;&#20204;&#21457;&#23637;&#20102;&#23545;&#20110;&#27599;&#20010;$q&gt;0$&#65292;&#31532;&#19968;&#32452;&#24050;&#30693;&#21487;&#20197;&#20934;&#30830;&#25551;&#36848;$q$-Wasserstein&#25910;&#25947;&#30340;KSD&#12290;
&lt;/p&gt;
&lt;p&gt;
Kernel Stein discrepancies (KSDs) measure the quality of a distributional approximation and can be computed even when the target density has an intractable normalizing constant. Notable applications include the diagnosis of approximate MCMC samplers and goodness-of-fit tests for unnormalized statistical models. The present work analyzes the convergence control properties of KSDs. We first show that standard KSDs used for weak convergence control fail to control moment convergence. To address this limitation, we next provide sufficient conditions under which alternative diffusion KSDs control both moment and weak convergence. As an immediate consequence we develop, for each $q &gt; 0$, the first KSDs known to exactly characterize $q$-Wasserstein convergence.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#36125;&#21494;&#26031;&#23618;&#27425;&#22238;&#24402;&#27169;&#22411;&#30340;&#36817;&#20284;&#20132;&#21449;&#39564;&#35777;&#22343;&#20540;&#20272;&#35745;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#26041;&#24046;-&#21327;&#26041;&#24046;&#21442;&#25968;&#19978;&#36827;&#34892;&#26465;&#20214;&#65292;&#23558;&#20132;&#21449;&#39564;&#35777;&#38382;&#39064;&#36716;&#21270;&#20026;&#31616;&#21333;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#22823;&#22411;BHRMs&#30340;&#21487;&#34892;&#24615;&#12290;</title><link>http://arxiv.org/abs/2011.14238</link><description>&lt;p&gt;
Bayesian&#23618;&#27425;&#22238;&#24402;&#27169;&#22411;&#30340;&#36817;&#20284;&#20132;&#21449;&#39564;&#35777;&#22343;&#20540;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Approximate Cross-validated Mean Estimates for Bayesian Hierarchical Regression Models. (arXiv:2011.14238v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2011.14238
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#36125;&#21494;&#26031;&#23618;&#27425;&#22238;&#24402;&#27169;&#22411;&#30340;&#36817;&#20284;&#20132;&#21449;&#39564;&#35777;&#22343;&#20540;&#20272;&#35745;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#26041;&#24046;-&#21327;&#26041;&#24046;&#21442;&#25968;&#19978;&#36827;&#34892;&#26465;&#20214;&#65292;&#23558;&#20132;&#21449;&#39564;&#35777;&#38382;&#39064;&#36716;&#21270;&#20026;&#31616;&#21333;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#22823;&#22411;BHRMs&#30340;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#33719;&#21462;&#36125;&#21494;&#26031;&#23618;&#27425;&#22238;&#24402;&#27169;&#22411;(BHRMs)&#30340;&#20132;&#21449;&#39564;&#35777;&#39044;&#27979;&#20272;&#35745;&#12290;&#36125;&#21494;&#26031;&#23618;&#27425;&#27169;&#22411;&#20197;&#20854;&#33021;&#22815;&#24314;&#27169;&#22797;&#26434;&#30340;&#20381;&#36182;&#32467;&#26500;&#24182;&#25552;&#20379;&#27010;&#29575;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#32780;&#21463;&#21040;&#27426;&#36814;&#65292;&#20294;&#36816;&#34892;&#30340;&#35745;&#31639;&#24320;&#38144;&#24456;&#22823;&#12290;&#22240;&#27492;&#65292;&#20132;&#21449;&#39564;&#35777;(CV)&#19981;&#26159;&#35780;&#20272;BHRMs&#39044;&#27979;&#24615;&#33021;&#30340;&#24120;&#35265;&#23454;&#36341;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36991;&#20813;&#20102;&#20026;&#27599;&#20010;&#20132;&#21449;&#39564;&#35777;&#25240;&#21472;&#37325;&#26032;&#36816;&#34892;&#35745;&#31639;&#24320;&#38144;&#26114;&#36149;&#30340;&#20272;&#35745;&#26041;&#27861;&#30340;&#38656;&#35201;&#65292;&#20351;CV&#22312;&#22823;&#22411;BHRMs&#20013;&#26356;&#21487;&#34892;&#12290;&#36890;&#36807;&#22312;&#26041;&#24046;-&#21327;&#26041;&#24046;&#21442;&#25968;&#19978;&#36827;&#34892;&#26465;&#20214;&#65292;&#23558;CV&#38382;&#39064;&#20174;&#22522;&#20110;&#27010;&#29575;&#30340;&#25277;&#26679;&#36716;&#21270;&#20026;&#31616;&#21333;&#29087;&#24713;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#36825;&#20135;&#29983;&#30340;&#20272;&#35745;&#19982;&#23436;&#25972;&#30340;CV&#31561;&#25928;&#12290;&#25105;&#20204;&#25552;&#20379;&#29702;&#35770;&#32467;&#26524;&#65292;&#24182;&#22312;&#20844;&#24320;&#21487;&#29992;&#30340;&#25968;&#25454;&#21644;&#27169;&#25311;&#20013;&#35777;&#26126;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a novel procedure for obtaining cross-validated predictive estimates for Bayesian hierarchical regression models (BHRMs). Bayesian hierarchical models are popular for their ability to model complex dependence structures and provide probabilistic uncertainty estimates, but can be computationally expensive to run. Cross-validation (CV) is therefore not a common practice to evaluate the predictive performance of BHRMs. Our method circumvents the need to re-run computationally costly estimation methods for each cross-validation fold and makes CV more feasible for large BHRMs. By conditioning on the variance-covariance parameters, we shift the CV problem from probability-based sampling to a simple and familiar optimization problem. In many cases, this produces estimates which are equivalent to full CV. We provide theoretical results and demonstrate its efficacy on publicly available data and in simulations.
&lt;/p&gt;</description></item></channel></rss>