<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#23558;&#26222;&#36890;GANs&#19982;&#27700;&#26031;&#22374;&#36317;&#31163;&#32852;&#31995;&#36215;&#26469;&#65292;&#25193;&#23637;&#29616;&#26377;&#27700;&#26031;&#22374;GANs&#32467;&#26524;&#21040;&#26222;&#36890;GANs&#65292;&#33719;&#24471;&#20102;&#26222;&#36890;GANs&#30340;&#31070;&#35861;&#19981;&#31561;&#24335;&#12290;</title><link>https://arxiv.org/abs/2403.15312</link><description>&lt;p&gt;
&#27700;&#26031;&#22374;&#35270;&#35282;&#19979;&#30340;&#26222;&#36890; GANs
&lt;/p&gt;
&lt;p&gt;
A Wasserstein perspective of Vanilla GANs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15312
&lt;/p&gt;
&lt;p&gt;
&#23558;&#26222;&#36890;GANs&#19982;&#27700;&#26031;&#22374;&#36317;&#31163;&#32852;&#31995;&#36215;&#26469;&#65292;&#25193;&#23637;&#29616;&#26377;&#27700;&#26031;&#22374;GANs&#32467;&#26524;&#21040;&#26222;&#36890;GANs&#65292;&#33719;&#24471;&#20102;&#26222;&#36890;GANs&#30340;&#31070;&#35861;&#19981;&#31561;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;(GANs)&#30340;&#23454;&#35777;&#25104;&#21151;&#24341;&#36215;&#20102;&#23545;&#29702;&#35770;&#30740;&#31350;&#26085;&#30410;&#22686;&#38271;&#30340;&#20852;&#36259;&#12290;&#32479;&#35745;&#25991;&#29486;&#20027;&#35201;&#38598;&#20013;&#22312;&#27700;&#26031;&#22374;GANs&#21450;&#20854;&#25193;&#23637;&#19978;&#65292;&#29305;&#21035;&#26159;&#20801;&#35768;&#20855;&#26377;&#33391;&#22909;&#30340;&#38477;&#32500;&#29305;&#24615;&#12290;&#23545;&#20110;&#26222;&#36890;GANs&#65292;&#21363;&#21407;&#22987;&#20248;&#21270;&#38382;&#39064;&#65292;&#32479;&#35745;&#32467;&#26524;&#20173;&#28982;&#30456;&#24403;&#26377;&#38480;&#65292;&#38656;&#35201;&#20551;&#35774;&#24179;&#28369;&#28608;&#27963;&#20989;&#25968;&#21644;&#28508;&#31354;&#38388;&#19982;&#21608;&#22260;&#31354;&#38388;&#30340;&#32500;&#24230;&#30456;&#31561;&#12290;&#20026;&#20102;&#24357;&#21512;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#23558;&#26222;&#36890;GANs&#19982;&#27700;&#26031;&#22374;&#36317;&#31163;&#32852;&#31995;&#36215;&#26469;&#12290;&#36890;&#36807;&#36825;&#26679;&#20570;&#65292;&#29616;&#26377;&#30340;&#27700;&#26031;&#22374;GANs&#32467;&#26524;&#21487;&#20197;&#25193;&#23637;&#21040;&#26222;&#36890;GANs&#12290;&#29305;&#21035;&#26159;&#65292;&#22312;&#27700;&#26031;&#22374;&#36317;&#31163;&#20013;&#33719;&#24471;&#20102;&#26222;&#36890;GANs&#30340;&#31070;&#35861;&#19981;&#31561;&#24335;&#12290;&#36825;&#20010;&#31070;&#35861;&#19981;&#31561;&#24335;&#30340;&#20551;&#35774;&#26088;&#22312;&#30001;&#23454;&#36341;&#20013;&#24120;&#29992;&#30340;&#32593;&#32476;&#26550;&#26500;&#28385;&#36275;&#65292;&#22914;&#21069;&#39304;ReLU&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15312v1 Announce Type: cross  Abstract: The empirical success of Generative Adversarial Networks (GANs) caused an increasing interest in theoretical research. The statistical literature is mainly focused on Wasserstein GANs and generalizations thereof, which especially allow for good dimension reduction properties. Statistical results for Vanilla GANs, the original optimization problem, are still rather limited and require assumptions such as smooth activation functions and equal dimensions of the latent space and the ambient space. To bridge this gap, we draw a connection from Vanilla GANs to the Wasserstein distance. By doing so, existing results for Wasserstein GANs can be extended to Vanilla GANs. In particular, we obtain an oracle inequality for Vanilla GANs in Wasserstein distance. The assumptions of this oracle inequality are designed to be satisfied by network architectures commonly used in practice, such as feedforward ReLU networks. By providing a quantitative resu
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#26816;&#39564;&#26041;&#27861;&#65292;&#36890;&#36807;&#36873;&#25321;&#24615;&#25512;&#26029;&#26694;&#26550;&#65292;&#22312;&#32771;&#34385;&#29983;&#25104;&#22270;&#20687;&#26159;&#30001;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#20135;&#29983;&#30340;&#26465;&#20214;&#19979;&#65292;&#37327;&#21270;&#21307;&#23398;&#22270;&#20687;&#35786;&#26029;&#32467;&#26524;&#30340;&#21487;&#38752;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.11789</link><description>&lt;p&gt;
&#36890;&#36807;&#25193;&#25955;&#27169;&#22411;&#29983;&#25104;&#30340;&#20551;&#35774;&#30340;&#32479;&#35745;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Statistical Test for Generated Hypotheses by Diffusion Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11789
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#26816;&#39564;&#26041;&#27861;&#65292;&#36890;&#36807;&#36873;&#25321;&#24615;&#25512;&#26029;&#26694;&#26550;&#65292;&#22312;&#32771;&#34385;&#29983;&#25104;&#22270;&#20687;&#26159;&#30001;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#20135;&#29983;&#30340;&#26465;&#20214;&#19979;&#65292;&#37327;&#21270;&#21307;&#23398;&#22270;&#20687;&#35786;&#26029;&#32467;&#26524;&#30340;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
AI&#30340;&#22686;&#24378;&#24615;&#33021;&#21152;&#36895;&#20102;&#20854;&#34701;&#20837;&#31185;&#23398;&#30740;&#31350;&#12290;&#29305;&#21035;&#26159;&#65292;&#21033;&#29992;&#29983;&#25104;&#24335;AI&#21019;&#24314;&#31185;&#23398;&#20551;&#35774;&#26159;&#24456;&#26377;&#21069;&#36884;&#30340;&#65292;&#24182;&#19988;&#27491;&#22312;&#36234;&#26469;&#36234;&#22810;&#22320;&#24212;&#29992;&#20110;&#21508;&#20010;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#24403;&#20351;&#29992;AI&#29983;&#25104;&#30340;&#20551;&#35774;&#36827;&#34892;&#20851;&#38190;&#20915;&#31574;&#65288;&#22914;&#21307;&#23398;&#35786;&#26029;&#65289;&#26102;&#65292;&#39564;&#35777;&#23427;&#20204;&#30340;&#21487;&#38752;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#29983;&#25104;&#30340;&#22270;&#20687;&#36827;&#34892;&#21307;&#23398;&#35786;&#26029;&#20219;&#21153;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#26816;&#39564;&#26469;&#37327;&#21270;&#20854;&#21487;&#38752;&#24615;&#12290;&#25152;&#25552;&#20986;&#30340;&#32479;&#35745;&#26816;&#39564;&#30340;&#22522;&#26412;&#24605;&#24819;&#26159;&#20351;&#29992;&#36873;&#25321;&#24615;&#25512;&#26029;&#26694;&#26550;&#65292;&#25105;&#20204;&#32771;&#34385;&#22312;&#29983;&#25104;&#30340;&#22270;&#20687;&#26159;&#30001;&#32463;&#36807;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#20135;&#29983;&#30340;&#36825;&#19968;&#20107;&#23454;&#26465;&#20214;&#19979;&#30340;&#32479;&#35745;&#26816;&#39564;&#12290;&#21033;&#29992;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#21307;&#23398;&#22270;&#20687;&#35786;&#26029;&#32467;&#26524;&#30340;&#32479;&#35745;&#21487;&#38752;&#24615;&#21487;&#20197;&#20197;p&#20540;&#30340;&#24418;&#24335;&#37327;&#21270;&#65292;&#20174;&#32780;&#23454;&#29616;&#22312;&#25511;&#21046;&#38169;&#35823;&#29575;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11789v1 Announce Type: cross  Abstract: The enhanced performance of AI has accelerated its integration into scientific research. In particular, the use of generative AI to create scientific hypotheses is promising and is increasingly being applied across various fields. However, when employing AI-generated hypotheses for critical decisions, such as medical diagnoses, verifying their reliability is crucial. In this study, we consider a medical diagnostic task using generated images by diffusion models, and propose a statistical test to quantify its reliability. The basic idea behind the proposed statistical test is to employ a selective inference framework, where we consider a statistical test conditional on the fact that the generated images are produced by a trained diffusion model. Using the proposed method, the statistical reliability of medical image diagnostic results can be quantified in the form of a p-value, allowing for decision-making with a controlled error rate. 
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#30740;&#31350;&#20102;&#36890;&#36807;&#36866;&#24212;&#24615;&#31574;&#30053;&#36873;&#25321;&#26368;&#22823;&#21270;&#31038;&#20250;&#31119;&#21033;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#20851;&#20110;&#36951;&#25022;&#30340;&#19979;&#30028;&#21644;&#31639;&#27861;&#30340;&#21305;&#37197;&#19978;&#30028;&#12290;&#30740;&#31350;&#21457;&#29616;&#31119;&#21033;&#26368;&#22823;&#21270;&#27604;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#26356;&#22256;&#38590;&#65292;&#20294;&#35813;&#31639;&#27861;&#36798;&#21040;&#20102;&#26368;&#20248;&#22686;&#38271;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.09597</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#26368;&#22823;&#21270;&#31038;&#20250;&#31119;&#21033;
&lt;/p&gt;
&lt;p&gt;
Adaptive maximization of social welfare. (arXiv:2310.09597v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09597
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#30740;&#31350;&#20102;&#36890;&#36807;&#36866;&#24212;&#24615;&#31574;&#30053;&#36873;&#25321;&#26368;&#22823;&#21270;&#31038;&#20250;&#31119;&#21033;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#20851;&#20110;&#36951;&#25022;&#30340;&#19979;&#30028;&#21644;&#31639;&#27861;&#30340;&#21305;&#37197;&#19978;&#30028;&#12290;&#30740;&#31350;&#21457;&#29616;&#31119;&#21033;&#26368;&#22823;&#21270;&#27604;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#26356;&#22256;&#38590;&#65292;&#20294;&#35813;&#31639;&#27861;&#36798;&#21040;&#20102;&#26368;&#20248;&#22686;&#38271;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#37325;&#22797;&#36873;&#25321;&#25919;&#31574;&#20197;&#26368;&#22823;&#21270;&#31038;&#20250;&#31119;&#21033;&#30340;&#38382;&#39064;&#12290;&#31119;&#21033;&#26159;&#20010;&#20154;&#25928;&#29992;&#21644;&#20844;&#20849;&#25910;&#20837;&#30340;&#21152;&#26435;&#21644;&#12290;&#26089;&#26399;&#30340;&#32467;&#26524;&#24433;&#21709;&#21518;&#32493;&#30340;&#25919;&#31574;&#36873;&#25321;&#12290;&#25928;&#29992;&#19981;&#21487;&#35266;&#27979;&#65292;&#20294;&#21487;&#20197;&#38388;&#25509;&#25512;&#26029;&#12290;&#21709;&#24212;&#20989;&#25968;&#36890;&#36807;&#23454;&#39564;&#23398;&#20064;&#33719;&#24471;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#20851;&#20110;&#36951;&#25022;&#30340;&#19979;&#30028;&#65292;&#24182;&#19988;&#23545;&#20110;&#19968;&#31181;Exp3&#31639;&#27861;&#30340;&#21305;&#37197;&#23545;&#31574;&#23545;&#31435;&#19978;&#30028;&#12290;&#32047;&#31215;&#36951;&#25022;&#20197;$T^{2/3}$&#30340;&#36895;&#29575;&#22686;&#38271;&#12290;&#36825;&#24847;&#21619;&#30528;(i)&#31119;&#21033;&#26368;&#22823;&#21270;&#27604;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#26356;&#22256;&#38590;&#65288;&#23545;&#20110;&#26377;&#38480;&#30340;&#25919;&#31574;&#38598;&#26469;&#35828;&#65292;&#22686;&#38271;&#36895;&#29575;&#20026;$T^{1/2}$&#65289;&#65292;&#21644;(ii)&#25105;&#20204;&#30340;&#31639;&#27861;&#23454;&#29616;&#20102;&#26368;&#20248;&#22686;&#38271;&#36895;&#29575;&#12290;&#23545;&#20110;&#38543;&#26426;&#35774;&#32622;&#65292;&#22914;&#26524;&#31038;&#20250;&#31119;&#21033;&#26159;&#20985;&#30340;&#65292;&#25105;&#20204;&#21487;&#20197;&#20351;&#29992;&#20108;&#20998;&#25628;&#32034;&#31639;&#27861;&#22312;&#36830;&#32493;&#25919;&#31574;&#38598;&#19978;&#23454;&#29616;$T^{1/2}$&#30340;&#36895;&#29575;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#38750;&#32447;&#24615;&#25910;&#20837;&#31246;&#25193;&#23637;&#65292;&#24182;&#27010;&#36848;&#20102;&#21830;&#21697;&#31246;&#25193;&#23637;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#35774;&#32622;&#19982;&#22404;&#26029;&#23450;&#20215;&#65288;&#26356;&#23481;&#26131;&#65289;&#21644;&#21452;&#36793;&#20132;&#26131;&#30340;&#23450;&#20215;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of repeatedly choosing policies to maximize social welfare. Welfare is a weighted sum of private utility and public revenue. Earlier outcomes inform later policies. Utility is not observed, but indirectly inferred. Response functions are learned through experimentation.  We derive a lower bound on regret, and a matching adversarial upper bound for a variant of the Exp3 algorithm. Cumulative regret grows at a rate of $T^{2/3}$. This implies that (i) welfare maximization is harder than the multi-armed bandit problem (with a rate of $T^{1/2}$ for finite policy sets), and (ii) our algorithm achieves the optimal rate. For the stochastic setting, if social welfare is concave, we can achieve a rate of $T^{1/2}$ (for continuous policy sets), using a dyadic search algorithm.  We analyze an extension to nonlinear income taxation, and sketch an extension to commodity taxation. We compare our setting to monopoly pricing (which is easier), and price setting for bilateral tra
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20174;&#22810;&#20219;&#21153;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#20013;&#24674;&#22797;&#32447;&#24615;&#25805;&#20316;&#31526;&#30340;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#29616;&#26377;&#30340;&#21508;&#21521;&#21516;&#24615;&#26080;&#20851;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;&#20250;&#23545;&#34920;&#31034;&#26356;&#26032;&#36896;&#25104;&#20559;&#24046;&#65292;&#38480;&#21046;&#20102;&#34920;&#31034;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;&#20026;&#27492;&#65292;&#24341;&#20837;&#20102;&#21435;&#20559;&#24046;&#21644;&#29305;&#24449;&#30333;&#21270;&#30340;&#36866;&#24212;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2308.04428</link><description>&lt;p&gt;
&#20174;&#22810;&#20219;&#21153;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#20013;&#20803;&#23398;&#20064;&#25805;&#20316;&#31526;&#21040;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
Meta-Learning Operators to Optimality from Multi-Task Non-IID Data. (arXiv:2308.04428v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04428
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20174;&#22810;&#20219;&#21153;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#20013;&#24674;&#22797;&#32447;&#24615;&#25805;&#20316;&#31526;&#30340;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#29616;&#26377;&#30340;&#21508;&#21521;&#21516;&#24615;&#26080;&#20851;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;&#20250;&#23545;&#34920;&#31034;&#26356;&#26032;&#36896;&#25104;&#20559;&#24046;&#65292;&#38480;&#21046;&#20102;&#34920;&#31034;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;&#20026;&#27492;&#65292;&#24341;&#20837;&#20102;&#21435;&#20559;&#24046;&#21644;&#29305;&#24449;&#30333;&#21270;&#30340;&#36866;&#24212;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#36817;&#21462;&#24471;&#36827;&#23637;&#30340;&#19968;&#20010;&#24378;&#22823;&#27010;&#24565;&#26159;&#20174;&#24322;&#26500;&#26469;&#28304;&#25110;&#20219;&#21153;&#30340;&#25968;&#25454;&#20013;&#25552;&#21462;&#20849;&#21516;&#29305;&#24449;&#12290;&#30452;&#35266;&#22320;&#35828;&#65292;&#23558;&#25152;&#26377;&#25968;&#25454;&#29992;&#20110;&#23398;&#20064;&#20849;&#21516;&#30340;&#34920;&#31034;&#20989;&#25968;&#65292;&#26082;&#26377;&#21161;&#20110;&#35745;&#31639;&#25928;&#29575;&#65292;&#21448;&#26377;&#21161;&#20110;&#32479;&#35745;&#27867;&#21270;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#20943;&#23569;&#35201;&#22312;&#32473;&#23450;&#20219;&#21153;&#19978;&#36827;&#34892;&#24494;&#35843;&#30340;&#21442;&#25968;&#25968;&#37327;&#12290;&#20026;&#20102;&#22312;&#29702;&#35770;&#19978;&#20570;&#20986;&#36825;&#20123;&#20248;&#28857;&#30340;&#26681;&#28304;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20174;&#22122;&#22768;&#21521;&#37327;&#27979;&#37327;$y = Mx + w$&#20013;&#22238;&#22797;&#32447;&#24615;&#25805;&#20316;&#31526;$M$&#30340;&#19968;&#33324;&#27169;&#22411;&#12290;&#20854;&#20013;&#65292;&#21327;&#21464;&#37327;$x$&#26082;&#21487;&#20197;&#26159;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#65292;&#20063;&#21487;&#20197;&#26159;&#38750;&#21508;&#21521;&#21516;&#24615;&#30340;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#29616;&#26377;&#30340;&#21508;&#21521;&#21516;&#24615;&#26080;&#20851;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;&#20250;&#23545;&#34920;&#31034;&#26356;&#26032;&#36896;&#25104;&#20559;&#24046;&#65292;&#36825;&#23548;&#33268;&#22122;&#22768;&#39033;&#30340;&#32553;&#25918;&#19981;&#20877;&#26377;&#21033;&#20110;&#28304;&#20219;&#21153;&#25968;&#37327;&#12290;&#36825;&#21453;&#36807;&#26469;&#20250;&#23548;&#33268;&#34920;&#31034;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#21463;&#21040;&#21333;&#20219;&#21153;&#25968;&#25454;&#35268;&#27169;&#30340;&#38480;&#21046;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#31216;&#20026;&#21435;&#20559;&#24046;&#21644;&#29305;&#24449;&#30333;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
A powerful concept behind much of the recent progress in machine learning is the extraction of common features across data from heterogeneous sources or tasks. Intuitively, using all of one's data to learn a common representation function benefits both computational effort and statistical generalization by leaving a smaller number of parameters to fine-tune on a given task. Toward theoretically grounding these merits, we propose a general setting of recovering linear operators $M$ from noisy vector measurements $y = Mx + w$, where the covariates $x$ may be both non-i.i.d. and non-isotropic. We demonstrate that existing isotropy-agnostic meta-learning approaches incur biases on the representation update, which causes the scaling of the noise terms to lose favorable dependence on the number of source tasks. This in turn can cause the sample complexity of representation learning to be bottlenecked by the single-task data size. We introduce an adaptation, $\texttt{De-bias &amp; Feature-Whiten}
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#30340;&#30446;&#26631;&#26159;&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#35782;&#21035;&#30446;&#26631;&#21464;&#37327;&#30340;&#30452;&#25509;&#21407;&#22240;&#65292;&#36890;&#36807;&#19981;&#23545;&#20854;&#20182;&#21464;&#37327;&#20570;&#22826;&#22810;&#20551;&#35774;&#65292;&#30740;&#31350;&#32773;&#25552;&#20986;&#20102;&#21487;&#35782;&#21035;&#24615;&#32467;&#26524;&#21644;&#20004;&#31181;&#23454;&#29992;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.16048</link><description>&lt;p&gt;
&#23616;&#37096;&#22240;&#26524;&#21457;&#29616;&#20013;&#30340;&#32467;&#26500;&#38480;&#21046;: &#35782;&#21035;&#30446;&#26631;&#21464;&#37327;&#30340;&#30452;&#25509;&#21407;&#22240;
&lt;/p&gt;
&lt;p&gt;
Structural restrictions in local causal discovery: identifying direct causes of a target variable. (arXiv:2307.16048v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16048
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#30340;&#30446;&#26631;&#26159;&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#35782;&#21035;&#30446;&#26631;&#21464;&#37327;&#30340;&#30452;&#25509;&#21407;&#22240;&#65292;&#36890;&#36807;&#19981;&#23545;&#20854;&#20182;&#21464;&#37327;&#20570;&#22826;&#22810;&#20551;&#35774;&#65292;&#30740;&#31350;&#32773;&#25552;&#20986;&#20102;&#21487;&#35782;&#21035;&#24615;&#32467;&#26524;&#21644;&#20004;&#31181;&#23454;&#29992;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20174;&#35266;&#23519;&#32852;&#21512;&#20998;&#24067;&#20013;&#23398;&#20064;&#30446;&#26631;&#21464;&#37327;&#30340;&#19968;&#32452;&#30452;&#25509;&#21407;&#22240;&#30340;&#38382;&#39064;&#12290;&#23398;&#20064;&#34920;&#31034;&#22240;&#26524;&#32467;&#26500;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;(DAG)&#26159;&#31185;&#23398;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#12290;&#24403;&#23436;&#25972;&#30340;DAG&#20174;&#20998;&#24067;&#20013;&#21487;&#35782;&#21035;&#26102;&#65292;&#24050;&#30693;&#26377;&#19968;&#20123;&#32467;&#26524;&#65292;&#20363;&#22914;&#20551;&#35774;&#38750;&#32447;&#24615;&#39640;&#26031;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#12290;&#36890;&#24120;&#65292;&#25105;&#20204;&#21482;&#23545;&#35782;&#21035;&#19968;&#20010;&#30446;&#26631;&#21464;&#37327;&#30340;&#30452;&#25509;&#21407;&#22240;&#65288;&#23616;&#37096;&#22240;&#26524;&#32467;&#26500;&#65289;&#65292;&#32780;&#19981;&#26159;&#23436;&#25972;&#30340;DAG&#24863;&#20852;&#36259;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#23545;&#30446;&#26631;&#21464;&#37327;&#30340;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#30340;&#19981;&#21516;&#20551;&#35774;&#65292;&#35813;&#20551;&#35774;&#19979;&#30452;&#25509;&#21407;&#22240;&#38598;&#21512;&#21487;&#20197;&#20174;&#20998;&#24067;&#20013;&#35782;&#21035;&#20986;&#26469;&#12290;&#22312;&#36825;&#26679;&#20570;&#30340;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#23545;&#38500;&#30446;&#26631;&#21464;&#37327;&#20043;&#22806;&#30340;&#21464;&#37327;&#22522;&#26412;&#19978;&#27809;&#26377;&#20219;&#20309;&#20551;&#35774;&#12290;&#38500;&#20102;&#26032;&#30340;&#21487;&#35782;&#21035;&#24615;&#32467;&#26524;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#20004;&#31181;&#20174;&#26377;&#38480;&#38543;&#26426;&#26679;&#26412;&#20272;&#35745;&#30452;&#25509;&#21407;&#22240;&#30340;&#23454;&#29992;&#31639;&#27861;&#65292;&#24182;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of learning a set of direct causes of a target variable from an observational joint distribution. Learning directed acyclic graphs (DAGs) that represent the causal structure is a fundamental problem in science. Several results are known when the full DAG is identifiable from the distribution, such as assuming a nonlinear Gaussian data-generating process. Often, we are only interested in identifying the direct causes of one target variable (local causal structure), not the full DAG. In this paper, we discuss different assumptions for the data-generating process of the target variable under which the set of direct causes is identifiable from the distribution. While doing so, we put essentially no assumptions on the variables other than the target variable. In addition to the novel identifiability results, we provide two practical algorithms for estimating the direct causes from a finite random sample and demonstrate their effectiveness on several benchmark dataset
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;Lasso&#22238;&#24402;&#23545;&#20110;&#31614;&#21517;&#21464;&#25442;&#30340;&#19968;&#33268;&#24615;&#38382;&#39064;&#65292;&#24182;&#21457;&#29616;&#23545;&#20110;&#19981;&#21516;&#30340;&#36807;&#31243;&#21644;&#26102;&#38388;&#24207;&#21015;&#65292;&#36873;&#25321;&#36866;&#24403;&#30340;&#31614;&#21517;&#23450;&#20041;&#21644;&#38543;&#26426;&#27169;&#22411;&#21487;&#20197;&#25552;&#39640;Lasso&#22238;&#24402;&#30340;&#19968;&#33268;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.10413</link><description>&lt;p&gt;
&#20351;&#29992;Lasso&#30340;&#31614;&#21517;&#19968;&#33268;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Consistency of Signatures Using Lasso. (arXiv:2305.10413v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10413
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;Lasso&#22238;&#24402;&#23545;&#20110;&#31614;&#21517;&#21464;&#25442;&#30340;&#19968;&#33268;&#24615;&#38382;&#39064;&#65292;&#24182;&#21457;&#29616;&#23545;&#20110;&#19981;&#21516;&#30340;&#36807;&#31243;&#21644;&#26102;&#38388;&#24207;&#21015;&#65292;&#36873;&#25321;&#36866;&#24403;&#30340;&#31614;&#21517;&#23450;&#20041;&#21644;&#38543;&#26426;&#27169;&#22411;&#21487;&#20197;&#25552;&#39640;Lasso&#22238;&#24402;&#30340;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31614;&#21517;&#21464;&#25442;&#26159;&#36830;&#32493;&#21644;&#31163;&#25955;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#36845;&#20195;&#36335;&#24452;&#31215;&#20998;&#65292;&#23427;&#20204;&#30340;&#26222;&#36941;&#38750;&#32447;&#24615;&#36890;&#36807;&#32447;&#24615;&#21270;&#29305;&#24449;&#36873;&#25321;&#38382;&#39064;&#12290;&#26412;&#25991;&#22312;&#29702;&#35770;&#21644;&#25968;&#20540;&#19978;&#37325;&#26032;&#23457;&#35270;&#20102;Lasso&#22238;&#24402;&#23545;&#20110;&#31614;&#21517;&#21464;&#25442;&#30340;&#19968;&#33268;&#24615;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#23545;&#20110;&#26356;&#25509;&#36817;&#24067;&#26391;&#36816;&#21160;&#25110;&#20855;&#26377;&#36739;&#24369;&#36328;&#32500;&#24230;&#30456;&#20851;&#24615;&#30340;&#36807;&#31243;&#21644;&#26102;&#38388;&#24207;&#21015;&#65292;&#31614;&#21517;&#23450;&#20041;&#20026;It\^o&#31215;&#20998;&#30340;Lasso&#22238;&#24402;&#26356;&#20855;&#19968;&#33268;&#24615;&#65307;&#23545;&#20110;&#22343;&#20540;&#22238;&#24402;&#36807;&#31243;&#21644;&#26102;&#38388;&#24207;&#21015;&#65292;&#20854;&#31614;&#21517;&#23450;&#20041;&#20026;Stratonovich&#31215;&#20998;&#22312;Lasso&#22238;&#24402;&#20013;&#20855;&#26377;&#26356;&#39640;&#30340;&#19968;&#33268;&#24615;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#24378;&#35843;&#20102;&#22312;&#32479;&#35745;&#25512;&#26029;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#36873;&#25321;&#36866;&#24403;&#30340;&#31614;&#21517;&#21644;&#38543;&#26426;&#27169;&#22411;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Signature transforms are iterated path integrals of continuous and discrete-time time series data, and their universal nonlinearity linearizes the problem of feature selection. This paper revisits the consistency issue of Lasso regression for the signature transform, both theoretically and numerically. Our study shows that, for processes and time series that are closer to Brownian motion or random walk with weaker inter-dimensional correlations, the Lasso regression is more consistent for their signatures defined by It\^o integrals; for mean reverting processes and time series, their signatures defined by Stratonovich integrals have more consistency in the Lasso regression. Our findings highlight the importance of choosing appropriate definitions of signatures and stochastic models in statistical inference and machine learning.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#21452;&#25351;&#25968;&#26063;&#30340;&#25193;&#23637;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#20013;&#30340;dropout&#27491;&#21017;&#21270;&#65292;dropout&#27491;&#21017;&#21270;&#20559;&#22909;&#32597;&#35265;&#20294;&#37325;&#35201;&#30340;&#29305;&#24449;&#65292;&#22312;&#22343;&#20540;&#21644;&#31163;&#25955;&#24230;&#26041;&#38754;&#37117;&#20855;&#26377;&#26222;&#36866;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.06625</link><description>&lt;p&gt;
&#22522;&#20110;&#21452;&#25351;&#25968;&#26063;&#30340;&#25193;&#23637;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#20013;&#30340;Dropout&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Dropout Regularization in Extended Generalized Linear Models based on Double Exponential Families. (arXiv:2305.06625v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06625
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#21452;&#25351;&#25968;&#26063;&#30340;&#25193;&#23637;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#20013;&#30340;dropout&#27491;&#21017;&#21270;&#65292;dropout&#27491;&#21017;&#21270;&#20559;&#22909;&#32597;&#35265;&#20294;&#37325;&#35201;&#30340;&#29305;&#24449;&#65292;&#22312;&#22343;&#20540;&#21644;&#31163;&#25955;&#24230;&#26041;&#38754;&#37117;&#20855;&#26377;&#26222;&#36866;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;dropout&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#20294;&#20854;&#29702;&#35770;&#24615;&#36136;&#23578;&#26410;&#34987;&#20805;&#20998;&#29702;&#35299;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#21452;&#25351;&#25968;&#26063;&#30340;&#25193;&#23637;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#20013;&#30340;dropout&#27491;&#21017;&#21270;&#65292;&#20854;&#20013;&#31163;&#25955;&#21442;&#25968;&#21487;&#20197;&#38543;&#29305;&#24449;&#21464;&#21270;&#12290;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;dropout&#27491;&#21017;&#21270;&#20559;&#22909;&#32597;&#35265;&#20294;&#37325;&#35201;&#30340;&#29305;&#24449;&#65292;&#22312;&#22343;&#20540;&#21644;&#31163;&#25955;&#24230;&#26041;&#38754;&#37117;&#20855;&#26377;&#26222;&#36866;&#24615;&#65292;&#36825;&#25193;&#23637;&#20102;&#20043;&#21069;&#38024;&#23545;&#20256;&#32479;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#32467;&#26524; &#12290;&#37319;&#29992;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#36827;&#34892;&#35757;&#32451;&#12290;&#20026;&#20102;&#35828;&#26126;&#36825;&#19968;&#28857;&#65292;&#25105;&#20204;&#23558;dropout&#24212;&#29992;&#20110;&#33258;&#36866;&#24212;B&#26679;&#26465;&#24179;&#28369;&#65292;&#20854;&#20013;&#22343;&#20540;&#21644;&#31163;&#25955;&#24230;&#21442;&#25968;&#37117;&#34987;&#28789;&#27963;&#22320;&#24314;&#27169;&#12290;&#37325;&#35201;&#30340;B&#26679;&#26465;&#22522;&#30784;&#20989;&#25968;&#21487;&#20197;&#34987;&#35748;&#20026;&#26159;&#32597;&#35265;&#30340;&#29305;&#24449;&#65292;&#25105;&#20204;&#22312;&#23454;&#39564;&#20013;&#35777;&#23454;&#65292;dropout&#26159;&#19968;&#31181;&#25913;&#21892;&#20102;&#32602;&#26368;&#22823;&#20284;&#28982;&#26041;&#27861;&#30340;&#26174;&#24335;&#24179;&#28369;&#24615;&#30340;&#22343;&#20540;&#21644;&#31163;&#25955;&#24230;&#21442;&#25968;&#30340;&#26377;&#25928;&#27491;&#21017;&#21270;&#24418;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Even though dropout is a popular regularization technique, its theoretical properties are not fully understood. In this paper we study dropout regularization in extended generalized linear models based on double exponential families, for which the dispersion parameter can vary with the features. A theoretical analysis shows that dropout regularization prefers rare but important features in both the mean and dispersion, generalizing an earlier result for conventional generalized linear models. Training is performed using stochastic gradient descent with adaptive learning rate. To illustrate, we apply dropout to adaptive smoothing with B-splines, where both the mean and dispersion parameters are modelled flexibly. The important B-spline basis functions can be thought of as rare features, and we confirm in experiments that dropout is an effective form of regularization for mean and dispersion parameters that improves on a penalized maximum likelihood approach with an explicit smoothness p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#20351;&#29992;&#25968;&#25454;&#30340;&#37327;&#23376;&#36153;&#33293;&#23572;&#20449;&#24687;&#24230;&#37327;&#26469;&#35780;&#20272;&#25104;&#21151;&#35757;&#32451;&#21644;&#27867;&#21270;&#25152;&#38656;&#30340;&#30005;&#36335;&#21442;&#25968;&#21644;&#35757;&#32451;&#25968;&#25454;&#30340;&#25968;&#37327;&#65292;&#24182;&#23637;&#31034;&#36890;&#36807;&#21435;&#38500;&#23545;&#31216;&#24615;&#26469;&#25552;&#39640;&#27867;&#21270;&#33021;&#21147;&#65292;&#21516;&#26102;&#21457;&#29616;&#36229;&#20986;&#20998;&#24067;&#27867;&#21270;&#33021;&#21147;&#21487;&#20197;&#27604;&#20351;&#29992;&#30456;&#21516;&#20998;&#24067;&#26356;&#20248;&#12290;</title><link>http://arxiv.org/abs/2303.13462</link><description>&lt;p&gt;
&#21033;&#29992;&#37327;&#23376;&#20960;&#20309;&#36827;&#34892;&#23398;&#20064;&#24186;&#27491;&#21464;&#25442;&#30340;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Generalization with quantum geometry for learning unitaries. (arXiv:2303.13462v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.13462
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#20351;&#29992;&#25968;&#25454;&#30340;&#37327;&#23376;&#36153;&#33293;&#23572;&#20449;&#24687;&#24230;&#37327;&#26469;&#35780;&#20272;&#25104;&#21151;&#35757;&#32451;&#21644;&#27867;&#21270;&#25152;&#38656;&#30340;&#30005;&#36335;&#21442;&#25968;&#21644;&#35757;&#32451;&#25968;&#25454;&#30340;&#25968;&#37327;&#65292;&#24182;&#23637;&#31034;&#36890;&#36807;&#21435;&#38500;&#23545;&#31216;&#24615;&#26469;&#25552;&#39640;&#27867;&#21270;&#33021;&#21147;&#65292;&#21516;&#26102;&#21457;&#29616;&#36229;&#20986;&#20998;&#24067;&#27867;&#21270;&#33021;&#21147;&#21487;&#20197;&#27604;&#20351;&#29992;&#30456;&#21516;&#20998;&#24067;&#26356;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27867;&#21270;&#26159;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20174;&#35757;&#32451;&#25968;&#25454;&#23398;&#20064;&#20934;&#30830;&#39044;&#27979;&#26032;&#25968;&#25454;&#30340;&#33021;&#21147;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#24341;&#20837;&#25968;&#25454;&#30340;&#37327;&#23376;&#36153;&#33293;&#23572;&#20449;&#24687;&#24230;&#37327;(DQFIM)&#26469;&#30830;&#23450;&#27169;&#22411;&#20309;&#26102;&#33021;&#22815;&#27867;&#21270;&#12290;&#23545;&#20110;&#24186;&#27491;&#21464;&#25442;&#30340;&#21487;&#21464;&#23398;&#20064;&#65292;DQFIM&#37327;&#21270;&#20102;&#25104;&#21151;&#35757;&#32451;&#21644;&#27867;&#21270;&#25152;&#38656;&#30340;&#30005;&#36335;&#21442;&#25968;&#21644;&#35757;&#32451;&#25968;&#25454;&#30340;&#25968;&#37327;&#12290;&#25105;&#20204;&#24212;&#29992;DQFIM&#26469;&#35299;&#37322;&#20309;&#26102;&#24658;&#23450;&#25968;&#37327;&#30340;&#35757;&#32451;&#29366;&#24577;&#21644;&#22810;&#39033;&#24335;&#25968;&#37327;&#30340;&#21442;&#25968;&#36275;&#20197;&#23454;&#29616;&#27867;&#21270;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#20174;&#35757;&#32451;&#25968;&#25454;&#20013;&#21024;&#38500;&#23545;&#31216;&#24615;&#65292;&#21487;&#20197;&#25552;&#39640;&#27867;&#21270;&#33021;&#21147;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#26174;&#31034;&#65292;&#20351;&#29992;&#19981;&#21516;&#25968;&#25454;&#20998;&#24067;&#36827;&#34892;&#35757;&#32451;&#21644;&#27979;&#35797;&#30340;&#36229;&#20986;&#20998;&#24067;&#27867;&#21270;&#33021;&#21147;&#21487;&#20197;&#27604;&#20351;&#29992;&#30456;&#21516;&#20998;&#24067;&#30340;&#33021;&#21147;&#26356;&#20248;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#20026;&#25552;&#39640;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#27867;&#21270;&#33021;&#21147;&#24320;&#36767;&#20102;&#26032;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generalization is the ability of quantum machine learning models to make accurate predictions on new data by learning from training data. Here, we introduce the data quantum Fisher information metric (DQFIM) to determine when a model can generalize. For variational learning of unitaries, the DQFIM quantifies the amount of circuit parameters and training data needed to successfully train and generalize. We apply the DQFIM to explain when a constant number of training states and polynomial number of parameters are sufficient for generalization. Further, we can improve generalization by removing symmetries from training data. Finally, we show that out-of-distribution generalization, where training and testing data are drawn from different data distributions, can be better than using the same distribution. Our work opens up new approaches to improve generalization in quantum machine learning.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22810;&#20219;&#21153;&#23398;&#20064;&#20197;&#21450;Bandits&#26041;&#27861;&#30340;&#20581;&#22766;&#32479;&#35745;&#23398;&#23454;&#29616;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20004;&#38454;&#27573;&#22810;&#20219;&#21153;&#23398;&#20064;&#20272;&#35745;&#22120;&#65292;&#35813;&#20272;&#35745;&#22120;&#20197;&#19968;&#31181;&#26679;&#26412;&#39640;&#25928;&#30340;&#26041;&#24335;&#21033;&#29992;&#20849;&#20139;&#20840;&#23616;&#21442;&#25968;&#21644;&#31232;&#30095;&#23454;&#20363;&#29305;&#23450;&#26415;&#35821;&#30340;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2112.14233</link><description>&lt;p&gt;
&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;Bandits&#36890;&#36807;&#20581;&#22766;&#32479;&#35745;&#23398;
&lt;/p&gt;
&lt;p&gt;
Multitask Learning and Bandits via Robust Statistics. (arXiv:2112.14233v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.14233
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22810;&#20219;&#21153;&#23398;&#20064;&#20197;&#21450;Bandits&#26041;&#27861;&#30340;&#20581;&#22766;&#32479;&#35745;&#23398;&#23454;&#29616;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20004;&#38454;&#27573;&#22810;&#20219;&#21153;&#23398;&#20064;&#20272;&#35745;&#22120;&#65292;&#35813;&#20272;&#35745;&#22120;&#20197;&#19968;&#31181;&#26679;&#26412;&#39640;&#25928;&#30340;&#26041;&#24335;&#21033;&#29992;&#20849;&#20139;&#20840;&#23616;&#21442;&#25968;&#21644;&#31232;&#30095;&#23454;&#20363;&#29305;&#23450;&#26415;&#35821;&#30340;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20915;&#31574;&#32773;&#32463;&#24120;&#21516;&#26102;&#38754;&#23545;&#35768;&#22810;&#30456;&#20851;&#20294;&#24322;&#36136;&#30340;&#23398;&#20064;&#38382;&#39064;&#12290;&#22312;&#27492;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#33258;&#28982;&#30340;&#35774;&#32622;&#65292;&#20854;&#20013;&#27599;&#20010;&#23398;&#20064;&#23454;&#20363;&#20013;&#30340;&#26410;&#30693;&#21442;&#25968;&#21487;&#20197;&#20998;&#35299;&#20026;&#20849;&#20139;&#20840;&#23616;&#21442;&#25968;&#21152;&#19978;&#31232;&#30095;&#30340;&#23454;&#20363;&#29305;&#23450;&#26415;&#35821;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20004;&#38454;&#27573;&#22810;&#20219;&#21153;&#23398;&#20064;&#20272;&#35745;&#22120;&#65292;&#20197;&#19968;&#31181;&#26679;&#26412;&#39640;&#25928;&#30340;&#26041;&#24335;&#21033;&#29992;&#36825;&#31181;&#32467;&#26500;&#65292;&#20351;&#29992;&#20581;&#22766;&#32479;&#35745;&#23398;&#65288;&#22312;&#30456;&#20284;&#23454;&#20363;&#19978;&#23398;&#20064;&#65289;&#21644;LASSO&#22238;&#24402;&#65288;&#21435;&#20559;&#24046;&#32467;&#26524;&#65289;&#30340;&#29420;&#29305;&#32452;&#21512;&#12290;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#25552;&#20379;&#20102;&#25913;&#36827;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
Decision-makers often simultaneously face many related but heterogeneous learning problems. For instance, a large retailer may wish to learn product demand at different stores to solve pricing or inventory problems, making it desirable to learn jointly for stores serving similar customers; alternatively, a hospital network may wish to learn patient risk at different providers to allocate personalized interventions, making it desirable to learn jointly for hospitals serving similar patient populations. Motivated by real datasets, we study a natural setting where the unknown parameter in each learning instance can be decomposed into a shared global parameter plus a sparse instance-specific term. We propose a novel two-stage multitask learning estimator that exploits this structure in a sample-efficient way, using a unique combination of robust statistics (to learn across similar instances) and LASSO regression (to debias the results). Our estimator yields improved sample complexity bound
&lt;/p&gt;</description></item></channel></rss>