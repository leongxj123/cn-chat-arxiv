<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#39640;&#32500;&#22238;&#24402;&#30340;&#33258;&#36866;&#24212;&#36801;&#31227;&#23398;&#20064;&#26041;&#27861;&#65292;&#21487;&#20197;&#26681;&#25454;&#21487;&#36801;&#31227;&#32467;&#26500;&#33258;&#36866;&#24212;&#26816;&#27979;&#21644;&#32858;&#21512;&#29305;&#24449;&#21644;&#26679;&#26412;&#30340;&#21487;&#36801;&#31227;&#32467;&#26500;&#12290;</title><link>https://arxiv.org/abs/2403.13565</link><description>&lt;p&gt;
AdaTrans&#65306;&#38024;&#23545;&#39640;&#32500;&#22238;&#24402;&#30340;&#29305;&#24449;&#33258;&#36866;&#24212;&#19982;&#26679;&#26412;&#33258;&#36866;&#24212;&#36801;&#31227;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
AdaTrans: Feature-wise and Sample-wise Adaptive Transfer Learning for High-dimensional Regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13565
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#39640;&#32500;&#22238;&#24402;&#30340;&#33258;&#36866;&#24212;&#36801;&#31227;&#23398;&#20064;&#26041;&#27861;&#65292;&#21487;&#20197;&#26681;&#25454;&#21487;&#36801;&#31227;&#32467;&#26500;&#33258;&#36866;&#24212;&#26816;&#27979;&#21644;&#32858;&#21512;&#29305;&#24449;&#21644;&#26679;&#26412;&#30340;&#21487;&#36801;&#31227;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#39640;&#32500;&#32972;&#26223;&#19979;&#30340;&#36801;&#31227;&#23398;&#20064;&#38382;&#39064;&#65292;&#22312;&#35813;&#38382;&#39064;&#20013;&#65292;&#29305;&#24449;&#32500;&#24230;&#22823;&#20110;&#26679;&#26412;&#22823;&#23567;&#12290;&#20026;&#20102;&#23398;&#20064;&#21487;&#36801;&#31227;&#30340;&#20449;&#24687;&#65292;&#35813;&#20449;&#24687;&#21487;&#33021;&#22312;&#29305;&#24449;&#25110;&#28304;&#26679;&#26412;&#20043;&#38388;&#21464;&#21270;&#65292;&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#33258;&#36866;&#24212;&#36801;&#31227;&#23398;&#20064;&#26041;&#27861;&#65292;&#21487;&#20197;&#26816;&#27979;&#21644;&#32858;&#21512;&#29305;&#24449;-wise (F-AdaTrans)&#25110;&#26679;&#26412;-wise (S-AdaTrans)&#21487;&#36801;&#31227;&#32467;&#26500;&#12290;&#25105;&#20204;&#36890;&#36807;&#37319;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#34701;&#21512;&#24809;&#32602;&#26041;&#27861;&#65292;&#32467;&#21512;&#26435;&#37325;&#65292;&#21487;&#20197;&#26681;&#25454;&#21487;&#36801;&#31227;&#32467;&#26500;&#36827;&#34892;&#35843;&#25972;&#12290;&#20026;&#20102;&#36873;&#25321;&#26435;&#37325;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#29702;&#35770;&#19978;&#24314;&#31435;&#65292;&#25968;&#25454;&#39537;&#21160;&#30340;&#36807;&#31243;&#65292;&#20351;&#24471; F-AdaTrans &#33021;&#22815;&#36873;&#25321;&#24615;&#22320;&#23558;&#21487;&#36801;&#31227;&#30340;&#20449;&#21495;&#19982;&#30446;&#26631;&#34701;&#21512;&#22312;&#19968;&#36215;&#65292;&#21516;&#26102;&#28388;&#38500;&#38750;&#21487;&#36801;&#31227;&#30340;&#20449;&#21495;&#65292;S-AdaTrans&#21017;&#21487;&#20197;&#33719;&#24471;&#27599;&#20010;&#28304;&#26679;&#26412;&#20256;&#36882;&#30340;&#20449;&#24687;&#30340;&#26368;&#20339;&#32452;&#21512;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#38750;&#28176;&#36817;&#36895;&#29575;&#65292;&#21487;&#20197;&#22312;&#29305;&#27530;&#24773;&#20917;&#19979;&#24674;&#22797;&#29616;&#26377;&#30340;&#36817;&#26368;&#23567;&#20284;&#20046;&#26368;&#20248;&#36895;&#29575;&#12290;&#25928;&#26524;&#35777;&#26126;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13565v1 Announce Type: cross  Abstract: We consider the transfer learning problem in the high dimensional setting, where the feature dimension is larger than the sample size. To learn transferable information, which may vary across features or the source samples, we propose an adaptive transfer learning method that can detect and aggregate the feature-wise (F-AdaTrans) or sample-wise (S-AdaTrans) transferable structures. We achieve this by employing a novel fused-penalty, coupled with weights that can adapt according to the transferable structure. To choose the weight, we propose a theoretically informed, data-driven procedure, enabling F-AdaTrans to selectively fuse the transferable signals with the target while filtering out non-transferable signals, and S-AdaTrans to obtain the optimal combination of information transferred from each source sample. The non-asymptotic rates are established, which recover existing near-minimax optimal rates in special cases. The effectivene
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32479;&#19968;&#26694;&#26550;&#65292;&#29992;&#20110;&#26500;&#24314;&#20449;&#24687;&#20016;&#23500;&#30340;&#31526;&#21512;&#39044;&#27979;&#38598;&#65292;&#21516;&#26102;&#25511;&#21046;&#25152;&#36873;&#26679;&#26412;&#30340;&#34394;&#35686;&#35206;&#30422;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.12295</link><description>&lt;p&gt;
&#36890;&#36807;&#25511;&#21046;&#34394;&#35686;&#35206;&#30422;&#29575;&#36873;&#25321;&#20449;&#24687;&#37327;&#20016;&#23500;&#30340;&#31526;&#21512;&#39044;&#27979;&#38598;
&lt;/p&gt;
&lt;p&gt;
Selecting informative conformal prediction sets with false coverage rate control
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12295
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32479;&#19968;&#26694;&#26550;&#65292;&#29992;&#20110;&#26500;&#24314;&#20449;&#24687;&#20016;&#23500;&#30340;&#31526;&#21512;&#39044;&#27979;&#38598;&#65292;&#21516;&#26102;&#25511;&#21046;&#25152;&#36873;&#26679;&#26412;&#30340;&#34394;&#35686;&#35206;&#30422;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#30417;&#30563;&#23398;&#20064;&#20013;&#65292;&#21253;&#25324;&#22238;&#24402;&#21644;&#20998;&#31867;&#65292;&#31526;&#21512;&#26041;&#27861;&#20026;&#20219;&#20309;&#26426;&#22120;&#23398;&#20064;&#39044;&#27979;&#22120;&#25552;&#20379;&#39044;&#27979;&#32467;&#26524;/&#26631;&#31614;&#30340;&#39044;&#27979;&#38598;&#21512;&#65292;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#35206;&#30422;&#29575;&#12290;&#22312;&#36825;&#37324;&#25105;&#20204;&#32771;&#34385;&#20102;&#36825;&#26679;&#19968;&#31181;&#24773;&#20917;&#65292;&#21363;&#36825;&#31181;&#39044;&#27979;&#38598;&#21512;&#26159;&#32463;&#36807;&#36873;&#25321;&#36807;&#31243;&#24471;&#21040;&#30340;&#12290;&#35813;&#36873;&#25321;&#36807;&#31243;&#35201;&#27714;&#36873;&#25321;&#30340;&#39044;&#27979;&#38598;&#22312;&#26576;&#31181;&#26126;&#30830;&#23450;&#20041;&#30340;&#24847;&#20041;&#19978;&#26159;&#8220;&#20449;&#24687;&#37327;&#20016;&#23500;&#30340;&#8221;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#20998;&#31867;&#21644;&#22238;&#24402;&#35774;&#32622;&#65292;&#22312;&#36825;&#20123;&#35774;&#32622;&#20013;&#65292;&#20998;&#26512;&#20154;&#21592;&#21487;&#33021;&#21482;&#32771;&#34385;&#20855;&#26377;&#39044;&#27979;&#26631;&#31614;&#38598;&#25110;&#39044;&#27979;&#21306;&#38388;&#36275;&#22815;&#23567;&#12289;&#19981;&#21253;&#25324;&#31354;&#20540;&#25110;&#36981;&#23432;&#20854;&#20182;&#36866;&#24403;&#30340;&#8220;&#21333;&#35843;&#8221;&#32422;&#26463;&#30340;&#26679;&#26412;&#20026;&#20855;&#26377;&#20449;&#24687;&#37327;&#20016;&#23500;&#30340;&#12290;&#34429;&#28982;&#36825;&#28085;&#30422;&#20102;&#21508;&#31181;&#24212;&#29992;&#20013;&#21487;&#33021;&#24863;&#20852;&#36259;&#30340;&#35768;&#22810;&#35774;&#32622;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#29992;&#26469;&#26500;&#24314;&#36825;&#26679;&#30340;&#20449;&#24687;&#37327;&#20016;&#23500;&#30340;&#31526;&#21512;&#39044;&#27979;&#38598;&#65292;&#21516;&#26102;&#25511;&#21046;&#25152;&#36873;&#26679;&#26412;&#19978;&#30340;&#34394;&#35686;&#35206;&#30422;&#29575;&#65288;FCR&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12295v1 Announce Type: cross  Abstract: In supervised learning, including regression and classification, conformal methods provide prediction sets for the outcome/label with finite sample coverage for any machine learning predictors. We consider here the case where such prediction sets come after a selection process. The selection process requires that the selected prediction sets be `informative' in a well defined sense. We consider both the classification and regression settings where the analyst may consider as informative only the sample with prediction label sets or prediction intervals small enough, excluding null values, or obeying other appropriate `monotone' constraints. While this covers many settings of possible interest in various applications, we develop a unified framework for building such informative conformal prediction sets while controlling the false coverage rate (FCR) on the selected sample. While conformal prediction sets after selection have been the f
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#20855;&#26377;&#23398;&#20064;&#35889;&#26680;&#30340;&#28151;&#21512;&#39640;&#26031;&#36807;&#31243;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#26041;&#27861;&#65292;&#38024;&#23545;&#22024;&#26434;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#36827;&#34892;&#40065;&#26834;&#23398;&#20064;&#12290;</title><link>https://arxiv.org/abs/2402.14081</link><description>&lt;p&gt;
&#20351;&#29992;&#20855;&#26377;&#36816;&#21160;&#20195;&#30721;&#30340;&#38543;&#26426;&#36807;&#31243;&#27169;&#22411;&#23545;&#22024;&#26434;&#26102;&#38388;&#24207;&#21015;&#38598;&#21512;&#36827;&#34892;&#40065;&#26834;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Robust Learning of Noisy Time Series Collections Using Stochastic Process Models with Motion Codes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14081
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#20855;&#26377;&#23398;&#20064;&#35889;&#26680;&#30340;&#28151;&#21512;&#39640;&#26031;&#36807;&#31243;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#26041;&#27861;&#65292;&#38024;&#23545;&#22024;&#26434;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#36827;&#34892;&#40065;&#26834;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#21644;&#39044;&#27979;&#38382;&#39064;&#24050;&#32463;&#24471;&#21040;&#24191;&#27867;&#30740;&#31350;&#65292;&#20294;&#20855;&#26377;&#20219;&#24847;&#26102;&#38388;&#24207;&#21015;&#38271;&#24230;&#30340;&#22024;&#26434;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#24773;&#20917;&#20173;&#20855;&#25361;&#25112;&#24615;&#12290;&#27599;&#20010;&#26102;&#38388;&#24207;&#21015;&#23454;&#20363;&#21487;&#20197;&#30475;&#20316;&#26159;&#22024;&#26434;&#21160;&#24577;&#27169;&#22411;&#30340;&#19968;&#20010;&#26679;&#26412;&#23454;&#29616;&#65292;&#20854;&#29305;&#28857;&#26159;&#36830;&#32493;&#38543;&#26426;&#36807;&#31243;&#12290;&#23545;&#20110;&#35768;&#22810;&#24212;&#29992;&#65292;&#25968;&#25454;&#26159;&#28151;&#21512;&#30340;&#65292;&#30001;&#22810;&#20010;&#38543;&#26426;&#36807;&#31243;&#24314;&#27169;&#30340;&#20960;&#31181;&#31867;&#22411;&#30340;&#22024;&#26434;&#26102;&#38388;&#24207;&#21015;&#24207;&#21015;&#32452;&#25104;&#65292;&#20351;&#24471;&#39044;&#27979;&#21644;&#20998;&#31867;&#20219;&#21153;&#21464;&#24471;&#26356;&#20855;&#25361;&#25112;&#24615;&#12290;&#25105;&#20204;&#19981;&#26159;&#31616;&#21333;&#22320;&#23558;&#25968;&#25454;&#22238;&#24402;&#21040;&#27599;&#31181;&#26102;&#38388;&#24207;&#21015;&#31867;&#22411;&#65292;&#32780;&#26159;&#37319;&#29992;&#20855;&#26377;&#23398;&#20064;&#35889;&#26680;&#30340;&#28151;&#21512;&#39640;&#26031;&#36807;&#31243;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#26041;&#27861;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#20026;&#27599;&#31181;&#31867;&#22411;&#30340;&#22024;&#26434;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#33258;&#21160;&#20998;&#37197;&#19968;&#20010;&#31216;&#20026;&#20854;&#36816;&#21160;&#20195;&#30721;&#30340;&#31614;&#21517;&#21521;&#37327;&#12290;&#28982;&#21518;&#65292;&#22312;&#27599;&#20010;&#20998;&#37197;&#30340;&#36816;&#21160;&#20195;&#30721;&#30340;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#25512;&#26029;&#20986;&#30456;&#20851;&#24615;&#30340;&#31232;&#30095;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14081v1 Announce Type: cross  Abstract: While time series classification and forecasting problems have been extensively studied, the cases of noisy time series data with arbitrary time sequence lengths have remained challenging. Each time series instance can be thought of as a sample realization of a noisy dynamical model, which is characterized by a continuous stochastic process. For many applications, the data are mixed and consist of several types of noisy time series sequences modeled by multiple stochastic processes, making the forecasting and classification tasks even more challenging. Instead of regressing data naively and individually to each time series type, we take a latent variable model approach using a mixtured Gaussian processes with learned spectral kernels. More specifically, we auto-assign each type of noisy time series data a signature vector called its motion code. Then, conditioned on each assigned motion code, we infer a sparse approximation of the corr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;&#20449;&#21495;&#20998;&#31163;&#65292;&#24182;&#19988;&#33021;&#22815;&#22788;&#29702;&#21253;&#21547;&#32431;&#32452;&#20998;&#20449;&#21495;&#21152;&#26435;&#21644;&#30340;&#24773;&#20917;&#65292;&#36866;&#29992;&#20110;&#20809;&#35889;&#23398;&#21644;&#20854;&#20182;&#39046;&#22495;&#30340;&#22810;&#31181;&#24212;&#29992;&#12290;</title><link>https://arxiv.org/abs/2402.09122</link><description>&lt;p&gt;
&#28151;&#21512;&#36755;&#20986;&#39640;&#26031;&#36807;&#31243;&#28508;&#21464;&#37327;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Mixed-Output Gaussian Process Latent Variable Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09122
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;&#20449;&#21495;&#20998;&#31163;&#65292;&#24182;&#19988;&#33021;&#22815;&#22788;&#29702;&#21253;&#21547;&#32431;&#32452;&#20998;&#20449;&#21495;&#21152;&#26435;&#21644;&#30340;&#24773;&#20917;&#65292;&#36866;&#29992;&#20110;&#20809;&#35889;&#23398;&#21644;&#20854;&#20182;&#39046;&#22495;&#30340;&#22810;&#31181;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#30340;&#20449;&#21495;&#20998;&#31163;&#26041;&#27861;&#65292;&#20854;&#20013;&#20449;&#21495;&#21487;&#20197;&#26681;&#25454;&#28508;&#21464;&#37327;&#21464;&#21270;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#22686;&#21152;&#20102;&#39640;&#26031;&#36807;&#31243;&#28508;&#21464;&#37327;&#27169;&#22411;&#65288;GPLVMs&#65289;&#65292;&#20197;&#21253;&#25324;&#27599;&#20010;&#25968;&#25454;&#28857;&#30001;&#24050;&#30693;&#25968;&#37327;&#30340;&#32431;&#32452;&#20998;&#20449;&#21495;&#30340;&#21152;&#26435;&#21644;&#32452;&#25104;&#30340;&#24773;&#20917;&#65292;&#24182;&#35266;&#23519;&#22810;&#20010;&#36755;&#20837;&#20301;&#32622;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#20801;&#35768;&#20351;&#29992;&#21508;&#31181;&#20851;&#20110;&#27599;&#20010;&#35266;&#27979;&#26435;&#37325;&#30340;&#20808;&#39564;&#12290;&#36825;&#31181;&#28789;&#27963;&#24615;&#20351;&#25105;&#20204;&#33021;&#22815;&#34920;&#31034;&#21253;&#25324;&#29992;&#20110;&#20272;&#35745;&#20998;&#25968;&#32452;&#25104;&#30340;&#24635;&#21644;&#20026;&#19968;&#32422;&#26463;&#21644;&#29992;&#20110;&#20998;&#31867;&#30340;&#20108;&#36827;&#21046;&#26435;&#37325;&#30340;&#29992;&#20363;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#23545;&#20110;&#20809;&#35889;&#23398;&#23588;&#20854;&#30456;&#20851;&#65292;&#22240;&#20026;&#25913;&#21464;&#26465;&#20214;&#21487;&#33021;&#23548;&#33268;&#22522;&#30784;&#32431;&#32452;&#20998;&#20449;&#21495;&#22312;&#26679;&#26412;&#20043;&#38388;&#21464;&#21270;&#12290;&#20026;&#20102;&#23637;&#31034;&#23545;&#20809;&#35889;&#23398;&#21644;&#20854;&#20182;&#39046;&#22495;&#30340;&#36866;&#29992;&#24615;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#20960;&#20010;&#24212;&#29992;&#65306;&#19968;&#20010;&#20855;&#26377;&#19981;&#21516;&#28201;&#24230;&#30340;&#36817;&#32418;&#22806;&#20809;&#35889;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09122v1 Announce Type: cross Abstract: This work develops a Bayesian non-parametric approach to signal separation where the signals may vary according to latent variables. Our key contribution is to augment Gaussian Process Latent Variable Models (GPLVMs) to incorporate the case where each data point comprises the weighted sum of a known number of pure component signals, observed across several input locations. Our framework allows the use of a range of priors for the weights of each observation. This flexibility enables us to represent use cases including sum-to-one constraints for estimating fractional makeup, and binary weights for classification. Our contributions are particularly relevant to spectroscopy, where changing conditions may cause the underlying pure component signals to vary from sample to sample. To demonstrate the applicability to both spectroscopy and other domains, we consider several applications: a near-infrared spectroscopy data set with varying temper
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#37325;&#26032;&#24605;&#32771;&#20102;&#22312;&#25112;&#30053;&#29615;&#22659;&#20013;&#23398;&#20064;&#30340;&#27604;&#20363;&#23450;&#24459;&#65292;&#21457;&#29616;&#25112;&#30053;&#20114;&#21160;&#21487;&#20197;&#25171;&#30772;&#20256;&#32479;&#30340;&#35266;&#28857;&#65292;&#21363;&#27169;&#22411;&#36234;&#22823;&#25110;&#34920;&#36798;&#33021;&#21147;&#36234;&#24378;&#24182;&#19981;&#19968;&#23450;&#20250;&#38543;&#20043;&#25552;&#39640;&#24615;&#33021;&#12290;&#36890;&#36807;&#20960;&#20010;&#25112;&#30053;&#29615;&#22659;&#30340;&#20363;&#23376;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#29616;&#35937;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2402.07588</link><description>&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;&#25112;&#30053;&#29615;&#22659;&#20013;&#23398;&#20064;&#30340;&#27604;&#20363;&#23450;&#24459;
&lt;/p&gt;
&lt;p&gt;
Rethinking Scaling Laws for Learning in Strategic Environments
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07588
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#26032;&#24605;&#32771;&#20102;&#22312;&#25112;&#30053;&#29615;&#22659;&#20013;&#23398;&#20064;&#30340;&#27604;&#20363;&#23450;&#24459;&#65292;&#21457;&#29616;&#25112;&#30053;&#20114;&#21160;&#21487;&#20197;&#25171;&#30772;&#20256;&#32479;&#30340;&#35266;&#28857;&#65292;&#21363;&#27169;&#22411;&#36234;&#22823;&#25110;&#34920;&#36798;&#33021;&#21147;&#36234;&#24378;&#24182;&#19981;&#19968;&#23450;&#20250;&#38543;&#20043;&#25552;&#39640;&#24615;&#33021;&#12290;&#36890;&#36807;&#20960;&#20010;&#25112;&#30053;&#29615;&#22659;&#30340;&#20363;&#23376;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#29616;&#35937;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36234;&#26469;&#36234;&#22823;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#37096;&#32626;&#21453;&#26144;&#20986;&#19968;&#20010;&#20849;&#35782;&#65306;&#27169;&#22411;&#36234;&#26377;&#34920;&#36798;&#33021;&#21147;&#65292;&#36234;&#25317;&#26377;&#22823;&#37327;&#25968;&#25454;&#65292;&#23601;&#33021;&#25913;&#21892;&#24615;&#33021;&#12290;&#38543;&#30528;&#27169;&#22411;&#22312;&#21508;&#31181;&#30495;&#23454;&#22330;&#26223;&#20013;&#30340;&#37096;&#32626;&#65292;&#23427;&#20204;&#19981;&#21487;&#36991;&#20813;&#22320;&#38754;&#20020;&#30528;&#25112;&#30053;&#29615;&#22659;&#12290;&#26412;&#25991;&#32771;&#34385;&#20102;&#27169;&#22411;&#19982;&#25112;&#30053;&#20114;&#21160;&#23545;&#27604;&#20363;&#23450;&#24459;&#30340;&#30456;&#20114;&#20316;&#29992;&#23545;&#24615;&#33021;&#30340;&#24433;&#21709;&#36825;&#20010;&#33258;&#28982;&#38382;&#39064;&#12290;&#25105;&#20204;&#21457;&#29616;&#25112;&#30053;&#20114;&#21160;&#21487;&#20197;&#25171;&#30772;&#20256;&#32479;&#30340;&#27604;&#20363;&#23450;&#24459;&#35266;&#28857;&#65292;&#21363;&#24615;&#33021;&#24182;&#19981;&#19968;&#23450;&#38543;&#30528;&#27169;&#22411;&#30340;&#25193;&#22823;&#21644;/&#25110;&#34920;&#36798;&#33021;&#21147;&#30340;&#22686;&#24378;&#65288;&#21363;&#20351;&#26377;&#26080;&#38480;&#25968;&#25454;&#65289;&#32780;&#21333;&#35843;&#25552;&#39640;&#12290;&#25105;&#20204;&#36890;&#36807;&#25112;&#30053;&#22238;&#24402;&#12289;&#25112;&#30053;&#20998;&#31867;&#21644;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#30340;&#20363;&#23376;&#23637;&#31034;&#20102;&#36825;&#19968;&#29616;&#35937;&#30340;&#24433;&#21709;&#65292;&#36825;&#20123;&#20363;&#23376;&#23637;&#31034;&#20102;&#25112;&#30053;&#29615;&#22659;&#20013;&#30340;&#38480;&#21046;&#27169;&#22411;&#25110;&#31574;&#30053;&#31867;&#30340;&#34920;&#36798;&#33021;&#21147;&#21363;&#21487;&#12290;
&lt;/p&gt;
&lt;p&gt;
The deployment of ever-larger machine learning models reflects a growing consensus that the more expressive the model$\unicode{x2013}$and the more data one has access to$\unicode{x2013}$the more one can improve performance. As models get deployed in a variety of real world scenarios, they inevitably face strategic environments. In this work, we consider the natural question of how the interplay of models and strategic interactions affects scaling laws. We find that strategic interactions can break the conventional view of scaling laws$\unicode{x2013}$meaning that performance does not necessarily monotonically improve as models get larger and/ or more expressive (even with infinite data). We show the implications of this phenomenon in several contexts including strategic regression, strategic classification, and multi-agent reinforcement learning through examples of strategic environments in which$\unicode{x2013}$by simply restricting the expressivity of one's model or policy class$\uni
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;TDS&#30340;&#25197;&#36716;&#24335;&#25193;&#25955;&#37319;&#26679;&#22120;&#65292;&#23427;&#26159;&#19968;&#31181;&#38024;&#23545;&#25193;&#25955;&#27169;&#22411;&#30340;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#31639;&#27861;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#20351;&#29992;&#25197;&#36716;&#25216;&#26415;&#32467;&#21512;&#21551;&#21457;&#24335;&#36817;&#20284;&#65292;&#33021;&#22815;&#22312;&#19981;&#38656;&#35201;&#29305;&#23450;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#22312;&#24191;&#27867;&#30340;&#26465;&#20214;&#20998;&#24067;&#19978;&#25552;&#20379;&#31934;&#30830;&#30340;&#26679;&#26412;&#12290;</title><link>http://arxiv.org/abs/2306.17775</link><description>&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#20013;&#30340;&#23454;&#29992;&#21644;&#28176;&#36827;&#31934;&#30830;&#26465;&#20214;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Practical and Asymptotically Exact Conditional Sampling in Diffusion Models. (arXiv:2306.17775v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17775
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;TDS&#30340;&#25197;&#36716;&#24335;&#25193;&#25955;&#37319;&#26679;&#22120;&#65292;&#23427;&#26159;&#19968;&#31181;&#38024;&#23545;&#25193;&#25955;&#27169;&#22411;&#30340;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#31639;&#27861;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#20351;&#29992;&#25197;&#36716;&#25216;&#26415;&#32467;&#21512;&#21551;&#21457;&#24335;&#36817;&#20284;&#65292;&#33021;&#22815;&#22312;&#19981;&#38656;&#35201;&#29305;&#23450;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#22312;&#24191;&#27867;&#30340;&#26465;&#20214;&#20998;&#24067;&#19978;&#25552;&#20379;&#31934;&#30830;&#30340;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#22312;&#20998;&#23376;&#35774;&#35745;&#21644;&#25991;&#26412;&#21040;&#22270;&#20687;&#29983;&#25104;&#31561;&#26465;&#20214;&#29983;&#25104;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#25104;&#23601;&#20027;&#35201;&#20381;&#36182;&#20110;&#20219;&#21153;&#29305;&#23450;&#30340;&#26465;&#20214;&#35757;&#32451;&#25110;&#23481;&#26131;&#20986;&#38169;&#30340;&#21551;&#21457;&#24335;&#36817;&#20284;&#12290;&#29702;&#24819;&#24773;&#20917;&#19979;&#65292;&#26465;&#20214;&#29983;&#25104;&#26041;&#27861;&#24212;&#35813;&#33021;&#22815;&#22312;&#19981;&#38656;&#35201;&#29305;&#23450;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#20026;&#24191;&#27867;&#30340;&#26465;&#20214;&#20998;&#24067;&#25552;&#20379;&#31934;&#30830;&#30340;&#26679;&#26412;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#25197;&#36716;&#24335;&#25193;&#25955;&#37319;&#26679;&#22120;(TDS)&#12290;TDS&#26159;&#19968;&#31181;&#38024;&#23545;&#25193;&#25955;&#27169;&#22411;&#30340;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;(SMC)&#31639;&#27861;&#12290;&#20854;&#20027;&#35201;&#24605;&#24819;&#26159;&#20351;&#29992;&#25197;&#36716;&#65292;&#19968;&#31181;&#20855;&#26377;&#33391;&#22909;&#35745;&#31639;&#25928;&#29575;&#30340;SMC&#25216;&#26415;&#65292;&#26469;&#32467;&#21512;&#21551;&#21457;&#24335;&#36817;&#20284;&#32780;&#19981;&#24433;&#21709;&#28176;&#36827;&#31934;&#30830;&#24615;&#12290;&#25105;&#20204;&#39318;&#20808;&#22312;&#27169;&#25311;&#23454;&#39564;&#21644;MNIST&#22270;&#20687;&#20462;&#22797;&#20197;&#21450;&#31867;&#26465;&#20214;&#29983;&#25104;&#20219;&#21153;&#20013;&#21457;&#29616;&#65292;TDS&#25552;&#20379;&#20102;&#35745;&#31639;&#32479;&#35745;&#26435;&#34913;&#65292;&#20351;&#29992;&#26356;&#22810;&#31890;&#23376;&#24471;&#21040;&#26356;&#20934;&#30830;&#30340;&#36817;&#20284;&#32467;&#26524;&#65292;&#20294;&#21516;&#26102;&#38656;&#35201;&#26356;&#22810;&#35745;&#31639;&#36164;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models have been successful on a range of conditional generation tasks including molecular design and text-to-image generation. However, these achievements have primarily depended on task-specific conditional training or error-prone heuristic approximations. Ideally, a conditional generation method should provide exact samples for a broad range of conditional distributions without requiring task-specific training. To this end, we introduce the Twisted Diffusion Sampler, or TDS. TDS is a sequential Monte Carlo (SMC) algorithm that targets the conditional distributions of diffusion models. The main idea is to use twisting, an SMC technique that enjoys good computational efficiency, to incorporate heuristic approximations without compromising asymptotic exactness. We first find in simulation and on MNIST image inpainting and class-conditional generation tasks that TDS provides a computational statistical trade-off, yielding more accurate approximations with many particles but wi
&lt;/p&gt;</description></item><item><title>&#20154;&#31867;&#19987;&#23478;&#30340;&#20215;&#20540;&#36229;&#20986;&#20102;&#31639;&#27861;&#21487;&#25429;&#25417;&#33539;&#22260;&#65292;&#25105;&#20204;&#21487;&#20197;&#29992;&#19968;&#20010;&#31616;&#21333;&#30340;&#31243;&#24207;&#27979;&#35797;&#36825;&#20010;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.01646</link><description>&lt;p&gt;
&#20154;&#31867;&#19987;&#23478;&#23457;&#26680;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Auditing for Human Expertise. (arXiv:2306.01646v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01646
&lt;/p&gt;
&lt;p&gt;
&#20154;&#31867;&#19987;&#23478;&#30340;&#20215;&#20540;&#36229;&#20986;&#20102;&#31639;&#27861;&#21487;&#25429;&#25417;&#33539;&#22260;&#65292;&#25105;&#20204;&#21487;&#20197;&#29992;&#19968;&#20010;&#31616;&#21333;&#30340;&#31243;&#24207;&#27979;&#35797;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#39118;&#38505;&#39044;&#27979;&#20219;&#21153;&#65288;&#20363;&#22914;&#24739;&#32773;&#35786;&#26029;&#65289;&#36890;&#24120;&#30001;&#25509;&#21463;&#22521;&#35757;&#30340;&#20154;&#31867;&#19987;&#23478;&#22788;&#29702;&#12290;&#22312;&#36825;&#20123;&#35774;&#32622;&#20013;&#65292;&#33258;&#21160;&#21270;&#30340;&#19968;&#20010;&#24120;&#35265;&#38382;&#39064;&#26159;&#65292;&#19987;&#23478;&#21487;&#33021;&#36816;&#29992;&#24456;&#38590;&#24314;&#27169;&#30340;&#30452;&#35273;&#65292;&#24182;&#19988;/&#25110;&#32773;&#21487;&#20197;&#33719;&#21462;&#20449;&#24687;&#65288;&#20363;&#22914;&#19982;&#24739;&#32773;&#30340;&#20132;&#35848;&#65289;&#65292;&#36825;&#20123;&#20449;&#24687;&#23545;&#20110;&#31639;&#27861;&#26469;&#35828;&#26159;&#19981;&#21487;&#29992;&#30340;&#12290;&#36825;&#24341;&#21457;&#20102;&#19968;&#20010;&#33258;&#28982;&#30340;&#38382;&#39064;&#65292;&#20154;&#31867;&#19987;&#23478;&#26159;&#21542;&#22686;&#21152;&#20102;&#26080;&#27861;&#34987;&#31639;&#27861;&#39044;&#27979;&#22120;&#25429;&#25417;&#21040;&#30340;&#20215;&#20540;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#32479;&#35745;&#26694;&#26550;&#65292;&#21487;&#20197;&#23558;&#36825;&#20010;&#38382;&#39064;&#25552;&#20986;&#20026;&#19968;&#20010;&#33258;&#28982;&#30340;&#20551;&#35774;&#26816;&#39564;&#12290;&#27491;&#22914;&#25105;&#20204;&#30340;&#26694;&#26550;&#25152;&#24378;&#35843;&#30340;&#37027;&#26679;&#65292;&#26816;&#27979;&#20154;&#31867;&#19987;&#19994;&#30693;&#35782;&#27604;&#31616;&#21333;&#27604;&#36739;&#19987;&#23478;&#39044;&#27979;&#20934;&#30830;&#24615;&#19982;&#29305;&#23450;&#23398;&#20064;&#31639;&#27861;&#20570;&#20986;&#30340;&#20934;&#30830;&#24615;&#26356;&#21152;&#24494;&#22937;&#12290;&#32780;&#26159;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#31243;&#24207;&#65292;&#27979;&#35797;&#19987;&#23478;&#39044;&#27979;&#26159;&#21542;&#22312;&#8220;&#29305;&#24449;&#8221;&#21487;&#29992;&#32780;&#26465;&#20214;&#19979;&#26159;&#21542;&#19982;&#24863;&#20852;&#36259;&#30340;&#32467;&#26524;&#32479;&#35745;&#19978;&#29420;&#31435;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#27979;&#35797;&#30340;&#25298;&#32477;&#34920;&#26126;&#20102;&#20154;&#31867;&#19987;&#19994;&#30693;&#35782;&#30830;&#23454;&#22686;&#21152;&#20102;&#36229;&#20986;&#31639;&#27861;&#21487;&#25429;&#25417;&#33539;&#22260;&#30340;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
High-stakes prediction tasks (e.g., patient diagnosis) are often handled by trained human experts. A common source of concern about automation in these settings is that experts may exercise intuition that is difficult to model and/or have access to information (e.g., conversations with a patient) that is simply unavailable to a would-be algorithm. This raises a natural question whether human experts add value which could not be captured by an algorithmic predictor. We develop a statistical framework under which we can pose this question as a natural hypothesis test. Indeed, as our framework highlights, detecting human expertise is more subtle than simply comparing the accuracy of expert predictions to those made by a particular learning algorithm. Instead, we propose a simple procedure which tests whether expert predictions are statistically independent from the outcomes of interest after conditioning on the available inputs (`features'). A rejection of our test thus suggests that huma
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#27010;&#29575;&#35270;&#35282;&#30340;&#23545;&#25239;&#26679;&#26412;&#26500;&#24314;&#26041;&#27861;&#65292;&#21487;&#20197;&#29983;&#25104;&#35821;&#20041;&#24863;&#30693;&#30340;&#23545;&#25239;&#24615;&#26679;&#26412;&#65292;&#24182;&#21487;&#20197;&#26377;&#25928;&#35268;&#36991;&#20256;&#32479;&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#24378;&#21270;&#23545;&#25239;&#35757;&#32451;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.00353</link><description>&lt;p&gt;
&#20174;&#27010;&#29575;&#35282;&#24230;&#26500;&#24314;&#35821;&#20041;&#24863;&#30693;&#30340;&#23545;&#25239;&#26679;&#26412;
&lt;/p&gt;
&lt;p&gt;
Constructing Semantics-Aware Adversarial Examples with Probabilistic Perspective. (arXiv:2306.00353v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00353
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#27010;&#29575;&#35270;&#35282;&#30340;&#23545;&#25239;&#26679;&#26412;&#26500;&#24314;&#26041;&#27861;&#65292;&#21487;&#20197;&#29983;&#25104;&#35821;&#20041;&#24863;&#30693;&#30340;&#23545;&#25239;&#24615;&#26679;&#26412;&#65292;&#24182;&#21487;&#20197;&#26377;&#25928;&#35268;&#36991;&#20256;&#32479;&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#24378;&#21270;&#23545;&#25239;&#35757;&#32451;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27010;&#29575;&#35270;&#35282;&#23545;&#25239;&#26679;&#26412;&#26500;&#24314;&#26041;&#27861;&#8212;&#8212;&#31665;&#32422;&#26463; Langevin Monte Carlo&#65288;LMC&#65289;&#12290;&#20174;&#36825;&#20010;&#35282;&#24230;&#20986;&#21457;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#21019;&#26032;&#24615;&#30340;&#26041;&#27861;&#65292;&#20197;&#21407;&#21017;&#24615;&#30340;&#26041;&#24335;&#29983;&#25104;&#35821;&#20041;&#24863;&#30693;&#30340;&#23545;&#25239;&#24615;&#26679;&#26412;&#12290;&#36825;&#31181;&#26041;&#27861;&#36229;&#36234;&#20102;&#20960;&#20309;&#36317;&#31163;&#25152;&#26045;&#21152;&#30340;&#38480;&#21046;&#65292;&#36873;&#25321;&#20102;&#35821;&#20041;&#32422;&#26463;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36171;&#20104;&#20102;&#20010;&#20307;&#23558;&#20854;&#23545;&#35821;&#20041;&#30340;&#29702;&#35299;&#34701;&#20837;&#21040;&#27169;&#22411;&#20013;&#30340;&#33021;&#21147;&#12290;&#36890;&#36807;&#20154;&#31867;&#35780;&#20272;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#35821;&#20041;&#24863;&#30693;&#30340;&#23545;&#25239;&#26679;&#26412;&#20445;&#25345;&#20854;&#22266;&#26377;&#30340;&#21547;&#20041;&#12290;&#22312; MNIST &#21644; SVHN &#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#35821;&#20041;&#24863;&#30693;&#30340;&#23545;&#25239;&#26679;&#26412;&#21487;&#20197;&#26377;&#25928;&#22320;&#35268;&#36991;&#38024;&#23545;&#20256;&#32479;&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#24378;&#20581;&#24615;&#23545;&#25239;&#35757;&#32451;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this study, we introduce a novel, probabilistic viewpoint on adversarial examples, achieved through box-constrained Langevin Monte Carlo (LMC). Proceeding from this perspective, we develop an innovative approach for generating semantics-aware adversarial examples in a principled manner. This methodology transcends the restriction imposed by geometric distance, instead opting for semantic constraints. Our approach empowers individuals to incorporate their personal comprehension of semantics into the model. Through human evaluation, we validate that our semantics-aware adversarial examples maintain their inherent meaning. Experimental findings on the MNIST and SVHN datasets demonstrate that our semantics-aware adversarial examples can effectively circumvent robust adversarial training methods tailored for traditional adversarial attacks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#32676;&#19981;&#21464;&#24615;&#30340;&#20998;&#24067;&#21464;&#37327;&#22312;&#21464;&#20998;&#24046;&#24322;&#20272;&#35745;&#20013;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#21457;&#29616;&#22312;&#32676;&#22823;&#23567;&#32500;&#24230;&#30456;&#20851;&#30340;&#24773;&#20917;&#19979;&#65292;&#26679;&#26412;&#22797;&#26434;&#24230;&#20250;&#26377;&#25152;&#38477;&#20302;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2302.01915</link><description>&lt;p&gt;
&#22522;&#20110;&#32676;&#23545;&#31216;&#24615;&#30340;&#27010;&#29575;&#24046;&#24322;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Sample Complexity of Probability Divergences under Group Symmetry. (arXiv:2302.01915v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.01915
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#32676;&#19981;&#21464;&#24615;&#30340;&#20998;&#24067;&#21464;&#37327;&#22312;&#21464;&#20998;&#24046;&#24322;&#20272;&#35745;&#20013;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#21457;&#29616;&#22312;&#32676;&#22823;&#23567;&#32500;&#24230;&#30456;&#20851;&#30340;&#24773;&#20917;&#19979;&#65292;&#26679;&#26412;&#22797;&#26434;&#24230;&#20250;&#26377;&#25152;&#38477;&#20302;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23545;&#20110;&#20855;&#26377;&#32676;&#19981;&#21464;&#24615;&#30340;&#20998;&#24067;&#21464;&#37327;&#22312;&#21464;&#20998;&#24046;&#24322;&#20272;&#35745;&#20013;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#36827;&#34892;&#20102;&#20005;&#35880;&#30340;&#37327;&#21270;&#20998;&#26512;&#12290;&#22312;Wasserstein-1&#36317;&#31163;&#21644;Lipschitz&#27491;&#21017;&#21270;&#945;&#24046;&#24322;&#30340;&#24773;&#20917;&#19979;&#65292;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#38477;&#20302;&#19982;&#32676;&#22823;&#23567;&#30340;&#32500;&#24230;&#30456;&#20851;&#12290;&#23545;&#20110;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#65288;MMD&#65289;&#65292;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#25913;&#36827;&#26356;&#21152;&#22797;&#26434;&#65292;&#22240;&#20026;&#23427;&#19981;&#20165;&#21462;&#20915;&#20110;&#32676;&#22823;&#23567;&#65292;&#36824;&#21462;&#20915;&#20110;&#20869;&#26680;&#30340;&#36873;&#25321;&#12290; &#25968;&#20540;&#27169;&#25311;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
We rigorously quantify the improvement in the sample complexity of variational divergence estimations for group-invariant distributions. In the cases of the Wasserstein-1 metric and the Lipschitz-regularized $\alpha$-divergences, the reduction of sample complexity is proportional to an ambient-dimension-dependent power of the group size. For the maximum mean discrepancy (MMD), the improvement of sample complexity is more nuanced, as it depends on not only the group size but also the choice of kernel. Numerical simulations verify our theories.
&lt;/p&gt;</description></item></channel></rss>