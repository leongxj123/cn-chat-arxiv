<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;CBA&#31639;&#27861;&#65292;&#20854;&#21033;&#29992;&#25918;&#24323;&#21442;&#19982;&#28216;&#25103;&#30340;&#20551;&#35774;&#33719;&#24471;&#20102;&#21487;&#20197;&#26174;&#33879;&#25913;&#36827;&#32463;&#20856;Exp4&#31639;&#27861;&#30340;&#22870;&#21169;&#30028;&#38480;&#65292;&#25104;&#20026;&#39318;&#20010;&#23545;&#19968;&#33324;&#32622;&#20449;&#35780;&#32423;&#39044;&#27979;&#22120;&#30340;&#39044;&#26399;&#32047;&#31215;&#22870;&#21169;&#23454;&#29616;&#30028;&#38480;&#30340;&#30740;&#31350;&#32773;&#65292;&#24182;&#22312;&#19987;&#23478;&#26696;&#20363;&#20013;&#23454;&#29616;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22870;&#21169;&#30028;&#38480;&#12290;</title><link>https://arxiv.org/abs/2402.14585</link><description>&lt;p&gt;
&#20855;&#26377;&#24323;&#26435;&#36873;&#39033;&#30340;&#19987;&#23478;&#24314;&#35758;&#19979;&#30340;&#36172;&#24466;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Bandits with Abstention under Expert Advice
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14585
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;CBA&#31639;&#27861;&#65292;&#20854;&#21033;&#29992;&#25918;&#24323;&#21442;&#19982;&#28216;&#25103;&#30340;&#20551;&#35774;&#33719;&#24471;&#20102;&#21487;&#20197;&#26174;&#33879;&#25913;&#36827;&#32463;&#20856;Exp4&#31639;&#27861;&#30340;&#22870;&#21169;&#30028;&#38480;&#65292;&#25104;&#20026;&#39318;&#20010;&#23545;&#19968;&#33324;&#32622;&#20449;&#35780;&#32423;&#39044;&#27979;&#22120;&#30340;&#39044;&#26399;&#32047;&#31215;&#22870;&#21169;&#23454;&#29616;&#30028;&#38480;&#30340;&#30740;&#31350;&#32773;&#65292;&#24182;&#22312;&#19987;&#23478;&#26696;&#20363;&#20013;&#23454;&#29616;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22870;&#21169;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#36172;&#24466;&#21453;&#39304;&#19979;&#21033;&#29992;&#19987;&#23478;&#24314;&#35758;&#36827;&#34892;&#39044;&#27979;&#30340;&#32463;&#20856;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#20551;&#35774;&#19968;&#31181;&#34892;&#21160;&#65292;&#21363;&#23398;&#20064;&#32773;&#25918;&#24323;&#21442;&#19982;&#28216;&#25103;&#65292;&#22312;&#27599;&#27425;&#35797;&#39564;&#20013;&#37117;&#27809;&#26377;&#22870;&#21169;&#25110;&#25439;&#22833;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;CBA&#31639;&#27861;&#65292;&#21033;&#29992;&#36825;&#19968;&#20551;&#35774;&#33719;&#24471;&#20102;&#21487;&#20197;&#26174;&#33879;&#25913;&#36827;&#32463;&#20856;Exp4&#31639;&#27861;&#30340;&#22870;&#21169;&#30028;&#38480;&#12290;&#25105;&#20204;&#21487;&#20197;&#23558;&#25105;&#20204;&#30340;&#38382;&#39064;&#35270;&#20026;&#22312;&#23398;&#20064;&#32773;&#26377;&#25918;&#24323;&#21442;&#19982;&#28216;&#25103;&#36873;&#39033;&#26102;&#23545;&#32622;&#20449;&#35780;&#32423;&#39044;&#27979;&#22120;&#36827;&#34892;&#32858;&#21512;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#26159;&#31532;&#19968;&#20010;&#23545;&#19968;&#33324;&#32622;&#20449;&#35780;&#32423;&#39044;&#27979;&#22120;&#30340;&#39044;&#26399;&#32047;&#31215;&#22870;&#21169;&#23454;&#29616;&#30028;&#38480;&#30340;&#30740;&#31350;&#32773;&#12290;&#22312;&#19987;&#23478;&#26696;&#20363;&#20013;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22870;&#21169;&#30028;&#38480;&#65292;&#26174;&#33879;&#25913;&#36827;&#20102;&#20043;&#21069;&#22312;&#19987;&#23478;Exp&#65288;&#23558;&#24323;&#26435;&#35270;&#20026;&#21478;&#19968;&#31181;&#34892;&#21160;&#65289;&#30340;&#36793;&#30028;&#12290;&#20316;&#20026;&#19968;&#20010;&#31034;&#20363;&#24212;&#29992;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#22312;&#26377;&#38480;&#24230;&#37327;&#31354;&#38388;&#20013;&#23398;&#20064;&#29699;&#30340;&#24182;&#38598;&#12290;&#22312;&#36825;&#20010;&#19978;&#19979;&#25991;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;CBA&#30340;&#26377;&#25928;&#23454;&#29616;&#65292;re
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14585v1 Announce Type: new  Abstract: We study the classic problem of prediction with expert advice under bandit feedback. Our model assumes that one action, corresponding to the learner's abstention from play, has no reward or loss on every trial. We propose the CBA algorithm, which exploits this assumption to obtain reward bounds that can significantly improve those of the classical Exp4 algorithm. We can view our problem as the aggregation of confidence-rated predictors when the learner has the option of abstention from play. Importantly, we are the first to achieve bounds on the expected cumulative reward for general confidence-rated predictors. In the special case of specialists we achieve a novel reward bound, significantly improving previous bounds of SpecialistExp (treating abstention as another action). As an example application, we discuss learning unions of balls in a finite metric space. In this contextual setting, we devise an efficient implementation of CBA, re
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20174;&#29702;&#35770;&#23618;&#38754;&#20998;&#26512;&#20102;&#19968;&#31181;&#20851;&#20110;&#19968;&#33324;&#20559;&#22909;&#19979;&#32435;&#20160;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#20004;&#20010;&#31454;&#20105;&#30340;LLM&#36827;&#34892;&#21338;&#24328;&#26469;&#25214;&#21040;&#19968;&#31181;&#19968;&#33268;&#29983;&#25104;&#21709;&#24212;&#30340;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2402.07314</link><description>&lt;p&gt;
&#19968;&#31181;&#20851;&#20110;&#19968;&#33324;KL&#27491;&#21017;&#21270;&#20559;&#22909;&#19979;&#32435;&#20160;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#30340;&#29702;&#35770;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
A Theoretical Analysis of Nash Learning from Human Feedback under General KL-Regularized Preference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07314
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20174;&#29702;&#35770;&#23618;&#38754;&#20998;&#26512;&#20102;&#19968;&#31181;&#20851;&#20110;&#19968;&#33324;&#20559;&#22909;&#19979;&#32435;&#20160;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#20004;&#20010;&#31454;&#20105;&#30340;LLM&#36827;&#34892;&#21338;&#24328;&#26469;&#25214;&#21040;&#19968;&#31181;&#19968;&#33268;&#29983;&#25104;&#21709;&#24212;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26469;&#33258;&#20154;&#31867;&#21453;&#39304;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288;RLHF&#65289;&#20174;&#19968;&#20010;&#27010;&#29575;&#20559;&#22909;&#27169;&#22411;&#25552;&#20379;&#30340;&#20559;&#22909;&#20449;&#21495;&#20013;&#23398;&#20064;&#65292;&#35813;&#27169;&#22411;&#20197;&#19968;&#20010;&#25552;&#31034;&#21644;&#20004;&#20010;&#21709;&#24212;&#20316;&#20026;&#36755;&#20837;&#65292;&#24182;&#20135;&#29983;&#19968;&#20010;&#20998;&#25968;&#65292;&#34920;&#31034;&#23545;&#19968;&#20010;&#21709;&#24212;&#30456;&#23545;&#20110;&#21478;&#19968;&#20010;&#21709;&#24212;&#30340;&#20559;&#22909;&#31243;&#24230;&#12290;&#36804;&#20170;&#20026;&#27490;&#65292;&#26368;&#27969;&#34892;&#30340;RLHF&#33539;&#24335;&#26159;&#22522;&#20110;&#22870;&#21169;&#30340;&#65292;&#23427;&#20174;&#22870;&#21169;&#24314;&#27169;&#30340;&#21021;&#22987;&#27493;&#39588;&#24320;&#22987;&#65292;&#28982;&#21518;&#20351;&#29992;&#26500;&#24314;&#30340;&#22870;&#21169;&#20026;&#21518;&#32493;&#30340;&#22870;&#21169;&#20248;&#21270;&#38454;&#27573;&#25552;&#20379;&#22870;&#21169;&#20449;&#21495;&#12290;&#28982;&#32780;&#65292;&#22870;&#21169;&#20989;&#25968;&#30340;&#23384;&#22312;&#26159;&#19968;&#20010;&#24378;&#20551;&#35774;&#65292;&#22522;&#20110;&#22870;&#21169;&#30340;RLHF&#22312;&#34920;&#36798;&#33021;&#21147;&#19978;&#26377;&#23616;&#38480;&#24615;&#65292;&#19981;&#33021;&#25429;&#25417;&#21040;&#30495;&#23454;&#19990;&#30028;&#20013;&#22797;&#26434;&#30340;&#20154;&#31867;&#20559;&#22909;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20026;&#26368;&#36817;&#25552;&#20986;&#30340;&#23398;&#20064;&#33539;&#24335;Nash&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#65288;NLHF&#65289;&#25552;&#20379;&#20102;&#29702;&#35770;&#27934;&#23519;&#21147;&#65292;&#35813;&#23398;&#20064;&#33539;&#24335;&#32771;&#34385;&#20102;&#19968;&#20010;&#19968;&#33324;&#30340;&#20559;&#22909;&#27169;&#22411;&#65292;&#24182;&#23558;&#23545;&#40784;&#36807;&#31243;&#23450;&#20041;&#20026;&#20004;&#20010;&#31454;&#20105;&#30340;LLM&#20043;&#38388;&#30340;&#21338;&#24328;&#12290;&#23398;&#20064;&#30446;&#26631;&#26159;&#25214;&#21040;&#19968;&#20010;&#19968;&#33268;&#29983;&#25104;&#21709;&#24212;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning from Human Feedback (RLHF) learns from the preference signal provided by a probabilistic preference model, which takes a prompt and two responses as input, and produces a score indicating the preference of one response against another. So far, the most popular RLHF paradigm is reward-based, which starts with an initial step of reward modeling, and the constructed reward is then used to provide a reward signal for the subsequent reward optimization stage. However, the existence of a reward function is a strong assumption and the reward-based RLHF is limited in expressivity and cannot capture the real-world complicated human preference.   In this work, we provide theoretical insights for a recently proposed learning paradigm, Nash learning from human feedback (NLHF), which considered a general preference model and formulated the alignment process as a game between two competitive LLMs. The learning objective is to find a policy that consistently generates responses
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20351;&#29992;&#34892;&#21015;&#24335;&#25277;&#26679;&#36827;&#34892;&#20449;&#21495;&#37325;&#24314;&#30340;&#26041;&#27861;&#65292;&#22312;&#26377;&#38480;&#25968;&#37327;&#30340;&#38543;&#26426;&#33410;&#28857;&#35780;&#20272;&#20013;&#36817;&#20284;&#34920;&#31034;&#26041;&#21487;&#31215;&#20989;&#25968;&#65292;&#23454;&#29616;&#20102;&#24555;&#36895;&#25910;&#25947;&#21644;&#26356;&#39640;&#30340;&#36866;&#24212;&#24615;&#27491;&#21017;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.09437</link><description>&lt;p&gt;
&#20351;&#29992;&#34892;&#21015;&#24335;&#25277;&#26679;&#36827;&#34892;&#20449;&#21495;&#37325;&#24314;
&lt;/p&gt;
&lt;p&gt;
Signal reconstruction using determinantal sampling. (arXiv:2310.09437v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09437
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20351;&#29992;&#34892;&#21015;&#24335;&#25277;&#26679;&#36827;&#34892;&#20449;&#21495;&#37325;&#24314;&#30340;&#26041;&#27861;&#65292;&#22312;&#26377;&#38480;&#25968;&#37327;&#30340;&#38543;&#26426;&#33410;&#28857;&#35780;&#20272;&#20013;&#36817;&#20284;&#34920;&#31034;&#26041;&#21487;&#31215;&#20989;&#25968;&#65292;&#23454;&#29616;&#20102;&#24555;&#36895;&#25910;&#25947;&#21644;&#26356;&#39640;&#30340;&#36866;&#24212;&#24615;&#27491;&#21017;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20174;&#38543;&#26426;&#33410;&#28857;&#30340;&#26377;&#38480;&#25968;&#37327;&#35780;&#20272;&#20013;&#36817;&#20284;&#34920;&#31034;&#19968;&#20010;&#26041;&#21487;&#31215;&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#38543;&#26426;&#33410;&#28857;&#30340;&#36873;&#25321;&#20381;&#25454;&#26159;&#19968;&#20010;&#31934;&#24515;&#36873;&#25321;&#30340;&#20998;&#24067;&#12290;&#24403;&#20989;&#25968;&#34987;&#20551;&#35774;&#23646;&#20110;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#26102;&#65292;&#36825;&#23588;&#20026;&#30456;&#20851;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#23558;&#22522;&#20110;&#20004;&#31181;&#21487;&#33021;&#30340;&#33410;&#28857;&#27010;&#29575;&#20998;&#24067;&#30340;&#20960;&#20010;&#33258;&#28982;&#26377;&#38480;&#32500;&#36924;&#36817;&#26041;&#27861;&#30456;&#32467;&#21512;&#12290;&#36825;&#20123;&#27010;&#29575;&#20998;&#24067;&#19982;&#34892;&#21015;&#24335;&#28857;&#36807;&#31243;&#30456;&#20851;&#65292;&#24182;&#21033;&#29992;RKHS&#30340;&#26680;&#20989;&#25968;&#26469;&#20248;&#21270;&#22312;&#38543;&#26426;&#35774;&#35745;&#20013;&#30340;RKHS&#36866;&#24212;&#24615;&#27491;&#21017;&#24615;&#12290;&#34429;&#28982;&#20808;&#21069;&#30340;&#34892;&#21015;&#24335;&#25277;&#26679;&#24037;&#20316;&#20381;&#36182;&#20110;RKHS&#33539;&#25968;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;$L^2$&#33539;&#25968;&#19979;&#30340;&#22343;&#26041;&#20445;&#35777;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#34892;&#21015;&#24335;&#28857;&#36807;&#31243;&#21450;&#20854;&#28151;&#21512;&#20307;&#21487;&#20197;&#20135;&#29983;&#24555;&#36895;&#25910;&#25947;&#36895;&#24230;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#36824;&#25581;&#31034;&#20102;&#24403;&#20551;&#35774;&#26356;&#22810;&#30340;&#24179;&#28369;&#24615;&#26102;&#25910;&#25947;&#36895;&#24230;&#22914;&#20309;&#21464;&#21270;&#65292;&#36825;&#31181;&#29616;&#35937;&#34987;&#31216;&#20026;&#36229;&#25910;&#25947;&#12290;&#27492;&#22806;&#65292;&#34892;&#21015;&#24335;&#25277;&#26679;&#25512;&#24191;&#20102;&#20174;Christoffel&#20989;&#25968;&#36827;&#34892;i.i.d.&#25277;&#26679;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the approximation of a square-integrable function from a finite number of evaluations on a random set of nodes according to a well-chosen distribution. This is particularly relevant when the function is assumed to belong to a reproducing kernel Hilbert space (RKHS). This work proposes to combine several natural finite-dimensional approximations based two possible probability distributions of nodes. These distributions are related to determinantal point processes, and use the kernel of the RKHS to favor RKHS-adapted regularity in the random design. While previous work on determinantal sampling relied on the RKHS norm, we prove mean-square guarantees in $L^2$ norm. We show that determinantal point processes and mixtures thereof can yield fast convergence rates. Our results also shed light on how the rate changes as more smoothness is assumed, a phenomenon known as superconvergence. Besides, determinantal sampling generalizes i.i.d. sampling from the Christoffel function which is
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#38024;&#23545;&#38169;&#20301;&#22788;&#29702;&#38382;&#39064;&#65292;&#23558;&#20854;&#35270;&#20026;&#27835;&#30103;&#20999;&#25442;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#27010;&#29575;&#27169;&#22411;&#35299;&#20915;&#20102;&#22797;&#22686;&#21644;&#26411;&#20107;&#20214;&#20559;&#24046;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2304.03247</link><description>&lt;p&gt;
&#19968;&#31181;&#22312;&#19981;&#21487;&#36991;&#20813;&#39118;&#38505;&#23384;&#22312;&#19979;&#36827;&#34892;&#22797;&#21457;&#20107;&#20214;&#22240;&#26524;&#20998;&#26512;&#30340;&#36125;&#21494;&#26031;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Bayesian Framework for Causal Analysis of Recurrent Events in Presence of Immortal Risk. (arXiv:2304.03247v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03247
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#38024;&#23545;&#38169;&#20301;&#22788;&#29702;&#38382;&#39064;&#65292;&#23558;&#20854;&#35270;&#20026;&#27835;&#30103;&#20999;&#25442;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#27010;&#29575;&#27169;&#22411;&#35299;&#20915;&#20102;&#22797;&#22686;&#21644;&#26411;&#20107;&#20214;&#20559;&#24046;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#29289;&#21307;&#23398;&#32479;&#35745;&#23398;&#20013;&#23545;&#22797;&#21457;&#20107;&#20214;&#29575;&#30340;&#35266;&#27979;&#30740;&#31350;&#24456;&#24120;&#35265;&#12290;&#36890;&#24120;&#30340;&#30446;&#26631;&#26159;&#22312;&#35268;&#23450;&#30340;&#38543;&#35775;&#26102;&#38388;&#31383;&#21475;&#20869;&#65292;&#20272;&#35745;&#22312;&#19968;&#20010;&#26126;&#30830;&#23450;&#20041;&#30340;&#30446;&#26631;&#20154;&#32676;&#20013;&#20004;&#31181;&#27835;&#30103;&#26041;&#27861;&#30340;&#20107;&#20214;&#29575;&#24046;&#24322;&#12290;&#20351;&#29992;&#35266;&#27979;&#24615;&#32034;&#36180;&#25968;&#25454;&#36827;&#34892;&#20272;&#35745;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#22240;&#20026;&#22312;&#30446;&#26631;&#20154;&#32676;&#30340;&#25104;&#21592;&#36164;&#26684;&#26041;&#38754;&#23450;&#20041;&#26102;&#65292;&#24456;&#23569;&#22312;&#36164;&#26684;&#30830;&#35748;&#26102;&#20934;&#30830;&#20998;&#37197;&#27835;&#30103;&#26041;&#24335;&#12290;&#30446;&#21069;&#30340;&#35299;&#20915;&#26041;&#26696;&#36890;&#24120;&#26159;&#38169;&#20301;&#22788;&#29702;&#65292;&#27604;&#22914;&#22522;&#20110;&#21518;&#32493;&#20998;&#37197;&#65292;&#22312;&#36164;&#26684;&#30830;&#35748;&#26102;&#20998;&#37197;&#27835;&#30103;&#26041;&#24335;&#65292;&#36825;&#20250;&#23558;&#20808;&#21069;&#30340;&#20107;&#20214;&#29575;&#38169;&#35823;&#22320;&#24402;&#22240;&#20110;&#27835;&#30103;-&#20174;&#32780;&#20135;&#29983;&#19981;&#21487;&#36991;&#20813;&#30340;&#39118;&#38505;&#20559;&#24046;&#12290;&#21363;&#20351;&#36164;&#26684;&#21644;&#27835;&#30103;&#24050;&#32463;&#23545;&#40784;&#65292;&#32456;&#27490;&#20107;&#20214;&#36807;&#31243;&#65288;&#20363;&#22914;&#27515;&#20129;&#65289;&#20063;&#32463;&#24120;&#20572;&#27490;&#24863;&#20852;&#36259;&#30340;&#22797;&#21457;&#20107;&#20214;&#36807;&#31243;&#12290;&#21516;&#26679;&#65292;&#36825;&#20004;&#20010;&#36807;&#31243;&#20063;&#21463;&#21040;&#23457;&#26597;&#30340;&#24433;&#21709;&#65292;&#22240;&#27492;&#22312;&#25972;&#20010;&#38543;&#35775;&#26102;&#38388;&#31383;&#21475;&#20869;&#19981;&#33021;&#35266;&#23519;&#21040;&#20107;&#20214;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#38169;&#20301;&#22788;&#29702;&#36716;&#21270;&#20026;&#27835;&#30103;&#20999;&#25442;&#38382;&#39064;&#65306;&#19968;&#20123;&#24739;&#32773;&#22312;&#25972;&#20010;&#38543;&#35775;&#26102;&#38388;&#31383;&#21475;&#20869;&#22362;&#25345;&#19968;&#20010;&#29305;&#23450;&#30340;&#27835;&#30103;&#31574;&#30053;&#65292;&#21478;&#19968;&#20123;&#24739;&#32773;&#22312;&#36825;&#20010;&#26102;&#38388;&#31383;&#21475;&#20869;&#32463;&#21382;&#27835;&#30103;&#31574;&#30053;&#30340;&#20999;&#25442;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#27010;&#29575;&#27169;&#22411;&#65292;&#20854;&#20013;&#21253;&#25324;&#20004;&#20010;&#22522;&#26412;&#20803;&#32032;&#65306;&#36890;&#36807;&#19968;&#20010;&#21512;&#29702;&#30340;&#26102;&#21051;&#20999;&#25442;&#27169;&#22411;&#65292;&#27491;&#30830;&#22320;&#24314;&#27169;&#27835;&#30103;&#20043;&#38388;&#30340;&#20999;&#25442;&#21644;&#19981;&#21487;&#36991;&#20813;&#39118;&#38505;&#65292;&#36890;&#36807;&#23558;&#38750;&#35266;&#23519;&#20107;&#20214;&#27169;&#22411;&#21270;&#20026;&#22797;&#21457;&#20107;&#20214;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#22797;&#22686;&#21644;&#26411;&#20107;&#20214;&#20559;&#24046;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Observational studies of recurrent event rates are common in biomedical statistics. Broadly, the goal is to estimate differences in event rates under two treatments within a defined target population over a specified followup window. Estimation with observational claims data is challenging because while membership in the target population is defined in terms of eligibility criteria, treatment is rarely assigned exactly at the time of eligibility. Ad-hoc solutions to this timing misalignment, such as assigning treatment at eligibility based on subsequent assignment, incorrectly attribute prior event rates to treatment - resulting in immortal risk bias. Even if eligibility and treatment are aligned, a terminal event process (e.g. death) often stops the recurrent event process of interest. Both processes are also censored so that events are not observed over the entire followup window. Our approach addresses misalignment by casting it as a treatment switching problem: some patients are on
&lt;/p&gt;</description></item></channel></rss>