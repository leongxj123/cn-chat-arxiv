<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38598;&#25104;&#31283;&#23450;&#36335;&#24452;&#30340;&#26032;&#31283;&#23450;&#36873;&#25321;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#23454;&#36341;&#20013;&#25552;&#39640;&#29305;&#24449;&#36873;&#25321;&#30340;&#28789;&#25935;&#24230;&#24182;&#26356;&#22909;&#22320;&#26657;&#20934;&#30446;&#26631;&#20551;&#38451;&#24615;&#25968;&#37327;&#12290;</title><link>https://arxiv.org/abs/2403.15877</link><description>&lt;p&gt;
&#38598;&#25104;&#36335;&#24452;&#31283;&#23450;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Integrated path stability selection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15877
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38598;&#25104;&#31283;&#23450;&#36335;&#24452;&#30340;&#26032;&#31283;&#23450;&#36873;&#25321;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#23454;&#36341;&#20013;&#25552;&#39640;&#29305;&#24449;&#36873;&#25321;&#30340;&#28789;&#25935;&#24230;&#24182;&#26356;&#22909;&#22320;&#26657;&#20934;&#30446;&#26631;&#20551;&#38451;&#24615;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31283;&#23450;&#36873;&#25321;&#26159;&#19968;&#31181;&#24191;&#27867;&#29992;&#20110;&#25913;&#21892;&#29305;&#24449;&#36873;&#25321;&#31639;&#27861;&#24615;&#33021;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#24050;&#21457;&#29616;&#31283;&#23450;&#36873;&#25321;&#36807;&#20110;&#20445;&#23432;&#65292;&#23548;&#33268;&#28789;&#25935;&#24230;&#36739;&#20302;&#12290;&#27492;&#22806;&#65292;&#23545;&#26399;&#26395;&#30340;&#20551;&#38451;&#24615;&#25968;&#37327;&#30340;&#29702;&#35770;&#30028;&#38480;E(FP)&#30456;&#23545;&#36739;&#26494;&#65292;&#38590;&#20197;&#30693;&#36947;&#23454;&#36341;&#20013;&#20250;&#26377;&#22810;&#23569;&#20551;&#38451;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#38598;&#25104;&#31283;&#23450;&#36335;&#24452;&#32780;&#38750;&#26368;&#22823;&#21270;&#31283;&#23450;&#36335;&#24452;&#30340;&#26032;&#26041;&#27861;&#12290;&#36825;&#20135;&#29983;&#20102;&#23545;E(FP)&#26356;&#32039;&#23494;&#30340;&#30028;&#38480;&#65292;&#23548;&#33268;&#23454;&#36341;&#20013;&#20855;&#26377;&#26356;&#39640;&#28789;&#25935;&#24230;&#30340;&#29305;&#24449;&#36873;&#25321;&#26631;&#20934;&#65292;&#24182;&#19988;&#22312;&#19982;&#30446;&#26631;E(FP)&#21305;&#37197;&#26041;&#38754;&#26356;&#22909;&#22320;&#26657;&#20934;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#19982;&#21407;&#22987;&#31283;&#23450;&#36873;&#25321;&#31639;&#27861;&#38656;&#35201;&#30456;&#21516;&#25968;&#37327;&#30340;&#35745;&#31639;&#65292;&#19988;&#20165;&#38656;&#35201;&#29992;&#25143;&#25351;&#23450;&#19968;&#20010;&#36755;&#20837;&#21442;&#25968;&#65292;&#21363;E(FP)&#30340;&#30446;&#26631;&#20540;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#24615;&#33021;&#30340;&#29702;&#35770;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15877v1 Announce Type: cross  Abstract: Stability selection is a widely used method for improving the performance of feature selection algorithms. However, stability selection has been found to be highly conservative, resulting in low sensitivity. Further, the theoretical bound on the expected number of false positives, E(FP), is relatively loose, making it difficult to know how many false positives to expect in practice. In this paper, we introduce a novel method for stability selection based on integrating the stability paths rather than maximizing over them. This yields a tighter bound on E(FP), resulting in a feature selection criterion that has higher sensitivity in practice and is better calibrated in terms of matching the target E(FP). Our proposed method requires the same amount of computation as the original stability selection algorithm, and only requires the user to specify one input parameter, a target value for E(FP). We provide theoretical bounds on performance
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#22238;&#24402;&#35774;&#32622;&#19979;&#32473;&#20986;&#20102;Mondrian&#38543;&#26426;&#26862;&#26519;&#30340;&#20272;&#35745;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#21644;&#21435;&#20559;&#36807;&#31243;&#65292;&#20351;&#20854;&#33021;&#22815;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#21644;&#23454;&#29616;&#26368;&#23567;&#26497;&#22823;&#20272;&#35745;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.09702</link><description>&lt;p&gt;
&#24102;&#26377;Mondrian&#38543;&#26426;&#26862;&#26519;&#30340;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Inference with Mondrian Random Forests. (arXiv:2310.09702v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09702
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#22238;&#24402;&#35774;&#32622;&#19979;&#32473;&#20986;&#20102;Mondrian&#38543;&#26426;&#26862;&#26519;&#30340;&#20272;&#35745;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#21644;&#21435;&#20559;&#36807;&#31243;&#65292;&#20351;&#20854;&#33021;&#22815;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#21644;&#23454;&#29616;&#26368;&#23567;&#26497;&#22823;&#20272;&#35745;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26862;&#26519;&#26159;&#19968;&#31181;&#24120;&#29992;&#30340;&#20998;&#31867;&#21644;&#22238;&#24402;&#26041;&#27861;&#65292;&#22312;&#26368;&#36817;&#20960;&#24180;&#20013;&#25552;&#20986;&#20102;&#35768;&#22810;&#19981;&#21516;&#30340;&#21464;&#20307;&#12290;&#19968;&#20010;&#26377;&#36259;&#30340;&#20363;&#23376;&#26159;Mondrian&#38543;&#26426;&#26862;&#26519;&#65292;&#20854;&#20013;&#24213;&#23618;&#26641;&#26159;&#26681;&#25454;Mondrian&#36807;&#31243;&#26500;&#24314;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;Mondrian&#38543;&#26426;&#26862;&#26519;&#22312;&#22238;&#24402;&#35774;&#32622;&#19979;&#30340;&#20272;&#35745;&#30340;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#12290;&#24403;&#19982;&#20559;&#24046;&#34920;&#24449;&#21644;&#19968;&#33268;&#26041;&#24046;&#20272;&#35745;&#22120;&#30456;&#32467;&#21512;&#26102;&#65292;&#36825;&#20801;&#35768;&#36827;&#34892;&#28176;&#36817;&#26377;&#25928;&#30340;&#32479;&#35745;&#25512;&#26029;&#65292;&#22914;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#65292;&#23545;&#26410;&#30693;&#30340;&#22238;&#24402;&#20989;&#25968;&#36827;&#34892;&#25512;&#26029;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#31181;&#21435;&#20559;&#36807;&#31243;&#65292;&#29992;&#20110;Mondrian&#38543;&#26426;&#26862;&#26519;&#65292;&#20351;&#20854;&#33021;&#22815;&#22312;&#36866;&#24403;&#30340;&#21442;&#25968;&#35843;&#25972;&#19979;&#23454;&#29616;$\beta$-H\"older&#22238;&#24402;&#20989;&#25968;&#30340;&#26368;&#23567;&#26497;&#22823;&#20272;&#35745;&#36895;&#29575;&#65292;&#23545;&#20110;&#25152;&#26377;&#30340;$\beta$&#21644;&#20219;&#24847;&#32500;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Random forests are popular methods for classification and regression, and many different variants have been proposed in recent years. One interesting example is the Mondrian random forest, in which the underlying trees are constructed according to a Mondrian process. In this paper we give a central limit theorem for the estimates made by a Mondrian random forest in the regression setting. When combined with a bias characterization and a consistent variance estimator, this allows one to perform asymptotically valid statistical inference, such as constructing confidence intervals, on the unknown regression function. We also provide a debiasing procedure for Mondrian random forests which allows them to achieve minimax-optimal estimation rates with $\beta$-H\"older regression functions, for all $\beta$ and in arbitrary dimension, assuming appropriate parameter tuning.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21487;&#36870;&#36830;&#32493;&#26102;&#38388;&#39532;&#23572;&#31185;&#22827;&#38142;&#65292;&#21363;&#8220;&#22240;&#26524;Zig-Zag&#37319;&#26679;&#22120;&#8221;&#65292;&#29992;&#20110;&#25512;&#26029;&#36125;&#21494;&#26031;&#32593;&#32476;&#32467;&#26500;&#12290;&#36890;&#36807;&#20351;&#29992;&#21160;&#37327;&#21464;&#37327;&#65292;&#35813;&#37319;&#26679;&#22120;&#21487;&#20197;&#26174;&#33879;&#25913;&#21892;&#28151;&#21512;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.05655</link><description>&lt;p&gt;
&#20351;&#29992;&#21160;&#37327;&#36827;&#34892;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#65306;&#22312;DAG&#30340;Markov&#31561;&#20215;&#31867;&#19978;&#37319;&#26679;&#20998;&#24067;
&lt;/p&gt;
&lt;p&gt;
Causal structure learning with momentum: Sampling distributions over Markov Equivalence Classes of DAGs. (arXiv:2310.05655v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05655
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21487;&#36870;&#36830;&#32493;&#26102;&#38388;&#39532;&#23572;&#31185;&#22827;&#38142;&#65292;&#21363;&#8220;&#22240;&#26524;Zig-Zag&#37319;&#26679;&#22120;&#8221;&#65292;&#29992;&#20110;&#25512;&#26029;&#36125;&#21494;&#26031;&#32593;&#32476;&#32467;&#26500;&#12290;&#36890;&#36807;&#20351;&#29992;&#21160;&#37327;&#21464;&#37327;&#65292;&#35813;&#37319;&#26679;&#22120;&#21487;&#20197;&#26174;&#33879;&#25913;&#21892;&#28151;&#21512;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25512;&#26029;&#36125;&#21494;&#26031;&#32593;&#32476;&#32467;&#26500;&#65288;&#26377;&#21521;&#26080;&#29615;&#22270;&#65292;DAG&#65289;&#30340;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#38750;&#21487;&#36870;&#36830;&#32493;&#26102;&#38388;&#39532;&#23572;&#31185;&#22827;&#38142;&#65292;&#21363;&#8220;&#22240;&#26524;Zig-Zag&#37319;&#26679;&#22120;&#8221;&#65292;&#35813;&#37319;&#26679;&#22120;&#38024;&#23545;&#19968;&#31867;&#35266;&#27979;&#31561;&#20215;&#65288;Markov&#31561;&#20215;&#65289;DAG&#30340;&#27010;&#29575;&#20998;&#24067;&#12290;&#36825;&#20123;&#31867;&#21035;&#20197;&#23436;&#25104;&#30340;&#37096;&#20998;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;CPDAG&#65289;&#34920;&#31034;&#12290;&#38750;&#21487;&#36870;&#39532;&#23572;&#31185;&#22827;&#38142;&#20381;&#36182;&#20110;Chickering&#30340;&#36138;&#23146;&#31561;&#20215;&#25628;&#32034;&#65288;GES&#65289;&#20013;&#20351;&#29992;&#30340;&#25805;&#20316;&#31526;&#65292;&#24182;&#19988;&#20855;&#26377;&#19968;&#20010;&#21160;&#37327;&#21464;&#37327;&#65292;&#32463;&#23454;&#39564;&#35777;&#26126;&#21487;&#20197;&#26174;&#33879;&#25913;&#21892;&#28151;&#21512;&#24615;&#33021;&#12290;&#21487;&#33021;&#30340;&#30446;&#26631;&#20998;&#24067;&#21253;&#25324;&#22522;&#20110;DAG&#20808;&#39564;&#21644;Markov&#31561;&#20215;&#20284;&#28982;&#30340;&#21518;&#39564;&#20998;&#24067;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#39640;&#25928;&#30340;&#23454;&#29616;&#65292;&#20854;&#20013;&#25105;&#20204;&#24320;&#21457;&#20102;&#26032;&#30340;&#31639;&#27861;&#26469;&#21015;&#20030;&#12289;&#35745;&#25968;&#12289;&#22343;&#21248;&#37319;&#26679;&#21644;&#24212;&#29992;GES&#25805;&#20316;&#31526;&#30340;&#21487;&#33021;&#31227;&#21160;&#65292;&#25152;&#26377;&#36825;&#20123;&#31639;&#27861;&#37117;&#26174;&#33879;&#25913;&#36827;&#20102;&#29616;&#26377;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the context of inferring a Bayesian network structure (directed acyclic graph, DAG for short), we devise a non-reversible continuous time Markov chain, the "Causal Zig-Zag sampler", that targets a probability distribution over classes of observationally equivalent (Markov equivalent) DAGs. The classes are represented as completed partially directed acyclic graphs (CPDAGs). The non-reversible Markov chain relies on the operators used in Chickering's Greedy Equivalence Search (GES) and is endowed with a momentum variable, which improves mixing significantly as we show empirically. The possible target distributions include posterior distributions based on a prior over DAGs and a Markov equivalent likelihood. We offer an efficient implementation wherein we develop new algorithms for listing, counting, uniformly sampling, and applying possible moves of the GES operators, all of which significantly improve upon the state-of-the-art.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#20027;&#21160;&#21644;&#34987;&#21160;&#22240;&#26524;&#25512;&#26029;&#23398;&#20064;&#30340;&#37325;&#35201;&#20551;&#35774;&#21644;&#25216;&#26415;&#65292;&#24182;&#20197;&#35752;&#35770;&#22240;&#26524;&#25512;&#26029;&#30340;&#32570;&#22833;&#26041;&#38754;&#32467;&#26463;&#65292;&#20026;&#35835;&#32773;&#25552;&#20379;&#20102;&#19968;&#20010;&#22810;&#26679;&#24615;&#36215;&#28857;&#12290;</title><link>http://arxiv.org/abs/2308.09248</link><description>&lt;p&gt;
&#20027;&#21160;&#21644;&#34987;&#21160;&#22240;&#26524;&#25512;&#26029;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Active and Passive Causal Inference Learning. (arXiv:2308.09248v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09248
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#20027;&#21160;&#21644;&#34987;&#21160;&#22240;&#26524;&#25512;&#26029;&#23398;&#20064;&#30340;&#37325;&#35201;&#20551;&#35774;&#21644;&#25216;&#26415;&#65292;&#24182;&#20197;&#35752;&#35770;&#22240;&#26524;&#25512;&#26029;&#30340;&#32570;&#22833;&#26041;&#38754;&#32467;&#26463;&#65292;&#20026;&#35835;&#32773;&#25552;&#20379;&#20102;&#19968;&#20010;&#22810;&#26679;&#24615;&#36215;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#26159;&#26426;&#22120;&#23398;&#20064;&#30740;&#31350;&#20154;&#21592;&#12289;&#24037;&#31243;&#24072;&#21644;&#23398;&#29983;&#23545;&#22240;&#26524;&#25512;&#26029;&#24863;&#20852;&#36259;&#20294;&#23578;&#26410;&#29087;&#24713;&#30340;&#19968;&#20010;&#36215;&#28857;&#12290;&#25105;&#20204;&#39318;&#20808;&#21015;&#20030;&#20102;&#19968;&#32452;&#37325;&#35201;&#30340;&#29992;&#20110;&#22240;&#26524;&#35782;&#21035;&#30340;&#20551;&#35774;&#65292;&#22914;&#21487;&#20132;&#25442;&#24615;&#12289;&#31215;&#26497;&#24615;&#12289;&#19968;&#33268;&#24615;&#21644;&#24178;&#25200;&#30340;&#32570;&#22833;&#12290;&#22522;&#20110;&#36825;&#20123;&#20551;&#35774;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#22871;&#37325;&#35201;&#30340;&#22240;&#26524;&#25512;&#26029;&#25216;&#26415;&#65292;&#24182;&#23558;&#20854;&#20998;&#20026;&#20004;&#31867;&#65306;&#20027;&#21160;&#21644;&#34987;&#21160;&#26041;&#27861;&#12290;&#25105;&#20204;&#25551;&#36848;&#21644;&#35752;&#35770;&#20102;&#20027;&#21160;&#26041;&#27861;&#20013;&#30340;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#21644;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;&#28982;&#21518;&#25105;&#20204;&#25551;&#36848;&#20102;&#34987;&#21160;&#26041;&#27861;&#20013;&#30340;&#32463;&#20856;&#26041;&#27861;&#65292;&#22914;&#21305;&#37197;&#21644;&#36870;&#27010;&#29575;&#21152;&#26435;&#65292;&#20197;&#21450;&#26368;&#36817;&#30340;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#31639;&#27861;&#12290;&#36890;&#36807;&#20171;&#32461;&#26412;&#25991;&#20013;&#19968;&#20123;&#22240;&#26524;&#25512;&#26029;&#30340;&#32570;&#22833;&#26041;&#38754;&#65292;&#22914;&#30896;&#25758;&#20559;&#24046;&#65292;&#25105;&#20204;&#26399;&#26395;&#26412;&#25991;&#20026;&#35835;&#32773;&#25552;&#20379;&#20102;&#19968;&#20010;&#22810;&#26679;&#24615;&#36215;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper serves as a starting point for machine learning researchers, engineers and students who are interested in but not yet familiar with causal inference. We start by laying out an important set of assumptions that are collectively needed for causal identification, such as exchangeability, positivity, consistency and the absence of interference. From these assumptions, we build out a set of important causal inference techniques, which we do so by categorizing them into two buckets; active and passive approaches. We describe and discuss randomized controlled trials and bandit-based approaches from the active category. We then describe classical approaches, such as matching and inverse probability weighting, in the passive category, followed by more recent deep learning based algorithms. By finishing the paper with some of the missing aspects of causal inference from this paper, such as collider biases, we expect this paper to provide readers with a diverse set of starting points f
&lt;/p&gt;</description></item></channel></rss>