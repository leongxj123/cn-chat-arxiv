<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#22312;&#21521;&#37327;&#23450;&#20041;&#27880;&#24847;&#21147;&#30340;&#26041;&#27861;&#65292;&#23558;&#26631;&#20934;transformer&#20013;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#20174;&#20108;&#27425;&#26041;&#38477;&#20302;&#21040;&#19982;&#26102;&#38388;&#32447;&#24615;&#30456;&#20851;&#65292;&#34920;&#29616;&#19982;&#26631;&#20934;&#27880;&#24847;&#21147;&#23218;&#32654;&#65292;&#20294;&#20801;&#35768;&#19978;&#19979;&#25991;&#31383;&#21475;&#25193;&#23637;&#21040;&#36828;&#36828;&#36229;&#20986;&#26631;&#20934;&#30340;&#33539;&#22260;&#12290;</title><link>https://arxiv.org/abs/2402.17512</link><description>&lt;p&gt;
Latent Attention for Linear Time Transformers
&lt;/p&gt;
&lt;p&gt;
Latent Attention for Linear Time Transformers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17512
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#22312;&#21521;&#37327;&#23450;&#20041;&#27880;&#24847;&#21147;&#30340;&#26041;&#27861;&#65292;&#23558;&#26631;&#20934;transformer&#20013;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#20174;&#20108;&#27425;&#26041;&#38477;&#20302;&#21040;&#19982;&#26102;&#38388;&#32447;&#24615;&#30456;&#20851;&#65292;&#34920;&#29616;&#19982;&#26631;&#20934;&#27880;&#24847;&#21147;&#23218;&#32654;&#65292;&#20294;&#20801;&#35768;&#19978;&#19979;&#25991;&#31383;&#21475;&#25193;&#23637;&#21040;&#36828;&#36828;&#36229;&#20986;&#26631;&#20934;&#30340;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#20934;transformer&#20013;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#38543;&#30528;&#24207;&#21015;&#38271;&#24230;&#30340;&#22686;&#21152;&#21576;&#20108;&#27425;&#26041;&#22686;&#38271;&#12290;&#25105;&#20204;&#24341;&#20837;&#19968;&#31181;&#36890;&#36807;&#23450;&#20041;&#28508;&#22312;&#21521;&#37327;&#30340;&#27880;&#24847;&#21147;&#26469;&#23558;&#20854;&#38477;&#20302;&#21040;&#19982;&#26102;&#38388;&#32447;&#24615;&#30456;&#20851;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#36731;&#26494;&#20316;&#20026;&#26631;&#20934;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#26367;&#20195;&#21697;&#12290;&#25105;&#20204;&#30340;&#8220;Latte Transformer&#8221;&#27169;&#22411;&#21487;&#29992;&#20110;&#21452;&#21521;&#21644;&#21333;&#21521;&#20219;&#21153;&#65292;&#22240;&#26524;&#29256;&#26412;&#20801;&#35768;&#19968;&#31181;&#22312;&#25512;&#29702;&#35821;&#35328;&#29983;&#25104;&#20219;&#21153;&#20013;&#20869;&#23384;&#21644;&#26102;&#38388;&#39640;&#25928;&#30340;&#36882;&#24402;&#23454;&#29616;&#12290;&#26631;&#20934;transformer&#30340;&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#38543;&#30528;&#24207;&#21015;&#38271;&#24230;&#32447;&#24615;&#22686;&#38271;&#65292;&#32780;Latte Transformer&#35745;&#31639;&#19979;&#19968;&#20010;&#26631;&#35760;&#25152;&#38656;&#30340;&#26102;&#38388;&#26159;&#24658;&#23450;&#30340;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#23454;&#35777;&#34920;&#29616;&#21487;&#19982;&#26631;&#20934;&#27880;&#24847;&#21147;&#23218;&#32654;&#65292;&#20294;&#20801;&#35768;&#23558;&#19978;&#19979;&#25991;&#31383;&#21475;&#25193;&#23637;&#21040;&#36828;&#36828;&#36229;&#20986;&#26631;&#20934;&#27880;&#24847;&#21147;&#23454;&#38469;&#21487;&#34892;&#30340;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17512v1 Announce Type: new  Abstract: The time complexity of the standard attention mechanism in a transformer scales quadratically with the length of the sequence. We introduce a method to reduce this to linear scaling with time, based on defining attention via latent vectors. The method is readily usable as a drop-in replacement for the standard attention mechanism. Our "Latte Transformer" model can be implemented for both bidirectional and unidirectional tasks, with the causal version allowing a recurrent implementation which is memory and time-efficient during inference of language generation tasks. Whilst next token prediction scales linearly with the sequence length for a standard transformer, a Latte Transformer requires constant time to compute the next token. The empirical performance of our method is comparable to standard attention, yet allows scaling to context windows much larger than practical in standard attention.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#25552;&#20379;&#35777;&#25454;&#34920;&#26126;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#31070;&#32463;&#22349;&#22604;&#20027;&#35201;&#26159;&#36890;&#36807;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#36827;&#34892;&#28145;&#24230;&#29305;&#24449;&#23398;&#20064;&#30340;&#65292;&#26435;&#37325;&#30340;&#22855;&#24322;&#32467;&#26500;&#19982;AGOP&#39640;&#24230;&#30456;&#20851;&#65292;&#23548;&#33268;&#31867;&#20869;&#21464;&#24322;&#22349;&#22604;&#12290;</title><link>https://arxiv.org/abs/2402.13728</link><description>&lt;p&gt;
&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#20316;&#20026;&#28145;&#24230;&#31070;&#32463;&#22349;&#22604;&#26426;&#21046;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Average gradient outer product as a mechanism for deep neural collapse
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13728
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25552;&#20379;&#35777;&#25454;&#34920;&#26126;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#31070;&#32463;&#22349;&#22604;&#20027;&#35201;&#26159;&#36890;&#36807;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#36827;&#34892;&#28145;&#24230;&#29305;&#24449;&#23398;&#20064;&#30340;&#65292;&#26435;&#37325;&#30340;&#22855;&#24322;&#32467;&#26500;&#19982;AGOP&#39640;&#24230;&#30456;&#20851;&#65292;&#23548;&#33268;&#31867;&#20869;&#21464;&#24322;&#22349;&#22604;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Deep Neural Collapse (DNC)&#25351;&#30340;&#26159;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#26368;&#21518;&#20960;&#23618;&#25968;&#25454;&#34920;&#31034;&#30340;&#24778;&#20154;&#21018;&#24615;&#32467;&#26500;&#12290;&#23613;&#31649;&#36825;&#31181;&#29616;&#35937;&#22312;&#21508;&#31181;&#24773;&#22659;&#20013;&#37117;&#24471;&#21040;&#20102;&#27979;&#37327;&#65292;&#20294;&#20854;&#20986;&#29616;&#21482;&#26377;&#37096;&#20998;&#34987;&#29702;&#35299;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#20805;&#20998;&#35777;&#25454;&#65292;&#34920;&#26126;DNC&#20027;&#35201;&#26159;&#36890;&#36807;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;(AGOP)&#36827;&#34892;&#28145;&#24230;&#29305;&#24449;&#23398;&#20064;&#32780;&#21457;&#29983;&#30340;&#12290;&#30456;&#27604;&#20110;&#35299;&#37322;&#31070;&#32463;&#22349;&#22604;&#30340;&#29305;&#24449;&#19981;&#21487;&#30693;&#26041;&#27861;&#65292;&#22914;&#26080;&#32422;&#26463;&#29305;&#24449;&#27169;&#22411;&#65292;&#36825;&#19968;&#36827;&#23637;&#26356;&#36827;&#19968;&#27493;&#12290;&#25105;&#20204;&#32487;&#32493;&#25552;&#20379;&#35777;&#25454;&#34920;&#26126;&#65292;&#26435;&#37325;&#30340;&#21491;&#22855;&#24322;&#21521;&#37327;&#21644;&#22855;&#24322;&#20540;&#26159;DNN&#20013;&#31867;&#20869;&#21464;&#24322;&#22349;&#22604;&#30340;&#20027;&#35201;&#22240;&#32032;&#12290;&#27491;&#22914;&#26368;&#36817;&#30340;&#30740;&#31350;&#25152;&#31034;&#65292;&#36825;&#31181;&#22855;&#24322;&#32467;&#26500;&#19982;AGOP&#30340;&#39640;&#24230;&#30456;&#20851;&#12290;&#28982;&#21518;&#25105;&#20204;&#22312;&#23454;&#39564;&#21644;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;AGOP&#22312;&#38543;&#26426;&#21021;&#22987;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#20013;&#24341;&#21457;&#31070;&#32463;&#22349;&#22604;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13728v1 Announce Type: new  Abstract: Deep Neural Collapse (DNC) refers to the surprisingly rigid structure of the data representations in the final layers of Deep Neural Networks (DNNs). Though the phenomenon has been measured in a wide variety of settings, its emergence is only partially understood. In this work, we provide substantial evidence that DNC formation occurs primarily through deep feature learning with the average gradient outer product (AGOP). This takes a step further compared to efforts that explain neural collapse via feature-agnostic approaches, such as the unconstrained features model. We proceed by providing evidence that the right singular vectors and values of the weights are responsible for the majority of within-class variability collapse in DNNs. As shown in recent work, this singular structure is highly correlated with that of the AGOP. We then establish experimentally and theoretically that AGOP induces neural collapse in a randomly initialized ne
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#26816;&#39564;&#26041;&#27861;&#65292;&#36890;&#36807;&#36873;&#25321;&#24615;&#25512;&#26029;&#26694;&#26550;&#65292;&#22312;&#32771;&#34385;&#29983;&#25104;&#22270;&#20687;&#26159;&#30001;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#20135;&#29983;&#30340;&#26465;&#20214;&#19979;&#65292;&#37327;&#21270;&#21307;&#23398;&#22270;&#20687;&#35786;&#26029;&#32467;&#26524;&#30340;&#21487;&#38752;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.11789</link><description>&lt;p&gt;
&#36890;&#36807;&#25193;&#25955;&#27169;&#22411;&#29983;&#25104;&#30340;&#20551;&#35774;&#30340;&#32479;&#35745;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Statistical Test for Generated Hypotheses by Diffusion Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11789
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#26816;&#39564;&#26041;&#27861;&#65292;&#36890;&#36807;&#36873;&#25321;&#24615;&#25512;&#26029;&#26694;&#26550;&#65292;&#22312;&#32771;&#34385;&#29983;&#25104;&#22270;&#20687;&#26159;&#30001;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#20135;&#29983;&#30340;&#26465;&#20214;&#19979;&#65292;&#37327;&#21270;&#21307;&#23398;&#22270;&#20687;&#35786;&#26029;&#32467;&#26524;&#30340;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
AI&#30340;&#22686;&#24378;&#24615;&#33021;&#21152;&#36895;&#20102;&#20854;&#34701;&#20837;&#31185;&#23398;&#30740;&#31350;&#12290;&#29305;&#21035;&#26159;&#65292;&#21033;&#29992;&#29983;&#25104;&#24335;AI&#21019;&#24314;&#31185;&#23398;&#20551;&#35774;&#26159;&#24456;&#26377;&#21069;&#36884;&#30340;&#65292;&#24182;&#19988;&#27491;&#22312;&#36234;&#26469;&#36234;&#22810;&#22320;&#24212;&#29992;&#20110;&#21508;&#20010;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#24403;&#20351;&#29992;AI&#29983;&#25104;&#30340;&#20551;&#35774;&#36827;&#34892;&#20851;&#38190;&#20915;&#31574;&#65288;&#22914;&#21307;&#23398;&#35786;&#26029;&#65289;&#26102;&#65292;&#39564;&#35777;&#23427;&#20204;&#30340;&#21487;&#38752;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#29983;&#25104;&#30340;&#22270;&#20687;&#36827;&#34892;&#21307;&#23398;&#35786;&#26029;&#20219;&#21153;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#26816;&#39564;&#26469;&#37327;&#21270;&#20854;&#21487;&#38752;&#24615;&#12290;&#25152;&#25552;&#20986;&#30340;&#32479;&#35745;&#26816;&#39564;&#30340;&#22522;&#26412;&#24605;&#24819;&#26159;&#20351;&#29992;&#36873;&#25321;&#24615;&#25512;&#26029;&#26694;&#26550;&#65292;&#25105;&#20204;&#32771;&#34385;&#22312;&#29983;&#25104;&#30340;&#22270;&#20687;&#26159;&#30001;&#32463;&#36807;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#20135;&#29983;&#30340;&#36825;&#19968;&#20107;&#23454;&#26465;&#20214;&#19979;&#30340;&#32479;&#35745;&#26816;&#39564;&#12290;&#21033;&#29992;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#21307;&#23398;&#22270;&#20687;&#35786;&#26029;&#32467;&#26524;&#30340;&#32479;&#35745;&#21487;&#38752;&#24615;&#21487;&#20197;&#20197;p&#20540;&#30340;&#24418;&#24335;&#37327;&#21270;&#65292;&#20174;&#32780;&#23454;&#29616;&#22312;&#25511;&#21046;&#38169;&#35823;&#29575;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11789v1 Announce Type: cross  Abstract: The enhanced performance of AI has accelerated its integration into scientific research. In particular, the use of generative AI to create scientific hypotheses is promising and is increasingly being applied across various fields. However, when employing AI-generated hypotheses for critical decisions, such as medical diagnoses, verifying their reliability is crucial. In this study, we consider a medical diagnostic task using generated images by diffusion models, and propose a statistical test to quantify its reliability. The basic idea behind the proposed statistical test is to employ a selective inference framework, where we consider a statistical test conditional on the fact that the generated images are produced by a trained diffusion model. Using the proposed method, the statistical reliability of medical image diagnostic results can be quantified in the form of a p-value, allowing for decision-making with a controlled error rate. 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#26368;&#20248;&#20256;&#36755;&#36827;&#34892;&#20998;&#24067;&#24335;&#23545;&#25239;&#35299;&#37322;&#30340;&#26041;&#27861;DISCOUNT&#65292;&#23558;&#23545;&#25239;&#35299;&#37322;&#30340;&#27010;&#24565;&#25193;&#23637;&#21040;&#25972;&#20010;&#36755;&#20837;&#36755;&#20986;&#20998;&#24067;&#65292;&#24182;&#36890;&#36807;&#32479;&#35745;&#32622;&#20449;&#24230;&#26469;&#25903;&#25745;&#36825;&#19968;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.13112</link><description>&lt;p&gt;
DISCOUNT: &#20351;&#29992;&#26368;&#20248;&#20256;&#36755;&#36827;&#34892;&#20998;&#24067;&#24335;&#23545;&#25239;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
DISCOUNT: Distributional Counterfactual Explanation With Optimal Transport. (arXiv:2401.13112v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13112
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#26368;&#20248;&#20256;&#36755;&#36827;&#34892;&#20998;&#24067;&#24335;&#23545;&#25239;&#35299;&#37322;&#30340;&#26041;&#27861;DISCOUNT&#65292;&#23558;&#23545;&#25239;&#35299;&#37322;&#30340;&#27010;&#24565;&#25193;&#23637;&#21040;&#25972;&#20010;&#36755;&#20837;&#36755;&#20986;&#20998;&#24067;&#65292;&#24182;&#36890;&#36807;&#32479;&#35745;&#32622;&#20449;&#24230;&#26469;&#25903;&#25745;&#36825;&#19968;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#35299;&#37322;&#26159;&#22312;&#40657;&#30418;&#20915;&#31574;&#27169;&#22411;&#20013;&#25552;&#20379;&#27934;&#23519;&#21147;&#21644;&#21487;&#35299;&#37322;&#24615;&#30340;&#20107;&#23454;&#26041;&#27861;&#65292;&#36890;&#36807;&#30830;&#23450;&#23548;&#33268;&#19981;&#21516;&#32467;&#26524;&#30340;&#26367;&#20195;&#36755;&#20837;&#23454;&#20363;&#26469;&#23454;&#29616;&#12290;&#26412;&#25991;&#23558;&#23545;&#25239;&#35299;&#37322;&#30340;&#27010;&#24565;&#25193;&#23637;&#21040;&#20998;&#24067;&#19978;&#19979;&#25991;&#65292;&#20174;&#20010;&#20307;&#25968;&#25454;&#28857;&#25193;&#22823;&#21040;&#25972;&#20010;&#36755;&#20837;&#36755;&#20986;&#20998;&#24067;&#65292;&#21629;&#21517;&#20026;&#20998;&#24067;&#24335;&#23545;&#25239;&#35299;&#37322;&#12290;&#22312;&#20998;&#24067;&#24335;&#23545;&#25239;&#35299;&#37322;&#20013;&#65292;&#25105;&#20204;&#30340;&#37325;&#28857;&#36716;&#21521;&#20998;&#26512;&#20107;&#23454;&#21644;&#23545;&#25239;&#30340;&#20998;&#24067;&#23646;&#24615;&#65292;&#31867;&#20284;&#20110;&#35780;&#20272;&#20010;&#20307;&#23454;&#20363;&#21450;&#20854;&#32467;&#26524;&#20915;&#31574;&#30340;&#32463;&#20856;&#26041;&#27861;&#12290;&#25105;&#20204;&#21033;&#29992;&#26368;&#20248;&#20256;&#36755;&#26469;&#26500;&#24314;&#19968;&#20010;&#26426;&#20250;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#65292;&#26088;&#22312;&#23548;&#20986;&#19982;&#20107;&#23454;&#23545;&#24212;&#30340;&#23545;&#25239;&#20998;&#24067;&#65292;&#20197;&#32479;&#35745;&#32622;&#20449;&#24230;&#20570;&#25903;&#25745;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#20248;&#21270;&#26041;&#27861;DISCOUNT&#22312;&#36755;&#20837;&#21644;&#36755;&#20986;&#20998;&#24067;&#20043;&#38388;&#24179;&#34913;&#36825;&#31181;&#32622;&#20449;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Counterfactual Explanations (CE) is the de facto method for providing insight and interpretability in black-box decision-making models by identifying alternative input instances that lead to different outcomes. This paper extends the concept of CEs to a distributional context, broadening the scope from individual data points to entire input and output distributions, named Distributional Counterfactual Explanation (DCE). In DCE, our focus shifts to analyzing the distributional properties of the factual and counterfactual, drawing parallels to the classical approach of assessing individual instances and their resulting decisions. We leverage Optimal Transport (OT) to frame a chance-constrained optimization problem, aiming to derive a counterfactual distribution that closely aligns with its factual counterpart, substantiated by statistical confidence. Our proposed optimization method, DISCOUNT, strategically balances this confidence across both input and output distributions. This algorit
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#29616;&#26377;&#25216;&#26415;&#23545;&#21327;&#21464;&#37327;&#20998;&#24067;&#30340;&#38480;&#21046;&#38382;&#39064;&#12290;&#30740;&#31350;&#32773;&#20204;&#21457;&#29616;&#65292;&#29616;&#26377;&#26041;&#27861;&#22312;&#22788;&#29702;&#38750;&#39640;&#26031;&#20998;&#24067;&#12289;&#24322;&#36136;&#24615;&#35774;&#35745;&#30697;&#38453;&#21644;&#32570;&#20047;&#21487;&#38752;&#29305;&#24449;&#21327;&#26041;&#24046;&#20272;&#35745;&#26102;&#36935;&#21040;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#20182;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#21033;&#29992;&#32553;&#25918;&#30340;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#36827;&#34892;&#21435;&#20559;&#26657;&#27491;&#12290;</title><link>http://arxiv.org/abs/2309.07810</link><description>&lt;p&gt;
Spectrum-Aware Adjustment: &#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#21450;&#20854;&#22312;&#20027;&#25104;&#20998;&#22238;&#24402;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Spectrum-Aware Adjustment: A New Debiasing Framework with Applications to Principal Components Regression. (arXiv:2309.07810v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07810
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#29616;&#26377;&#25216;&#26415;&#23545;&#21327;&#21464;&#37327;&#20998;&#24067;&#30340;&#38480;&#21046;&#38382;&#39064;&#12290;&#30740;&#31350;&#32773;&#20204;&#21457;&#29616;&#65292;&#29616;&#26377;&#26041;&#27861;&#22312;&#22788;&#29702;&#38750;&#39640;&#26031;&#20998;&#24067;&#12289;&#24322;&#36136;&#24615;&#35774;&#35745;&#30697;&#38453;&#21644;&#32570;&#20047;&#21487;&#38752;&#29305;&#24449;&#21327;&#26041;&#24046;&#20272;&#35745;&#26102;&#36935;&#21040;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#20182;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#21033;&#29992;&#32553;&#25918;&#30340;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#36827;&#34892;&#21435;&#20559;&#26657;&#27491;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#21435;&#20559;&#26041;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#29616;&#20195;&#21435;&#20559;&#25216;&#26415;&#23545;&#21327;&#21464;&#37327;&#20998;&#24067;&#30340;&#32422;&#26463;&#38382;&#39064;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#29305;&#24449;&#25968;&#21644;&#26679;&#26412;&#25968;&#37117;&#24456;&#22823;&#19988;&#30456;&#36817;&#30340;&#26222;&#36941;&#24773;&#20917;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#29616;&#20195;&#21435;&#20559;&#25216;&#26415;&#20351;&#29992;&#33258;&#30001;&#24230;&#26657;&#27491;&#26469;&#38500;&#21435;&#27491;&#21017;&#21270;&#20272;&#35745;&#37327;&#30340;&#25910;&#32553;&#20559;&#24046;&#24182;&#36827;&#34892;&#25512;&#26029;&#12290;&#28982;&#32780;&#65292;&#35813;&#26041;&#27861;&#35201;&#27714;&#35266;&#27979;&#26679;&#26412;&#26159;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#65292;&#21327;&#21464;&#37327;&#36981;&#24490;&#22343;&#20540;&#20026;&#38646;&#30340;&#39640;&#26031;&#20998;&#24067;&#65292;&#24182;&#19988;&#33021;&#22815;&#33719;&#24471;&#21487;&#38752;&#30340;&#29305;&#24449;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#12290;&#24403;&#65288;i&#65289;&#21327;&#21464;&#37327;&#20855;&#26377;&#38750;&#39640;&#26031;&#20998;&#24067;&#12289;&#37325;&#23614;&#25110;&#38750;&#23545;&#31216;&#20998;&#24067;&#65292;&#65288;ii&#65289;&#35774;&#35745;&#30697;&#38453;&#30340;&#34892;&#21576;&#24322;&#36136;&#24615;&#25110;&#23384;&#22312;&#20381;&#36182;&#24615;&#65292;&#20197;&#21450;&#65288;iii&#65289;&#32570;&#20047;&#21487;&#38752;&#30340;&#29305;&#24449;&#21327;&#26041;&#24046;&#20272;&#35745;&#26102;&#65292;&#36825;&#31181;&#26041;&#27861;&#23601;&#20250;&#36935;&#21040;&#22256;&#38590;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#20854;&#20013;&#21435;&#20559;&#26657;&#27491;&#26159;&#19968;&#27493;&#32553;&#25918;&#30340;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#65288;&#36866;&#24403;&#32553;&#25918;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new debiasing framework for high-dimensional linear regression that bypasses the restrictions on covariate distributions imposed by modern debiasing technology. We study the prevalent setting where the number of features and samples are both large and comparable. In this context, state-of-the-art debiasing technology uses a degrees-of-freedom correction to remove shrinkage bias of regularized estimators and conduct inference. However, this method requires that the observed samples are i.i.d., the covariates follow a mean zero Gaussian distribution, and reliable covariance matrix estimates for observed features are available. This approach struggles when (i) covariates are non-Gaussian with heavy tails or asymmetric distributions, (ii) rows of the design exhibit heterogeneity or dependencies, and (iii) reliable feature covariance estimates are lacking.  To address these, we develop a new strategy where the debiasing correction is a rescaled gradient descent step (suitably
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#30005;&#21147;&#36127;&#33655;&#39044;&#27979;&#23384;&#26723;&#65292;&#21253;&#25324;&#36127;&#33655;&#39046;&#22495;&#29305;&#23450;&#30340;&#29305;&#24449;&#24037;&#31243;&#65292;&#24110;&#21161;&#27169;&#22411;&#26356;&#22909;&#22320;&#27169;&#25311;&#36127;&#33655;&#25968;&#25454;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#26469;&#26368;&#23567;&#21270;&#21518;&#32493;&#20219;&#21153;&#30340;&#25104;&#26412;&#12290;</title><link>http://arxiv.org/abs/2307.07191</link><description>&lt;p&gt;
&#29992;&#20110;&#30005;&#21147;&#36127;&#33655;&#39044;&#27979;&#30340;&#22522;&#20934;&#21644;&#33258;&#23450;&#20041;&#21253;
&lt;/p&gt;
&lt;p&gt;
Benchmarks and Custom Package for Electrical Load Forecasting. (arXiv:2307.07191v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07191
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#30005;&#21147;&#36127;&#33655;&#39044;&#27979;&#23384;&#26723;&#65292;&#21253;&#25324;&#36127;&#33655;&#39046;&#22495;&#29305;&#23450;&#30340;&#29305;&#24449;&#24037;&#31243;&#65292;&#24110;&#21161;&#27169;&#22411;&#26356;&#22909;&#22320;&#27169;&#25311;&#36127;&#33655;&#25968;&#25454;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#26469;&#26368;&#23567;&#21270;&#21518;&#32493;&#20219;&#21153;&#30340;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36127;&#33655;&#39044;&#27979;&#22312;&#30005;&#21147;&#34892;&#19994;&#20013;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#65292;&#21487;&#20197;&#20026;&#21518;&#32493;&#20219;&#21153;&#22914;&#30005;&#32593;&#35843;&#24230;&#25552;&#20379;&#21442;&#32771;&#65292;&#20174;&#32780;&#24102;&#26469;&#24040;&#22823;&#30340;&#32463;&#27982;&#25928;&#30410;&#12290;&#28982;&#32780;&#65292;&#36127;&#33655;&#39044;&#27979;&#19982;&#20256;&#32479;&#30340;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20043;&#38388;&#23384;&#22312;&#35768;&#22810;&#24046;&#24322;&#12290;&#19968;&#26041;&#38754;&#65292;&#36127;&#33655;&#39044;&#27979;&#30340;&#30446;&#26631;&#26159;&#26368;&#23567;&#21270;&#21518;&#32493;&#20219;&#21153;&#65288;&#22914;&#30005;&#32593;&#35843;&#24230;&#65289;&#30340;&#25104;&#26412;&#65292;&#32780;&#19981;&#20165;&#20165;&#36861;&#27714;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#36127;&#33655;&#21463;&#21040;&#35768;&#22810;&#22806;&#37096;&#22240;&#32032;&#30340;&#24433;&#21709;&#65292;&#22914;&#28201;&#24230;&#25110;&#26085;&#21382;&#21464;&#37327;&#12290;&#27492;&#22806;&#65292;&#39044;&#27979;&#30340;&#35268;&#27169;&#65288;&#22914;&#24314;&#31569;&#32423;&#36127;&#33655;&#21644;&#32858;&#21512;&#32423;&#36127;&#33655;&#65289;&#20063;&#20250;&#23545;&#39044;&#27979;&#32467;&#26524;&#20135;&#29983;&#37325;&#22823;&#24433;&#21709;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#36127;&#33655;&#39044;&#27979;&#23384;&#26723;&#65292;&#20854;&#20013;&#21253;&#25324;&#36127;&#33655;&#39046;&#22495;&#29305;&#23450;&#30340;&#29305;&#24449;&#24037;&#31243;&#65292;&#20197;&#24110;&#21161;&#39044;&#27979;&#27169;&#22411;&#26356;&#22909;&#22320;&#27169;&#25311;&#36127;&#33655;&#25968;&#25454;&#12290;&#27492;&#22806;&#65292;&#19982;&#20256;&#32479;&#30340;&#25439;&#22833;&#20989;&#25968;&#20165;&#36861;&#27714;&#20934;&#30830;&#24615;&#19981;&#21516;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;...
&lt;/p&gt;
&lt;p&gt;
Load forecasting is of great significance in the power industry as it can provide a reference for subsequent tasks such as power grid dispatch, thus bringing huge economic benefits. However, there are many differences between load forecasting and traditional time series forecasting. On the one hand, load forecasting aims to minimize the cost of subsequent tasks such as power grid dispatch, rather than simply pursuing prediction accuracy. On the other hand, the load is largely influenced by many external factors, such as temperature or calendar variables. In addition, the scale of predictions (such as building-level loads and aggregated-level loads) can also significantly impact the predicted results. In this paper, we provide a comprehensive load forecasting archive, which includes load domain-specific feature engineering to help forecasting models better model load data. In addition, different from the traditional loss function which only aims for accuracy, we also provide a method to
&lt;/p&gt;</description></item></channel></rss>