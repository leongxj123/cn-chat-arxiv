<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36890;&#36807;&#30740;&#31350;&#24046;&#20998;&#38544;&#31169;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;DP-SGD&#65289;&#20013;&#30340;&#24635;&#26799;&#24230;&#26041;&#24046;&#65292;&#25105;&#20204;&#21457;&#29616;&#22823;&#25209;&#27425;&#22823;&#23567;&#26377;&#21161;&#20110;&#20943;&#23567;&#21063;&#37319;&#27171;&#24341;&#36215;&#30340;&#26041;&#24046;&#65292;&#20174;&#32780;&#25552;&#39640;&#20248;&#21270;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.03990</link><description>&lt;p&gt;
&#21063;&#37319;&#27171;&#24182;&#19981;&#26159;&#39764;&#27861;: &#22823;&#25209;&#37327;&#22823;&#23567;&#28858;&#20160;&#40636;&#36969;&#29992;&#26044;&#24046;&#20998;&#38577;&#31169;&#38568;&#27231;&#20778;&#21270;
&lt;/p&gt;
&lt;p&gt;
Subsampling is not Magic: Why Large Batch Sizes Work for Differentially Private Stochastic Optimisation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03990
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#30740;&#31350;&#24046;&#20998;&#38544;&#31169;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;DP-SGD&#65289;&#20013;&#30340;&#24635;&#26799;&#24230;&#26041;&#24046;&#65292;&#25105;&#20204;&#21457;&#29616;&#22823;&#25209;&#27425;&#22823;&#23567;&#26377;&#21161;&#20110;&#20943;&#23567;&#21063;&#37319;&#27171;&#24341;&#36215;&#30340;&#26041;&#24046;&#65292;&#20174;&#32780;&#25552;&#39640;&#20248;&#21270;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20497;&#30740;&#31350;&#20102;&#25209;&#27425;&#22823;&#23567;&#23565;&#24046;&#20998;&#38577;&#31169;&#38568;&#27231;&#26799;&#24230;&#19979;&#38477;&#65288;DP-SGD&#65289;&#20013;&#32317;&#26799;&#24230;&#26041;&#24046;&#30340;&#24433;&#38911;&#65292;&#23563;&#27714;&#23565;&#22823;&#25209;&#27425;&#22823;&#23567;&#26377;&#29992;&#24615;&#30340;&#29702;&#35542;&#35299;&#37323;&#12290;&#30001;&#26044;DP-SGD&#26159;&#29694;&#20195;&#24046;&#20998;&#38577;&#31169;&#28145;&#24230;&#23416;&#32722;&#30340;&#22522;&#30990;&#65292;&#20854;&#24615;&#36074;&#24050;&#34987;&#24291;&#27867;&#30740;&#31350;&#65292;&#26368;&#36817;&#30340;&#24037;&#20316;&#22312;&#23526;&#36368;&#20013;&#30332;&#29694;&#22823;&#25209;&#27425;&#22823;&#23567;&#26377;&#30410;&#12290;&#28982;&#32780;&#65292;&#23565;&#26044;&#36889;&#31278;&#22909;&#34389;&#30340;&#29702;&#35542;&#35299;&#37323;&#30446;&#21069;&#26368;&#22810;&#21482;&#33021;&#35498;&#26159;&#21855;&#30332;&#24335;&#30340;&#12290;&#25105;&#20497;&#39318;&#20808;&#35264;&#23519;&#21040;&#65292;&#22312;DP-SGD&#20013;&#65292;&#32317;&#26799;&#24230;&#26041;&#24046;&#21487;&#20197;&#20998;&#35299;&#28858;&#30001;&#21063;&#37319;&#27171;&#21644;&#22122;&#32882;&#24341;&#36215;&#30340;&#26041;&#24046;&#12290;&#28982;&#24460;&#65292;&#25105;&#20497;&#35657;&#26126;&#22312;&#28961;&#38480;&#27425;&#36845;&#20195;&#30340;&#26997;&#38480;&#24773;&#27841;&#19979;&#65292;&#26377;&#25928;&#30340;&#22122;&#32882;&#24341;&#36215;&#30340;&#26041;&#24046;&#23565;&#25209;&#27425;&#22823;&#23567;&#26159;&#19981;&#35722;&#30340;&#12290;&#21097;&#19979;&#30340;&#21063;&#37319;&#27171;&#24341;&#36215;&#30340;&#26041;&#24046;&#38568;&#33879;&#25209;&#27425;&#22823;&#23567;&#30340;&#22686;&#22823;&#32780;&#28187;&#23567;&#65292;&#22240;&#27492;&#22823;&#25209;&#27425;&#22823;&#23567;&#28187;&#23567;&#20102;&#26377;&#25928;&#30340;&#32317;&#26799;&#24230;&#26041;&#24046;&#12290;&#25105;&#20497;&#22312;&#25976;&#20540;&#19978;&#30906;&#35469;&#36889;&#31278;&#28472;&#36914;&#30340;&#24773;&#27841;&#22312;&#23526;&#38555;&#29872;&#22659;&#20013;&#26159;&#30456;&#38364;&#30340;&#65292;&#30070;&#25209;&#27425;&#22823;&#23567;&#19981;&#23567;&#30340;&#26178;&#20505;&#26371;&#36215;&#20316;&#29992;&#65292;&#20006;&#19988;&#30332;&#29694;
&lt;/p&gt;
&lt;p&gt;
We study the effect of the batch size to the total gradient variance in differentially private stochastic gradient descent (DP-SGD), seeking a theoretical explanation for the usefulness of large batch sizes. As DP-SGD is the basis of modern DP deep learning, its properties have been widely studied, and recent works have empirically found large batch sizes to be beneficial. However, theoretical explanations of this benefit are currently heuristic at best. We first observe that the total gradient variance in DP-SGD can be decomposed into subsampling-induced and noise-induced variances. We then prove that in the limit of an infinite number of iterations, the effective noise-induced variance is invariant to the batch size. The remaining subsampling-induced variance decreases with larger batch sizes, so large batches reduce the effective total gradient variance. We confirm numerically that the asymptotic regime is relevant in practical settings when the batch size is not small, and find tha
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20272;&#35745;&#21644;&#25512;&#26029;&#38382;&#39064;&#65292;&#36890;&#36807;&#20351;&#29992;&#31561;&#20215;&#30830;&#23450;&#27861;&#65292;&#22312;&#25552;&#20379;&#29983;&#25104;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#20197;&#39640;&#25928;&#30340;&#26041;&#24335;&#35299;&#20915;&#20102;&#20998;&#24067;&#24335;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.17262</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20272;&#35745;&#21644;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Estimation and Inference in Distributional Reinforcement Learning. (arXiv:2309.17262v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.17262
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20272;&#35745;&#21644;&#25512;&#26029;&#38382;&#39064;&#65292;&#36890;&#36807;&#20351;&#29992;&#31561;&#20215;&#30830;&#23450;&#27861;&#65292;&#22312;&#25552;&#20379;&#29983;&#25104;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#20197;&#39640;&#25928;&#30340;&#26041;&#24335;&#35299;&#20915;&#20102;&#20998;&#24067;&#24335;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#32479;&#35745;&#25928;&#29575;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#20998;&#24067;&#24335;&#31574;&#30053;&#35780;&#20272;&#65292;&#26088;&#22312;&#20272;&#35745;&#30001;&#32473;&#23450;&#31574;&#30053;&#960;&#33719;&#24471;&#30340;&#38543;&#26426;&#22238;&#25253;&#30340;&#23436;&#25972;&#20998;&#24067;&#65288;&#34920;&#31034;&#20026;&#951;^&#960;&#65289;&#12290;&#22312;&#25552;&#20379;&#29983;&#25104;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#20351;&#29992;&#31561;&#20215;&#30830;&#23450;&#27861;&#26500;&#36896;&#20102;&#20272;&#35745;&#22120;&#951;^&#960;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#20855;&#26377;&#22823;&#23567;&#20026;O(|S||A|/(&#949;^(2p)(1-&#947;)^(2p+2)))&#30340;&#25968;&#25454;&#38598;&#21487;&#20197;&#20445;&#35777;&#20272;&#35745;&#22120;&#951;^&#960;&#21644;&#30495;&#23454;&#20998;&#24067;&#951;^&#960;&#20043;&#38388;&#30340;p-Wasserstein&#36317;&#31163;&#23567;&#20110;&#949;&#30340;&#27010;&#29575;&#24456;&#39640;&#12290;&#36825;&#24847;&#21619;&#30528;&#20998;&#24067;&#24335;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#21487;&#20197;&#20197;&#39640;&#25928;&#21033;&#29992;&#26679;&#26412;&#30340;&#26041;&#24335;&#35299;&#20915;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#65292;&#22312;&#19981;&#21516;&#30340;&#28201;&#21644;&#20551;&#35774;&#19979;&#65292;&#36890;&#36807;&#20855;&#26377;&#22823;&#23567;&#20026;O(|S||A|/(&#949;^2(1-&#947;)^4))&#30340;&#25968;&#25454;&#38598;&#23601;&#36275;&#20197;&#30830;&#20445;Kolmogorov&#36317;&#31163;&#21644;&#24635;&#21464;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study distributional reinforcement learning from the perspective of statistical efficiency.  We investigate distributional policy evaluation, aiming to estimate the complete distribution of the random return (denoted $\eta^\pi$) attained by a given policy $\pi$.  We use the certainty-equivalence method to construct our estimator $\hat\eta^\pi$, given a generative model is available.  We show that in this circumstance we need a dataset of size $\widetilde O\left(\frac{|\mathcal{S}||\mathcal{A}|}{\epsilon^{2p}(1-\gamma)^{2p+2}}\right)$ to guarantee a $p$-Wasserstein metric between $\hat\eta^\pi$ and $\eta^\pi$ is less than $\epsilon$ with high probability.  This implies the distributional policy evaluation problem can be solved with sample efficiency.  Also, we show that under different mild assumptions a dataset of size $\widetilde O\left(\frac{|\mathcal{S}||\mathcal{A}|}{\epsilon^{2}(1-\gamma)^{4}}\right)$ suffices to ensure the Kolmogorov metric and total variation m
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20462;&#25913;&#22240;&#26524;&#26862;&#26519;&#26041;&#27861;&#65292;&#20197;&#30456;&#23545;&#39118;&#38505;&#20026;&#30446;&#26631;&#65292;&#20174;&#32780;&#25429;&#25417;&#21040;&#27835;&#30103;&#25928;&#24212;&#24322;&#36136;&#24615;&#30340;&#28508;&#22312;&#26469;&#28304;&#12290;</title><link>http://arxiv.org/abs/2309.15793</link><description>&lt;p&gt;
&#29992;&#22240;&#26524;&#26862;&#26519;&#38024;&#23545;&#30456;&#23545;&#39118;&#38505;&#24322;&#36136;&#24615;&#36827;&#34892;&#30446;&#26631;&#21270;
&lt;/p&gt;
&lt;p&gt;
Targeting Relative Risk Heterogeneity with Causal Forests. (arXiv:2309.15793v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15793
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20462;&#25913;&#22240;&#26524;&#26862;&#26519;&#26041;&#27861;&#65292;&#20197;&#30456;&#23545;&#39118;&#38505;&#20026;&#30446;&#26631;&#65292;&#20174;&#32780;&#25429;&#25417;&#21040;&#27835;&#30103;&#25928;&#24212;&#24322;&#36136;&#24615;&#30340;&#28508;&#22312;&#26469;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20020;&#24202;&#35797;&#39564;&#20998;&#26512;&#20013;&#65292;&#27835;&#30103;&#25928;&#24212;&#24322;&#36136;&#24615;&#65288;TEH&#65289;&#21363;&#31181;&#32676;&#20013;&#19981;&#21516;&#20122;&#32676;&#30340;&#27835;&#30103;&#25928;&#24212;&#30340;&#21464;&#24322;&#24615;&#26159;&#38750;&#24120;&#37325;&#35201;&#30340;&#12290;&#22240;&#26524;&#26862;&#26519;&#65288;Wager&#21644;Athey&#65292;2018&#65289;&#26159;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#19968;&#31181;&#38750;&#24120;&#27969;&#34892;&#30340;&#26041;&#27861;&#65292;&#20294;&#20687;&#35768;&#22810;&#20854;&#20182;&#21457;&#29616;TEH&#30340;&#26041;&#27861;&#19968;&#26679;&#65292;&#23427;&#29992;&#20110;&#20998;&#31163;&#20122;&#32676;&#30340;&#26631;&#20934;&#20391;&#37325;&#20110;&#32477;&#23545;&#39118;&#38505;&#30340;&#24046;&#24322;&#12290;&#36825;&#21487;&#33021;&#20250;&#21066;&#24369;&#32479;&#35745;&#21151;&#25928;&#65292;&#25513;&#30422;&#20102;&#30456;&#23545;&#39118;&#38505;&#20013;&#30340;&#32454;&#24494;&#24046;&#21035;&#65292;&#32780;&#30456;&#23545;&#39118;&#38505;&#36890;&#24120;&#26159;&#20020;&#24202;&#20851;&#27880;&#30340;&#26356;&#21512;&#36866;&#30340;&#25968;&#37327;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#24182;&#23454;&#29616;&#20102;&#19968;&#31181;&#20462;&#25913;&#22240;&#26524;&#26862;&#26519;&#20197;&#38024;&#23545;&#30456;&#23545;&#39118;&#38505;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#22522;&#20110;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#65288;GLM&#65289;&#27604;&#36739;&#30340;&#26032;&#39062;&#33410;&#28857;&#20998;&#21106;&#36807;&#31243;&#12290;&#25105;&#20204;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#19978;&#23637;&#31034;&#20102;&#32467;&#26524;&#65292;&#34920;&#26126;&#30456;&#23545;&#39118;&#38505;&#30340;&#22240;&#26524;&#26862;&#26519;&#21487;&#20197;&#25429;&#25417;&#21040;&#20854;&#20182;&#26410;&#35266;&#23519;&#21040;&#30340;&#24322;&#36136;&#24615;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;
Treatment effect heterogeneity (TEH), or variability in treatment effect for different subgroups within a population, is of significant interest in clinical trial analysis. Causal forests (Wager and Athey, 2018) is a highly popular method for this problem, but like many other methods for detecting TEH, its criterion for separating subgroups focuses on differences in absolute risk. This can dilute statistical power by masking nuance in the relative risk, which is often a more appropriate quantity of clinical interest. In this work, we propose and implement a methodology for modifying causal forests to target relative risk using a novel node-splitting procedure based on generalized linear model (GLM) comparison. We present results on simulated and real-world data that suggest relative risk causal forests can capture otherwise unobserved sources of heterogeneity.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20272;&#35745;&#22120;MOLAR&#65292;&#23427;&#21033;&#29992;&#21327;&#21516;&#32447;&#24615;&#22238;&#24402;&#21644;&#19978;&#19979;&#25991;&#33218;&#38382;&#39064;&#20013;&#30340;&#31232;&#30095;&#24322;&#36136;&#24615;&#26469;&#25552;&#39640;&#20272;&#35745;&#31934;&#24230;&#65292;&#24182;&#19988;&#30456;&#27604;&#29420;&#31435;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2306.06291</link><description>&lt;p&gt;
&#26368;&#20248;&#24322;&#26500;&#21327;&#21516;&#32447;&#24615;&#22238;&#24402;&#21644;&#19978;&#19979;&#25991;&#33218;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Optimal Heterogeneous Collaborative Linear Regression and Contextual Bandits. (arXiv:2306.06291v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06291
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20272;&#35745;&#22120;MOLAR&#65292;&#23427;&#21033;&#29992;&#21327;&#21516;&#32447;&#24615;&#22238;&#24402;&#21644;&#19978;&#19979;&#25991;&#33218;&#38382;&#39064;&#20013;&#30340;&#31232;&#30095;&#24322;&#36136;&#24615;&#26469;&#25552;&#39640;&#20272;&#35745;&#31934;&#24230;&#65292;&#24182;&#19988;&#30456;&#27604;&#29420;&#31435;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#21644;&#22797;&#26434;&#30340;&#25968;&#25454;&#38598;&#24448;&#24448;&#26469;&#33258;&#20110;&#20960;&#20010;&#21487;&#33021;&#26159;&#24322;&#26500;&#30340;&#26469;&#28304;&#12290;&#21327;&#21516;&#23398;&#20064;&#26041;&#27861;&#36890;&#36807;&#21033;&#29992;&#25968;&#25454;&#38598;&#20043;&#38388;&#30340;&#20849;&#24615;&#25552;&#39640;&#25928;&#29575;&#65292;&#21516;&#26102;&#32771;&#34385;&#21487;&#33021;&#20986;&#29616;&#30340;&#24046;&#24322;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#30740;&#31350;&#21327;&#21516;&#32447;&#24615;&#22238;&#24402;&#21644;&#19978;&#19979;&#25991;&#33218;&#38382;&#39064;&#65292;&#20854;&#20013;&#27599;&#20010;&#23454;&#20363;&#30340;&#30456;&#20851;&#21442;&#25968;&#31561;&#20110;&#20840;&#23616;&#21442;&#25968;&#21152;&#19978;&#19968;&#20010;&#31232;&#30095;&#30340;&#23454;&#20363;&#29305;&#23450;&#26415;&#35821;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;MOLAR&#30340;&#26032;&#22411;&#20108;&#38454;&#27573;&#20272;&#35745;&#22120;&#65292;&#23427;&#36890;&#36807;&#39318;&#20808;&#26500;&#24314;&#23454;&#20363;&#32447;&#24615;&#22238;&#24402;&#20272;&#35745;&#30340;&#36880;&#39033;&#20013;&#20301;&#25968;&#65292;&#28982;&#21518;&#23558;&#23454;&#20363;&#29305;&#23450;&#20272;&#35745;&#20540;&#25910;&#32553;&#21040;&#20013;&#20301;&#25968;&#38468;&#36817;&#26469;&#21033;&#29992;&#36825;&#31181;&#32467;&#26500;&#12290;&#19982;&#29420;&#31435;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#30456;&#27604;&#65292;MOLAR&#25552;&#39640;&#20102;&#20272;&#35745;&#35823;&#24046;&#23545;&#25968;&#25454;&#32500;&#24230;&#30340;&#20381;&#36182;&#24615;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;MOLAR&#24212;&#29992;&#20110;&#24320;&#21457;&#29992;&#20110;&#31232;&#30095;&#24322;&#26500;&#21327;&#21516;&#19978;&#19979;&#25991;&#33218;&#30340;&#26041;&#27861;&#65292;&#36825;&#20123;&#26041;&#27861;&#30456;&#27604;&#29420;&#31435;&#33218;&#27169;&#22411;&#20855;&#26377;&#26356;&#22909;&#30340;&#36951;&#25022;&#20445;&#35777;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#36129;&#29486;&#20248;&#20110;&#20808;&#21069;&#22312;&#25991;&#29486;&#20013;&#25253;&#36947;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large and complex datasets are often collected from several, possibly heterogeneous sources. Collaborative learning methods improve efficiency by leveraging commonalities across datasets while accounting for possible differences among them. Here we study collaborative linear regression and contextual bandits, where each instance's associated parameters are equal to a global parameter plus a sparse instance-specific term. We propose a novel two-stage estimator called MOLAR that leverages this structure by first constructing an entry-wise median of the instances' linear regression estimates, and then shrinking the instance-specific estimates towards the median. MOLAR improves the dependence of the estimation error on the data dimension, compared to independent least squares estimates. We then apply MOLAR to develop methods for sparsely heterogeneous collaborative contextual bandits, which lead to improved regret guarantees compared to independent bandit methods. We further show that our 
&lt;/p&gt;</description></item><item><title>repliclust &#26159;&#19968;&#20010; Python &#21253;&#65292;&#29992;&#20110;&#29983;&#25104;&#20855;&#26377;&#32858;&#31867;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#65292;&#22522;&#20110;&#25968;&#25454;&#38598;&#30340;&#21407;&#22411;&#65292;&#25552;&#20379;&#20102;&#25918;&#32622;&#38598;&#32676;&#20013;&#24515;&#12289;&#37319;&#26679;&#38598;&#32676;&#24418;&#29366;&#12289;&#36873;&#25321;&#27599;&#20010;&#38598;&#32676;&#30340;&#25968;&#25454;&#28857;&#25968;&#37327;&#20197;&#21450;&#20026;&#38598;&#32676;&#20998;&#37197;&#27010;&#29575;&#20998;&#24067;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2303.14301</link><description>&lt;p&gt;
repliclust&#65306;&#32858;&#31867;&#20998;&#26512;&#30340;&#21512;&#25104;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
repliclust: Synthetic Data for Cluster Analysis. (arXiv:2303.14301v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14301
&lt;/p&gt;
&lt;p&gt;
repliclust &#26159;&#19968;&#20010; Python &#21253;&#65292;&#29992;&#20110;&#29983;&#25104;&#20855;&#26377;&#32858;&#31867;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#65292;&#22522;&#20110;&#25968;&#25454;&#38598;&#30340;&#21407;&#22411;&#65292;&#25552;&#20379;&#20102;&#25918;&#32622;&#38598;&#32676;&#20013;&#24515;&#12289;&#37319;&#26679;&#38598;&#32676;&#24418;&#29366;&#12289;&#36873;&#25321;&#27599;&#20010;&#38598;&#32676;&#30340;&#25968;&#25454;&#28857;&#25968;&#37327;&#20197;&#21450;&#20026;&#38598;&#32676;&#20998;&#37197;&#27010;&#29575;&#20998;&#24067;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102; repliclust&#65288;&#26469;&#33258;&#20110; repli-cate &#21644; clust-er&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#29983;&#25104;&#20855;&#26377;&#32858;&#31867;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#30340; Python &#21253;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#25968;&#25454;&#38598;&#30340;&#21407;&#22411;&#65292;&#21363;&#39640;&#32423;&#20960;&#20309;&#25551;&#36848;&#65292;&#29992;&#25143;&#21487;&#20197;&#20174;&#20013;&#21019;&#24314;&#35768;&#22810;&#19981;&#21516;&#30340;&#25968;&#25454;&#38598;&#65292;&#24182;&#20855;&#26377;&#25152;&#38656;&#30340;&#20960;&#20309;&#29305;&#24615;&#12290;&#25105;&#20204;&#36719;&#20214;&#30340;&#26550;&#26500;&#26159;&#27169;&#22359;&#21270;&#21644;&#38754;&#21521;&#23545;&#35937;&#30340;&#65292;&#23558;&#25968;&#25454;&#29983;&#25104;&#20998;&#35299;&#25104;&#25918;&#32622;&#38598;&#32676;&#20013;&#24515;&#30340;&#31639;&#27861;&#12289;&#37319;&#26679;&#38598;&#32676;&#24418;&#29366;&#30340;&#31639;&#27861;&#12289;&#36873;&#25321;&#27599;&#20010;&#38598;&#32676;&#30340;&#25968;&#25454;&#28857;&#25968;&#37327;&#30340;&#31639;&#27861;&#20197;&#21450;&#20026;&#38598;&#32676;&#20998;&#37197;&#27010;&#29575;&#20998;&#24067;&#30340;&#31639;&#27861;&#12290;repliclust.org &#39033;&#30446;&#32593;&#39029;&#25552;&#20379;&#20102;&#31616;&#26126;&#30340;&#29992;&#25143;&#25351;&#21335;&#21644;&#20840;&#38754;&#30340;&#25991;&#26723;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present repliclust (from repli-cate and clust-er), a Python package for generating synthetic data sets with clusters. Our approach is based on data set archetypes, high-level geometric descriptions from which the user can create many different data sets, each possessing the desired geometric characteristics. The architecture of our software is modular and object-oriented, decomposing data generation into algorithms for placing cluster centers, sampling cluster shapes, selecting the number of data points for each cluster, and assigning probability distributions to clusters. The project webpage, repliclust.org, provides a concise user guide and thorough documentation.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#23614;&#24179;&#22343;&#21644;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#23545;&#26102;&#24207;&#24046;&#24322;(TD)&#23398;&#20064;&#31639;&#27861;&#36827;&#34892;&#20102;&#26377;&#38480;&#26102;&#38388;&#34892;&#20026;&#30340;&#30740;&#31350;&#12290;&#25105;&#20204;&#24471;&#20986;&#32467;&#35770;&#65292;&#23614;&#24179;&#22343;TD&#33021;&#20197;&#26368;&#20248;&#36895;&#29575; $O(1/t)$ &#25910;&#25947;&#65292;&#24182;&#19988;&#21021;&#22987;&#35823;&#24046;&#34928;&#20943;&#36895;&#29575;&#26356;&#24555;&#12290;&#27492;&#22806;&#65292;&#27491;&#21017;&#21270;&#30340;TD&#29256;&#26412;&#22312;&#20855;&#26377;&#30149;&#24577;&#29305;&#24449;&#30340;&#38382;&#39064;&#19978;&#24456;&#26377;&#29992;&#12290;</title><link>http://arxiv.org/abs/2210.05918</link><description>&lt;p&gt;
&#26377;&#38480;&#26102;&#38388;&#20869;&#20351;&#29992;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#36827;&#34892;&#26102;&#24207;&#24046;&#24322;&#23398;&#20064;&#30340;&#20998;&#26512;&#65306;&#23614;&#24179;&#22343;&#21644;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Finite time analysis of temporal difference learning with linear function approximation: Tail averaging and regularisation. (arXiv:2210.05918v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.05918
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#23614;&#24179;&#22343;&#21644;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#23545;&#26102;&#24207;&#24046;&#24322;(TD)&#23398;&#20064;&#31639;&#27861;&#36827;&#34892;&#20102;&#26377;&#38480;&#26102;&#38388;&#34892;&#20026;&#30340;&#30740;&#31350;&#12290;&#25105;&#20204;&#24471;&#20986;&#32467;&#35770;&#65292;&#23614;&#24179;&#22343;TD&#33021;&#20197;&#26368;&#20248;&#36895;&#29575; $O(1/t)$ &#25910;&#25947;&#65292;&#24182;&#19988;&#21021;&#22987;&#35823;&#24046;&#34928;&#20943;&#36895;&#29575;&#26356;&#24555;&#12290;&#27492;&#22806;&#65292;&#27491;&#21017;&#21270;&#30340;TD&#29256;&#26412;&#22312;&#20855;&#26377;&#30149;&#24577;&#29305;&#24449;&#30340;&#38382;&#39064;&#19978;&#24456;&#26377;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#27969;&#34892;&#30340;&#26102;&#24207;&#24046;&#24322;(TD)&#23398;&#20064;&#31639;&#27861;&#19982;&#23614;&#24179;&#22343;&#30456;&#32467;&#21512;&#26102;&#30340;&#26377;&#38480;&#26102;&#38388;&#34892;&#20026;&#12290;&#25105;&#20204;&#22312;&#19981;&#38656;&#35201;&#20851;&#20110;&#24213;&#23618;&#25237;&#24433;TD&#19981;&#21160;&#28857;&#30697;&#38453;&#30340;&#29305;&#24449;&#20540;&#20449;&#24687;&#30340;&#27493;&#38271;&#36873;&#25321;&#19979;&#65292;&#25512;&#23548;&#20102;&#23614;&#24179;&#22343;TD&#36845;&#20195;&#30340;&#21442;&#25968;&#35823;&#24046;&#30340;&#26377;&#38480;&#26102;&#38388;&#30028;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#23614;&#24179;&#22343;TD&#20197;&#26399;&#26395;&#36895;&#29575;&#21644;&#39640;&#27010;&#29575;&#25910;&#25947;&#20110;&#26368;&#20248;&#30340; $O(1/t)$ &#36895;&#29575;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#30028;&#38480;&#23637;&#31034;&#20102;&#21021;&#22987;&#35823;&#24046;(&#20559;&#24046;)&#30340;&#26356;&#24555;&#34928;&#20943;&#36895;&#29575;&#65292;&#36825;&#26159;&#23545;&#25152;&#26377;&#36845;&#20195;&#30340;&#24179;&#22343;&#20540;&#30340;&#25913;&#36827;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#24182;&#20998;&#26512;&#20102;&#19968;&#31181;&#32467;&#21512;&#27491;&#21017;&#21270;&#30340;TD&#21464;&#20307;&#12290;&#36890;&#36807;&#20998;&#26512;&#65292;&#25105;&#20204;&#24471;&#20986;&#32467;&#35770;&#35748;&#20026;&#27491;&#21017;&#21270;&#30340;TD&#29256;&#26412;&#22312;&#20855;&#26377;&#30149;&#24577;&#29305;&#24449;&#30340;&#38382;&#39064;&#19978;&#26159;&#26377;&#29992;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the finite-time behaviour of the popular temporal difference (TD) learning algorithm when combined with tail-averaging. We derive finite time bounds on the parameter error of the tail-averaged TD iterate under a step-size choice that does not require information about the eigenvalues of the matrix underlying the projected TD fixed point. Our analysis shows that tail-averaged TD converges at the optimal $O\left(1/t\right)$ rate, both in expectation and with high probability. In addition, our bounds exhibit a sharper rate of decay for the initial error (bias), which is an improvement over averaging all iterates. We also propose and analyse a variant of TD that incorporates regularisation. From analysis, we conclude that the regularised version of TD is useful for problems with ill-conditioned features.
&lt;/p&gt;</description></item></channel></rss>