# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Heterogeneous Multi-agent Zero-Shot Coordination by Coevolution.](http://arxiv.org/abs/2208.04957) | 本研究首次研究了异构零样本协同问题，并提出了一种基于协同进化的通用方法，通过配对、更新和选择的过程，实现了多智能体零样本协同。实验结果表明，考虑异构情况的必要性，并证明了该方法对于异构零样本协同任务的有前景的解决方案。 |

# 详细

[^1]: 异构多智能体零样本协同进化研究

    Heterogeneous Multi-agent Zero-Shot Coordination by Coevolution. (arXiv:2208.04957v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2208.04957](http://arxiv.org/abs/2208.04957)

    本研究首次研究了异构零样本协同问题，并提出了一种基于协同进化的通用方法，通过配对、更新和选择的过程，实现了多智能体零样本协同。实验结果表明，考虑异构情况的必要性，并证明了该方法对于异构零样本协同任务的有前景的解决方案。

    

    在合作多智能体强化学习领域，生成能够与未知合作伙伴零样本协同的智能体是一个新的挑战。最近的一些研究在零样本协同方面取得了进展，通过训练过程中向智能体暴露多样化的合作伙伴。然而，这些方法通常在训练伙伴时涉及自我对弈，隐式地假设任务是同质的。然而，许多真实世界的任务是异构的，因此先前的方法可能效率低下。本文首次研究了异构零样本协同的问题，并提出了一种基于协同进化的通用方法，通过三个子过程：配对、更新和选择，对两个智能体和合作伙伴进行协同进化。对不同异构任务的实验结果突出了考虑异构情况的必要性，并证明我们提出的方法是解决异构零样本协同任务的一种有前景的解决方案。

    Generating agents that can achieve zero-shot coordination (ZSC) with unseen partners is a new challenge in cooperative multi-agent reinforcement learning (MARL). Recently, some studies have made progress in ZSC by exposing the agents to diverse partners during the training process. They usually involve self-play when training the partners, implicitly assuming that the tasks are homogeneous. However, many real-world tasks are heterogeneous, and hence previous methods may be inefficient. In this paper, we study the heterogeneous ZSC problem for the first time and propose a general method based on coevolution, which coevolves two populations of agents and partners through three sub-processes: pairing, updating and selection. Experimental results on various heterogeneous tasks highlight the necessity of considering the heterogeneous setting and demonstrate that our proposed method is a promising solution for heterogeneous ZSC tasks.
    

