<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#25552;&#20986;&#20351;&#29992;LLMs&#21021;&#22987;&#21270;&#22810;&#27169;&#24577;DE&#26816;&#32034;&#31995;&#32479;&#65292;&#23454;&#29616;&#22312;102&#31181;&#35821;&#35328;&#20013;&#21305;&#37197;&#35821;&#38899;&#21644;&#25991;&#26412;&#30340;&#33021;&#21147;&#65292;&#26080;&#38656;&#22312;LLM&#39044;&#35757;&#32451;&#26399;&#38388;&#20351;&#29992;&#35821;&#38899;&#25968;&#25454;&#65292;&#19988;&#30456;&#27604;&#20808;&#21069;&#31995;&#32479;&#21462;&#24471;10%&#30340;Recall@1&#32477;&#23545;&#25913;&#36827;</title><link>https://arxiv.org/abs/2404.01616</link><description>&lt;p&gt;
&#23558;LLMs&#36716;&#21270;&#20026;&#36328;&#27169;&#24577;&#21644;&#36328;&#35821;&#35328;&#26816;&#32034;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Transforming LLMs into Cross-modal and Cross-lingual RetrievalSystems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01616
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20351;&#29992;LLMs&#21021;&#22987;&#21270;&#22810;&#27169;&#24577;DE&#26816;&#32034;&#31995;&#32479;&#65292;&#23454;&#29616;&#22312;102&#31181;&#35821;&#35328;&#20013;&#21305;&#37197;&#35821;&#38899;&#21644;&#25991;&#26412;&#30340;&#33021;&#21147;&#65292;&#26080;&#38656;&#22312;LLM&#39044;&#35757;&#32451;&#26399;&#38388;&#20351;&#29992;&#35821;&#38899;&#25968;&#25454;&#65292;&#19988;&#30456;&#27604;&#20808;&#21069;&#31995;&#32479;&#21462;&#24471;10%&#30340;Recall@1&#32477;&#23545;&#25913;&#36827;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26159;&#22312;&#20165;&#22522;&#20110;&#25991;&#26412;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#30340;&#65292;&#36825;&#36229;&#20986;&#20102;&#20855;&#26377;&#37197;&#23545;&#35821;&#38899;&#21644;&#25991;&#26412;&#25968;&#25454;&#30340;&#35821;&#35328;&#33539;&#22260;&#12290;&#21516;&#26102;&#65292;&#22522;&#20110;&#21452;&#32534;&#30721;&#22120;&#65288;DE&#65289;&#30340;&#26816;&#32034;&#31995;&#32479;&#23558;&#26597;&#35810;&#21644;&#25991;&#26723;&#25237;&#24433;&#21040;&#30456;&#21516;&#30340;&#23884;&#20837;&#31354;&#38388;&#20013;&#65292;&#24182;&#22312;&#26816;&#32034;&#21644;&#21452;&#35821;&#25991;&#26412;&#25366;&#25496;&#20013;&#23637;&#31034;&#20102;&#25104;&#21151;&#12290;&#20026;&#20102;&#22312;&#35768;&#22810;&#35821;&#35328;&#20013;&#21305;&#37197;&#35821;&#38899;&#21644;&#25991;&#26412;&#65292;&#25105;&#20204;&#24314;&#35758;&#20351;&#29992;LLMs&#21021;&#22987;&#21270;&#22810;&#27169;&#24577;DE&#26816;&#32034;&#31995;&#32479;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#31995;&#32479;&#22312;LLM&#39044;&#35757;&#32451;&#26399;&#38388;&#19981;&#38656;&#35201;&#35821;&#38899;&#25968;&#25454;&#65292;&#24182;&#19988;&#21487;&#20197;&#21033;&#29992;LLM&#30340;&#22810;&#35821;&#35328;&#25991;&#26412;&#29702;&#35299;&#33021;&#21147;&#26469;&#21305;&#37197;&#26816;&#32034;&#35757;&#32451;&#26399;&#38388;&#30475;&#19981;&#35265;&#30340;&#35821;&#35328;&#20013;&#30340;&#35821;&#38899;&#21644;&#25991;&#26412;&#12290;&#25105;&#20204;&#30340;&#22810;&#27169;&#24577;LLM-based&#26816;&#32034;&#31995;&#32479;&#33021;&#22815;&#22312;102&#31181;&#35821;&#35328;&#20013;&#21305;&#37197;&#35821;&#38899;&#21644;&#25991;&#26412;&#65292;&#23613;&#31649;&#21482;&#22312;21&#31181;&#35821;&#35328;&#19978;&#36827;&#34892;&#20102;&#35757;&#32451;&#12290;&#25105;&#20204;&#30340;&#31995;&#32479;&#20248;&#20110;&#20808;&#21069;&#19987;&#38376;&#22312;&#25152;&#26377;102&#31181;&#35821;&#35328;&#19978;&#35757;&#32451;&#30340;&#31995;&#32479;&#12290;&#22312;&#36825;&#20123;&#35821;&#35328;&#20013;&#65292;&#25105;&#20204;&#22312;Recall@1&#19978;&#23454;&#29616;&#20102;10&#65285;&#30340;&#32477;&#23545;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01616v1 Announce Type: new  Abstract: Large language models (LLMs) are trained on text-only data that go far beyond the languages with paired speech and text data. At the same time, Dual Encoder (DE) based retrieval systems project queries and documents into the same embedding space and have demonstrated their success in retrieval and bi-text mining. To match speech and text in many languages, we propose using LLMs to initialize multi-modal DE retrieval systems. Unlike traditional methods, our system doesn't require speech data during LLM pre-training and can exploit LLM's multilingual text understanding capabilities to match speech and text in languages unseen during retrieval training. Our multi-modal LLM-based retrieval system is capable of matching speech and text in 102 languages despite only training on 21 languages. Our system outperforms previous systems trained explicitly on all 102 languages. We achieve a 10% absolute improvement in Recall@1 averaged across these l
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25506;&#35752;&#20102;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#32654;&#22269;&#22269;&#20250;&#22270;&#20070;&#39302;&#20027;&#39064;&#26631;&#22836;&#30340;&#28508;&#21147;&#65292;&#23637;&#31034;&#20102;&#20854;&#23545;&#20110;&#35299;&#20915;&#23398;&#26415;&#22270;&#20070;&#39302;&#24453;&#32534;&#30446;&#39033;&#30446;&#31215;&#21387;&#38382;&#39064;&#20855;&#26377;&#25112;&#30053;&#24212;&#23545;&#24847;&#20041;&#65292;&#21516;&#26102;&#20063;&#24378;&#35843;&#20102;&#20154;&#31867;&#32534;&#30446;&#21592;&#20173;&#28982;&#22312;&#39564;&#35777;&#21644;&#22686;&#24378;&#29983;&#25104;&#20027;&#39064;&#26631;&#22836;&#26041;&#38754;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.16424</link><description>&lt;p&gt;
&#20351;&#29992;ChatGPT&#20026;&#30005;&#23376;&#23398;&#20301;&#35770;&#25991;&#25351;&#23450;LCSH&#20027;&#39064;&#30340;&#23454;&#39564;
&lt;/p&gt;
&lt;p&gt;
An Experiment with the Use of ChatGPT for LCSH Subject Assignment on Electronic Theses and Dissertations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16424
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25506;&#35752;&#20102;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#32654;&#22269;&#22269;&#20250;&#22270;&#20070;&#39302;&#20027;&#39064;&#26631;&#22836;&#30340;&#28508;&#21147;&#65292;&#23637;&#31034;&#20102;&#20854;&#23545;&#20110;&#35299;&#20915;&#23398;&#26415;&#22270;&#20070;&#39302;&#24453;&#32534;&#30446;&#39033;&#30446;&#31215;&#21387;&#38382;&#39064;&#20855;&#26377;&#25112;&#30053;&#24212;&#23545;&#24847;&#20041;&#65292;&#21516;&#26102;&#20063;&#24378;&#35843;&#20102;&#20154;&#31867;&#32534;&#30446;&#21592;&#20173;&#28982;&#22312;&#39564;&#35777;&#21644;&#22686;&#24378;&#29983;&#25104;&#20027;&#39064;&#26631;&#22836;&#26041;&#38754;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25506;&#35752;&#20102;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#29983;&#25104;&#32654;&#22269;&#22269;&#20250;&#22270;&#20070;&#39302;&#20027;&#39064;&#26631;&#22836;&#65288;LCSH&#65289;&#30340;&#28508;&#21147;&#12290;&#20316;&#32773;&#20351;&#29992;ChatGPT&#26681;&#25454;&#30005;&#23376;&#23398;&#20301;&#35770;&#25991;&#30340;&#26631;&#39064;&#21644;&#25688;&#35201;&#29983;&#25104;&#20027;&#39064;&#26631;&#22836;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#23613;&#31649;&#19968;&#20123;&#29983;&#25104;&#30340;&#20027;&#39064;&#26631;&#22836;&#26159;&#26377;&#25928;&#30340;&#65292;&#20294;&#23384;&#22312;&#29305;&#23450;&#24615;&#21644;&#35814;&#23613;&#24615;&#26041;&#38754;&#30340;&#38382;&#39064;&#12290;&#35813;&#30740;&#31350;&#23637;&#31034;&#20102;LLMs&#21487;&#20197;&#20316;&#20026;&#23398;&#26415;&#22270;&#20070;&#39302;&#24453;&#32534;&#30446;&#39033;&#30446;&#30340;&#25112;&#30053;&#24615;&#24212;&#23545;&#25514;&#26045;&#65292;&#21516;&#26102;&#20063;&#25552;&#20379;&#20102;&#19968;&#31181;&#25104;&#26412;&#25928;&#30410;&#39640;&#19988;&#24555;&#36895;&#29983;&#25104;LCSH&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#20154;&#31867;&#32534;&#30446;&#21592;&#20173;&#28982;&#26159;&#39564;&#35777;&#21644;&#22686;&#24378;LLMs&#29983;&#25104;&#30340;LCSH&#30340;&#26377;&#25928;&#24615;&#12289;&#35814;&#23613;&#24615;&#21644;&#29305;&#23450;&#24615;&#30340;&#24517;&#35201;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16424v1 Announce Type: new  Abstract: This study delves into the potential use of Large Language Models (LLMs) for generating Library of Congress Subject Headings (LCSH). The authors employed ChatGPT to generate subject headings for electronic theses and dissertations (ETDs) based on their titles and summaries. The results revealed that although some generated subject headings were valid, there were issues regarding specificity and exhaustiveness. The study showcases that LLMs can serve as a strategic response to the backlog of items awaiting cataloging in academic libraries, while also offering a cost-effective approach for promptly generating LCSH. Nonetheless, human catalogers remain essential for verifying and enhancing the validity, exhaustiveness, and specificity of LCSH generated by LLMs.
&lt;/p&gt;</description></item></channel></rss>