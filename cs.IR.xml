<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#22810;&#20010;&#26597;&#35810;&#20197;&#22686;&#24378;&#23545;&#35805;&#21709;&#24212;&#26816;&#32034;&#30340;&#26041;&#27861;&#65292;&#24182;&#22522;&#20110;&#19981;&#21516;LLMs&#23454;&#29616;&#35780;&#20272;&#65292;&#21516;&#26102;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;TREC iKAT&#22522;&#20934;&#12290;</title><link>https://arxiv.org/abs/2403.19302</link><description>&lt;p&gt;
&#29983;&#25104;&#28982;&#21518;&#26816;&#32034;&#65306;&#20351;&#29992;LLM&#20316;&#20026;&#31572;&#26696;&#21644;&#26597;&#35810;&#29983;&#25104;&#22120;&#30340;&#23545;&#35805;&#21709;&#24212;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Generate then Retrieve: Conversational Response Retrieval Using LLMs as Answer and Query Generators
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19302
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#22810;&#20010;&#26597;&#35810;&#20197;&#22686;&#24378;&#23545;&#35805;&#21709;&#24212;&#26816;&#32034;&#30340;&#26041;&#27861;&#65292;&#24182;&#22522;&#20110;&#19981;&#21516;LLMs&#23454;&#29616;&#35780;&#20272;&#65292;&#21516;&#26102;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;TREC iKAT&#22522;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
CIS&#26159;&#20449;&#24687;&#26816;&#32034;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#39046;&#22495;&#65292;&#19987;&#27880;&#20110;&#24320;&#21457;&#20132;&#20114;&#24335;&#30693;&#35782;&#21161;&#25163;&#12290;&#36825;&#20123;&#31995;&#32479;&#24517;&#39035;&#33021;&#22815;&#29087;&#32451;&#22320;&#29702;&#35299;&#29992;&#25143;&#22312;&#23545;&#35805;&#29615;&#22659;&#20013;&#30340;&#20449;&#24687;&#38656;&#27714;&#65292;&#24182;&#26816;&#32034;&#30456;&#20851;&#20449;&#24687;&#12290;&#20026;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#29616;&#26377;&#26041;&#27861;&#20351;&#29992;&#19968;&#20010;&#31216;&#20026;&#37325;&#20889;&#26597;&#35810;&#30340;&#26597;&#35810;&#26469;&#24314;&#27169;&#29992;&#25143;&#30340;&#20449;&#24687;&#38656;&#27714;&#65292;&#24182;&#23558;&#27492;&#26597;&#35810;&#29992;&#20110;&#27573;&#33853;&#26816;&#32034;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19977;&#31181;&#29992;&#20110;&#29983;&#25104;&#22810;&#20010;&#26597;&#35810;&#20197;&#22686;&#24378;&#26816;&#32034;&#30340;&#19981;&#21516;&#26041;&#27861;&#12290;&#22312;&#36825;&#20123;&#26041;&#27861;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#33021;&#21147;&#26469;&#29702;&#35299;&#29992;&#25143;&#30340;&#20449;&#24687;&#38656;&#27714;&#21644;&#29983;&#25104;&#36866;&#24403;&#30340;&#21709;&#24212;&#65292;&#20197;&#29983;&#25104;&#22810;&#20010;&#26597;&#35810;&#12290;&#25105;&#20204;&#23454;&#29616;&#24182;&#35780;&#20272;&#20102;&#25552;&#20986;&#30340;&#27169;&#22411;&#65292;&#21033;&#29992;&#21253;&#25324;GPT-4&#21644;Llama-2&#22312;&#38646;-shot&#21644;&#23569;-shot&#35774;&#32622;&#20013;&#30340;&#21508;&#31181;LLMs&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22522;&#20110;gpt 3.5&#30340;&#21028;&#26029;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;TREC iKAT&#30340;&#26032;&#22522;&#20934;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#25581;&#31034;&#20102;&#25928;&#26524;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19302v1 Announce Type: new  Abstract: CIS is a prominent area in IR that focuses on developing interactive knowledge assistants. These systems must adeptly comprehend the user's information requirements within the conversational context and retrieve the relevant information. To this aim, the existing approaches model the user's information needs with one query called rewritten query and use this query for passage retrieval. In this paper, we propose three different methods for generating multiple queries to enhance the retrieval. In these methods, we leverage the capabilities of large language models (LLMs) in understanding the user's information need and generating an appropriate response, to generate multiple queries. We implement and evaluate the proposed models utilizing various LLMs including GPT-4 and Llama-2 chat in zero-shot and few-shot settings. In addition, we propose a new benchmark for TREC iKAT based on gpt 3.5 judgments. Our experiments reveal the effectivenes
&lt;/p&gt;</description></item><item><title>MACRec&#26159;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#26088;&#22312;&#36890;&#36807;&#22810;&#26234;&#33021;&#20307;&#21327;&#20316;&#26469;&#22686;&#24378;&#25512;&#33616;&#31995;&#32479;&#65292;&#25552;&#20379;&#20102;&#22810;&#31181;&#19987;&#19994;&#26234;&#33021;&#20307;&#30340;&#21327;&#20316;&#21162;&#21147;&#35299;&#20915;&#25512;&#33616;&#20219;&#21153;&#65292;&#24182;&#25552;&#20379;&#20102;&#24212;&#29992;&#31034;&#20363;&#12290;</title><link>https://arxiv.org/abs/2402.15235</link><description>&lt;p&gt;
&#29992;&#20110;&#25512;&#33616;&#31995;&#32479;&#30340;&#22810;&#26234;&#33021;&#20307;&#21327;&#20316;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Multi-Agent Collaboration Framework for Recommender Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15235
&lt;/p&gt;
&lt;p&gt;
MACRec&#26159;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#26088;&#22312;&#36890;&#36807;&#22810;&#26234;&#33021;&#20307;&#21327;&#20316;&#26469;&#22686;&#24378;&#25512;&#33616;&#31995;&#32479;&#65292;&#25552;&#20379;&#20102;&#22810;&#31181;&#19987;&#19994;&#26234;&#33021;&#20307;&#30340;&#21327;&#20316;&#21162;&#21147;&#35299;&#20915;&#25512;&#33616;&#20219;&#21153;&#65292;&#24182;&#25552;&#20379;&#20102;&#24212;&#29992;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;LLM&#30340;&#26234;&#33021;&#20307;&#22240;&#20854;&#20915;&#31574;&#25216;&#33021;&#21644;&#22788;&#29702;&#22797;&#26434;&#20219;&#21153;&#30340;&#33021;&#21147;&#32780;&#21463;&#21040;&#24191;&#27867;&#20851;&#27880;&#12290;&#37492;&#20110;&#24403;&#21069;&#22312;&#21033;&#29992;&#26234;&#33021;&#20307;&#21327;&#20316;&#33021;&#21147;&#22686;&#24378;&#25512;&#33616;&#31995;&#32479;&#26041;&#38754;&#23384;&#22312;&#30340;&#31354;&#30333;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;MACRec&#65292;&#36825;&#26159;&#19968;&#20010;&#26088;&#22312;&#36890;&#36807;&#22810;&#26234;&#33021;&#20307;&#21327;&#20316;&#22686;&#24378;&#25512;&#33616;&#31995;&#32479;&#30340;&#26032;&#39062;&#26694;&#26550;&#12290;&#19982;&#29616;&#26377;&#20851;&#20110;&#20351;&#29992;&#26234;&#33021;&#20307;&#36827;&#34892;&#29992;&#25143;/&#21830;&#21697;&#27169;&#25311;&#30340;&#24037;&#20316;&#19981;&#21516;&#65292;&#25105;&#20204;&#26088;&#22312;&#37096;&#32626;&#22810;&#26234;&#33021;&#20307;&#30452;&#25509;&#22788;&#29702;&#25512;&#33616;&#20219;&#21153;&#12290;&#22312;&#25105;&#20204;&#30340;&#26694;&#26550;&#20013;&#65292;&#36890;&#36807;&#21508;&#31181;&#19987;&#19994;&#26234;&#33021;&#20307;&#30340;&#21327;&#20316;&#21162;&#21147;&#26469;&#35299;&#20915;&#25512;&#33616;&#20219;&#21153;&#65292;&#21253;&#25324;&#32463;&#29702;&#12289;&#29992;&#25143;/&#21830;&#21697;&#20998;&#26512;&#24072;&#12289;&#21453;&#23556;&#22120;&#12289;&#25628;&#32034;&#22120;&#21644;&#20219;&#21153;&#35299;&#37322;&#22120;&#65292;&#23427;&#20204;&#20855;&#26377;&#19981;&#21516;&#30340;&#24037;&#20316;&#27969;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#24212;&#29992;&#31034;&#20363;&#65292;&#35828;&#26126;&#24320;&#21457;&#20154;&#21592;&#22914;&#20309;&#36731;&#26494;&#22312;&#21508;&#31181;&#25512;&#33616;&#20219;&#21153;&#19978;&#20351;&#29992;MACRec&#65292;&#21253;&#25324;&#35780;&#20998;&#39044;&#27979;&#12289;&#24207;&#21015;&#25512;&#33616;&#12289;&#23545;&#35805;&#25512;&#33616;&#21644;&#35299;&#37322;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15235v1 Announce Type: new  Abstract: LLM-based agents have gained considerable attention for their decision-making skills and ability to handle complex tasks. Recognizing the current gap in leveraging agent capabilities for multi-agent collaboration in recommendation systems, we introduce MACRec, a novel framework designed to enhance recommendation systems through multi-agent collaboration. Unlike existing work on using agents for user/item simulation, we aim to deploy multi-agents to tackle recommendation tasks directly. In our framework, recommendation tasks are addressed through the collaborative efforts of various specialized agents, including Manager, User/Item Analyst, Reflector, Searcher, and Task Interpreter, with different working flows. Furthermore, we provide application examples of how developers can easily use MACRec on various recommendation tasks, including rating prediction, sequential recommendation, conversational recommendation, and explanation generation
&lt;/p&gt;</description></item></channel></rss>