<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#25552;&#20986;&#20102;DGMed&#26694;&#26550;&#65292;&#21033;&#29992;&#22240;&#26524;&#25512;&#26029;&#21644;&#21019;&#26032;&#30340;&#29305;&#24449;&#23545;&#40784;&#26041;&#27861;&#36827;&#34892;&#21452;&#31890;&#24230;&#33647;&#29289;&#25512;&#33616;</title><link>https://arxiv.org/abs/2403.00880</link><description>&lt;p&gt;
&#22522;&#20110;&#22240;&#26524;&#25512;&#26029;&#30340;&#21452;&#31890;&#24230;&#33647;&#29289;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Dual-Granularity Medication Recommendation Based on Causal Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00880
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;DGMed&#26694;&#26550;&#65292;&#21033;&#29992;&#22240;&#26524;&#25512;&#26029;&#21644;&#21019;&#26032;&#30340;&#29305;&#24449;&#23545;&#40784;&#26041;&#27861;&#36827;&#34892;&#21452;&#31890;&#24230;&#33647;&#29289;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#21307;&#30103;&#38656;&#27714;&#22686;&#38271;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#30340;&#36827;&#27493;&#65292;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#30340;&#35786;&#26029;&#21644;&#27835;&#30103;&#31995;&#32479;&#22791;&#21463;&#20851;&#27880;&#12290;&#33647;&#29289;&#25512;&#33616;&#26088;&#22312;&#23558;&#24739;&#32773;&#30340;&#38271;&#26399;&#20581;&#24247;&#35760;&#24405;&#19982;&#21307;&#23398;&#30693;&#35782;&#25972;&#21512;&#65292;&#20026;&#29305;&#23450;&#30142;&#30149;&#25512;&#33616;&#20934;&#30830;&#21644;&#23433;&#20840;&#30340;&#33647;&#29289;&#32452;&#21512;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30740;&#31350;&#23558;&#33647;&#29289;&#25512;&#33616;&#31995;&#32479;&#20165;&#35270;&#20026;&#20256;&#32479;&#25512;&#33616;&#31995;&#32479;&#30340;&#21464;&#20307;&#65292;&#24573;&#35270;&#20102;&#33647;&#29289;&#21644;&#30142;&#30149;&#20043;&#38388;&#30340;&#24322;&#36136;&#24615;&#12290;&#20026;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;DGMed&#65292;&#19968;&#20010;&#29992;&#20110;&#33647;&#29289;&#25512;&#33616;&#30340;&#26694;&#26550;&#12290;DGMed&#21033;&#29992;&#22240;&#26524;&#25512;&#26029;&#25581;&#31034;&#21307;&#23398;&#23454;&#20307;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#29305;&#24449;&#23545;&#40784;&#26041;&#27861;&#26469;&#35299;&#20915;&#24322;&#36136;&#24615;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#35813;&#30740;&#31350;&#39318;&#20808;&#24212;&#29992;&#22240;&#26524;&#25512;&#26029;&#20998;&#26512;&#21382;&#21490;&#35760;&#24405;&#20013;&#33647;&#29289;&#23545;&#29305;&#23450;&#30142;&#30149;&#30340;&#37327;&#21270;&#27835;&#30103;&#25928;&#26524;&#65292;&#25581;&#31034;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00880v1 Announce Type: cross  Abstract: As medical demands grow and machine learning technology advances, AI-based diagnostic and treatment systems are garnering increasing attention. Medication recommendation aims to integrate patients' long-term health records with medical knowledge, recommending accuracy and safe medication combinations for specific conditions. However, most existing researches treat medication recommendation systems merely as variants of traditional recommendation systems, overlooking the heterogeneity between medications and diseases. To address this challenge, we propose DGMed, a framework for medication recommendation. DGMed utilizes causal inference to uncover the connections among medical entities and presents an innovative feature alignment method to tackle heterogeneity issues. Specifically, this study first applies causal inference to analyze the quantified therapeutic effects of medications on specific diseases from historical records, uncoverin
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#30740;&#31350;&#30041;&#23384;&#24341;&#21457;&#30340;&#20559;&#35265;&#65292;&#21457;&#29616;&#25913;&#21464;&#25512;&#33616;&#31639;&#27861;&#20250;&#23548;&#33268;&#25512;&#33616;&#31995;&#32479;&#30340;&#34892;&#20026;&#22312;&#36807;&#28193;&#26399;&#38388;&#19982;&#20854;&#26032;&#31283;&#24577;&#19981;&#21516;&#65292;&#20174;&#32780;&#30772;&#22351;&#20102;A/B&#23454;&#39564;&#20316;&#20026;&#35780;&#20272;RS&#25913;&#36827;&#30340;&#21487;&#38752;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.13959</link><description>&lt;p&gt;
&#20855;&#26377;&#24322;&#26500;&#29992;&#25143;&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#30041;&#23384;&#24341;&#21457;&#20559;&#35265;
&lt;/p&gt;
&lt;p&gt;
Retention Induced Biases in a Recommendation System with Heterogeneous Users
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13959
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#30740;&#31350;&#30041;&#23384;&#24341;&#21457;&#30340;&#20559;&#35265;&#65292;&#21457;&#29616;&#25913;&#21464;&#25512;&#33616;&#31639;&#27861;&#20250;&#23548;&#33268;&#25512;&#33616;&#31995;&#32479;&#30340;&#34892;&#20026;&#22312;&#36807;&#28193;&#26399;&#38388;&#19982;&#20854;&#26032;&#31283;&#24577;&#19981;&#21516;&#65292;&#20174;&#32780;&#30772;&#22351;&#20102;A/B&#23454;&#39564;&#20316;&#20026;&#35780;&#20272;RS&#25913;&#36827;&#30340;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#30740;&#31350;&#20102;&#19968;&#20010;&#20855;&#26377;&#29992;&#25143;&#27969;&#20837;&#21644;&#27969;&#22833;&#21160;&#24577;&#30340;&#25512;&#33616;&#31995;&#32479;&#65288;RS&#65289;&#30340;&#27010;&#24565;&#27169;&#22411;&#12290;&#24403;&#27969;&#20837;&#21644;&#27969;&#22833;&#36798;&#21040;&#24179;&#34913;&#26102;&#65292;&#29992;&#25143;&#20998;&#24067;&#36798;&#21040;&#31283;&#23450;&#29366;&#24577;&#12290;&#25913;&#21464;&#25512;&#33616;&#31639;&#27861;&#20250;&#25913;&#21464;&#31283;&#23450;&#29366;&#24577;&#24182;&#20135;&#29983;&#36807;&#28193;&#26399;&#12290;&#22312;&#36825;&#20010;&#26399;&#38388;&#65292;RS&#30340;&#34892;&#20026;&#19982;&#20854;&#26032;&#31283;&#24577;&#19981;&#21516;&#12290;&#29305;&#21035;&#26159;&#65292;&#22312;&#36807;&#28193;&#26399;&#20869;&#33719;&#24471;&#30340;A/B&#23454;&#39564;&#25351;&#26631;&#26159;RS&#38271;&#26399;&#24615;&#33021;&#30340;&#20559;&#35265;&#25351;&#26631;&#12290;&#28982;&#32780;&#65292;&#23398;&#32773;&#21644;&#23454;&#36341;&#32773;&#32463;&#24120;&#22312;&#24341;&#20837;&#26032;&#31639;&#27861;&#21518;&#19981;&#20037;&#36827;&#34892;A/B&#27979;&#35797;&#20197;&#39564;&#35777;&#20854;&#26377;&#25928;&#24615;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#34987;&#24191;&#27867;&#35748;&#20026;&#26159;&#35780;&#20272;RS&#25913;&#36827;&#30340;&#40644;&#37329;&#26631;&#20934;&#30340;A/B&#23454;&#39564;&#33539;&#24335;&#21487;&#33021;&#20135;&#29983;&#38169;&#35823;&#32467;&#35770;&#12290;&#25105;&#36824;&#31616;&#35201;&#35752;&#35770;&#20102;&#29992;&#25143;&#20445;&#30041;&#21160;&#24577;&#36896;&#25104;&#30340;&#25968;&#25454;&#20559;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13959v1 Announce Type: new  Abstract: I examine a conceptual model of a recommendation system (RS) with user inflow and churn dynamics. When inflow and churn balance out, the user distribution reaches a steady state. Changing the recommendation algorithm alters the steady state and creates a transition period. During this period, the RS behaves differently from its new steady state. In particular, A/B experiment metrics obtained in transition periods are biased indicators of the RS's long term performance. Scholars and practitioners, however, often conduct A/B tests shortly after introducing new algorithms to validate their effectiveness. This A/B experiment paradigm, widely regarded as the gold standard for assessing RS improvements, may consequently yield false conclusions. I also briefly discuss the data bias caused by the user retention dynamics.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20844;&#24179;&#25490;&#21517;&#26631;&#20934;Equal-Opportunity Ranking&#65288;EOR&#65289;&#65292;&#23558;&#24213;&#23618;&#30456;&#20851;&#24615;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#24046;&#24322;&#32771;&#34385;&#22312;&#20869;&#65292;&#36890;&#36807;&#32452;&#20869;&#20844;&#24179;&#25277;&#22870;&#23454;&#29616;&#20844;&#24179;&#25490;&#21517;&#12290;</title><link>https://arxiv.org/abs/2309.01610</link><description>&lt;p&gt;
&#19981;&#21516;&#19981;&#30830;&#23450;&#24615;&#19979;&#30340;&#20844;&#24179;&#25490;&#21517;
&lt;/p&gt;
&lt;p&gt;
Fair Ranking under Disparate Uncertainty
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2309.01610
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20844;&#24179;&#25490;&#21517;&#26631;&#20934;Equal-Opportunity Ranking&#65288;EOR&#65289;&#65292;&#23558;&#24213;&#23618;&#30456;&#20851;&#24615;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#24046;&#24322;&#32771;&#34385;&#22312;&#20869;&#65292;&#36890;&#36807;&#32452;&#20869;&#20844;&#24179;&#25277;&#22870;&#23454;&#29616;&#20844;&#24179;&#25490;&#21517;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25490;&#21517;&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#23558;&#20154;&#31867;&#35780;&#20272;&#32773;&#30340;&#27880;&#24847;&#21147;&#38598;&#20013;&#22312;&#21487;&#31649;&#29702;&#30340;&#36873;&#39033;&#23376;&#38598;&#19978;&#12290;&#23427;&#20316;&#20026;&#20154;&#31867;&#20915;&#31574;&#36807;&#31243;&#30340;&#19968;&#37096;&#20998;&#30340;&#20351;&#29992;&#33539;&#22260;&#20174;&#22312;&#30005;&#23376;&#21830;&#21153;&#32593;&#31449;&#19978;&#23637;&#31034;&#28508;&#22312;&#30456;&#20851;&#20135;&#21697;&#21040;&#20026;&#20154;&#24037;&#23457;&#26597;&#20248;&#20808;&#22788;&#29702;&#22823;&#23398;&#30003;&#35831;&#12290;&#34429;&#28982;&#25490;&#21517;&#21487;&#20197;&#36890;&#36807;&#23558;&#20851;&#27880;&#38598;&#20013;&#22312;&#26368;&#26377;&#21069;&#36884;&#30340;&#36873;&#39033;&#19978;&#20351;&#20154;&#31867;&#35780;&#20272;&#26356;&#21152;&#39640;&#25928;&#65292;&#20294;&#25105;&#20204;&#35748;&#20026;&#65292;&#22914;&#26524;&#24213;&#23618;&#30456;&#20851;&#24615;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#22312;&#19981;&#21516;&#32452;&#21035;&#30340;&#36873;&#39033;&#20043;&#38388;&#23384;&#22312;&#24046;&#24322;&#65292;&#25490;&#21517;&#21487;&#33021;&#20250;&#24341;&#20837;&#19981;&#20844;&#24179;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#36825;&#31181;&#19981;&#30830;&#23450;&#24615;&#24046;&#24322;&#20284;&#20046;&#26222;&#36941;&#23384;&#22312;&#65292;&#24120;&#24120;&#23545;&#23569;&#25968;&#32676;&#20307;&#36896;&#25104;&#25439;&#23475;&#65292;&#22240;&#20026;&#36825;&#20123;&#32676;&#20307;&#30340;&#30456;&#20851;&#24615;&#20272;&#35745;&#21487;&#33021;&#30001;&#20110;&#32570;&#20047;&#25968;&#25454;&#25110;&#21512;&#36866;&#30340;&#29305;&#24449;&#32780;&#20855;&#26377;&#26356;&#39640;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#20844;&#24179;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Equal-Opportunity Ranking&#65288;EOR&#65289;&#20316;&#20026;&#25490;&#21517;&#30340;&#26032;&#20844;&#24179;&#26631;&#20934;&#65292;&#24182;&#23637;&#31034;&#23427;&#23545;&#24212;&#20110;&#22312;&#30456;&#20851;&#36873;&#39033;&#20043;&#38388;&#36827;&#34892;&#32452;&#20869;&#20844;&#24179;&#25277;&#22870;
&lt;/p&gt;
&lt;p&gt;
arXiv:2309.01610v2 Announce Type: replace  Abstract: Ranking is a ubiquitous method for focusing the attention of human evaluators on a manageable subset of options. Its use as part of human decision-making processes ranges from surfacing potentially relevant products on an e-commerce site to prioritizing college applications for human review. While ranking can make human evaluation more effective by focusing attention on the most promising options, we argue that it can introduce unfairness if the uncertainty of the underlying relevance model differs between groups of options. Unfortunately, such disparity in uncertainty appears widespread, often to the detriment of minority groups for which relevance estimates can have higher uncertainty due to a lack of data or appropriate features. To address this fairness issue, we propose Equal-Opportunity Ranking (EOR) as a new fairness criterion for ranking and show that it corresponds to a group-wise fair lottery among the relevant options even
&lt;/p&gt;</description></item><item><title>ChatQA&#26159;&#19968;&#31995;&#21015;&#23545;&#35805;&#38382;&#31572;&#27169;&#22411;&#65292;&#21487;&#20197;&#36798;&#21040;GPT-4&#32423;&#21035;&#30340;&#20934;&#30830;&#24615;&#12290;&#36890;&#36807;&#20004;&#38454;&#27573;&#30340;&#25351;&#20196;&#35843;&#25972;&#26041;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#38646;-shot&#23545;&#35805;&#38382;&#31572;&#20013;&#30340;&#32467;&#26524;&#12290;&#20351;&#29992;&#23494;&#38598;&#26816;&#32034;&#22120;&#36827;&#34892;&#38382;&#31572;&#25968;&#25454;&#38598;&#30340;&#24494;&#35843;&#21487;&#20197;&#23454;&#29616;&#19982;&#26368;&#20808;&#36827;&#30340;&#26597;&#35810;&#37325;&#20889;&#27169;&#22411;&#30456;&#24403;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#38477;&#20302;&#37096;&#32626;&#25104;&#26412;&#12290;ChatQA-70B&#22312;10&#20010;&#23545;&#35805;&#38382;&#31572;&#25968;&#25454;&#38598;&#19978;&#30340;&#24179;&#22343;&#24471;&#20998;&#36229;&#36807;&#20102;GPT-4&#65292;&#19988;&#19981;&#20381;&#36182;&#20110;&#20219;&#20309;&#26469;&#33258;OpenAI GPT&#27169;&#22411;&#30340;&#21512;&#25104;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2401.10225</link><description>&lt;p&gt;
ChatQA: &#26500;&#24314;GPT-4&#32423;&#23545;&#35805;&#38382;&#31572;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
ChatQA: Building GPT-4 Level Conversational QA Models. (arXiv:2401.10225v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10225
&lt;/p&gt;
&lt;p&gt;
ChatQA&#26159;&#19968;&#31995;&#21015;&#23545;&#35805;&#38382;&#31572;&#27169;&#22411;&#65292;&#21487;&#20197;&#36798;&#21040;GPT-4&#32423;&#21035;&#30340;&#20934;&#30830;&#24615;&#12290;&#36890;&#36807;&#20004;&#38454;&#27573;&#30340;&#25351;&#20196;&#35843;&#25972;&#26041;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#38646;-shot&#23545;&#35805;&#38382;&#31572;&#20013;&#30340;&#32467;&#26524;&#12290;&#20351;&#29992;&#23494;&#38598;&#26816;&#32034;&#22120;&#36827;&#34892;&#38382;&#31572;&#25968;&#25454;&#38598;&#30340;&#24494;&#35843;&#21487;&#20197;&#23454;&#29616;&#19982;&#26368;&#20808;&#36827;&#30340;&#26597;&#35810;&#37325;&#20889;&#27169;&#22411;&#30456;&#24403;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#38477;&#20302;&#37096;&#32626;&#25104;&#26412;&#12290;ChatQA-70B&#22312;10&#20010;&#23545;&#35805;&#38382;&#31572;&#25968;&#25454;&#38598;&#19978;&#30340;&#24179;&#22343;&#24471;&#20998;&#36229;&#36807;&#20102;GPT-4&#65292;&#19988;&#19981;&#20381;&#36182;&#20110;&#20219;&#20309;&#26469;&#33258;OpenAI GPT&#27169;&#22411;&#30340;&#21512;&#25104;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;ChatQA&#65292;&#19968;&#31995;&#21015;&#20855;&#26377;GPT-4&#32423;&#21035;&#20934;&#30830;&#24615;&#30340;&#23545;&#35805;&#38382;&#31572;&#27169;&#22411;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#30340;&#25351;&#20196;&#35843;&#25972;&#26041;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#38646;-shot&#23545;&#35805;&#38382;&#31572;&#20013;&#30340;&#32467;&#26524;&#12290;&#20026;&#20102;&#22788;&#29702;&#23545;&#35805;&#38382;&#31572;&#20013;&#30340;&#26816;&#32034;&#38382;&#39064;&#65292;&#25105;&#20204;&#22312;&#22810;&#36718;&#38382;&#31572;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23494;&#38598;&#26816;&#32034;&#22120;&#30340;&#24494;&#35843;&#65292;&#36825;&#26679;&#21487;&#20197;&#25552;&#20379;&#19982;&#20351;&#29992;&#26368;&#20808;&#36827;&#30340;&#26597;&#35810;&#37325;&#20889;&#27169;&#22411;&#30456;&#24403;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#22823;&#22823;&#38477;&#20302;&#37096;&#32626;&#25104;&#26412;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;ChatQA-70B&#21487;&#20197;&#22312;10&#20010;&#23545;&#35805;&#38382;&#31572;&#25968;&#25454;&#38598;&#30340;&#24179;&#22343;&#20998;&#19978;&#36229;&#36807;GPT-4&#65288;54.14 vs. 53.90&#65289;&#65292;&#32780;&#19981;&#20381;&#36182;&#20110;OpenAI GPT&#27169;&#22411;&#30340;&#20219;&#20309;&#21512;&#25104;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we introduce ChatQA, a family of conversational question answering (QA) models, that obtain GPT-4 level accuracies. Specifically, we propose a two-stage instruction tuning method that can significantly improve the zero-shot conversational QA results from large language models (LLMs). To handle retrieval in conversational QA, we fine-tune a dense retriever on a multi-turn QA dataset, which provides comparable results to using the state-of-the-art query rewriting model while largely reducing deployment cost. Notably, our ChatQA-70B can outperform GPT-4 in terms of average score on 10 conversational QA datasets (54.14 vs. 53.90), without relying on any synthetic data from OpenAI GPT models.
&lt;/p&gt;</description></item></channel></rss>