<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21518;&#35757;&#32451;&#23646;&#24615;&#21462;&#28040;&#23398;&#20064;&#65288;PoT-AU&#65289;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35774;&#35745;&#20004;&#37096;&#20998;&#25439;&#22833;&#20989;&#25968;&#65292;&#26088;&#22312;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#20445;&#25252;&#29992;&#25143;&#30340;&#25935;&#24863;&#23646;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.06737</link><description>&lt;p&gt;
&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#36827;&#34892;&#21518;&#35757;&#32451;&#23646;&#24615;&#36951;&#24536;
&lt;/p&gt;
&lt;p&gt;
Post-Training Attribute Unlearning in Recommender Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06737
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21518;&#35757;&#32451;&#23646;&#24615;&#21462;&#28040;&#23398;&#20064;&#65288;PoT-AU&#65289;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35774;&#35745;&#20004;&#37096;&#20998;&#25439;&#22833;&#20989;&#25968;&#65292;&#26088;&#22312;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#20445;&#25252;&#29992;&#25143;&#30340;&#25935;&#24863;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#25512;&#33616;&#31995;&#32479;&#20013;&#26085;&#30410;&#22686;&#38271;&#30340;&#38544;&#31169;&#38382;&#39064;&#65292;&#25512;&#33616;&#21462;&#28040;&#23398;&#20064;&#36234;&#26469;&#36234;&#21463;&#21040;&#20851;&#27880;&#12290;&#29616;&#26377;&#30740;&#31350;&#20027;&#35201;&#20351;&#29992;&#35757;&#32451;&#25968;&#25454;&#65292;&#21363;&#27169;&#22411;&#36755;&#20837;&#65292;&#20316;&#20026;&#21462;&#28040;&#23398;&#20064;&#30446;&#26631;&#12290;&#28982;&#32780;&#65292;&#21363;&#20351;&#27169;&#22411;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#27809;&#26377;&#26126;&#30830;&#36935;&#21040;&#65292;&#25915;&#20987;&#32773;&#20173;&#21487;&#20197;&#20174;&#27169;&#22411;&#20013;&#25552;&#21462;&#31169;&#20154;&#20449;&#24687;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#26410;&#35265;&#20449;&#24687;&#31216;&#20026;&#23646;&#24615;&#65292;&#24182;&#23558;&#20854;&#35270;&#20026;&#21462;&#28040;&#23398;&#20064;&#30446;&#26631;&#12290;&#20026;&#20102;&#20445;&#25252;&#29992;&#25143;&#30340;&#25935;&#24863;&#23646;&#24615;&#65292;&#23646;&#24615;&#21462;&#28040;&#23398;&#20064;&#65288;AU&#65289;&#26088;&#22312;&#20351;&#30446;&#26631;&#23646;&#24615;&#38590;&#20197;&#20998;&#36776;&#12290;&#26412;&#25991;&#20391;&#37325;&#20110;AU&#30340;&#19968;&#20010;&#20005;&#26684;&#20294;&#23454;&#38469;&#30340;&#35774;&#32622;&#65292;&#21363;&#21518;&#35757;&#32451;&#23646;&#24615;&#21462;&#28040;&#23398;&#20064;&#65288;PoT-AU&#65289;&#65292;&#20854;&#20013;&#21462;&#28040;&#23398;&#20064;&#21482;&#33021;&#22312;&#25512;&#33616;&#27169;&#22411;&#35757;&#32451;&#23436;&#25104;&#21518;&#25191;&#34892;&#12290;&#20026;&#20102;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;PoT-AU&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#37096;&#20998;&#25439;&#22833;&#20989;&#25968;&#12290;&#31532;&#19968;&#37096;&#20998;&#26159;&#21487;&#21306;&#20998;&#24615;&#25439;&#22833;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#22522;&#20110;&#20998;&#24067;&#30340;&#24230;&#37327;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06737v1 Announce Type: new  Abstract: With the growing privacy concerns in recommender systems, recommendation unlearning is getting increasing attention. Existing studies predominantly use training data, i.e., model inputs, as unlearning target. However, attackers can extract private information from the model even if it has not been explicitly encountered during training. We name this unseen information as \textit{attribute} and treat it as unlearning target. To protect the sensitive attribute of users, Attribute Unlearning (AU) aims to make target attributes indistinguishable. In this paper, we focus on a strict but practical setting of AU, namely Post-Training Attribute Unlearning (PoT-AU), where unlearning can only be performed after the training of the recommendation model is completed. To address the PoT-AU problem in recommender systems, we propose a two-component loss function. The first component is distinguishability loss, where we design a distribution-based meas
&lt;/p&gt;</description></item></channel></rss>