<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#35813;&#30740;&#31350;&#25506;&#31350;&#20102;&#23494;&#38598;&#26816;&#32034;&#27169;&#22411;&#30340;&#24615;&#33021;&#26159;&#21542;&#36981;&#24490;&#20854;&#20182;&#31070;&#32463;&#27169;&#22411;&#30340;&#32553;&#25918;&#35268;&#24459;&#65292;&#24182;&#25552;&#20986;&#20351;&#29992;&#23545;&#27604;&#23545;&#25968;&#20284;&#28982;&#20316;&#20026;&#35780;&#20272;&#25351;&#26631;&#36827;&#34892;&#20102;&#24191;&#27867;&#23454;&#39564;&#12290;</title><link>https://arxiv.org/abs/2403.18684</link><description>&lt;p&gt;
&#23494;&#38598;&#26816;&#32034;&#30340;&#25193;&#23637;&#35268;&#24459;
&lt;/p&gt;
&lt;p&gt;
Scaling Laws For Dense Retrieval
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18684
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25506;&#31350;&#20102;&#23494;&#38598;&#26816;&#32034;&#27169;&#22411;&#30340;&#24615;&#33021;&#26159;&#21542;&#36981;&#24490;&#20854;&#20182;&#31070;&#32463;&#27169;&#22411;&#30340;&#32553;&#25918;&#35268;&#24459;&#65292;&#24182;&#25552;&#20986;&#20351;&#29992;&#23545;&#27604;&#23545;&#25968;&#20284;&#28982;&#20316;&#20026;&#35780;&#20272;&#25351;&#26631;&#36827;&#34892;&#20102;&#24191;&#27867;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#31070;&#32463;&#27169;&#22411;&#25193;&#23637;&#21040;&#26356;&#22823;&#35268;&#27169;&#24050;&#32463;&#22312;&#22810;&#39033;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#29305;&#21035;&#26159;&#22312;&#35821;&#35328;&#29983;&#25104;&#26041;&#38754;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#31070;&#32463;&#27169;&#22411;&#30340;&#24615;&#33021;&#24120;&#36981;&#24490;&#21487;&#39044;&#27979;&#30340;&#25193;&#23637;&#35268;&#24459;&#65292;&#19982;&#35757;&#32451;&#38598;&#22823;&#23567;&#21644;&#27169;&#22411;&#22823;&#23567;&#31561;&#22240;&#32032;&#30456;&#20851;&#12290;&#36825;&#19968;&#27934;&#23519;&#21147;&#38750;&#24120;&#23453;&#36149;&#65292;&#23588;&#20854;&#26159;&#38543;&#30528;&#22823;&#35268;&#27169;&#23454;&#39564;&#21464;&#24471;&#36234;&#26469;&#36234;&#32791;&#36153;&#36164;&#28304;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#26816;&#32034;&#25351;&#26631;&#30340;&#31163;&#25955;&#24615;&#20197;&#21450;&#26816;&#32034;&#20219;&#21153;&#20013;&#35757;&#32451;&#25968;&#25454;&#21644;&#27169;&#22411;&#22823;&#23567;&#20043;&#38388;&#30340;&#22797;&#26434;&#20851;&#31995;&#65292;&#23494;&#38598;&#26816;&#32034;&#20013;&#30340;&#36825;&#31181;&#25193;&#23637;&#35268;&#24459;&#23578;&#26410;&#24471;&#21040;&#20805;&#20998;&#25506;&#35752;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#23494;&#38598;&#26816;&#32034;&#27169;&#22411;&#30340;&#24615;&#33021;&#26159;&#21542;&#36981;&#24490;&#20854;&#20182;&#31070;&#32463;&#27169;&#22411;&#30340;&#32553;&#25918;&#35268;&#24459;&#12290;&#25105;&#20204;&#24314;&#35758;&#20351;&#29992;&#23545;&#27604;&#23545;&#25968;&#20284;&#28982;&#20316;&#20026;&#35780;&#20272;&#25351;&#26631;&#65292;&#24182;&#23545;&#23454;&#29616;&#20102;&#19981;&#21516;&#21442;&#25968;&#25968;&#37327;&#24182;&#20351;&#29992;&#19981;&#21516;&#25968;&#37327;&#30340;&#25968;&#25454;&#35757;&#32451;&#30340;&#23494;&#38598;&#26816;&#32034;&#27169;&#22411;&#36827;&#34892;&#20102;&#24191;&#27867;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18684v1 Announce Type: cross  Abstract: Scaling up neural models has yielded significant advancements in a wide array of tasks, particularly in language generation. Previous studies have found that the performance of neural models frequently adheres to predictable scaling laws, correlated with factors such as training set size and model size. This insight is invaluable, especially as large-scale experiments grow increasingly resource-intensive. Yet, such scaling law has not been fully explored in dense retrieval due to the discrete nature of retrieval metrics and complex relationships between training data and model sizes in retrieval tasks. In this study, we investigate whether the performance of dense retrieval models follows the scaling law as other neural models. We propose to use contrastive log-likelihood as the evaluation metric and conduct extensive experiments with dense retrieval models implemented with different numbers of parameters and trained with different amo
&lt;/p&gt;</description></item><item><title>&#35774;&#35745;&#19968;&#31181;&#26032;&#39062;&#30340;&#20960;&#36718;&#24037;&#20316;&#27969;&#31243;&#65292;&#19987;&#38376;&#29992;&#20110;&#27861;&#24459;&#26696;&#20363;&#30340;&#30456;&#20851;&#21028;&#26029;&#65292;&#33021;&#22815;&#36890;&#36807;&#27169;&#20223;&#20154;&#31867;&#27880;&#37322;&#32773;&#30340;&#36807;&#31243;&#24182;&#25972;&#21512;&#19987;&#23478;&#25512;&#29702;&#65292;&#25552;&#39640;&#30456;&#20851;&#24615;&#21028;&#26029;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.18405</link><description>&lt;p&gt;
&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#20013;&#30340;&#30456;&#20851;&#24615;&#21028;&#26029;
&lt;/p&gt;
&lt;p&gt;
Leveraging Large Language Models for Relevance Judgments in Legal Case Retrieval
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18405
&lt;/p&gt;
&lt;p&gt;
&#35774;&#35745;&#19968;&#31181;&#26032;&#39062;&#30340;&#20960;&#36718;&#24037;&#20316;&#27969;&#31243;&#65292;&#19987;&#38376;&#29992;&#20110;&#27861;&#24459;&#26696;&#20363;&#30340;&#30456;&#20851;&#21028;&#26029;&#65292;&#33021;&#22815;&#36890;&#36807;&#27169;&#20223;&#20154;&#31867;&#27880;&#37322;&#32773;&#30340;&#36807;&#31243;&#24182;&#25972;&#21512;&#19987;&#23478;&#25512;&#29702;&#65292;&#25552;&#39640;&#30456;&#20851;&#24615;&#21028;&#26029;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25910;&#38598;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#30340;&#30456;&#20851;&#21028;&#20915;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#19988;&#32791;&#26102;&#30340;&#20219;&#21153;&#12290;&#20934;&#30830;&#21028;&#26029;&#20004;&#20010;&#27861;&#24459;&#26696;&#20363;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#38656;&#35201;&#38405;&#35835;&#20887;&#38271;&#30340;&#25991;&#26412;&#24182;&#20855;&#22791;&#39640;&#27700;&#24179;&#30340;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#20197;&#25552;&#21462;&#27861;&#24459;&#20107;&#23454;&#24182;&#20316;&#20986;&#21496;&#27861;&#21028;&#26029;&#12290;&#38543;&#30528;&#20808;&#36827;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20986;&#29616;&#65292;&#19968;&#20123;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#20351;&#29992;LLM&#65288;Large Language Models&#65289;&#36827;&#34892;&#30456;&#20851;&#24615;&#21028;&#26029;&#26159;&#26377;&#21069;&#36884;&#30340;&#12290;&#28982;&#32780;&#65292;&#23558;&#19968;&#33324;&#24615;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24212;&#29992;&#20110;&#27861;&#24459;&#26696;&#20363;&#26816;&#32034;&#20013;&#21487;&#38752;&#30340;&#30456;&#20851;&#24615;&#21028;&#26029;&#30340;&#26041;&#27861;&#23578;&#26410;&#24471;&#21040;&#20805;&#20998;&#25506;&#35752;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#30740;&#31350;&#31354;&#30333;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20960;&#36718;&#24037;&#20316;&#27969;&#31243;&#65292;&#19987;&#38376;&#29992;&#20110;&#27861;&#24459;&#26696;&#20363;&#30340;&#30456;&#20851;&#21028;&#26029;&#12290;&#25152;&#25552;&#20986;&#30340;&#24037;&#20316;&#27969;&#31243;&#23558;&#27880;&#37322;&#36807;&#31243;&#20998;&#35299;&#20026;&#19968;&#31995;&#21015;&#38454;&#27573;&#65292;&#27169;&#20223;&#20154;&#31867;&#27880;&#37322;&#32773;&#25152;&#20351;&#29992;&#30340;&#36807;&#31243;&#65292;&#24182;&#20351;&#19987;&#23478;&#25512;&#29702;&#33021;&#22815;&#28789;&#27963;&#22320;&#25972;&#21512;&#20197;&#22686;&#24378;&#30456;&#20851;&#24615;&#21028;&#26029;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18405v1 Announce Type: new  Abstract: Collecting relevant judgments for legal case retrieval is a challenging and time-consuming task. Accurately judging the relevance between two legal cases requires a considerable effort to read the lengthy text and a high level of domain expertise to extract Legal Facts and make juridical judgments. With the advent of advanced large language models, some recent studies have suggested that it is promising to use LLMs for relevance judgment. Nonetheless, the method of employing a general large language model for reliable relevance judgments in legal case retrieval is yet to be thoroughly explored. To fill this research gap, we devise a novel few-shot workflow tailored to the relevant judgment of legal cases. The proposed workflow breaks down the annotation process into a series of stages, imitating the process employed by human annotators and enabling a flexible integration of expert reasoning to enhance the accuracy of relevance judgments.
&lt;/p&gt;</description></item><item><title>LLM&#36741;&#21161;&#30340;&#22810;&#25945;&#24072;&#25345;&#32493;&#23398;&#20064;&#20026;&#26426;&#22120;&#20154;&#25163;&#26415;&#20013;&#30340;&#35270;&#35273;&#38382;&#31572;&#31995;&#32479;&#26356;&#26032;&#25552;&#20379;&#20102;&#35299;&#20915;&#26032;&#20219;&#21153;&#38656;&#27714;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#35299;&#20915;&#20102;&#22806;&#31185;&#39046;&#22495;&#20013;&#30340;&#22823;&#39046;&#22495;&#36716;&#21464;&#21644;&#25968;&#25454;&#19981;&#24179;&#34913;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.16664</link><description>&lt;p&gt;
LLM&#36741;&#21161;&#30340;&#22810;&#25945;&#24072;&#25345;&#32493;&#23398;&#20064;&#22312;&#26426;&#22120;&#20154;&#25163;&#26415;&#20013;&#30340;&#35270;&#35273;&#38382;&#31572;
&lt;/p&gt;
&lt;p&gt;
LLM-Assisted Multi-Teacher Continual Learning for Visual Question Answering in Robotic Surgery
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16664
&lt;/p&gt;
&lt;p&gt;
LLM&#36741;&#21161;&#30340;&#22810;&#25945;&#24072;&#25345;&#32493;&#23398;&#20064;&#20026;&#26426;&#22120;&#20154;&#25163;&#26415;&#20013;&#30340;&#35270;&#35273;&#38382;&#31572;&#31995;&#32479;&#26356;&#26032;&#25552;&#20379;&#20102;&#35299;&#20915;&#26032;&#20219;&#21153;&#38656;&#27714;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#35299;&#20915;&#20102;&#22806;&#31185;&#39046;&#22495;&#20013;&#30340;&#22823;&#39046;&#22495;&#36716;&#21464;&#21644;&#25968;&#25454;&#19981;&#24179;&#34913;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35270;&#35273;&#38382;&#31572;(VQA)&#22312;&#20419;&#36827;&#26426;&#22120;&#20154;&#36741;&#21161;&#25163;&#26415;&#25945;&#32946;&#26041;&#38754;&#21487;&#33021;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#23398;&#21592;&#30340;&#38656;&#27714;&#19981;&#26029;&#21457;&#23637;&#65292;&#27604;&#22914;&#23398;&#20064;&#26356;&#22810;&#31181;&#31867;&#30340;&#25163;&#26415;&#65292;&#36866;&#24212;&#19981;&#21516;&#30340;&#26426;&#22120;&#20154;&#65292;&#20197;&#21450;&#20026;&#19968;&#31181;&#25163;&#26415;&#23398;&#20064;&#26032;&#30340;&#22806;&#31185;&#22120;&#26800;&#21644;&#25216;&#26415;&#12290;&#22240;&#27492;&#65292;&#22312;&#26426;&#22120;&#20154;&#25163;&#26415;&#20013;&#38656;&#35201;&#36890;&#36807;&#22810;&#20010;&#36164;&#28304;&#30340;&#39034;&#24207;&#25968;&#25454;&#27969;&#25345;&#32493;&#26356;&#26032;VQA&#31995;&#32479;&#65292;&#20197;&#35299;&#20915;&#26032;&#20219;&#21153;&#12290;&#22312;&#22806;&#31185;&#22330;&#26223;&#20013;&#65292;&#23384;&#20648;&#25104;&#26412;&#21644;&#24739;&#32773;&#25968;&#25454;&#38544;&#31169;&#36890;&#24120;&#38480;&#21046;&#20102;&#22312;&#26356;&#26032;&#27169;&#22411;&#26102;&#26087;&#25968;&#25454;&#30340;&#21487;&#29992;&#24615;&#65292;&#36825;&#38656;&#35201;&#19968;&#20010;&#26080;&#26679;&#26412;&#30340;&#25345;&#32493;&#23398;&#20064;(CL)&#35774;&#32622;&#12290;&#28982;&#32780;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#24573;&#35270;&#20102;&#22806;&#31185;&#39046;&#22495;&#30340;&#20004;&#20010;&#37325;&#35201;&#38382;&#39064;&#65306;i)&#26469;&#33258;&#19981;&#21516;&#31185;&#23460;&#25110;&#20020;&#24202;&#20013;&#24515;&#25910;&#38598;&#30340;&#21508;&#31181;&#22806;&#31185;&#25163;&#26415;&#30340;&#22823;&#39046;&#22495;&#36716;&#21464;&#65292;ii)&#30001;&#20110;&#22806;&#31185;&#22120;&#26800;&#25110;&#27963;&#21160;&#30340;&#19981;&#22343;&#21248;&#20986;&#29616;&#32780;&#23548;&#33268;&#30340;&#20005;&#37325;&#25968;&#25454;&#19981;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16664v1 Announce Type: new  Abstract: Visual question answering (VQA) can be fundamentally crucial for promoting robotic-assisted surgical education. In practice, the needs of trainees are constantly evolving, such as learning more surgical types, adapting to different robots, and learning new surgical instruments and techniques for one surgery. Therefore, continually updating the VQA system by a sequential data stream from multiple resources is demanded in robotic surgery to address new tasks. In surgical scenarios, the storage cost and patient data privacy often restrict the availability of old data when updating the model, necessitating an exemplar-free continual learning (CL) setup. However, prior studies overlooked two vital problems of the surgical domain: i) large domain shifts from diverse surgical operations collected from multiple departments or clinical centers, and ii) severe data imbalance arising from the uneven presence of surgical instruments or activities du
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#26465;&#36890;&#21521;&#22810;&#20803;&#23545;&#40784;&#30340;&#36335;&#32447;&#22270;&#65292;&#20197;&#35299;&#20915;&#35774;&#35745;AI&#31995;&#32479;&#33021;&#22815;&#26381;&#21153;&#20110;&#20154;&#20204;&#20855;&#26377;&#19981;&#21516;&#20215;&#20540;&#35266;&#21644;&#35266;&#28857;&#30340;&#38656;&#27714;&#12290;&#35770;&#25991;&#20171;&#32461;&#20102;&#23545;&#40784;&#23450;&#20041;&#21644;&#23454;&#29616;&#22810;&#20803;&#20027;&#20041;&#30340;&#19977;&#31181;&#26041;&#24335;&#65292;&#24182;&#25552;&#20986;&#20102;&#19977;&#31181;&#22810;&#20803;&#22522;&#20934;&#31867;&#21035;&#26469;&#35780;&#20272;&#21644;&#27979;&#35797;&#22810;&#20803;&#23545;&#40784;&#30340;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.05070</link><description>&lt;p&gt;
&#36890;&#24448;&#22810;&#20803;&#23545;&#40784;&#30340;&#36335;&#32447;&#22270;
&lt;/p&gt;
&lt;p&gt;
A Roadmap to Pluralistic Alignment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05070
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#26465;&#36890;&#21521;&#22810;&#20803;&#23545;&#40784;&#30340;&#36335;&#32447;&#22270;&#65292;&#20197;&#35299;&#20915;&#35774;&#35745;AI&#31995;&#32479;&#33021;&#22815;&#26381;&#21153;&#20110;&#20154;&#20204;&#20855;&#26377;&#19981;&#21516;&#20215;&#20540;&#35266;&#21644;&#35266;&#28857;&#30340;&#38656;&#27714;&#12290;&#35770;&#25991;&#20171;&#32461;&#20102;&#23545;&#40784;&#23450;&#20041;&#21644;&#23454;&#29616;&#22810;&#20803;&#20027;&#20041;&#30340;&#19977;&#31181;&#26041;&#24335;&#65292;&#24182;&#25552;&#20986;&#20102;&#19977;&#31181;&#22810;&#20803;&#22522;&#20934;&#31867;&#21035;&#26469;&#35780;&#20272;&#21644;&#27979;&#35797;&#22810;&#20803;&#23545;&#40784;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#30340;&#26435;&#21147;&#21644;&#26222;&#21450;&#31243;&#24230;&#30340;&#22686;&#21152;&#65292;&#35774;&#35745;&#33021;&#22815;&#20026;&#19981;&#21516;&#20215;&#20540;&#35266;&#21644;&#35266;&#28857;&#30340;&#20154;&#26381;&#21153;&#30340;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#21464;&#24471;&#24840;&#21457;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#23558;&#27169;&#22411;&#23545;&#40784;&#20197;&#26381;&#21153;&#22810;&#20803;&#20154;&#31867;&#20215;&#20540;&#35266;&#20173;&#28982;&#26159;&#19968;&#20010;&#24453;&#35299;&#20915;&#30340;&#30740;&#31350;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#26465;&#36890;&#21521;&#22810;&#20803;&#23545;&#40784;&#30340;&#36335;&#32447;&#22270;&#65292;&#20855;&#20307;&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#27979;&#35797;&#24179;&#21488;&#12290;&#25105;&#20204;&#30830;&#23450;&#21644;&#24418;&#24335;&#21270;&#20102;&#19977;&#31181;&#21487;&#33021;&#30340;&#26041;&#24335;&#26469;&#23450;&#20041;&#21644;&#23454;&#29616;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#20013;&#30340;&#22810;&#20803;&#20027;&#20041;&#65306;1&#65289;Overton&#22810;&#20803;&#27169;&#22411;&#65292;&#23637;&#31034;&#21512;&#29702;&#21453;&#24212;&#30340;&#20809;&#35889;&#65307;2&#65289;&#21487;&#25805;&#25511;&#30340;&#22810;&#20803;&#27169;&#22411;&#65292;&#21487;&#20197;&#35843;&#25972;&#20197;&#21453;&#26144;&#29305;&#23450;&#30340;&#35266;&#28857;&#65307;3&#65289;&#20998;&#24067;&#22810;&#20803;&#27169;&#22411;&#65292;&#22312;&#20998;&#24067;&#20013;&#24456;&#22909;&#22320;&#26657;&#20934;&#32473;&#23450;&#20154;&#32676;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#21644;&#24418;&#24335;&#21270;&#20102;&#19977;&#31181;&#21487;&#33021;&#30340;&#22810;&#20803;&#22522;&#20934;&#31867;&#21035;&#65306;1&#65289;&#22810;&#30446;&#26631;&#22522;&#20934;&#65307;2&#65289;&#26435;&#34913;&#21487;&#25805;&#25511;&#22522;&#20934;&#65292;&#40723;&#21169;&#27169;&#22411;&#23545;&#20219;&#24847;&#26435;&#34913;&#36827;&#34892;&#35843;&#25972;&#65307;3&#65289;&#38506;&#23457;&#22242;&#22810;&#20803;&#22522;&#20934;&#65292;&#26126;&#30830;&#22320;&#27169;&#25311;&#20102;&#19981;&#21516;&#38506;&#23457;&#22242;&#30340;&#24847;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;
With increased power and prevalence of AI systems, it is ever more critical that AI systems are designed to serve all, i.e., people with diverse values and perspectives. However, aligning models to serve pluralistic human values remains an open research question. In this piece, we propose a roadmap to pluralistic alignment, specifically using language models as a test bed. We identify and formalize three possible ways to define and operationalize pluralism in AI systems: 1) Overton pluralistic models that present a spectrum of reasonable responses; 2) Steerably pluralistic models that can steer to reflect certain perspectives; and 3) Distributionally pluralistic models that are well-calibrated to a given population in distribution. We also propose and formalize three possible classes of pluralistic benchmarks: 1) Multi-objective benchmarks, 2) Trade-off steerable benchmarks, which incentivize models to steer to arbitrary trade-offs, and 3) Jury-pluralistic benchmarks which explicitly m
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22810;&#31181;&#19981;&#30830;&#23450;&#24615;&#26657;&#20934;&#25216;&#26415;&#65292;&#20197;&#25913;&#36827;&#25512;&#33616;&#31995;&#32479;&#20013;&#20542;&#21521;&#24615;&#20272;&#35745;&#30340;&#25928;&#26524;&#12290;&#32463;&#36807;&#23454;&#39564;&#39564;&#35777;&#65292;&#26657;&#20934;&#21518;&#30340;IPS&#20272;&#35745;&#22120;&#22312;Coat&#21644;yahoo&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2303.12973</link><description>&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#20013;&#21453;&#20107;&#23454;&#20542;&#21521;&#20272;&#35745;&#30340;&#19981;&#30830;&#23450;&#24615;&#26657;&#20934;
&lt;/p&gt;
&lt;p&gt;
Uncertainty Calibration for Counterfactual Propensity Estimation in Recommendation. (arXiv:2303.12973v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12973
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22810;&#31181;&#19981;&#30830;&#23450;&#24615;&#26657;&#20934;&#25216;&#26415;&#65292;&#20197;&#25913;&#36827;&#25512;&#33616;&#31995;&#32479;&#20013;&#20542;&#21521;&#24615;&#20272;&#35745;&#30340;&#25928;&#26524;&#12290;&#32463;&#36807;&#23454;&#39564;&#39564;&#35777;&#65292;&#26657;&#20934;&#21518;&#30340;IPS&#20272;&#35745;&#22120;&#22312;Coat&#21644;yahoo&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#30001;&#20110;&#36873;&#25321;&#20559;&#24046;&#65292;&#35768;&#22810;&#35780;&#20998;&#20449;&#24687;&#37117;&#20002;&#22833;&#20102;&#65292;&#36825;&#34987;&#31216;&#20026;&#38750;&#38543;&#26426;&#32570;&#22833;&#12290;&#21453;&#20107;&#23454;&#36870;&#20542;&#21521;&#35780;&#20998;&#65288;IPS&#65289;&#34987;&#29992;&#20110;&#34913;&#37327;&#27599;&#20010;&#35266;&#23519;&#21040;&#30340;&#35780;&#20998;&#30340;&#22635;&#20805;&#38169;&#35823;&#12290;&#34429;&#28982;&#22312;&#22810;&#31181;&#24773;&#20917;&#19979;&#26377;&#25928;&#65292;&#20294;&#25105;&#20204;&#35748;&#20026;IPS&#20272;&#35745;&#30340;&#24615;&#33021;&#21463;&#21040;&#20542;&#21521;&#24615;&#20272;&#35745;&#19981;&#30830;&#23450;&#24615;&#30340;&#38480;&#21046;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#22810;&#31181;&#20195;&#34920;&#24615;&#30340;&#19981;&#30830;&#23450;&#24615;&#26657;&#20934;&#25216;&#26415;&#65292;&#20197;&#25913;&#36827;&#25512;&#33616;&#31995;&#32479;&#20013;&#20542;&#21521;&#24615;&#20272;&#35745;&#30340;&#19981;&#30830;&#23450;&#24615;&#26657;&#20934;&#12290;&#36890;&#36807;&#23545;&#20559;&#35823;&#21644;&#25512;&#24191;&#30028;&#38480;&#30340;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;&#32463;&#36807;&#26657;&#20934;&#30340;IPS&#20272;&#35745;&#22120;&#20248;&#20110;&#26410;&#26657;&#20934;&#30340;IPS&#20272;&#35745;&#22120;&#12290; Coat&#21644;yahoo&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#19981;&#30830;&#23450;&#24615;&#26657;&#20934;&#24471;&#21040;&#25913;&#36827;&#65292;&#20174;&#32780;&#20351;&#25512;&#33616;&#32467;&#26524;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recommendation systems, a large portion of the ratings are missing due to the selection biases, which is known as Missing Not At Random. The counterfactual inverse propensity scoring (IPS) was used to weight the imputation error of every observed rating. Although effective in multiple scenarios, we argue that the performance of IPS estimation is limited due to the uncertainty miscalibration of propensity estimation. In this paper, we propose the uncertainty calibration for the propensity estimation in recommendation systems with multiple representative uncertainty calibration techniques. Theoretical analysis on the bias and generalization bound shows the superiority of the calibrated IPS estimator over the uncalibrated one. Experimental results on the coat and yahoo datasets shows that the uncertainty calibration is improved and hence brings the better recommendation results.
&lt;/p&gt;</description></item></channel></rss>