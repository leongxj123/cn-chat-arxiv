<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#20004;&#38454;&#27573;&#36328;&#23454;&#20307;&#36328;&#22495;&#25512;&#33616;&#30693;&#35782;&#20256;&#36755;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#22810;&#23454;&#20307;&#25512;&#33616;&#20013;&#28304;&#23454;&#20307;&#25968;&#25454;&#20998;&#24067;&#19981;&#21516;&#21644;&#29305;&#24449;&#27169;&#24335;&#19981;&#23545;&#40784;&#31561;&#37325;&#35201;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.19101</link><description>&lt;p&gt;
&#26377;&#25928;&#30340;&#20004;&#38454;&#27573;&#36328;&#23454;&#20307;&#36328;&#22495;&#25512;&#33616;&#30693;&#35782;&#20256;&#36755;
&lt;/p&gt;
&lt;p&gt;
Effective Two-Stage Knowledge Transfer for Multi-Entity Cross-Domain Recommendation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.19101
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#20004;&#38454;&#27573;&#36328;&#23454;&#20307;&#36328;&#22495;&#25512;&#33616;&#30693;&#35782;&#20256;&#36755;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#22810;&#23454;&#20307;&#25512;&#33616;&#20013;&#28304;&#23454;&#20307;&#25968;&#25454;&#20998;&#24067;&#19981;&#21516;&#21644;&#29305;&#24449;&#27169;&#24335;&#19981;&#23545;&#40784;&#31561;&#37325;&#35201;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#30005;&#23376;&#21830;&#21153;&#24179;&#21488;&#19978;&#30340;&#25512;&#33616;&#20869;&#23481;&#21464;&#24471;&#36234;&#26469;&#36234;&#20016;&#23500; -- &#21333;&#20010;&#29992;&#25143;&#21453;&#39304;&#21487;&#33021;&#21253;&#21547;&#22810;&#20010;&#23454;&#20307;&#65292;&#22914;&#38144;&#21806;&#20135;&#21697;&#12289;&#30701;&#35270;&#39057;&#21644;&#20869;&#23481;&#24086;&#23376;&#12290;&#20026;&#20102;&#35299;&#20915;&#22810;&#23454;&#20307;&#25512;&#33616;&#38382;&#39064;&#65292;&#19968;&#20010;&#30452;&#35266;&#30340;&#35299;&#20915;&#26041;&#26696;&#26159;&#37319;&#29992;&#22522;&#20110;&#20849;&#20139;&#32593;&#32476;&#30340;&#26550;&#26500;&#36827;&#34892;&#32852;&#21512;&#35757;&#32451;&#12290;&#36825;&#19968;&#24819;&#27861;&#26159;&#23558;&#19968;&#20010;&#31867;&#22411;&#23454;&#20307;&#65288;&#28304;&#23454;&#20307;&#65289;&#20013;&#25552;&#21462;&#30340;&#30693;&#35782;&#20256;&#36755;&#21040;&#21478;&#19968;&#20010;&#31867;&#22411;&#23454;&#20307;&#65288;&#30446;&#26631;&#23454;&#20307;&#65289;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.19101v1 Announce Type: cross  Abstract: In recent years, the recommendation content on e-commerce platforms has become increasingly rich -- a single user feed may contain multiple entities, such as selling products, short videos, and content posts. To deal with the multi-entity recommendation problem, an intuitive solution is to adopt the shared-network-based architecture for joint training. The idea is to transfer the extracted knowledge from one type of entity (source entity) to another (target entity). However, different from the conventional same-entity cross-domain recommendation, multi-entity knowledge transfer encounters several important issues: (1) data distributions of the source entity and target entity are naturally different, making the shared-network-based joint training susceptible to the negative transfer issue, (2) more importantly, the corresponding feature schema of each entity is not exactly aligned (e.g., price is an essential feature for selling product
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#20219;&#21153;&#65306;&#32452;&#21512;&#20154;&#21592;&#26816;&#32034;&#65288;CPR&#65289;&#65292;&#26088;&#22312;&#32852;&#21512;&#21033;&#29992;&#22270;&#20687;&#21644;&#25991;&#26412;&#20449;&#24687;&#36827;&#34892;&#30446;&#26631;&#20154;&#21592;&#26816;&#32034;&#65292;&#24341;&#20837;&#38646;&#26679;&#26412;&#32452;&#21512;&#20154;&#21592;&#26816;&#32034;&#65288;ZS-CPR&#65289;&#35299;&#20915;&#20102;CPR&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#23398;&#20064;&#26694;&#26550;Word4Per&#12290;</title><link>https://arxiv.org/abs/2311.16515</link><description>&lt;p&gt;
Word4Per: Zero-shot&#32452;&#21512;&#20154;&#21592;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Word4Per: Zero-shot Composed Person Retrieval
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.16515
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#20219;&#21153;&#65306;&#32452;&#21512;&#20154;&#21592;&#26816;&#32034;&#65288;CPR&#65289;&#65292;&#26088;&#22312;&#32852;&#21512;&#21033;&#29992;&#22270;&#20687;&#21644;&#25991;&#26412;&#20449;&#24687;&#36827;&#34892;&#30446;&#26631;&#20154;&#21592;&#26816;&#32034;&#65292;&#24341;&#20837;&#38646;&#26679;&#26412;&#32452;&#21512;&#20154;&#21592;&#26816;&#32034;&#65288;ZS-CPR&#65289;&#35299;&#20915;&#20102;CPR&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#23398;&#20064;&#26694;&#26550;Word4Per&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23547;&#25214;&#29305;&#23450;&#20154;&#21592;&#20855;&#26377;&#26497;&#22823;&#30340;&#31038;&#20250;&#25928;&#30410;&#21644;&#23433;&#20840;&#20215;&#20540;&#65292;&#36890;&#24120;&#28041;&#21450;&#35270;&#35273;&#21644;&#25991;&#26412;&#20449;&#24687;&#30340;&#32467;&#21512;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20840;&#26032;&#30340;&#20219;&#21153;&#65292;&#31216;&#20026;&#32452;&#21512;&#20154;&#21592;&#26816;&#32034;&#65288;CPR&#65289;&#65292;&#26088;&#22312;&#32852;&#21512;&#21033;&#29992;&#22270;&#20687;&#21644;&#25991;&#26412;&#20449;&#24687;&#36827;&#34892;&#30446;&#26631;&#20154;&#21592;&#26816;&#32034;&#12290;&#28982;&#32780;&#65292;&#30417;&#30563;CPR&#38656;&#35201;&#26114;&#36149;&#30340;&#25163;&#21160;&#27880;&#37322;&#25968;&#25454;&#38598;&#65292;&#32780;&#30446;&#21069;&#27809;&#26377;&#21487;&#29992;&#36164;&#28304;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#39318;&#20808;&#24341;&#20837;&#20102;&#38646;&#26679;&#26412;&#32452;&#21512;&#20154;&#21592;&#26816;&#32034;&#65288;ZS-CPR&#65289;&#65292;&#21033;&#29992;&#29616;&#26377;&#30340;&#39046;&#22495;&#30456;&#20851;&#25968;&#25454;&#35299;&#20915;&#20102;CPR&#38382;&#39064;&#32780;&#19981;&#38656;&#35201;&#26114;&#36149;&#30340;&#27880;&#37322;&#12290;&#20854;&#27425;&#65292;&#20026;&#20102;&#23398;&#20064;ZS-CPR&#27169;&#22411;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#23398;&#20064;&#26694;&#26550;&#65292;&#21363;Word4Per&#65292;&#20854;&#20013;&#21253;&#21547;&#19968;&#20010;&#36731;&#37327;&#32423;&#30340;&#25991;&#26412;&#21453;&#36716;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.16515v2 Announce Type: replace-cross  Abstract: Searching for specific person has great social benefits and security value, and it often involves a combination of visual and textual information. Conventional person retrieval methods, whether image-based or text-based, usually fall short in effectively harnessing both types of information, leading to the loss of accuracy. In this paper, a whole new task called Composed Person Retrieval (CPR) is proposed to jointly utilize both image and text information for target person retrieval. However, the supervised CPR requires very costly manual annotation dataset, while there are currently no available resources. To mitigate this issue, we firstly introduce the Zero-shot Composed Person Retrieval (ZS-CPR), which leverages existing domain-related data to resolve the CPR problem without expensive annotations. Secondly, to learn ZS-CPR model, we propose a two-stage learning framework, Word4Per, where a lightweight Textual Inversion Netw
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#25490;&#24207;&#30340;&#35821;&#35328;&#27169;&#22411;&#30340;&#31574;&#30053;&#26799;&#24230;&#35757;&#32451;&#31639;&#27861;Neural PG-RANK&#65292;&#36890;&#36807;&#23558;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#23454;&#20363;&#21270;&#20026;Plackett-Luce&#25490;&#21517;&#31574;&#30053;&#65292;&#23454;&#29616;&#20102;&#23545;&#26816;&#32034;&#27169;&#22411;&#30340;&#21407;&#21017;&#24615;&#12289;&#31471;&#21040;&#31471;&#35757;&#32451;&#12290;</title><link>http://arxiv.org/abs/2310.04407</link><description>&lt;p&gt;
&#29992;&#20110;&#25490;&#24207;&#30340;&#35821;&#35328;&#27169;&#22411;&#30340;&#31574;&#30053;&#26799;&#24230;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Policy-Gradient Training of Language Models for Ranking. (arXiv:2310.04407v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04407
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#25490;&#24207;&#30340;&#35821;&#35328;&#27169;&#22411;&#30340;&#31574;&#30053;&#26799;&#24230;&#35757;&#32451;&#31639;&#27861;Neural PG-RANK&#65292;&#36890;&#36807;&#23558;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#23454;&#20363;&#21270;&#20026;Plackett-Luce&#25490;&#21517;&#31574;&#30053;&#65292;&#23454;&#29616;&#20102;&#23545;&#26816;&#32034;&#27169;&#22411;&#30340;&#21407;&#21017;&#24615;&#12289;&#31471;&#21040;&#31471;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25991;&#26412;&#26816;&#32034;&#22312;&#23558;&#20107;&#23454;&#30693;&#35782;&#32435;&#20837;&#21040;&#35821;&#35328;&#22788;&#29702;&#27969;&#31243;&#20013;&#30340;&#20915;&#31574;&#36807;&#31243;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#65292;&#20174;&#32842;&#22825;&#24335;&#32593;&#39029;&#25628;&#32034;&#21040;&#38382;&#31572;&#31995;&#32479;&#12290;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#25991;&#26412;&#26816;&#32034;&#27169;&#22411;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20197;&#36798;&#21040;&#26377;&#31454;&#20105;&#21147;&#30340;&#24615;&#33021;&#65292;&#20294;&#36890;&#36807;&#20856;&#22411;&#30340;&#23545;&#27604;&#25439;&#22833;&#35757;&#32451;&#22522;&#20110;LLM&#30340;&#26816;&#32034;&#22120;&#38656;&#35201;&#22797;&#26434;&#30340;&#21551;&#21457;&#24335;&#31639;&#27861;&#65292;&#21253;&#25324;&#36873;&#25321;&#22256;&#38590;&#30340;&#36127;&#26679;&#26412;&#21644;&#20351;&#29992;&#39069;&#22806;&#30340;&#30417;&#30563;&#20316;&#20026;&#23398;&#20064;&#20449;&#21495;&#12290;&#36825;&#31181;&#20381;&#36182;&#20110;&#21551;&#21457;&#24335;&#31639;&#27861;&#30340;&#21407;&#22240;&#26159;&#23545;&#27604;&#25439;&#22833;&#26412;&#36523;&#26159;&#21551;&#21457;&#24335;&#30340;&#65292;&#19981;&#33021;&#30452;&#25509;&#20248;&#21270;&#22788;&#29702;&#27969;&#31243;&#26411;&#31471;&#20915;&#31574;&#36136;&#37327;&#30340;&#19979;&#28216;&#25351;&#26631;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#31070;&#32463;PG-RANK&#65292;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#31639;&#27861;&#65292;&#36890;&#36807;&#23558;LLM&#23454;&#20363;&#21270;&#20026;Plackett-Luce&#25490;&#21517;&#31574;&#30053;&#65292;&#23398;&#20064;&#25490;&#24207;&#12290;&#31070;&#32463;PG-RANK&#20026;&#26816;&#32034;&#27169;&#22411;&#30340;&#31471;&#21040;&#31471;&#35757;&#32451;&#25552;&#20379;&#20102;&#19968;&#31181;&#21407;&#21017;&#24615;&#26041;&#27861;&#65292;&#20316;&#20026;&#26356;&#22823;&#30340;&#20915;&#31574;&#31995;&#32479;&#30340;&#19968;&#37096;&#20998;&#36827;&#34892;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
Text retrieval plays a crucial role in incorporating factual knowledge for decision making into language processing pipelines, ranging from chat-based web search to question answering systems. Current state-of-the-art text retrieval models leverage pre-trained large language models (LLMs) to achieve competitive performance, but training LLM-based retrievers via typical contrastive losses requires intricate heuristics, including selecting hard negatives and using additional supervision as learning signals. This reliance on heuristics stems from the fact that the contrastive loss itself is heuristic and does not directly optimize the downstream metrics of decision quality at the end of the processing pipeline. To address this issue, we introduce Neural PG-RANK, a novel training algorithm that learns to rank by instantiating a LLM as a Plackett-Luce ranking policy. Neural PG-RANK provides a principled method for end-to-end training of retrieval models as part of larger decision systems vi
&lt;/p&gt;</description></item></channel></rss>