<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25237;&#24433;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65288;SHGD&#65289;&#65292;&#36890;&#36807;&#23545;&#31216;&#22240;&#23376;&#20998;&#35299;&#36827;&#34892;&#35889;&#21387;&#32553;&#24863;&#30693;&#65292;&#20943;&#23569;&#20102;&#35745;&#31639;&#21644;&#23384;&#20648;&#25104;&#26412;&#65292;&#24341;&#20837;&#20102;&#26032;&#30340;&#22240;&#23376;&#20998;&#35299;&#27495;&#20041;&#12290;</title><link>https://arxiv.org/abs/2403.09031</link><description>&lt;p&gt;
&#22522;&#20110;&#23545;&#31216; Hankel &#22240;&#23376;&#20998;&#35299;&#30340;&#35889;&#21387;&#32553;&#24863;&#30693;&#30340;&#25237;&#24433;&#26799;&#24230;&#19979;&#38477;
&lt;/p&gt;
&lt;p&gt;
Projected Gradient Descent for Spectral Compressed Sensing via Symmetric Hankel Factorization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09031
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25237;&#24433;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65288;SHGD&#65289;&#65292;&#36890;&#36807;&#23545;&#31216;&#22240;&#23376;&#20998;&#35299;&#36827;&#34892;&#35889;&#21387;&#32553;&#24863;&#30693;&#65292;&#20943;&#23569;&#20102;&#35745;&#31639;&#21644;&#23384;&#20648;&#25104;&#26412;&#65292;&#24341;&#20837;&#20102;&#26032;&#30340;&#22240;&#23376;&#20998;&#35299;&#27495;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#35889;&#21387;&#32553;&#24863;&#30693;&#26041;&#27861;&#36890;&#36807; Hankel &#30697;&#38453;&#23436;&#25104;&#37319;&#29992;&#23545;&#31216;&#22240;&#23376;&#20998;&#35299;&#26469;&#23637;&#31034; Hankel &#30697;&#38453;&#30340;&#20302;&#31209;&#24615;&#36136;&#12290;&#28982;&#32780;&#65292;&#20808;&#21069;&#30340;&#38750;&#20984;&#26799;&#24230;&#26041;&#27861;&#21482;&#21033;&#29992;&#19981;&#23545;&#31216;&#22240;&#23376;&#20998;&#35299;&#26469;&#23454;&#29616;&#35889;&#21387;&#32553;&#24863;&#30693;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25237;&#24433;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#31216;&#22240;&#23376;&#20998;&#35299;&#36827;&#34892;&#35889;&#21387;&#32553;&#24863;&#30693;&#65292;&#21517;&#20026;&#23545;&#31216; Hankel &#25237;&#24433;&#26799;&#24230;&#19979;&#38477;&#65288;SHGD&#65289;&#65292;&#23427;&#20165;&#26356;&#26032;&#19968;&#20010;&#30697;&#38453;&#24182;&#36991;&#20813;&#20102;&#24179;&#34913;&#27491;&#21017;&#21270;&#39033;&#12290;&#19982;&#22522;&#20110;&#19981;&#23545;&#31216;&#22240;&#23376;&#20998;&#35299;&#30340;&#20808;&#21069;&#26799;&#24230;&#26041;&#27861;&#30456;&#27604;&#65292;SHGD&#20943;&#23569;&#20102;&#22823;&#32422;&#19968;&#21322;&#30340;&#35745;&#31639;&#21644;&#23384;&#20648;&#25104;&#26412;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24037;&#20316;&#20013;&#20351;&#29992;&#30340;&#23545;&#31216;&#22240;&#23376;&#20998;&#35299;&#19982;&#20808;&#21069;&#30340;&#20302;&#31209;&#20998;&#35299;&#27169;&#22411;&#23436;&#20840;&#19981;&#21516;&#65292;&#24341;&#20837;&#20102;&#22312;&#22797;&#27491;&#20132;&#21464;&#25442;&#19979;&#30340;&#26032;&#22240;&#23376;&#20998;&#35299;&#27495;&#20041;&#12290;&#25105;&#20204;&#20026;&#25105;&#20204;&#30340;&#20998;&#35299;&#35774;&#35745;&#20102;&#26032;&#39062;&#30340;&#36317;&#31163;&#24230;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09031v1 Announce Type: new  Abstract: Current spectral compressed sensing methods via Hankel matrix completion employ symmetric factorization to demonstrate the low-rank property of the Hankel matrix. However, previous non-convex gradient methods only utilize asymmetric factorization to achieve spectral compressed sensing. In this paper, we propose a novel nonconvex projected gradient descent method for spectral compressed sensing via symmetric factorization named Symmetric Hankel Projected Gradient Descent (SHGD), which updates only one matrix and avoids a balancing regularization term. SHGD reduces about half of the computation and storage costs compared to the prior gradient method based on asymmetric factorization. {Besides, the symmetric factorization employed in our work is completely novel to the prior low-rank factorization model, introducing a new factorization ambiguity under complex orthogonal transformation}. Novel distance metrics are designed for our factorizat
&lt;/p&gt;</description></item><item><title>C-Pack&#26159;&#19968;&#22871;&#25512;&#36827;&#26222;&#36890;&#27721;&#35821;&#23884;&#20837;&#39046;&#22495;&#30340;&#36164;&#28304;&#65292;&#21253;&#25324;&#20840;&#38754;&#27721;&#35821;&#25991;&#26412;&#23884;&#20837;&#22522;&#20934;&#12289;&#22823;&#35268;&#27169;&#25991;&#26412;&#23884;&#20837;&#25968;&#25454;&#38598;&#21644;&#28085;&#30422;&#22810;&#20010;&#23610;&#23544;&#30340;&#23884;&#20837;&#27169;&#22411;&#31995;&#21015;&#12290;&#35813;&#36164;&#28304;&#38598;&#22312;C-MTEB&#22522;&#20934;&#19978;&#23454;&#29616;&#20102;&#26368;&#39640;+10%&#30340;&#34920;&#29616;&#65292;&#24182;&#36890;&#36807;&#25972;&#21512;&#21644;&#20248;&#21270;&#19968;&#22871;&#35757;&#32451;&#26041;&#27861;&#36827;&#19968;&#27493;&#25552;&#21319;&#20102;&#25928;&#26524;&#12290;&#27492;&#22806;&#65292;C-Pack&#36824;&#21457;&#24067;&#20102;&#33521;&#35821;&#25991;&#26412;&#23884;&#20837;&#25968;&#25454;&#21644;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#35813;&#36164;&#28304;&#38598;&#21487;&#20844;&#24320;&#33719;&#21462;&#12290;</title><link>http://arxiv.org/abs/2309.07597</link><description>&lt;p&gt;
C-Pack: &#25512;&#36827;&#26222;&#36890;&#27721;&#35821;&#23884;&#20837;&#30340;&#25171;&#21253;&#36164;&#28304;
&lt;/p&gt;
&lt;p&gt;
C-Pack: Packaged Resources To Advance General Chinese Embedding. (arXiv:2309.07597v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07597
&lt;/p&gt;
&lt;p&gt;
C-Pack&#26159;&#19968;&#22871;&#25512;&#36827;&#26222;&#36890;&#27721;&#35821;&#23884;&#20837;&#39046;&#22495;&#30340;&#36164;&#28304;&#65292;&#21253;&#25324;&#20840;&#38754;&#27721;&#35821;&#25991;&#26412;&#23884;&#20837;&#22522;&#20934;&#12289;&#22823;&#35268;&#27169;&#25991;&#26412;&#23884;&#20837;&#25968;&#25454;&#38598;&#21644;&#28085;&#30422;&#22810;&#20010;&#23610;&#23544;&#30340;&#23884;&#20837;&#27169;&#22411;&#31995;&#21015;&#12290;&#35813;&#36164;&#28304;&#38598;&#22312;C-MTEB&#22522;&#20934;&#19978;&#23454;&#29616;&#20102;&#26368;&#39640;+10%&#30340;&#34920;&#29616;&#65292;&#24182;&#36890;&#36807;&#25972;&#21512;&#21644;&#20248;&#21270;&#19968;&#22871;&#35757;&#32451;&#26041;&#27861;&#36827;&#19968;&#27493;&#25552;&#21319;&#20102;&#25928;&#26524;&#12290;&#27492;&#22806;&#65292;C-Pack&#36824;&#21457;&#24067;&#20102;&#33521;&#35821;&#25991;&#26412;&#23884;&#20837;&#25968;&#25454;&#21644;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#35813;&#36164;&#28304;&#38598;&#21487;&#20844;&#24320;&#33719;&#21462;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;C-Pack&#65292;&#36825;&#26159;&#19968;&#22871;&#26174;&#33879;&#25512;&#36827;&#26222;&#36890;&#27721;&#35821;&#23884;&#20837;&#39046;&#22495;&#30340;&#36164;&#28304;&#12290;C-Pack&#21253;&#25324;&#19977;&#20010;&#20851;&#38190;&#36164;&#28304;&#12290;1&#65289;C-MTEB&#26159;&#19968;&#20010;&#28085;&#30422;6&#20010;&#20219;&#21153;&#21644;35&#20010;&#25968;&#25454;&#38598;&#30340;&#20840;&#38754;&#27721;&#35821;&#25991;&#26412;&#23884;&#20837;&#22522;&#20934;&#12290;2&#65289;C-MTP&#26159;&#19968;&#20010;&#20174;&#26631;&#35760;&#21644;&#26410;&#26631;&#35760;&#30340;&#27721;&#35821;&#35821;&#26009;&#24211;&#20013;&#31574;&#21010;&#30340;&#22823;&#35268;&#27169;&#25991;&#26412;&#23884;&#20837;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#35757;&#32451;&#23884;&#20837;&#27169;&#22411;&#12290;3&#65289;C-TEM&#26159;&#19968;&#20010;&#28085;&#30422;&#22810;&#20010;&#23610;&#23544;&#30340;&#23884;&#20837;&#27169;&#22411;&#31995;&#21015;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;C-MTEB&#19978;&#30340;&#34920;&#29616;&#20248;&#20110;&#20043;&#21069;&#30340;&#25152;&#26377;&#27721;&#35821;&#25991;&#26412;&#23884;&#20837;&#36798;&#21040;&#20102;&#21457;&#24067;&#26102;&#30340;&#26368;&#39640;+10%&#12290;&#25105;&#20204;&#36824;&#25972;&#21512;&#21644;&#20248;&#21270;&#20102;C-TEM&#30340;&#25972;&#22871;&#35757;&#32451;&#26041;&#27861;&#12290;&#38500;&#20102;&#25105;&#20204;&#20851;&#20110;&#26222;&#36890;&#27721;&#35821;&#23884;&#20837;&#30340;&#36164;&#28304;&#22806;&#65292;&#25105;&#20204;&#36824;&#21457;&#24067;&#20102;&#25105;&#20204;&#30340;&#33521;&#35821;&#25991;&#26412;&#23884;&#20837;&#25968;&#25454;&#21644;&#27169;&#22411;&#12290;&#36825;&#20123;&#33521;&#35821;&#27169;&#22411;&#22312;MTEB&#22522;&#20934;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65307;&#19982;&#27492;&#21516;&#26102;&#65292;&#25105;&#20204;&#21457;&#24067;&#30340;&#33521;&#35821;&#25968;&#25454;&#27604;&#27721;&#35821;&#25968;&#25454;&#22823;2&#20493;&#12290;&#25152;&#26377;&#36825;&#20123;&#36164;&#28304;&#37117;&#21487;&#20197;&#22312;https://github.com/FlagOpen/FlagEmbedding&#19978;&#20844;&#24320;&#33719;&#21462;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce C-Pack, a package of resources that significantly advance the field of general Chinese embeddings. C-Pack includes three critical resources. 1) C-MTEB is a comprehensive benchmark for Chinese text embeddings covering 6 tasks and 35 datasets. 2) C-MTP is a massive text embedding dataset curated from labeled and unlabeled Chinese corpora for training embedding models. 3) C-TEM is a family of embedding models covering multiple sizes. Our models outperform all prior Chinese text embeddings on C-MTEB by up to +10% upon the time of the release. We also integrate and optimize the entire suite of training methods for C-TEM. Along with our resources on general Chinese embedding, we release our data and models for English text embeddings. The English models achieve state-of-the-art performance on MTEB benchmark; meanwhile, our released English data is 2 times larger than the Chinese data. All these resources are made publicly available at https://github.com/FlagOpen/FlagEmbedding.
&lt;/p&gt;</description></item></channel></rss>