<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#22810;&#20010;&#26597;&#35810;&#20197;&#22686;&#24378;&#23545;&#35805;&#21709;&#24212;&#26816;&#32034;&#30340;&#26041;&#27861;&#65292;&#24182;&#22522;&#20110;&#19981;&#21516;LLMs&#23454;&#29616;&#35780;&#20272;&#65292;&#21516;&#26102;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;TREC iKAT&#22522;&#20934;&#12290;</title><link>https://arxiv.org/abs/2403.19302</link><description>&lt;p&gt;
&#29983;&#25104;&#28982;&#21518;&#26816;&#32034;&#65306;&#20351;&#29992;LLM&#20316;&#20026;&#31572;&#26696;&#21644;&#26597;&#35810;&#29983;&#25104;&#22120;&#30340;&#23545;&#35805;&#21709;&#24212;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Generate then Retrieve: Conversational Response Retrieval Using LLMs as Answer and Query Generators
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19302
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#22810;&#20010;&#26597;&#35810;&#20197;&#22686;&#24378;&#23545;&#35805;&#21709;&#24212;&#26816;&#32034;&#30340;&#26041;&#27861;&#65292;&#24182;&#22522;&#20110;&#19981;&#21516;LLMs&#23454;&#29616;&#35780;&#20272;&#65292;&#21516;&#26102;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;TREC iKAT&#22522;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
CIS&#26159;&#20449;&#24687;&#26816;&#32034;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#39046;&#22495;&#65292;&#19987;&#27880;&#20110;&#24320;&#21457;&#20132;&#20114;&#24335;&#30693;&#35782;&#21161;&#25163;&#12290;&#36825;&#20123;&#31995;&#32479;&#24517;&#39035;&#33021;&#22815;&#29087;&#32451;&#22320;&#29702;&#35299;&#29992;&#25143;&#22312;&#23545;&#35805;&#29615;&#22659;&#20013;&#30340;&#20449;&#24687;&#38656;&#27714;&#65292;&#24182;&#26816;&#32034;&#30456;&#20851;&#20449;&#24687;&#12290;&#20026;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#29616;&#26377;&#26041;&#27861;&#20351;&#29992;&#19968;&#20010;&#31216;&#20026;&#37325;&#20889;&#26597;&#35810;&#30340;&#26597;&#35810;&#26469;&#24314;&#27169;&#29992;&#25143;&#30340;&#20449;&#24687;&#38656;&#27714;&#65292;&#24182;&#23558;&#27492;&#26597;&#35810;&#29992;&#20110;&#27573;&#33853;&#26816;&#32034;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19977;&#31181;&#29992;&#20110;&#29983;&#25104;&#22810;&#20010;&#26597;&#35810;&#20197;&#22686;&#24378;&#26816;&#32034;&#30340;&#19981;&#21516;&#26041;&#27861;&#12290;&#22312;&#36825;&#20123;&#26041;&#27861;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#33021;&#21147;&#26469;&#29702;&#35299;&#29992;&#25143;&#30340;&#20449;&#24687;&#38656;&#27714;&#21644;&#29983;&#25104;&#36866;&#24403;&#30340;&#21709;&#24212;&#65292;&#20197;&#29983;&#25104;&#22810;&#20010;&#26597;&#35810;&#12290;&#25105;&#20204;&#23454;&#29616;&#24182;&#35780;&#20272;&#20102;&#25552;&#20986;&#30340;&#27169;&#22411;&#65292;&#21033;&#29992;&#21253;&#25324;GPT-4&#21644;Llama-2&#22312;&#38646;-shot&#21644;&#23569;-shot&#35774;&#32622;&#20013;&#30340;&#21508;&#31181;LLMs&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22522;&#20110;gpt 3.5&#30340;&#21028;&#26029;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;TREC iKAT&#30340;&#26032;&#22522;&#20934;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#25581;&#31034;&#20102;&#25928;&#26524;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19302v1 Announce Type: new  Abstract: CIS is a prominent area in IR that focuses on developing interactive knowledge assistants. These systems must adeptly comprehend the user's information requirements within the conversational context and retrieve the relevant information. To this aim, the existing approaches model the user's information needs with one query called rewritten query and use this query for passage retrieval. In this paper, we propose three different methods for generating multiple queries to enhance the retrieval. In these methods, we leverage the capabilities of large language models (LLMs) in understanding the user's information need and generating an appropriate response, to generate multiple queries. We implement and evaluate the proposed models utilizing various LLMs including GPT-4 and Llama-2 chat in zero-shot and few-shot settings. In addition, we propose a new benchmark for TREC iKAT based on gpt 3.5 judgments. Our experiments reveal the effectivenes
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#27169;&#22411;&#65292;&#26088;&#22312;&#21516;&#26102;&#27169;&#25311;&#35821;&#20041;&#21644;&#21327;&#21516;&#30693;&#35782;&#65292;&#20197;&#23454;&#29616;&#20934;&#30830;&#30340;CTR&#20272;&#35745;&#65292;&#24182;&#35299;&#20915;&#25512;&#29702;&#25928;&#29575;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.09234</link><description>&lt;p&gt;
ClickPrompt: CTR&#27169;&#22411;&#26159;&#23558;&#35821;&#35328;&#27169;&#22411;&#36866;&#24212;&#20026;CTR&#39044;&#27979;&#30340;&#24378;&#22823;&#25552;&#31034;&#29983;&#25104;&#22120;
&lt;/p&gt;
&lt;p&gt;
ClickPrompt: CTR Models are Strong Prompt Generators for Adapting Language Models to CTR Prediction. (arXiv:2310.09234v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09234
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#27169;&#22411;&#65292;&#26088;&#22312;&#21516;&#26102;&#27169;&#25311;&#35821;&#20041;&#21644;&#21327;&#21516;&#30693;&#35782;&#65292;&#20197;&#23454;&#29616;&#20934;&#30830;&#30340;CTR&#20272;&#35745;&#65292;&#24182;&#35299;&#20915;&#25512;&#29702;&#25928;&#29575;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28857;&#20987;&#29575;&#65288;CTR&#65289;&#39044;&#27979;&#24050;&#32463;&#25104;&#20026;&#21508;&#31181;&#20114;&#32852;&#32593;&#24212;&#29992;&#31243;&#24207;&#20013;&#36234;&#26469;&#36234;&#19981;&#21487;&#25110;&#32570;&#30340;&#12290;&#20256;&#32479;&#30340;CTR&#27169;&#22411;&#36890;&#36807;&#29420;&#28909;&#32534;&#30721;&#23558;&#22810;&#23383;&#27573;&#20998;&#31867;&#25968;&#25454;&#36716;&#25442;&#20026;ID&#29305;&#24449;&#65292;&#24182;&#25552;&#21462;&#29305;&#24449;&#20043;&#38388;&#30340;&#21327;&#21516;&#20449;&#21495;&#12290;&#36825;&#31181;&#33539;&#24335;&#30340;&#38382;&#39064;&#22312;&#20110;&#35821;&#20041;&#20449;&#24687;&#30340;&#20002;&#22833;&#12290;&#21478;&#19968;&#26041;&#38754;&#30340;&#30740;&#31350;&#36890;&#36807;&#23558;&#36755;&#20837;&#25968;&#25454;&#36716;&#25442;&#20026;&#25991;&#26412;&#21477;&#23376;&#26469;&#25506;&#32034;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLM&#65289;&#22312;CTR&#39044;&#27979;&#20013;&#30340;&#28508;&#21147;&#12290;&#34429;&#28982;&#35821;&#20041;&#20449;&#21495;&#24471;&#21040;&#20102;&#20445;&#30041;&#65292;&#20294;&#23427;&#20204;&#36890;&#24120;&#26080;&#27861;&#25429;&#25417;&#21040;&#21327;&#21516;&#20449;&#24687;&#65288;&#22914;&#29305;&#24449;&#20132;&#20114;&#12289;&#32431;ID&#29305;&#24449;&#65289;&#65292;&#26356;&#19981;&#29992;&#35828;&#30001;&#24222;&#22823;&#30340;&#27169;&#22411;&#22823;&#23567;&#24102;&#26469;&#30340;&#26080;&#27861;&#25509;&#21463;&#30340;&#25512;&#29702;&#24320;&#38144;&#20102;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#20026;&#20934;&#30830;&#30340;CTR&#20272;&#35745;&#24314;&#31435;&#35821;&#20041;&#30693;&#35782;&#21644;&#21327;&#21516;&#30693;&#35782;&#65292;&#24182;&#35299;&#20915;&#25512;&#29702;&#25928;&#29575;&#38382;&#39064;&#12290;&#20026;&#20102;&#20174;&#20004;&#20010;&#39046;&#22495;&#20013;&#21463;&#30410;&#24182;&#24357;&#21512;&#23427;&#20204;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27169;&#22411;-&#12290;
&lt;/p&gt;
&lt;p&gt;
Click-through rate (CTR) prediction has become increasingly indispensable for various Internet applications. Traditional CTR models convert the multi-field categorical data into ID features via one-hot encoding, and extract the collaborative signals among features. Such a paradigm suffers from the problem of semantic information loss. Another line of research explores the potential of pretrained language models (PLMs) for CTR prediction by converting input data into textual sentences through hard prompt templates. Although semantic signals are preserved, they generally fail to capture the collaborative information (e.g., feature interactions, pure ID features), not to mention the unacceptable inference overhead brought by the huge model size. In this paper, we aim to model both the semantic knowledge and collaborative knowledge for accurate CTR estimation, and meanwhile address the inference inefficiency issue. To benefit from both worlds and close their gaps, we propose a novel model-
&lt;/p&gt;</description></item></channel></rss>