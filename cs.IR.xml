<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#21033;&#29992;&#25552;&#20379;&#19982;&#35268;&#27169;&#26657;&#20934;&#30456;&#20851;&#30340;&#26597;&#35810;&#21644;&#25991;&#26723;&#23545;&#30340;&#19981;&#30830;&#23450;&#24615;&#27979;&#37327;&#30340;&#28508;&#21147;&#65292;&#20197;&#35299;&#20915;&#31070;&#32463;&#25490;&#24207;&#22120;&#30340;&#35268;&#27169;&#26657;&#20934;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.12276</link><description>&lt;p&gt;
&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33258;&#28982;&#35821;&#35328;&#35299;&#37322;&#36827;&#34892;&#31070;&#32463;&#25490;&#24207;&#22120;&#30340;&#35268;&#27169;&#26657;&#20934;&#35299;&#37322;&#21644;&#25490;&#21517;
&lt;/p&gt;
&lt;p&gt;
Explain then Rank: Scale Calibration of Neural Rankers Using Natural Language Explanations from Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12276
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#21033;&#29992;&#25552;&#20379;&#19982;&#35268;&#27169;&#26657;&#20934;&#30456;&#20851;&#30340;&#26597;&#35810;&#21644;&#25991;&#26723;&#23545;&#30340;&#19981;&#30830;&#23450;&#24615;&#27979;&#37327;&#30340;&#28508;&#21147;&#65292;&#20197;&#35299;&#20915;&#31070;&#32463;&#25490;&#24207;&#22120;&#30340;&#35268;&#27169;&#26657;&#20934;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25490;&#21517;&#31995;&#32479;&#20013;&#30340;&#35268;&#27169;&#26657;&#20934;&#36807;&#31243;&#28041;&#21450;&#35843;&#25972;&#25490;&#24207;&#22120;&#30340;&#36755;&#20986;&#65292;&#20197;&#20351;&#20854;&#19982;&#37325;&#35201;&#21697;&#36136;&#65288;&#22914;&#28857;&#20987;&#29575;&#25110;&#30456;&#20851;&#24615;&#65289;&#30456;&#23545;&#24212;&#65292;&#36825;&#23545;&#20110;&#21453;&#26144;&#29616;&#23454;&#20215;&#20540;&#20197;&#21450;&#25552;&#39640;&#31995;&#32479;&#30340;&#25928;&#26524;&#21644;&#21487;&#38752;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#34429;&#28982;&#24050;&#32463;&#30740;&#31350;&#20102;&#23398;&#20064;&#25490;&#24207;&#27169;&#22411;&#20013;&#30340;&#26657;&#20934;&#25490;&#24207;&#25439;&#22833;&#65292;&#20294;&#35843;&#25972;&#31070;&#32463;&#25490;&#24207;&#22120;&#30340;&#35268;&#27169;&#30340;&#29305;&#23450;&#38382;&#39064;&#65292;&#36825;&#20123;&#27169;&#22411;&#25797;&#38271;&#22788;&#29702;&#25991;&#26412;&#20449;&#24687;&#65292;&#23578;&#26410;&#24471;&#21040;&#20805;&#20998;&#30740;&#31350;&#12290;&#31070;&#32463;&#25490;&#24207;&#27169;&#22411;&#25797;&#38271;&#22788;&#29702;&#25991;&#26412;&#25968;&#25454;&#65292;&#20294;&#23558;&#29616;&#26377;&#35268;&#27169;&#26657;&#20934;&#25216;&#26415;&#24212;&#29992;&#21040;&#36825;&#20123;&#27169;&#22411;&#20250;&#38754;&#20020;&#37325;&#22823;&#25361;&#25112;&#65292;&#22240;&#20026;&#23427;&#20204;&#30340;&#22797;&#26434;&#24615;&#21644;&#38656;&#35201;&#22823;&#37327;&#35757;&#32451;&#65292;&#24448;&#24448;&#23548;&#33268;&#27425;&#20248;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12276v1 Announce Type: new  Abstract: The process of scale calibration in ranking systems involves adjusting the outputs of rankers to correspond with significant qualities like click-through rates or relevance, crucial for mirroring real-world value and thereby boosting the system's effectiveness and reliability. Although there has been research on calibrated ranking losses within learning-to-rank models, the particular issue of adjusting the scale for neural rankers, which excel in handling textual information, has not been thoroughly examined. Neural ranking models are adept at processing text data, yet the application of existing scale calibration techniques to these models poses significant challenges due to their complexity and the intensive training they require, often resulting in suboptimal outcomes.   This study delves into the potential of large language models (LLMs) to provide uncertainty measurements for a query and document pair that correlate with the scale-c
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#22810;&#26679;&#21270;&#30340;&#24320;&#25918;&#25968;&#25454;&#38598;&#65292;&#24182;&#22312;&#22810;&#20010;&#24230;&#37327;&#25351;&#26631;&#19978;&#35780;&#20272;&#22810;&#31181;&#21327;&#21516;&#36807;&#28388;&#31639;&#27861;&#65292;&#26469;&#30740;&#31350;&#25968;&#25454;&#38598;&#29305;&#24449;&#23545;&#31639;&#27861;&#24615;&#33021;&#30340;&#24433;&#21709;&#12290;&#36825;&#19968;&#26041;&#27861;&#22635;&#34917;&#20102;&#25512;&#33616;&#31995;&#32479;&#31639;&#27861;&#27604;&#36739;&#20013;&#30340;&#19981;&#36275;&#20043;&#22788;&#65292;&#25512;&#36827;&#20102;&#35780;&#20272;&#23454;&#36341;&#12290;</title><link>https://arxiv.org/abs/2402.09766</link><description>&lt;p&gt;
&#20174;&#21464;&#21160;&#24615;&#21040;&#31283;&#23450;&#24615;&#65306;&#25512;&#33616;&#31995;&#32479;&#22522;&#20934;&#21270;&#23454;&#36341;&#30340;&#36827;&#23637;
&lt;/p&gt;
&lt;p&gt;
From Variability to Stability: Advancing RecSys Benchmarking Practices
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09766
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#22810;&#26679;&#21270;&#30340;&#24320;&#25918;&#25968;&#25454;&#38598;&#65292;&#24182;&#22312;&#22810;&#20010;&#24230;&#37327;&#25351;&#26631;&#19978;&#35780;&#20272;&#22810;&#31181;&#21327;&#21516;&#36807;&#28388;&#31639;&#27861;&#65292;&#26469;&#30740;&#31350;&#25968;&#25454;&#38598;&#29305;&#24449;&#23545;&#31639;&#27861;&#24615;&#33021;&#30340;&#24433;&#21709;&#12290;&#36825;&#19968;&#26041;&#27861;&#22635;&#34917;&#20102;&#25512;&#33616;&#31995;&#32479;&#31639;&#27861;&#27604;&#36739;&#20013;&#30340;&#19981;&#36275;&#20043;&#22788;&#65292;&#25512;&#36827;&#20102;&#35780;&#20272;&#23454;&#36341;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24555;&#36895;&#21457;&#23637;&#30340;&#25512;&#33616;&#31995;&#32479;&#39046;&#22495;&#20013;&#65292;&#26032;&#30340;&#31639;&#27861;&#32463;&#24120;&#36890;&#36807;&#23545;&#19968;&#32452;&#26377;&#38480;&#30340;&#20219;&#24847;&#36873;&#25321;&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#35780;&#20272;&#26469;&#22768;&#31216;&#33258;&#24049;&#20855;&#26377;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#25968;&#25454;&#38598;&#29305;&#24449;&#23545;&#31639;&#27861;&#24615;&#33021;&#26377;&#37325;&#22823;&#24433;&#21709;&#65292;&#36825;&#31181;&#26041;&#27861;&#21487;&#33021;&#26080;&#27861;&#20840;&#38754;&#21453;&#26144;&#23427;&#20204;&#30340;&#26377;&#25928;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797;&#26041;&#27861;&#65292;&#20197;&#20419;&#36827;&#20844;&#24179;&#21644;&#31283;&#20581;&#30340;&#25512;&#33616;&#31995;&#32479;&#31639;&#27861;&#27604;&#36739;&#65292;&#20174;&#32780;&#25512;&#36827;&#35780;&#20272;&#23454;&#36341;&#12290;&#36890;&#36807;&#21033;&#29992;&#21253;&#25324;&#26412;&#25991;&#20171;&#32461;&#30340;&#20004;&#20010;&#25968;&#25454;&#38598;&#22312;&#20869;&#30340;30&#20010;&#24320;&#25918;&#25968;&#25454;&#38598;&#65292;&#24182;&#22312;9&#20010;&#24230;&#37327;&#25351;&#26631;&#19978;&#35780;&#20272;11&#31181;&#21327;&#21516;&#36807;&#28388;&#31639;&#27861;&#65292;&#25105;&#20204;&#23545;&#25968;&#25454;&#38598;&#29305;&#24449;&#23545;&#31639;&#27861;&#24615;&#33021;&#30340;&#24433;&#21709;&#36827;&#34892;&#20102;&#37325;&#35201;&#30340;&#30740;&#31350;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#30740;&#31350;&#20102;&#23558;&#22810;&#20010;&#25968;&#25454;&#38598;&#30340;&#32467;&#26524;&#32858;&#21512;&#25104;&#19968;&#20010;&#32479;&#19968;&#25490;&#21517;&#30340;&#21487;&#34892;&#24615;&#12290;&#36890;&#36807;&#20005;&#26684;&#30340;&#23454;&#39564;&#20998;&#26512;&#65292;&#25105;&#20204;&#21457;&#29616;......
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09766v1 Announce Type: cross  Abstract: In the rapidly evolving domain of Recommender Systems (RecSys), new algorithms frequently claim state-of-the-art performance based on evaluations over a limited set of arbitrarily selected datasets. However, this approach may fail to holistically reflect their effectiveness due to the significant impact of dataset characteristics on algorithm performance. Addressing this deficiency, this paper introduces a novel benchmarking methodology to facilitate a fair and robust comparison of RecSys algorithms, thereby advancing evaluation practices. By utilizing a diverse set of $30$ open datasets, including two introduced in this work, and evaluating $11$ collaborative filtering algorithms across $9$ metrics, we critically examine the influence of dataset characteristics on algorithm performance. We further investigate the feasibility of aggregating outcomes from multiple datasets into a unified ranking. Through rigorous experimental analysis, 
&lt;/p&gt;</description></item></channel></rss>