<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#25552;&#20986;&#20102;MerRec&#65292;&#36825;&#26159;&#39318;&#20010;&#19987;&#38376;&#38024;&#23545;C2C&#25512;&#33616;&#32780;&#25552;&#20986;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#65292;&#22635;&#34917;&#20102;C2C&#25512;&#33616;&#25968;&#25454;&#38598;&#20013;&#29289;&#21697;&#23646;&#24615;&#12289;&#29992;&#25143;&#22810;&#26679;&#24615;&#21644;&#35268;&#27169;&#31561;&#26041;&#38754;&#30340;&#32570;&#22833;&#12290;</title><link>https://arxiv.org/abs/2402.14230</link><description>&lt;p&gt;
MerRec&#65306;&#29992;&#20110;&#28040;&#36153;&#32773;&#23545;&#28040;&#36153;&#32773;&#25512;&#33616;&#31995;&#32479;&#30340;&#22823;&#35268;&#27169;&#22810;&#21151;&#33021;Mercari&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
MerRec: A Large-scale Multipurpose Mercari Dataset for Consumer-to-Consumer Recommendation Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14230
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;MerRec&#65292;&#36825;&#26159;&#39318;&#20010;&#19987;&#38376;&#38024;&#23545;C2C&#25512;&#33616;&#32780;&#25552;&#20986;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#65292;&#22635;&#34917;&#20102;C2C&#25512;&#33616;&#25968;&#25454;&#38598;&#20013;&#29289;&#21697;&#23646;&#24615;&#12289;&#29992;&#25143;&#22810;&#26679;&#24615;&#21644;&#35268;&#27169;&#31561;&#26041;&#38754;&#30340;&#32570;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#19981;&#26029;&#21457;&#23637;&#30340;&#30005;&#23376;&#21830;&#21153;&#39046;&#22495;&#20013;&#65292;&#25512;&#33616;&#31995;&#32479;&#33267;&#20851;&#37325;&#35201;&#22320;&#22609;&#36896;&#20102;&#29992;&#25143;&#20307;&#39564;&#21644;&#21442;&#19982;&#24230;&#12290;&#28040;&#36153;&#32773;&#23545;&#28040;&#36153;&#32773;&#65288;C2C&#65289;&#25512;&#33616;&#31995;&#32479;&#30340;&#23835;&#36215;&#65292;&#20197;&#20854;&#28789;&#27963;&#24615;&#21644;&#20026;&#23458;&#25143;&#20379;&#24212;&#21830;&#25552;&#20379;&#26131;&#20110;&#35775;&#38382;&#30340;&#29305;&#28857;&#65292;&#26631;&#24535;&#30528;&#19968;&#20010;&#37325;&#35201;&#36235;&#21183;&#12290;&#28982;&#32780;&#65292;&#23398;&#26415;&#20851;&#27880;&#20027;&#35201;&#38598;&#20013;&#22312;&#21830;&#23478;&#23545;&#28040;&#36153;&#32773;&#65288;B2C&#65289;&#27169;&#22411;&#19978;&#65292;&#30041;&#19979;&#20102;&#19968;&#20010;&#31354;&#30333;&#65292;&#21363;&#32570;&#20047;&#29289;&#21697;&#23646;&#24615;&#12289;&#29992;&#25143;&#22810;&#26679;&#24615;&#21644;&#35268;&#27169;&#30340;C2C&#25512;&#33616;&#25968;&#25454;&#38598;&#12290;C2C&#25512;&#33616;&#31995;&#32479;&#30340;&#22797;&#26434;&#24615;&#36827;&#19968;&#27493;&#31361;&#20986;&#20102;&#29992;&#25143;&#25198;&#28436;&#21334;&#23478;&#21644;&#20080;&#23478;&#20004;&#31181;&#35282;&#33394;&#30340;&#21452;&#37325;&#24615;&#36136;&#65292;&#24341;&#20837;&#20102;&#19968;&#31995;&#21015;&#19981;&#37027;&#20040;&#32479;&#19968;&#21644;&#22810;&#26679;&#21270;&#30340;&#36755;&#20837;&#12290;&#20026;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;MerRec&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#19987;&#38376;&#29992;&#20110;C2C&#25512;&#33616;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#65292;&#28304;&#33258;Mercari&#30005;&#23376;&#21830;&#21153;&#24179;&#21488;&#65292;&#35206;&#30422;&#20102;2023&#24180;6&#20010;&#26376;&#20869;&#25968;&#30334;&#19975;&#29992;&#25143;&#21644;&#20135;&#21697;&#12290;MerRec&#19981;&#20165;&#21253;&#25324;&#26631;&#20934;&#29305;&#24449;&#65292;&#22914;user_id&#12289;item_id&#21644;session_id
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14230v1 Announce Type: cross  Abstract: In the evolving e-commerce field, recommendation systems crucially shape user experience and engagement. The rise of Consumer-to-Consumer (C2C) recommendation systems, noted for their flexibility and ease of access for customer vendors, marks a significant trend. However, the academic focus remains largely on Business-to-Consumer (B2C) models, leaving a gap filled by the limited C2C recommendation datasets that lack in item attributes, user diversity, and scale. The intricacy of C2C recommendation systems is further accentuated by the dual roles users assume as both sellers and buyers, introducing a spectrum of less uniform and varied inputs. Addressing this, we introduce MerRec, the first large-scale dataset specifically for C2C recommendations, sourced from the Mercari e-commerce platform, covering millions of users and products over 6 months in 2023. MerRec not only includes standard features such as user_id, item_id, and session_id
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;&#21644;&#22522;&#20934;&#65292;&#26088;&#22312;&#25581;&#31034;&#29992;&#25143;&#36141;&#20080;&#20915;&#31574;&#32972;&#21518;&#30340;&#21407;&#22240;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26377;&#25928;&#30340;&#22522;&#20110;LLM&#30340;&#26041;&#27861;&#26469;&#29983;&#25104;&#39640;&#36136;&#37327;&#12289;&#20010;&#24615;&#21270;&#30340;&#36141;&#20080;&#21407;&#22240;&#35299;&#37322;&#12290;</title><link>https://arxiv.org/abs/2402.13417</link><description>&lt;p&gt;
&#35299;&#38145;&#36141;&#20080;&#30340;&#8220;&#20026;&#20309;&#8221;&#65306;&#24341;&#20837;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;&#21644;&#36141;&#20080;&#21407;&#22240;&#19982;&#21518;&#36141;&#20080;&#20307;&#39564;&#30340;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
Unlocking the `Why' of Buying: Introducing a New Dataset and Benchmark for Purchase Reason and Post-Purchase Experience
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13417
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;&#21644;&#22522;&#20934;&#65292;&#26088;&#22312;&#25581;&#31034;&#29992;&#25143;&#36141;&#20080;&#20915;&#31574;&#32972;&#21518;&#30340;&#21407;&#22240;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26377;&#25928;&#30340;&#22522;&#20110;LLM&#30340;&#26041;&#27861;&#26469;&#29983;&#25104;&#39640;&#36136;&#37327;&#12289;&#20010;&#24615;&#21270;&#30340;&#36141;&#20080;&#21407;&#22240;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35299;&#37322;&#23545;&#20110;&#25552;&#39640;&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#20013;&#29992;&#25143;&#20449;&#20219;&#21644;&#29702;&#35299;&#33267;&#20851;&#37325;&#35201;&#12290;&#20026;&#20102;&#26500;&#24314;&#30495;&#27491;&#21487;&#35299;&#37322;&#30340;&#31995;&#32479;&#65292;&#25105;&#20204;&#38656;&#35201;&#33021;&#38416;&#26126;&#29992;&#25143;&#20026;&#20309;&#20570;&#20986;&#36873;&#25321;&#30340;&#39640;&#36136;&#37327;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#36141;&#20080;&#21407;&#22240;&#35299;&#37322;&#20219;&#21153;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;LLM&#30340;&#26041;&#27861;&#26469;&#29983;&#25104;&#19968;&#20010;&#30001;&#30495;&#23454;&#29992;&#25143;&#35299;&#37322;&#20026;&#20309;&#20570;&#20986;&#26576;&#20123;&#36141;&#20080;&#20915;&#31574;&#30340;&#25991;&#26412;&#35299;&#37322;&#30340;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#35825;&#23548;LLM&#26126;&#30830;&#21306;&#20998;&#29992;&#25143;&#35780;&#35770;&#20013;&#36141;&#20080;&#20135;&#21697;&#32972;&#21518;&#30340;&#21407;&#22240;&#21644;&#36141;&#20080;&#21518;&#30340;&#20307;&#39564;&#12290;&#33258;&#21160;&#21270;&#30340;LLM&#39537;&#21160;&#35780;&#20272;&#20197;&#21450;&#23567;&#35268;&#27169;&#20154;&#24037;&#35780;&#20272;&#35777;&#23454;&#20102;&#25105;&#20204;&#26041;&#27861;&#33719;&#21462;&#39640;&#36136;&#37327;&#12289;&#20010;&#24615;&#21270;&#35299;&#37322;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#20010;&#24615;&#21270;&#25968;&#25454;&#38598;&#19978;&#23545;&#35813;&#25968;&#25454;&#38598;&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13417v1 Announce Type: new  Abstract: Explanations are crucial for enhancing user trust and understanding within modern recommendation systems. To build truly explainable systems, we need high-quality datasets that elucidate why users make choices. While previous efforts have focused on extracting users' post-purchase sentiment in reviews, they ignore the reasons behind the decision to buy.   In our work, we propose a novel purchase reason explanation task. To this end, we introduce an LLM-based approach to generate a dataset that consists of textual explanations of why real users make certain purchase decisions. We induce LLMs to explicitly distinguish between the reasons behind purchasing a product and the experience after the purchase in a user review. An automated, LLM-driven evaluation, as well as a small scale human evaluation, confirms the effectiveness of our approach to obtaining high-quality, personalized explanations. We benchmark this dataset on two personalized 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35774;&#35745;&#20102;&#19968;&#20010;&#22522;&#20934;&#27979;&#35797;&#26469;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#23545;&#32467;&#26500;&#21270;&#34920;&#26684;&#25968;&#25454;&#30340;&#29702;&#35299;&#33021;&#21147;&#65292;&#24182;&#21457;&#29616;&#19981;&#21516;&#30340;&#36755;&#20837;&#36873;&#25321;&#20250;&#23545;&#24615;&#33021;&#20135;&#29983;&#24433;&#21709;&#12290;&#22312;&#22522;&#20934;&#27979;&#35797;&#30340;&#22522;&#30784;&#19978;&#65292;&#25552;&#20986;&#20102;&#8220;&#33258;&#25105;&#22686;&#24378;&#8221;&#25216;&#26415;&#20197;&#25913;&#21892;&#29702;&#35299;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2305.13062</link><description>&lt;p&gt;
GPT4Table&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#29702;&#35299;&#32467;&#26500;&#21270;&#34920;&#26684;&#25968;&#25454;&#21527;&#65311;&#19968;&#39033;&#22522;&#20934;&#27979;&#35797;&#21644;&#23454;&#35777;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
GPT4Table: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study. (arXiv:2305.13062v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13062
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35774;&#35745;&#20102;&#19968;&#20010;&#22522;&#20934;&#27979;&#35797;&#26469;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#23545;&#32467;&#26500;&#21270;&#34920;&#26684;&#25968;&#25454;&#30340;&#29702;&#35299;&#33021;&#21147;&#65292;&#24182;&#21457;&#29616;&#19981;&#21516;&#30340;&#36755;&#20837;&#36873;&#25321;&#20250;&#23545;&#24615;&#33021;&#20135;&#29983;&#24433;&#21709;&#12290;&#22312;&#22522;&#20934;&#27979;&#35797;&#30340;&#22522;&#30784;&#19978;&#65292;&#25552;&#20986;&#20102;&#8220;&#33258;&#25105;&#22686;&#24378;&#8221;&#25216;&#26415;&#20197;&#25913;&#21892;&#29702;&#35299;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20316;&#20026;&#23569;&#26679;&#26412;&#25512;&#29702;&#22120;&#26469;&#35299;&#20915;&#19982;&#33258;&#28982;&#35821;&#35328;&#30456;&#20851;&#30340;&#20219;&#21153;&#36234;&#26469;&#36234;&#20855;&#21560;&#24341;&#21147;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;LLMs&#23545;&#32467;&#26500;&#21270;&#25968;&#25454;&#65288;&#20363;&#22914;&#34920;&#26684;&#65289;&#30340;&#29702;&#35299;&#31243;&#24230;&#36824;&#26377;&#24456;&#22810;&#38656;&#35201;&#23398;&#20064;&#30340;&#22320;&#26041;&#12290;&#23613;&#31649;&#21487;&#20197;&#20351;&#29992;&#34920;&#26684;&#24207;&#21015;&#21270;&#20316;&#20026;LLMs&#30340;&#36755;&#20837;&#65292;&#20294;&#30446;&#21069;&#36824;&#32570;&#20047;&#23545;LLMs&#26159;&#21542;&#30495;&#27491;&#33021;&#22815;&#29702;&#35299;&#36825;&#31867;&#25968;&#25454;&#30340;&#20840;&#38754;&#30740;&#31350;&#12290;&#26412;&#25991;&#36890;&#36807;&#35774;&#35745;&#19968;&#20010;&#22522;&#20934;&#27979;&#35797;&#26469;&#35780;&#20272;LLMs&#30340;&#32467;&#26500;&#29702;&#35299;&#33021;&#21147;&#65288;SUC&#65289;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#21019;&#24314;&#30340;&#22522;&#20934;&#27979;&#35797;&#21253;&#25324;&#19971;&#20010;&#20219;&#21153;&#65292;&#27599;&#20010;&#20219;&#21153;&#37117;&#26377;&#20854;&#29420;&#29305;&#30340;&#25361;&#25112;&#65292;&#20363;&#22914;&#21333;&#20803;&#26684;&#26597;&#25214;&#12289;&#34892;&#26816;&#32034;&#21644;&#22823;&#23567;&#26816;&#27979;&#12290;&#25105;&#20204;&#23545;GPT-3.5&#21644;GPT-4&#36827;&#34892;&#20102;&#19968;&#31995;&#21015;&#35780;&#20272;&#12290;&#25105;&#20204;&#21457;&#29616;&#24615;&#33021;&#22240;&#22810;&#31181;&#36755;&#20837;&#36873;&#25321;&#32780;&#24322;&#65292;&#21253;&#25324;&#34920;&#26684;&#36755;&#20837;&#26684;&#24335;&#12289;&#20869;&#23481;&#39034;&#24207;&#12289;&#35282;&#33394;&#25552;&#31034;&#21644;&#20998;&#21306;&#26631;&#35760;&#31561;&#12290;&#26681;&#25454;&#22522;&#20934;&#27979;&#35797;&#35780;&#20272;&#25152;&#24471;&#30340;&#35265;&#35299;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#8220;&#33258;&#25105;&#22686;&#24378;&#8221;&#25216;&#26415;&#20197;&#25913;&#21892;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) are becoming attractive as few-shot reasoners to solve Natural Language (NL)-related tasks. However, there is still much to learn about how well LLMs understand structured data, such as tables. While it is true that tables can be used as inputs to LLMs with serialization, there lack of comprehensive studies examining whether LLMs can truly comprehend such data. In this paper, we try to understand this by designing a benchmark to evaluate the structural understanding capabilities (SUC) of LLMs. The benchmark we create includes seven tasks, each with its own unique challenges, \eg, cell lookup, row retrieval, and size detection. We run a series of evaluations on GPT-3.5 and GPT-4. We discover that the performance varied depending on a number of input choices, including table input format, content order, role prompting, and partition marks. Drawing from the insights gained through the benchmark evaluations, we then propose \textit{self-augmentation} for effect
&lt;/p&gt;</description></item></channel></rss>