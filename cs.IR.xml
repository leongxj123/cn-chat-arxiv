<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;GNN&#30340;&#26694;&#26550;&#65292;&#22312;&#23454;&#20307;&#23545;&#40784;&#20013;&#35299;&#20915;&#20102;&#26080;&#26631;&#31614;&#24748;&#25346;&#26696;&#20363;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#35774;&#35745;&#27880;&#24847;&#26426;&#21046;&#21644;&#27491;&#26679;&#26412;-&#26080;&#26631;&#31614;&#25439;&#22833;&#26469;&#23454;&#29616;&#26356;&#22909;&#30340;&#23545;&#40784;&#24615;&#33021;</title><link>https://arxiv.org/abs/2403.10978</link><description>&lt;p&gt;
&#20855;&#26377;&#26080;&#26631;&#31614;&#24748;&#25346;&#26696;&#20363;&#30340;&#23454;&#20307;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Entity Alignment with Unlabeled Dangling Cases
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10978
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;GNN&#30340;&#26694;&#26550;&#65292;&#22312;&#23454;&#20307;&#23545;&#40784;&#20013;&#35299;&#20915;&#20102;&#26080;&#26631;&#31614;&#24748;&#25346;&#26696;&#20363;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#35774;&#35745;&#27880;&#24847;&#26426;&#21046;&#21644;&#27491;&#26679;&#26412;-&#26080;&#26631;&#31614;&#25439;&#22833;&#26469;&#23454;&#29616;&#26356;&#22909;&#30340;&#23545;&#40784;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#26080;&#26631;&#31614;&#24748;&#25346;&#26696;&#20363;&#30340;&#23454;&#20307;&#23545;&#40784;&#38382;&#39064;&#65292;&#36825;&#24847;&#21619;&#30528;&#28304;&#22270;&#25110;&#30446;&#26631;&#22270;&#20013;&#26377;&#19968;&#20123;&#23454;&#20307;&#22312;&#21478;&#19968;&#26041;&#20013;&#27809;&#26377;&#23545;&#24212;&#23454;&#20307;&#65292;&#24182;&#19988;&#36825;&#20123;&#23454;&#20307;&#20445;&#25345;&#26410;&#26631;&#35760;&#29366;&#24577;&#12290;&#35813;&#38382;&#39064;&#20986;&#29616;&#22312;&#28304;&#22270;&#21644;&#30446;&#26631;&#22270;&#30340;&#35268;&#27169;&#19981;&#21516;&#65292;&#24182;&#19988;&#26631;&#35760;&#21487;&#21305;&#37197;&#23454;&#20307;&#30340;&#25104;&#26412;&#36828;&#20302;&#20110;&#24748;&#25346;&#23454;&#20307;&#30340;&#24773;&#20917;&#19979;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;GNN&#30340;&#24748;&#25346;&#26816;&#27979;&#21644;&#23454;&#20307;&#23545;&#40784;&#26694;&#26550;&#12290;&#34429;&#28982;&#36825;&#20004;&#20010;&#20219;&#21153;&#20849;&#20139;&#30456;&#21516;&#30340;GNN&#65292;&#24182;&#19988;&#19968;&#36215;&#35757;&#32451;&#65292;&#20294;&#26816;&#27979;&#21040;&#30340;&#24748;&#25346;&#23454;&#20307;&#22312;&#23545;&#40784;&#20013;&#34987;&#31227;&#38500;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#29305;&#28857;&#26159;&#20855;&#26377;&#29992;&#20110;&#36873;&#25321;&#24615;&#37051;&#22495;&#32858;&#21512;&#30340;&#35774;&#35745;&#23454;&#20307;&#21644;&#20851;&#31995;&#27880;&#24847;&#26426;&#21046;&#65292;&#20197;&#21450;&#29992;&#20110;&#23545;&#24748;&#25346;&#23454;&#20307;&#36827;&#34892;&#26080;&#20559;&#20272;&#35745;&#30340;&#27491;&#26679;&#26412;-&#26080;&#26631;&#31614;&#23398;&#20064;&#25439;&#22833;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#25105;&#20204;&#35774;&#35745;&#30340;&#27599;&#20010;&#32452;&#20214;&#37117;&#23545;&#25972;&#20307;&#23545;&#40784;&#24615;&#33021;&#26377;&#36129;&#29486;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10978v1 Announce Type: new  Abstract: We investigate the entity alignment problem with unlabeled dangling cases, meaning that there are entities in the source or target graph having no counterparts in the other, and those entities remain unlabeled. The problem arises when the source and target graphs are of different scales, and it is much cheaper to label the matchable pairs than the dangling entities. To solve the issue, we propose a novel GNN-based dangling detection and entity alignment framework. While the two tasks share the same GNN and are trained together, the detected dangling entities are removed in the alignment. Our framework is featured by a designed entity and relation attention mechanism for selective neighborhood aggregation in representation learning, as well as a positive-unlabeled learning loss for an unbiased estimation of dangling entities. Experimental results have shown that each component of our design contributes to the overall alignment performance
&lt;/p&gt;</description></item><item><title>&#24314;&#31435;&#20102;&#29992;&#20110;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22810;&#35821;&#35328;&#29615;&#22659;&#20013;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#20013;&#30340;&#40065;&#26834;&#24615;&#30340;NoMIRACL&#25968;&#25454;&#38598;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#20010;&#34913;&#37327;&#27169;&#22411;&#40065;&#26834;&#24615;&#30340;&#25351;&#26631;&#65306;&#24187;&#35273;&#29575;&#21644;&#38169;&#35823;&#29575;&#12290;</title><link>https://arxiv.org/abs/2312.11361</link><description>&lt;p&gt;
NoMIRACL: &#30693;&#36947;&#33258;&#24049;&#19981;&#30693;&#36947;&#30340;&#40065;&#26834;&#22810;&#35821;&#35328;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
NoMIRACL: Knowing When You Don't Know for Robust Multilingual Retrieval-Augmented Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.11361
&lt;/p&gt;
&lt;p&gt;
&#24314;&#31435;&#20102;&#29992;&#20110;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22810;&#35821;&#35328;&#29615;&#22659;&#20013;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#20013;&#30340;&#40065;&#26834;&#24615;&#30340;NoMIRACL&#25968;&#25454;&#38598;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#20010;&#34913;&#37327;&#27169;&#22411;&#40065;&#26834;&#24615;&#30340;&#25351;&#26631;&#65306;&#24187;&#35273;&#29575;&#21644;&#38169;&#35823;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2312.11361v2 &#20844;&#21578;&#31867;&#22411;: &#26367;&#25442; &#25688;&#35201;: &#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#36890;&#36807;&#21033;&#29992;&#22806;&#37096;&#30693;&#35782;&#28304;&#26469;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#36755;&#20986;&#19982;&#29616;&#23454;&#32852;&#31995;&#36215;&#26469;&#65292;&#20197;&#20943;&#23569;&#20107;&#23454;&#24187;&#35273;&#12290;&#28982;&#32780;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#32570;&#20047;&#23545;&#19981;&#21516;&#35821;&#35328;&#26063;&#30340;&#20840;&#38754;&#35780;&#20272;&#65292;&#36825;&#20351;&#24471;&#24456;&#38590;&#35780;&#20272;LLM&#23545;&#22806;&#37096;&#26816;&#32034;&#30693;&#35782;&#38169;&#35823;&#30340;&#40065;&#26834;&#24615;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;NoMIRACL&#65292;&#36825;&#26159;&#19968;&#20010;&#20154;&#31867;&#27880;&#37322;&#30340;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#35780;&#20272;RAG&#20013;LLM&#23545;18&#31181;&#22312;&#31867;&#22411;&#19978;&#22810;&#26679;&#21270;&#30340;&#35821;&#35328;&#30340;&#40065;&#26834;&#24615;&#12290;NoMIRACL&#21253;&#25324;&#19968;&#20010;&#38750;&#30456;&#20851;&#23376;&#38598;&#21644;&#19968;&#20010;&#30456;&#20851;&#23376;&#38598;&#12290;&#38750;&#30456;&#20851;&#23376;&#38598;&#20013;&#30340;&#26597;&#35810;&#21253;&#21547;&#34987;&#21028;&#26029;&#20026;&#19981;&#30456;&#20851;&#30340;&#27573;&#33853;&#65292;&#32780;&#30456;&#20851;&#23376;&#38598;&#20013;&#30340;&#26597;&#35810;&#33267;&#23569;&#21253;&#21547;&#19968;&#20010;&#34987;&#21028;&#26029;&#20026;&#30456;&#20851;&#30340;&#27573;&#33853;&#12290;&#25105;&#20204;&#20351;&#29992;&#20004;&#20010;&#25351;&#26631;&#26469;&#34913;&#37327;LLM&#30340;&#40065;&#26834;&#24615;&#65306;&#65288;i&#65289;&#24187;&#35273;&#29575;&#65292;&#34913;&#37327;&#27169;&#22411;&#20542;&#21521;&#20110;&#22312;&#38750;&#30456;&#20851;&#23376;&#38598;&#30340;&#27573;&#33853;&#20013;&#20135;&#29983;&#24187;&#35273;&#31572;&#26696;&#30340;&#31243;&#24230;&#65292;&#20197;&#21450;&#65288;ii&#65289;&#38169;&#35823;&#29575;&#65292;&#34913;&#37327;&#27169;&#22411;&#30340;&#19981;&#20934;&#30830;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.11361v2 Announce Type: replace  Abstract: Retrieval-augmented generation (RAG) grounds large language model (LLM) output by leveraging external knowledge sources to reduce factual hallucinations. However, prior works lack a comprehensive evaluation of different language families, making it challenging to evaluate LLM robustness against errors in external retrieved knowledge. To overcome this, we establish NoMIRACL, a human-annotated dataset for evaluating LLM robustness in RAG across 18 typologically diverse languages. NoMIRACL includes both a non-relevant and a relevant subset. Queries in the non-relevant subset contain passages judged as non-relevant, whereas queries in the relevant subset include at least a single judged relevant passage. We measure LLM robustness using two metrics: (i) hallucination rate, measuring model tendency to hallucinate an answer, when the answer is not present in passages in the non-relevant subset, and (ii) error rate, measuring model inaccurac
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#25512;&#33616;&#20013;&#24847;&#22270;&#23398;&#20064;&#30340;&#31471;&#21040;&#31471;&#21487;&#23398;&#20064;&#32858;&#31867;&#26041;&#27861;ELCRec&#65292;&#35813;&#26041;&#27861;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#20013;&#30340;&#22797;&#26434;&#20248;&#21270;&#38382;&#39064;&#21644;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#32858;&#31867;&#30340;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.05975</link><description>&lt;p&gt;
&#29992;&#20110;&#25512;&#33616;&#20013;&#24847;&#22270;&#23398;&#20064;&#30340;&#31471;&#21040;&#31471;&#21487;&#23398;&#20064;&#32858;&#31867;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
End-to-end Learnable Clustering for Intent Learning in Recommendation. (arXiv:2401.05975v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05975
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#25512;&#33616;&#20013;&#24847;&#22270;&#23398;&#20064;&#30340;&#31471;&#21040;&#31471;&#21487;&#23398;&#20064;&#32858;&#31867;&#26041;&#27861;ELCRec&#65292;&#35813;&#26041;&#27861;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#20013;&#30340;&#22797;&#26434;&#20248;&#21270;&#38382;&#39064;&#21644;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#32858;&#31867;&#30340;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25366;&#25496;&#29992;&#25143;&#30340;&#24847;&#22270;&#22312;&#24207;&#21015;&#25512;&#33616;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#26368;&#36817;&#30340;&#26041;&#27861;ICLRec&#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#21644;&#32858;&#31867;&#26469;&#25552;&#21462;&#29992;&#25143;&#30340;&#28508;&#22312;&#24847;&#22270;&#12290;&#23613;&#31649;&#23427;&#24050;&#32463;&#26174;&#31034;&#20986;&#26377;&#25928;&#24615;&#65292;&#20294;&#29616;&#26377;&#30340;&#26041;&#27861;&#23384;&#22312;&#22797;&#26434;&#21644;&#32321;&#29712;&#30340;&#20132;&#26367;&#20248;&#21270;&#38382;&#39064;&#65292;&#23548;&#33268;&#20004;&#20010;&#20027;&#35201;&#38382;&#39064;&#12290;&#39318;&#20808;&#65292;&#22312;&#24191;&#20041;&#26399;&#26395;&#26368;&#22823;&#21270;(EM)&#26694;&#26550;&#20013;&#20998;&#31163;&#34920;&#31034;&#23398;&#20064;&#21644;&#32858;&#31867;&#20248;&#21270;&#32463;&#24120;&#23548;&#33268;&#27425;&#20248;&#24615;&#33021;&#12290;&#20854;&#27425;&#65292;&#22312;&#25972;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#32858;&#31867;&#20250;&#24433;&#21709;&#22823;&#35268;&#27169;&#34892;&#19994;&#25968;&#25454;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24847;&#22270;&#23398;&#20064;&#26041;&#27861;&#65292;&#31216;&#20026;ELCRec&#65292;&#23427;&#23558;&#34920;&#31034;&#23398;&#20064;&#38598;&#25104;&#21040;&#19968;&#20010;&#31471;&#21040;&#31471;&#21487;&#23398;&#20064;&#32858;&#31867;&#26694;&#26550;&#20013;&#36827;&#34892;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mining users' intents plays a crucial role in sequential recommendation. The recent approach, ICLRec, was introduced to extract underlying users' intents using contrastive learning and clustering. While it has shown effectiveness, the existing method suffers from complex and cumbersome alternating optimization, leading to two main issues. Firstly, the separation of representation learning and clustering optimization within a generalized expectation maximization (EM) framework often results in sub-optimal performance. Secondly, performing clustering on the entire dataset hampers scalability for large-scale industry data. To address these challenges, we propose a novel intent learning method called \underline{ELCRec}, which integrates representation learning into an \underline{E}nd-to-end \underline{L}earnable \underline{C}lustering framework for \underline{Rec}ommendation. Specifically, we encode users' behavior sequences and initialize the cluster centers as learnable network parameter
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26469;&#22686;&#24378;&#22522;&#20110;&#20869;&#23481;&#30340;&#25512;&#33616;&#20013;&#30340;&#20813;&#35757;&#32451;&#25968;&#25454;&#38598;&#21387;&#32553;&#26041;&#27861;&#65292;&#26088;&#22312;&#36890;&#36807;&#29983;&#25104;&#25991;&#26412;&#20869;&#23481;&#26469;&#21512;&#25104;&#19968;&#20010;&#23567;&#32780;&#20449;&#24687;&#20016;&#23500;&#30340;&#25968;&#25454;&#38598;&#65292;&#20351;&#24471;&#27169;&#22411;&#33021;&#22815;&#36798;&#21040;&#19982;&#22312;&#22823;&#22411;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.09874</link><description>&lt;p&gt;
&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22686;&#24378;&#22522;&#20110;&#20869;&#23481;&#30340;&#25512;&#33616;&#30340;&#20813;&#35757;&#32451;&#25968;&#25454;&#38598;&#21387;&#32553;
&lt;/p&gt;
&lt;p&gt;
Leveraging Large Language Models (LLMs) to Empower Training-Free Dataset Condensation for Content-Based Recommendation. (arXiv:2310.09874v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09874
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26469;&#22686;&#24378;&#22522;&#20110;&#20869;&#23481;&#30340;&#25512;&#33616;&#20013;&#30340;&#20813;&#35757;&#32451;&#25968;&#25454;&#38598;&#21387;&#32553;&#26041;&#27861;&#65292;&#26088;&#22312;&#36890;&#36807;&#29983;&#25104;&#25991;&#26412;&#20869;&#23481;&#26469;&#21512;&#25104;&#19968;&#20010;&#23567;&#32780;&#20449;&#24687;&#20016;&#23500;&#30340;&#25968;&#25454;&#38598;&#65292;&#20351;&#24471;&#27169;&#22411;&#33021;&#22815;&#36798;&#21040;&#19982;&#22312;&#22823;&#22411;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#20869;&#23481;&#25512;&#33616;&#65288;CBR&#65289;&#25216;&#26415;&#21033;&#29992;&#29289;&#21697;&#30340;&#20869;&#23481;&#20449;&#24687;&#20026;&#29992;&#25143;&#25552;&#20379;&#20010;&#24615;&#21270;&#26381;&#21153;&#65292;&#20294;&#22312;&#22823;&#22411;&#25968;&#25454;&#38598;&#19978;&#30340;&#36164;&#28304;&#23494;&#38598;&#22411;&#35757;&#32451;&#23384;&#22312;&#38382;&#39064;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25506;&#35752;&#20102;&#23545;&#25991;&#26412;CBR&#36827;&#34892;&#25968;&#25454;&#38598;&#21387;&#32553;&#30340;&#26041;&#27861;&#12290;&#25968;&#25454;&#38598;&#21387;&#32553;&#30340;&#30446;&#26631;&#26159;&#21512;&#25104;&#19968;&#20010;&#23567;&#19988;&#20449;&#24687;&#20016;&#23500;&#30340;&#25968;&#25454;&#38598;&#65292;&#20351;&#27169;&#22411;&#24615;&#33021;&#21487;&#20197;&#19982;&#22312;&#22823;&#22411;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#30456;&#23218;&#32654;&#12290;&#29616;&#26377;&#30340;&#21387;&#32553;&#26041;&#27861;&#38024;&#23545;&#36830;&#32493;&#25968;&#25454;&#65288;&#22914;&#22270;&#20687;&#25110;&#23884;&#20837;&#21521;&#37327;&#65289;&#30340;&#20998;&#31867;&#20219;&#21153;&#32780;&#35774;&#35745;&#65292;&#30452;&#25509;&#24212;&#29992;&#20110;CBR&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22522;&#20110;&#20869;&#23481;&#30340;&#25512;&#33616;&#20013;&#39640;&#25928;&#30340;&#25968;&#25454;&#38598;&#21387;&#32553;&#26041;&#27861;&#12290;&#21463;&#21040;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#25991;&#26412;&#29702;&#35299;&#21644;&#29983;&#25104;&#26041;&#38754;&#20986;&#33394;&#30340;&#33021;&#21147;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#21033;&#29992;LLMs&#22312;&#25968;&#25454;&#38598;&#21387;&#32553;&#26399;&#38388;&#29983;&#25104;&#25991;&#26412;&#20869;&#23481;&#12290;&#20026;&#20102;&#22788;&#29702;&#28041;&#21450;&#29992;&#25143;&#21644;&#29289;&#21697;&#30340;&#20132;&#20114;&#25968;&#25454;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#21452;...
&lt;/p&gt;
&lt;p&gt;
Modern techniques in Content-based Recommendation (CBR) leverage item content information to provide personalized services to users, but suffer from resource-intensive training on large datasets. To address this issue, we explore the dataset condensation for textual CBR in this paper. The goal of dataset condensation is to synthesize a small yet informative dataset, upon which models can achieve performance comparable to those trained on large datasets. While existing condensation approaches are tailored to classification tasks for continuous data like images or embeddings, direct application of them to CBR has limitations. To bridge this gap, we investigate efficient dataset condensation for content-based recommendation. Inspired by the remarkable abilities of large language models (LLMs) in text comprehension and generation, we leverage LLMs to empower the generation of textual content during condensation. To handle the interaction data involving both users and items, we devise a dua
&lt;/p&gt;</description></item></channel></rss>