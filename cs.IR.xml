<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#20869;&#23481;&#30340;&#21327;&#20316;&#29983;&#25104;&#24335;&#25512;&#33616;&#31995;&#32479;ColaRec&#65292;&#26088;&#22312;&#35299;&#20915;&#29983;&#25104;&#24335;&#25512;&#33616;&#20013;&#30340;&#21327;&#20316;&#20449;&#21495;&#38598;&#25104;&#21644;&#20449;&#24687;&#23545;&#40784;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2403.18480</link><description>&lt;p&gt;
&#36890;&#36807;&#20869;&#23481;&#21644;&#21327;&#20316;&#38598;&#25104;&#22686;&#24378;&#29983;&#25104;&#24335;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Enhanced Generative Recommendation via Content and Collaboration Integration
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18480
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#20869;&#23481;&#30340;&#21327;&#20316;&#29983;&#25104;&#24335;&#25512;&#33616;&#31995;&#32479;ColaRec&#65292;&#26088;&#22312;&#35299;&#20915;&#29983;&#25104;&#24335;&#25512;&#33616;&#20013;&#30340;&#21327;&#20316;&#20449;&#21495;&#38598;&#25104;&#21644;&#20449;&#24687;&#23545;&#40784;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24335;&#25512;&#33616;&#24050;&#32463;&#20986;&#29616;&#20316;&#20026;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#33539;&#24335;&#65292;&#26088;&#22312;&#36890;&#36807;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#30340;&#26368;&#26032;&#36827;&#23637;&#26469;&#22686;&#24378;&#25512;&#33616;&#31995;&#32479;&#12290;&#26412;&#20219;&#21153;&#34987;&#21046;&#23450;&#20026;&#19968;&#20010;&#24207;&#21015;&#21040;&#24207;&#21015;&#30340;&#29983;&#25104;&#36807;&#31243;&#65292;&#20854;&#20013;&#36755;&#20837;&#24207;&#21015;&#21253;&#21547;&#19982;&#29992;&#25143;&#20808;&#21069;&#20132;&#20114;&#30340;&#39033;&#30446;&#30456;&#20851;&#30340;&#25968;&#25454;&#65292;&#36755;&#20986;&#24207;&#21015;&#34920;&#31034;&#24314;&#35758;&#39033;&#30446;&#30340;&#29983;&#25104;&#26631;&#35782;&#31526;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#29983;&#25104;&#24335;&#25512;&#33616;&#26041;&#27861;&#20173;&#28982;&#38754;&#20020;&#30528;&#20197;&#19979;&#25361;&#25112;&#65306;&#26377;&#25928;&#22320;&#22312;&#32479;&#19968;&#29983;&#25104;&#26694;&#26550;&#20869;&#38598;&#25104;&#29992;&#25143;-&#39033;&#30446;&#21327;&#20316;&#20449;&#21495;&#21644;&#39033;&#30446;&#20869;&#23481;&#20449;&#24687;&#65292;&#20197;&#21450;&#22312;&#20869;&#23481;&#20449;&#24687;&#21644;&#21327;&#20316;&#20449;&#21495;&#20043;&#38388;&#25191;&#34892;&#39640;&#25928;&#30340;&#23545;&#40784;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18480v1 Announce Type: new  Abstract: Generative recommendation has emerged as a promising paradigm aimed at augmenting recommender systems with recent advancements in generative artificial intelligence. This task has been formulated as a sequence-to-sequence generation process, wherein the input sequence encompasses data pertaining to the user's previously interacted items, and the output sequence denotes the generative identifier for the suggested item. However, existing generative recommendation approaches still encounter challenges in (i) effectively integrating user-item collaborative signals and item content information within a unified generative framework, and (ii) executing an efficient alignment between content information and collaborative signals.   In this paper, we introduce content-based collaborative generation for recommender systems, denoted as ColaRec. To capture collaborative signals, the generative item identifiers are derived from a pretrained collabora
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#35299;&#37322;&#21644;&#35782;&#21035;&#20234;&#26031;&#20848;&#25945;&#20167;&#24680;&#35328;&#35770;&#65292;&#27169;&#22411;&#22312;&#20445;&#25345;&#20986;&#33394;&#24615;&#33021;&#30340;&#21516;&#26102;&#33021;&#22815;&#35299;&#37322;&#30456;&#20851;&#24615;&#21644;&#22240;&#26524;&#20851;&#31995;&#12290;</title><link>https://arxiv.org/abs/2311.04916</link><description>&lt;p&gt;
&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#35299;&#37322;&#20234;&#26031;&#20848;&#25945;&#20167;&#24680;&#35328;&#35770;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Explainable Identification of Hate Speech towards Islam using Graph Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.04916
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#35299;&#37322;&#21644;&#35782;&#21035;&#20234;&#26031;&#20848;&#25945;&#20167;&#24680;&#35328;&#35770;&#65292;&#27169;&#22411;&#22312;&#20445;&#25345;&#20986;&#33394;&#24615;&#33021;&#30340;&#21516;&#26102;&#33021;&#22815;&#35299;&#37322;&#30456;&#20851;&#24615;&#21644;&#22240;&#26524;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20234;&#26031;&#20848;&#25945;&#20167;&#24680;&#35328;&#35770;&#22312;&#22312;&#32447;&#31038;&#20132;&#20114;&#21160;&#24179;&#21488;&#19978;&#26159;&#19968;&#20010;&#26222;&#36941;&#23384;&#22312;&#30340;&#25361;&#25112;&#12290;&#35782;&#21035;&#21644;&#28040;&#38500;&#36825;&#31181;&#20167;&#24680;&#26159;&#36808;&#21521;&#21644;&#35856;&#19982;&#21644;&#24179;&#26410;&#26469;&#30340;&#20851;&#38190;&#19968;&#27493;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33539;&#20363;&#65292;&#21033;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#26469;&#35782;&#21035;&#21644;&#35299;&#37322;&#38024;&#23545;&#20234;&#26031;&#20848;&#25945;&#30340;&#20167;&#24680;&#35328;&#35770;&#12290;&#21033;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#21457;&#29616;&#12289;&#25552;&#21462;&#24182;&#21033;&#29992;&#19981;&#21516;&#25968;&#25454;&#28857;&#20043;&#38388;&#30340;&#20851;&#31995;&#30340;&#20869;&#22312;&#33021;&#21147;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#22987;&#32456;&#33021;&#22815;&#22312;&#20445;&#25345;&#20986;&#33394;&#24615;&#33021;&#30340;&#21516;&#26102;&#25552;&#20379;&#23545;&#28508;&#22312;&#30456;&#20851;&#24615;&#21644;&#22240;&#26524;&#20851;&#31995;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.04916v2 Announce Type: cross  Abstract: Islamophobic language is a prevalent challenge on online social interaction platforms. Identifying and eliminating such hatred is a crucial step towards a future of harmony and peace. This study presents a novel paradigm for identifying and explaining hate speech towards Islam using graph neural networks. Utilizing the intrinsic ability of graph neural networks to find, extract, and use relationships across disparate data points, our model consistently achieves outstanding performance while offering explanations for the underlying correlations and causation.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;sRank&#30340;&#36890;&#29992;&#35821;&#20041;&#23398;&#20064;&#25490;&#21517;&#26694;&#26550;&#65292;&#23427;&#20351;&#29992;transformer&#27169;&#22411;&#65292;&#33021;&#22815;&#22312;&#26234;&#33021;&#22238;&#22797;&#21644;&#29615;&#22659;&#20020;&#24202;&#26234;&#33021;&#31561;&#30495;&#23454;&#24212;&#29992;&#20013;&#65292;&#23454;&#29616;11.7%&#30340;&#31163;&#32447;&#20934;&#30830;&#24230;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2304.04918</link><description>&lt;p&gt;
&#26174;&#24335;&#21644;&#38544;&#24335;&#35821;&#20041;&#25490;&#24207;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Explicit and Implicit Semantic Ranking Framework. (arXiv:2304.04918v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04918
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;sRank&#30340;&#36890;&#29992;&#35821;&#20041;&#23398;&#20064;&#25490;&#21517;&#26694;&#26550;&#65292;&#23427;&#20351;&#29992;transformer&#27169;&#22411;&#65292;&#33021;&#22815;&#22312;&#26234;&#33021;&#22238;&#22797;&#21644;&#29615;&#22659;&#20020;&#24202;&#26234;&#33021;&#31561;&#30495;&#23454;&#24212;&#29992;&#20013;&#65292;&#23454;&#29616;11.7%&#30340;&#31163;&#32447;&#20934;&#30830;&#24230;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#26680;&#24515;&#38590;&#39064;&#26159;&#23558;&#19968;&#20010;&#26597;&#35810;&#19982;&#19968;&#20010;&#21487;&#21464;&#19988;&#26377;&#38480;&#30340;&#25991;&#26723;&#38598;&#20013;&#30340;&#26368;&#20339;&#25991;&#26723;&#36827;&#34892;&#21305;&#37197;&#12290;&#29616;&#26377;&#30340;&#24037;&#19994;&#35299;&#20915;&#26041;&#26696;&#65292;&#29305;&#21035;&#26159;&#24310;&#36831;&#21463;&#38480;&#30340;&#26381;&#21153;&#65292;&#36890;&#24120;&#20381;&#36182;&#20110;&#30456;&#20284;&#24615;&#31639;&#27861;&#65292;&#36825;&#20123;&#31639;&#27861;&#20026;&#20102;&#36895;&#24230;&#32780;&#29306;&#29298;&#20102;&#36136;&#37327;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#35821;&#20041;&#23398;&#20064;&#25490;&#21517;&#26694;&#26550;&#65292;&#33258;&#25105;&#35757;&#32451;&#35821;&#20041;&#20132;&#21449;&#20851;&#27880;&#25490;&#21517;&#65288;sRank&#65289;&#12290;&#36825;&#20010;&#22522;&#20110;transformer&#30340;&#26694;&#26550;&#20351;&#29992;&#32447;&#24615;&#25104;&#23545;&#25439;&#22833;&#65292;&#20855;&#26377;&#21487;&#21464;&#30340;&#35757;&#32451;&#25209;&#37327;&#22823;&#23567;&#12289;&#23454;&#29616;&#36136;&#37327;&#25552;&#21319;&#21644;&#39640;&#25928;&#29575;&#65292;&#24182;&#24050;&#25104;&#21151;&#24212;&#29992;&#20110;&#24494;&#36719;&#20844;&#21496;&#30340;&#20004;&#20010;&#24037;&#19994;&#20219;&#21153;&#65306;&#26234;&#33021;&#22238;&#22797;&#65288;SR&#65289;&#21644;&#29615;&#22659;&#20020;&#24202;&#26234;&#33021;&#65288;ACI&#65289;&#30340;&#30495;&#23454;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#12290;&#22312;&#26234;&#33021;&#22238;&#22797;&#20013;&#65292;$sRank$&#36890;&#36807;&#22522;&#20110;&#28040;&#36153;&#32773;&#21644;&#25903;&#25345;&#20195;&#29702;&#20449;&#24687;&#30340;&#39044;&#23450;&#20041;&#35299;&#20915;&#26041;&#26696;&#36873;&#25321;&#26368;&#20339;&#31572;&#26696;&#65292;&#24110;&#21161;&#29992;&#25143;&#23454;&#26102;&#33719;&#24471;&#25216;&#26415;&#25903;&#25345;&#12290;&#22312;SR&#20219;&#21153;&#19978;&#65292;$sRank$&#23454;&#29616;&#20102;11.7%&#30340;&#31163;&#32447;top-one&#20934;&#30830;&#24230;&#25552;&#21319;&#65292;&#27604;&#20043;&#21069;&#30340;&#31995;&#32479;&#26356;&#21152;&#20248;&#31168;&#12290;
&lt;/p&gt;
&lt;p&gt;
The core challenge in numerous real-world applications is to match an inquiry to the best document from a mutable and finite set of candidates. Existing industry solutions, especially latency-constrained services, often rely on similarity algorithms that sacrifice quality for speed. In this paper we introduce a generic semantic learning-to-rank framework, Self-training Semantic Cross-attention Ranking (sRank). This transformer-based framework uses linear pairwise loss with mutable training batch sizes and achieves quality gains and high efficiency, and has been applied effectively to show gains on two industry tasks at Microsoft over real-world large-scale data sets: Smart Reply (SR) and Ambient Clinical Intelligence (ACI). In Smart Reply, $sRank$ assists live customers with technical support by selecting the best reply from predefined solutions based on consumer and support agent messages. It achieves 11.7% gain in offline top-one accuracy on the SR task over the previous system, and 
&lt;/p&gt;</description></item></channel></rss>