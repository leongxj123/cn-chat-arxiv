<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#22312;&#20302;&#36164;&#28304;&#35821;&#35328;&#20013;&#65292;&#36890;&#36807;&#23558;LLMs&#38598;&#25104;&#21040;&#20027;&#21160;&#23398;&#20064;&#24490;&#29615;&#20013;&#36827;&#34892;&#25968;&#25454;&#27880;&#37322;&#65292;&#26377;&#25928;&#20943;&#23569;&#25152;&#38656;&#25968;&#25454;&#37327;&#65292;&#24182;&#21462;&#24471;&#25509;&#36817;&#26368;&#20808;&#36827;&#24615;&#33021;&#30340;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2404.02261</link><description>&lt;p&gt;
&#22312;LLMs&#20013;&#24490;&#29615;&#65306;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27880;&#37322;&#36827;&#34892;&#20302;&#36164;&#28304;&#35821;&#35328;&#30340;&#20027;&#21160;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
LLMs in the Loop: Leveraging Large Language Model Annotations for Active Learning in Low-Resource Languages
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02261
&lt;/p&gt;
&lt;p&gt;
&#22312;&#20302;&#36164;&#28304;&#35821;&#35328;&#20013;&#65292;&#36890;&#36807;&#23558;LLMs&#38598;&#25104;&#21040;&#20027;&#21160;&#23398;&#20064;&#24490;&#29615;&#20013;&#36827;&#34892;&#25968;&#25454;&#27880;&#37322;&#65292;&#26377;&#25928;&#20943;&#23569;&#25152;&#38656;&#25968;&#25454;&#37327;&#65292;&#24182;&#21462;&#24471;&#25509;&#36817;&#26368;&#20808;&#36827;&#24615;&#33021;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#35821;&#35328;&#36164;&#28304;&#21644;&#25968;&#25454;&#26631;&#27880;&#19987;&#19994;&#30693;&#35782;&#26377;&#38480;&#65292;&#20302;&#36164;&#28304;&#35821;&#35328;&#22312;&#20154;&#24037;&#26234;&#33021;&#24320;&#21457;&#20013;&#38754;&#20020;&#30528;&#37325;&#22823;&#38556;&#30861;&#65292;&#20351;&#23427;&#20204;&#21464;&#24471;&#32597;&#35265;&#19988;&#25104;&#26412;&#39640;&#26114;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#19981;&#36275;&#65292;&#25105;&#20204;&#25552;&#20986;&#21033;&#29992;LLMs&#30340;&#28508;&#21147;&#22312;&#20027;&#21160;&#23398;&#20064;&#29615;&#33410;&#20013;&#36827;&#34892;&#25968;&#25454;&#27880;&#37322;&#12290;&#25105;&#20204;&#39318;&#20808;&#36827;&#34892;&#35780;&#20272;&#20197;&#35780;&#20272;&#27880;&#37322;&#32773;&#20043;&#38388;&#30340;&#19968;&#33268;&#24615;&#65292;&#20174;&#32780;&#36873;&#25321;&#36866;&#24403;&#30340;LLM&#27880;&#37322;&#32773;&#12290;&#28982;&#21518;&#65292;&#36873;&#25321;&#30340;&#27880;&#37322;&#32773;&#34987;&#38598;&#25104;&#21040;&#19968;&#20010;&#20998;&#31867;&#22120;&#30340;&#35757;&#32451;&#24490;&#29615;&#20013;&#65292;&#20351;&#29992;&#20027;&#21160;&#23398;&#20064;&#33539;&#24335;&#65292;&#26368;&#23567;&#21270;&#25152;&#38656;&#30340;&#26597;&#35810;&#25968;&#25454;&#37327;&#12290;&#23454;&#35777;&#35780;&#20272;&#65292;&#29305;&#21035;&#26159;&#20351;&#29992;GPT-4-Turbo&#65292;&#23637;&#31034;&#20102;&#20960;&#20046;&#36798;&#21040;&#26368;&#20808;&#36827;&#24615;&#33021;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#22823;&#22823;&#20943;&#23569;&#20102;&#25968;&#25454;&#38656;&#27714;&#65292;&#30001;&#20272;&#31639;&#30340;&#28508;&#22312;&#24615;&#33021;&#25351;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02261v1 Announce Type: cross  Abstract: Low-resource languages face significant barriers in AI development due to limited linguistic resources and expertise for data labeling, rendering them rare and costly. The scarcity of data and the absence of preexisting tools exacerbate these challenges, especially since these languages may not be adequately represented in various NLP datasets. To address this gap, we propose leveraging the potential of LLMs in the active learning loop for data annotation. Initially, we conduct evaluations to assess inter-annotator agreement and consistency, facilitating the selection of a suitable LLM annotator. The chosen annotator is then integrated into a training loop for a classifier using an active learning paradigm, minimizing the amount of queried data required. Empirical evaluations, notably employing GPT-4-Turbo, demonstrate near-state-of-the-art performance with significantly reduced data requirements, as indicated by estimated potential co
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20855;&#26377;&#23545;&#40784;&#21015;&#34920;&#25490;&#21517;&#30446;&#26631;&#30340;&#35821;&#35328;&#27169;&#22411;&#26694;&#26550;&#65288;ALRO&#65289;&#65292;&#26088;&#22312;&#24357;&#21512;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#19982;&#25512;&#33616;&#31995;&#32479;&#25490;&#21517;&#20219;&#21153;&#30340;&#35201;&#27714;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;</title><link>https://arxiv.org/abs/2403.19181</link><description>&lt;p&gt;
&#35753;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25104;&#20026;&#26356;&#22909;&#30340;&#25490;&#21517;&#22120;
&lt;/p&gt;
&lt;p&gt;
Make Large Language Model a Better Ranker
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19181
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20855;&#26377;&#23545;&#40784;&#21015;&#34920;&#25490;&#21517;&#30446;&#26631;&#30340;&#35821;&#35328;&#27169;&#22411;&#26694;&#26550;&#65288;ALRO&#65289;&#65292;&#26088;&#22312;&#24357;&#21512;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#19982;&#25512;&#33616;&#31995;&#32479;&#25490;&#21517;&#20219;&#21153;&#30340;&#35201;&#27714;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#21457;&#23637;&#26174;&#33879;&#22686;&#24378;&#20102;&#21508;&#20010;&#39046;&#22495;&#30340;&#33021;&#21147;&#65292;&#23548;&#33268;&#25512;&#33616;&#31995;&#32479;&#65288;RSs&#65289;&#27010;&#24565;&#21644;&#24320;&#21457;&#26041;&#24335;&#21457;&#29983;&#20102;&#36716;&#21464;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#28857;&#23545;&#28857;&#21644;&#25104;&#23545;&#25512;&#33616;&#33539;&#24335;&#19978;&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#22522;&#20110;LLM&#30340;&#25512;&#33616;&#22120;&#20013;&#25928;&#29575;&#20302;&#19979;&#65292;&#22240;&#20026;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#35745;&#31639;&#25104;&#26412;&#24456;&#39640;&#12290;&#19968;&#20123;&#30740;&#31350;&#34429;&#28982;&#28145;&#20837;&#30740;&#31350;&#20102;&#21015;&#34920;&#22411;&#26041;&#27861;&#65292;&#20294;&#22312;&#25490;&#21517;&#20219;&#21153;&#20013;&#34920;&#29616;&#19981;&#20339;&#12290;&#36825;&#19968;&#19981;&#36275;&#24402;&#22240;&#20110;&#25490;&#21517;&#21644;&#35821;&#35328;&#29983;&#25104;&#30446;&#26631;&#20043;&#38388;&#30340;&#19981;&#21305;&#37197;&#12290;&#20026;&#27492;&#65292;&#26412;&#25991;&#20171;&#32461;&#20102;&#20855;&#26377;&#23545;&#40784;&#21015;&#34920;&#25490;&#21517;&#30446;&#26631;&#30340;&#35821;&#35328;&#27169;&#22411;&#26694;&#26550;&#65288;ALRO&#65289;&#12290;ALRO&#26088;&#22312;&#24357;&#21512;LLMs&#30340;&#33021;&#21147;&#19982;&#25512;&#33616;&#31995;&#32479;&#25490;&#21517;&#20219;&#21153;&#30340;&#24494;&#22937;&#35201;&#27714;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;ALRO&#30340;&#19968;&#20010;&#20851;&#38190;&#29305;&#24615;&#26159;&#24341;&#20837;&#20102;&#36719;lambda&#20540;lo
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19181v1 Announce Type: cross  Abstract: The evolution of Large Language Models (LLMs) has significantly enhanced capabilities across various fields, leading to a paradigm shift in how Recommender Systems (RSs) are conceptualized and developed. However, existing research primarily focuses on point-wise and pair-wise recommendation paradigms. These approaches prove inefficient in LLM-based recommenders due to the high computational cost of utilizing Large Language Models. While some studies have delved into list-wise approaches, they fall short in ranking tasks. This shortfall is attributed to the misalignment between the objectives of ranking and language generation. To this end, this paper introduces the Language Model Framework with Aligned Listwise Ranking Objectives (ALRO). ALRO is designed to bridge the gap between the capabilities of LLMs and the nuanced requirements of ranking tasks within recommender systems. A key feature of ALRO is the introduction of soft lambda lo
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20195;&#29702;&#29983;&#25104;AAS&#23454;&#20363;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#22312;&#25968;&#23383;&#23402;&#29983;&#20013;&#30340;&#20114;&#25805;&#20316;&#24615;&#65292;&#38477;&#20302;&#20102;&#25163;&#21160;&#21019;&#24314;&#25104;&#26412;&#21644;&#26102;&#38388;&#12290;</title><link>https://arxiv.org/abs/2403.17209</link><description>&lt;p&gt;
&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20195;&#29702;&#29983;&#25104;&#36164;&#20135;&#31649;&#29702;&#22806;&#22771;&#65306;&#25968;&#23383;&#23402;&#29983;&#21644;&#35821;&#20041;&#33410;&#28857;&#20013;&#30340;&#20114;&#25805;&#20316;&#24615;
&lt;/p&gt;
&lt;p&gt;
Generation of Asset Administration Shell with Large Language Model Agents: Interoperability in Digital Twins with Semantic Node
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17209
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20195;&#29702;&#29983;&#25104;AAS&#23454;&#20363;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#22312;&#25968;&#23383;&#23402;&#29983;&#20013;&#30340;&#20114;&#25805;&#20316;&#24615;&#65292;&#38477;&#20302;&#20102;&#25163;&#21160;&#21019;&#24314;&#25104;&#26412;&#21644;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#21327;&#21161;&#22312;&#24037;&#19994;4.0&#32972;&#26223;&#19979;&#20026;&#25968;&#23383;&#23402;&#29983;&#24314;&#27169;&#21019;&#24314;&#36164;&#20135;&#31649;&#29702;&#22806;&#22771;&#65288;AAS&#65289;&#23454;&#20363;&#65292;&#26088;&#22312;&#22686;&#24378;&#26234;&#33021;&#21046;&#36896;&#20013;&#30340;&#20114;&#25805;&#20316;&#24615;&#65292;&#20943;&#23569;&#25163;&#21160;&#24037;&#20316;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#8220;&#35821;&#20041;&#33410;&#28857;&#8221;&#25968;&#25454;&#32467;&#26500;&#26469;&#25429;&#25417;&#25991;&#26412;&#25968;&#25454;&#30340;&#35821;&#20041;&#35201;&#20041;&#12290;&#28982;&#21518;&#65292;&#35774;&#35745;&#24182;&#23454;&#29616;&#20102;&#19968;&#20010;&#30001;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#39537;&#21160;&#30340;&#31995;&#32479;&#65292;&#29992;&#20110;&#22788;&#29702;&#8220;&#35821;&#20041;&#33410;&#28857;&#8221;&#24182;&#20174;&#25991;&#26412;&#25216;&#26415;&#25968;&#25454;&#29983;&#25104;AAS&#23454;&#20363;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#35780;&#20272;&#34920;&#26126;&#65292;&#26377;&#25928;&#29983;&#25104;&#29575;&#20026;62-79%&#65292;&#34920;&#26126;&#30456;&#24403;&#27604;&#20363;&#30340;&#25163;&#21160;&#21019;&#24314;&#24037;&#20316;&#21487;&#20197;&#36716;&#25442;&#20026;&#26356;&#23481;&#26131;&#30340;&#39564;&#35777;&#24037;&#20316;&#65292;&#20174;&#32780;&#20943;&#23569;&#21019;&#24314;AAS&#23454;&#20363;&#27169;&#22411;&#30340;&#26102;&#38388;&#21644;&#25104;&#26412;&#12290;&#22312;&#25105;&#20204;&#30340;&#35780;&#20272;&#20013;&#65292;&#23545;&#19981;&#21516;LLM&#30340;&#27604;&#36739;&#20998;&#26512;&#20197;&#21450;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#26426;&#21046;&#30340;&#28145;&#20837;&#28040;&#34701;&#30740;&#31350;&#25552;&#20379;&#20102;&#26377;&#20851;LLM&#26377;&#25928;&#24615;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17209v1 Announce Type: new  Abstract: This research introduces a novel approach for assisting the creation of Asset Administration Shell (AAS) instances for digital twin modeling within the context of Industry 4.0, aiming to enhance interoperability in smart manufacturing and reduce manual effort. We construct a "semantic node" data structure to capture the semantic essence of textual data. Then, a system powered by large language models is designed and implemented to process "semantic node" and generate AAS instance models from textual technical data. Our evaluation demonstrates a 62-79% effective generation rate, indicating a substantial proportion of manual creation effort can be converted into easier validation effort, thereby reducing the time and cost in creating AAS instance models. In our evaluation, a comparative analysis of different LLMs and an in-depth ablation study of Retrieval-Augmented Generation (RAG) mechanisms provide insights into the effectiveness of LLM
&lt;/p&gt;</description></item><item><title>Fundus&#26159;&#19968;&#20010;&#31616;&#21333;&#26131;&#29992;&#30340;&#26032;&#38395;&#29228;&#34411;&#24037;&#20855;&#65292;&#36890;&#36807;&#25163;&#24037;&#23450;&#21046;&#30340;&#20869;&#23481;&#25552;&#21462;&#22120;&#65292;&#38024;&#23545;&#27599;&#20010;&#25903;&#25345;&#30340;&#22312;&#32447;&#25253;&#32440;&#26684;&#24335;&#25351;&#21335;&#36827;&#34892;&#20248;&#21270;&#65292;&#23454;&#29616;&#39640;&#36136;&#37327;&#30340;&#26032;&#38395;&#25991;&#31456;&#25552;&#21462;&#65292;&#21516;&#26102;&#32467;&#21512;&#29228;&#21462;&#21644;&#20869;&#23481;&#25552;&#21462;&#20110;&#19968;&#20307;&#65292;&#20026;&#38750;&#25216;&#26415;&#29992;&#25143;&#25552;&#20379;&#32479;&#19968;&#20351;&#29992;&#30028;&#38754;&#12290;</title><link>https://arxiv.org/abs/2403.15279</link><description>&lt;p&gt;
Fundus&#65306;&#19968;&#20010;&#31616;&#21333;&#26131;&#29992;&#30340;&#26032;&#38395;&#29228;&#34411;&#65292;&#20248;&#21270;&#39640;&#36136;&#37327;&#25552;&#21462;
&lt;/p&gt;
&lt;p&gt;
Fundus: A Simple-to-Use News Scraper Optimized for High Quality Extractions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15279
&lt;/p&gt;
&lt;p&gt;
Fundus&#26159;&#19968;&#20010;&#31616;&#21333;&#26131;&#29992;&#30340;&#26032;&#38395;&#29228;&#34411;&#24037;&#20855;&#65292;&#36890;&#36807;&#25163;&#24037;&#23450;&#21046;&#30340;&#20869;&#23481;&#25552;&#21462;&#22120;&#65292;&#38024;&#23545;&#27599;&#20010;&#25903;&#25345;&#30340;&#22312;&#32447;&#25253;&#32440;&#26684;&#24335;&#25351;&#21335;&#36827;&#34892;&#20248;&#21270;&#65292;&#23454;&#29616;&#39640;&#36136;&#37327;&#30340;&#26032;&#38395;&#25991;&#31456;&#25552;&#21462;&#65292;&#21516;&#26102;&#32467;&#21512;&#29228;&#21462;&#21644;&#20869;&#23481;&#25552;&#21462;&#20110;&#19968;&#20307;&#65292;&#20026;&#38750;&#25216;&#26415;&#29992;&#25143;&#25552;&#20379;&#32479;&#19968;&#20351;&#29992;&#30028;&#38754;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;Fundus&#65292;&#19968;&#20010;&#29992;&#25143;&#21451;&#22909;&#30340;&#26032;&#38395;&#29228;&#34411;&#65292;&#20351;&#29992;&#25143;&#21487;&#20197;&#20165;&#20973;&#20960;&#34892;&#20195;&#30721;&#33719;&#24471;&#25968;&#30334;&#19975;&#39640;&#36136;&#37327;&#30340;&#26032;&#38395;&#25991;&#31456;&#12290;&#19982;&#29616;&#26377;&#30340;&#26032;&#38395;&#29228;&#34411;&#19981;&#21516;&#65292;&#25105;&#20204;&#20351;&#29992;&#25163;&#24037;&#23450;&#21046;&#30340;&#12289;&#19987;&#38376;&#38024;&#23545;&#27599;&#20010;&#25903;&#25345;&#30340;&#22312;&#32447;&#25253;&#32440;&#30340;&#26684;&#24335;&#25351;&#21335;&#30340;&#20869;&#23481;&#25552;&#21462;&#22120;&#12290;&#36825;&#26679;&#25105;&#20204;&#21487;&#20197;&#20248;&#21270;&#25105;&#20204;&#30340;&#29228;&#21462;&#36136;&#37327;&#65292;&#20197;&#30830;&#20445;&#26816;&#32034;&#21040;&#30340;&#26032;&#38395;&#25991;&#31456;&#23436;&#25972;&#19988;&#27809;&#26377;HTML&#30165;&#36857;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#23558;&#29228;&#21462;&#65288;&#20174;&#32593;&#32476;&#25110;&#22823;&#22411;&#32593;&#32476;&#24402;&#26723;&#20013;&#26816;&#32034;HTML&#65289;&#21644;&#20869;&#23481;&#25552;&#21462;&#32467;&#21512;&#21040;&#19968;&#20010;&#21333;&#19968;&#30340;&#27969;&#27700;&#32447;&#20013;&#12290;&#36890;&#36807;&#20026;&#39044;&#23450;&#20041;&#30340;&#19968;&#32452;&#25253;&#32440;&#25552;&#20379;&#32479;&#19968;&#30340;&#30028;&#38754;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#20351;Fundus&#21363;&#20351;&#23545;&#38750;&#25216;&#26415;&#29992;&#25143;&#20063;&#26131;&#20110;&#20351;&#29992;&#12290;&#26412;&#25991;&#27010;&#36848;&#20102;&#26694;&#26550;&#65292;&#35752;&#35770;&#20102;&#25105;&#20204;&#30340;&#35774;&#35745;&#36873;&#25321;&#65292;&#24182;&#38024;&#23545;&#20854;&#20182;&#27969;&#34892;&#30340;&#26032;&#38395;&#29228;&#34411;&#36827;&#34892;&#20102;&#27604;&#36739;&#35780;&#20272;&#12290;&#25105;&#20204;&#30340;&#35780;&#20272;&#34920;&#26126;&#65292;Fundus&#21462;&#24471;&#20102;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15279v1 Announce Type: new  Abstract: This paper introduces Fundus, a user-friendly news scraper that enables users to obtain millions of high-quality news articles with just a few lines of code. Unlike existing news scrapers, we use manually crafted, bespoke content extractors that are specifically tailored to the formatting guidelines of each supported online newspaper. This allows us to optimize our scraping for quality such that retrieved news articles are textually complete and without HTML artifacts. Further, our framework combines both crawling (retrieving HTML from the web or large web archives) and content extraction into a single pipeline. By providing a unified interface for a predefined collection of newspapers, we aim to make Fundus broadly usable even for non-technical users. This paper gives an overview of the framework, discusses our design choices, and presents a comparative evaluation against other popular news scrapers. Our evaluation shows that Fundus yie
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#35843;&#26597;&#28145;&#20837;&#20998;&#26512;&#20102;LLMs&#22312;&#34701;&#21512;&#19978;&#19979;&#25991;&#21644;&#21442;&#25968;&#21270;&#30693;&#35782;&#26102;&#25152;&#38754;&#20020;&#30340;&#30693;&#35782;&#20914;&#31361;&#65292;&#25506;&#35752;&#20102;&#19977;&#31867;&#30693;&#35782;&#20914;&#31361;&#23545;&#20854;&#21487;&#20449;&#24230;&#21644;&#24615;&#33021;&#30340;&#37325;&#35201;&#24433;&#21709;&#65292;&#24182;&#25552;&#20986;&#25913;&#36827;LLMs&#31283;&#20581;&#24615;&#31574;&#30053;&#30340;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2403.08319</link><description>&lt;p&gt;
LLMs&#30340;&#30693;&#35782;&#20914;&#31361;&#65306;&#19968;&#39033;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Knowledge Conflicts for LLMs: A Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08319
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#35843;&#26597;&#28145;&#20837;&#20998;&#26512;&#20102;LLMs&#22312;&#34701;&#21512;&#19978;&#19979;&#25991;&#21644;&#21442;&#25968;&#21270;&#30693;&#35782;&#26102;&#25152;&#38754;&#20020;&#30340;&#30693;&#35782;&#20914;&#31361;&#65292;&#25506;&#35752;&#20102;&#19977;&#31867;&#30693;&#35782;&#20914;&#31361;&#23545;&#20854;&#21487;&#20449;&#24230;&#21644;&#24615;&#33021;&#30340;&#37325;&#35201;&#24433;&#21709;&#65292;&#24182;&#25552;&#20986;&#25913;&#36827;LLMs&#31283;&#20581;&#24615;&#31574;&#30053;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#35843;&#26597;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#30693;&#35782;&#20914;&#31361;&#36827;&#34892;&#20102;&#28145;&#20837;&#20998;&#26512;&#65292;&#31361;&#20986;&#20102;&#24403;&#23427;&#20204;&#34701;&#21512;&#19978;&#19979;&#25991;&#21644;&#21442;&#25968;&#21270;&#30693;&#35782;&#26102;&#25152;&#36935;&#21040;&#30340;&#22797;&#26434;&#25361;&#25112;&#12290;&#25105;&#20204;&#20851;&#27880;&#19977;&#31867;&#30693;&#35782;&#20914;&#31361;&#65306;&#19978;&#19979;&#25991;-&#35760;&#24518;&#20914;&#31361;&#12289;&#36328;&#19978;&#19979;&#25991;&#20914;&#31361;&#21644;&#20869;&#37096;&#35760;&#24518;&#20914;&#31361;&#12290;&#36825;&#20123;&#20914;&#31361;&#21487;&#33021;&#20250;&#26174;&#33879;&#24433;&#21709;LLMs&#30340;&#21487;&#20449;&#24230;&#21644;&#24615;&#33021;&#65292;&#29305;&#21035;&#26159;&#22312;&#29616;&#23454;&#19990;&#30028;&#24212;&#29992;&#20013;&#65292;&#22122;&#38899;&#21644;&#38169;&#35823;&#20449;&#24687;&#24456;&#24120;&#35265;&#12290;&#36890;&#36807;&#23545;&#36825;&#20123;&#20914;&#31361;&#36827;&#34892;&#20998;&#31867;&#65292;&#25506;&#35752;&#20854;&#21407;&#22240;&#65292;&#30740;&#31350;LLMs&#22312;&#36825;&#20123;&#20914;&#31361;&#19979;&#30340;&#34892;&#20026;&#65292;&#24182;&#22238;&#39038;&#21487;&#29992;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#26412;&#35843;&#26597;&#26088;&#22312;&#20026;&#25913;&#36827;LLMs&#30340;&#31283;&#20581;&#24615;&#31574;&#30053;&#25552;&#20379;&#21551;&#31034;&#65292;&#20174;&#32780;&#25104;&#20026;&#25512;&#21160;&#36825;&#19968;&#19981;&#26029;&#21457;&#23637;&#39046;&#22495;&#30740;&#31350;&#30340;&#23453;&#36149;&#36164;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08319v1 Announce Type: cross  Abstract: This survey provides an in-depth analysis of knowledge conflicts for large language models (LLMs), highlighting the complex challenges they encounter when blending contextual and parametric knowledge. Our focus is on three categories of knowledge conflicts: context-memory, inter-context, and intra-memory conflict. These conflicts can significantly impact the trustworthiness and performance of LLMs, especially in real-world applications where noise and misinformation are common. By categorizing these conflicts, exploring the causes, examining the behaviors of LLMs under such conflicts, and reviewing available solutions, this survey aims to shed light on strategies for improving the robustness of LLMs, thereby serving as a valuable resource for advancing research in this evolving area.
&lt;/p&gt;</description></item><item><title>EasyInstruct&#26159;&#19968;&#20010;&#26131;&#20110;&#20351;&#29992;&#30340;&#29992;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25351;&#20196;&#22788;&#29702;&#26694;&#26550;&#65292;&#36890;&#36807;&#27169;&#22359;&#21270;&#25351;&#20196;&#29983;&#25104;&#12289;&#36873;&#25321;&#21644;&#25552;&#31034;&#65292;&#24182;&#32771;&#34385;&#23427;&#20204;&#30340;&#32452;&#21512;&#21644;&#20132;&#20114;&#65292;&#20351;&#25351;&#20196;&#22788;&#29702;&#26356;&#21152;&#26041;&#20415;&#21644;&#39640;&#25928;&#12290;</title><link>https://arxiv.org/abs/2402.03049</link><description>&lt;p&gt;
EasyInstruct&#65306;&#19968;&#20010;&#26131;&#20110;&#20351;&#29992;&#30340;&#29992;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25351;&#20196;&#22788;&#29702;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
EasyInstruct: An Easy-to-use Instruction Processing Framework for Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03049
&lt;/p&gt;
&lt;p&gt;
EasyInstruct&#26159;&#19968;&#20010;&#26131;&#20110;&#20351;&#29992;&#30340;&#29992;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25351;&#20196;&#22788;&#29702;&#26694;&#26550;&#65292;&#36890;&#36807;&#27169;&#22359;&#21270;&#25351;&#20196;&#29983;&#25104;&#12289;&#36873;&#25321;&#21644;&#25552;&#31034;&#65292;&#24182;&#32771;&#34385;&#23427;&#20204;&#30340;&#32452;&#21512;&#21644;&#20132;&#20114;&#65292;&#20351;&#25351;&#20196;&#22788;&#29702;&#26356;&#21152;&#26041;&#20415;&#21644;&#39640;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#25351;&#20196;&#35843;&#25972;&#24050;&#32463;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#65292;&#24182;&#25104;&#20026;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#33021;&#21147;&#30340;&#19968;&#31181;&#20851;&#38190;&#25216;&#26415;&#12290;&#20026;&#20102;&#26500;&#24314;&#39640;&#36136;&#37327;&#30340;&#25351;&#20196;&#25968;&#25454;&#38598;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#35768;&#22810;&#25351;&#20196;&#22788;&#29702;&#26041;&#27861;&#65292;&#26088;&#22312;&#22312;&#25968;&#25454;&#25968;&#37327;&#21644;&#25968;&#25454;&#36136;&#37327;&#20043;&#38388;&#36798;&#21040;&#31934;&#24039;&#30340;&#24179;&#34913;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#21508;&#31181;&#25351;&#20196;&#22788;&#29702;&#26041;&#27861;&#20043;&#38388;&#20173;&#28982;&#23384;&#22312;&#19981;&#19968;&#33268;&#65292;&#30446;&#21069;&#27809;&#26377;&#26631;&#20934;&#30340;&#24320;&#28304;&#25351;&#20196;&#22788;&#29702;&#23454;&#29616;&#26694;&#26550;&#21487;&#20379;&#31038;&#21306;&#20351;&#29992;&#65292;&#36825;&#20351;&#24471;&#20174;&#19994;&#32773;&#26080;&#27861;&#36827;&#19968;&#27493;&#24320;&#21457;&#21644;&#25512;&#36827;&#12290;&#20026;&#20102;&#20419;&#36827;&#25351;&#20196;&#22788;&#29702;&#30340;&#30740;&#31350;&#21644;&#24320;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;EasyInstruct&#65292;&#19968;&#20010;&#26131;&#20110;&#20351;&#29992;&#30340;&#29992;&#20110;LLMs&#30340;&#25351;&#20196;&#22788;&#29702;&#26694;&#26550;&#65292;&#23427;&#23558;&#25351;&#20196;&#29983;&#25104;&#12289;&#36873;&#25321;&#21644;&#25552;&#31034;&#27169;&#22359;&#21270;&#65292;&#24182;&#32771;&#34385;&#23427;&#20204;&#30340;&#32452;&#21512;&#21644;&#20132;&#20114;&#12290;EasyInstruct&#24050;&#32463;&#22312;https://github.com/zjunlp/EasyInstruct&#19978;&#20844;&#24320;&#21457;&#24067;&#65292;&#24182;&#24471;&#21040;&#20102;&#31215;&#26497;&#32500;&#25252;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, instruction tuning has gained increasing attention and emerged as a crucial technique to enhance the capabilities of Large Language Models (LLMs). To construct high-quality instruction datasets, many instruction processing approaches have been proposed, aiming to achieve a delicate balance between data quantity and data quality. Nevertheless, due to inconsistencies that persist among various instruction processing methods, there is no standard open-source instruction processing implementation framework available for the community, which hinders practitioners from further developing and advancing. To facilitate instruction processing research and development, we present EasyInstruct, an easy-to-use instruction processing framework for LLMs, which modularizes instruction generation, selection, and prompting, while also considering their combination and interaction. EasyInstruct is publicly released and actively maintained at https://github.com/zjunlp/EasyInstruct, along 
&lt;/p&gt;</description></item><item><title>EasyEdit&#25552;&#20986;&#20102;&#19968;&#31181;&#26131;&#20110;&#20351;&#29992;&#30340;&#30693;&#35782;&#32534;&#36753;&#26694;&#26550;&#65292;&#38024;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#30693;&#35782;&#25130;&#26029;&#25110;&#35884;&#35823;&#38382;&#39064;&#65292;&#25903;&#25345;&#21508;&#31181;&#26368;&#26032;&#30340;&#30693;&#35782;&#32534;&#36753;&#26041;&#27861;&#65292;&#24182;&#21487;&#24212;&#29992;&#20110;&#22810;&#20010;&#30693;&#21517;&#30340;LLMs&#12290;</title><link>https://arxiv.org/abs/2308.07269</link><description>&lt;p&gt;
EasyEdit&#65306;&#19968;&#31181;&#26131;&#20110;&#20351;&#29992;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30693;&#35782;&#32534;&#36753;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
EasyEdit: An Easy-to-use Knowledge Editing Framework for Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2308.07269
&lt;/p&gt;
&lt;p&gt;
EasyEdit&#25552;&#20986;&#20102;&#19968;&#31181;&#26131;&#20110;&#20351;&#29992;&#30340;&#30693;&#35782;&#32534;&#36753;&#26694;&#26550;&#65292;&#38024;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#30693;&#35782;&#25130;&#26029;&#25110;&#35884;&#35823;&#38382;&#39064;&#65292;&#25903;&#25345;&#21508;&#31181;&#26368;&#26032;&#30340;&#30693;&#35782;&#32534;&#36753;&#26041;&#27861;&#65292;&#24182;&#21487;&#24212;&#29992;&#20110;&#22810;&#20010;&#30693;&#21517;&#30340;LLMs&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36890;&#24120;&#36973;&#21463;&#30693;&#35782;&#25130;&#26029;&#25110;&#35884;&#35823;&#38382;&#39064;&#65292;&#36825;&#24847;&#21619;&#30528;&#23427;&#20204;&#23545;&#26410;&#35265;&#20107;&#20214;&#19981;&#30693;&#24773;&#25110;&#29983;&#25104;&#20855;&#26377;&#19981;&#27491;&#30830;&#20107;&#23454;&#30340;&#25991;&#26412;&#65292;&#21407;&#22240;&#26159;&#25968;&#25454;&#36807;&#26102;/&#22024;&#26434;&#12290;&#20026;&#27492;&#65292;&#20986;&#29616;&#20102;&#35768;&#22810;&#38024;&#23545;LLMs&#30340;&#30693;&#35782;&#32534;&#36753;&#26041;&#27861;&#65292;&#26088;&#22312;&#24494;&#22937;&#22320;&#27880;&#20837;/&#32534;&#36753;&#26356;&#26032;&#30340;&#30693;&#35782;&#25110;&#35843;&#25972;&#19981;&#33391;&#34892;&#20026;&#65292;&#21516;&#26102;&#23558;&#23545;&#19981;&#30456;&#20851;&#36755;&#20837;&#30340;&#24433;&#21709;&#26368;&#23567;&#21270;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#21508;&#31181;&#30693;&#35782;&#32534;&#36753;&#26041;&#27861;&#20043;&#38388;&#23384;&#22312;&#26174;&#33879;&#24046;&#24322;&#65292;&#20197;&#21450;&#20219;&#21153;&#35774;&#32622;&#20013;&#30340;&#21464;&#21270;&#65292;&#31038;&#21306;&#20013;&#27809;&#26377;&#21487;&#29992;&#20110;&#30693;&#35782;&#32534;&#36753;&#30340;&#26631;&#20934;&#23454;&#26045;&#26694;&#26550;&#65292;&#36825;&#22952;&#30861;&#20102;&#20174;&#19994;&#32773;&#23558;&#30693;&#35782;&#32534;&#36753;&#24212;&#29992;&#20110;&#24212;&#29992;&#31243;&#24207;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;EasyEdit&#65292;&#19968;&#31181;&#26131;&#20110;&#20351;&#29992;&#30340;LLMs&#30693;&#35782;&#32534;&#36753;&#26694;&#26550;&#12290;&#23427;&#25903;&#25345;&#21508;&#31181;&#23574;&#31471;&#30340;&#30693;&#35782;&#32534;&#36753;&#26041;&#27861;&#65292;&#24182;&#21487;&#20197;&#36731;&#26494;&#24212;&#29992;&#20110;&#35768;&#22810;&#33879;&#21517;&#30340;LLMs&#65292;&#22914;T5&#12289;GPT-J&#12289;LlaMA&#31561;&#12290;&#20174;&#32463;&#39564;&#19978;&#26469;&#30475;&#65292;&#25105;&#20204;&#25253;&#21578;&#20102;kno
&lt;/p&gt;
&lt;p&gt;
arXiv:2308.07269v2 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) usually suffer from knowledge cutoff or fallacy issues, which means they are unaware of unseen events or generate text with incorrect facts owing to outdated/noisy data. To this end, many knowledge editing approaches for LLMs have emerged -- aiming to subtly inject/edit updated knowledge or adjust undesired behavior while minimizing the impact on unrelated inputs. Nevertheless, due to significant differences among various knowledge editing methods and the variations in task setups, there is no standard implementation framework available for the community, which hinders practitioners from applying knowledge editing to applications. To address these issues, we propose EasyEdit, an easy-to-use knowledge editing framework for LLMs. It supports various cutting-edge knowledge editing approaches and can be readily applied to many well-known LLMs such as T5, GPT-J, LlaMA, etc. Empirically, we report the kno
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#32508;&#36848;&#35843;&#30740;&#20102;&#31070;&#32463;&#20027;&#39064;&#27169;&#22411;&#30340;&#26041;&#27861;&#12289;&#24212;&#29992;&#21644;&#25361;&#25112;&#65292;&#23545;&#20110;&#30701;&#25991;&#26412;&#21644;&#36328;&#35821;&#35328;&#25991;&#26723;&#31561;&#21508;&#31181;&#22330;&#26223;&#25552;&#20379;&#20102;&#31995;&#32479;&#24615;&#30340;&#32452;&#32455;&#21644;&#20171;&#32461;&#65292;&#24182;&#35752;&#35770;&#20102;&#24191;&#27867;&#24212;&#29992;&#30340;&#19968;&#31995;&#21015;&#28909;&#38376;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2401.15351</link><description>&lt;p&gt;
&#20851;&#20110;&#31070;&#32463;&#20027;&#39064;&#27169;&#22411;&#30340;&#32508;&#36848;&#65306;&#26041;&#27861;&#12289;&#24212;&#29992;&#21644;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;
A Survey on Neural Topic Models: Methods, Applications, and Challenges. (arXiv:2401.15351v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15351
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#32508;&#36848;&#35843;&#30740;&#20102;&#31070;&#32463;&#20027;&#39064;&#27169;&#22411;&#30340;&#26041;&#27861;&#12289;&#24212;&#29992;&#21644;&#25361;&#25112;&#65292;&#23545;&#20110;&#30701;&#25991;&#26412;&#21644;&#36328;&#35821;&#35328;&#25991;&#26723;&#31561;&#21508;&#31181;&#22330;&#26223;&#25552;&#20379;&#20102;&#31995;&#32479;&#24615;&#30340;&#32452;&#32455;&#21644;&#20171;&#32461;&#65292;&#24182;&#35752;&#35770;&#20102;&#24191;&#27867;&#24212;&#29992;&#30340;&#19968;&#31995;&#21015;&#28909;&#38376;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20027;&#39064;&#27169;&#22411;&#20960;&#21313;&#24180;&#26469;&#19968;&#30452;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#26080;&#30417;&#30563;&#26041;&#24335;&#19979;&#21457;&#29616;&#28508;&#22312;&#20027;&#39064;&#21644;&#25512;&#26029;&#25991;&#26723;&#30340;&#20027;&#39064;&#27604;&#20363;&#12290;&#23427;&#20204;&#22312;&#25991;&#26412;&#20998;&#26512;&#21644;&#19978;&#19979;&#25991;&#25512;&#33616;&#31561;&#21508;&#31181;&#24212;&#29992;&#20013;&#24471;&#21040;&#24191;&#27867;&#24212;&#29992;&#12290;&#36817;&#24180;&#26469;&#65292;&#31070;&#32463;&#32593;&#32476;&#30340;&#23835;&#36215;&#20419;&#25104;&#20102;&#19968;&#20010;&#26032;&#30340;&#30740;&#31350;&#39046;&#22495;&#8212;&#8212;&#31070;&#32463;&#20027;&#39064;&#27169;&#22411;(NTMs)&#30340;&#20986;&#29616;&#12290;&#19982;&#20256;&#32479;&#30340;&#20027;&#39064;&#27169;&#22411;&#19981;&#21516;&#65292;NTMs&#30452;&#25509;&#20248;&#21270;&#21442;&#25968;&#65292;&#32780;&#19981;&#38656;&#35201;&#27169;&#22411;&#29305;&#23450;&#30340;&#25512;&#23548;&#12290;&#36825;&#20351;&#24471;NTMs&#20855;&#26377;&#26356;&#22909;&#30340;&#21487;&#25193;&#23637;&#24615;&#21644;&#28789;&#27963;&#24615;&#65292;&#21560;&#24341;&#20102;&#22823;&#37327;&#30340;&#30740;&#31350;&#20851;&#27880;&#24182;&#20135;&#29983;&#20102;&#20016;&#23500;&#30340;&#26032;&#26041;&#27861;&#21644;&#24212;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23545;&#31070;&#32463;&#20027;&#39064;&#27169;&#22411;&#30340;&#26041;&#27861;&#12289;&#24212;&#29992;&#21644;&#25361;&#25112;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#35843;&#30740;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#26681;&#25454;&#32593;&#32476;&#32467;&#26500;&#31995;&#32479;&#22320;&#32452;&#32455;&#20102;&#24403;&#21069;NTM&#26041;&#27861;&#65292;&#24182;&#20171;&#32461;&#20102;&#38024;&#23545;&#30701;&#25991;&#26412;&#21644;&#36328;&#35821;&#35328;&#25991;&#26723;&#31561;&#21508;&#31181;&#22330;&#26223;&#30340;NTMs&#12290;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#24191;&#27867;&#24212;&#29992;&#30340;&#19968;&#31995;&#21015;&#28909;&#38376;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Topic models have been prevalent for decades to discover latent topics and infer topic proportions of documents in an unsupervised fashion. They have been widely used in various applications like text analysis and context recommendation. Recently, the rise of neural networks has facilitated the emergence of a new research field -- Neural Topic Models (NTMs). Different from conventional topic models, NTMs directly optimize parameters without requiring model-specific derivations. This endows NTMs with better scalability and flexibility, resulting in significant research attention and plentiful new methods and applications. In this paper, we present a comprehensive survey on neural topic models concerning methods, applications, and challenges. Specifically, we systematically organize current NTM methods according to their network structures and introduce the NTMs for various scenarios like short texts and cross-lingual documents. We also discuss a wide range of popular applications built 
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#27169;&#22411;&#65292;&#26088;&#22312;&#21516;&#26102;&#27169;&#25311;&#35821;&#20041;&#21644;&#21327;&#21516;&#30693;&#35782;&#65292;&#20197;&#23454;&#29616;&#20934;&#30830;&#30340;CTR&#20272;&#35745;&#65292;&#24182;&#35299;&#20915;&#25512;&#29702;&#25928;&#29575;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.09234</link><description>&lt;p&gt;
ClickPrompt: CTR&#27169;&#22411;&#26159;&#23558;&#35821;&#35328;&#27169;&#22411;&#36866;&#24212;&#20026;CTR&#39044;&#27979;&#30340;&#24378;&#22823;&#25552;&#31034;&#29983;&#25104;&#22120;
&lt;/p&gt;
&lt;p&gt;
ClickPrompt: CTR Models are Strong Prompt Generators for Adapting Language Models to CTR Prediction. (arXiv:2310.09234v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09234
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#27169;&#22411;&#65292;&#26088;&#22312;&#21516;&#26102;&#27169;&#25311;&#35821;&#20041;&#21644;&#21327;&#21516;&#30693;&#35782;&#65292;&#20197;&#23454;&#29616;&#20934;&#30830;&#30340;CTR&#20272;&#35745;&#65292;&#24182;&#35299;&#20915;&#25512;&#29702;&#25928;&#29575;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28857;&#20987;&#29575;&#65288;CTR&#65289;&#39044;&#27979;&#24050;&#32463;&#25104;&#20026;&#21508;&#31181;&#20114;&#32852;&#32593;&#24212;&#29992;&#31243;&#24207;&#20013;&#36234;&#26469;&#36234;&#19981;&#21487;&#25110;&#32570;&#30340;&#12290;&#20256;&#32479;&#30340;CTR&#27169;&#22411;&#36890;&#36807;&#29420;&#28909;&#32534;&#30721;&#23558;&#22810;&#23383;&#27573;&#20998;&#31867;&#25968;&#25454;&#36716;&#25442;&#20026;ID&#29305;&#24449;&#65292;&#24182;&#25552;&#21462;&#29305;&#24449;&#20043;&#38388;&#30340;&#21327;&#21516;&#20449;&#21495;&#12290;&#36825;&#31181;&#33539;&#24335;&#30340;&#38382;&#39064;&#22312;&#20110;&#35821;&#20041;&#20449;&#24687;&#30340;&#20002;&#22833;&#12290;&#21478;&#19968;&#26041;&#38754;&#30340;&#30740;&#31350;&#36890;&#36807;&#23558;&#36755;&#20837;&#25968;&#25454;&#36716;&#25442;&#20026;&#25991;&#26412;&#21477;&#23376;&#26469;&#25506;&#32034;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLM&#65289;&#22312;CTR&#39044;&#27979;&#20013;&#30340;&#28508;&#21147;&#12290;&#34429;&#28982;&#35821;&#20041;&#20449;&#21495;&#24471;&#21040;&#20102;&#20445;&#30041;&#65292;&#20294;&#23427;&#20204;&#36890;&#24120;&#26080;&#27861;&#25429;&#25417;&#21040;&#21327;&#21516;&#20449;&#24687;&#65288;&#22914;&#29305;&#24449;&#20132;&#20114;&#12289;&#32431;ID&#29305;&#24449;&#65289;&#65292;&#26356;&#19981;&#29992;&#35828;&#30001;&#24222;&#22823;&#30340;&#27169;&#22411;&#22823;&#23567;&#24102;&#26469;&#30340;&#26080;&#27861;&#25509;&#21463;&#30340;&#25512;&#29702;&#24320;&#38144;&#20102;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#20026;&#20934;&#30830;&#30340;CTR&#20272;&#35745;&#24314;&#31435;&#35821;&#20041;&#30693;&#35782;&#21644;&#21327;&#21516;&#30693;&#35782;&#65292;&#24182;&#35299;&#20915;&#25512;&#29702;&#25928;&#29575;&#38382;&#39064;&#12290;&#20026;&#20102;&#20174;&#20004;&#20010;&#39046;&#22495;&#20013;&#21463;&#30410;&#24182;&#24357;&#21512;&#23427;&#20204;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27169;&#22411;-&#12290;
&lt;/p&gt;
&lt;p&gt;
Click-through rate (CTR) prediction has become increasingly indispensable for various Internet applications. Traditional CTR models convert the multi-field categorical data into ID features via one-hot encoding, and extract the collaborative signals among features. Such a paradigm suffers from the problem of semantic information loss. Another line of research explores the potential of pretrained language models (PLMs) for CTR prediction by converting input data into textual sentences through hard prompt templates. Although semantic signals are preserved, they generally fail to capture the collaborative information (e.g., feature interactions, pure ID features), not to mention the unacceptable inference overhead brought by the huge model size. In this paper, we aim to model both the semantic knowledge and collaborative knowledge for accurate CTR estimation, and meanwhile address the inference inefficiency issue. To benefit from both worlds and close their gaps, we propose a novel model-
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#22270;&#24418;&#25688;&#35201;&#26469;&#25628;&#32034;COVID-19&#20020;&#24202;&#30740;&#31350;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#23558;&#25688;&#35201;&#21644;&#22270;&#24418;&#25688;&#35201;&#34920;&#31034;&#20026;&#26412;&#20307;&#26415;&#35821;&#22270;&#24182;&#22312;&#32593;&#32476;&#20013;&#21305;&#37197;&#65292;&#21487;&#20197;&#26356;&#26377;&#25928;&#22320;&#23545;&#29616;&#26377;&#25991;&#29486;&#36827;&#34892;&#25628;&#32034;&#12290;</title><link>http://arxiv.org/abs/2310.04094</link><description>&lt;p&gt;
&#20351;&#29992;&#22270;&#24418;&#25688;&#35201;&#25628;&#32034;COVID-19&#20020;&#24202;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Searching COVID-19 clinical research using graphical abstracts. (arXiv:2310.04094v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04094
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#22270;&#24418;&#25688;&#35201;&#26469;&#25628;&#32034;COVID-19&#20020;&#24202;&#30740;&#31350;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#23558;&#25688;&#35201;&#21644;&#22270;&#24418;&#25688;&#35201;&#34920;&#31034;&#20026;&#26412;&#20307;&#26415;&#35821;&#22270;&#24182;&#22312;&#32593;&#32476;&#20013;&#21305;&#37197;&#65292;&#21487;&#20197;&#26356;&#26377;&#25928;&#22320;&#23545;&#29616;&#26377;&#25991;&#29486;&#36827;&#34892;&#25628;&#32034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#26631;&#65306;&#22270;&#24418;&#25688;&#35201;&#26159;&#23545;&#31185;&#23398;&#25991;&#31456;&#20027;&#35201;&#21457;&#29616;&#36827;&#34892;&#35270;&#35273;&#24635;&#32467;&#30340;&#27010;&#24565;&#22270;&#12290;&#34429;&#28982;&#22270;&#24418;&#25688;&#35201;&#36890;&#24120;&#29992;&#20110;&#31185;&#23398;&#20986;&#29256;&#29289;&#20013;&#39044;&#27979;&#21644;&#24635;&#32467;&#20027;&#35201;&#32467;&#26524;&#65292;&#20294;&#25105;&#20204;&#23558;&#20854;&#20316;&#20026;&#34920;&#36798;&#23545;&#29616;&#26377;&#25991;&#29486;&#36827;&#34892;&#22270;&#24418;&#25628;&#32034;&#30340;&#25163;&#27573;&#12290;&#26448;&#26009;&#21644;&#26041;&#27861;&#65306;&#25105;&#20204;&#32771;&#34385;COVID-19&#24320;&#25918;&#30740;&#31350;&#25968;&#25454;&#38598;&#65288;CORD-19&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#21253;&#21547;&#36229;&#36807;&#19968;&#30334;&#19975;&#20010;&#25688;&#35201;&#30340;&#35821;&#26009;&#24211;&#65307;&#27599;&#20010;&#25688;&#35201;&#34987;&#25551;&#36848;&#20026;&#20849;&#29616;&#26412;&#20307;&#26415;&#35821;&#22270;&#65292;&#36825;&#20123;&#26415;&#35821;&#20174;&#32479;&#19968;&#21307;&#23398;&#35821;&#35328;&#31995;&#32479;&#65288;UMLS&#65289;&#21644;&#20896;&#29366;&#30149;&#27602;&#20256;&#26579;&#30149;&#26412;&#20307;&#65288;CIDO&#65289;&#20013;&#36873;&#25321;&#12290;&#22270;&#24418;&#25688;&#35201;&#20063;&#34987;&#34920;&#31034;&#20026;&#26412;&#20307;&#26415;&#35821;&#22270;&#65292;&#21487;&#33021;&#36824;&#21253;&#25324;&#25551;&#36848;&#20854;&#30456;&#20114;&#20316;&#29992;&#30340;&#23454;&#29992;&#26415;&#35821;&#65288;&#20363;&#22914;&#65292;&#8220;&#30456;&#20851;&#8221;&#65292;&#8220;&#22686;&#21152;&#8221;&#65292;&#8220;&#24341;&#21457;&#8221;&#65289;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#21253;&#21547;&#35821;&#26009;&#24211;&#20013;&#25552;&#21450;&#30340;&#27010;&#24565;&#30340;&#20849;&#29616;&#32593;&#32476;&#65307;&#28982;&#21518;&#25105;&#20204;&#22312;&#32593;&#32476;&#19978;&#35782;&#21035;&#20986;&#22270;&#24418;&#25688;&#35201;&#30340;&#26368;&#20339;&#21305;&#37197;&#39033;&#12290;&#25105;&#20204;&#21033;&#29992;&#22270;&#24418;&#25968;&#25454;&#24211;...
&lt;/p&gt;
&lt;p&gt;
Objective. Graphical abstracts are small graphs of concepts that visually summarize the main findings of scientific articles. While graphical abstracts are customarily used in scientific publications to anticipate and summarize their main results, we propose them as a means for expressing graph searches over existing literature. Materials and methods. We consider the COVID-19 Open Research Dataset (CORD-19), a corpus of more than one million abstracts; each of them is described as a graph of co-occurring ontological terms, selected from the Unified Medical Language System (UMLS) and the Ontology of Coronavirus Infectious Disease (CIDO). Graphical abstracts are also expressed as graphs of ontological terms, possibly augmented by utility terms describing their interactions (e.g., "associated with", "increases", "induces"). We build a co-occurrence network of concepts mentioned in the corpus; we then identify the best matches of graphical abstracts on the network. We exploit graph databas
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ReLLa&#30340;&#26816;&#32034;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26694;&#26550;&#65292;&#29992;&#20110;&#38646;&#26679;&#26412;&#21644;&#23567;&#26679;&#26412;&#25512;&#33616;&#20219;&#21153;&#12290;&#36890;&#36807;&#35821;&#20041;&#29992;&#25143;&#34892;&#20026;&#26816;&#32034;&#65288;SUBR&#65289;&#26469;&#25552;&#21462;&#19978;&#19979;&#25991;&#20013;&#30340;&#26377;&#29992;&#20449;&#24687;&#65292;&#20197;&#25913;&#21892;LLMs&#30340;&#25512;&#33616;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.11131</link><description>&lt;p&gt;
ReLLa: &#22522;&#20110;&#26816;&#32034;&#22686;&#24378;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#29983;&#21629;&#21608;&#26399;&#24207;&#21015;&#34892;&#20026;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation. (arXiv:2308.11131v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11131
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ReLLa&#30340;&#26816;&#32034;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26694;&#26550;&#65292;&#29992;&#20110;&#38646;&#26679;&#26412;&#21644;&#23567;&#26679;&#26412;&#25512;&#33616;&#20219;&#21153;&#12290;&#36890;&#36807;&#35821;&#20041;&#29992;&#25143;&#34892;&#20026;&#26816;&#32034;&#65288;SUBR&#65289;&#26469;&#25552;&#21462;&#19978;&#19979;&#25991;&#20013;&#30340;&#26377;&#29992;&#20449;&#24687;&#65292;&#20197;&#25913;&#21892;LLMs&#30340;&#25512;&#33616;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#39046;&#22495;&#21462;&#24471;&#20102;&#26174;&#33879;&#31361;&#30772;&#65292;&#22522;&#20110;LLM&#30340;&#25512;&#33616;&#31995;&#32479;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#24182;&#34987;&#31215;&#26497;&#25506;&#32034;&#12290;&#26412;&#25991;&#19987;&#27880;&#20110;&#36866;&#24212;&#21644;&#22686;&#24378;&#32431;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20197;&#29992;&#20110;&#38646;&#26679;&#26412;&#21644;&#23567;&#26679;&#26412;&#25512;&#33616;&#20219;&#21153;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#38024;&#23545;&#25512;&#33616;&#39046;&#22495;&#20013;LLMs&#26080;&#27861;&#20174;&#38271;&#29992;&#25143;&#34892;&#20026;&#24207;&#21015;&#30340;&#25991;&#26412;&#19978;&#19979;&#25991;&#20013;&#25552;&#21462;&#26377;&#29992;&#20449;&#24687;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#24182;&#23450;&#20041;&#20102;&#29983;&#21629;&#21608;&#26399;&#24207;&#21015;&#34892;&#20026;&#29702;&#35299;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#24182;&#25552;&#39640;LLMs&#30340;&#25512;&#33616;&#24615;&#33021;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#21363;&#26816;&#32034;&#22686;&#24378;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;ReLLa&#65289;&#12290;&#38024;&#23545;&#38646;&#26679;&#26412;&#25512;&#33616;&#65292;&#25105;&#20204;&#25191;&#34892;&#35821;&#20041;&#29992;&#25143;&#34892;&#20026;&#26816;&#32034;&#65288;SUBR&#65289;&#26469;&#25552;&#39640;&#25968;&#25454;&#30340;&#21033;&#29992;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
With large language models (LLMs) achieving remarkable breakthroughs in natural language processing (NLP) domains, LLM-enhanced recommender systems have received much attention and have been actively explored currently. In this paper, we focus on adapting and empowering a pure large language model for zero-shot and few-shot recommendation tasks. First and foremost, we identify and formulate the lifelong sequential behavior incomprehension problem for LLMs in recommendation domains, i.e., LLMs fail to extract useful information from a textual context of long user behavior sequence, even if the length of context is far from reaching the context limitation of LLMs. To address such an issue and improve the recommendation performance of LLMs, we propose a novel framework, namely Retrieval-enhanced Large Language models (ReLLa) for recommendation tasks in both zero-shot and few-shot settings. For zero-shot recommendation, we perform semantic user behavior retrieval (SUBR) to improve the data
&lt;/p&gt;</description></item></channel></rss>