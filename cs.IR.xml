<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>LiRank&#26159;&#39046;&#33521;&#30340;&#19968;&#20010;&#22823;&#35268;&#27169;&#25490;&#21517;&#26694;&#26550;&#65292;&#23427;&#24212;&#29992;&#20102;&#26368;&#20808;&#36827;&#30340;&#24314;&#27169;&#26550;&#26500;&#21644;&#20248;&#21270;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#24314;&#27169;&#25913;&#36827;&#21644;&#25216;&#26415;&#65292;&#36890;&#36807;A/B&#27979;&#35797;&#21462;&#24471;&#20102;&#26377;&#25928;&#30340;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.06859</link><description>&lt;p&gt;
LiRank: &#39046;&#33521;&#30340;&#24037;&#19994;&#35268;&#27169;&#25490;&#21517;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
LiRank: Industrial Large Scale Ranking Models at LinkedIn
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06859
&lt;/p&gt;
&lt;p&gt;
LiRank&#26159;&#39046;&#33521;&#30340;&#19968;&#20010;&#22823;&#35268;&#27169;&#25490;&#21517;&#26694;&#26550;&#65292;&#23427;&#24212;&#29992;&#20102;&#26368;&#20808;&#36827;&#30340;&#24314;&#27169;&#26550;&#26500;&#21644;&#20248;&#21270;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#24314;&#27169;&#25913;&#36827;&#21644;&#25216;&#26415;&#65292;&#36890;&#36807;A/B&#27979;&#35797;&#21462;&#24471;&#20102;&#26377;&#25928;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;LiRank&#65292;&#36825;&#26159;&#39046;&#33521;&#30340;&#19968;&#20010;&#22823;&#35268;&#27169;&#25490;&#21517;&#26694;&#26550;&#65292;&#23427;&#23558;&#26368;&#20808;&#36827;&#30340;&#24314;&#27169;&#26550;&#26500;&#21644;&#20248;&#21270;&#26041;&#27861;&#24212;&#29992;&#20110;&#29983;&#20135;&#12290;&#25105;&#20204;&#25581;&#31034;&#20102;&#20960;&#20010;&#24314;&#27169;&#25913;&#36827;&#65292;&#21253;&#25324;Residual DCN&#65292;&#23427;&#22312;&#33879;&#21517;&#30340;DCNv2&#26550;&#26500;&#20013;&#28155;&#21152;&#20102;&#27880;&#24847;&#21147;&#21644;&#27531;&#24046;&#36830;&#25509;&#12290;&#25105;&#20204;&#20998;&#20139;&#20102;&#23558;SOTA&#26550;&#26500;&#32452;&#21512;&#21644;&#35843;&#20248;&#20197;&#21019;&#24314;&#32479;&#19968;&#27169;&#22411;&#30340;&#35265;&#35299;&#65292;&#21253;&#25324;Dense Gating&#12289;Transformers&#21644;Residual DCN&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#29992;&#20110;&#26657;&#20934;&#30340;&#26032;&#25216;&#26415;&#65292;&#24182;&#25551;&#36848;&#20102;&#22914;&#20309;&#23558;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#25506;&#32034;/&#21033;&#29992;&#26041;&#27861;&#24212;&#29992;&#20110;&#29983;&#20135;&#29615;&#22659;&#12290;&#20026;&#20102;&#23454;&#29616;&#22823;&#35268;&#27169;&#25490;&#21517;&#27169;&#22411;&#30340;&#26377;&#25928;&#12289;&#29983;&#20135;&#32423;&#26381;&#21153;&#65292;&#25105;&#20204;&#35814;&#32454;&#20171;&#32461;&#20102;&#20351;&#29992;&#37327;&#21270;&#21644;&#35789;&#27719;&#21387;&#32553;&#35757;&#32451;&#21644;&#21387;&#32553;&#27169;&#22411;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;Feed&#25490;&#21517;&#12289;&#32844;&#20301;&#25512;&#33616;&#21644;&#24191;&#21578;&#28857;&#20987;&#29575;&#65288;CTR&#65289;&#39044;&#27979;&#31561;&#22823;&#35268;&#27169;&#20351;&#29992;&#26696;&#20363;&#30340;&#37096;&#32626;&#35774;&#32622;&#32454;&#33410;&#12290;&#36890;&#36807;&#38416;&#26126;&#26368;&#26377;&#25928;&#30340;&#25216;&#26415;&#26041;&#27861;&#65292;&#25105;&#20204;&#24635;&#32467;&#20102;&#21508;&#31181;A/B&#27979;&#35797;&#30340;&#32463;&#39564;&#25945;&#35757;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present LiRank, a large-scale ranking framework at LinkedIn that brings to production state-of-the-art modeling architectures and optimization methods. We unveil several modeling improvements, including Residual DCN, which adds attention and residual connections to the famous DCNv2 architecture. We share insights into combining and tuning SOTA architectures to create a unified model, including Dense Gating, Transformers and Residual DCN. We also propose novel techniques for calibration and describe how we productionalized deep learning based explore/exploit methods. To enable effective, production-grade serving of large ranking models, we detail how to train and compress models using quantization and vocabulary compression. We provide details about the deployment setup for large-scale use cases of Feed ranking, Jobs Recommendations, and Ads click-through rate (CTR) prediction. We summarize our learnings from various A/B tests by elucidating the most effective technical approaches. T
&lt;/p&gt;</description></item></channel></rss>