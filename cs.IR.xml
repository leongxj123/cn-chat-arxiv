<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#29983;&#25104;&#27169;&#22411;&#22312;&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#20013;&#23637;&#29616;&#20986;&#20102;&#24378;&#22823;&#30340;&#28508;&#21147;&#65292;&#33021;&#22815;&#21516;&#26102;&#22788;&#29702;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#21382;&#21490;&#12289;&#25991;&#26412;&#12289;&#22270;&#20687;&#21644;&#35270;&#39057;&#31561;&#22797;&#26434;&#25968;&#25454;&#65292;&#20026;&#25512;&#33616;&#31995;&#32479;&#24102;&#26469;&#20102;&#26032;&#30340;&#21487;&#33021;&#24615;&#12290;</title><link>https://arxiv.org/abs/2404.00579</link><description>&lt;p&gt;
&#20351;&#29992;&#29983;&#25104;&#27169;&#22411;&#30340;&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#65288;Gen-RecSys&#65289;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Review of Modern Recommender Systems Using Generative Models (Gen-RecSys)
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00579
&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#27169;&#22411;&#22312;&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#20013;&#23637;&#29616;&#20986;&#20102;&#24378;&#22823;&#30340;&#28508;&#21147;&#65292;&#33021;&#22815;&#21516;&#26102;&#22788;&#29702;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#21382;&#21490;&#12289;&#25991;&#26412;&#12289;&#22270;&#20687;&#21644;&#35270;&#39057;&#31561;&#22797;&#26434;&#25968;&#25454;&#65292;&#20026;&#25512;&#33616;&#31995;&#32479;&#24102;&#26469;&#20102;&#26032;&#30340;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#25512;&#33616;&#31995;&#32479;&#65288;RS&#65289;&#36890;&#24120;&#20351;&#29992;&#29992;&#25143;-&#39033;&#30446;&#35780;&#20998;&#21382;&#21490;&#20316;&#20026;&#20027;&#35201;&#25968;&#25454;&#26469;&#28304;&#65292;&#21327;&#21516;&#36807;&#28388;&#26159;&#20027;&#35201;&#26041;&#27861;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#29983;&#25104;&#27169;&#22411;&#26368;&#36817;&#24050;&#32463;&#20855;&#22791;&#20102;&#24314;&#27169;&#21644;&#37319;&#26679;&#22797;&#26434;&#25968;&#25454;&#20998;&#24067;&#30340;&#33021;&#21147;&#65292;&#19981;&#20165;&#21487;&#20197;&#28085;&#30422;&#29992;&#25143;-&#39033;&#30446;&#20132;&#20114;&#21382;&#21490;&#65292;&#36824;&#21487;&#20197;&#21253;&#25324;&#25991;&#26412;&#12289;&#22270;&#20687;&#21644;&#35270;&#39057;&#65292;&#20026;&#26032;&#39062;&#30340;&#25512;&#33616;&#20219;&#21153;&#35299;&#38145;&#20102;&#20016;&#23500;&#30340;&#25968;&#25454;&#12290;&#36890;&#36807;&#36825;&#31687;&#20840;&#38754;&#30340;&#12289;&#22810;&#23398;&#31185;&#30340;&#35843;&#30740;&#65292;&#25105;&#20204;&#26088;&#22312;&#25506;&#35752;&#20351;&#29992;&#29983;&#25104;&#27169;&#22411;&#65288;Gen-RecSys&#65289;&#22312;RS&#20013;&#30340;&#20851;&#38190;&#36827;&#23637;&#65292;&#21253;&#25324;&#65306;&#22522;&#20110;&#20132;&#20114;&#39537;&#21160;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#22522;&#30784;&#27010;&#36848;&#65307;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#29983;&#25104;&#25512;&#33616;&#12289;&#26816;&#32034;&#21644;&#23545;&#35805;&#25512;&#33616;&#20013;&#30340;&#24212;&#29992;&#65307;&#20197;&#21450;&#29992;&#20110;&#22788;&#29702;&#21644;&#29983;&#25104;RS&#20013;&#30340;&#22270;&#20687;&#21644;&#35270;&#39057;&#20869;&#23481;&#30340;&#22810;&#27169;&#24577;&#27169;&#22411;&#30340;&#25972;&#21512;&#12290;&#25105;&#20204;&#30340;&#25972;&#20307;&#35270;&#35282;&#20351;&#25105;&#20204;&#33021;&#22815;&#24378;&#35843;&#35780;&#20272;&#25152;&#38656;&#33539;&#24335;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00579v1 Announce Type: cross  Abstract: Traditional recommender systems (RS) have used user-item rating histories as their primary data source, with collaborative filtering being one of the principal methods. However, generative models have recently developed abilities to model and sample from complex data distributions, including not only user-item interaction histories but also text, images, and videos - unlocking this rich data for novel recommendation tasks. Through this comprehensive and multi-disciplinary survey, we aim to connect the key advancements in RS using Generative Models (Gen-RecSys), encompassing: a foundational overview of interaction-driven generative models; the application of large language models (LLM) for generative recommendation, retrieval, and conversational recommendation; and the integration of multimodal models for processing and generating image and video content in RS. Our holistic perspective allows us to highlight necessary paradigms for eval
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#35780;&#20272;&#20102;&#22235;&#31181;&#20808;&#36827;&#30340;&#25991;&#26412;&#26816;&#27979;&#22120;&#23545;LLM&#36741;&#21161;&#20889;&#20316;&#30340;&#34920;&#29616;&#65292;&#21457;&#29616;&#23427;&#20204;&#30340;&#24615;&#33021;&#19981;&#22914;&#19968;&#20010;&#31616;&#21333;&#30340;&#26816;&#27979;&#22120;&#12290;&#30740;&#31350;&#35748;&#20026;&#38656;&#35201;&#24320;&#21457;&#19987;&#38376;&#29992;&#20110;LLM&#36741;&#21161;&#20889;&#20316;&#30340;&#29305;&#23450;&#26816;&#27979;&#22120;&#65292;&#20197;&#35299;&#20915;&#24403;&#21069;&#25215;&#35748;&#23454;&#36341;&#20013;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2401.16807</link><description>&lt;p&gt;
&#22312;&#31185;&#23398;&#20132;&#27969;&#20013;&#26816;&#27979;LLM&#36741;&#21161;&#20889;&#20316;&#65306;&#25105;&#20204;&#24050;&#32463;&#21040;&#36798;&#20102;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Detecting LLM-Assisted Writing in Scientific Communication: Are We There Yet?. (arXiv:2401.16807v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16807
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#35780;&#20272;&#20102;&#22235;&#31181;&#20808;&#36827;&#30340;&#25991;&#26412;&#26816;&#27979;&#22120;&#23545;LLM&#36741;&#21161;&#20889;&#20316;&#30340;&#34920;&#29616;&#65292;&#21457;&#29616;&#23427;&#20204;&#30340;&#24615;&#33021;&#19981;&#22914;&#19968;&#20010;&#31616;&#21333;&#30340;&#26816;&#27979;&#22120;&#12290;&#30740;&#31350;&#35748;&#20026;&#38656;&#35201;&#24320;&#21457;&#19987;&#38376;&#29992;&#20110;LLM&#36741;&#21161;&#20889;&#20316;&#30340;&#29305;&#23450;&#26816;&#27979;&#22120;&#65292;&#20197;&#35299;&#20915;&#24403;&#21069;&#25215;&#35748;&#23454;&#36341;&#20013;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#22914;ChatGPT&#65292;&#22312;&#25991;&#26412;&#29983;&#25104;&#26041;&#38754;&#20135;&#29983;&#20102;&#37325;&#22823;&#24433;&#21709;&#65292;&#23588;&#20854;&#26159;&#22312;&#20889;&#20316;&#36741;&#21161;&#39046;&#22495;&#12290;&#23613;&#31649;&#20262;&#29702;&#32771;&#34385;&#24378;&#35843;&#20102;&#22312;&#31185;&#23398;&#20132;&#27969;&#20013;&#36879;&#26126;&#22320;&#25215;&#35748;LLM&#30340;&#20351;&#29992;&#30340;&#37325;&#35201;&#24615;&#65292;&#20294;&#30495;&#23454;&#30340;&#25215;&#35748;&#20173;&#28982;&#24456;&#23569;&#35265;&#12290;&#40723;&#21169;&#20934;&#30830;&#25215;&#35748;LLM&#36741;&#21161;&#20889;&#20316;&#30340;&#19968;&#20010;&#28508;&#22312;&#36884;&#24452;&#28041;&#21450;&#20351;&#29992;&#33258;&#21160;&#26816;&#27979;&#22120;&#12290;&#25105;&#20204;&#23545;&#22235;&#20010;&#21069;&#27839;&#30340;LLM&#29983;&#25104;&#25991;&#26412;&#26816;&#27979;&#22120;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#21457;&#29616;&#23427;&#20204;&#30340;&#24615;&#33021;&#19981;&#22914;&#19968;&#20010;&#31616;&#21333;&#30340;&#20020;&#26102;&#26816;&#27979;&#22120;&#65292;&#35813;&#26816;&#27979;&#22120;&#35774;&#35745;&#29992;&#20110;&#35782;&#21035;&#22312;LLM&#22823;&#37327;&#20986;&#29616;&#26102;&#30340;&#31361;&#28982;&#20889;&#20316;&#39118;&#26684;&#21464;&#21270;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#24320;&#21457;&#19987;&#38376;&#29992;&#20110;LLM&#36741;&#21161;&#20889;&#20316;&#26816;&#27979;&#30340;&#19987;&#29992;&#26816;&#27979;&#22120;&#26159;&#24517;&#35201;&#30340;&#12290;&#36825;&#26679;&#30340;&#26816;&#27979;&#22120;&#21487;&#20197;&#22312;&#20419;&#36827;&#23545;LLM&#21442;&#19982;&#31185;&#23398;&#20132;&#27969;&#30340;&#26356;&#30495;&#23454;&#35748;&#21487;&#12289;&#35299;&#20915;&#24403;&#21069;&#25215;&#35748;&#23454;&#36341;&#20013;&#30340;&#25361;&#25112;&#26041;&#38754;&#21457;&#25381;&#20851;&#38190;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs), exemplified by ChatGPT, have significantly reshaped text generation, particularly in the realm of writing assistance. While ethical considerations underscore the importance of transparently acknowledging LLM use, especially in scientific communication, genuine acknowledgment remains infrequent. A potential avenue to encourage accurate acknowledging of LLM-assisted writing involves employing automated detectors. Our evaluation of four cutting-edge LLM-generated text detectors reveals their suboptimal performance compared to a simple ad-hoc detector designed to identify abrupt writing style changes around the time of LLM proliferation. We contend that the development of specialized detectors exclusively dedicated to LLM-assisted writing detection is necessary. Such detectors could play a crucial role in fostering more authentic recognition of LLM involvement in scientific communication, addressing the current challenges in acknowledgment practices.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24341;&#20837;EAUC&#20316;&#20026;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#29992;&#20197;&#25581;&#31034;&#36842;&#20122;&#24503;&#22238;&#24402;&#27169;&#22411;&#20013;&#38544;&#34255;&#30340;&#20559;&#35265;&#21644;&#19981;&#20844;&#24179;&#38382;&#39064;&#12290;&#20256;&#32479;&#30340;&#20840;&#23616;&#38169;&#35823;&#24230;&#37327;&#26631;&#20934;&#22914;RMSE&#21644;MAE&#26080;&#27861;&#25429;&#25417;&#21040;&#36825;&#31181;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.10690</link><description>&lt;p&gt;
&#36229;&#36234;RMSE&#21644;MAE&#65306;&#24341;&#20837;EAUC&#26469;&#25581;&#31034;&#20559;&#35265;&#21644;&#19981;&#20844;&#24179;&#30340;&#36842;&#20122;&#24503;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#38544;&#34255;&#22240;&#32032;
&lt;/p&gt;
&lt;p&gt;
Beyond RMSE and MAE: Introducing EAUC to unmask hidden bias and unfairness in dyadic regression models. (arXiv:2401.10690v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10690
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24341;&#20837;EAUC&#20316;&#20026;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#29992;&#20197;&#25581;&#31034;&#36842;&#20122;&#24503;&#22238;&#24402;&#27169;&#22411;&#20013;&#38544;&#34255;&#30340;&#20559;&#35265;&#21644;&#19981;&#20844;&#24179;&#38382;&#39064;&#12290;&#20256;&#32479;&#30340;&#20840;&#23616;&#38169;&#35823;&#24230;&#37327;&#26631;&#20934;&#22914;RMSE&#21644;MAE&#26080;&#27861;&#25429;&#25417;&#21040;&#36825;&#31181;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36842;&#20122;&#24503;&#22238;&#24402;&#27169;&#22411;&#29992;&#20110;&#39044;&#27979;&#19968;&#23545;&#23454;&#20307;&#30340;&#23454;&#20540;&#32467;&#26524;&#65292;&#22312;&#35768;&#22810;&#39046;&#22495;&#20013;&#37117;&#26159;&#22522;&#30784;&#30340;&#65288;&#20363;&#22914;&#65292;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#39044;&#27979;&#29992;&#25143;&#23545;&#20135;&#21697;&#30340;&#35780;&#20998;&#65289;&#65292;&#22312;&#35768;&#22810;&#20854;&#20182;&#39046;&#22495;&#20013;&#20063;&#26377;&#35768;&#22810;&#28508;&#21147;&#20294;&#23578;&#26410;&#28145;&#20837;&#25506;&#32034;&#65288;&#20363;&#22914;&#65292;&#22312;&#20010;&#24615;&#21270;&#33647;&#29702;&#23398;&#20013;&#36817;&#20284;&#30830;&#23450;&#24739;&#32773;&#30340;&#36866;&#24403;&#21058;&#37327;&#65289;&#12290;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20010;&#20307;&#23454;&#20307;&#35266;&#23519;&#20540;&#20998;&#24067;&#30340;&#38750;&#22343;&#21248;&#24615;&#23548;&#33268;&#20102;&#26368;&#20808;&#36827;&#27169;&#22411;&#20013;&#30340;&#20005;&#37325;&#20559;&#35265;&#39044;&#27979;&#65292;&#20559;&#21521;&#20110;&#23454;&#20307;&#30340;&#35266;&#23519;&#36807;&#21435;&#20540;&#30340;&#24179;&#22343;&#20540;&#65292;&#24182;&#22312;&#21478;&#31867;&#20294;&#21516;&#26679;&#37325;&#35201;&#30340;&#24773;&#20917;&#19979;&#25552;&#20379;&#27604;&#38543;&#26426;&#39044;&#27979;&#26356;&#24046;&#30340;&#39044;&#27979;&#33021;&#21147;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#20840;&#23616;&#38169;&#35823;&#24230;&#37327;&#26631;&#20934;&#22914;&#22343;&#26041;&#26681;&#35823;&#24046;&#65288;RMSE&#65289;&#21644;&#24179;&#22343;&#32477;&#23545;&#35823;&#24046;&#65288;MAE&#65289;&#19981;&#36275;&#20197;&#25429;&#25417;&#21040;&#36825;&#31181;&#29616;&#35937;&#65292;&#25105;&#20204;&#23558;&#20854;&#21629;&#21517;&#20026;&#21478;&#31867;&#20559;&#35265;&#65292;&#24182;&#24341;&#20837;&#21478;&#31867;-&#26354;&#32447;&#19979;&#38754;&#31215;&#65288;EAUC&#65289;&#20316;&#20026;&#19968;&#20010;&#26032;&#30340;&#34917;&#20805;&#24230;&#37327;&#65292;&#21487;&#20197;&#22312;&#25152;&#26377;&#30740;&#31350;&#30340;&#27169;&#22411;&#20013;&#37327;&#21270;&#23427;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dyadic regression models, which predict real-valued outcomes for pairs of entities, are fundamental in many domains (e.g. predicting the rating of a user to a product in Recommender Systems) and promising and under exploration in many others (e.g. approximating the adequate dosage of a drug for a patient in personalized pharmacology). In this work, we demonstrate that non-uniformity in the observed value distributions of individual entities leads to severely biased predictions in state-of-the-art models, skewing predictions towards the average of observed past values for the entity and providing worse-than-random predictive power in eccentric yet equally important cases. We show that the usage of global error metrics like Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE) is insufficient to capture this phenomenon, which we name eccentricity bias, and we introduce Eccentricity-Area Under the Curve (EAUC) as a new complementary metric that can quantify it in all studied models
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25581;&#31034;&#20102;&#22522;&#20110;ChatGPT&#30340;&#25512;&#33616;&#31995;&#32479;&#30340;&#20559;&#35265;&#38382;&#39064;&#65292;&#24182;&#30740;&#31350;&#20102;&#25552;&#31034;&#35774;&#35745;&#31574;&#30053;&#23545;&#25512;&#33616;&#36136;&#37327;&#30340;&#24433;&#21709;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#22312;RecLLMs&#20013;&#24341;&#20837;&#29305;&#23450;&#30340;&#31995;&#32479;&#35282;&#33394;&#21644;&#25552;&#31034;&#31574;&#30053;&#21487;&#20197;&#22686;&#24378;&#25512;&#33616;&#30340;&#20844;&#24179;&#24615;&#21644;&#22810;&#26679;&#24615;&#65292;&#21516;&#26102;GPT-based&#27169;&#22411;&#20542;&#21521;&#20110;&#25512;&#33616;&#26368;&#26032;&#21644;&#26356;&#22810;&#26679;&#21270;&#30340;&#30005;&#24433;&#27969;&#27966;&#12290;</title><link>http://arxiv.org/abs/2401.10545</link><description>&lt;p&gt;
&#29702;&#35299;ChatGPT&#22522;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#20559;&#35265;&#65306;&#20379;&#24212;&#21830;&#20844;&#24179;&#24615;&#12289;&#26102;&#38388;&#31283;&#23450;&#24615;&#21644;&#26368;&#26032;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Understanding Biases in ChatGPT-based Recommender Systems: Provider Fairness, Temporal Stability, and Recency. (arXiv:2401.10545v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10545
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25581;&#31034;&#20102;&#22522;&#20110;ChatGPT&#30340;&#25512;&#33616;&#31995;&#32479;&#30340;&#20559;&#35265;&#38382;&#39064;&#65292;&#24182;&#30740;&#31350;&#20102;&#25552;&#31034;&#35774;&#35745;&#31574;&#30053;&#23545;&#25512;&#33616;&#36136;&#37327;&#30340;&#24433;&#21709;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#22312;RecLLMs&#20013;&#24341;&#20837;&#29305;&#23450;&#30340;&#31995;&#32479;&#35282;&#33394;&#21644;&#25552;&#31034;&#31574;&#30053;&#21487;&#20197;&#22686;&#24378;&#25512;&#33616;&#30340;&#20844;&#24179;&#24615;&#21644;&#22810;&#26679;&#24615;&#65292;&#21516;&#26102;GPT-based&#27169;&#22411;&#20542;&#21521;&#20110;&#25512;&#33616;&#26368;&#26032;&#21644;&#26356;&#22810;&#26679;&#21270;&#30340;&#30005;&#24433;&#27969;&#27966;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;RecLLMs&#65289;&#30340;&#25512;&#33616;&#31995;&#32479;&#30340;&#32454;&#24494;&#33021;&#21147;&#21644;&#22266;&#26377;&#20559;&#35265;&#65292;&#37325;&#28857;&#30740;&#31350;&#20102;&#22522;&#20110;ChatGPT&#30340;&#31995;&#32479;&#12290;&#30740;&#31350;&#20102;&#29983;&#25104;&#27169;&#22411;&#21644;&#20256;&#32479;&#21327;&#21516;&#36807;&#28388;&#27169;&#22411;&#22312;&#30005;&#24433;&#25512;&#33616;&#20013;&#30340;&#24046;&#24322;&#34892;&#20026;&#12290;&#26412;&#30740;&#31350;&#20027;&#35201;&#35843;&#26597;&#20102;&#25552;&#31034;&#35774;&#35745;&#31574;&#30053;&#21450;&#20854;&#23545;&#25512;&#33616;&#36136;&#37327;&#30340;&#21508;&#20010;&#26041;&#38754;&#65288;&#21253;&#25324;&#20934;&#30830;&#24615;&#12289;&#20379;&#24212;&#21830;&#20844;&#24179;&#24615;&#12289;&#22810;&#26679;&#24615;&#12289;&#31283;&#23450;&#24615;&#12289;&#27969;&#34892;&#31867;&#22411;&#21644;&#26102;&#25928;&#24615;&#65289;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#20998;&#26512;&#34920;&#26126;&#65292;&#22312;RecLLMs&#20013;&#24341;&#20837;&#29305;&#23450;&#30340;&#8220;&#31995;&#32479;&#35282;&#33394;&#8221;&#21644;&#8220;&#25552;&#31034;&#31574;&#30053;&#8221;&#26174;&#33879;&#24433;&#21709;&#20854;&#24615;&#33021;&#12290;&#20363;&#22914;&#65292;&#22522;&#20110;&#35282;&#33394;&#30340;&#25552;&#31034;&#21487;&#20197;&#22686;&#24378;&#25512;&#33616;&#30340;&#20844;&#24179;&#24615;&#21644;&#22810;&#26679;&#24615;&#65292;&#20943;&#36731;&#27969;&#34892;&#20559;&#35265;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#34429;&#28982;&#22522;&#20110;GPT&#30340;&#27169;&#22411;&#24182;&#19981;&#24635;&#26159;&#33021;&#19982;&#20256;&#32479;&#21327;&#21516;&#36807;&#28388;&#22522;&#32447;&#27169;&#22411;&#30340;&#24615;&#33021;&#21305;&#37197;&#65292;&#20294;&#23427;&#20204;&#20542;&#21521;&#20110;&#25512;&#33616;&#26356;&#26032;&#12289;&#26356;&#22810;&#26679;&#21270;&#30340;&#30005;&#24433;&#27969;&#27966;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;GPT-base
&lt;/p&gt;
&lt;p&gt;
This study explores the nuanced capabilities and inherent biases of Recommender Systems using Large Language Models (RecLLMs), with a focus on ChatGPT-based systems. It studies into the contrasting behaviors of generative models and traditional collaborative filtering models in movie recommendations. The research primarily investigates prompt design strategies and their impact on various aspects of recommendation quality, including accuracy, provider fairness, diversity, stability, genre dominance, and temporal freshness (recency).  Our experimental analysis reveals that the introduction of specific 'system roles' and 'prompt strategies' in RecLLMs significantly influences their performance. For instance, role-based prompts enhance fairness and diversity in recommendations, mitigating popularity bias. We find that while GPT-based models do not always match the performance of CF baselines, they exhibit a unique tendency to recommend newer and more diverse movie genres. Notably, GPT-base
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#26102;&#38388;&#20852;&#36259;&#32593;&#32476;&#65288;TIN&#65289;&#65292;&#29992;&#20110;&#25429;&#25417;&#34892;&#20026;&#19982;&#30446;&#26631;&#20043;&#38388;&#30340;&#22235;&#37325;&#35821;&#20041;&#21644;&#26102;&#38388;&#30456;&#20851;&#24615;&#65292;&#20197;&#39044;&#27979;&#28857;&#20987;&#29575;&#30340;&#25928;&#26524;&#21644;&#24050;&#26377;&#26041;&#27861;&#23545;&#36825;&#31181;&#30456;&#20851;&#24615;&#30340;&#23398;&#20064;&#31243;&#24230;&#23578;&#19981;&#28165;&#26970;&#12290;</title><link>http://arxiv.org/abs/2308.08487</link><description>&lt;p&gt;
&#28857;&#20987;&#29575;&#39044;&#27979;&#30340;&#26102;&#38388;&#20852;&#36259;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Temporal Interest Network for Click-Through Rate Prediction. (arXiv:2308.08487v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08487
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#26102;&#38388;&#20852;&#36259;&#32593;&#32476;&#65288;TIN&#65289;&#65292;&#29992;&#20110;&#25429;&#25417;&#34892;&#20026;&#19982;&#30446;&#26631;&#20043;&#38388;&#30340;&#22235;&#37325;&#35821;&#20041;&#21644;&#26102;&#38388;&#30456;&#20851;&#24615;&#65292;&#20197;&#39044;&#27979;&#28857;&#20987;&#29575;&#30340;&#25928;&#26524;&#21644;&#24050;&#26377;&#26041;&#27861;&#23545;&#36825;&#31181;&#30456;&#20851;&#24615;&#30340;&#23398;&#20064;&#31243;&#24230;&#23578;&#19981;&#28165;&#26970;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29992;&#25143;&#34892;&#20026;&#30340;&#21382;&#21490;&#26159;&#39044;&#27979;&#28857;&#20987;&#29575;&#26368;&#37325;&#35201;&#30340;&#29305;&#24449;&#20043;&#19968;&#65292;&#22240;&#20026;&#23427;&#20204;&#19982;&#30446;&#26631;&#39033;&#30446;&#20855;&#26377;&#24378;&#28872;&#30340;&#35821;&#20041;&#21644;&#26102;&#38388;&#30456;&#20851;&#24615;&#12290;&#34429;&#28982;&#24050;&#26377;&#25991;&#29486;&#20998;&#21035;&#30740;&#31350;&#20102;&#36825;&#20123;&#30456;&#20851;&#24615;&#65292;&#20294;&#23578;&#26410;&#20998;&#26512;&#23427;&#20204;&#30340;&#32452;&#21512;&#65292;&#21363;&#34892;&#20026;&#35821;&#20041;&#12289;&#30446;&#26631;&#35821;&#20041;&#12289;&#34892;&#20026;&#26102;&#38388;&#21644;&#30446;&#26631;&#26102;&#38388;&#30340;&#22235;&#37325;&#30456;&#20851;&#24615;&#12290;&#36825;&#31181;&#30456;&#20851;&#24615;&#23545;&#24615;&#33021;&#30340;&#24433;&#21709;&#20197;&#21450;&#29616;&#26377;&#26041;&#27861;&#23398;&#20064;&#36825;&#31181;&#30456;&#20851;&#24615;&#30340;&#31243;&#24230;&#23578;&#19981;&#28165;&#26970;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#22312;&#23454;&#36341;&#20013;&#27979;&#37327;&#20102;&#22235;&#37325;&#30456;&#20851;&#24615;&#65292;&#24182;&#35266;&#23519;&#21040;&#30452;&#35266;&#32780;&#24378;&#22823;&#30340;&#22235;&#37325;&#27169;&#24335;&#12290;&#25105;&#20204;&#27979;&#37327;&#20102;&#20960;&#31181;&#20195;&#34920;&#24615;&#30340;&#29992;&#25143;&#34892;&#20026;&#26041;&#27861;&#30340;&#23398;&#20064;&#30456;&#20851;&#24615;&#65292;&#20294;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#23427;&#20204;&#37117;&#27809;&#26377;&#23398;&#20064;&#21040;&#36825;&#26679;&#30340;&#27169;&#24335;&#65292;&#29305;&#21035;&#26159;&#26102;&#38388;&#27169;&#24335;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26102;&#38388;&#20852;&#36259;&#32593;&#32476;&#65288;TIN&#65289;&#26469;&#25429;&#25417;&#34892;&#20026;&#19982;&#30446;&#26631;&#20043;&#38388;&#30340;&#22235;&#37325;&#35821;&#20041;&#21644;&#26102;&#38388;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The history of user behaviors constitutes one of the most significant characteristics in predicting the click-through rate (CTR), owing to their strong semantic and temporal correlation with the target item. While the literature has individually examined each of these correlations, research has yet to analyze them in combination, that is, the quadruple correlation of (behavior semantics, target semantics, behavior temporal, and target temporal). The effect of this correlation on performance and the extent to which existing methods learn it remain unknown. To address this gap, we empirically measure the quadruple correlation and observe intuitive yet robust quadruple patterns. We measure the learned correlation of several representative user behavior methods, but to our surprise, none of them learn such a pattern, especially the temporal one.  In this paper, we propose the Temporal Interest Network (TIN) to capture the quadruple semantic and temporal correlation between behaviors and th
&lt;/p&gt;</description></item></channel></rss>