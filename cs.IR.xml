<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20020;&#24202;&#25991;&#26723;&#21160;&#24577;&#38382;&#31572;&#30340;&#33258;&#28982;&#35821;&#35328;&#25509;&#21475;&#12290;&#36890;&#36807;Langchain&#21644;Transformer-based LLMs&#39537;&#21160;&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;&#65292;&#29992;&#25143;&#21487;&#20197;&#29992;&#33258;&#28982;&#35821;&#35328;&#26597;&#35810;&#20020;&#24202;&#31508;&#35760;&#24182;&#33719;&#24471;&#30456;&#20851;&#31572;&#26696;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;Wizard Vicuna&#20855;&#26377;&#20986;&#33394;&#30340;&#20934;&#30830;&#24615;&#65292;&#20294;&#35745;&#31639;&#35201;&#27714;&#36739;&#39640;&#12290;&#27169;&#22411;&#20248;&#21270;&#26041;&#26696;&#25552;&#39640;&#20102;&#32422;48&#20493;&#30340;&#24310;&#36831;&#12290;&#28982;&#32780;&#65292;&#27169;&#22411;&#20135;&#29983;&#24187;&#35937;&#21644;&#22810;&#26679;&#21270;&#21307;&#30103;&#26696;&#20363;&#35780;&#20272;&#30340;&#38480;&#21046;&#20173;&#28982;&#23384;&#22312;&#12290;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#23545;&#20110;&#21457;&#25496;&#20020;&#24202;&#31508;&#35760;&#30340;&#20215;&#20540;&#21644;&#25512;&#36827;&#22522;&#20110;AI&#30340;&#20020;&#24202;&#20915;&#31574;&#33267;&#20851;&#37325;&#35201;&#12290;</title><link>http://arxiv.org/abs/2401.10733</link><description>&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20020;&#24202;&#25991;&#26723;&#30340;&#21160;&#24577;&#38382;&#31572;
&lt;/p&gt;
&lt;p&gt;
Dynamic Q&amp;A of Clinical Documents with Large Language Models. (arXiv:2401.10733v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10733
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20020;&#24202;&#25991;&#26723;&#21160;&#24577;&#38382;&#31572;&#30340;&#33258;&#28982;&#35821;&#35328;&#25509;&#21475;&#12290;&#36890;&#36807;Langchain&#21644;Transformer-based LLMs&#39537;&#21160;&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;&#65292;&#29992;&#25143;&#21487;&#20197;&#29992;&#33258;&#28982;&#35821;&#35328;&#26597;&#35810;&#20020;&#24202;&#31508;&#35760;&#24182;&#33719;&#24471;&#30456;&#20851;&#31572;&#26696;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;Wizard Vicuna&#20855;&#26377;&#20986;&#33394;&#30340;&#20934;&#30830;&#24615;&#65292;&#20294;&#35745;&#31639;&#35201;&#27714;&#36739;&#39640;&#12290;&#27169;&#22411;&#20248;&#21270;&#26041;&#26696;&#25552;&#39640;&#20102;&#32422;48&#20493;&#30340;&#24310;&#36831;&#12290;&#28982;&#32780;&#65292;&#27169;&#22411;&#20135;&#29983;&#24187;&#35937;&#21644;&#22810;&#26679;&#21270;&#21307;&#30103;&#26696;&#20363;&#35780;&#20272;&#30340;&#38480;&#21046;&#20173;&#28982;&#23384;&#22312;&#12290;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#23545;&#20110;&#21457;&#25496;&#20020;&#24202;&#31508;&#35760;&#30340;&#20215;&#20540;&#21644;&#25512;&#36827;&#22522;&#20110;AI&#30340;&#20020;&#24202;&#20915;&#31574;&#33267;&#20851;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#65288;EHR&#65289;&#20013;&#25910;&#24405;&#20102;&#20020;&#24202;&#31508;&#35760;&#20013;&#30340;&#37325;&#35201;&#24739;&#32773;&#25968;&#25454;&#12290;&#38543;&#30528;&#36825;&#20123;&#31508;&#35760;&#25968;&#37327;&#21644;&#22797;&#26434;&#24230;&#30340;&#22686;&#21152;&#65292;&#25163;&#21160;&#25552;&#21462;&#21464;&#24471;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#30740;&#31350;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24341;&#20837;&#20102;&#19968;&#31181;&#33258;&#28982;&#35821;&#35328;&#25509;&#21475;&#65292;&#29992;&#20110;&#23545;&#20020;&#24202;&#31508;&#35760;&#36827;&#34892;&#21160;&#24577;&#38382;&#31572;&#12290;&#25105;&#20204;&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;&#30001;Langchain&#21644;&#22522;&#20110;Transformer&#30340;LLMs&#39537;&#21160;&#65292;&#20801;&#35768;&#29992;&#25143;&#29992;&#33258;&#28982;&#35821;&#35328;&#21457;&#20986;&#26597;&#35810;&#65292;&#24182;&#20174;&#20020;&#24202;&#31508;&#35760;&#20013;&#33719;&#24471;&#30456;&#20851;&#31572;&#26696;&#12290;&#36890;&#36807;&#20351;&#29992;&#21508;&#31181;&#23884;&#20837;&#27169;&#22411;&#21644;&#20808;&#36827;&#30340;LLMs&#36827;&#34892;&#23454;&#39564;&#65292;&#32467;&#26524;&#34920;&#26126;Wizard Vicuna&#22312;&#20934;&#30830;&#24615;&#26041;&#38754;&#34920;&#29616;&#20248;&#24322;&#65292;&#23613;&#31649;&#35745;&#31639;&#35201;&#27714;&#36739;&#39640;&#12290;&#27169;&#22411;&#20248;&#21270;&#65292;&#21253;&#25324;&#26435;&#37325;&#37327;&#21270;&#65292;&#23558;&#24310;&#36831;&#25552;&#39640;&#20102;&#32422;48&#20493;&#12290;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#26174;&#31034;&#20102;&#20020;&#24202;&#31508;&#35760;&#20013;&#30340;&#20215;&#20540;&#28508;&#21147;&#65292;&#20294;&#20173;&#23384;&#22312;&#27169;&#22411;&#20135;&#29983;&#24187;&#35937;&#21644;&#26377;&#38480;&#30340;&#22810;&#26679;&#21270;&#21307;&#30103;&#26696;&#20363;&#35780;&#20272;&#31561;&#25361;&#25112;&#12290;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#23545;&#20110;&#21457;&#25496;&#20020;&#24202;&#31508;&#35760;&#30340;&#20215;&#20540;&#21644;&#25512;&#21160;AI&#39537;&#21160;&#30340;&#20020;&#24202;&#20915;&#31574;&#33267;&#20851;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
Electronic health records (EHRs) house crucial patient data in clinical notes. As these notes grow in volume and complexity, manual extraction becomes challenging. This work introduces a natural language interface using large language models (LLMs) for dynamic question-answering on clinical notes. Our chatbot, powered by Langchain and transformer-based LLMs, allows users to query in natural language, receiving relevant answers from clinical notes. Experiments, utilizing various embedding models and advanced LLMs, show Wizard Vicuna's superior accuracy, albeit with high compute demands. Model optimization, including weight quantization, improves latency by approximately 48 times. Promising results indicate potential, yet challenges such as model hallucinations and limited diverse medical case evaluations remain. Addressing these gaps is crucial for unlocking the value in clinical notes and advancing AI-driven clinical decision-making.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#32508;&#36848;&#35770;&#25991;&#35752;&#35770;&#20102;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#27969;&#34892;&#20559;&#24046;&#38382;&#39064;&#65292;&#24182;&#22238;&#39038;&#20102;&#29616;&#26377;&#30340;&#26041;&#27861;&#26469;&#26816;&#27979;&#12289;&#37327;&#21270;&#21644;&#20943;&#23569;&#27969;&#34892;&#20559;&#24046;&#12290;&#23427;&#21516;&#26102;&#25552;&#20379;&#20102;&#35745;&#31639;&#24230;&#37327;&#30340;&#27010;&#36848;&#21644;&#20027;&#35201;&#25216;&#26415;&#26041;&#27861;&#30340;&#22238;&#39038;&#12290;</title><link>http://arxiv.org/abs/2308.01118</link><description>&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#27969;&#34892;&#20559;&#24046;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Survey on Popularity Bias in Recommender Systems. (arXiv:2308.01118v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01118
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#32508;&#36848;&#35770;&#25991;&#35752;&#35770;&#20102;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#27969;&#34892;&#20559;&#24046;&#38382;&#39064;&#65292;&#24182;&#22238;&#39038;&#20102;&#29616;&#26377;&#30340;&#26041;&#27861;&#26469;&#26816;&#27979;&#12289;&#37327;&#21270;&#21644;&#20943;&#23569;&#27969;&#34892;&#20559;&#24046;&#12290;&#23427;&#21516;&#26102;&#25552;&#20379;&#20102;&#35745;&#31639;&#24230;&#37327;&#30340;&#27010;&#36848;&#21644;&#20027;&#35201;&#25216;&#26415;&#26041;&#27861;&#30340;&#22238;&#39038;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#20197;&#20010;&#24615;&#21270;&#30340;&#26041;&#24335;&#24110;&#21161;&#20154;&#20204;&#25214;&#21040;&#30456;&#20851;&#20869;&#23481;&#12290;&#36825;&#20123;&#31995;&#32479;&#30340;&#19968;&#20010;&#20027;&#35201;&#25215;&#35834;&#26159;&#33021;&#22815;&#22686;&#21152;&#30446;&#24405;&#20013;&#36739;&#23569;&#30693;&#21517;&#30340;&#29289;&#21697;&#30340;&#21487;&#35265;&#24615;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#29616;&#20170;&#30340;&#25512;&#33616;&#31639;&#27861;&#21453;&#32780;&#34920;&#29616;&#20986;&#27969;&#34892;&#20559;&#24046;&#65292;&#21363;&#23427;&#20204;&#22312;&#25512;&#33616;&#20013;&#32463;&#24120;&#20851;&#27880;&#30456;&#24403;&#27969;&#34892;&#30340;&#29289;&#21697;&#12290;&#36825;&#31181;&#20559;&#24046;&#19981;&#20165;&#21487;&#33021;&#23548;&#33268;&#30701;&#26399;&#20869;&#23545;&#28040;&#36153;&#32773;&#21644;&#25552;&#20379;&#32773;&#30340;&#25512;&#33616;&#20215;&#20540;&#26377;&#38480;&#65292;&#32780;&#19988;&#36824;&#21487;&#33021;&#24341;&#36215;&#19981;&#24076;&#26395;&#30340;&#24378;&#21270;&#25928;&#24212;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#27969;&#34892;&#20559;&#24046;&#30340;&#28508;&#22312;&#21407;&#22240;&#65292;&#24182;&#22238;&#39038;&#20102;&#29616;&#26377;&#30340;&#26816;&#27979;&#12289;&#37327;&#21270;&#21644;&#20943;&#23569;&#25512;&#33616;&#31995;&#32479;&#20013;&#27969;&#34892;&#20559;&#24046;&#30340;&#26041;&#27861;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;&#32508;&#36848;&#26082;&#21253;&#25324;&#20102;&#25991;&#29486;&#20013;&#20351;&#29992;&#30340;&#35745;&#31639;&#24230;&#37327;&#30340;&#27010;&#36848;&#65292;&#20063;&#21253;&#25324;&#20102;&#20943;&#23569;&#20559;&#24046;&#30340;&#20027;&#35201;&#25216;&#26415;&#26041;&#27861;&#30340;&#22238;&#39038;&#12290;&#25105;&#20204;&#36824;&#23545;&#36825;&#20123;&#26041;&#27861;&#36827;&#34892;&#20102;&#25209;&#21028;&#24615;&#35752;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems help people find relevant content in a personalized way. One main promise of such systems is that they are able to increase the visibility of items in the long tail, i.e., the lesser-known items in a catalogue. Existing research, however, suggests that in many situations today's recommendation algorithms instead exhibit a popularity bias, meaning that they often focus on rather popular items in their recommendations. Such a bias may not only lead to limited value of the recommendations for consumers and providers in the short run, but it may also cause undesired reinforcement effects over time. In this paper, we discuss the potential reasons for popularity bias and we review existing approaches to detect, quantify and mitigate popularity bias in recommender systems. Our survey therefore includes both an overview of the computational metrics used in the literature as well as a review of the main technical approaches to reduce the bias. We furthermore critically discu
&lt;/p&gt;</description></item></channel></rss>