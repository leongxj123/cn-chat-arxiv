<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#38646;&#26679;&#26412;&#26597;&#35810;&#37325;&#26500;&#65288;ZeQR&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#26426;&#22120;&#38405;&#35835;&#29702;&#35299;&#20219;&#21153;&#30340;&#35821;&#35328;&#27169;&#22411;&#26469;&#35299;&#20915;&#23545;&#35805;&#25628;&#32034;&#20013;&#30340;&#25968;&#25454;&#31232;&#30095;&#24615;&#12289;&#35299;&#37322;&#24615;&#19981;&#36275;&#21644;&#27495;&#20041;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.09384</link><description>&lt;p&gt;
&#38646;&#26679;&#26412;&#23545;&#35805;&#25628;&#32034;&#20013;&#30340;&#26597;&#35810;&#37325;&#26500;
&lt;/p&gt;
&lt;p&gt;
Zero-shot Query Reformulation for Conversational Search. (arXiv:2307.09384v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09384
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#38646;&#26679;&#26412;&#26597;&#35810;&#37325;&#26500;&#65288;ZeQR&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#26426;&#22120;&#38405;&#35835;&#29702;&#35299;&#20219;&#21153;&#30340;&#35821;&#35328;&#27169;&#22411;&#26469;&#35299;&#20915;&#23545;&#35805;&#25628;&#32034;&#20013;&#30340;&#25968;&#25454;&#31232;&#30095;&#24615;&#12289;&#35299;&#37322;&#24615;&#19981;&#36275;&#21644;&#27495;&#20041;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#35821;&#38899;&#21161;&#25163;&#30340;&#26222;&#21450;&#65292;&#23545;&#35805;&#25628;&#32034;&#22312;&#20449;&#24687;&#26816;&#32034;&#39046;&#22495;&#24341;&#36215;&#20102;&#26356;&#22810;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#23545;&#35805;&#25628;&#32034;&#20013;&#30340;&#25968;&#25454;&#31232;&#30095;&#24615;&#38382;&#39064;&#20005;&#37325;&#38459;&#30861;&#20102;&#30417;&#30563;&#24335;&#23545;&#35805;&#25628;&#32034;&#26041;&#27861;&#30340;&#36827;&#23637;&#12290;&#22240;&#27492;&#65292;&#30740;&#31350;&#20154;&#21592;&#26356;&#21152;&#20851;&#27880;&#38646;&#26679;&#26412;&#23545;&#35805;&#25628;&#32034;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#38646;&#26679;&#26412;&#26041;&#27861;&#23384;&#22312;&#19977;&#20010;&#20027;&#35201;&#38480;&#21046;&#65306;&#23427;&#20204;&#19981;&#36866;&#29992;&#20110;&#25152;&#26377;&#30340;&#26816;&#32034;&#22120;&#65292;&#23427;&#20204;&#30340;&#26377;&#25928;&#24615;&#32570;&#20047;&#36275;&#22815;&#30340;&#35299;&#37322;&#24615;&#65292;&#24182;&#19988;&#20182;&#20204;&#26080;&#27861;&#35299;&#20915;&#22240;&#30465;&#30053;&#32780;&#23548;&#33268;&#30340;&#24120;&#35265;&#23545;&#35805;&#27495;&#20041;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38646;&#26679;&#26412;&#26597;&#35810;&#37325;&#26500;&#65288;ZeQR&#65289;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#26681;&#25454;&#20808;&#21069;&#30340;&#23545;&#35805;&#19978;&#19979;&#25991;&#37325;&#26500;&#26597;&#35810;&#65292;&#32780;&#26080;&#38656;&#23545;&#35805;&#25628;&#32034;&#25968;&#25454;&#30340;&#30417;&#30563;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#21033;&#29992;&#20102;&#35774;&#35745;&#29992;&#20110;&#26426;&#22120;&#38405;&#35835;&#29702;&#35299;&#20219;&#21153;&#30340;&#35821;&#35328;&#27169;&#22411;&#26469;&#26126;&#30830;&#35299;&#20915;&#20004;&#20010;&#24120;&#35265;&#30340;&#27495;&#20041;&#65306;&#21327;&#35843;&#21644;&#30465;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
As the popularity of voice assistants continues to surge, conversational search has gained increased attention in Information Retrieval. However, data sparsity issues in conversational search significantly hinder the progress of supervised conversational search methods. Consequently, researchers are focusing more on zero-shot conversational search approaches. Nevertheless, existing zero-shot methods face three primary limitations: they are not universally applicable to all retrievers, their effectiveness lacks sufficient explainability, and they struggle to resolve common conversational ambiguities caused by omission. To address these limitations, we introduce a novel Zero-shot Query Reformulation (ZeQR) framework that reformulates queries based on previous dialogue contexts without requiring supervision from conversational search data. Specifically, our framework utilizes language models designed for machine reading comprehension tasks to explicitly resolve two common ambiguities: cor
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23545;&#35805;&#24335;&#27573;&#33853;&#26816;&#32034;&#20013;&#28151;&#21512;&#20027;&#21160;&#26597;&#35810;&#37325;&#26500;&#30340;&#25506;&#32034;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#28151;&#21512;&#20027;&#21160;&#26597;&#35810;&#37325;&#26500;&#27169;&#22359;&#65292;&#35813;&#27169;&#22359;&#33021;&#22815;&#22522;&#20110;&#29992;&#25143;&#19982;&#31995;&#32479;&#20043;&#38388;&#30340;&#28151;&#21512;&#20027;&#21160;&#20132;&#20114;&#23545;&#21407;&#22987;&#26597;&#35810;&#36827;&#34892;&#37325;&#26500;&#65292;&#20197;&#25552;&#39640;&#26816;&#32034;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.08803</link><description>&lt;p&gt;
&#12298;&#28151;&#21512;&#20027;&#21160;&#26597;&#35810;&#37325;&#26500;&#22312;&#23545;&#35805;&#24335;&#27573;&#33853;&#26816;&#32034;&#20013;&#30340;&#25506;&#32034;&#30740;&#31350;&#12299;&#30340;&#30740;&#31350;&#25253;&#21578;
&lt;/p&gt;
&lt;p&gt;
An Exploration Study of Mixed-initiative Query Reformulation in Conversational Passage Retrieval. (arXiv:2307.08803v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08803
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23545;&#35805;&#24335;&#27573;&#33853;&#26816;&#32034;&#20013;&#28151;&#21512;&#20027;&#21160;&#26597;&#35810;&#37325;&#26500;&#30340;&#25506;&#32034;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#28151;&#21512;&#20027;&#21160;&#26597;&#35810;&#37325;&#26500;&#27169;&#22359;&#65292;&#35813;&#27169;&#22359;&#33021;&#22815;&#22522;&#20110;&#29992;&#25143;&#19982;&#31995;&#32479;&#20043;&#38388;&#30340;&#28151;&#21512;&#20027;&#21160;&#20132;&#20114;&#23545;&#21407;&#22987;&#26597;&#35810;&#36827;&#34892;&#37325;&#26500;&#65292;&#20197;&#25552;&#39640;&#26816;&#32034;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25253;&#21578;&#20102;&#25105;&#20204;&#22312;TREC Conversational Assistance Track (CAsT) 2022&#20013;&#30340;&#26041;&#27861;&#21644;&#23454;&#39564;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#22797;&#29616;&#22810;&#38454;&#27573;&#30340;&#26816;&#32034;&#31649;&#32447;&#65292;&#24182;&#25506;&#32034;&#22312;&#23545;&#35805;&#24335;&#27573;&#33853;&#26816;&#32034;&#22330;&#26223;&#20013;&#28041;&#21450;&#28151;&#21512;&#20027;&#21160;&#20132;&#20114;&#30340;&#28508;&#22312;&#22909;&#22788;&#20043;&#19968;&#65306;&#23545;&#21407;&#22987;&#26597;&#35810;&#36827;&#34892;&#37325;&#26500;&#12290;&#22312;&#22810;&#38454;&#27573;&#26816;&#32034;&#31649;&#32447;&#30340;&#31532;&#19968;&#20010;&#25490;&#21517;&#38454;&#27573;&#20043;&#21069;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#28151;&#21512;&#20027;&#21160;&#26597;&#35810;&#37325;&#26500;&#27169;&#22359;&#65292;&#23427;&#36890;&#36807;&#29992;&#25143;&#19982;&#31995;&#32479;&#20043;&#38388;&#30340;&#28151;&#21512;&#20027;&#21160;&#20132;&#20114;&#23454;&#29616;&#26597;&#35810;&#37325;&#26500;&#65292;&#20316;&#20026;&#31070;&#32463;&#37325;&#26500;&#26041;&#27861;&#30340;&#26367;&#20195;&#21697;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#31639;&#27861;&#26469;&#29983;&#25104;&#19982;&#21407;&#22987;&#26597;&#35810;&#20013;&#30340;&#27495;&#20041;&#30456;&#20851;&#30340;&#36866;&#24403;&#38382;&#39064;&#65292;&#20197;&#21450;&#21478;&#19968;&#20010;&#31639;&#27861;&#26469;&#35299;&#26512;&#29992;&#25143;&#30340;&#21453;&#39304;&#24182;&#23558;&#20854;&#34701;&#20837;&#21040;&#21407;&#22987;&#26597;&#35810;&#20013;&#20197;&#36827;&#34892;&#26597;&#35810;&#37325;&#26500;&#12290;&#23545;&#20110;&#25105;&#20204;&#30340;&#22810;&#38454;&#27573;&#31649;&#32447;&#30340;&#31532;&#19968;&#20010;&#25490;&#21517;&#38454;&#27573;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#19968;&#20010;&#31232;&#30095;&#25490;&#21517;&#20989;&#25968;&#65306;BM25&#21644;&#19968;&#20010;&#23494;&#38598;&#26816;&#32034;&#26041;&#27861;&#65306;TCT-ColBERT&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we report our methods and experiments for the TREC Conversational Assistance Track (CAsT) 2022. In this work, we aim to reproduce multi-stage retrieval pipelines and explore one of the potential benefits of involving mixed-initiative interaction in conversational passage retrieval scenarios: reformulating raw queries. Before the first ranking stage of a multi-stage retrieval pipeline, we propose a mixed-initiative query reformulation module, which achieves query reformulation based on the mixed-initiative interaction between the users and the system, as the replacement for the neural reformulation method. Specifically, we design an algorithm to generate appropriate questions related to the ambiguities in raw queries, and another algorithm to reformulate raw queries by parsing users' feedback and incorporating it into the raw query. For the first ranking stage of our multi-stage pipelines, we adopt a sparse ranking function: BM25, and a dense retrieval method: TCT-ColBERT
&lt;/p&gt;</description></item></channel></rss>