<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#29992;&#25143;&#34920;&#31034;&#25490;&#26021;&#30340;&#26032;&#22411;&#22810;&#22612;&#22810;&#20852;&#36259;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#22810;&#20852;&#36259;&#23398;&#20064;&#26041;&#27861;&#38754;&#20020;&#30340;&#35757;&#32451;&#21644;&#37096;&#32626;&#30446;&#26631;&#24046;&#24322;&#12289;&#26080;&#27861;&#35775;&#38382;&#21830;&#21697;&#20449;&#24687;&#20197;&#21450;&#38590;&#20197;&#24037;&#19994;&#37319;&#29992;&#31561;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.05122</link><description>&lt;p&gt;
&#20855;&#26377;&#29992;&#25143;&#34920;&#31034;&#25490;&#26021;&#30340;&#22810;&#22612;&#22810;&#20852;&#36259;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Multi-Tower Multi-Interest Recommendation with User Representation Repel
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05122
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#29992;&#25143;&#34920;&#31034;&#25490;&#26021;&#30340;&#26032;&#22411;&#22810;&#22612;&#22810;&#20852;&#36259;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#22810;&#20852;&#36259;&#23398;&#20064;&#26041;&#27861;&#38754;&#20020;&#30340;&#35757;&#32451;&#21644;&#37096;&#32626;&#30446;&#26631;&#24046;&#24322;&#12289;&#26080;&#27861;&#35775;&#38382;&#21830;&#21697;&#20449;&#24687;&#20197;&#21450;&#38590;&#20197;&#24037;&#19994;&#37319;&#29992;&#31561;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20449;&#24687;&#36807;&#36733;&#30340;&#26102;&#20195;&#65292;&#23398;&#26415;&#30028;&#21644;&#24037;&#19994;&#30028;&#37117;&#28145;&#21051;&#35748;&#35782;&#21040;&#25512;&#33616;&#31995;&#32479;&#30340;&#20215;&#20540;&#12290;&#29305;&#21035;&#26159;&#22810;&#20852;&#36259;&#24207;&#21015;&#25512;&#33616;&#26159;&#36817;&#24180;&#26469;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#20851;&#27880;&#30340;&#19968;&#20010;&#23376;&#39046;&#22495;&#12290;&#36890;&#36807;&#29983;&#25104;&#22810;&#29992;&#25143;&#34920;&#31034;&#65292;&#22810;&#20852;&#36259;&#23398;&#20064;&#27169;&#22411;&#22312;&#29702;&#35770;&#19978;&#21644;&#32463;&#39564;&#19978;&#37117;&#27604;&#21333;&#29992;&#25143;&#34920;&#31034;&#27169;&#22411;&#20855;&#26377;&#26356;&#24378;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;&#23613;&#31649;&#35813;&#39046;&#22495;&#21462;&#24471;&#20102;&#37325;&#22823;&#36827;&#23637;&#65292;&#20294;&#20173;&#23384;&#22312;&#19977;&#20010;&#20027;&#35201;&#38382;&#39064;&#22256;&#25200;&#30528;&#22810;&#20852;&#36259;&#23398;&#20064;&#26041;&#27861;&#30340;&#24615;&#33021;&#21644;&#21487;&#37319;&#29992;&#24615;&#65292;&#21363;&#35757;&#32451;&#21644;&#37096;&#32626;&#30446;&#26631;&#20043;&#38388;&#30340;&#24046;&#24322;&#12289;&#26080;&#27861;&#35775;&#38382;&#21830;&#21697;&#20449;&#24687;&#20197;&#21450;&#30001;&#20110;&#20854;&#21333;&#22612;&#26550;&#26500;&#32780;&#38590;&#20197;&#24037;&#19994;&#37319;&#29992;&#12290;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#20855;&#26377;&#29992;&#25143;&#34920;&#31034;&#25490;&#26021;&#30340;&#26032;&#22411;&#22810;&#22612;&#22810;&#20852;&#36259;&#26694;&#26550;&#26469;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#12290;&#36890;&#36807;&#36328;&#22810;&#20010;&#22823;&#35268;&#27169;&#23454;&#39564;&#32467;&#26524;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05122v1 Announce Type: cross  Abstract: In the era of information overload, the value of recommender systems has been profoundly recognized in academia and industry alike. Multi-interest sequential recommendation, in particular, is a subfield that has been receiving increasing attention in recent years. By generating multiple-user representations, multi-interest learning models demonstrate superior expressiveness than single-user representation models, both theoretically and empirically. Despite major advancements in the field, three major issues continue to plague the performance and adoptability of multi-interest learning methods, the difference between training and deployment objectives, the inability to access item information, and the difficulty of industrial adoption due to its single-tower architecture. We address these challenges by proposing a novel multi-tower multi-interest framework with user representation repel. Experimental results across multiple large-scale 
&lt;/p&gt;</description></item><item><title>&#36817;&#26399;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#23545;&#20449;&#24687;&#26816;&#32034;&#31995;&#32479;&#20135;&#29983;&#20102;&#19968;&#31181;&#20559;&#35265;&#65292;&#20542;&#21521;&#20110;&#23558;LLM&#29983;&#25104;&#30340;&#25991;&#26723;&#25490;&#21517;&#36739;&#39640;&#12290;&#36825;&#31181;&#8220;&#26469;&#28304;&#20559;&#35265;&#8221;&#21487;&#33021;&#23545;&#20449;&#24687;&#35775;&#38382;&#20135;&#29983;&#37325;&#22823;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2310.20501</link><description>&lt;p&gt;
LLM&#21487;&#33021;&#20027;&#23548;&#20449;&#24687;&#35775;&#38382;&#65306;&#31070;&#32463;&#26816;&#32034;&#22120;&#23545;LLM&#29983;&#25104;&#30340;&#25991;&#26412;&#23384;&#22312;&#20559;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;
LLMs may Dominate Information Access: Neural Retrievers are Biased Towards LLM-Generated Texts. (arXiv:2310.20501v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20501
&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#23545;&#20449;&#24687;&#26816;&#32034;&#31995;&#32479;&#20135;&#29983;&#20102;&#19968;&#31181;&#20559;&#35265;&#65292;&#20542;&#21521;&#20110;&#23558;LLM&#29983;&#25104;&#30340;&#25991;&#26723;&#25490;&#21517;&#36739;&#39640;&#12290;&#36825;&#31181;&#8220;&#26469;&#28304;&#20559;&#35265;&#8221;&#21487;&#33021;&#23545;&#20449;&#24687;&#35775;&#38382;&#20135;&#29983;&#37325;&#22823;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20986;&#29616;&#22312;&#20449;&#24687;&#26816;&#32034;&#65288;IR&#65289;&#24212;&#29992;&#65292;&#23588;&#20854;&#26159;&#22312;&#32593;&#32476;&#25628;&#32034;&#26041;&#38754;&#65292;&#24443;&#24213;&#25913;&#21464;&#20102;&#33539;&#24335;&#12290;&#30001;&#20110;&#20854;&#22312;&#29983;&#25104;&#31867;&#20154;&#25991;&#26412;&#26041;&#38754;&#30340;&#21331;&#36234;&#33021;&#21147;&#65292;LLMs&#22312;&#20114;&#32852;&#32593;&#19978;&#21019;&#36896;&#20102;&#22823;&#37327;&#30340;&#25991;&#26412;&#12290;&#22240;&#27492;&#65292;LLMs&#26102;&#20195;&#30340;IR&#31995;&#32479;&#38754;&#20020;&#19968;&#20010;&#26032;&#30340;&#25361;&#25112;&#65306;&#32034;&#24341;&#30340;&#25991;&#26723;&#19981;&#20165;&#26159;&#30001;&#20154;&#31867;&#25776;&#20889;&#30340;&#65292;&#32780;&#19988;&#36824;&#21253;&#25324;&#30001;LLMs&#33258;&#21160;&#29983;&#25104;&#30340;&#25991;&#26723;&#12290;&#36825;&#20123;LLM&#29983;&#25104;&#30340;&#25991;&#26723;&#22914;&#20309;&#24433;&#21709;IR&#31995;&#32479;&#26159;&#19968;&#20010;&#32039;&#36843;&#19988;&#23578;&#26410;&#25506;&#32034;&#30340;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#22312;&#28041;&#21450;&#20154;&#31867;&#32534;&#20889;&#21644;LLM&#29983;&#25104;&#30340;&#25991;&#26412;&#30340;&#19981;&#21516;IR&#27169;&#22411;&#30340;&#22330;&#26223;&#20013;&#36827;&#34892;&#20102;&#23450;&#37327;&#35780;&#20272;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#31070;&#32463;&#26816;&#32034;&#27169;&#22411;&#20542;&#21521;&#20110;&#23558;LLM&#29983;&#25104;&#30340;&#25991;&#26723;&#25490;&#21517;&#36739;&#39640;&#12290;&#25105;&#20204;&#23558;&#36825;&#31181;&#31070;&#32463;&#26816;&#32034;&#27169;&#22411;&#23545;LLM&#29983;&#25104;&#25991;&#26412;&#30340;&#20559;&#35265;&#31216;&#20026;&#8220;&#26469;&#28304;&#20559;&#35265;&#8221;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21457;&#29616;&#36825;&#31181;&#20559;&#35265;&#19981;&#20165;&#38480;&#20110;f&#26041;&#30456;&#24403;&#30340;&#24773;&#20917;&#65292;&#32780;&#19988;&#22312;&#20998;&#31867;&#20219;&#21153;&#19978;&#20063;&#23384;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, the emergence of large language models (LLMs) has revolutionized the paradigm of information retrieval (IR) applications, especially in web search. With their remarkable capabilities in generating human-like texts, LLMs have created enormous texts on the Internet. As a result, IR systems in the LLMs era are facing a new challenge: the indexed documents now are not only written by human beings but also automatically generated by the LLMs. How these LLM-generated documents influence the IR systems is a pressing and still unexplored question. In this work, we conduct a quantitative evaluation of different IR models in scenarios where both human-written and LLM-generated texts are involved. Surprisingly, our findings indicate that neural retrieval models tend to rank LLM-generated documents higher. We refer to this category of biases in neural retrieval models towards the LLM-generated text as the \textbf{source bias}. Moreover, we discover that this bias is not confined to the f
&lt;/p&gt;</description></item></channel></rss>