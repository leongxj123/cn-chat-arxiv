<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#22312;&#28151;&#21512;&#30446;&#26631;&#25512;&#33616;&#20013;&#65292;&#36890;&#36807;&#30740;&#31350;&#22810;&#20219;&#21153;&#23398;&#20064;&#38382;&#39064;&#65292;&#25506;&#35752;&#20102;&#31163;&#25955;&#36716;&#21270;&#34892;&#20026;&#19982;&#36830;&#32493;&#36716;&#21270;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#35299;&#20915;&#20102;&#26680;&#24515;&#22238;&#24402;&#20219;&#21153;&#23545;&#20854;&#20182;&#20219;&#21153;&#24433;&#21709;&#36739;&#22823;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.17442</link><description>&lt;p&gt;
&#35302;&#21450;&#26680;&#24515;&#65306;&#25506;&#32034;&#28151;&#21512;&#30446;&#26631;&#25512;&#33616;&#20013;&#20219;&#21153;&#20381;&#36182;&#20851;&#31995;
&lt;/p&gt;
&lt;p&gt;
Touch the Core: Exploring Task Dependence Among Hybrid Targets for Recommendation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17442
&lt;/p&gt;
&lt;p&gt;
&#22312;&#28151;&#21512;&#30446;&#26631;&#25512;&#33616;&#20013;&#65292;&#36890;&#36807;&#30740;&#31350;&#22810;&#20219;&#21153;&#23398;&#20064;&#38382;&#39064;&#65292;&#25506;&#35752;&#20102;&#31163;&#25955;&#36716;&#21270;&#34892;&#20026;&#19982;&#36830;&#32493;&#36716;&#21270;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#35299;&#20915;&#20102;&#26680;&#24515;&#22238;&#24402;&#20219;&#21153;&#23545;&#20854;&#20182;&#20219;&#21153;&#24433;&#21709;&#36739;&#22823;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#29992;&#25143;&#34892;&#20026;&#22312;&#21830;&#19994;&#24179;&#21488;&#19978;&#21464;&#24471;&#22797;&#26434;&#65292;&#22312;&#32447;&#25512;&#33616;&#26356;&#21152;&#20851;&#27880;&#22914;&#20309;&#35302;&#21450;&#26680;&#24515;&#36716;&#21270;&#65292;&#36825;&#20123;&#36716;&#21270;&#19982;&#24179;&#21488;&#30340;&#20852;&#36259;&#23494;&#20999;&#30456;&#20851;&#12290;&#36825;&#20123;&#26680;&#24515;&#36716;&#21270;&#36890;&#24120;&#26159;&#36830;&#32493;&#30340;&#30446;&#26631;&#65292;&#22914;&#8220;&#35266;&#30475;&#26102;&#38388;&#8221;&#12289;&#8220;&#25910;&#20837;&#8221;&#31561;&#65292;&#23427;&#20204;&#30340;&#39044;&#27979;&#21487;&#20197;&#36890;&#36807;&#20043;&#21069;&#30340;&#31163;&#25955;&#36716;&#21270;&#34892;&#20026;&#26469;&#22686;&#24378;&#12290;&#22240;&#27492;&#65292;&#22810;&#20219;&#21153;&#23398;&#20064;&#65288;MTL&#65289;&#21487;&#20197;&#34987;&#37319;&#29992;&#20316;&#20026;&#23398;&#20064;&#36825;&#20123;&#28151;&#21512;&#30446;&#26631;&#30340;&#33539; paradigm&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#24037;&#20316;&#20027;&#35201;&#24378;&#35843;&#30740;&#31350;&#31163;&#25955;&#36716;&#21270;&#34892;&#20026;&#20043;&#38388;&#30340;&#39034;&#24207;&#20381;&#36182;&#20851;&#31995;&#65292;&#32780;&#24573;&#35270;&#20102;&#31163;&#25955;&#36716;&#21270;&#19982;&#26368;&#32456;&#36830;&#32493;&#36716;&#21270;&#20043;&#38388;&#30340;&#20381;&#36182;&#22797;&#26434;&#24615;&#12290;&#27492;&#22806;&#65292;&#21516;&#26102;&#20248;&#21270;&#20855;&#26377;&#26356;&#24378;&#20219;&#21153;&#20381;&#36182;&#24615;&#30340;&#28151;&#21512;&#20219;&#21153;&#23558;&#38754;&#20020;&#19981;&#31283;&#23450;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#26680;&#24515;&#22238;&#24402;&#20219;&#21153;&#21487;&#33021;&#23545;&#20854;&#20182;&#20219;&#21153;&#20135;&#29983;&#26356;&#22823;&#30340;&#24433;&#21709;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#28151;&#21512;&#30446;&#26631;&#30340;MTL&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17442v1 Announce Type: new  Abstract: As user behaviors become complicated on business platforms, online recommendations focus more on how to touch the core conversions, which are highly related to the interests of platforms. These core conversions are usually continuous targets, such as \textit{watch time}, \textit{revenue}, and so on, whose predictions can be enhanced by previous discrete conversion actions. Therefore, multi-task learning (MTL) can be adopted as the paradigm to learn these hybrid targets. However, existing works mainly emphasize investigating the sequential dependence among discrete conversion actions, which neglects the complexity of dependence between discrete conversions and the final continuous conversion. Moreover, simultaneously optimizing hybrid tasks with stronger task dependence will suffer from volatile issues where the core regression task might have a larger influence on other tasks. In this paper, we study the MTL problem with hybrid targets f
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#38750;&#33258;&#22238;&#24402;&#30340;&#29983;&#25104;&#27169;&#22411;&#29992;&#20110;&#25490;&#24207;&#25512;&#33616;&#65292;&#22312;&#22810;&#38454;&#27573;&#25512;&#33616;&#31995;&#32479;&#20013;&#25198;&#28436;&#20851;&#38190;&#35282;&#33394;&#12290;&#35813;&#27169;&#22411;&#26088;&#22312;&#25552;&#39640;&#25928;&#29575;&#21644;&#25928;&#26524;&#65292;&#24182;&#35299;&#20915;&#31232;&#30095;&#35757;&#32451;&#26679;&#26412;&#21644;&#21160;&#24577;&#20505;&#36873;&#39033;&#23545;&#27169;&#22411;&#25910;&#25947;&#24615;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.06871</link><description>&lt;p&gt;
&#38750;&#33258;&#22238;&#24402;&#30340;&#29983;&#25104;&#27169;&#22411;&#29992;&#20110;&#25490;&#24207;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Non-autoregressive Generative Models for Reranking Recommendation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06871
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#38750;&#33258;&#22238;&#24402;&#30340;&#29983;&#25104;&#27169;&#22411;&#29992;&#20110;&#25490;&#24207;&#25512;&#33616;&#65292;&#22312;&#22810;&#38454;&#27573;&#25512;&#33616;&#31995;&#32479;&#20013;&#25198;&#28436;&#20851;&#38190;&#35282;&#33394;&#12290;&#35813;&#27169;&#22411;&#26088;&#22312;&#25552;&#39640;&#25928;&#29575;&#21644;&#25928;&#26524;&#65292;&#24182;&#35299;&#20915;&#31232;&#30095;&#35757;&#32451;&#26679;&#26412;&#21644;&#21160;&#24577;&#20505;&#36873;&#39033;&#23545;&#27169;&#22411;&#25910;&#25947;&#24615;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22810;&#38454;&#27573;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#37325;&#26032;&#25490;&#24207;&#36890;&#36807;&#24314;&#27169;&#39033;&#30446;&#20043;&#38388;&#30340;&#20869;&#37096;&#30456;&#20851;&#24615;&#36215;&#21040;&#20102;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#37325;&#26032;&#25490;&#24207;&#30340;&#20851;&#38190;&#25361;&#25112;&#22312;&#20110;&#22312;&#25490;&#21015;&#30340;&#32452;&#21512;&#31354;&#38388;&#20013;&#25506;&#32034;&#26368;&#20339;&#24207;&#21015;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#25552;&#20986;&#20102;&#29983;&#25104;&#22120;-&#35780;&#20272;&#22120;&#23398;&#20064;&#33539;&#24335;&#65292;&#29983;&#25104;&#22120;&#29983;&#25104;&#22810;&#20010;&#21487;&#34892;&#24207;&#21015;&#65292;&#35780;&#20272;&#22120;&#22522;&#20110;&#20272;&#35745;&#30340;&#21015;&#34920;&#24471;&#20998;&#36873;&#25321;&#26368;&#20339;&#24207;&#21015;&#12290;&#29983;&#25104;&#22120;&#33267;&#20851;&#37325;&#35201;&#65292;&#32780;&#29983;&#25104;&#27169;&#22411;&#38750;&#24120;&#36866;&#21512;&#29983;&#25104;&#22120;&#20989;&#25968;&#12290;&#24403;&#21069;&#30340;&#29983;&#25104;&#27169;&#22411;&#37319;&#29992;&#33258;&#22238;&#24402;&#31574;&#30053;&#36827;&#34892;&#24207;&#21015;&#29983;&#25104;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#26102;&#24037;&#19994;&#31995;&#32479;&#20013;&#37096;&#32626;&#33258;&#22238;&#24402;&#27169;&#22411;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#38750;&#33258;&#22238;&#24402;&#29983;&#25104;&#27169;&#22411;&#29992;&#20110;&#25490;&#24207;&#25512;&#33616;&#65288;NAR4Rec&#65289;&#65292;&#20197;&#25552;&#39640;&#25928;&#29575;&#21644;&#25928;&#26524;&#12290;&#20026;&#20102;&#35299;&#20915;&#19982;&#31232;&#30095;&#35757;&#32451;&#26679;&#26412;&#21644;&#21160;&#24577;&#20505;&#36873;&#39033;&#23545;&#27169;&#22411;&#25910;&#25947;&#24615;&#30340;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;m
&lt;/p&gt;
&lt;p&gt;
In a multi-stage recommendation system, reranking plays a crucial role by modeling the intra-list correlations among items.The key challenge of reranking lies in the exploration of optimal sequences within the combinatorial space of permutations. Recent research proposes a generator-evaluator learning paradigm, where the generator generates multiple feasible sequences and the evaluator picks out the best sequence based on the estimated listwise score. Generator is of vital importance, and generative models are well-suited for the generator function. Current generative models employ an autoregressive strategy for sequence generation. However, deploying autoregressive models in real-time industrial systems is challenging. Hence, we propose a Non-AutoRegressive generative model for reranking Recommendation (NAR4Rec) designed to enhance efficiency and effectiveness. To address challenges related to sparse training samples and dynamic candidates impacting model convergence, we introduce a m
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#21019;&#24314;&#26032;&#30340;&#25968;&#25454;&#38598;&#12289;&#35780;&#20272;&#22810;&#35821;&#35328;&#39044;&#35757;&#32451;Transformer&#27169;&#22411;&#20197;&#21450;&#25552;&#20986;&#22810;&#38454;&#27573;&#26694;&#26550;&#26469;&#35299;&#20915;&#20102;&#36328;&#35821;&#35328;&#28548;&#28165;&#26816;&#32034;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.05680</link><description>&lt;p&gt;
&#36890;&#36807;&#22810;&#38454;&#27573;&#26816;&#32034;&#25214;&#21040;&#24050;&#32463;&#34987;&#28548;&#28165;&#30340;&#21465;&#36848;&#65306;&#23454;&#29616;&#36328;&#35821;&#35328;&#12289;&#36328;&#25968;&#25454;&#38598;&#21644;&#38646;&#26679;&#26412;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Finding Already Debunked Narratives via Multistage Retrieval: Enabling Cross-Lingual, Cross-Dataset and Zero-Shot Learning. (arXiv:2308.05680v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05680
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#21019;&#24314;&#26032;&#30340;&#25968;&#25454;&#38598;&#12289;&#35780;&#20272;&#22810;&#35821;&#35328;&#39044;&#35757;&#32451;Transformer&#27169;&#22411;&#20197;&#21450;&#25552;&#20986;&#22810;&#38454;&#27573;&#26694;&#26550;&#26469;&#35299;&#20915;&#20102;&#36328;&#35821;&#35328;&#28548;&#28165;&#26816;&#32034;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26816;&#32034;&#24050;&#32463;&#34987;&#28548;&#28165;&#30340;&#21465;&#36848;&#30340;&#20219;&#21153;&#26088;&#22312;&#26816;&#27979;&#24050;&#32463;&#32463;&#36807;&#20107;&#23454;&#26680;&#26597;&#30340;&#25925;&#20107;&#12290;&#25104;&#21151;&#26816;&#27979;&#21040;&#24050;&#34987;&#28548;&#28165;&#30340;&#22768;&#26126;&#19981;&#20165;&#20943;&#23569;&#20102;&#19987;&#19994;&#20107;&#23454;&#26680;&#26597;&#20154;&#21592;&#30340;&#25163;&#21160;&#21162;&#21147;&#65292;&#36824;&#21487;&#20197;&#26377;&#21161;&#20110;&#20943;&#32531;&#34394;&#20551;&#20449;&#24687;&#30340;&#20256;&#25773;&#12290;&#30001;&#20110;&#32570;&#20047;&#21487;&#29992;&#25968;&#25454;&#65292;&#36825;&#26159;&#19968;&#20010;&#30740;&#31350;&#19981;&#36275;&#30340;&#38382;&#39064;&#65292;&#29305;&#21035;&#26159;&#22312;&#32771;&#34385;&#36328;&#35821;&#35328;&#20219;&#21153;&#26102;&#65292;&#21363;&#22312;&#26816;&#26597;&#30340;&#22312;&#32447;&#24086;&#23376;&#30340;&#35821;&#35328;&#19982;&#20107;&#23454;&#26680;&#26597;&#25991;&#31456;&#30340;&#35821;&#35328;&#19981;&#21516;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#26816;&#32034;&#12290;&#26412;&#25991;&#36890;&#36807;&#20197;&#19979;&#26041;&#24335;&#22635;&#34917;&#20102;&#36825;&#19968;&#31354;&#30333;&#65306;&#65288;i&#65289;&#21019;&#24314;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#25968;&#25454;&#38598;&#65292;&#20197;&#20801;&#35768;&#23545;&#24050;&#34987;&#28548;&#28165;&#30340;&#21465;&#36848;&#36827;&#34892;&#36328;&#35821;&#35328;&#26816;&#32034;&#30340;&#30740;&#31350;&#65292;&#20351;&#29992;&#25512;&#25991;&#20316;&#20026;&#23545;&#20107;&#23454;&#26680;&#26597;&#25991;&#31456;&#25968;&#25454;&#24211;&#30340;&#26597;&#35810;&#65307;&#65288;ii&#65289;&#23637;&#31034;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#23454;&#39564;&#65292;&#20197;&#35780;&#20272;&#32463;&#36807;&#24494;&#35843;&#21644;&#29616;&#25104;&#30340;&#22810;&#35821;&#35328;&#39044;&#35757;&#32451;Transformer&#27169;&#22411;&#22312;&#36825;&#20010;&#20219;&#21153;&#19978;&#30340;&#24615;&#33021;&#65307;&#65288;iii&#65289;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#22810;&#38454;&#27573;&#26694;&#26550;&#65292;&#23558;&#36825;&#20010;&#36328;&#35821;&#35328;&#28548;&#28165;&#26816;&#32034;&#38382;&#39064;&#21010;&#20998;&#20026;&#19981;&#21516;&#30340;&#38454;&#27573;&#12290;
&lt;/p&gt;
&lt;p&gt;
The task of retrieving already debunked narratives aims to detect stories that have already been fact-checked. The successful detection of claims that have already been debunked not only reduces the manual efforts of professional fact-checkers but can also contribute to slowing the spread of misinformation. Mainly due to the lack of readily available data, this is an understudied problem, particularly when considering the cross-lingual task, i.e. the retrieval of fact-checking articles in a language different from the language of the online post being checked. This paper fills this gap by (i) creating a novel dataset to enable research on cross-lingual retrieval of already debunked narratives, using tweets as queries to a database of fact-checking articles; (ii) presenting an extensive experiment to benchmark fine-tuned and off-the-shelf multilingual pre-trained Transformer models for this task; and (iii) proposing a novel multistage framework that divides this cross-lingual debunk ret
&lt;/p&gt;</description></item></channel></rss>