<rss version="2.0"><channel><title>Chat Arxiv cs.IR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IR</description><item><title>&#36890;&#36807;&#22312;&#25991;&#26723;&#20013;&#25554;&#20837;&#20010;&#20154;&#23494;&#30721;&#24182;&#35782;&#21035;&#29983;&#25104;&#20869;&#23481;&#20013;&#30340;&#8220;&#24189;&#28789;&#21477;&#23376;&#8221;&#65292;&#26222;&#36890;&#29992;&#25143;&#21487;&#20197;&#30830;&#35748;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#28389;&#29992;&#20854;&#25968;&#25454;&#65292;&#20174;&#32780;&#23454;&#29616;&#25968;&#25454;&#29256;&#26435;&#20445;&#25252;&#12290;</title><link>https://arxiv.org/abs/2403.15740</link><description>&lt;p&gt;
Ghost Sentence&#65306;&#19968;&#31181;&#20379;&#26222;&#36890;&#29992;&#25143;&#20351;&#29992;&#30340;&#24037;&#20855;&#65292;&#29992;&#20110;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#25968;&#25454;&#36827;&#34892;&#29256;&#26435;&#20445;&#25252;
&lt;/p&gt;
&lt;p&gt;
Ghost Sentence: A Tool for Everyday Users to Copyright Data from Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15740
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22312;&#25991;&#26723;&#20013;&#25554;&#20837;&#20010;&#20154;&#23494;&#30721;&#24182;&#35782;&#21035;&#29983;&#25104;&#20869;&#23481;&#20013;&#30340;&#8220;&#24189;&#28789;&#21477;&#23376;&#8221;&#65292;&#26222;&#36890;&#29992;&#25143;&#21487;&#20197;&#30830;&#35748;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#28389;&#29992;&#20854;&#25968;&#25454;&#65292;&#20174;&#32780;&#23454;&#29616;&#25968;&#25454;&#29256;&#26435;&#20445;&#25252;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Web&#29992;&#25143;&#25968;&#25454;&#22312;&#39044;&#35757;&#32451;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#21450;&#20854;&#24494;&#35843;&#21464;&#31181;&#30340;&#29983;&#24577;&#31995;&#32479;&#20013;&#36215;&#30528;&#26680;&#24515;&#20316;&#29992;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#24314;&#35758;&#29992;&#25143;&#22312;&#20854;&#25991;&#26723;&#20013;&#21453;&#22797;&#25554;&#20837;&#20010;&#20154;&#23494;&#30721;&#65292;&#20351;LLMs&#33021;&#22815;&#35760;&#24518;&#36825;&#20123;&#23494;&#30721;&#12290;&#36825;&#20123;&#29992;&#25143;&#25991;&#26723;&#20013;&#38544;&#34255;&#30340;&#23494;&#30721;&#65292;&#34987;&#31216;&#20026;&#8220;&#24189;&#28789;&#21477;&#23376;&#8221;&#65292;&#19968;&#26086;&#23427;&#20204;&#20986;&#29616;&#22312;LLMs&#29983;&#25104;&#30340;&#20869;&#23481;&#20013;&#65292;&#29992;&#25143;&#23601;&#21487;&#20197;&#30830;&#20449;&#20182;&#20204;&#30340;&#25968;&#25454;&#34987;&#29992;&#20110;&#35757;&#32451;&#12290;&#20026;&#20102;&#25506;&#32034;&#36825;&#31181;&#29256;&#26435;&#24037;&#20855;&#30340;&#26377;&#25928;&#24615;&#21644;&#29992;&#27861;&#65292;&#25105;&#20204;&#21033;&#29992;&#24189;&#28789;&#21477;&#23376;&#23450;&#20041;&#20102;&#8220;&#29992;&#25143;&#35757;&#32451;&#25968;&#25454;&#35782;&#21035;&#8221;&#20219;&#21153;&#12290;&#25105;&#20204;&#21019;&#24314;&#20102;&#26469;&#33258;&#19981;&#21516;&#26469;&#28304;&#12289;&#19981;&#21516;&#35268;&#27169;&#30340;&#22810;&#20010;&#25968;&#25454;&#38598;&#65292;&#24182;&#20351;&#29992;&#19981;&#21516;&#35268;&#27169;&#30340;LLMs&#36827;&#34892;&#27979;&#35797;&#12290;&#20026;&#20102;&#35780;&#20272;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26368;&#21518;$k$&#20010;&#21333;&#35789;&#39564;&#35777;&#30340;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15740v1 Announce Type: new  Abstract: Web user data plays a central role in the ecosystem of pre-trained large language models (LLMs) and their fine-tuned variants. Billions of data are crawled from the web and fed to LLMs. How can \textit{\textbf{everyday web users}} confirm if LLMs misuse their data without permission? In this work, we suggest that users repeatedly insert personal passphrases into their documents, enabling LLMs to memorize them. These concealed passphrases in user documents, referred to as \textit{ghost sentences}, once they are identified in the generated content of LLMs, users can be sure that their data is used for training. To explore the effectiveness and usage of this copyrighting tool, we define the \textit{user training data identification} task with ghost sentences. Multiple datasets from various sources at different scales are created and tested with LLMs of different sizes. For evaluation, we introduce a last $k$ words verification manner along 
&lt;/p&gt;</description></item><item><title>PK-ICR&#26159;&#19968;&#31181;&#22522;&#20110;&#35282;&#33394;&#21644;&#30693;&#35782;&#30340;&#20114;&#21160;&#19978;&#19979;&#25991;&#26816;&#32034;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#22797;&#26434;&#30340;&#22810;&#22330;&#26223;&#23545;&#35805;&#20013;&#21516;&#26102;&#35782;&#21035;&#35282;&#33394;&#21644;&#30693;&#35782;&#12290;&#36890;&#36807;&#21033;&#29992;&#31070;&#32463;&#38382;&#31572;&#26816;&#32034;&#27169;&#22411;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#22312;&#36739;&#23569;&#30340;&#35745;&#31639;&#36164;&#28304;&#19979;&#23454;&#29616;&#26816;&#32034;&#65292;&#24182;&#19988;&#36890;&#36807;&#24341;&#20837;&#31354;-&#27491;&#21521;&#25490;&#21517;&#27979;&#35797;&#26041;&#27861;&#26469;&#25552;&#39640;&#25490;&#21517;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2302.06674</link><description>&lt;p&gt;
PK-ICR: &#22522;&#20110;&#35282;&#33394;&#21644;&#30693;&#35782;&#30340;&#20114;&#21160;&#19978;&#19979;&#25991;&#26816;&#32034;&#36827;&#34892;&#22522;&#20110;&#22330;&#26223;&#23545;&#35805;
&lt;/p&gt;
&lt;p&gt;
PK-ICR: Persona-Knowledge Interactive Context Retrieval for Grounded Dialogue. (arXiv:2302.06674v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.06674
&lt;/p&gt;
&lt;p&gt;
PK-ICR&#26159;&#19968;&#31181;&#22522;&#20110;&#35282;&#33394;&#21644;&#30693;&#35782;&#30340;&#20114;&#21160;&#19978;&#19979;&#25991;&#26816;&#32034;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#22797;&#26434;&#30340;&#22810;&#22330;&#26223;&#23545;&#35805;&#20013;&#21516;&#26102;&#35782;&#21035;&#35282;&#33394;&#21644;&#30693;&#35782;&#12290;&#36890;&#36807;&#21033;&#29992;&#31070;&#32463;&#38382;&#31572;&#26816;&#32034;&#27169;&#22411;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#22312;&#36739;&#23569;&#30340;&#35745;&#31639;&#36164;&#28304;&#19979;&#23454;&#29616;&#26816;&#32034;&#65292;&#24182;&#19988;&#36890;&#36807;&#24341;&#20837;&#31354;-&#27491;&#21521;&#25490;&#21517;&#27979;&#35797;&#26041;&#27861;&#26469;&#25552;&#39640;&#25490;&#21517;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#21035;&#19982;&#23545;&#35805;&#31995;&#32479;&#30456;&#20851;&#30340;&#35282;&#33394;&#21644;&#30693;&#35782;&#23545;&#20110;&#22522;&#20110;&#22330;&#26223;&#30340;&#23545;&#35805;&#24212;&#31572;&#29983;&#25104;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#27599;&#20010;&#23545;&#35805;&#22522;&#26412;&#19978;&#37117;&#26159;&#23396;&#31435;&#30740;&#31350;&#30340;&#65292;&#32780;&#26368;&#36817;&#30340;&#24037;&#20316;&#20013;&#24341;&#20837;&#20102;&#26356;&#23454;&#38469;&#30340;&#22810;&#22330;&#26223;&#23545;&#35805;&#20219;&#21153;&#12290;&#25105;&#20204;&#23558;&#35282;&#33394;&#21644;&#30693;&#35782;&#21452;&#19978;&#19979;&#25991;&#35782;&#21035;&#23450;&#20041;&#20026;&#20026;&#32473;&#23450;&#30340;&#23545;&#35805;&#21516;&#26102;&#35782;&#21035;&#35282;&#33394;&#21644;&#30693;&#35782;&#30340;&#20219;&#21153;&#65292;&#22312;&#22797;&#26434;&#30340;&#22810;&#22330;&#26223;&#23545;&#35805;&#35774;&#32622;&#20013;&#21487;&#33021;&#20855;&#26377;&#25552;&#21319;&#37325;&#35201;&#24615;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#26816;&#32034;&#30340;&#26816;&#32034;&#26041;&#27861;&#65292;&#21487;&#20197;&#21516;&#26102;&#21033;&#29992;&#23545;&#35805;&#30340;&#25152;&#26377;&#19978;&#19979;&#25991;&#20449;&#24687;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#20351;&#29992;&#31070;&#32463;&#38382;&#31572;&#26816;&#32034;&#27169;&#22411;&#65292;&#38656;&#35201;&#36739;&#23569;&#30340;&#35745;&#31639;&#36164;&#28304;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#31354;-&#27491;&#21521;&#25490;&#21517;&#27979;&#35797;&#26041;&#27861;&#65292;&#29992;&#20110;&#34913;&#37327;&#19982;&#25968;&#25454;&#22686;&#24378;&#30456;&#20851;&#30340;&#35821;&#20041;&#24046;&#24322;&#26679;&#26412;&#65288;&#21363;&#22256;&#38590;&#36127;&#26679;&#26412;&#65289;&#30340;&#25490;&#21517;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Identifying relevant persona or knowledge for conversational systems is critical to grounded dialogue response generation. However, each grounding has been mostly researched in isolation with more practical multi-context dialogue tasks introduced in recent works. We define Persona and Knowledge Dual Context Identification as the task to identify persona and knowledge jointly for a given dialogue, which could be of elevated importance in complex multi-context dialogue settings. We develop a novel grounding retrieval method that utilizes all contexts of dialogue simultaneously. Our method requires less computational power via utilizing neural QA retrieval models. We further introduce our novel null-positive rank test which measures ranking performance on semantically dissimilar samples (i.e. hard negatives) in relation to data augmentation.
&lt;/p&gt;</description></item></channel></rss>