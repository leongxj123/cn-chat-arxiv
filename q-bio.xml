<rss version="2.0"><channel><title>Chat Arxiv q-bio</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for q-bio</description><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#22270;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#21644;&#23545;&#27604;&#23398;&#20064;&#35299;&#24320;&#31070;&#32463;&#31995;&#32479;&#30142;&#30149;&#20013;&#28023;&#39532;&#24418;&#29366;&#21464;&#24322;&#30340;&#20851;&#38190;&#28508;&#21464;&#37327;&#65292;&#36229;&#36234;&#20102;&#20854;&#20182;&#20808;&#36827;&#26041;&#27861;&#22312;&#35299;&#24320;&#33021;&#21147;&#19978;&#30340;&#34920;&#29616;&#12290;</title><link>https://arxiv.org/abs/2404.00785</link><description>&lt;p&gt;
&#35299;&#24320;&#28023;&#39532;&#24418;&#29366;&#21464;&#24322;&#20043;&#35868;&#65306;&#21033;&#29992;&#23545;&#27604;&#23398;&#20064;&#30340;&#22270;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#30740;&#31350;&#31070;&#32463;&#31995;&#32479;&#30142;&#30149;
&lt;/p&gt;
&lt;p&gt;
Disentangling Hippocampal Shape Variations: A Study of Neurological Disorders Using Graph Variational Autoencoder with Contrastive Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00785
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#22270;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#21644;&#23545;&#27604;&#23398;&#20064;&#35299;&#24320;&#31070;&#32463;&#31995;&#32479;&#30142;&#30149;&#20013;&#28023;&#39532;&#24418;&#29366;&#21464;&#24322;&#30340;&#20851;&#38190;&#28508;&#21464;&#37327;&#65292;&#36229;&#36234;&#20102;&#20854;&#20182;&#20808;&#36827;&#26041;&#27861;&#22312;&#35299;&#24320;&#33021;&#21147;&#19978;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#39033;&#32508;&#21512;&#30740;&#31350;&#65292;&#19987;&#27880;&#20110;&#22312;&#31070;&#32463;&#31995;&#32479;&#30142;&#30149;&#32972;&#26223;&#19979;&#20174;&#25193;&#25955;&#24352;&#37327;&#25104;&#20687;&#65288;DTI&#65289;&#25968;&#25454;&#38598;&#20013;&#35299;&#24320;&#28023;&#39532;&#24418;&#29366;&#21464;&#24322;&#12290;&#20511;&#21161;&#22686;&#24378;&#30340;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#22270;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26088;&#22312;&#36890;&#36807;&#21306;&#20998;&#20195;&#34920;&#24180;&#40836;&#21644;&#26159;&#21542;&#24739;&#30149;&#30340;&#20004;&#20010;&#19981;&#21516;&#28508;&#21464;&#37327;&#26469;&#25552;&#39640;&#35299;&#37322;&#24615;&#12290;&#22312;&#25105;&#20204;&#30340;&#28040;&#34701;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#19968;&#31995;&#21015;VAE&#26550;&#26500;&#21644;&#23545;&#27604;&#25439;&#22833;&#20989;&#25968;&#65292;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#22686;&#24378;&#30340;&#35299;&#24320;&#33021;&#21147;&#12290;&#36825;&#20010;&#35780;&#20272;&#20351;&#29992;&#20102;&#26469;&#33258;DTI&#28023;&#39532;&#25968;&#25454;&#38598;&#30340;&#21512;&#25104;3D&#29615;&#24418;&#32593;&#26684;&#25968;&#25454;&#21644;&#30495;&#23454;&#30340;3D&#28023;&#39532;&#32593;&#26684;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#30340;&#30417;&#30563;&#35299;&#24320;&#27169;&#22411;&#22312;&#35299;&#24320;&#20998;&#25968;&#26041;&#38754;&#20248;&#20110;&#20960;&#31181;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#65292;&#22914;&#23646;&#24615;&#21644;&#24341;&#23548;VAE&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#21487;&#20197;&#21306;&#20998;&#19981;&#21516;&#24180;&#40836;&#32452;&#21644;&#30142;&#30149;&#29366;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00785v1 Announce Type: cross  Abstract: This paper presents a comprehensive study focused on disentangling hippocampal shape variations from diffusion tensor imaging (DTI) datasets within the context of neurological disorders. Leveraging a Graph Variational Autoencoder (VAE) enhanced with Supervised Contrastive Learning, our approach aims to improve interpretability by disentangling two distinct latent variables corresponding to age and the presence of diseases. In our ablation study, we investigate a range of VAE architectures and contrastive loss functions, showcasing the enhanced disentanglement capabilities of our approach. This evaluation uses synthetic 3D torus mesh data and real 3D hippocampal mesh datasets derived from the DTI hippocampal dataset. Our supervised disentanglement model outperforms several state-of-the-art (SOTA) methods like attribute and guided VAEs in terms of disentanglement scores. Our model distinguishes between age groups and disease status in pa
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#36895;&#35745;&#31639;&#19981;&#21487;&#32422;&#34920;&#31034;&#24352;&#37327;&#31215;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#31561;&#21464;&#25805;&#20316;&#22522;&#30784;&#20174;&#29699;&#24418;&#35856;&#27874;&#25913;&#21464;&#20026;2D&#20613;&#31435;&#21494;&#22522;&#30784;&#65292;&#23454;&#29616;&#20102;&#23545;E(3)&#32676;&#30340;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#30340;&#39640;&#25928;&#24314;&#27169;&#12290;</title><link>http://arxiv.org/abs/2401.10216</link><description>&lt;p&gt;
&#36890;&#36807;Gaunt&#24352;&#37327;&#31215;&#22312;&#20613;&#37324;&#21494;&#22522;&#30784;&#19978;&#23454;&#29616;&#39640;&#25928;&#30340;&#31561;&#21464;&#25805;&#20316;
&lt;/p&gt;
&lt;p&gt;
Enabling Efficient Equivariant Operations in the Fourier Basis via Gaunt Tensor Products. (arXiv:2401.10216v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10216
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#36895;&#35745;&#31639;&#19981;&#21487;&#32422;&#34920;&#31034;&#24352;&#37327;&#31215;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#31561;&#21464;&#25805;&#20316;&#22522;&#30784;&#20174;&#29699;&#24418;&#35856;&#27874;&#25913;&#21464;&#20026;2D&#20613;&#31435;&#21494;&#22522;&#30784;&#65292;&#23454;&#29616;&#20102;&#23545;E(3)&#32676;&#30340;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#30340;&#39640;&#25928;&#24314;&#27169;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24314;&#27169;&#29616;&#23454;&#19990;&#30028;&#24212;&#29992;&#20013;&#30340;3D&#25968;&#25454;&#26102;&#65292;&#21457;&#23637;E(3)&#32676;&#30340;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#36215;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#23454;&#29616;&#36825;&#31181;&#31561;&#21464;&#24615;&#20027;&#35201;&#28041;&#21450;&#21040;&#19981;&#21487;&#32422;&#34920;&#31034;&#65288;irreps&#65289;&#30340;&#24352;&#37327;&#31215;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#20351;&#29992;&#39640;&#38454;&#24352;&#37327;&#65292;&#36825;&#20123;&#25805;&#20316;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#26174;&#33879;&#22686;&#21152;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31995;&#32479;&#30340;&#26041;&#27861;&#26469;&#22823;&#22823;&#21152;&#36895;&#19981;&#21487;&#32422;&#34920;&#31034;&#30340;&#24352;&#37327;&#31215;&#30340;&#35745;&#31639;&#12290;&#25105;&#20204;&#23558;&#24120;&#29992;&#30340;Clebsch-Gordan&#31995;&#25968;&#19982;Gaunt&#31995;&#25968;&#36827;&#34892;&#20102;&#25968;&#23398;&#19978;&#30340;&#36830;&#25509;&#65292;Gaunt&#31995;&#25968;&#26159;&#19977;&#20010;&#29699;&#24418;&#35856;&#27874;&#20056;&#31215;&#30340;&#31215;&#20998;&#12290;&#36890;&#36807;Gaunt&#31995;&#25968;&#65292;&#19981;&#21487;&#32422;&#34920;&#31034;&#30340;&#24352;&#37327;&#31215;&#31561;&#20215;&#20110;&#30001;&#29699;&#24418;&#35856;&#27874;&#34920;&#31034;&#30340;&#29699;&#24418;&#20989;&#25968;&#20043;&#38388;&#30340;&#20056;&#27861;&#12290;&#36825;&#31181;&#35266;&#28857;&#36827;&#19968;&#27493;&#20351;&#25105;&#20204;&#33021;&#22815;&#23558;&#31561;&#21464;&#25805;&#20316;&#30340;&#22522;&#30784;&#20174;&#29699;&#24418;&#35856;&#27874;&#25913;&#21464;&#20026;2D&#20613;&#31435;&#21494;&#22522;&#30784;&#12290;&#22240;&#27492;&#65292;&#29699;&#24418;&#20989;&#25968;&#20043;&#38388;&#30340;&#20056;&#27861;&#21487;&#20197;&#22312;&#20613;&#31435;&#21494;&#22522;&#30784;&#19978;&#36827;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;
Developing equivariant neural networks for the E(3) group plays an important role in modeling 3D data across real-world applications. Enforcing this equivariance primarily involves the tensor products of irreducible representations (irreps). However, the computational complexity of such operations increases significantly as higher-order tensors are used. In this work, we propose a systematic approach to substantially accelerate the computation of the tensor products of irreps. We mathematically connect the commonly used Clebsch-Gordan coefficients to the Gaunt coefficients, which are integrals of products of three spherical harmonics. Through Gaunt coefficients, the tensor product of irreps becomes equivalent to the multiplication between spherical functions represented by spherical harmonics. This perspective further allows us to change the basis for the equivariant operations from spherical harmonics to a 2D Fourier basis. Consequently, the multiplication between spherical functions 
&lt;/p&gt;</description></item></channel></rss>