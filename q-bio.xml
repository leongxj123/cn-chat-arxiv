<rss version="2.0"><channel><title>Chat Arxiv q-bio</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for q-bio</description><item><title>&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#22810;&#24847;&#22270;&#36870;Q&#23398;&#20064;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#22312;&#25512;&#26029;&#31163;&#25955;&#26102;&#21464;&#22870;&#21169;&#26102;&#30340;&#25361;&#25112;&#12290;&#36890;&#36807;&#32858;&#31867;&#35266;&#23519;&#21040;&#30340;&#19987;&#23478;&#36712;&#36857;&#24182;&#29420;&#31435;&#35299;&#20915;&#27599;&#20010;&#24847;&#22270;&#30340;&#36870;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21160;&#29289;&#34892;&#20026;&#39044;&#27979;&#26041;&#38754;&#36229;&#36234;&#20102;&#24403;&#21069;&#30340;&#22522;&#20934;&#65292;&#20135;&#29983;&#20102;&#21487;&#35299;&#37322;&#30340;&#22870;&#21169;&#20989;&#25968;&#12290;</title><link>https://rss.arxiv.org/abs/2311.13870</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#34892;&#20026;&#34920;&#31034;&#30340;&#22810;&#24847;&#22270;&#36870;Q&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Multi-intention Inverse Q-learning for Interpretable Behavior Representation
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2311.13870
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#22810;&#24847;&#22270;&#36870;Q&#23398;&#20064;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#22312;&#25512;&#26029;&#31163;&#25955;&#26102;&#21464;&#22870;&#21169;&#26102;&#30340;&#25361;&#25112;&#12290;&#36890;&#36807;&#32858;&#31867;&#35266;&#23519;&#21040;&#30340;&#19987;&#23478;&#36712;&#36857;&#24182;&#29420;&#31435;&#35299;&#20915;&#27599;&#20010;&#24847;&#22270;&#30340;&#36870;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21160;&#29289;&#34892;&#20026;&#39044;&#27979;&#26041;&#38754;&#36229;&#36234;&#20102;&#24403;&#21069;&#30340;&#22522;&#20934;&#65292;&#20135;&#29983;&#20102;&#21487;&#35299;&#37322;&#30340;&#22870;&#21169;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25512;&#21160;&#20915;&#31574;&#36807;&#31243;&#29702;&#35299;&#26041;&#38754;&#65292;&#36870;&#24378;&#21270;&#23398;&#20064;&#65288;IRL&#65289;&#22312;&#37325;&#26500;&#21160;&#29289;&#22797;&#26434;&#34892;&#20026;&#20013;&#30340;&#22810;&#20010;&#24847;&#22270;&#26041;&#38754;&#35777;&#26126;&#20102;&#20854;&#37325;&#35201;&#24615;&#12290;&#37492;&#20110;&#26368;&#36817;&#21457;&#23637;&#30340;&#36830;&#32493;&#26102;&#38388;&#22810;&#24847;&#22270;IRL&#26694;&#26550;&#65292;&#20154;&#20204;&#19968;&#30452;&#22312;&#30740;&#31350;&#22914;&#20309;&#20351;&#29992;IRL&#25512;&#26029;&#31163;&#25955;&#30340;&#26102;&#21464;&#22870;&#21169;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#28508;&#65288;&#39532;&#23572;&#31185;&#22827;&#65289;&#21464;&#37327;&#36870;Q&#23398;&#20064;&#65288;L(M)V-IQL&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#19987;&#38376;&#29992;&#20110;&#36866;&#24212;&#31163;&#25955;&#20869;&#22312;&#22870;&#21169;&#20989;&#25968;&#30340;IRL&#31639;&#27861;&#12290;&#36890;&#36807;&#21033;&#29992;&#26399;&#26395;&#26368;&#22823;&#21270;&#26041;&#27861;&#65292;&#25105;&#20204;&#23558;&#35266;&#23519;&#21040;&#30340;&#19987;&#23478;&#36712;&#36857;&#32858;&#31867;&#25104;&#19981;&#21516;&#30340;&#24847;&#22270;&#65292;&#24182;&#20026;&#27599;&#20010;&#24847;&#22270;&#29420;&#31435;&#35299;&#20915;IRL&#38382;&#39064;&#12290;&#36890;&#36807;&#27169;&#25311;&#23454;&#39564;&#21644;&#23545;&#19981;&#21516;&#30495;&#23454;&#40736;&#31867;&#34892;&#20026;&#25968;&#25454;&#38598;&#30340;&#24212;&#29992;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21160;&#29289;&#34892;&#20026;&#39044;&#27979;&#26041;&#38754;&#36229;&#36234;&#20102;&#24403;&#21069;&#30340;&#22522;&#20934;&#65292;&#20135;&#29983;&#20102;&#21487;&#35299;&#37322;&#30340;&#22870;&#21169;&#20989;&#25968;&#12290;&#36825;&#19968;&#36827;&#23637;&#26377;&#26395;&#25171;&#24320;&#25512;&#21160;&#31185;&#23398;&#19982;&#24037;&#31243;&#24212;&#29992;&#30340;&#26032;&#26426;&#36935;&#12290;
&lt;/p&gt;
&lt;p&gt;
In advancing the understanding of decision-making processes, Inverse Reinforcement Learning (IRL) have proven instrumental in reconstructing animal's multiple intentions amidst complex behaviors. Given the recent development of a continuous-time multi-intention IRL framework, there has been persistent inquiry into inferring discrete time-varying rewards with IRL. To tackle the challenge, we introduce Latent (Markov) Variable Inverse Q-learning (L(M)V-IQL), a novel class of IRL algorthms tailored for accommodating discrete intrinsic reward functions. Leveraging an Expectation-Maximization approach, we cluster observed expert trajectories into distinct intentions and independently solve the IRL problem for each. Demonstrating the efficacy of L(M)V-IQL through simulated experiments and its application to different real mouse behavior datasets, our approach surpasses current benchmarks in animal behavior prediction, producing interpretable reward functions. This advancement holds promise f
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#22270;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#21644;&#23545;&#27604;&#23398;&#20064;&#35299;&#24320;&#31070;&#32463;&#31995;&#32479;&#30142;&#30149;&#20013;&#28023;&#39532;&#24418;&#29366;&#21464;&#24322;&#30340;&#20851;&#38190;&#28508;&#21464;&#37327;&#65292;&#36229;&#36234;&#20102;&#20854;&#20182;&#20808;&#36827;&#26041;&#27861;&#22312;&#35299;&#24320;&#33021;&#21147;&#19978;&#30340;&#34920;&#29616;&#12290;</title><link>https://arxiv.org/abs/2404.00785</link><description>&lt;p&gt;
&#35299;&#24320;&#28023;&#39532;&#24418;&#29366;&#21464;&#24322;&#20043;&#35868;&#65306;&#21033;&#29992;&#23545;&#27604;&#23398;&#20064;&#30340;&#22270;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#30740;&#31350;&#31070;&#32463;&#31995;&#32479;&#30142;&#30149;
&lt;/p&gt;
&lt;p&gt;
Disentangling Hippocampal Shape Variations: A Study of Neurological Disorders Using Graph Variational Autoencoder with Contrastive Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00785
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#22270;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#21644;&#23545;&#27604;&#23398;&#20064;&#35299;&#24320;&#31070;&#32463;&#31995;&#32479;&#30142;&#30149;&#20013;&#28023;&#39532;&#24418;&#29366;&#21464;&#24322;&#30340;&#20851;&#38190;&#28508;&#21464;&#37327;&#65292;&#36229;&#36234;&#20102;&#20854;&#20182;&#20808;&#36827;&#26041;&#27861;&#22312;&#35299;&#24320;&#33021;&#21147;&#19978;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#39033;&#32508;&#21512;&#30740;&#31350;&#65292;&#19987;&#27880;&#20110;&#22312;&#31070;&#32463;&#31995;&#32479;&#30142;&#30149;&#32972;&#26223;&#19979;&#20174;&#25193;&#25955;&#24352;&#37327;&#25104;&#20687;&#65288;DTI&#65289;&#25968;&#25454;&#38598;&#20013;&#35299;&#24320;&#28023;&#39532;&#24418;&#29366;&#21464;&#24322;&#12290;&#20511;&#21161;&#22686;&#24378;&#30340;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#22270;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26088;&#22312;&#36890;&#36807;&#21306;&#20998;&#20195;&#34920;&#24180;&#40836;&#21644;&#26159;&#21542;&#24739;&#30149;&#30340;&#20004;&#20010;&#19981;&#21516;&#28508;&#21464;&#37327;&#26469;&#25552;&#39640;&#35299;&#37322;&#24615;&#12290;&#22312;&#25105;&#20204;&#30340;&#28040;&#34701;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#19968;&#31995;&#21015;VAE&#26550;&#26500;&#21644;&#23545;&#27604;&#25439;&#22833;&#20989;&#25968;&#65292;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#22686;&#24378;&#30340;&#35299;&#24320;&#33021;&#21147;&#12290;&#36825;&#20010;&#35780;&#20272;&#20351;&#29992;&#20102;&#26469;&#33258;DTI&#28023;&#39532;&#25968;&#25454;&#38598;&#30340;&#21512;&#25104;3D&#29615;&#24418;&#32593;&#26684;&#25968;&#25454;&#21644;&#30495;&#23454;&#30340;3D&#28023;&#39532;&#32593;&#26684;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#30340;&#30417;&#30563;&#35299;&#24320;&#27169;&#22411;&#22312;&#35299;&#24320;&#20998;&#25968;&#26041;&#38754;&#20248;&#20110;&#20960;&#31181;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#65292;&#22914;&#23646;&#24615;&#21644;&#24341;&#23548;VAE&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#21487;&#20197;&#21306;&#20998;&#19981;&#21516;&#24180;&#40836;&#32452;&#21644;&#30142;&#30149;&#29366;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00785v1 Announce Type: cross  Abstract: This paper presents a comprehensive study focused on disentangling hippocampal shape variations from diffusion tensor imaging (DTI) datasets within the context of neurological disorders. Leveraging a Graph Variational Autoencoder (VAE) enhanced with Supervised Contrastive Learning, our approach aims to improve interpretability by disentangling two distinct latent variables corresponding to age and the presence of diseases. In our ablation study, we investigate a range of VAE architectures and contrastive loss functions, showcasing the enhanced disentanglement capabilities of our approach. This evaluation uses synthetic 3D torus mesh data and real 3D hippocampal mesh datasets derived from the DTI hippocampal dataset. Our supervised disentanglement model outperforms several state-of-the-art (SOTA) methods like attribute and guided VAEs in terms of disentanglement scores. Our model distinguishes between age groups and disease status in pa
&lt;/p&gt;</description></item></channel></rss>