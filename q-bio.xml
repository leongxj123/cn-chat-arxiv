<rss version="2.0"><channel><title>Chat Arxiv q-bio</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for q-bio</description><item><title>&#20351;&#29992;&#22823;&#35821;&#35328;&#27169;&#22411;&#20026;&#38750;&#32534;&#30721;RNA&#25991;&#29486;&#29983;&#25104;&#39640;&#36136;&#37327;&#21644;&#20934;&#30830;&#30340;&#25688;&#35201;&#65292;&#24110;&#21161;&#20943;&#36731;&#29983;&#21629;&#31185;&#23398;&#25991;&#29486;&#25972;&#29702;&#20013;&#32570;&#20047;&#31574;&#23637;&#20154;&#21592;&#26102;&#38388;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2311.03056</link><description>&lt;p&gt;
LitSumm&#65306;&#22823;&#35821;&#35328;&#27169;&#22411;&#29992;&#20110;&#38750;&#32534;&#30721;RNA&#25991;&#29486;&#25688;&#35201;
&lt;/p&gt;
&lt;p&gt;
LitSumm: Large language models for literature summarisation of non-coding RNAs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.03056
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#22823;&#35821;&#35328;&#27169;&#22411;&#20026;&#38750;&#32534;&#30721;RNA&#25991;&#29486;&#29983;&#25104;&#39640;&#36136;&#37327;&#21644;&#20934;&#30830;&#30340;&#25688;&#35201;&#65292;&#24110;&#21161;&#20943;&#36731;&#29983;&#21629;&#31185;&#23398;&#25991;&#29486;&#25972;&#29702;&#20013;&#32570;&#20047;&#31574;&#23637;&#20154;&#21592;&#26102;&#38388;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Motivation: &#22312;&#29983;&#21629;&#31185;&#23398;&#25991;&#29486;&#30340;&#25972;&#29702;&#24037;&#20316;&#20013;&#65292;&#38754;&#20020;&#30528;&#26085;&#30410;&#20005;&#23803;&#30340;&#25361;&#25112;&#12290;&#38543;&#30528;&#21457;&#24067;&#36895;&#24230;&#30340;&#25345;&#32493;&#22686;&#21152;&#65292;&#20877;&#21152;&#19978;&#20840;&#29699;&#22266;&#23450;&#25968;&#37327;&#30340;&#31574;&#23637;&#20154;&#21592;&#65292;&#24320;&#21457;&#29983;&#29289;&#21307;&#23398;&#30693;&#35782;&#24211;&#38754;&#20020;&#37325;&#22823;&#25361;&#25112;&#12290;&#24456;&#23569;&#26377;&#30693;&#35782;&#24211;&#26377;&#36164;&#28304;&#21487;&#20197;&#25193;&#23637;&#21040;&#25152;&#26377;&#30456;&#20851;&#25991;&#29486;&#65292;&#32780;&#25152;&#26377;&#30693;&#35782;&#24211;&#37117;&#24517;&#39035;&#20248;&#20808;&#32771;&#34385;&#33258;&#24049;&#30340;&#21162;&#21147;&#12290; &#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20026;&#38750;&#32534;&#30721;RNA&#29983;&#25104;&#25991;&#29486;&#25688;&#35201;&#65292;&#39318;&#27425;&#20943;&#36731;&#20102;RNA&#31185;&#23398;&#20013;&#32570;&#20047;&#31574;&#23637;&#20154;&#21592;&#26102;&#38388;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#21487;&#20197;&#20351;&#29992;&#21830;&#19994;LLM&#21644;&#19968;&#31995;&#21015;&#25552;&#31034;&#21644;&#26816;&#26597;&#20174;&#25991;&#29486;&#20013;&#33258;&#21160;&#29983;&#25104;&#39640;&#36136;&#37327;&#12289;&#20107;&#23454;&#20934;&#30830;&#30340;&#25688;&#35201;&#21450;&#20934;&#30830;&#30340;&#24341;&#29992;&#12290;&#20154;&#24037;&#35780;&#20272;&#38024;&#23545;&#25688;&#35201;&#23376;&#38598;&#36827;&#34892;&#65292;&#20854;&#20013;&#22823;&#22810;&#25968;&#34987;&#35780;&#20026;&#38750;&#24120;&#39640;&#36136;&#37327;&#12290;&#25105;&#20204;&#36824;&#24212;&#29992;&#20102;&#26368;&#24120;&#29992;&#30340;&#33258;&#21160;&#21270;e
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.03056v2 Announce Type: replace-cross  Abstract: Motivation: Curation of literature in life sciences is a growing challenge. The continued increase in the rate of publication, coupled with the relatively fixed number of curators worldwide presents a major challenge to developers of biomedical knowledgebases. Very few knowledgebases have resources to scale to the whole relevant literature and all have to prioritise their efforts.   Results: In this work, we take a first step to alleviating the lack of curator time in RNA science by generating summaries of literature for non-coding RNAs using large language models (LLMs). We demonstrate that high-quality, factually accurate summaries with accurate references can be automatically generated from the literature using a commercial LLM and a chain of prompts and checks. Manual assessment was carried out for a subset of summaries, with the majority being rated extremely high quality. We also applied the most commonly used automated e
&lt;/p&gt;</description></item></channel></rss>