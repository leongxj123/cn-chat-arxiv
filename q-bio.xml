<rss version="2.0"><channel><title>Chat Arxiv q-bio</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for q-bio</description><item><title>&#36890;&#36807;&#39044;&#27979;&#21512;&#25104;&#26102;&#38388;&#24207;&#21015;&#30340;&#39057;&#29575;&#20869;&#23481;&#36827;&#34892;&#39044;&#35757;&#32451;&#65292;&#23454;&#29616;&#20102;&#22312;&#26377;&#38480;&#25968;&#25454;&#21644;&#23569;&#21463;&#35797;&#32773;&#24773;&#20917;&#19979;&#36229;&#36234;&#23436;&#20840;&#30417;&#30563;&#23398;&#20064;&#30340;&#26041;&#27861;</title><link>https://arxiv.org/abs/2403.08592</link><description>&lt;p&gt;
&#29992;&#21512;&#25104;&#26102;&#38388;&#24207;&#21015;&#39044;&#35757;&#32451;&#23454;&#29616;&#39640;&#25928;&#30340;&#30561;&#30496;&#20998;&#26399;
&lt;/p&gt;
&lt;p&gt;
Data-Efficient Sleep Staging with Synthetic Time Series Pretraining
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08592
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#39044;&#27979;&#21512;&#25104;&#26102;&#38388;&#24207;&#21015;&#30340;&#39057;&#29575;&#20869;&#23481;&#36827;&#34892;&#39044;&#35757;&#32451;&#65292;&#23454;&#29616;&#20102;&#22312;&#26377;&#38480;&#25968;&#25454;&#21644;&#23569;&#21463;&#35797;&#32773;&#24773;&#20917;&#19979;&#36229;&#36234;&#23436;&#20840;&#30417;&#30563;&#23398;&#20064;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#26512;&#33041;&#30005;&#22270;&#65288;EEG&#65289;&#26102;&#38388;&#24207;&#21015;&#21487;&#33021;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#29305;&#21035;&#26159;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#30001;&#20110;&#20154;&#31867;&#21463;&#35797;&#32773;&#20043;&#38388;&#30340;&#22823;&#37327;&#21464;&#24322;&#21644;&#36890;&#24120;&#35268;&#27169;&#36739;&#23567;&#30340;&#25968;&#25454;&#38598;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25552;&#20986;&#20102;&#21508;&#31181;&#31574;&#30053;&#65292;&#20363;&#22914;&#33258;&#30417;&#30563;&#23398;&#20064;&#65292;&#20294;&#23427;&#20204;&#36890;&#24120;&#20381;&#36182;&#20110;&#24191;&#27867;&#30340;&#23454;&#35777;&#25968;&#25454;&#38598;&#12290;&#21463;&#35745;&#31639;&#26426;&#35270;&#35273;&#26368;&#26032;&#36827;&#23637;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39044;&#35757;&#32451;&#20219;&#21153;&#65292;&#31216;&#20026;&#8220;&#39057;&#29575;&#39044;&#35757;&#32451;&#8221;&#65292;&#36890;&#36807;&#39044;&#27979;&#38543;&#26426;&#29983;&#25104;&#30340;&#21512;&#25104;&#26102;&#38388;&#24207;&#21015;&#30340;&#39057;&#29575;&#20869;&#23481;&#26469;&#20026;&#30561;&#30496;&#20998;&#26399;&#39044;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#26377;&#38480;&#25968;&#25454;&#21644;&#23569;&#21463;&#35797;&#32773;&#30340;&#24773;&#20917;&#19979;&#20248;&#20110;&#23436;&#20840;&#30417;&#30563;&#23398;&#20064;&#65292;&#24182;&#22312;&#35768;&#22810;&#21463;&#35797;&#32773;&#30340;&#24773;&#22659;&#20013;&#34920;&#29616;&#30456;&#21305;&#37197;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#24378;&#35843;&#20102;&#39057;&#29575;&#20449;&#24687;&#23545;&#20110;&#30561;&#30496;&#20998;&#26399;&#35780;&#20998;&#30340;&#30456;&#20851;&#24615;&#65292;&#21516;&#26102;&#34920;&#26126;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21033;&#29992;&#20102;&#36229;&#20986;&#39057;&#29575;&#20449;&#24687;&#30340;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08592v1 Announce Type: new  Abstract: Analyzing electroencephalographic (EEG) time series can be challenging, especially with deep neural networks, due to the large variability among human subjects and often small datasets. To address these challenges, various strategies, such as self-supervised learning, have been suggested, but they typically rely on extensive empirical datasets. Inspired by recent advances in computer vision, we propose a pretraining task termed "frequency pretraining" to pretrain a neural network for sleep staging by predicting the frequency content of randomly generated synthetic time series. Our experiments demonstrate that our method surpasses fully supervised learning in scenarios with limited data and few subjects, and matches its performance in regimes with many subjects. Furthermore, our results underline the relevance of frequency information for sleep stage scoring, while also demonstrating that deep neural networks utilize information beyond fr
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#31216;&#20026;&#21152;&#26435;&#28966;&#28857;&#21487;&#24494;MCC&#65292;&#29992;&#20110;&#25913;&#21892;&#20998;&#31867;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#24182;&#22312;&#39044;&#27979;&#21754;&#20083;&#21160;&#29289;&#34507;&#30333;&#36136;&#20013;&#30340;O-GlcNAcylation&#20301;&#28857;&#26041;&#38754;&#21462;&#24471;&#20102;&#36827;&#23637;</title><link>https://arxiv.org/abs/2402.17131</link><description>&lt;p&gt;
&#20351;&#29992;Transformer&#21644;RNN&#22312;&#32463;&#36807;&#35757;&#32451;&#30340;&#26032;&#25439;&#22833;&#20989;&#25968;&#19979;&#39044;&#27979;&#21754;&#20083;&#21160;&#29289;&#34507;&#30333;&#36136;&#20013;&#30340;O-GlcNAcylation&#20301;&#28857;
&lt;/p&gt;
&lt;p&gt;
Predicting O-GlcNAcylation Sites in Mammalian Proteins with Transformers and RNNs Trained with a New Loss Function
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17131
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#31216;&#20026;&#21152;&#26435;&#28966;&#28857;&#21487;&#24494;MCC&#65292;&#29992;&#20110;&#25913;&#21892;&#20998;&#31867;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#24182;&#22312;&#39044;&#27979;&#21754;&#20083;&#21160;&#29289;&#34507;&#30333;&#36136;&#20013;&#30340;O-GlcNAcylation&#20301;&#28857;&#26041;&#38754;&#21462;&#24471;&#20102;&#36827;&#23637;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31958;&#22522;&#21270;&#26159;&#19968;&#31181;&#34507;&#30333;&#36136;&#20462;&#39280;&#65292;&#22312;&#21151;&#33021;&#21644;&#32467;&#26500;&#19978;&#36215;&#30528;&#22810;&#31181;&#37325;&#35201;&#20316;&#29992;&#12290;O-GlcNAcylation&#26159;&#31958;&#22522;&#21270;&#30340;&#19968;&#31181;&#20122;&#22411;&#65292;&#26377;&#28508;&#21147;&#25104;&#20026;&#27835;&#30103;&#30340;&#37325;&#35201;&#38774;&#28857;&#65292;&#20294;&#22312;2023&#24180;&#20043;&#21069;&#23578;&#26410;&#26377;&#21487;&#38752;&#39044;&#27979;O-GlcNAcylation&#20301;&#28857;&#30340;&#26041;&#27861;&#65307;2021&#24180;&#30340;&#19968;&#31687;&#35780;&#35770;&#27491;&#30830;&#25351;&#20986;&#24050;&#21457;&#34920;&#30340;&#27169;&#22411;&#19981;&#36275;&#65292;&#24182;&#19988;&#26410;&#33021;&#27867;&#21270;&#12290;&#27492;&#22806;&#65292;&#35768;&#22810;&#27169;&#22411;&#24050;&#19981;&#20877;&#21487;&#29992;&#12290;2023&#24180;&#65292;&#19968;&#31687;&#20855;&#26377;F$_1$&#20998;&#25968;36.17%&#21644;MCC&#20998;&#25968;34.57%&#30340;&#22823;&#22411;&#25968;&#25454;&#38598;&#19978;&#30340;&#26174;&#30528;&#26356;&#22909;&#30340;RNN&#27169;&#22411;&#34987;&#21457;&#34920;&#12290;&#26412;&#25991;&#39318;&#27425;&#35797;&#22270;&#36890;&#36807;Transformer&#32534;&#30721;&#22120;&#25552;&#39640;&#36825;&#20123;&#25351;&#26631;&#12290;&#23613;&#31649;Transformer&#22312;&#35813;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#20854;&#24615;&#33021;&#20173;&#19981;&#21450;&#20808;&#21069;&#21457;&#34920;&#30340;RNN&#12290;&#28982;&#21518;&#25105;&#20204;&#21019;&#24314;&#20102;&#19968;&#31181;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#31216;&#20026;&#21152;&#26435;&#28966;&#28857;&#21487;&#24494;MCC&#65292;&#20197;&#25552;&#39640;&#20998;&#31867;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17131v1 Announce Type: new  Abstract: Glycosylation, a protein modification, has multiple essential functional and structural roles. O-GlcNAcylation, a subtype of glycosylation, has the potential to be an important target for therapeutics, but methods to reliably predict O-GlcNAcylation sites had not been available until 2023; a 2021 review correctly noted that published models were insufficient and failed to generalize. Moreover, many are no longer usable. In 2023, a considerably better RNN model with an F$_1$ score of 36.17% and an MCC of 34.57% on a large dataset was published. This article first sought to improve these metrics using transformer encoders. While transformers displayed high performance on this dataset, their performance was inferior to that of the previously published RNN. We then created a new loss function, which we call the weighted focal differentiable MCC, to improve the performance of classification models. RNN models trained with this new function di
&lt;/p&gt;</description></item></channel></rss>