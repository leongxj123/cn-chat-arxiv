<rss version="2.0"><channel><title>Chat Arxiv q-bio</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for q-bio</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26080;&#30417;&#30563;&#23398;&#20064;&#30340;&#34507;&#30333;&#36136;&#32467;&#26500;&#34920;&#31034;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#20351;&#29992;&#24378;&#22823;&#30340;&#34507;&#30333;&#36136;&#35821;&#35328;&#27169;&#22411;&#21644;&#33258;&#30417;&#30563;&#32467;&#26500;&#32422;&#26463;&#65292;&#36991;&#20813;&#20102;&#30772;&#22351;&#30495;&#23454;&#30340;&#31354;&#38388;&#32467;&#26500;&#34920;&#31034;&#21644;&#26631;&#35760;&#25968;&#25454;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2303.11783</link><description>&lt;p&gt;
&#36731;&#37327;&#32423;&#23545;&#27604;&#34507;&#30333;&#36136;&#32467;&#26500;-&#24207;&#21015;&#21464;&#25442;
&lt;/p&gt;
&lt;p&gt;
Lightweight Contrastive Protein Structure-Sequence Transformation. (arXiv:2303.11783v1 [q-bio.BM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11783
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26080;&#30417;&#30563;&#23398;&#20064;&#30340;&#34507;&#30333;&#36136;&#32467;&#26500;&#34920;&#31034;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#20351;&#29992;&#24378;&#22823;&#30340;&#34507;&#30333;&#36136;&#35821;&#35328;&#27169;&#22411;&#21644;&#33258;&#30417;&#30563;&#32467;&#26500;&#32422;&#26463;&#65292;&#36991;&#20813;&#20102;&#30772;&#22351;&#30495;&#23454;&#30340;&#31354;&#38388;&#32467;&#26500;&#34920;&#31034;&#21644;&#26631;&#35760;&#25968;&#25454;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22823;&#22810;&#25968;&#34507;&#30333;&#36136;&#19979;&#28216;&#24212;&#29992;&#20013;&#65292;&#26080;&#26631;&#31614;&#30340;&#39044;&#35757;&#32451;&#34507;&#30333;&#36136;&#32467;&#26500;&#27169;&#22411;&#26159;&#20851;&#38190;&#22522;&#30784;&#12290;&#20256;&#32479;&#30340;&#32467;&#26500;&#39044;&#35757;&#32451;&#26041;&#27861;&#36981;&#24490;&#25104;&#29087;&#30340;&#33258;&#28982;&#35821;&#35328;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#20363;&#22914;&#21435;&#22122;&#37325;&#26500;&#21644;&#25513;&#30721;&#35821;&#35328;&#24314;&#27169;&#65292;&#20294;&#36890;&#24120;&#20250;&#30772;&#22351;&#30495;&#23454;&#30340;&#31354;&#38388;&#32467;&#26500;&#34920;&#31034;&#12290;&#20854;&#20182;&#24120;&#35265;&#30340;&#39044;&#35757;&#32451;&#26041;&#27861;&#21487;&#33021;&#20250;&#39044;&#27979;&#19968;&#32452;&#22266;&#23450;&#30340;&#39044;&#23450;&#23545;&#35937;&#31867;&#21035;&#65292;&#20854;&#20013;&#21463;&#38480;&#30340;&#30417;&#30563;&#26041;&#24335;&#38480;&#21046;&#20102;&#23427;&#20204;&#30340;&#36890;&#29992;&#24615;&#21644;&#21487;&#29992;&#24615;&#65292;&#22240;&#20026;&#38656;&#35201;&#39069;&#22806;&#30340;&#26631;&#35760;&#25968;&#25454;&#26469;&#25351;&#23450;&#20219;&#20309;&#20854;&#20182;&#30340;&#34507;&#30333;&#36136;&#27010;&#24565;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26080;&#30417;&#30563;&#34507;&#30333;&#36136;&#32467;&#26500;&#34920;&#31034;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#20854;&#20013;&#20351;&#29992;&#24378;&#22823;&#30340;&#34507;&#30333;&#36136;&#35821;&#35328;&#27169;&#22411;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#39318;&#20808;&#24314;&#35758;&#21033;&#29992;&#29616;&#26377;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#36890;&#36807;&#26080;&#30417;&#30563;&#30340;&#23545;&#27604;&#23545;&#40784;&#26469;&#25351;&#23548;&#32467;&#26500;&#27169;&#22411;&#30340;&#23398;&#20064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#30417;&#30563;&#32467;&#26500;&#32422;&#26463;&#65292;&#20197;&#36827;&#19968;&#27493;&#23398;&#20064;&#20869;&#22312;&#30340;&#34507;&#30333;&#36136;&#32467;&#26500;&#34920;&#31034;&#24418;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pretrained protein structure models without labels are crucial foundations for the majority of protein downstream applications. The conventional structure pretraining methods follow the mature natural language pretraining methods such as denoised reconstruction and masked language modeling but usually destroy the real representation of spatial structures. The other common pretraining methods might predict a fixed set of predetermined object categories, where a restricted supervised manner limits their generality and usability as additional labeled data is required to specify any other protein concepts. In this work, we introduce a novel unsupervised protein structure representation pretraining with a robust protein language model. In particular, we first propose to leverage an existing pretrained language model to guide structure model learning through an unsupervised contrastive alignment. In addition, a self-supervised structure constraint is proposed to further learn the intrinsic i
&lt;/p&gt;</description></item></channel></rss>