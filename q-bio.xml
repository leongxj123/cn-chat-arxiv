<rss version="2.0"><channel><title>Chat Arxiv q-bio</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for q-bio</description><item><title>&#26412;&#25991;&#21033;&#29992;&#30524;&#21160;&#36861;&#36394;&#25216;&#26415;&#30740;&#31350;&#20102;&#27597;&#35821;&#20026;&#27721;&#35821;&#30340;&#20154;&#23545;&#35821;&#35328;&#26223;&#35266;&#30340;&#27880;&#24847;&#28857;&#65292;&#21457;&#29616;&#20854;&#20851;&#27880;&#31243;&#24230;&#39640;&#20110;&#19968;&#33324;&#26223;&#35266;&#65292;&#21487;&#33021;&#26159;&#22240;&#20026;&#35821;&#35328;&#26223;&#35266;&#30340;&#20449;&#24687;&#23494;&#24230;&#36739;&#39640;&#12290;</title><link>https://arxiv.org/abs/2312.08906</link><description>&lt;p&gt;
&#20351;&#29992;&#30524;&#21160;&#36861;&#36394;&#30740;&#31350;&#27597;&#35821;&#20026;&#27721;&#35821;&#30340;&#20154;&#23545;&#35821;&#35328;&#26223;&#35266;&#22270;&#20687;&#30340;&#27880;&#24847;&#21147;
&lt;/p&gt;
&lt;p&gt;
Using eye tracking to investigate what native Chinese speakers notice about linguistic landscape images
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.08906
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#30524;&#21160;&#36861;&#36394;&#25216;&#26415;&#30740;&#31350;&#20102;&#27597;&#35821;&#20026;&#27721;&#35821;&#30340;&#20154;&#23545;&#35821;&#35328;&#26223;&#35266;&#30340;&#27880;&#24847;&#28857;&#65292;&#21457;&#29616;&#20854;&#20851;&#27880;&#31243;&#24230;&#39640;&#20110;&#19968;&#33324;&#26223;&#35266;&#65292;&#21487;&#33021;&#26159;&#22240;&#20026;&#35821;&#35328;&#26223;&#35266;&#30340;&#20449;&#24687;&#23494;&#24230;&#36739;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#26223;&#35266;&#26159;&#31038;&#20250;&#35821;&#35328;&#23398;&#30740;&#31350;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#39046;&#22495;&#65292;&#30524;&#21160;&#36861;&#36394;&#25216;&#26415;&#26159;&#24515;&#29702;&#23398;&#30740;&#31350;&#20013;&#24120;&#29992;&#30340;&#25216;&#26415;&#12290;&#22312;&#23545;&#35821;&#35328;&#26223;&#35266;&#30340;&#30740;&#31350;&#20013;&#65292;&#24456;&#23569;&#20351;&#29992;&#30524;&#21160;&#36861;&#36394;&#26469;&#36827;&#34892;&#30740;&#31350;&#12290;&#26412;&#25991;&#21033;&#29992;&#30524;&#21160;&#36861;&#36394;&#25216;&#26415;&#30740;&#31350;&#20102;&#27597;&#35821;&#20026;&#27721;&#35821;&#30340;&#20154;&#23545;&#35821;&#35328;&#26223;&#35266;&#30340;&#23454;&#38469;&#27880;&#24847;&#28857;&#65292;&#24182;&#21457;&#29616;&#22312;&#20957;&#35270;&#26102;&#38388;&#21644;&#20957;&#35270;&#27425;&#25968;&#36825;&#20004;&#20010;&#32500;&#24230;&#19978;&#65292;&#27597;&#35821;&#20026;&#27721;&#35821;&#30340;&#20154;&#23545;&#35821;&#35328;&#26223;&#35266;&#30340;&#20851;&#27880;&#31243;&#24230;&#39640;&#20110;&#19968;&#33324;&#26223;&#35266;&#12290;&#26412;&#25991;&#35748;&#20026;&#36825;&#31181;&#29616;&#35937;&#26159;&#30001;&#20110;&#35821;&#35328;&#26223;&#35266;&#30340;&#20449;&#24687;&#23494;&#24230;&#36739;&#39640;&#12290;&#21516;&#26102;&#65292;&#26412;&#25991;&#36824;&#35752;&#35770;&#20102;&#36825;&#19968;&#29616;&#35937;&#30340;&#20854;&#20182;&#21487;&#33021;&#21407;&#22240;&#12290;
&lt;/p&gt;
&lt;p&gt;
Linguistic landscape is an important field in sociolinguistic research. Eye tracking technology is a common technology in psychological research. There are few cases of using eye movement to study linguistic landscape. This paper uses eye tracking technology to study the actual fixation of the linguistic landscape and finds that in the two dimensions of fixation time and fixation times, the fixation of native Chinese speakers to the linguistic landscape is higher than that of the general landscape. This paper argues that this phenomenon is due to the higher information density of linguistic landscapes. At the same time, the article also discusses other possible reasons for this phenomenon.
&lt;/p&gt;</description></item><item><title>APACE&#26159;&#19968;&#20010;&#23558;AlphaFold2&#21644;&#20808;&#36827;&#35745;&#31639;&#20316;&#20026;&#26381;&#21153;&#30340;&#35745;&#31639;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#29616;&#20195;&#36229;&#32423;&#35745;&#31639;&#29615;&#22659;&#20013;&#21152;&#36895;&#34507;&#30333;&#36136;&#32467;&#26500;&#39044;&#27979;&#20998;&#26512;&#12290;&#30740;&#31350;&#32773;&#22312;Delta&#36229;&#32423;&#35745;&#31639;&#26426;&#20013;&#37096;&#32626;&#20102;APACE&#65292;&#22312;&#20934;&#30830;&#34507;&#30333;&#36136;&#32467;&#26500;&#39044;&#27979;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#24615;&#33021;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2308.07954</link><description>&lt;p&gt;
APACE: AlphaFold2&#21644;&#20808;&#36827;&#35745;&#31639;&#20316;&#20026;&#21152;&#36895;&#29983;&#29289;&#29289;&#29702;&#23398;&#21457;&#29616;&#30340;&#26381;&#21153;
&lt;/p&gt;
&lt;p&gt;
APACE: AlphaFold2 and advanced computing as a service for accelerated discovery in biophysics. (arXiv:2308.07954v1 [q-bio.BM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07954
&lt;/p&gt;
&lt;p&gt;
APACE&#26159;&#19968;&#20010;&#23558;AlphaFold2&#21644;&#20808;&#36827;&#35745;&#31639;&#20316;&#20026;&#26381;&#21153;&#30340;&#35745;&#31639;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#29616;&#20195;&#36229;&#32423;&#35745;&#31639;&#29615;&#22659;&#20013;&#21152;&#36895;&#34507;&#30333;&#36136;&#32467;&#26500;&#39044;&#27979;&#20998;&#26512;&#12290;&#30740;&#31350;&#32773;&#22312;Delta&#36229;&#32423;&#35745;&#31639;&#26426;&#20013;&#37096;&#32626;&#20102;APACE&#65292;&#22312;&#20934;&#30830;&#34507;&#30333;&#36136;&#32467;&#26500;&#39044;&#27979;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#27688;&#22522;&#37240;&#24207;&#21015;&#39044;&#27979;&#34507;&#30333;&#36136;&#30340;3D&#32467;&#26500;&#26159;&#29983;&#29289;&#29289;&#29702;&#23398;&#20013;&#30340;&#19968;&#20010;&#35745;&#31639;&#37325;&#22823;&#25361;&#25112;&#65292;&#23427;&#22312;&#31283;&#20581;&#30340;&#34507;&#30333;&#36136;&#32467;&#26500;&#39044;&#27979;&#31639;&#27861;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#65292;&#20174;&#33647;&#29289;&#21457;&#29616;&#21040;&#22522;&#22240;&#32452;&#35299;&#35835;&#37117;&#31163;&#19981;&#24320;&#36825;&#20010;&#25216;&#26415;&#12290;AI&#27169;&#22411;&#30340;&#20986;&#29616;&#65292;&#27604;&#22914;AlphaFold&#65292;&#27491;&#22312;&#38761;&#26032;&#20381;&#36182;&#31283;&#20581;&#34507;&#30333;&#36136;&#32467;&#26500;&#39044;&#27979;&#31639;&#27861;&#30340;&#24212;&#29992;&#12290;&#20026;&#20102;&#26368;&#22823;&#31243;&#24230;&#22320;&#21457;&#25381;&#36825;&#20123;&#26032;&#22411;AI&#24037;&#20855;&#30340;&#24433;&#21709;&#21147;&#21644;&#26131;&#29992;&#24615;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;APACE&#65292;AlphaFold2&#21644;&#20808;&#36827;&#35745;&#31639;&#20316;&#20026;&#26381;&#21153;&#30340;&#26032;&#22411;&#35745;&#31639;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#33021;&#22815;&#26377;&#25928;&#22320;&#22788;&#29702;&#36825;&#20010;AI&#27169;&#22411;&#21450;&#20854;TB&#32423;&#22823;&#23567;&#30340;&#25968;&#25454;&#24211;&#65292;&#20197;&#22312;&#29616;&#20195;&#36229;&#32423;&#35745;&#31639;&#29615;&#22659;&#20013;&#21152;&#36895;&#34507;&#30333;&#36136;&#32467;&#26500;&#39044;&#27979;&#20998;&#26512;&#12290;&#25105;&#20204;&#23558;APACE&#37096;&#32626;&#22312;Delta&#36229;&#32423;&#35745;&#31639;&#26426;&#20013;&#65292;&#24182;&#20351;&#29992;&#22235;&#20010;&#31034;&#20363;&#34507;&#30333;&#36136;&#65288;6AWO&#65292;6OAN&#65292;7MEZ&#21644;6D6U&#65289;&#26469;&#37327;&#21270;&#20854;&#22312;&#20934;&#30830;&#34507;&#30333;&#36136;&#32467;&#26500;&#39044;&#27979;&#26041;&#38754;&#30340;&#24615;&#33021;&#12290;&#22312;Delta&#30340;50&#20010;&#33410;&#28857;&#19978;&#20998;&#24067;&#20102;&#22810;&#36798;200&#20010;&#21512;&#38598;&#65292;&#30456;&#24403;&#20110;200&#20010;A100 NVIDIA GPU&#65292;&#25105;&#20204;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
The prediction of protein 3D structure from amino acid sequence is a computational grand challenge in biophysics, and plays a key role in robust protein structure prediction algorithms, from drug discovery to genome interpretation. The advent of AI models, such as AlphaFold, is revolutionizing applications that depend on robust protein structure prediction algorithms. To maximize the impact, and ease the usability, of these novel AI tools we introduce APACE, AlphaFold2 and advanced computing as a service, a novel computational framework that effectively handles this AI model and its TB-size database to conduct accelerated protein structure prediction analyses in modern supercomputing environments. We deployed APACE in the Delta supercomputer, and quantified its performance for accurate protein structure predictions using four exemplar proteins: 6AWO, 6OAN, 7MEZ, and 6D6U. Using up to 200 ensembles, distributed across 50 nodes in Delta, equivalent to 200 A100 NVIDIA GPUs, we found that 
&lt;/p&gt;</description></item></channel></rss>