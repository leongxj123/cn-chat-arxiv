<rss version="2.0"><channel><title>Chat Arxiv q-bio</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for q-bio</description><item><title>&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#65292;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#26368;&#22823;&#21270;&#30456;&#21516;&#21050;&#28608;&#19979;&#21508;&#20010;&#20010;&#20307;&#30340;EEG&#34920;&#31034;&#30340;&#30456;&#20284;&#24615;&#65292;&#20197;&#27492;&#23454;&#29616;&#20010;&#20307;&#38388;&#20849;&#20139;&#26102;&#31354;&#33041;&#30005;&#22270;&#34920;&#31034;&#30340;&#23398;&#20064;&#12290;</title><link>https://arxiv.org/abs/2402.14213</link><description>&lt;p&gt;
&#20010;&#20307;&#38388;&#20849;&#20139;&#33041;&#30005;&#22270;&#26102;&#31354;&#34920;&#31034;&#30340;&#23545;&#27604;&#23398;&#20064;&#29992;&#20110;&#33258;&#28982;&#31070;&#32463;&#31185;&#23398;
&lt;/p&gt;
&lt;p&gt;
Contrastive Learning of Shared Spatiotemporal EEG Representations Across Individuals for Naturalistic Neuroscience
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14213
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#65292;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#26368;&#22823;&#21270;&#30456;&#21516;&#21050;&#28608;&#19979;&#21508;&#20010;&#20010;&#20307;&#30340;EEG&#34920;&#31034;&#30340;&#30456;&#20284;&#24615;&#65292;&#20197;&#27492;&#23454;&#29616;&#20010;&#20307;&#38388;&#20849;&#20139;&#26102;&#31354;&#33041;&#30005;&#22270;&#34920;&#31034;&#30340;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#28982;&#21050;&#28608;&#35825;&#23548;&#30340;&#31070;&#32463;&#34920;&#24449;&#25581;&#31034;&#20102;&#20154;&#31867;&#22914;&#20309;&#23545;&#26085;&#24120;&#29983;&#27963;&#20013;&#30340;&#22806;&#22260;&#21050;&#28608;&#20570;&#20986;&#21453;&#24212;&#12290;&#29702;&#35299;&#33258;&#28982;&#21050;&#28608;&#22788;&#29702;&#30340;&#19968;&#33324;&#31070;&#32463;&#26426;&#21046;&#30340;&#20851;&#38190;&#22312;&#20110;&#23545;&#40784;&#21508;&#20010;&#20010;&#20307;&#30340;&#31070;&#32463;&#27963;&#21160;&#24182;&#25552;&#21462;&#20010;&#20307;&#38388;&#30340;&#20849;&#20139;&#31070;&#32463;&#34920;&#24449;&#12290;&#26412;&#30740;&#31350;&#38024;&#23545;&#33041;&#30005;&#22270;&#65288;EEG&#65289;&#25216;&#26415;&#65292;&#35813;&#25216;&#26415;&#20197;&#20854;&#20016;&#23500;&#30340;&#31354;&#38388;&#21644;&#26102;&#38388;&#20449;&#24687;&#32780;&#38395;&#21517;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#20010;&#20307;&#38388;&#20849;&#20139;&#26102;&#31354;&#33041;&#30005;&#22270;&#34920;&#31034;&#30340;&#23545;&#27604;&#23398;&#20064;&#30340;&#36890;&#29992;&#26694;&#26550;&#65288;CL-SSTER&#65289;&#12290;&#21033;&#29992;&#23545;&#27604;&#23398;&#20064;&#30340;&#34920;&#24449;&#33021;&#21147;&#65292;CL-SSTER&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#26368;&#22823;&#21270;&#30456;&#21516;&#21050;&#28608;&#19979;&#21508;&#20010;&#20010;&#20307;&#30340;EEG&#34920;&#31034;&#30340;&#30456;&#20284;&#24615;&#65292;&#19982;&#19981;&#21516;&#21050;&#28608;&#30340;&#30456;&#23545;&#24212;&#12290;&#35813;&#32593;&#32476;&#37319;&#29992;&#31354;&#38388;&#21644;&#26102;&#38388;&#21367;&#31215;&#21516;&#26102;&#23398;&#20064;&#31354;&#38388;&#21644;&#26102;&#38388;&#27169;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14213v1 Announce Type: cross  Abstract: Neural representations induced by naturalistic stimuli offer insights into how humans respond to peripheral stimuli in daily life. The key to understanding the general neural mechanisms underlying naturalistic stimuli processing involves aligning neural activities across individuals and extracting inter-subject shared neural representations. Targeting the Electroencephalogram (EEG) technique, known for its rich spatial and temporal information, this study presents a general framework for Contrastive Learning of Shared SpatioTemporal EEG Representations across individuals (CL-SSTER). Harnessing the representational capabilities of contrastive learning, CL-SSTER utilizes a neural network to maximize the similarity of EEG representations across individuals for identical stimuli, contrasting with those for varied stimuli. The network employed spatial and temporal convolutions to simultaneously learn the spatial and temporal patterns inhere
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#29702;&#35770;&#19978;&#30740;&#31350;&#20102;&#22312;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#20803;&#23398;&#20064;&#26368;&#20248;&#31574;&#30053;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#23398;&#20064;&#21162;&#21147;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#20248;&#21270;&#25511;&#21046;&#20449;&#21495;&#65292;&#20174;&#32780;&#25552;&#21319;&#23398;&#20064;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.19919</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#20013;&#22522;&#20110;&#20215;&#20540;&#26368;&#22823;&#21270;&#30340;&#20803;&#23398;&#20064;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Meta-Learning Strategies through Value Maximization in Neural Networks. (arXiv:2310.19919v1 [cs.NE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19919
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#29702;&#35770;&#19978;&#30740;&#31350;&#20102;&#22312;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#20803;&#23398;&#20064;&#26368;&#20248;&#31574;&#30053;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#23398;&#20064;&#21162;&#21147;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#20248;&#21270;&#25511;&#21046;&#20449;&#21495;&#65292;&#20174;&#32780;&#25552;&#21319;&#23398;&#20064;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#29289;&#21644;&#20154;&#24037;&#23398;&#20064;&#20195;&#29702;&#38754;&#20020;&#35832;&#22810;&#23398;&#20064;&#36873;&#25321;&#65292;&#21253;&#25324;&#36229;&#21442;&#25968;&#36873;&#25321;&#21644;&#20219;&#21153;&#20998;&#24067;&#30340;&#21508;&#20010;&#26041;&#38754;&#65292;&#22914;&#35838;&#31243;&#12290;&#20102;&#35299;&#22914;&#20309;&#36827;&#34892;&#36825;&#20123;&#20803;&#23398;&#20064;&#36873;&#25321;&#21487;&#20197;&#25552;&#20379;&#23545;&#29983;&#29289;&#23398;&#20064;&#32773;&#30340;&#35748;&#30693;&#25511;&#21046;&#21151;&#33021;&#30340;&#35268;&#33539;&#35299;&#37322;&#65292;&#24182;&#25913;&#36827;&#24037;&#31243;&#31995;&#32479;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20248;&#21270;&#25972;&#20010;&#23398;&#20064;&#36807;&#31243;&#30340;&#22797;&#26434;&#24615;&#65292;&#30446;&#21069;&#20173;&#28982;&#25361;&#25112;&#30528;&#35745;&#31639;&#29616;&#20195;&#28145;&#24230;&#32593;&#32476;&#20013;&#30340;&#26368;&#20248;&#31574;&#30053;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#22312;&#19968;&#20010;&#21487;&#22788;&#29702;&#30340;&#29615;&#22659;&#20013;&#20174;&#29702;&#35770;&#19978;&#30740;&#31350;&#26368;&#20248;&#31574;&#30053;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23398;&#20064;&#21162;&#21147;&#30340;&#26694;&#26550;&#65292;&#33021;&#22815;&#22312;&#23436;&#20840;&#35268;&#33539;&#21270;&#30340;&#30446;&#26631;&#19978;&#39640;&#25928;&#22320;&#20248;&#21270;&#25511;&#21046;&#20449;&#21495;&#65306;&#22312;&#23398;&#20064;&#36807;&#31243;&#20013;&#30340;&#25240;&#29616;&#32047;&#31215;&#24615;&#33021;&#12290;&#36890;&#36807;&#20351;&#29992;&#20272;&#35745;&#26799;&#24230;&#19979;&#38477;&#30340;&#24179;&#22343;&#21160;&#21147;&#26041;&#31243;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#35745;&#31639;&#30340;&#21487;&#34892;&#24615;&#65292;&#35813;&#26041;&#31243;&#36866;&#29992;&#20110;&#31616;&#21333;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21253;&#23481;&#20102;&#19968;&#31995;&#21015;&#20803;&#23398;&#20064;&#21644;&#33258;&#21160;&#35838;&#31243;&#23398;&#20064;&#26041;&#27861;&#65292;&#24418;&#25104;&#20102;&#32479;&#19968;&#30340;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
Biological and artificial learning agents face numerous choices about how to learn, ranging from hyperparameter selection to aspects of task distributions like curricula. Understanding how to make these meta-learning choices could offer normative accounts of cognitive control functions in biological learners and improve engineered systems. Yet optimal strategies remain challenging to compute in modern deep networks due to the complexity of optimizing through the entire learning process. Here we theoretically investigate optimal strategies in a tractable setting. We present a learning effort framework capable of efficiently optimizing control signals on a fully normative objective: discounted cumulative performance throughout learning. We obtain computational tractability by using average dynamical equations for gradient descent, available for simple neural network architectures. Our framework accommodates a range of meta-learning and automatic curriculum learning methods in a unified n
&lt;/p&gt;</description></item></channel></rss>