<rss version="2.0"><channel><title>Chat Arxiv q-bio</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for q-bio</description><item><title>&#36890;&#36807;&#30452;&#25509;&#22522;&#20110;&#33021;&#37327;&#20559;&#22909;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#25239;&#21407;&#29305;&#24322;&#24615;&#25239;&#20307;&#35774;&#35745;&#20013;&#30340;&#34507;&#30333;&#36136;&#24207;&#21015;-&#32467;&#26500;&#20849;&#35774;&#35745;&#38382;&#39064;&#65292;&#20197;&#29983;&#25104;&#20855;&#26377;&#29702;&#24615;&#32467;&#26500;&#21644;&#33391;&#22909;&#32467;&#21512;&#20146;&#21644;&#21147;&#30340;&#25239;&#20307;&#35774;&#35745;&#12290;</title><link>https://arxiv.org/abs/2403.16576</link><description>&lt;p&gt;
&#36890;&#36807;&#30452;&#25509;&#22522;&#20110;&#33021;&#37327;&#20559;&#22909;&#20248;&#21270;&#30340;&#25239;&#21407;&#29305;&#24322;&#24615;&#25239;&#20307;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Antigen-Specific Antibody Design via Direct Energy-based Preference Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16576
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#30452;&#25509;&#22522;&#20110;&#33021;&#37327;&#20559;&#22909;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#25239;&#21407;&#29305;&#24322;&#24615;&#25239;&#20307;&#35774;&#35745;&#20013;&#30340;&#34507;&#30333;&#36136;&#24207;&#21015;-&#32467;&#26500;&#20849;&#35774;&#35745;&#38382;&#39064;&#65292;&#20197;&#29983;&#25104;&#20855;&#26377;&#29702;&#24615;&#32467;&#26500;&#21644;&#33391;&#22909;&#32467;&#21512;&#20146;&#21644;&#21147;&#30340;&#25239;&#20307;&#35774;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25239;&#20307;&#35774;&#35745;&#26159;&#19968;&#20010;&#33267;&#20851;&#37325;&#35201;&#30340;&#20219;&#21153;&#65292;&#23545;&#21508;&#31181;&#39046;&#22495;&#37117;&#26377;&#37325;&#35201;&#24433;&#21709;&#65292;&#22914;&#27835;&#30103;&#21644;&#29983;&#29289;&#23398;&#65292;&#30001;&#20110;&#20854;&#38169;&#32508;&#22797;&#26434;&#30340;&#24615;&#36136;&#65292;&#38754;&#20020;&#30528;&#30456;&#24403;&#22823;&#30340;&#25361;&#25112;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#25239;&#21407;&#29305;&#24322;&#24615;&#25239;&#20307;&#35774;&#35745;&#20316;&#20026;&#19968;&#20010;&#34507;&#30333;&#36136;&#24207;&#21015;-&#32467;&#26500;&#20849;&#35774;&#35745;&#38382;&#39064;&#65292;&#32771;&#34385;&#20102;&#29702;&#24615;&#21644;&#21151;&#33021;&#24615;&#12290;&#21033;&#29992;&#19968;&#20010;&#39044;&#20808;&#35757;&#32451;&#30340;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#32852;&#21512;&#24314;&#27169;&#25239;&#20307;&#20013;&#20114;&#34917;&#20915;&#23450;&#21306;&#65288;CDR&#65289;&#30340;&#24207;&#21015;&#21644;&#32467;&#26500;&#65292;&#24182;&#32467;&#21512;&#20102;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#30452;&#25509;&#22522;&#20110;&#33021;&#37327;&#20559;&#22909;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#20197;&#24341;&#23548;&#29983;&#25104;&#26082;&#20855;&#26377;&#21512;&#29702;&#32467;&#26500;&#21448;&#20855;&#26377;&#26126;&#26174;&#32467;&#21512;&#20146;&#21644;&#21147;&#30340;&#25239;&#20307;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#28041;&#21450;&#20351;&#29992;&#27531;&#22522;&#32423;&#20998;&#35299;&#33021;&#37327;&#20559;&#22909;&#23545;&#39044;&#20808;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#37319;&#29992;&#26799;&#24230;&#25163;&#26415;&#26469;&#35299;&#20915;&#21508;&#31181;&#31867;&#22411;&#33021;&#37327;&#20043;&#38388;&#30340;&#20914;&#31361;&#65292;&#20363;&#22914;&#21560;&#24341;&#21644;&#26021;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16576v1 Announce Type: cross  Abstract: Antibody design, a crucial task with significant implications across various disciplines such as therapeutics and biology, presents considerable challenges due to its intricate nature. In this paper, we tackle antigen-specific antibody design as a protein sequence-structure co-design problem, considering both rationality and functionality. Leveraging a pre-trained conditional diffusion model that jointly models sequences and structures of complementarity-determining regions (CDR) in antibodies with equivariant neural networks, we propose direct energy-based preference optimization to guide the generation of antibodies with both rational structures and considerable binding affinities to given antigens. Our method involves fine-tuning the pre-trained diffusion model using a residue-level decomposed energy preference. Additionally, we employ gradient surgery to address conflicts between various types of energy, such as attraction and repu
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#39046;&#22495;&#29305;&#23450;&#32467;&#26500;&#20449;&#24687;&#26469;&#24341;&#23548;&#20462;&#21098;&#30340;&#26041;&#27861; DASH &#22312;&#23398;&#20064;&#21160;&#24577;&#22522;&#22240;&#35843;&#25511;&#32593;&#32476;&#27169;&#22411;&#26102;&#34920;&#29616;&#20986;&#33394;&#65292;&#25552;&#20379;&#20102;&#26356;&#26377;&#24847;&#20041;&#30340;&#29983;&#29289;&#23398;&#35265;&#35299;</title><link>https://arxiv.org/abs/2403.04805</link><description>&lt;p&gt;
&#19981;&#26159;&#25152;&#26377;&#30340;&#31080;&#25454;&#37117;&#26159;&#24179;&#31561;&#30340;&#65292;&#32780;&#25105;&#20204;&#30693;&#36947;&#65306;&#29992;&#39046;&#22495;&#29305;&#23450;&#30693;&#35782;&#26469;&#24341;&#23548;&#20462;&#21098;
&lt;/p&gt;
&lt;p&gt;
Not all tickets are equal and we know it: Guiding pruning with domain-specific knowledge
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04805
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#39046;&#22495;&#29305;&#23450;&#32467;&#26500;&#20449;&#24687;&#26469;&#24341;&#23548;&#20462;&#21098;&#30340;&#26041;&#27861; DASH &#22312;&#23398;&#20064;&#21160;&#24577;&#22522;&#22240;&#35843;&#25511;&#32593;&#32476;&#27169;&#22411;&#26102;&#34920;&#29616;&#20986;&#33394;&#65292;&#25552;&#20379;&#20102;&#26356;&#26377;&#24847;&#20041;&#30340;&#29983;&#29289;&#23398;&#35265;&#35299;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32467;&#26500;&#23398;&#20064;&#23545;&#20110;&#31185;&#23398;&#21457;&#29616;&#21644;&#21487;&#35299;&#37322;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#24403;&#20195;&#20391;&#37325;&#20110;&#35745;&#31639;&#36164;&#28304;&#25928;&#29575;&#30340;&#20462;&#21098;&#31639;&#27861;&#22312;&#36873;&#25321;&#31526;&#21512;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#30340;&#26377;&#24847;&#20041;&#27169;&#22411;&#26041;&#38754;&#38754;&#20020;&#31639;&#27861;&#38556;&#30861;&#12290;&#20026;&#20102;&#20943;&#36731;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;DASH&#65292;&#21033;&#29992;&#21487;&#29992;&#30340;&#39046;&#22495;&#29305;&#23450;&#32467;&#26500;&#20449;&#24687;&#26469;&#24341;&#23548;&#20462;&#21098;&#12290;&#22312;&#23398;&#20064;&#21160;&#24577;&#22522;&#22240;&#35843;&#25511;&#32593;&#32476;&#27169;&#22411;&#30340;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;DASH&#19982;&#29616;&#26377;&#19968;&#33324;&#30693;&#35782;&#30456;&#32467;&#21512;&#65292;&#25552;&#20379;&#20102;&#19982;&#29983;&#29289;&#23398;&#19968;&#33268;&#30340;&#25968;&#25454;&#29305;&#23450;&#35265;&#35299;&#12290;&#23545;&#20110;&#36825;&#19968;&#20219;&#21153;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#20855;&#26377;&#22320;&#38754;&#30495;&#23454;&#20449;&#24687;&#30340;&#21512;&#25104;&#25968;&#25454;&#21644;&#20004;&#20010;&#30495;&#23454;&#19990;&#30028;&#24212;&#29992;&#20013;&#65292;DASH&#30340;&#26377;&#25928;&#24615;&#65292;&#20854;&#20248;&#20110;&#31454;&#20105;&#26041;&#27861;&#24456;&#22823;&#65292;&#24182;&#25552;&#20379;&#20102;&#26356;&#26377;&#24847;&#20041;&#30340;&#29983;&#29289;&#23398;&#35265;&#35299;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#34920;&#26126;&#65292;&#39046;&#22495;&#29305;&#23450;&#30340;&#32467;&#26500;&#20449;&#24687;&#20855;&#26377;&#25552;&#39640;&#27169;&#22411;&#34893;&#29983;&#31185;&#23398;&#27934;&#35265;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04805v1 Announce Type: new  Abstract: Neural structure learning is of paramount importance for scientific discovery and interpretability. Yet, contemporary pruning algorithms that focus on computational resource efficiency face algorithmic barriers to select a meaningful model that aligns with domain expertise. To mitigate this challenge, we propose DASH, which guides pruning by available domain-specific structural information. In the context of learning dynamic gene regulatory network models, we show that DASH combined with existing general knowledge on interaction partners provides data-specific insights aligned with biology. For this task, we show on synthetic data with ground truth information and two real world applications the effectiveness of DASH, which outperforms competing methods by a large margin and provides more meaningful biological insights. Our work shows that domain specific structural information bears the potential to improve model-derived scientific insi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;BrainRGIN&#24314;&#27169;&#26550;&#26500;&#65292;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#26469;&#39044;&#27979;&#26234;&#21147;&#65292;&#25193;&#23637;&#20102;&#29616;&#26377;&#30340;&#22270;&#21367;&#31215;&#32593;&#32476;&#24182;&#32467;&#21512;&#20102;&#32858;&#31867;&#23884;&#20837;&#12289;&#22270;&#21516;&#26500;&#32593;&#32476;&#12289;TopK&#27744;&#21270;&#21644;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#35835;&#20986;&#20989;&#25968;&#12290;</title><link>https://arxiv.org/abs/2311.03520</link><description>&lt;p&gt;
&#22823;&#33041;&#32593;&#32476;&#19982;&#26234;&#21147;&#65306;&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#38745;&#24687;&#24577;fMRI&#25968;&#25454;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Brain Networks and Intelligence: A Graph Neural Network Based Approach to Resting State fMRI Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.03520
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;BrainRGIN&#24314;&#27169;&#26550;&#26500;&#65292;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#26469;&#39044;&#27979;&#26234;&#21147;&#65292;&#25193;&#23637;&#20102;&#29616;&#26377;&#30340;&#22270;&#21367;&#31215;&#32593;&#32476;&#24182;&#32467;&#21512;&#20102;&#32858;&#31867;&#23884;&#20837;&#12289;&#22270;&#21516;&#26500;&#32593;&#32476;&#12289;TopK&#27744;&#21270;&#21644;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#35835;&#20986;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38745;&#24687;&#24577;&#21151;&#33021;&#30913;&#20849;&#25391;&#25104;&#20687;&#65288;rsfMRI&#65289;&#26159;&#19968;&#31181;&#30740;&#31350;&#22823;&#33041;&#21151;&#33021;&#21644;&#35748;&#30693;&#36807;&#31243;&#20851;&#31995;&#30340;&#24378;&#22823;&#24037;&#20855;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#25429;&#33719;&#22823;&#33041;&#30340;&#21151;&#33021;&#32452;&#32455;&#65292;&#32780;&#26080;&#38656;&#20381;&#36182;&#20110;&#29305;&#23450;&#20219;&#21153;&#25110;&#21050;&#28608;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;BrainRGIN&#30340;&#26032;&#39062;&#24314;&#27169;&#26550;&#26500;&#65292;&#21033;&#29992;rsfMRI&#25512;&#23548;&#30340;&#38745;&#24577;&#21151;&#33021;&#32593;&#32476;&#36830;&#25509;&#30697;&#38453;&#65292;&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#26234;&#21147;&#65288;&#27969;&#20307;&#12289;&#26230;&#20307;&#21644;&#24635;&#20307;&#26234;&#21147;&#65289;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#25193;&#23637;&#20102;&#29616;&#26377;&#30340;&#22270;&#21367;&#31215;&#32593;&#32476;&#65292;&#23558;&#32858;&#31867;&#23884;&#20837;&#21644;&#22270;&#21516;&#26500;&#32593;&#32476;&#32435;&#20837;&#21040;&#22270;&#21367;&#31215;&#23618;&#20013;&#65292;&#20197;&#21453;&#26144;&#22823;&#33041;&#23376;&#32593;&#32476;&#32452;&#32455;&#30340;&#24615;&#36136;&#21644;&#39640;&#25928;&#32593;&#32476;&#34920;&#36798;&#65292;&#20877;&#36741;&#20197;TopK&#27744;&#21270;&#21644;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#35835;&#20986;&#20989;&#25968;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#22823;&#22411;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26550;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.03520v2 Announce Type: replace-cross  Abstract: Resting-state functional magnetic resonance imaging (rsfMRI) is a powerful tool for investigating the relationship between brain function and cognitive processes as it allows for the functional organization of the brain to be captured without relying on a specific task or stimuli. In this paper, we present a novel modeling architecture called BrainRGIN for predicting intelligence (fluid, crystallized, and total intelligence) using graph neural networks on rsfMRI derived static functional network connectivity matrices. Extending from the existing graph convolution networks, our approach incorporates a clustering-based embedding and graph isomorphism network in the graph convolutional layer to reflect the nature of the brain sub-network organization and efficient network expression, in combination with TopK pooling and attention-based readout functions. We evaluated our proposed architecture on a large dataset, specifically the A
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#21435;&#22122;&#25193;&#25955;&#21464;&#20998;&#25512;&#26029;&#65288;DDVI&#65289;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#34920;&#36798;&#24615;&#21464;&#20998;&#21518;&#39564;&#65292;&#24182;&#36890;&#36807;&#21453;&#36716;&#21152;&#22122;&#36807;&#31243;&#22312;&#28508;&#31354;&#38388;&#20013;&#36827;&#34892;&#25193;&#25955;&#12290;&#35813;&#26041;&#27861;&#26131;&#20110;&#23454;&#29616;&#65292;&#20860;&#23481;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#65292;&#24182;&#22312;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#20013;&#30340;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>http://arxiv.org/abs/2401.02739</link><description>&lt;p&gt;
&#25193;&#25955;&#21464;&#20998;&#25512;&#26029;&#65306;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#34920;&#36798;&#24615;&#21464;&#20998;&#21518;&#39564;
&lt;/p&gt;
&lt;p&gt;
Diffusion Variational Inference: Diffusion Models as Expressive Variational Posteriors. (arXiv:2401.02739v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02739
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#21435;&#22122;&#25193;&#25955;&#21464;&#20998;&#25512;&#26029;&#65288;DDVI&#65289;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#34920;&#36798;&#24615;&#21464;&#20998;&#21518;&#39564;&#65292;&#24182;&#36890;&#36807;&#21453;&#36716;&#21152;&#22122;&#36807;&#31243;&#22312;&#28508;&#31354;&#38388;&#20013;&#36827;&#34892;&#25193;&#25955;&#12290;&#35813;&#26041;&#27861;&#26131;&#20110;&#23454;&#29616;&#65292;&#20860;&#23481;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#65292;&#24182;&#22312;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#20013;&#30340;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#21435;&#22122;&#25193;&#25955;&#21464;&#20998;&#25512;&#26029;&#65288;DDVI&#65289;&#65292;&#19968;&#31181;&#29992;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#34920;&#36798;&#24615;&#21464;&#20998;&#21518;&#39564;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#36817;&#20284;&#25512;&#26029;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#36741;&#21161;&#28508;&#21464;&#37327;&#22686;&#21152;&#20102;&#21464;&#20998;&#21518;&#39564;&#65292;&#20174;&#32780;&#24471;&#21040;&#19968;&#20010;&#34920;&#36798;&#24615;&#30340;&#27169;&#22411;&#31867;&#65292;&#36890;&#36807;&#21453;&#36716;&#29992;&#25143;&#25351;&#23450;&#30340;&#21152;&#22122;&#36807;&#31243;&#22312;&#28508;&#31354;&#38388;&#20013;&#36827;&#34892;&#25193;&#25955;&#12290;&#25105;&#20204;&#36890;&#36807;&#20248;&#21270;&#19968;&#20010;&#21463;&#21040;&#35273;&#37266;-&#30561;&#30496;&#31639;&#27861;&#21551;&#21457;&#30340;&#36793;&#38469;&#20284;&#28982;&#26032;&#19979;&#30028;&#26469;&#25311;&#21512;&#36825;&#20123;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26131;&#20110;&#23454;&#29616;&#65288;&#23427;&#36866;&#37197;&#20102;&#27491;&#21017;&#21270;&#30340;ELBO&#25193;&#23637;&#65289;&#65292;&#19982;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#20860;&#23481;&#65292;&#24182;&#19988;&#34920;&#29616;&#20248;&#20110;&#22522;&#20110;&#24402;&#19968;&#21270;&#27969;&#25110;&#23545;&#25239;&#32593;&#32476;&#30340;&#26367;&#20195;&#36817;&#20284;&#21518;&#39564;&#31867;&#21035;&#12290;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#26102;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24471;&#21040;&#20102;&#21435;&#22122;&#25193;&#25955;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;DD-VAE&#65289;&#31639;&#27861;&#12290;&#25105;&#20204;&#23558;&#35813;&#31639;&#27861;&#24212;&#29992;&#20110;&#29983;&#29289;&#23398;&#20013;&#30340;&#19968;&#20010;&#28608;&#21169;&#20219;&#21153; -- &#20174;&#20154;&#31867;&#22522;&#22240;&#32452;&#20013;&#25512;&#26029;&#28508;&#22312;&#34880;&#32479; -- &#36229;&#36807;&#20102;&#24378;&#22522;&#32447;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose denoising diffusion variational inference (DDVI), an approximate inference algorithm for latent variable models which relies on diffusion models as expressive variational posteriors. Our method augments variational posteriors with auxiliary latents, which yields an expressive class of models that perform diffusion in latent space by reversing a user-specified noising process. We fit these models by optimizing a novel lower bound on the marginal likelihood inspired by the wake-sleep algorithm. Our method is easy to implement (it fits a regularized extension of the ELBO), is compatible with black-box variational inference, and outperforms alternative classes of approximate posteriors based on normalizing flows or adversarial networks. When applied to deep latent variable models, our method yields the denoising diffusion VAE (DD-VAE) algorithm. We use this algorithm on a motivating task in biology -- inferring latent ancestry from human genomes -- outperforming strong baselines
&lt;/p&gt;</description></item></channel></rss>