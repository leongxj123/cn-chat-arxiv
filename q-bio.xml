<rss version="2.0"><channel><title>Chat Arxiv q-bio</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for q-bio</description><item><title>&#30740;&#31350;&#23545;&#27604;&#20102;&#20154;&#31867;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#22270;&#20687;&#20998;&#31867;&#20013;&#30340;&#34892;&#20026;&#24046;&#24322;&#65292;&#21457;&#29616;&#20154;&#31867;&#20855;&#26377;&#21363;&#26102;&#27010;&#25324;&#33021;&#21147;&#65292;&#32780;DNNs&#23384;&#22312;&#28382;&#21518;&#27010;&#25324;&#29616;&#35937;&#65292;&#36825;&#34920;&#26126;&#20102;&#34920;&#31034;&#20998;&#27495;&#30340;&#23384;&#22312;&#12290;</title><link>https://arxiv.org/abs/2402.09303</link><description>&lt;p&gt;
&#20154;&#31867;&#20013;&#30340;&#21363;&#26102;&#27010;&#25324;&#19982;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#28382;&#21518;&#27010;&#25324;&#8212;&#8212;&#34920;&#31034;&#20998;&#27495;&#30340;&#35777;&#25454;&#65311;
&lt;/p&gt;
&lt;p&gt;
Immediate generalisation in humans but a generalisation lag in deep neural networks$\unicode{x2014}$evidence for representational divergence?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09303
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#23545;&#27604;&#20102;&#20154;&#31867;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#22270;&#20687;&#20998;&#31867;&#20013;&#30340;&#34892;&#20026;&#24046;&#24322;&#65292;&#21457;&#29616;&#20154;&#31867;&#20855;&#26377;&#21363;&#26102;&#27010;&#25324;&#33021;&#21147;&#65292;&#32780;DNNs&#23384;&#22312;&#28382;&#21518;&#27010;&#25324;&#29616;&#35937;&#65292;&#36825;&#34920;&#26126;&#20102;&#34920;&#31034;&#20998;&#27495;&#30340;&#23384;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#30340;&#30740;&#31350;&#22312;&#22270;&#20687;&#20998;&#31867;&#39046;&#22495;&#20013;&#23545;&#27604;&#20102;&#20154;&#31867;&#19982;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNNs&#65289;&#30340;&#35768;&#22810;&#34892;&#20026;&#27604;&#36739;&#12290;&#36890;&#24120;&#65292;&#27604;&#36739;&#30740;&#31350;&#20851;&#27880;&#30340;&#26159;&#23398;&#20064;&#36807;&#31243;&#30340;&#26368;&#32456;&#32467;&#26524;&#65292;&#36890;&#36807;&#27979;&#37327;&#21644;&#27604;&#36739;&#30446;&#26631;&#31867;&#21035;&#34920;&#31034;&#30340;&#30456;&#20284;&#24615;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#34920;&#31034;&#22914;&#20309;&#24418;&#25104;&#21363;&#20854;&#36807;&#31243;&#8212;&#8212;&#21363;&#22312;&#33719;&#21462;&#36807;&#31243;&#20013;&#35266;&#23519;&#21040;&#30340;&#34892;&#20026;&#21464;&#21270;&#21644;&#20013;&#38388;&#38454;&#27573;&#8212;&#8212;&#24448;&#24448;&#23569;&#26377;&#30452;&#25509;&#21644;&#23454;&#35777;&#30340;&#27604;&#36739;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25253;&#21578;&#20102;&#23545;&#20154;&#31867;&#35266;&#23519;&#32773;&#21644;&#19981;&#21516;&#32463;&#20856;&#19982;&#26368;&#26032;&#25216;&#26415;&#30340;DNNs&#20013;&#21487;&#36716;&#31227;&#34920;&#31034;&#26159;&#22914;&#20309;&#34987;&#33719;&#21462;&#30340;&#30340;&#35814;&#32454;&#35843;&#26597;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#21463;&#38480;&#30340;&#30417;&#30563;&#23398;&#20064;&#29615;&#22659;&#65292;&#35813;&#29615;&#22659;&#20013;&#25105;&#20204;&#23545;&#40784;&#20102;&#23398;&#20064;&#30456;&#20851;&#30340;&#21442;&#25968;&#65292;&#22914;&#36215;&#22987;&#28857;&#12289;&#36755;&#20837;&#27169;&#24335;&#12289;&#21487;&#29992;&#36755;&#20837;&#25968;&#25454;&#20197;&#21450;&#25552;&#20379;&#30340;&#21453;&#39304;&#12290;&#22312;&#25972;&#20010;&#23398;&#20064;&#36807;&#31243;&#20013;&#25105;&#20204;&#35780;&#20272;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09303v1 Announce Type: cross Abstract: Recent research has seen many behavioral comparisons between humans and deep neural networks (DNNs) in the domain of image classification. Often, comparison studies focus on the end-result of the learning process by measuring and comparing the similarities in the representations of object categories once they have been formed. However, the process of how these representations emerge$\unicode{x2014}$that is, the behavioral changes and intermediate stages observed during the acquisition$\unicode{x2014}$is less often directly and empirically compared.   Here we report a detailed investigation of how transferable representations are acquired in human observers and various classic and state-of-the-art DNNs. We develop a constrained supervised learning environment in which we align learning-relevant parameters such as starting point, input modality, available input data and the feedback provided. Across the whole learning process we evaluate 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20351;&#29992;&#21457;&#32946;Braitenberg Vehicles&#20195;&#29702;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#21457;&#32946;&#21551;&#21457;&#30340;&#23398;&#20064;&#20195;&#29702;&#35774;&#35745;&#65292;&#23454;&#29616;&#20102;&#35745;&#31639;&#33258;&#20027;&#24615;&#30340;&#20855;&#36523;&#32463;&#39564;&#21644;&#24418;&#24577;&#21457;&#29983;&#22686;&#38271;&#27169;&#25311;&#65292;&#24182;&#32771;&#34385;&#20102;&#21457;&#32946;&#36712;&#36857;&#22312;&#31070;&#32463;&#31995;&#32479;&#24418;&#24577;&#29983;&#25104;&#12289;&#21457;&#32946;&#23398;&#20064;&#21644;&#21487;&#22609;&#24615;&#31561;&#26041;&#38754;&#30340;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2103.05753</link><description>&lt;p&gt;
&#25345;&#32493;&#21457;&#23637;&#30340;&#31070;&#32463;&#20223;&#30495;&#65306;&#22522;&#20110;&#20855;&#36523;&#35745;&#31639;&#20195;&#29702;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Continual Developmental Neurosimulation Using Embodied Computational Agents. (arXiv:2103.05753v2 [q-bio.NC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2103.05753
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#21457;&#32946;Braitenberg Vehicles&#20195;&#29702;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#21457;&#32946;&#21551;&#21457;&#30340;&#23398;&#20064;&#20195;&#29702;&#35774;&#35745;&#65292;&#23454;&#29616;&#20102;&#35745;&#31639;&#33258;&#20027;&#24615;&#30340;&#20855;&#36523;&#32463;&#39564;&#21644;&#24418;&#24577;&#21457;&#29983;&#22686;&#38271;&#27169;&#25311;&#65292;&#24182;&#32771;&#34385;&#20102;&#21457;&#32946;&#36712;&#36857;&#22312;&#31070;&#32463;&#31995;&#32479;&#24418;&#24577;&#29983;&#25104;&#12289;&#21457;&#32946;&#23398;&#20064;&#21644;&#21487;&#22609;&#24615;&#31561;&#26041;&#38754;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#32508;&#21512;&#21457;&#32946;&#29983;&#29289;&#23398;&#12289;&#35748;&#30693;&#31185;&#23398;&#21644;&#35745;&#31639;&#24314;&#27169;&#65292;&#25105;&#20204;&#21487;&#20197;&#33719;&#24471;&#24456;&#22810;&#30693;&#35782;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#30446;&#26631;&#26159;&#22522;&#20110;Braitenberg Vehicles&#35774;&#35745;&#24320;&#21457;&#21463;&#21457;&#32946;&#21551;&#21457;&#30340;&#23398;&#20064;&#20195;&#29702;&#12290;&#21033;&#29992;&#36825;&#20123;&#20195;&#29702;&#20307;&#29616;&#20102;&#35745;&#31639;&#33258;&#20027;&#24615;&#30340;&#20855;&#36523;&#29305;&#24615;&#65292;&#19981;&#26029;&#38752;&#36817;&#23545;&#20855;&#36523;&#32463;&#39564;&#21644;&#24418;&#24577;&#21457;&#29983;&#22686;&#38271;&#20316;&#20026;&#35748;&#30693;&#21457;&#23637;&#33021;&#21147;&#32452;&#25104;&#37096;&#20998;&#30340;&#24314;&#27169;&#12290;&#25105;&#20204;&#32771;&#34385;&#29983;&#29289;&#21644;&#35748;&#30693;&#21457;&#23637;&#23545;&#25104;&#24180;&#34920;&#22411;&#29983;&#25104;&#21644;&#21487;&#29992;&#21457;&#23637;&#36335;&#24452;&#30340;&#24433;&#21709;&#12290;&#25345;&#32493;&#21457;&#23637;&#31070;&#32463;&#20223;&#30495;&#20351;&#25105;&#20204;&#33021;&#22815;&#32771;&#34385;&#21457;&#32946;&#36712;&#36857;&#22312;&#36830;&#25509;&#31070;&#32463;&#31995;&#32479;&#24418;&#24577;&#21457;&#29983;&#12289;&#21457;&#32946;&#23398;&#20064;&#21644;&#21487;&#22609;&#24615;&#31561;&#30456;&#20851;&#29616;&#35937;&#20013;&#25152;&#36215;&#30340;&#20316;&#29992;&#12290;&#30001;&#20110;&#19982;&#25345;&#32493;&#23398;&#20064;&#32039;&#23494;&#30456;&#20851;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#21457;&#32946;&#20855;&#36523;&#32039;&#23494;&#38598;&#25104;&#65292;&#21487;&#20197;&#20351;&#29992;&#19968;&#31181;&#31216;&#20026;&#21457;&#32946;Braitenberg Vehicles (dBVs)&#30340;&#20195;&#29702;&#26469;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
There is much to learn through synthesis of Developmental Biology, Cognitive Science and Computational Modeling. Our path forward is to present a design for developmentally-inspired learning agents based on Braitenberg Vehicles. Using these agents to exemplify the embodied nature of computational autonomy, we move closer to modeling embodied experience and morphogenetic growth as components of cognitive developmental capacity. We consider biological and cognitive development which influence the generation of adult phenotypes and the contingency of available developmental pathways. Continual developmental neurosimulation allows us to consider the role of developmental trajectories in bridging the related phenomena of nervous system morphogenesis, developmental learning, and plasticity. Being closely tied to continual learning, our approach is tightly integrated with developmental embodiment, and can be implemented using a type of agent called developmental Braitenberg Vehicles (dBVs). T
&lt;/p&gt;</description></item></channel></rss>