<rss version="2.0"><channel><title>Chat Arxiv q-bio</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for q-bio</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#22810;&#27169;&#24577;&#24341;&#23548;&#29983;&#25104;/&#20248;&#21270;&#20219;&#21153;&#35299;&#20915;&#20998;&#23376;&#35774;&#35745;&#38382;&#39064;&#30340;&#21019;&#26032;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.03425</link><description>&lt;p&gt;
&#22312;3D&#20013;&#22609;&#36896;&#20998;&#23376;&#65306;&#38754;&#21521;&#25991;&#26412;&#30340;&#20998;&#23376;&#20248;&#21270;&#28789;&#27963;&#23376;&#32467;&#26500;&#24863;&#30693;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Sculpting Molecules in 3D: A Flexible Substructure Aware Framework for Text-Oriented Molecular Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03425
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#22810;&#27169;&#24577;&#24341;&#23548;&#29983;&#25104;/&#20248;&#21270;&#20219;&#21153;&#35299;&#20915;&#20998;&#23376;&#35774;&#35745;&#38382;&#39064;&#30340;&#21019;&#26032;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23558;&#28145;&#24230;&#23398;&#20064;&#65292;&#29305;&#21035;&#26159;AI-Generated Content&#65292;&#19982;&#20174;&#31532;&#19968;&#21407;&#29702;&#35745;&#31639;&#20013;&#24471;&#20986;&#30340;&#39640;&#36136;&#37327;&#25968;&#25454;&#30456;&#32467;&#21512;&#65292;&#24050;&#32463;&#25104;&#20026;&#25913;&#21464;&#31185;&#23398;&#30740;&#31350;&#26684;&#23616;&#30340;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#36884;&#24452;&#12290;&#28982;&#32780;&#65292;&#35774;&#35745;&#26082;&#21253;&#21547;&#22810;&#27169;&#24577;&#20808;&#39564;&#30693;&#35782;&#21448;&#20855;&#26377;&#20851;&#38190;&#21644;&#22797;&#26434;&#24615;&#30340;&#20998;&#23376;&#33647;&#29289;&#25110;&#26448;&#26009;&#30340;&#25361;&#25112;&#20381;&#28982;&#26159;&#19968;&#39033;&#20851;&#38190;&#32780;&#22797;&#26434;&#30340;&#24037;&#20316;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#19968;&#36870;&#35774;&#35745;&#38382;&#39064;&#65292;&#23558;&#20854;&#26500;&#36896;&#20026;&#19968;&#31181;&#22810;&#27169;&#24577;&#23548;&#21521;&#29983;&#25104;/&#20248;&#21270;&#20219;&#21153;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#35299;&#20915;&#26041;&#26696;&#28041;&#21450;&#19968;&#20010;&#38754;&#21521;&#25991;&#26412;-&#32467;&#26500;&#23545;&#40784;&#30340;&#23545;&#31216;&#25193;&#25955;&#26694;&#26550;&#65292;&#29992;&#20110;&#23454;&#29616;&#20998;&#23376;&#29983;&#25104;/&#20248;&#21270;&#20219;&#21153;&#65292;&#21363;3DToMolo.
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03425v1 Announce Type: new  Abstract: The integration of deep learning, particularly AI-Generated Content, with high-quality data derived from ab initio calculations has emerged as a promising avenue for transforming the landscape of scientific research. However, the challenge of designing molecular drugs or materials that incorporate multi-modality prior knowledge remains a critical and complex undertaking. Specifically, achieving a practical molecular design necessitates not only meeting the diversity requirements but also addressing structural and textural constraints with various symmetries outlined by domain experts. In this article, we present an innovative approach to tackle this inverse design problem by formulating it as a multi-modality guidance generation/optimization task. Our proposed solution involves a textural-structure alignment symmetric diffusion framework for the implementation of molecular generation/optimization tasks, namely 3DToMolo. 3DToMolo aims to 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#22312;&#20998;&#23376;&#32467;&#26500;&#21644;&#29983;&#29289;&#21307;&#23398;&#30693;&#35782;&#22270;&#35889;&#20013;&#38598;&#25104;&#22810;&#20010;&#39046;&#22495;&#20449;&#24687;&#65292;&#36890;&#36807;&#33258;&#25105;&#30417;&#30563;&#31574;&#30053;&#39044;&#20808;&#35757;&#32451;&#26356;&#24191;&#27867;&#21644;&#26356;&#24378;&#22823;&#30340;&#34920;&#31034;&#65292;&#24182;&#22312;&#21270;&#23398;&#23646;&#24615;&#39044;&#27979;&#20219;&#21153;&#19978;&#23637;&#31034;&#20986;&#20986;&#33394;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.01631</link><description>&lt;p&gt;
Gode -- &#23558;&#29983;&#29289;&#21270;&#23398;&#30693;&#35782;&#22270;&#35889;&#38598;&#25104;&#21040;&#20998;&#23376;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#39044;&#35757;&#32451;&#20013;
&lt;/p&gt;
&lt;p&gt;
Gode -- Integrating Biochemical Knowledge Graph into Pre-training Molecule Graph Neural Network. (arXiv:2306.01631v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01631
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#22312;&#20998;&#23376;&#32467;&#26500;&#21644;&#29983;&#29289;&#21307;&#23398;&#30693;&#35782;&#22270;&#35889;&#20013;&#38598;&#25104;&#22810;&#20010;&#39046;&#22495;&#20449;&#24687;&#65292;&#36890;&#36807;&#33258;&#25105;&#30417;&#30563;&#31574;&#30053;&#39044;&#20808;&#35757;&#32451;&#26356;&#24191;&#27867;&#21644;&#26356;&#24378;&#22823;&#30340;&#34920;&#31034;&#65292;&#24182;&#22312;&#21270;&#23398;&#23646;&#24615;&#39044;&#27979;&#20219;&#21153;&#19978;&#23637;&#31034;&#20986;&#20986;&#33394;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#23376;&#23646;&#24615;&#30340;&#20934;&#30830;&#39044;&#27979;&#23545;&#20110;&#20419;&#36827;&#21019;&#26032;&#27835;&#30103;&#26041;&#27861;&#30340;&#21457;&#23637;&#21644;&#29702;&#35299;&#21270;&#23398;&#29289;&#36136;&#21644;&#29983;&#29289;&#31995;&#32479;&#20043;&#38388;&#22797;&#26434;&#30340;&#30456;&#20114;&#20316;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#23558;&#21333;&#20010;&#20998;&#23376;&#32467;&#26500;&#30340;&#22270;&#34920;&#31034;&#19982;&#29983;&#29289;&#21307;&#23398;&#30693;&#35782;&#22270;&#35889; (KG) &#30340;&#22810;&#20010;&#39046;&#22495;&#20449;&#24687;&#36827;&#34892;&#38598;&#25104;&#12290;&#36890;&#36807;&#38598;&#25104;&#20004;&#20010;&#32423;&#21035;&#30340;&#20449;&#24687;&#65292;&#25105;&#20204;&#21487;&#20197;&#20351;&#29992;&#33258;&#25105;&#30417;&#30563;&#31574;&#30053;&#39044;&#20808;&#35757;&#32451;&#26356;&#24191;&#27867;&#21644;&#26356;&#24378;&#22823;&#30340;&#34920;&#31034;&#65292;&#29992;&#20110;&#20998;&#23376;&#32423;&#21644; KG &#32423;&#39044;&#27979;&#20219;&#21153;&#12290;&#22312;&#24615;&#33021;&#35780;&#20272;&#26041;&#38754;&#65292;&#25105;&#20204;&#22312; 11 &#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#21270;&#23398;&#23646;&#24615;&#39044;&#27979;&#20219;&#21153;&#19978;&#24494;&#35843;&#25105;&#20204;&#39044;&#20808;&#35757;&#32451;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#24494;&#35843;&#30340;&#27169;&#22411;&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
The precise prediction of molecular properties holds paramount importance in facilitating the development of innovative treatments and comprehending the intricate interplay between chemicals and biological systems. In this study, we propose a novel approach that integrates graph representations of individual molecular structures with multi-domain information from biomedical knowledge graphs (KGs). Integrating information from both levels, we can pre-train a more extensive and robust representation for both molecule-level and KG-level prediction tasks with our novel self-supervision strategy. For performance evaluation, we fine-tune our pre-trained model on 11 challenging chemical property prediction tasks. Results from our framework demonstrate our fine-tuned models outperform existing state-of-the-art models.
&lt;/p&gt;</description></item></channel></rss>