<rss version="2.0"><channel><title>Chat Arxiv q-bio</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for q-bio</description><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#19982;&#22270;&#23572;&#25991;&#30340;&#35760;&#24518;&#29702;&#35770;&#20043;&#38388;&#30340;&#23545;&#24212;&#20851;&#31995;&#65292;&#24182;&#25552;&#20986;&#20102;&#24847;&#35782;&#21487;&#33021;&#26159;&#19968;&#31181;&#22522;&#20110;&#36825;&#31181;&#23545;&#24212;&#20851;&#31995;&#30340;&#26032;&#20852;&#33021;&#21147;&#30340;&#29468;&#24819;&#12290;</title><link>http://arxiv.org/abs/2401.02509</link><description>&lt;p&gt;
&#35760;&#24518;&#12289;&#24847;&#35782;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Memory, Consciousness and Large Language Model. (arXiv:2401.02509v1 [q-bio.NC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02509
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#19982;&#22270;&#23572;&#25991;&#30340;&#35760;&#24518;&#29702;&#35770;&#20043;&#38388;&#30340;&#23545;&#24212;&#20851;&#31995;&#65292;&#24182;&#25552;&#20986;&#20102;&#24847;&#35782;&#21487;&#33021;&#26159;&#19968;&#31181;&#22522;&#20110;&#36825;&#31181;&#23545;&#24212;&#20851;&#31995;&#30340;&#26032;&#20852;&#33021;&#21147;&#30340;&#29468;&#24819;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#35748;&#30693;&#31185;&#23398;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#21457;&#23637;&#65292;&#36825;&#20004;&#20010;&#19981;&#21516;&#39046;&#22495;&#20043;&#38388;&#30340;&#32852;&#31995;&#36234;&#26469;&#36234;&#22810;&#22320;&#34987;&#25581;&#31034;&#20986;&#26469;&#12290;&#22312;&#36825;&#20123;&#32852;&#31995;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29468;&#24819;&#65292;&#21363;LLM&#21644;&#22270;&#23572;&#25991;&#30340;&#35760;&#24518;&#29702;&#35770;&#20043;&#38388;&#23384;&#22312;&#19968;&#31181;&#23545;&#20598;&#20851;&#31995;&#12290;&#25105;&#20204;&#30830;&#23450;&#20102;&#22270;&#23572;&#25991;&#30340;&#21327;&#21516;&#24341;&#21457;&#65288;SEM&#65289;&#26816;&#32034;&#27169;&#22411;&#21644;LLM&#20013;&#35266;&#23519;&#21040;&#30340;&#26032;&#20852;&#33021;&#21147;&#20043;&#38388;&#30340;&#28508;&#22312;&#23545;&#24212;&#20851;&#31995;&#65292;&#20026;&#25105;&#20204;&#30340;&#29468;&#24819;&#25552;&#20379;&#20102;&#25903;&#25345;&#35777;&#25454;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25512;&#27979;&#24847;&#35782;&#21487;&#33021;&#34987;&#35748;&#20026;&#26159;&#36825;&#31181;&#23545;&#20598;&#24615;&#30340;&#19968;&#31181;&#26032;&#20852;&#33021;&#21147;&#24418;&#24335;&#12290;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#20854;&#20182;&#24847;&#35782;&#29702;&#35770;&#22914;&#20309;&#19982;&#25105;&#20204;&#30340;&#30740;&#31350;&#30456;&#20132;&#21449;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the development in cognitive science and Large Language Models (LLMs), increasing connections have come to light between these two distinct fields. Building upon these connections, we propose a conjecture suggesting the existence of a duality between LLMs and Tulving's theory of memory. We identify a potential correspondence between Tulving's synergistic ecphory model (SEM) of retrieval and the emergent abilities observed in LLMs, serving as supporting evidence for our conjecture. Furthermore, we speculate that consciousness may be considered a form of emergent ability based on this duality. We also discuss how other theories of consciousness intersect with our research.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21644;&#33041;&#23545;&#40784;&#30340;&#30740;&#31350;&#65292;&#37325;&#28857;&#22312;&#20110;&#33041;&#32534;&#30721;&#21644;&#35299;&#30721;&#27169;&#22411;&#30340;&#24212;&#29992;&#12290;&#36825;&#20123;&#27169;&#22411;&#23545;&#20110;&#29702;&#35299;&#22823;&#33041;&#30340;&#20449;&#24687;&#22788;&#29702;&#26426;&#21046;&#20197;&#21450;&#35774;&#35745;&#33041;&#26426;&#25509;&#21475;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2307.10246</link><description>&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21644;&#33041;&#23545;&#40784;&#65306;&#33041;&#32534;&#30721;&#21644;&#35299;&#30721;&#65288;&#32508;&#36848;&#65289;
&lt;/p&gt;
&lt;p&gt;
Deep Neural Networks and Brain Alignment: Brain Encoding and Decoding (Survey). (arXiv:2307.10246v1 [q-bio.NC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10246
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21644;&#33041;&#23545;&#40784;&#30340;&#30740;&#31350;&#65292;&#37325;&#28857;&#22312;&#20110;&#33041;&#32534;&#30721;&#21644;&#35299;&#30721;&#27169;&#22411;&#30340;&#24212;&#29992;&#12290;&#36825;&#20123;&#27169;&#22411;&#23545;&#20110;&#29702;&#35299;&#22823;&#33041;&#30340;&#20449;&#24687;&#22788;&#29702;&#26426;&#21046;&#20197;&#21450;&#35774;&#35745;&#33041;&#26426;&#25509;&#21475;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#33041;&#22914;&#20309;&#34920;&#31034;&#19981;&#21516;&#30340;&#20449;&#24687;&#27169;&#24335;&#65311;&#25105;&#20204;&#33021;&#21542;&#35774;&#35745;&#20986;&#19968;&#20010;&#21487;&#20197;&#33258;&#21160;&#29702;&#35299;&#29992;&#25143;&#24605;&#32771;&#20869;&#23481;&#30340;&#31995;&#32479;&#65311;&#36825;&#20123;&#38382;&#39064;&#21487;&#20197;&#36890;&#36807;&#30740;&#31350;&#21151;&#33021;&#30913;&#20849;&#25391;&#25104;&#20687;&#65288;fMRI&#65289;&#31561;&#22823;&#33041;&#35760;&#24405;&#26469;&#22238;&#31572;&#12290;&#20316;&#20026;&#31532;&#19968;&#27493;&#65292;&#31070;&#32463;&#31185;&#23398;&#30028;&#20026;&#34987;&#21160;&#38405;&#35835;/&#21548;&#35273;/&#35266;&#30475;&#27010;&#24565;&#35789;&#27719;&#12289;&#21465;&#36848;&#12289;&#22270;&#29255;&#21644;&#30005;&#24433;&#30456;&#20851;&#30340;&#35748;&#30693;&#31070;&#32463;&#31185;&#23398;&#25968;&#25454;&#38598;&#20316;&#20986;&#20102;&#36129;&#29486;&#12290;&#36807;&#21435;&#20108;&#21313;&#24180;&#20013;&#65292;&#36824;&#25552;&#20986;&#20102;&#20351;&#29992;&#36825;&#20123;&#25968;&#25454;&#38598;&#30340;&#32534;&#30721;&#21644;&#35299;&#30721;&#27169;&#22411;&#12290;&#36825;&#20123;&#27169;&#22411;&#20316;&#20026;&#22522;&#30784;&#30740;&#31350;&#20013;&#30340;&#39069;&#22806;&#24037;&#20855;&#65292;&#22312;&#35748;&#30693;&#31185;&#23398;&#21644;&#31070;&#32463;&#31185;&#23398;&#39046;&#22495;&#26377;&#30528;&#22810;&#31181;&#23454;&#38469;&#24212;&#29992;&#12290;&#32534;&#30721;&#27169;&#22411;&#26088;&#22312;&#33258;&#21160;&#22320;&#29983;&#25104;fMRI&#22823;&#33041;&#34920;&#24449;&#65292;&#32473;&#23450;&#19968;&#20010;&#21050;&#28608;&#12290;&#23427;&#20204;&#22312;&#35780;&#20272;&#21644;&#35786;&#26029;&#31070;&#32463;&#31995;&#32479;&#30142;&#30149;&#20197;&#21450;&#35774;&#35745;&#22823;&#33041;&#25439;&#20260;&#27835;&#30103;&#26041;&#27861;&#26041;&#38754;&#26377;&#30528;&#22810;&#31181;&#23454;&#38469;&#24212;&#29992;&#12290;&#35299;&#30721;&#27169;&#22411;&#35299;&#20915;&#20102;&#26681;&#25454;fMRI&#37325;&#26500;&#21050;&#28608;&#30340;&#36870;&#38382;&#39064;&#12290;&#23427;&#20204;&#23545;&#20110;&#29702;&#35299;&#22823;&#33041;&#22914;&#20309;&#22788;&#29702;&#20449;&#24687;&#20197;&#21450;&#35774;&#35745;&#33041;&#26426;&#25509;&#21475;&#30340;&#21457;&#23637;&#37117;&#26377;&#30528;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;
How does the brain represent different modes of information? Can we design a system that automatically understands what the user is thinking? Such questions can be answered by studying brain recordings like functional magnetic resonance imaging (fMRI). As a first step, the neuroscience community has contributed several large cognitive neuroscience datasets related to passive reading/listening/viewing of concept words, narratives, pictures and movies. Encoding and decoding models using these datasets have also been proposed in the past two decades. These models serve as additional tools for basic research in cognitive science and neuroscience. Encoding models aim at generating fMRI brain representations given a stimulus automatically. They have several practical applications in evaluating and diagnosing neurological conditions and thus also help design therapies for brain damage. Decoding models solve the inverse problem of reconstructing the stimuli given the fMRI. They are useful for 
&lt;/p&gt;</description></item></channel></rss>