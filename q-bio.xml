<rss version="2.0"><channel><title>Chat Arxiv q-bio</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for q-bio</description><item><title>ChatGPT&#22312;LLM&#35268;&#27169;&#19978;&#36890;&#36807;&#21033;&#29992;&#35821;&#35328;&#26412;&#36523;&#30340;&#25910;&#25947;&#32422;&#26463;&#26469;&#20570;&#21040;&#36229;&#20986;&#39044;&#26399;&#30340;&#34920;&#29616;&#65292;&#20294;&#24182;&#19981;&#30495;&#27491;&#29702;&#35299;&#35821;&#20041;&#20197;&#21450;&#19982;&#24863;&#35273;&#21160;&#20316;&#30340;&#30452;&#25509;&#32852;&#31995;&#12290;</title><link>https://arxiv.org/abs/2402.02243</link><description>&lt;p&gt;
&#35821;&#35328;&#25193;&#23637;&#65306;LLMs&#65292;ChatGPT&#65292;&#25509;&#22320;&#65292;&#24847;&#20041;&#21644;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Language Writ Large: LLMs, ChatGPT, Grounding, Meaning and Understanding
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02243
&lt;/p&gt;
&lt;p&gt;
ChatGPT&#22312;LLM&#35268;&#27169;&#19978;&#36890;&#36807;&#21033;&#29992;&#35821;&#35328;&#26412;&#36523;&#30340;&#25910;&#25947;&#32422;&#26463;&#26469;&#20570;&#21040;&#36229;&#20986;&#39044;&#26399;&#30340;&#34920;&#29616;&#65292;&#20294;&#24182;&#19981;&#30495;&#27491;&#29702;&#35299;&#35821;&#20041;&#20197;&#21450;&#19982;&#24863;&#35273;&#21160;&#20316;&#30340;&#30452;&#25509;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38500;&#20102;OpenAI&#21487;&#33021;&#23545;&#25105;&#20204;&#38544;&#30610;&#30340;&#23569;&#37327;&#20449;&#24687;&#22806;&#65292;&#25105;&#20204;&#37117;&#22823;&#33268;&#30693;&#36947;ChatGPT&#26159;&#22914;&#20309;&#24037;&#20316;&#30340;&#65288;&#23427;&#30340;&#22823;&#22411;&#25991;&#26412;&#25968;&#25454;&#24211;&#65292;&#32479;&#35745;&#25968;&#25454;&#65292;&#21521;&#37327;&#34920;&#31034;&#20197;&#21450;&#23427;&#24040;&#22823;&#30340;&#21442;&#25968;&#25968;&#37327;&#65292;&#20854;&#19979;&#19968;&#20010;&#35789;&#30340;&#35757;&#32451;&#31561;&#65289;&#12290;&#20294;&#25105;&#20204;&#35841;&#20063;&#19981;&#33021;&#35828;&#25105;&#20204;&#23545;ChatGPT&#30340;&#36825;&#20123;&#36164;&#28304;&#25152;&#33021;&#20570;&#21040;&#30340;&#20107;&#24773;&#19981;&#24863;&#21040;&#24778;&#35766;&#12290;&#36825;&#29978;&#33267;&#35753;&#25105;&#20204;&#26377;&#20154;&#24471;&#20986;&#32467;&#35770;&#65292;ChatGPT&#23454;&#38469;&#19978;&#29702;&#35299;&#20102;&#12290;&#23427;&#24182;&#19981;&#29702;&#35299;&#65292;&#20294;&#25105;&#20204;&#20063;&#19981;&#33021;&#35828;&#25105;&#20204;&#29702;&#35299;&#23427;&#26159;&#22914;&#20309;&#20570;&#21040;&#36825;&#19968;&#28857;&#30340;&#12290;&#25105;&#23558;&#25552;&#20986;&#20851;&#20110;&#33391;&#24615;&#20559;&#35265;&#30340;&#19968;&#20123;&#29468;&#24819;&#65306;&#22312;LLM&#35268;&#27169;&#19978;&#20986;&#29616;&#30340;&#25910;&#25947;&#32422;&#26463;&#21487;&#33021;&#26377;&#21161;&#20110;ChatGPT&#20570;&#24471;&#27604;&#25105;&#20204;&#39044;&#26399;&#30340;&#22909;&#24471;&#22810;&#12290;&#36825;&#20123;&#20559;&#35265;&#26159;&#35821;&#35328;&#26412;&#36523;&#22312;LLM&#35268;&#27169;&#19978;&#22266;&#26377;&#30340;&#65292;&#24182;&#19988;&#19982;ChatGPT&#32570;&#20047;&#30452;&#25509;&#30340;&#24863;&#35273;&#21160;&#20316;&#25509;&#22320;&#20197;&#23558;&#20854;&#35789;&#19982;&#20854;&#25152;&#25351;&#30340;&#23545;&#35937;&#20197;&#21450;&#20854;&#21629;&#39064;&#19982;&#20854;&#24847;&#20041;&#32852;&#31995;&#36215;&#26469;&#23494;&#20999;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;
Apart from what (little) OpenAI may be concealing from us, we all know (roughly) how ChatGPT works (its huge text database, its statistics, its vector representations, and their huge number of parameters, its next-word training, and so on). But none of us can say (hand on heart) that we are not surprised by what ChatGPT has proved to be able to do with these resources. This has even driven some of us to conclude that ChatGPT actually understands. It is not true that it understands. But it is also not true that we understand how it can do what it can do. I will suggest some hunches about benign biases: convergent constraints that emerge at LLM scale that may be helping ChatGPT do so much better than we would have expected. These biases are inherent in the nature of language itself, at LLM scale, and they are closely linked to what it is that ChatGPT lacks, which is direct sensorimotor grounding to connect its words to their referents and its propositions to their meanings. These converg
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#31070;&#32463;&#32593;&#32476;&#34920;&#31034;&#19982;&#20154;&#31867;&#24515;&#29702;&#34920;&#31034;&#20043;&#38388;&#30340;&#23545;&#40784;&#38382;&#39064;&#65292;&#21457;&#29616;&#27169;&#22411;&#35268;&#27169;&#21644;&#20307;&#31995;&#32467;&#26500;&#23545;&#23545;&#40784;&#20960;&#20046;&#27809;&#26377;&#24433;&#21709;&#65292;&#32780;&#35757;&#32451;&#25968;&#25454;&#38598;&#21644;&#30446;&#26631;&#20989;&#25968;&#37117;&#23545;&#23545;&#40784;&#26377;&#24456;&#22823;&#30340;&#24433;&#21709;&#12290;&#20174;&#19968;&#20010;&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#30340;&#31070;&#32463;&#32593;&#32476;&#34920;&#31034;&#30340;&#32447;&#24615;&#21464;&#25442;&#33021;&#26174;&#33879;&#25552;&#39640;&#23545;&#21478;&#22806;&#20004;&#20010;&#25968;&#25454;&#38598;&#20013;&#20154;&#31867;&#30456;&#20284;&#24615;&#21028;&#26029;&#30340;&#23545;&#40784;&#24615;&#12290;</title><link>http://arxiv.org/abs/2211.01201</link><description>&lt;p&gt;
&#20154;&#31867;&#23545;&#31070;&#32463;&#32593;&#32476;&#34920;&#31034;&#30340;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Human alignment of neural network representations. (arXiv:2211.01201v4 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.01201
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#31070;&#32463;&#32593;&#32476;&#34920;&#31034;&#19982;&#20154;&#31867;&#24515;&#29702;&#34920;&#31034;&#20043;&#38388;&#30340;&#23545;&#40784;&#38382;&#39064;&#65292;&#21457;&#29616;&#27169;&#22411;&#35268;&#27169;&#21644;&#20307;&#31995;&#32467;&#26500;&#23545;&#23545;&#40784;&#20960;&#20046;&#27809;&#26377;&#24433;&#21709;&#65292;&#32780;&#35757;&#32451;&#25968;&#25454;&#38598;&#21644;&#30446;&#26631;&#20989;&#25968;&#37117;&#23545;&#23545;&#40784;&#26377;&#24456;&#22823;&#30340;&#24433;&#21709;&#12290;&#20174;&#19968;&#20010;&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#30340;&#31070;&#32463;&#32593;&#32476;&#34920;&#31034;&#30340;&#32447;&#24615;&#21464;&#25442;&#33021;&#26174;&#33879;&#25552;&#39640;&#23545;&#21478;&#22806;&#20004;&#20010;&#25968;&#25454;&#38598;&#20013;&#20154;&#31867;&#30456;&#20284;&#24615;&#21028;&#26029;&#30340;&#23545;&#40784;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#20170;&#30340;&#35745;&#31639;&#26426;&#35270;&#35273;&#27169;&#22411;&#22312;&#21508;&#31181;&#35270;&#35273;&#20219;&#21153;&#19978;&#23454;&#29616;&#20102;&#20154;&#31867;&#25110;&#25509;&#36817;&#20154;&#31867;&#27700;&#24179;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#20307;&#31995;&#32467;&#26500;&#12289;&#25968;&#25454;&#21644;&#23398;&#20064;&#31639;&#27861;&#19982;&#23548;&#33268;&#20154;&#31867;&#35270;&#35273;&#30340;&#26041;&#24335;&#23384;&#22312;&#35768;&#22810;&#19981;&#21516;&#20043;&#22788;&#12290;&#26412;&#25991;&#30740;&#31350;&#24433;&#21709;&#31070;&#32463;&#32593;&#32476;&#25152;&#23398;&#20064;&#30340;&#34920;&#31034;&#19982;&#36890;&#36807;&#34892;&#20026;&#21453;&#24212;&#25512;&#26029;&#20986;&#30340;&#20154;&#31867;&#24515;&#29702;&#34920;&#31034;&#20043;&#38388;&#23545;&#40784;&#30340;&#22240;&#32032;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#27169;&#22411;&#30340;&#35268;&#27169;&#21644;&#20307;&#31995;&#32467;&#26500;&#23545;&#19982;&#20154;&#31867;&#34892;&#20026;&#21453;&#24212;&#30340;&#23545;&#40784;&#22522;&#26412;&#19978;&#27809;&#26377;&#24433;&#21709;&#65292;&#32780;&#35757;&#32451;&#25968;&#25454;&#38598;&#21644;&#30446;&#26631;&#20989;&#25968;&#21017;&#20855;&#26377;&#26356;&#22823;&#30340;&#24433;&#21709;&#12290;&#36825;&#20123;&#21457;&#29616;&#22312;&#20351;&#29992;&#20004;&#31181;&#19981;&#21516;&#20219;&#21153;&#25910;&#38598;&#30340;&#19977;&#20010;&#20154;&#31867;&#30456;&#20284;&#24230;&#21028;&#26029;&#25968;&#25454;&#38598;&#20013;&#20445;&#25345;&#19968;&#33268;&#12290;&#20174;&#19968;&#20010;&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#30340;&#31070;&#32463;&#32593;&#32476;&#34920;&#31034;&#30340;&#32447;&#24615;&#21464;&#25442;&#26174;&#33879;&#25552;&#39640;&#20102;&#23545;&#21478;&#22806;&#20004;&#20010;&#25968;&#25454;&#38598;&#20013;&#30340;&#20154;&#31867;&#30456;&#20284;&#24230;&#21028;&#26029;&#30340;&#23545;&#40784;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21457;&#29616;&#65292;&#19968;&#20123;&#20154;&#31867;&#27010;&#24565;...
&lt;/p&gt;
&lt;p&gt;
Today's computer vision models achieve human or near-human level performance across a wide variety of vision tasks. However, their architectures, data, and learning algorithms differ in numerous ways from those that give rise to human vision. In this paper, we investigate the factors that affect the alignment between the representations learned by neural networks and human mental representations inferred from behavioral responses. We find that model scale and architecture have essentially no effect on the alignment with human behavioral responses, whereas the training dataset and objective function both have a much larger impact. These findings are consistent across three datasets of human similarity judgments collected using two different tasks. Linear transformations of neural network representations learned from behavioral responses from one dataset substantially improve alignment with human similarity judgments on the other two datasets. In addition, we find that some human concept
&lt;/p&gt;</description></item></channel></rss>