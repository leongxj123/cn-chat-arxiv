<rss version="2.0"><channel><title>Chat Arxiv q-bio</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for q-bio</description><item><title>&#25552;&#20986;&#20102; Generalized Latent Equilibrium (GLE)&#65292;&#23427;&#26159;&#19968;&#31181;&#38024;&#23545;&#31070;&#32463;&#20803;&#32593;&#32476;&#30340;&#29289;&#29702;&#21160;&#24577;&#23616;&#37096;&#26102;&#31354;&#20449;&#29992;&#20998;&#37197;&#30340;&#35745;&#31639;&#26694;&#26550;&#12290;</title><link>https://arxiv.org/abs/2403.16933</link><description>&lt;p&gt;
&#36890;&#36807;&#31354;&#38388;&#12289;&#26102;&#38388;&#21644;&#22823;&#33041;&#36827;&#34892;&#21453;&#21521;&#20256;&#25773;
&lt;/p&gt;
&lt;p&gt;
Backpropagation through space, time, and the brain
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16933
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102; Generalized Latent Equilibrium (GLE)&#65292;&#23427;&#26159;&#19968;&#31181;&#38024;&#23545;&#31070;&#32463;&#20803;&#32593;&#32476;&#30340;&#29289;&#29702;&#21160;&#24577;&#23616;&#37096;&#26102;&#31354;&#20449;&#29992;&#20998;&#37197;&#30340;&#35745;&#31639;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26377;&#25928;&#30340;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#38656;&#35201;&#26681;&#25454;&#23427;&#20204;&#23545;&#35299;&#20915;&#20219;&#21153;&#30340;&#30456;&#23545;&#36129;&#29486;&#26469;&#35843;&#25972;&#21333;&#20010;&#31361;&#35302;&#12290;&#28982;&#32780;&#65292;&#26080;&#35770;&#26159;&#29983;&#29289;&#36824;&#26159;&#20154;&#24037;&#30340;&#29289;&#29702;&#31070;&#32463;&#31995;&#32479;&#37117;&#21463;&#21040;&#26102;&#31354;&#23616;&#38480;&#12290;&#36825;&#26679;&#30340;&#32593;&#32476;&#22914;&#20309;&#25191;&#34892;&#39640;&#25928;&#30340;&#20449;&#29992;&#20998;&#37197;&#65292;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#20173;&#26159;&#19968;&#20010;&#24748;&#32780;&#26410;&#20915;&#30340;&#38382;&#39064;&#12290;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#38169;&#35823;&#30340;&#21453;&#21521;&#20256;&#25773;&#31639;&#27861;&#20960;&#20046;&#26222;&#36941;&#34987;&#31354;&#38388;&#65288;BP&#65289;&#21644;&#26102;&#38388;&#65288;BPTT&#65289;&#20004;&#31181;&#26041;&#24335;&#32473;&#20986;&#31572;&#26696;&#12290;&#28982;&#32780;&#65292;BP(TT)&#34987;&#24191;&#27867;&#35748;&#20026;&#20381;&#36182;&#20110;&#19981;&#20855;&#29983;&#29289;&#23398;&#24847;&#20041;&#30340;&#20551;&#35774;&#65292;&#29305;&#21035;&#26159;&#20851;&#20110;&#26102;&#31354;&#23616;&#38480;&#24615;&#65292;&#32780;&#27491;&#21521;&#20256;&#25773;&#27169;&#22411;&#65292;&#22914;&#23454;&#26102;&#36882;&#24402;&#23398;&#20064;&#65288;RTRL&#65289;&#65292;&#21017;&#21463;&#21040;&#20869;&#23384;&#32422;&#26463;&#30340;&#38480;&#21046;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#24191;&#20041;&#28508;&#22312;&#24179;&#34913;&#65288;GLE&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#38024;&#23545;&#31070;&#32463;&#20803;&#29289;&#29702;&#21160;&#24577;&#32593;&#32476;&#23436;&#20840;&#23616;&#37096;&#26102;&#31354;&#20449;&#29992;&#20998;&#37197;&#30340;&#35745;&#31639;&#26694;&#26550;&#12290;&#25105;&#20204;&#20174;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16933v1 Announce Type: cross  Abstract: Effective learning in neuronal networks requires the adaptation of individual synapses given their relative contribution to solving a task. However, physical neuronal systems -- whether biological or artificial -- are constrained by spatio-temporal locality. How such networks can perform efficient credit assignment, remains, to a large extent, an open question. In Machine Learning, the answer is almost universally given by the error backpropagation algorithm, through both space (BP) and time (BPTT). However, BP(TT) is well-known to rely on biologically implausible assumptions, in particular with respect to spatiotemporal (non-)locality, while forward-propagation models such as real-time recurrent learning (RTRL) suffer from prohibitive memory constraints. We introduce Generalized Latent Equilibrium (GLE), a computational framework for fully local spatio-temporal credit assignment in physical, dynamical networks of neurons. We start by 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21463;&#21040;&#35745;&#31639;&#26426;&#35270;&#35273;&#20013; JEPA &#26550;&#26500;&#21551;&#21457;&#30340; Spatio-Temporal Joint Embedding Masked Autoencoder&#65288;ST-JEMA&#65289;&#29992;&#20110;&#21160;&#24577;&#21151;&#33021;&#36830;&#25509;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#12290;</title><link>https://arxiv.org/abs/2403.06432</link><description>&lt;p&gt;
&#20154;&#31867;&#22823;&#33041;&#21160;&#24577;&#21151;&#33021;&#36830;&#25509;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#32852;&#21512;&#23884;&#20837;&#25513;&#34109;&#33258;&#32534;&#30721;&#22120;
&lt;/p&gt;
&lt;p&gt;
Joint-Embedding Masked Autoencoder for Self-supervised Learning of Dynamic Functional Connectivity from the Human Brain
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06432
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21463;&#21040;&#35745;&#31639;&#26426;&#35270;&#35273;&#20013; JEPA &#26550;&#26500;&#21551;&#21457;&#30340; Spatio-Temporal Joint Embedding Masked Autoencoder&#65288;ST-JEMA&#65289;&#29992;&#20110;&#21160;&#24577;&#21151;&#33021;&#36830;&#25509;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06432v1 &#36890;&#21578;&#31867;&#22411;: &#26032;&#30340; &#25688;&#35201;: &#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#22312;&#23398;&#20064;&#21160;&#24577;&#21151;&#33021;&#36830;&#25509;&#26041;&#38754;&#34920;&#29616;&#20986;&#28508;&#21147;&#65292;&#21487;&#20197;&#21306;&#20998;&#20154;&#33041;&#32593;&#32476;&#20013;&#30340;&#34920;&#29616;&#22411;&#12290;&#28982;&#32780;&#65292;&#33719;&#24471;&#29992;&#20110;&#35757;&#32451;&#30340;&#22823;&#37327;&#26631;&#35760;&#20020;&#24202;&#25968;&#25454;&#36890;&#24120;&#20855;&#26377;&#36164;&#28304;&#23494;&#38598;&#24615;&#65292;&#36825;&#20351;&#24471;&#23454;&#38469;&#24212;&#29992;&#21464;&#24471;&#22256;&#38590;&#12290;&#22240;&#27492;&#65292;&#22312;&#26631;&#31614;&#31232;&#32570;&#35774;&#32622;&#20013;&#65292;&#21033;&#29992;&#26410;&#26631;&#35760;&#25968;&#25454;&#23545;&#20110;&#34920;&#31034;&#23398;&#20064;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#12290;&#23613;&#31649;&#29983;&#25104;&#24335;&#33258;&#30417;&#30563;&#23398;&#20064;&#25216;&#26415;&#65292;&#29305;&#21035;&#26159;&#25513;&#34109;&#33258;&#32534;&#30721;&#22120;&#65292;&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#34920;&#31034;&#23398;&#20064;&#20013;&#23637;&#29616;&#20986;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#65292;&#20294;&#23427;&#20204;&#22312;&#21160;&#24577;&#22270;&#24418;&#19978;&#30340;&#24212;&#29992;&#20197;&#21450;&#21160;&#24577;&#21151;&#33021;&#36830;&#25509;&#26041;&#38754;&#20173;&#26410;&#24471;&#21040;&#20805;&#20998;&#25506;&#35752;&#65292;&#38754;&#20020;&#30528;&#25429;&#25417;&#39640;&#32423;&#35821;&#20041;&#34920;&#31034;&#26041;&#38754;&#30340;&#25361;&#25112;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#26102;&#31354;&#32852;&#21512;&#23884;&#20837;&#25513;&#34109;&#33258;&#32534;&#30721;&#22120;&#65288;ST-JEMA&#65289;&#65292;&#21463;&#21040;&#35745;&#31639;&#26426;&#35270;&#35273;&#20013;&#32852;&#21512;&#23884;&#20837;&#39044;&#27979;&#26550;&#26500;&#65288;JEPA&#65289;&#30340;&#21551;&#21457;&#12290;ST-JEMA&#37319;&#29992;&#20102;&#19968;&#31181;&#21463;JEPA&#21551;&#21457;&#30340;&#31574;&#30053;&#26469;&#37325;&#26500;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06432v1 Announce Type: new  Abstract: Graph Neural Networks (GNNs) have shown promise in learning dynamic functional connectivity for distinguishing phenotypes from human brain networks. However, obtaining extensive labeled clinical data for training is often resource-intensive, making practical application difficult. Leveraging unlabeled data thus becomes crucial for representation learning in a label-scarce setting. Although generative self-supervised learning techniques, especially masked autoencoders, have shown promising results in representation learning in various domains, their application to dynamic graphs for dynamic functional connectivity remains underexplored, facing challenges in capturing high-level semantic representations. Here, we introduce the Spatio-Temporal Joint Embedding Masked Autoencoder (ST-JEMA), drawing inspiration from the Joint Embedding Predictive Architecture (JEPA) in computer vision. ST-JEMA employs a JEPA-inspired strategy for reconstructin
&lt;/p&gt;</description></item></channel></rss>