<rss version="2.0"><channel><title>Chat Arxiv q-bio</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for q-bio</description><item><title>FABind+&#36890;&#36807;&#25913;&#36827;&#21475;&#34955;&#39044;&#27979;&#21644;&#23039;&#24577;&#29983;&#25104;&#65292;&#25552;&#21319;&#20998;&#23376;&#23545;&#25509;&#34920;&#29616;</title><link>https://arxiv.org/abs/2403.20261</link><description>&lt;p&gt;
FABind+: &#36890;&#36807;&#25913;&#36827;&#21475;&#34955;&#39044;&#27979;&#21644;&#23039;&#24577;&#29983;&#25104;&#22686;&#24378;&#20998;&#23376;&#23545;&#25509;
&lt;/p&gt;
&lt;p&gt;
FABind+: Enhancing Molecular Docking through Improved Pocket Prediction and Pose Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.20261
&lt;/p&gt;
&lt;p&gt;
FABind+&#36890;&#36807;&#25913;&#36827;&#21475;&#34955;&#39044;&#27979;&#21644;&#23039;&#24577;&#29983;&#25104;&#65292;&#25552;&#21319;&#20998;&#23376;&#23545;&#25509;&#34920;&#29616;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#23376;&#23545;&#25509;&#26159;&#33647;&#29289;&#21457;&#29616;&#20013;&#33267;&#20851;&#37325;&#35201;&#30340;&#36807;&#31243;&#12290;&#20256;&#32479;&#25216;&#26415;&#20381;&#36182;&#20110;&#21463;&#29289;&#29702;&#21407;&#29702;&#25903;&#37197;&#30340;&#24191;&#27867;&#37319;&#26679;&#21644;&#27169;&#25311;&#65292;&#20294;&#36825;&#20123;&#26041;&#27861;&#24448;&#24448;&#36895;&#24230;&#24930;&#19988;&#26114;&#36149;&#12290;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#30340;&#20986;&#29616;&#26174;&#31034;&#20986;&#26174;&#33879;&#30340;&#21069;&#26223;&#65292;&#25552;&#20379;&#20102;&#31934;&#30830;&#24615;&#21644;&#25928;&#29575;&#30340;&#22686;&#38271;&#12290;&#24314;&#31435;&#22312;FABind&#30340;&#22522;&#30784;&#24037;&#20316;&#20043;&#19978;&#65292;&#36825;&#26159;&#19968;&#20010;&#19987;&#27880;&#20110;&#36895;&#24230;&#21644;&#20934;&#30830;&#24615;&#30340;&#27169;&#22411;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;FABind+&#65292;&#36825;&#26159;&#19968;&#20010;&#22823;&#22823;&#25552;&#21319;&#20854;&#21069;&#36523;&#24615;&#33021;&#30340;&#22686;&#24378;&#29256;&#12290;&#25105;&#20204;&#30830;&#23450;&#21475;&#34955;&#39044;&#27979;&#26159;&#20998;&#23376;&#23545;&#25509;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#29942;&#39048;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26174;&#33879;&#25913;&#36827;&#21475;&#34955;&#39044;&#27979;&#30340;&#26032;&#26041;&#27861;&#65292;&#20174;&#32780;&#31616;&#21270;&#20102;&#23545;&#25509;&#36807;&#31243;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23545;&#23545;&#25509;&#27169;&#22359;&#36827;&#34892;&#20102;&#20462;&#25913;&#65292;&#20197;&#22686;&#24378;&#20854;&#23039;&#24577;&#29983;&#25104;&#33021;&#21147;&#12290;&#20026;&#20102;&#32553;&#23567;&#19982;&#20256;&#32479;&#37319;&#26679;/&#29983;&#25104;&#26041;&#27861;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#25105;&#20204;&#32467;&#21512;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;s
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.20261v1 Announce Type: cross  Abstract: Molecular docking is a pivotal process in drug discovery. While traditional techniques rely on extensive sampling and simulation governed by physical principles, these methods are often slow and costly. The advent of deep learning-based approaches has shown significant promise, offering increases in both accuracy and efficiency. Building upon the foundational work of FABind, a model designed with a focus on speed and accuracy, we present FABind+, an enhanced iteration that largely boosts the performance of its predecessor. We identify pocket prediction as a critical bottleneck in molecular docking and propose a novel methodology that significantly refines pocket prediction, thereby streamlining the docking process. Furthermore, we introduce modifications to the docking module to enhance its pose generation capabilities. In an effort to bridge the gap with conventional sampling/generative methods, we incorporate a simple yet effective s
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#21521;&#22270;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;BGGAN&#65289;&#65292;&#29992;&#20110;&#34920;&#31034;&#38463;&#23572;&#33576;&#28023;&#40664;&#30149;&#65288;AD&#65289;&#30340;&#33041;&#32467;&#26500;-&#21151;&#33021;&#36830;&#25509;&#12290;&#36890;&#36807;&#29305;&#27530;&#35774;&#35745;&#30340;&#20869;&#37096;&#22270;&#21367;&#31215;&#32593;&#32476;&#27169;&#22359;&#21644;&#24179;&#34913;&#22120;&#27169;&#22359;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#20934;&#30830;&#22320;&#23398;&#20064;&#32467;&#26500;&#22495;&#21644;&#21151;&#33021;&#22495;&#20043;&#38388;&#30340;&#26144;&#23556;&#20989;&#25968;&#65292;&#24182;&#35299;&#20915;&#27169;&#24335;&#22349;&#22604;&#38382;&#39064;&#65292;&#21516;&#26102;&#23398;&#20064;&#32467;&#26500;&#21644;&#21151;&#33021;&#29305;&#24449;&#30340;&#20114;&#34917;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.08916</link><description>&lt;p&gt;
&#21452;&#21521;&#22270;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65306;&#29992;&#20110;&#38463;&#23572;&#33576;&#28023;&#40664;&#30149;&#30340;&#33041;&#32467;&#26500;-&#21151;&#33021;&#36830;&#25509;&#30340;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Bidirectional Graph GAN: Representing Brain Structure-Function Connections for Alzheimer's Disease. (arXiv:2309.08916v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08916
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#21521;&#22270;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;BGGAN&#65289;&#65292;&#29992;&#20110;&#34920;&#31034;&#38463;&#23572;&#33576;&#28023;&#40664;&#30149;&#65288;AD&#65289;&#30340;&#33041;&#32467;&#26500;-&#21151;&#33021;&#36830;&#25509;&#12290;&#36890;&#36807;&#29305;&#27530;&#35774;&#35745;&#30340;&#20869;&#37096;&#22270;&#21367;&#31215;&#32593;&#32476;&#27169;&#22359;&#21644;&#24179;&#34913;&#22120;&#27169;&#22359;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#20934;&#30830;&#22320;&#23398;&#20064;&#32467;&#26500;&#22495;&#21644;&#21151;&#33021;&#22495;&#20043;&#38388;&#30340;&#26144;&#23556;&#20989;&#25968;&#65292;&#24182;&#35299;&#20915;&#27169;&#24335;&#22349;&#22604;&#38382;&#39064;&#65292;&#21516;&#26102;&#23398;&#20064;&#32467;&#26500;&#21644;&#21151;&#33021;&#29305;&#24449;&#30340;&#20114;&#34917;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25581;&#31034;&#33041;&#30142;&#30149;&#30340;&#21457;&#30149;&#26426;&#21046;&#65292;&#21253;&#25324;&#38463;&#23572;&#33576;&#28023;&#40664;&#30149;&#65288;AD&#65289;&#65292;&#33041;&#32467;&#26500;&#19982;&#21151;&#33021;&#20043;&#38388;&#30340;&#20851;&#31995;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#21508;&#31181;&#21407;&#22240;&#65292;&#23558;&#33041;&#32467;&#26500;-&#21151;&#33021;&#36830;&#25509;&#26144;&#23556;&#26159;&#19968;&#20010;&#24040;&#22823;&#30340;&#25361;&#25112;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#21521;&#22270;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;BGGAN&#65289;&#26469;&#34920;&#31034;&#33041;&#32467;&#26500;-&#21151;&#33021;&#36830;&#25509;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#36890;&#36807;&#35774;&#35745;&#19968;&#20010;&#20869;&#37096;&#22270;&#21367;&#31215;&#32593;&#32476;&#65288;InnerGCN&#65289;&#27169;&#22359;&#65292;BGGAN&#30340;&#29983;&#25104;&#22120;&#21487;&#20197;&#21033;&#29992;&#30452;&#25509;&#21644;&#38388;&#25509;&#33041;&#21306;&#22495;&#30340;&#29305;&#24449;&#26469;&#23398;&#20064;&#32467;&#26500;&#22495;&#21644;&#21151;&#33021;&#22495;&#20043;&#38388;&#30340;&#26144;&#23556;&#20989;&#25968;&#12290;&#27492;&#22806;&#65292;&#36824;&#35774;&#35745;&#20102;&#19968;&#20010;&#21517;&#20026;Balancer&#30340;&#26032;&#27169;&#22359;&#26469;&#24179;&#34913;&#29983;&#25104;&#22120;&#21644;&#21028;&#21035;&#22120;&#20043;&#38388;&#30340;&#20248;&#21270;&#12290;&#36890;&#36807;&#23558;Balancer&#24341;&#20837;&#21040;BGGAN&#20013;&#65292;&#32467;&#26500;&#29983;&#25104;&#22120;&#21644;&#21151;&#33021;&#29983;&#25104;&#22120;&#19981;&#20165;&#21487;&#20197;&#32531;&#35299;&#27169;&#24335;&#22349;&#22604;&#38382;&#39064;&#65292;&#36824;&#21487;&#20197;&#23398;&#20064;&#32467;&#26500;&#21644;&#21151;&#33021;&#29305;&#24449;&#30340;&#20114;&#34917;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#33021;&#22815;&#22312;AD&#20013;&#20934;&#30830;&#22320;&#34920;&#31034;&#33041;&#32467;&#26500;-&#21151;&#33021;&#36830;&#25509;&#12290;
&lt;/p&gt;
&lt;p&gt;
The relationship between brain structure and function is critical for revealing the pathogenesis of brain disease, including Alzheimer's disease (AD). However, it is a great challenge to map brain structure-function connections due to various reasons. In this work, a bidirectional graph generative adversarial networks (BGGAN) is proposed to represent brain structure-function connections. Specifically, by designing a module incorporating inner graph convolution network (InnerGCN), the generators of BGGAN can employ features of direct and indirect brain regions to learn the mapping function between structural domain and functional domain. Besides, a new module named Balancer is designed to counterpoise the optimization between generators and discriminators. By introducing the Balancer into BGGAN, both the structural generator and functional generator can not only alleviate the issue of mode collapse but also learn complementarity of structural and functional features. Experimental result
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;MIML&#65292;&#35813;&#26694;&#26550;&#36890;&#36807;&#23558;&#26080;&#26631;&#35760;&#32454;&#32990;&#22270;&#20687;&#19982;&#29983;&#29289;&#21147;&#23398;&#23646;&#24615;&#25968;&#25454;&#30456;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#39640;&#31934;&#24230;&#32454;&#32990;&#20998;&#31867;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#20102;&#24418;&#24577;&#20449;&#24687;&#65292;&#23558;&#32454;&#32990;&#23646;&#24615;&#29702;&#35299;&#24471;&#26356;&#20840;&#38754;&#65292;&#30456;&#36739;&#20110;&#20165;&#32771;&#34385;&#21333;&#19968;&#25968;&#25454;&#31867;&#22411;&#30340;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;98.3&#65285;&#30340;&#20998;&#31867;&#31934;&#24230;&#12290;&#35813;&#26041;&#27861;&#24050;&#22312;&#30333;&#32454;&#32990;&#21644;&#32959;&#30244;&#32454;&#32990;&#20998;&#31867;&#20013;&#24471;&#21040;&#35777;&#26126;&#65292;&#24182;&#20855;&#26377;&#26356;&#24191;&#27867;&#30340;&#24212;&#29992;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2309.08421</link><description>&lt;p&gt;
MIML: &#36890;&#36807;&#24494;&#27969;&#25511;&#31995;&#32479;&#20869;&#30340;&#26426;&#26800;&#29305;&#24615;&#23545;&#39640;&#31934;&#24230;&#32454;&#32990;&#20998;&#31867;&#36827;&#34892;&#22810;&#37325;&#22270;&#20687;&#26426;&#22120;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
MIML: Multiplex Image Machine Learning for High Precision Cell Classification via Mechanical Traits within Microfluidic Systems. (arXiv:2309.08421v1 [eess.IV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08421
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;MIML&#65292;&#35813;&#26694;&#26550;&#36890;&#36807;&#23558;&#26080;&#26631;&#35760;&#32454;&#32990;&#22270;&#20687;&#19982;&#29983;&#29289;&#21147;&#23398;&#23646;&#24615;&#25968;&#25454;&#30456;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#39640;&#31934;&#24230;&#32454;&#32990;&#20998;&#31867;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#20102;&#24418;&#24577;&#20449;&#24687;&#65292;&#23558;&#32454;&#32990;&#23646;&#24615;&#29702;&#35299;&#24471;&#26356;&#20840;&#38754;&#65292;&#30456;&#36739;&#20110;&#20165;&#32771;&#34385;&#21333;&#19968;&#25968;&#25454;&#31867;&#22411;&#30340;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;98.3&#65285;&#30340;&#20998;&#31867;&#31934;&#24230;&#12290;&#35813;&#26041;&#27861;&#24050;&#22312;&#30333;&#32454;&#32990;&#21644;&#32959;&#30244;&#32454;&#32990;&#20998;&#31867;&#20013;&#24471;&#21040;&#35777;&#26126;&#65292;&#24182;&#20855;&#26377;&#26356;&#24191;&#27867;&#30340;&#24212;&#29992;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#26631;&#35760;&#32454;&#32990;&#20998;&#31867;&#26377;&#21161;&#20110;&#20026;&#36827;&#19968;&#27493;&#20351;&#29992;&#25110;&#26816;&#26597;&#25552;&#20379;&#21407;&#22987;&#32454;&#32990;&#65292;&#28982;&#32780;&#29616;&#26377;&#25216;&#26415;&#22312;&#29305;&#24322;&#24615;&#21644;&#36895;&#24230;&#26041;&#38754;&#24448;&#24448;&#19981;&#36275;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#24320;&#21457;&#19968;&#31181;&#26032;&#39062;&#30340;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;MIML&#26469;&#35299;&#20915;&#36825;&#20123;&#23616;&#38480;&#24615;&#12290;&#35813;&#26550;&#26500;&#23558;&#26080;&#26631;&#35760;&#32454;&#32990;&#22270;&#20687;&#19982;&#29983;&#29289;&#21147;&#23398;&#23646;&#24615;&#25968;&#25454;&#30456;&#32467;&#21512;&#65292;&#21033;&#29992;&#27599;&#20010;&#32454;&#32990;&#22266;&#26377;&#30340;&#24191;&#38420;&#19988;&#24120;&#24120;&#34987;&#20302;&#20272;&#30340;&#24418;&#24577;&#20449;&#24687;&#12290;&#36890;&#36807;&#25972;&#21512;&#36825;&#20004;&#31181;&#31867;&#22411;&#30340;&#25968;&#25454;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#25552;&#20379;&#20102;&#23545;&#32454;&#32990;&#23646;&#24615;&#26356;&#20840;&#38754;&#30340;&#29702;&#35299;&#65292;&#21033;&#29992;&#20102;&#20256;&#32479;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#36890;&#24120;&#34987;&#20002;&#24323;&#30340;&#24418;&#24577;&#20449;&#24687;&#12290;&#36825;&#31181;&#26041;&#27861;&#20351;&#32454;&#32990;&#20998;&#31867;&#31934;&#24230;&#36798;&#21040;&#20102;&#24778;&#20154;&#30340;98.3&#65285;&#65292;&#22823;&#22823;&#20248;&#20110;&#20165;&#32771;&#34385;&#21333;&#19968;&#25968;&#25454;&#31867;&#22411;&#30340;&#27169;&#22411;&#12290;MIML&#24050;&#34987;&#35777;&#26126;&#22312;&#30333;&#32454;&#32990;&#21644;&#32959;&#30244;&#32454;&#32990;&#20998;&#31867;&#20013;&#26377;&#25928;&#65292;&#24182;&#20855;&#26377;&#26356;&#24191;&#27867;&#30340;&#24212;&#29992;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Label-free cell classification is advantageous for supplying pristine cells for further use or examination, yet existing techniques frequently fall short in terms of specificity and speed. In this study, we address these limitations through the development of a novel machine learning framework, Multiplex Image Machine Learning (MIML). This architecture uniquely combines label-free cell images with biomechanical property data, harnessing the vast, often underutilized morphological information intrinsic to each cell. By integrating both types of data, our model offers a more holistic understanding of the cellular properties, utilizing morphological information typically discarded in traditional machine learning models. This approach has led to a remarkable 98.3\% accuracy in cell classification, a substantial improvement over models that only consider a single data type. MIML has been proven effective in classifying white blood cells and tumor cells, with potential for broader applicatio
&lt;/p&gt;</description></item></channel></rss>