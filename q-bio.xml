<rss version="2.0"><channel><title>Chat Arxiv q-bio</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for q-bio</description><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;&#27604;&#33258;&#30417;&#30563;&#23398;&#20064;&#24212;&#29992;&#20110;1D&#24515;&#38899;&#22270;&#26679;&#26412;&#20013;&#24322;&#24120;&#26816;&#27979;&#65292;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#38899;&#39057;&#22686;&#24378;&#26041;&#27861;&#27604;&#36739;&#35780;&#20272;&#21644;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#20998;&#31867;&#22120;&#30340;&#30740;&#31350;&#12290;</title><link>https://arxiv.org/abs/2312.00502</link><description>&lt;p&gt;
&#23545;&#31283;&#20581;&#30340;OOD&#33258;&#30417;&#30563;&#23545;&#27604;&#24515;&#38899;&#22270;&#34920;&#31034;&#23398;&#20064;&#22686;&#24378;&#26041;&#27861;&#30340;&#20840;&#38754;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
A Comprehensive Evaluation of Augmentations for Robust OOD Self-Supervised Contrastive Phonocardiogram Representation Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.00502
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;&#27604;&#33258;&#30417;&#30563;&#23398;&#20064;&#24212;&#29992;&#20110;1D&#24515;&#38899;&#22270;&#26679;&#26412;&#20013;&#24322;&#24120;&#26816;&#27979;&#65292;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#38899;&#39057;&#22686;&#24378;&#26041;&#27861;&#27604;&#36739;&#35780;&#20272;&#21644;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#20998;&#31867;&#22120;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#36817;&#24180;&#26469;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#30740;&#31350;&#27963;&#21160;&#26377;&#25152;&#22686;&#21152;&#65292;&#20294;&#22312;&#21307;&#23398;&#31561;&#22810;&#20010;&#29616;&#23454;&#19990;&#30028;&#29615;&#22659;&#20013;&#65292;&#36825;&#20123;&#27169;&#22411;&#23578;&#26410;&#34987;&#24191;&#27867;&#25509;&#21463;&#12290;&#39640;&#36136;&#37327;&#26631;&#35760;&#25968;&#25454;&#30340;&#30701;&#32570;&#32463;&#24120;&#38459;&#30861;&#20102;&#24320;&#21457;&#31283;&#20581;&#19988;&#20855;&#26377;&#19968;&#33324;&#24615;&#30340;&#27169;&#22411;&#65292;&#24403;&#38754;&#20020;&#26032;&#25910;&#38598;&#30340;&#36229;&#20986;&#20998;&#24067;&#65288;OOD&#65289;&#25968;&#25454;&#38598;&#26102;&#65292;&#36825;&#20123;&#27169;&#22411;&#19981;&#20250;&#22240;&#25928;&#26524;&#19979;&#38477;&#32780;&#21463;&#25439;&#12290;&#23545;&#27604;&#33258;&#30417;&#30563;&#23398;&#20064;&#65288;SSL&#65289;&#20026;&#26631;&#35760;&#25968;&#25454;&#31232;&#32570;&#24615;&#25552;&#20379;&#20102;&#28508;&#22312;&#35299;&#20915;&#26041;&#26696;&#65292;&#22240;&#20026;&#23427;&#21033;&#29992;&#26410;&#26631;&#35760;&#25968;&#25454;&#22686;&#21152;&#27169;&#22411;&#30340;&#25928;&#33021;&#21644;&#31283;&#20581;&#24615;&#12290;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#23558;&#23545;&#27604;SSL&#24212;&#29992;&#20110;&#26816;&#27979;1D&#24515;&#38899;&#22270;&#65288;PCG&#65289;&#26679;&#26412;&#20013;&#30340;&#24322;&#24120;&#65292;&#36890;&#36807;&#23398;&#20064;&#20449;&#21495;&#30340;&#24191;&#20041;&#34920;&#31034;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#39033;&#24191;&#27867;&#30340;&#27604;&#36739;&#35780;&#20272;&#65292;&#28041;&#21450;&#22810;&#31181;&#22522;&#20110;&#38899;&#39057;&#30340;&#22686;&#24378;&#26041;&#27861;&#65292;&#35780;&#20272;&#20102;&#22312;&#19981;&#21516;&#19979;&#28216;&#20219;&#21153;&#30340;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#20998;&#31867;&#22120;&#65292;&#26368;&#32456;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.00502v2 Announce Type: replace  Abstract: Despite the recent increase in research activity, deep-learning models have not yet been widely accepted in several real-world settings, such as medicine. The shortage of high-quality annotated data often hinders the development of robust and generalizable models, which do not suffer from degraded effectiveness when presented with newly-collected, out-of-distribution (OOD) datasets. Contrastive Self-Supervised Learning (SSL) offers a potential solution to labeled data scarcity, as it takes advantage of unlabeled data to increase model effectiveness and robustness. In this research, we propose applying contrastive SSL for detecting abnormalities in 1D phonocardiogram (PCG) samples by learning a generalized representation of the signal. Specifically, we perform an extensive comparative evaluation of a wide range of audio-based augmentations, evaluate trained classifiers on multiple datasets across different downstream tasks, and finall
&lt;/p&gt;</description></item></channel></rss>