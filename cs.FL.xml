<rss version="2.0"><channel><title>Chat Arxiv cs.FL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.FL</description><item><title>&#36890;&#36807;&#23558;&#21464;&#21387;&#22120;&#19982;&#26377;&#38480;&#20256;&#24863;&#22120;&#32852;&#31995;&#36215;&#26469;&#65292;&#25105;&#20204;&#21457;&#29616;&#23427;&#20204;&#21487;&#20197;&#34920;&#36798;&#20196;&#20154;&#24778;&#35766;&#30340;&#22823;&#31867;&#20256;&#24863;&#65292;&#36827;&#19968;&#27493;&#25193;&#23637;&#20102;RASP&#65292;&#25512;&#20986;&#20102;&#26032;&#30340;&#21464;&#20307;&#65292;&#24182;&#23637;&#31034;&#20102;&#25513;&#30721;&#24179;&#22343;&#22256;&#38590;&#27880;&#24847;&#21464;&#21387;&#22120;&#21487;&#20197;&#27169;&#25311;S-RASP.</title><link>https://arxiv.org/abs/2404.02040</link><description>&lt;p&gt;
&#21464;&#21387;&#22120;&#20316;&#20026;&#20256;&#24863;&#22120;
&lt;/p&gt;
&lt;p&gt;
Transformers as Transducers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02040
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23558;&#21464;&#21387;&#22120;&#19982;&#26377;&#38480;&#20256;&#24863;&#22120;&#32852;&#31995;&#36215;&#26469;&#65292;&#25105;&#20204;&#21457;&#29616;&#23427;&#20204;&#21487;&#20197;&#34920;&#36798;&#20196;&#20154;&#24778;&#35766;&#30340;&#22823;&#31867;&#20256;&#24863;&#65292;&#36827;&#19968;&#27493;&#25193;&#23637;&#20102;RASP&#65292;&#25512;&#20986;&#20102;&#26032;&#30340;&#21464;&#20307;&#65292;&#24182;&#23637;&#31034;&#20102;&#25513;&#30721;&#24179;&#22343;&#22256;&#38590;&#27880;&#24847;&#21464;&#21387;&#22120;&#21487;&#20197;&#27169;&#25311;S-RASP.
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36890;&#36807;&#23558;&#21464;&#21387;&#22120;&#19982;&#26377;&#38480;&#20256;&#24863;&#22120;&#32852;&#31995;&#36215;&#26469;&#65292;&#30740;&#31350;&#20102;&#21464;&#21387;&#22120;&#30340;&#24207;&#21015;&#21040;&#24207;&#21015;&#26144;&#23556;&#33021;&#21147;&#65292;&#24182;&#21457;&#29616;&#23427;&#20204;&#21487;&#20197;&#34920;&#36798;&#20196;&#20154;&#24778;&#35766;&#30340;&#22823;&#31867;&#20256;&#24863;&#12290;&#25105;&#20204;&#20351;&#29992;RASP&#30340;&#21464;&#20307;&#65292;&#36825;&#26159;&#19968;&#31181;&#26088;&#22312;&#24110;&#21161;&#20154;&#20204;&#8220;&#20687;&#21464;&#21387;&#22120;&#19968;&#26679;&#24605;&#32771;&#8221;&#30340;&#32534;&#31243;&#35821;&#35328;&#65292;&#20316;&#20026;&#20013;&#38388;&#34920;&#31034;&#12290;&#25105;&#20204;&#25193;&#23637;&#20102;&#29616;&#26377;&#30340;&#24067;&#23572;&#21464;&#20307;B-RASP&#21040;&#24207;&#21015;&#21040;&#24207;&#21015;&#20989;&#25968;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#30830;&#20999;&#35745;&#31639;&#20102;&#19968;&#38454;&#26377;&#29702;&#20989;&#25968;&#65288;&#22914;&#23383;&#31526;&#20018;&#26059;&#36716;&#65289;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#20010;&#26032;&#25193;&#23637;&#12290;B-RASP[pos]&#20801;&#35768;&#22312;&#20301;&#32622;&#19978;&#36827;&#34892;&#35745;&#31639;&#65288;&#22914;&#22797;&#21046;&#23383;&#31526;&#20018;&#30340;&#21069;&#21322;&#37096;&#20998;&#65289;&#65292;&#24182;&#21253;&#21547;&#25152;&#26377;&#19968;&#38454;&#27491;&#21017;&#20989;&#25968;&#12290;S-RASP&#28155;&#21152;&#21069;&#32512;&#21644;&#65292;&#21487;&#20197;&#36827;&#34892;&#39069;&#22806;&#30340;&#31639;&#26415;&#25805;&#20316;&#65288;&#22914;&#23545;&#23383;&#31526;&#20018;&#27714;&#24179;&#26041;&#65289;&#65292;&#24182;&#21253;&#21547;&#25152;&#26377;&#19968;&#38454;&#22810;&#27491;&#21017;&#20989;&#25968;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25513;&#30721;&#24179;&#22343;&#22256;&#38590;&#27880;&#24847;&#21464;&#21387;&#22120;&#21487;&#20197;&#27169;&#25311;S-RASP&#12290;&#25105;&#20204;&#32467;&#26524;&#30340;&#19968;&#20010;&#25512;&#35770;&#26159;n...
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02040v1 Announce Type: cross  Abstract: We study the sequence-to-sequence mapping capacity of transformers by relating them to finite transducers, and find that they can express surprisingly large classes of transductions. We do so using variants of RASP, a programming language designed to help people "think like transformers," as an intermediate representation. We extend the existing Boolean variant B-RASP to sequence-to-sequence functions and show that it computes exactly the first-order rational functions (such as string rotation). Then, we introduce two new extensions. B-RASP[pos] enables calculations on positions (such as copying the first half of a string) and contains all first-order regular functions. S-RASP adds prefix sum, which enables additional arithmetic operations (such as squaring a string) and contains all first-order polyregular functions. Finally, we show that masked average-hard attention transformers can simulate S-RASP. A corollary of our results is a n
&lt;/p&gt;</description></item><item><title>SynCode&#26159;&#19968;&#20010;&#26032;&#26694;&#26550;&#65292;&#32467;&#21512;&#32534;&#31243;&#35821;&#35328;&#30340;&#35821;&#27861;&#21644;DFA mask store&#65292;&#22312;LLMs&#20013;&#29983;&#25104;&#20195;&#30721;&#36807;&#31243;&#20013;&#33719;&#24471;96.07%&#30340;&#21477;&#27861;&#38169;&#35823;&#38477;&#20302;&#65292;&#24182;&#23637;&#29616;&#20986;&#25552;&#39640;&#21477;&#27861;&#31934;&#24230;&#30340;&#37325;&#22823;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2403.01632</link><description>&lt;p&gt;
&#36890;&#36807;&#35821;&#27861;&#22686;&#24378;&#25913;&#36827;LLM&#20195;&#30721;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Improving LLM Code Generation with Grammar Augmentation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01632
&lt;/p&gt;
&lt;p&gt;
SynCode&#26159;&#19968;&#20010;&#26032;&#26694;&#26550;&#65292;&#32467;&#21512;&#32534;&#31243;&#35821;&#35328;&#30340;&#35821;&#27861;&#21644;DFA mask store&#65292;&#22312;LLMs&#20013;&#29983;&#25104;&#20195;&#30721;&#36807;&#31243;&#20013;&#33719;&#24471;96.07%&#30340;&#21477;&#27861;&#38169;&#35823;&#38477;&#20302;&#65292;&#24182;&#23637;&#29616;&#20986;&#25552;&#39640;&#21477;&#27861;&#31934;&#24230;&#30340;&#37325;&#22823;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102; SynCode&#65292;&#19968;&#20010;&#29992;&#20110;&#39640;&#25928;&#21644;&#36890;&#29992;&#22320;&#35299;&#30721;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20195;&#30721;&#30340;&#26032;&#26694;&#26550;&#12290;SynCode&#21033;&#29992;&#32534;&#31243;&#35821;&#35328;&#30340;&#35821;&#27861;&#65292;&#21033;&#29992;&#31163;&#32447;&#26500;&#24314;&#30340;&#22522;&#20110;&#35821;&#35328;&#35821;&#27861;&#32456;&#32467;&#31526;&#30340;&#39640;&#25928;&#26597;&#25214;&#34920;DFA mask store&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;SynCode&#22312;&#32473;&#23450;&#32534;&#31243;&#35821;&#35328;&#30340;&#19978;&#19979;&#25991;&#26080;&#20851;&#25991;&#27861;&#65288;CFG&#65289;&#30340;&#23436;&#22791;&#24615;&#21644;&#27491;&#30830;&#24615;&#65292;&#23637;&#31034;&#20854;&#22312;&#20445;&#30041;&#35821;&#20041;&#19978;&#26377;&#25928;&#20196;&#29260;&#30340;&#21516;&#26102;&#25298;&#32477;&#26080;&#25928;&#20196;&#29260;&#30340;&#33021;&#21147;&#12290;&#35813;&#26694;&#26550;&#19982;&#30001;CFG&#23450;&#20041;&#30340;&#20219;&#20309;&#35821;&#35328;&#26080;&#32541;&#38598;&#25104;&#65292;&#39564;&#35777;&#20102;&#38024;&#23545;Python&#21644;Go&#30340;CFG&#23454;&#39564;&#12290;&#32467;&#26524;&#31361;&#20986;&#20102;&#24403;SynCode&#19982;&#26368;&#20808;&#36827;&#30340;LLMs&#32467;&#21512;&#26102;&#65292;&#35821;&#27861;&#38169;&#35823;&#20943;&#23569;96.07%&#65292;&#24432;&#26174;&#20102;&#20854;&#23545;&#25552;&#39640;&#20195;&#30721;&#29983;&#25104;&#20013;&#30340;&#21477;&#27861;&#31934;&#24230;&#30340;&#37325;&#22823;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01632v1 Announce Type: new  Abstract: We present SynCode a novel framework for efficient and general syntactical decoding of code with large language models (LLMs). SynCode leverages the grammar of a programming language, utilizing an offline-constructed efficient lookup table called DFA mask store based on language grammar terminals. We demonstrate SynCode's soundness and completeness given the context-free grammar (CFG) of the programming language, presenting its ability to retain syntactically valid tokens while rejecting invalid ones. The framework seamlessly integrates with any language defined by CFG, as evidenced by experiments on CFGs for Python and Go. The results underscore the significant reduction of 96.07% of syntax errors achieved when SynCode is combined with state-of-the-art LLMs, showcasing its substantial impact on enhancing syntactical precision in code generation.   Our code is available at https://github.com/uiuc-focal-lab/syncode.
&lt;/p&gt;</description></item></channel></rss>