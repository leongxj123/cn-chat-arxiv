<rss version="2.0"><channel><title>Chat Arxiv cs.FL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.FL</description><item><title>&#36890;&#36807;&#23558;&#21464;&#21387;&#22120;&#19982;&#26377;&#38480;&#20256;&#24863;&#22120;&#32852;&#31995;&#36215;&#26469;&#65292;&#25105;&#20204;&#21457;&#29616;&#23427;&#20204;&#21487;&#20197;&#34920;&#36798;&#20196;&#20154;&#24778;&#35766;&#30340;&#22823;&#31867;&#20256;&#24863;&#65292;&#36827;&#19968;&#27493;&#25193;&#23637;&#20102;RASP&#65292;&#25512;&#20986;&#20102;&#26032;&#30340;&#21464;&#20307;&#65292;&#24182;&#23637;&#31034;&#20102;&#25513;&#30721;&#24179;&#22343;&#22256;&#38590;&#27880;&#24847;&#21464;&#21387;&#22120;&#21487;&#20197;&#27169;&#25311;S-RASP.</title><link>https://arxiv.org/abs/2404.02040</link><description>&lt;p&gt;
&#21464;&#21387;&#22120;&#20316;&#20026;&#20256;&#24863;&#22120;
&lt;/p&gt;
&lt;p&gt;
Transformers as Transducers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02040
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23558;&#21464;&#21387;&#22120;&#19982;&#26377;&#38480;&#20256;&#24863;&#22120;&#32852;&#31995;&#36215;&#26469;&#65292;&#25105;&#20204;&#21457;&#29616;&#23427;&#20204;&#21487;&#20197;&#34920;&#36798;&#20196;&#20154;&#24778;&#35766;&#30340;&#22823;&#31867;&#20256;&#24863;&#65292;&#36827;&#19968;&#27493;&#25193;&#23637;&#20102;RASP&#65292;&#25512;&#20986;&#20102;&#26032;&#30340;&#21464;&#20307;&#65292;&#24182;&#23637;&#31034;&#20102;&#25513;&#30721;&#24179;&#22343;&#22256;&#38590;&#27880;&#24847;&#21464;&#21387;&#22120;&#21487;&#20197;&#27169;&#25311;S-RASP.
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36890;&#36807;&#23558;&#21464;&#21387;&#22120;&#19982;&#26377;&#38480;&#20256;&#24863;&#22120;&#32852;&#31995;&#36215;&#26469;&#65292;&#30740;&#31350;&#20102;&#21464;&#21387;&#22120;&#30340;&#24207;&#21015;&#21040;&#24207;&#21015;&#26144;&#23556;&#33021;&#21147;&#65292;&#24182;&#21457;&#29616;&#23427;&#20204;&#21487;&#20197;&#34920;&#36798;&#20196;&#20154;&#24778;&#35766;&#30340;&#22823;&#31867;&#20256;&#24863;&#12290;&#25105;&#20204;&#20351;&#29992;RASP&#30340;&#21464;&#20307;&#65292;&#36825;&#26159;&#19968;&#31181;&#26088;&#22312;&#24110;&#21161;&#20154;&#20204;&#8220;&#20687;&#21464;&#21387;&#22120;&#19968;&#26679;&#24605;&#32771;&#8221;&#30340;&#32534;&#31243;&#35821;&#35328;&#65292;&#20316;&#20026;&#20013;&#38388;&#34920;&#31034;&#12290;&#25105;&#20204;&#25193;&#23637;&#20102;&#29616;&#26377;&#30340;&#24067;&#23572;&#21464;&#20307;B-RASP&#21040;&#24207;&#21015;&#21040;&#24207;&#21015;&#20989;&#25968;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#30830;&#20999;&#35745;&#31639;&#20102;&#19968;&#38454;&#26377;&#29702;&#20989;&#25968;&#65288;&#22914;&#23383;&#31526;&#20018;&#26059;&#36716;&#65289;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#20010;&#26032;&#25193;&#23637;&#12290;B-RASP[pos]&#20801;&#35768;&#22312;&#20301;&#32622;&#19978;&#36827;&#34892;&#35745;&#31639;&#65288;&#22914;&#22797;&#21046;&#23383;&#31526;&#20018;&#30340;&#21069;&#21322;&#37096;&#20998;&#65289;&#65292;&#24182;&#21253;&#21547;&#25152;&#26377;&#19968;&#38454;&#27491;&#21017;&#20989;&#25968;&#12290;S-RASP&#28155;&#21152;&#21069;&#32512;&#21644;&#65292;&#21487;&#20197;&#36827;&#34892;&#39069;&#22806;&#30340;&#31639;&#26415;&#25805;&#20316;&#65288;&#22914;&#23545;&#23383;&#31526;&#20018;&#27714;&#24179;&#26041;&#65289;&#65292;&#24182;&#21253;&#21547;&#25152;&#26377;&#19968;&#38454;&#22810;&#27491;&#21017;&#20989;&#25968;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25513;&#30721;&#24179;&#22343;&#22256;&#38590;&#27880;&#24847;&#21464;&#21387;&#22120;&#21487;&#20197;&#27169;&#25311;S-RASP&#12290;&#25105;&#20204;&#32467;&#26524;&#30340;&#19968;&#20010;&#25512;&#35770;&#26159;n...
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02040v1 Announce Type: cross  Abstract: We study the sequence-to-sequence mapping capacity of transformers by relating them to finite transducers, and find that they can express surprisingly large classes of transductions. We do so using variants of RASP, a programming language designed to help people "think like transformers," as an intermediate representation. We extend the existing Boolean variant B-RASP to sequence-to-sequence functions and show that it computes exactly the first-order rational functions (such as string rotation). Then, we introduce two new extensions. B-RASP[pos] enables calculations on positions (such as copying the first half of a string) and contains all first-order regular functions. S-RASP adds prefix sum, which enables additional arithmetic operations (such as squaring a string) and contains all first-order polyregular functions. Finally, we show that masked average-hard attention transformers can simulate S-RASP. A corollary of our results is a n
&lt;/p&gt;</description></item></channel></rss>