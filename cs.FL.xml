<rss version="2.0"><channel><title>Chat Arxiv cs.FL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.FL</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026; $L^*LM$ &#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#21644;&#28436;&#31034;&#23398;&#20064; DFA&#65292;&#25552;&#39640;&#20102;&#25968;&#25454;&#25928;&#29575;&#65292;&#20855;&#22791;&#24378;&#22823;&#30340;&#23569;&#26679;&#26412;&#23398;&#20064;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.07051</link><description>&lt;p&gt;
$L^*LM$: &#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#23450;&#20041;&#31034;&#20363;&#23398;&#20064;&#33258;&#21160;&#26426;
&lt;/p&gt;
&lt;p&gt;
$L^*LM$: Learning Automata from Examples using Natural Language Oracles
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07051
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026; $L^*LM$ &#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#21644;&#28436;&#31034;&#23398;&#20064; DFA&#65292;&#25552;&#39640;&#20102;&#25968;&#25454;&#25928;&#29575;&#65292;&#20855;&#22791;&#24378;&#22823;&#30340;&#23569;&#26679;&#26412;&#23398;&#20064;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19987;&#23478;&#28436;&#31034;&#24050;&#34987;&#35777;&#26126;&#26159;&#31616;&#21270;&#38388;&#25509;&#25351;&#23450;&#22797;&#26434;&#20219;&#21153;&#30340;&#19968;&#31181;&#26041;&#27861;&#12290;&#26368;&#36817;&#30340;&#31639;&#27861;&#29978;&#33267;&#25903;&#25345;&#20174;&#28436;&#31034;&#20013;&#25552;&#21462;&#26126;&#30830;&#30340;&#24418;&#24335;&#35268;&#33539;&#65292;&#22914;&#30830;&#23450;&#24615;&#26377;&#38480;&#33258;&#21160;&#26426;&#65288;DFA&#65289;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#36825;&#20123;&#25216;&#26415;&#36890;&#24120;&#19981;&#20855;&#22791;&#39640;&#26679;&#26412;&#25928;&#29575;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026; $L^*LM$ &#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#20174;&#28436;&#31034;&#21644;&#33258;&#28982;&#35821;&#35328;&#20013;&#23398;&#20064; DFA&#12290;&#30001;&#20110;&#33258;&#28982;&#35821;&#35328;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#20174;&#19987;&#23478;&#28436;&#31034;&#20013;&#23398;&#20064; DFA &#30340;&#25968;&#25454;&#25928;&#29575;&#26174;&#33879;&#25552;&#39640;&#12290;&#20174;&#25216;&#26415;&#19978;&#35762;&#65292;$L^*LM$ &#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26469;&#22238;&#31572;&#20851;&#20110;&#24213;&#23618;&#20219;&#21153;&#30340;&#25104;&#21592;&#26597;&#35810;&#12290;&#28982;&#21518;&#23558;&#20854;&#19982;&#26368;&#36817;&#30340;&#28436;&#31034;&#23398;&#20064;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#23558;&#23398;&#20064;&#36716;&#21270;&#20026;&#19968;&#31995;&#21015;&#24102;&#26631;&#31614;&#31034;&#20363;&#23398;&#20064;&#38382;&#39064;&#12290;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#36825;&#20004;&#31181;&#27169;&#24577;&#30456;&#20114;&#34917;&#20805;&#65292;&#20174;&#32780;&#20135;&#29983;&#20102;&#19968;&#20010;&#24378;&#22823;&#30340;&#23569;&#26679;&#26412;&#23398;&#20064;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Expert demonstrations have proven an easy way to indirectly specify complex tasks. Recent algorithms even support extracting unambiguous formal specifications, e.g. deterministic finite automata (DFA), from demonstrations. Unfortunately, these techniques are generally not sample efficient. In this work, we introduce $L^*LM$, an algorithm for learning DFAs from both demonstrations and natural language. Due to the expressivity of natural language, we observe a significant improvement in the data efficiency of learning DFAs from expert demonstrations. Technically, $L^*LM$ leverages large language models to answer membership queries about the underlying task. This is then combined with recent techniques for transforming learning from demonstrations into a sequence of labeled example learning problems. In our experiments, we observe the two modalities complement each other, yielding a powerful few-shot learner.
&lt;/p&gt;</description></item></channel></rss>