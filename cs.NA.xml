<rss version="2.0"><channel><title>Chat Arxiv cs.NA</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NA</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#30340;&#22810;&#36830;&#32493;&#20307;&#27169;&#22411;&#65292;&#29992;&#20110;&#25913;&#36827;&#22810;&#23610;&#24230;&#38382;&#39064;&#20013;&#21333;&#19968;&#36830;&#32493;&#20307;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;</title><link>https://arxiv.org/abs/2403.14084</link><description>&lt;p&gt;
&#22522;&#20110;&#23398;&#20064;&#30340;&#22810;&#23380;&#20171;&#36136;&#27169;&#22411;&#29992;&#20110;&#22810;&#23610;&#24230;&#27969;&#21160;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Learning-based Multi-continuum Model for Multiscale Flow Problems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14084
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#30340;&#22810;&#36830;&#32493;&#20307;&#27169;&#22411;&#65292;&#29992;&#20110;&#25913;&#36827;&#22810;&#23610;&#24230;&#38382;&#39064;&#20013;&#21333;&#19968;&#36830;&#32493;&#20307;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#23610;&#24230;&#38382;&#39064;&#36890;&#24120;&#21487;&#20197;&#36890;&#36807;&#25968;&#20540;&#22343;&#36136;&#21270;&#26469;&#36817;&#20284;&#65292;&#36890;&#36807;&#20855;&#26377;&#26576;&#20123;&#26377;&#25928;&#21442;&#25968;&#30340;&#26041;&#31243;&#26469;&#25429;&#33719;&#21407;&#22987;&#31995;&#32479;&#22312;&#31895;&#32593;&#26684;&#19978;&#30340;&#23439;&#35266;&#34892;&#20026;&#65292;&#20197;&#21152;&#24555;&#27169;&#25311;&#36895;&#24230;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#36890;&#24120;&#20551;&#35774;&#23610;&#24230;&#20998;&#31163;&#65292;&#24182;&#19988;&#35299;&#30340;&#24322;&#36136;&#24615;&#21487;&#20197;&#36890;&#36807;&#27599;&#20010;&#31895;&#22359;&#20013;&#30340;&#35299;&#30340;&#24179;&#22343;&#20540;&#26469;&#36817;&#20284;&#12290;&#23545;&#20110;&#22797;&#26434;&#30340;&#22810;&#23610;&#24230;&#38382;&#39064;&#65292;&#35745;&#31639;&#30340;&#21333;&#19968;&#26377;&#25928;&#24615;&#29305;&#24615;/&#36830;&#32493;&#20307;&#21487;&#33021;&#19981;&#36275;&#22815;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#23398;&#20064;&#30340;&#22810;&#36830;&#32493;&#20307;&#27169;&#22411;&#65292;&#29992;&#20110;&#20016;&#23500;&#22343;&#36136;&#21270;&#26041;&#31243;&#24182;&#25552;&#39640;&#22810;&#23610;&#24230;&#38382;&#39064;&#21333;&#19968;&#36830;&#32493;&#20307;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#65292;&#32473;&#23450;&#19968;&#20123;&#25968;&#25454;&#12290;&#19981;&#22833;&#19968;&#33324;&#24615;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#21452;&#36830;&#32493;&#20307;&#30340;&#24773;&#20917;&#12290;&#31532;&#19968;&#20010;&#27969;&#21160;&#26041;&#31243;&#20445;&#30041;&#20102;&#21407;&#22987;&#22343;&#36136;&#21270;&#26041;&#31243;&#30340;&#20449;&#24687;&#65292;&#20855;&#26377;&#39069;&#22806;&#30340;&#20132;&#20114;&#39033;&#12290;&#31532;&#20108;&#20010;&#36830;&#32493;&#20307;&#26159;&#26032;&#24341;&#20837;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14084v1 Announce Type: cross  Abstract: Multiscale problems can usually be approximated through numerical homogenization by an equation with some effective parameters that can capture the macroscopic behavior of the original system on the coarse grid to speed up the simulation. However, this approach usually assumes scale separation and that the heterogeneity of the solution can be approximated by the solution average in each coarse block. For complex multiscale problems, the computed single effective properties/continuum might be inadequate. In this paper, we propose a novel learning-based multi-continuum model to enrich the homogenized equation and improve the accuracy of the single continuum model for multiscale problems with some given data. Without loss of generalization, we consider a two-continuum case. The first flow equation keeps the information of the original homogenized equation with an additional interaction term. The second continuum is newly introduced, and t
&lt;/p&gt;</description></item><item><title>DynGMA&#26041;&#27861;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#23494;&#24230;&#36817;&#20284;&#65292;&#20248;&#20110;&#22522;&#20934;&#26041;&#27861;&#22312;&#23398;&#20064;&#23436;&#20840;&#26410;&#30693;&#30340;&#28418;&#31227;&#21644;&#25193;&#25955;&#20989;&#25968;&#20197;&#21450;&#35745;&#31639;&#19981;&#21464;&#24615;&#26041;&#38754;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.14475</link><description>&lt;p&gt;
DynGMA&#65306;&#19968;&#31181;&#20174;&#25968;&#25454;&#23398;&#20064;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#31283;&#20581;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
DynGMA: a robust approach for learning stochastic differential equations from data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14475
&lt;/p&gt;
&lt;p&gt;
DynGMA&#26041;&#27861;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#23494;&#24230;&#36817;&#20284;&#65292;&#20248;&#20110;&#22522;&#20934;&#26041;&#27861;&#22312;&#23398;&#20064;&#23436;&#20840;&#26410;&#30693;&#30340;&#28418;&#31227;&#21644;&#25193;&#25955;&#20989;&#25968;&#20197;&#21450;&#35745;&#31639;&#19981;&#21464;&#24615;&#26041;&#38754;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#23398;&#20064;&#26410;&#30693;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDEs&#65289;&#26159;&#19968;&#39033;&#37325;&#35201;&#19988;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#24212;&#29992;&#20110;&#21508;&#20010;&#39046;&#22495;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#26032;&#30340;&#36817;&#20284;&#21442;&#25968;&#21270;SDE&#36716;&#31227;&#23494;&#24230;&#30340;&#26041;&#27861;&#65306;&#21463;&#21160;&#21147;&#31995;&#32479;&#38543;&#26426;&#25668;&#21160;&#29702;&#35770;&#21551;&#21457;&#30340;&#39640;&#26031;&#23494;&#24230;&#36817;&#20284;&#65292;&#20197;&#21450;&#23427;&#30340;&#25193;&#23637;&#65292;&#21160;&#21147;&#39640;&#26031;&#28151;&#21512;&#36817;&#20284;&#65288;DynGMA&#65289;&#12290;&#21463;&#30410;&#20110;&#31283;&#20581;&#30340;&#23494;&#24230;&#36817;&#20284;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#23398;&#20064;&#23436;&#20840;&#26410;&#30693;&#30340;&#28418;&#31227;&#21644;&#25193;&#25955;&#20989;&#25968;&#20197;&#21450;&#35745;&#31639;&#30697;&#19981;&#21464;&#24615;&#26041;&#38754;&#34920;&#29616;&#20986;&#20248;&#36234;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14475v1 Announce Type: new  Abstract: Learning unknown stochastic differential equations (SDEs) from observed data is a significant and challenging task with applications in various fields. Current approaches often use neural networks to represent drift and diffusion functions, and construct likelihood-based loss by approximating the transition density to train these networks. However, these methods often rely on one-step stochastic numerical schemes, necessitating data with sufficiently high time resolution. In this paper, we introduce novel approximations to the transition density of the parameterized SDE: a Gaussian density approximation inspired by the random perturbation theory of dynamical systems, and its extension, the dynamical Gaussian mixture approximation (DynGMA). Benefiting from the robust density approximation, our method exhibits superior accuracy compared to baseline methods in learning the fully unknown drift and diffusion functions and computing the invari
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24494;&#20998;&#21516;&#32986;&#31070;&#32463;&#31639;&#23376;&#23398;&#20064;&#26694;&#26550;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#21508;&#31181;&#21644;&#22797;&#26434;&#39046;&#22495;&#30340;&#29289;&#29702;&#31995;&#32479;&#30340;&#39046;&#22495;&#28789;&#27963;&#27169;&#22411;&#65292;&#20174;&#32780;&#23558;&#23398;&#20064;&#20989;&#25968;&#26144;&#23556;&#22312;&#19981;&#21516;&#39046;&#22495;&#30340;&#38382;&#39064;&#36716;&#21270;&#20026;&#22312;&#20849;&#20139;&#30340;&#24494;&#20998;&#21516;&#32986;&#19978;&#23398;&#20064;&#31639;&#23376;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.12475</link><description>&lt;p&gt;
&#19981;&#21516;&#39046;&#22495;&#21644;&#21442;&#25968;&#30340;&#24494;&#20998;&#21516;&#32986;&#31070;&#32463;&#31639;&#23376;
&lt;/p&gt;
&lt;p&gt;
Diffeomorphism Neural Operator for various domains and parameters of partial differential equations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12475
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24494;&#20998;&#21516;&#32986;&#31070;&#32463;&#31639;&#23376;&#23398;&#20064;&#26694;&#26550;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#21508;&#31181;&#21644;&#22797;&#26434;&#39046;&#22495;&#30340;&#29289;&#29702;&#31995;&#32479;&#30340;&#39046;&#22495;&#28789;&#27963;&#27169;&#22411;&#65292;&#20174;&#32780;&#23558;&#23398;&#20064;&#20989;&#25968;&#26144;&#23556;&#22312;&#19981;&#21516;&#39046;&#22495;&#30340;&#38382;&#39064;&#36716;&#21270;&#20026;&#22312;&#20849;&#20139;&#30340;&#24494;&#20998;&#21516;&#32986;&#19978;&#23398;&#20064;&#31639;&#23376;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#31185;&#23398;&#21644;&#24037;&#31243;&#24212;&#29992;&#38656;&#35201;&#23545;&#20256;&#32479;&#19978;&#20351;&#29992;&#36164;&#28304;&#23494;&#38598;&#22411;&#25968;&#20540;&#27714;&#35299;&#22120;&#35745;&#31639;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDE&#65289;&#36827;&#34892;&#35780;&#20272;&#12290;&#31070;&#32463;&#31639;&#23376;&#27169;&#22411;&#36890;&#36807;&#30452;&#25509;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#25511;&#21046;&#29289;&#29702;&#23450;&#24459;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#19981;&#21516;&#21442;&#25968;&#30340;PDE&#31867;&#21035;&#65292;&#20294;&#22312;&#22266;&#23450;&#36793;&#30028;&#65288;&#39046;&#22495;&#65289;&#20869;&#21463;&#38480;&#12290;&#35768;&#22810;&#24212;&#29992;&#65292;&#20363;&#22914;&#35774;&#35745;&#21644;&#21046;&#36896;&#65292;&#22312;&#22823;&#35268;&#27169;&#30740;&#31350;&#26102;&#23558;&#21463;&#30410;&#20110;&#20855;&#26377;&#28789;&#27963;&#39046;&#22495;&#30340;&#31070;&#32463;&#31639;&#23376;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24494;&#20998;&#21516;&#32986;&#31070;&#32463;&#31639;&#23376;&#23398;&#20064;&#26694;&#26550;&#65292;&#26088;&#22312;&#20026;&#20855;&#26377;&#21508;&#31181;&#21644;&#22797;&#26434;&#39046;&#22495;&#30340;&#29289;&#29702;&#31995;&#32479;&#24320;&#21457;&#39046;&#22495;&#28789;&#27963;&#27169;&#22411;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#30001;&#24494;&#20998;&#21516;&#32986;&#20174;&#21508;&#39046;&#22495;&#26144;&#23556;&#32780;&#26469;&#30340;&#20849;&#20139;&#39046;&#22495;&#20013;&#35757;&#32451;&#30340;&#31070;&#32463;&#31639;&#23376;&#65292;&#35813;&#26041;&#27861;&#23558;&#22312;&#19981;&#21516;&#39046;&#22495;&#65288;&#31354;&#38388;&#65289;&#23398;&#20064;&#20989;&#25968;&#26144;&#23556;&#30340;&#38382;&#39064;&#36716;&#21270;&#20026;&#22312;&#20849;&#20139;&#30340;&#24494;&#20998;&#21516;&#32986;&#19978;&#23398;&#20064;&#31639;&#23376;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12475v1 Announce Type: cross  Abstract: Many science and engineering applications demand partial differential equations (PDE) evaluations that are traditionally computed with resource-intensive numerical solvers. Neural operator models provide an efficient alternative by learning the governing physical laws directly from data in a class of PDEs with different parameters, but constrained in a fixed boundary (domain). Many applications, such as design and manufacturing, would benefit from neural operators with flexible domains when studied at scale. Here we present a diffeomorphism neural operator learning framework towards developing domain-flexible models for physical systems with various and complex domains. Specifically, a neural operator trained in a shared domain mapped from various domains of fields by diffeomorphism is proposed, which transformed the problem of learning function mappings in varying domains (spaces) into the problem of learning operators on a shared dif
&lt;/p&gt;</description></item></channel></rss>