<rss version="2.0"><channel><title>Chat Arxiv cs.NA</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NA</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#21367;&#31215;&#33258;&#32534;&#30721;&#22120;&#30340;&#38477;&#38454;&#27169;&#22411;&#30340;&#23454;&#29992;&#23384;&#22312;&#23450;&#29702;&#65292;&#35299;&#20915;&#20102;&#22312;&#22788;&#29702;&#22797;&#26434;&#38750;&#32447;&#24615;&#38382;&#39064;&#26041;&#38754;&#20256;&#32479;&#26041;&#27861;&#30340;&#19981;&#36275;&#65292;&#24182;&#35752;&#35770;&#20102;&#22914;&#20309;&#23398;&#20064;&#28508;&#22312;&#29305;&#24449;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.00435</link><description>&lt;p&gt;
&#22522;&#20110;&#21367;&#31215;&#33258;&#32534;&#30721;&#22120;&#30340;&#38477;&#38454;&#27169;&#22411;&#30340;&#23454;&#29992;&#23384;&#22312;&#23450;&#29702;
&lt;/p&gt;
&lt;p&gt;
A practical existence theorem for reduced order models based on convolutional autoencoders
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00435
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#21367;&#31215;&#33258;&#32534;&#30721;&#22120;&#30340;&#38477;&#38454;&#27169;&#22411;&#30340;&#23454;&#29992;&#23384;&#22312;&#23450;&#29702;&#65292;&#35299;&#20915;&#20102;&#22312;&#22788;&#29702;&#22797;&#26434;&#38750;&#32447;&#24615;&#38382;&#39064;&#26041;&#38754;&#20256;&#32479;&#26041;&#27861;&#30340;&#19981;&#36275;&#65292;&#24182;&#35752;&#35770;&#20102;&#22914;&#20309;&#23398;&#20064;&#28508;&#22312;&#29305;&#24449;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#28145;&#24230;&#23398;&#20064;&#22312;&#20559;&#24494;&#20998;&#26041;&#31243;&#21644;&#38477;&#38454;&#24314;&#27169;&#39046;&#22495;&#36234;&#21457;&#21463;&#27426;&#36814;&#65292;&#25552;&#20379;&#20102;&#22522;&#20110;&#29289;&#29702;&#30693;&#35782;&#30340;&#31070;&#32463;&#32593;&#32476;&#12289;&#31070;&#32463;&#31639;&#23376;&#12289;&#28145;&#24230;&#31639;&#23376;&#32593;&#32476;&#21644;&#28145;&#24230;&#23398;&#20064;&#38477;&#38454;&#27169;&#22411;&#31561;&#24378;&#22823;&#30340;&#25968;&#25454;&#39537;&#21160;&#25216;&#26415;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#22522;&#20110;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#28145;&#24230;&#33258;&#32534;&#30721;&#22120;&#34920;&#29616;&#20986;&#26497;&#39640;&#30340;&#25928;&#26524;&#65292;&#22312;&#22788;&#29702;&#22797;&#26434;&#30340;&#38750;&#32447;&#24615;&#38382;&#39064;&#26102;&#65292;&#20248;&#20110;&#20256;&#32479;&#30340;&#38477;&#38454;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#22522;&#20110;CNN&#30340;&#33258;&#32534;&#30721;&#22120;&#22312;&#23454;&#36341;&#20013;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#30446;&#21069;&#21482;&#26377;&#23569;&#25968;&#29702;&#35770;&#32467;&#26524;&#25903;&#25345;&#36825;&#20123;&#26550;&#26500;&#65292;&#36890;&#24120;&#20197;&#19975;&#33021;&#36924;&#36817;&#23450;&#29702;&#30340;&#24418;&#24335;&#38472;&#36848;&#12290;&#23588;&#20854;&#26159;&#65292;&#23613;&#31649;&#29616;&#26377;&#25991;&#29486;&#20026;&#35774;&#35745;&#21367;&#31215;&#33258;&#32534;&#30721;&#22120;&#25552;&#20379;&#20102;&#25351;&#23548;&#26041;&#38024;&#65292;&#20294;&#23398;&#20064;&#28508;&#22312;&#29305;&#24449;&#30340;&#21518;&#32493;&#25361;&#25112;&#20960;&#20046;&#27809;&#26377;&#34987;&#25506;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, deep learning has gained increasing popularity in the fields of Partial Differential Equations (PDEs) and Reduced Order Modeling (ROM), providing domain practitioners with new powerful data-driven techniques such as Physics-Informed Neural Networks (PINNs), Neural Operators, Deep Operator Networks (DeepONets) and Deep-Learning based ROMs (DL-ROMs). In this context, deep autoencoders based on Convolutional Neural Networks (CNNs) have proven extremely effective, outperforming established techniques, such as the reduced basis method, when dealing with complex nonlinear problems. However, despite the empirical success of CNN-based autoencoders, there are only a few theoretical results supporting these architectures, usually stated in the form of universal approximation theorems. In particular, although the existing literature provides users with guidelines for designing convolutional autoencoders, the subsequent challenge of learning the latent features has been barely inv
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#29289;&#29702;&#20449;&#24687;&#28145;&#24230;&#23398;&#20064;&#31574;&#30053;&#65292;&#28040;&#38500;&#20102;&#23545;&#21021;&#22987;&#26465;&#20214;&#30340;&#23398;&#20064;&#38656;&#27714;&#65292;&#24182;&#30830;&#20445;&#22312;&#22810;&#27425;&#24212;&#29992;&#26102;&#24471;&#21040;&#30340;&#20989;&#25968;&#26159;&#36830;&#32493;&#30340;&#12290;</title><link>http://arxiv.org/abs/2309.07899</link><description>&lt;p&gt;
&#25913;&#36827;&#20855;&#26377;&#30828;&#32422;&#26463;&#30340;&#29289;&#29702;&#20449;&#24687;DeepONets
&lt;/p&gt;
&lt;p&gt;
Improving physics-informed DeepONets with hard constraints. (arXiv:2309.07899v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07899
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#29289;&#29702;&#20449;&#24687;&#28145;&#24230;&#23398;&#20064;&#31574;&#30053;&#65292;&#28040;&#38500;&#20102;&#23545;&#21021;&#22987;&#26465;&#20214;&#30340;&#23398;&#20064;&#38656;&#27714;&#65292;&#24182;&#30830;&#20445;&#22312;&#22810;&#27425;&#24212;&#29992;&#26102;&#24471;&#21040;&#30340;&#20989;&#25968;&#26159;&#36830;&#32493;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#30340;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#65288;&#26631;&#20934;&#25110;&#25805;&#20316;&#31526;&#65289;&#20173;&#28982;&#20381;&#36182;&#20110;&#20934;&#30830;&#22320;&#23398;&#20064;&#25152;&#35299;&#20915;&#31995;&#32479;&#30340;&#21021;&#22987;&#26465;&#20214;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#26631;&#20934;&#30340;&#25968;&#20540;&#26041;&#27861;&#22312;&#19981;&#38656;&#35201;&#23398;&#20064;&#36825;&#20123;&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#28436;&#21270;&#36825;&#20123;&#21021;&#22987;&#26465;&#20214;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#25913;&#36827;&#24403;&#21069;&#30340;&#29289;&#29702;&#20449;&#24687;&#28145;&#24230;&#23398;&#20064;&#31574;&#30053;&#65292;&#20351;&#24471;&#19981;&#38656;&#35201;&#23398;&#20064;&#21021;&#22987;&#26465;&#20214;&#65292;&#24182;&#19988;&#23558;&#20854;&#20934;&#30830;&#22320;&#34920;&#31034;&#22312;&#39044;&#27979;&#30340;&#35299;&#20013;&#12290;&#27492;&#22806;&#65292;&#35813;&#26041;&#27861;&#20445;&#35777;&#24403;&#23558;DeepONet&#22810;&#27425;&#24212;&#29992;&#20110;&#26102;&#38388;&#27493;&#38271;&#35299;&#19978;&#26102;&#65292;&#24471;&#21040;&#30340;&#20989;&#25968;&#26159;&#36830;&#32493;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Current physics-informed (standard or operator) neural networks still rely on accurately learning the initial conditions of the system they are solving. In contrast, standard numerical methods evolve such initial conditions without needing to learn these. In this study, we propose to improve current physics-informed deep learning strategies such that initial conditions do not need to be learned and are represented exactly in the predicted solution. Moreover, this method guarantees that when a DeepONet is applied multiple times to time step a solution, the resulting function is continuous.
&lt;/p&gt;</description></item></channel></rss>