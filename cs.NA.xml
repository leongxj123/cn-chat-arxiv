<rss version="2.0"><channel><title>Chat Arxiv cs.NA</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NA</description><item><title>&#36825;&#39033;&#24037;&#20316;&#24320;&#21457;&#20102;&#19968;&#31181;&#20351;&#29992;&#24191;&#20041;&#23545;&#27604;&#25439;&#22833;&#30340;&#23545;&#27604;&#39044;&#35757;&#32451;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#29289;&#29702;&#20449;&#24687;&#25913;&#21892;&#20102;&#31070;&#32463;&#31639;&#23376;&#22312;&#22810;&#20010;&#20559;&#24494;&#20998;&#26041;&#31243;&#20013;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2401.16327</link><description>&lt;p&gt;
PICL: &#29289;&#29702;&#20449;&#24687;&#23545;&#27604;&#23398;&#20064;&#29992;&#20110;&#20559;&#24494;&#20998;&#26041;&#31243;
&lt;/p&gt;
&lt;p&gt;
PICL: Physics Informed Contrastive Learning for Partial Differential Equations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.16327
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#24320;&#21457;&#20102;&#19968;&#31181;&#20351;&#29992;&#24191;&#20041;&#23545;&#27604;&#25439;&#22833;&#30340;&#23545;&#27604;&#39044;&#35757;&#32451;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#29289;&#29702;&#20449;&#24687;&#25913;&#21892;&#20102;&#31070;&#32463;&#31639;&#23376;&#22312;&#22810;&#20010;&#20559;&#24494;&#20998;&#26041;&#31243;&#20013;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#31070;&#32463;&#31639;&#23376;&#20316;&#20026;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDE&#65289;&#26367;&#20195;&#27169;&#22411;&#36880;&#28176;&#21463;&#21040;&#20851;&#27880;&#12290;&#23398;&#20064;&#35299;&#20915;&#26041;&#26696;&#20989;&#25968;&#32780;&#19981;&#26159;&#20989;&#25968;&#26412;&#36523;&#24050;&#34987;&#35777;&#26126;&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#26041;&#27861;&#65292;&#21487;&#24555;&#36895;&#20934;&#30830;&#22320;&#27714;&#35299;&#22797;&#26434;&#30340;PDE&#12290;&#23613;&#31649;&#22312;&#24191;&#27867;&#30340;&#20195;&#29702;&#24314;&#27169;&#20219;&#21153;&#20013;&#23545;&#31070;&#32463;&#31639;&#23376;&#30340;&#24615;&#33021;&#36827;&#34892;&#20102;&#35768;&#22810;&#30740;&#31350;&#65292;&#20294;&#36825;&#20123;&#24037;&#20316;&#36890;&#24120;&#26159;&#36880;&#20010;&#26041;&#31243;&#35780;&#20272;&#24615;&#33021;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#23545;&#27604;&#39044;&#35757;&#32451;&#26694;&#26550;&#65292;&#21033;&#29992;&#24191;&#20041;&#23545;&#27604;&#25439;&#22833;&#65292;&#21487;&#20197;&#21516;&#26102;&#25913;&#21892;&#31070;&#32463;&#31639;&#23376;&#22312;&#22810;&#20010;&#25511;&#21046;&#26041;&#31243;&#20013;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#25511;&#21046;&#26041;&#31243;&#31995;&#25968;&#29992;&#20110;&#34913;&#37327;&#31995;&#32479;&#20043;&#38388;&#30340;&#30495;&#23454;&#30456;&#20284;&#24615;&#12290;&#29289;&#29702;&#20449;&#24687;&#31995;&#32479;&#28436;&#21270;&#21644;&#28508;&#22312;&#31354;&#38388;&#27169;&#22411;&#36755;&#20986;&#30340;&#32467;&#21512;&#34987;&#38170;&#23450;&#21040;&#36755;&#20837;&#25968;&#25454;&#20013;&#65292;&#24182;&#29992;&#20110;&#25105;&#20204;&#30340;&#36317;&#31163;&#20989;&#25968;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#29289;&#29702;&#20449;&#24687;&#23545;&#27604;&#39044;&#35757;&#32451;&#21487;&#20197;&#25552;&#39640;&#20613;&#31435;&#21494;&#31070;&#32463;&#31639;&#23376;&#30340;&#20934;&#30830;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural operators have recently grown in popularity as Partial Differential Equation (PDEs) surrogate models. Learning solution functionals, rather than functions, has proven to be a powerful approach to calculate fast, accurate solutions to complex PDEs. While much work has been done evaluating neural operator performance on a wide variety of surrogate modeling tasks, these works normally evaluate performance on a single equation at a time. In this work, we develop a novel contrastive pretraining framework utilizing Generalized Contrastive Loss that improves neural operator generalization across multiple governing equations simultaneously. Governing equation coefficients are used to measure ground-truth similarity between systems. A combination of physics-informed system evolution and latent-space model output are anchored to input data and used in our distance function. We find that physics-informed contrastive pretraining improves both accuracy and generalization for the Fourier Neur
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#32852;&#21512;&#20998;&#24067;&#23398;&#20064;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#20174;&#22823;&#37327;&#25968;&#25454;&#28857;&#20013;&#20272;&#35745;&#20302;&#32500;&#12289;&#24402;&#19968;&#21270;&#21644;&#27491;&#30340;Radon-Nikodym&#23548;&#25968;&#27169;&#22411;&#65292;&#24182;&#22312;&#19981;&#21516;&#23398;&#20064;&#38382;&#39064;&#19978;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2110.04829</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#32852;&#21512;&#20998;&#24067;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Adaptive joint distribution learning. (arXiv:2110.04829v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.04829
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#32852;&#21512;&#20998;&#24067;&#23398;&#20064;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#20174;&#22823;&#37327;&#25968;&#25454;&#28857;&#20013;&#20272;&#35745;&#20302;&#32500;&#12289;&#24402;&#19968;&#21270;&#21644;&#27491;&#30340;Radon-Nikodym&#23548;&#25968;&#27169;&#22411;&#65292;&#24182;&#22312;&#19981;&#21516;&#23398;&#20064;&#38382;&#39064;&#19978;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#23558;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#23884;&#20837;&#24352;&#37327;&#31215;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#20013;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#23481;&#32435;&#19968;&#20010;&#20302;&#32500;&#12289;&#24402;&#19968;&#21270;&#21644;&#27491;&#30340;Radon-Nikodym&#23548;&#25968;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#20174;&#22810;&#36798;&#25968;&#30334;&#19975;&#20010;&#25968;&#25454;&#28857;&#30340;&#26679;&#26412;&#22823;&#23567;&#20013;&#36827;&#34892;&#20272;&#35745;&#65292;&#20943;&#36731;&#20102;RKHS&#24314;&#27169;&#30340;&#22266;&#26377;&#38480;&#21046;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#33258;&#28982;&#20135;&#29983;&#20102;&#23450;&#20041;&#33391;&#22909;&#30340;&#24402;&#19968;&#21270;&#21644;&#27491;&#30340;&#26465;&#20214;&#20998;&#24067;&#12290;&#23884;&#20837;&#35745;&#31639;&#36895;&#24230;&#24555;&#19988;&#36866;&#29992;&#20110;&#20174;&#39044;&#27979;&#21040;&#20998;&#31867;&#30340;&#21508;&#31181;&#23398;&#20064;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#24471;&#21040;&#20102;&#26377;&#30410;&#30340;&#25968;&#20540;&#32467;&#26524;&#30340;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a new framework for embedding joint probability distributions in tensor product reproducing kernel Hilbert spaces (RKHS). Our framework accommodates a low-dimensional, normalized and positive model of a Radon-Nikodym derivative, which we estimate from sample sizes of up to several million data points, alleviating the inherent limitations of RKHS modeling. Well-defined normalized and positive conditional distributions are natural by-products to our approach. The embedding is fast to compute and accommodates learning problems ranging from prediction to classification. Our theoretical findings are supplemented by favorable numerical results.
&lt;/p&gt;</description></item></channel></rss>