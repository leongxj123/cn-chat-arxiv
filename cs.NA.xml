<rss version="2.0"><channel><title>Chat Arxiv cs.NA</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NA</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#21452;&#23610;&#24230;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#35299;&#20915;&#20855;&#26377;&#23567;&#21442;&#25968;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#30452;&#25509;&#23558;&#23567;&#21442;&#25968;&#32435;&#20837;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#20013;&#65292;&#20174;&#32780;&#31616;&#21270;&#35299;&#20915;&#36807;&#31243;&#65292;&#24182;&#33021;&#22815;&#21512;&#29702;&#20934;&#30830;&#22320;&#25429;&#25417;&#30001;&#23567;&#21442;&#25968;&#24341;&#36215;&#30340;&#35299;&#20013;&#22823;&#23548;&#25968;&#29305;&#24449;&#12290;</title><link>https://arxiv.org/abs/2402.17232</link><description>&lt;p&gt;
&#20855;&#26377;&#23567;&#21442;&#25968;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#21452;&#23610;&#24230;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Two-scale Neural Networks for Partial Differential Equations with Small Parameters
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17232
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#21452;&#23610;&#24230;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#35299;&#20915;&#20855;&#26377;&#23567;&#21442;&#25968;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#30452;&#25509;&#23558;&#23567;&#21442;&#25968;&#32435;&#20837;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#20013;&#65292;&#20174;&#32780;&#31616;&#21270;&#35299;&#20915;&#36807;&#31243;&#65292;&#24182;&#33021;&#22815;&#21512;&#29702;&#20934;&#30830;&#22320;&#25429;&#25417;&#30001;&#23567;&#21442;&#25968;&#24341;&#36215;&#30340;&#35299;&#20013;&#22823;&#23548;&#25968;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#65288;PINNs&#65289;&#35299;&#20915;&#20855;&#26377;&#23567;&#21442;&#25968;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDEs&#65289;&#30340;&#21452;&#23610;&#24230;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#12290;&#25105;&#20204;&#30452;&#25509;&#23558;&#23567;&#21442;&#25968;&#32435;&#20837;&#31070;&#32463;&#32593;&#32476;&#30340;&#26550;&#26500;&#20013;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20351;&#24471;&#20197;&#31616;&#21333;&#26041;&#24335;&#35299;&#20915;&#20855;&#26377;&#23567;&#21442;&#25968;&#30340;PDE&#25104;&#20026;&#21487;&#33021;&#65292;&#32780;&#26080;&#38656;&#28155;&#21152;&#20613;&#37324;&#21494;&#29305;&#24449;&#25110;&#20854;&#20182;&#35745;&#31639;&#32321;&#29712;&#30340;&#25130;&#26029;&#21442;&#25968;&#25628;&#32034;&#12290;&#22810;&#20010;&#25968;&#20540;&#20363;&#23376;&#23637;&#31034;&#20102;&#22312;&#35299;&#20915;&#30001;&#23567;&#21442;&#25968;&#24341;&#36215;&#30340;&#35299;&#20013;&#22823;&#23548;&#25968;&#29305;&#24449;&#26102;&#30340;&#21512;&#29702;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17232v1 Announce Type: cross  Abstract: We propose a two-scale neural network method for solving partial differential equations (PDEs) with small parameters using physics-informed neural networks (PINNs). We directly incorporate the small parameters into the architecture of neural networks. The proposed method enables solving PDEs with small parameters in a simple fashion, without adding Fourier features or other computationally taxing searches of truncation parameters. Various numerical examples demonstrate reasonable accuracy in capturing features of large derivatives in the solutions caused by small parameters.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#30028;&#22495;&#19978;&#36890;&#36807;&#21333;&#38544;&#34255;&#23618;ReLU&#32593;&#32476;&#36924;&#36817;&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#20171;&#32461;&#20102;&#26032;&#30340;&#27169;&#22411;&#31867;&#23450;&#20041;&#21152;&#26435;&#21464;&#24046;&#31354;&#38388;&#65292;&#35813;&#23450;&#20041;&#19982;&#22495;&#26412;&#36523;&#30456;&#20851;&#12290;</title><link>http://arxiv.org/abs/2307.15772</link><description>&lt;p&gt;
&#21152;&#26435;&#21464;&#24046;&#31354;&#38388;&#19982;&#27973;&#23618;ReLU&#32593;&#32476;&#30340;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
Weighted variation spaces and approximation by shallow ReLU networks. (arXiv:2307.15772v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15772
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#30028;&#22495;&#19978;&#36890;&#36807;&#21333;&#38544;&#34255;&#23618;ReLU&#32593;&#32476;&#36924;&#36817;&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#20171;&#32461;&#20102;&#26032;&#30340;&#27169;&#22411;&#31867;&#23450;&#20041;&#21152;&#26435;&#21464;&#24046;&#31354;&#38388;&#65292;&#35813;&#23450;&#20041;&#19982;&#22495;&#26412;&#36523;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#30028;&#22495;&#937;&#8834;Rd&#19978;&#65292;&#36890;&#36807;&#23485;&#24230;&#20026;n&#30340;&#21333;&#38544;&#34255;&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20986;&#26469;&#36924;&#36817;&#20989;&#25968;f&#30340;&#24773;&#20917;&#12290;&#36825;&#31181;&#38750;&#32447;&#24615;&#30340;n&#39033;&#23383;&#20856;&#36924;&#36817;&#24050;&#32463;&#24471;&#21040;&#24191;&#27867;&#30740;&#31350;&#65292;&#22240;&#20026;&#23427;&#26159;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;(NNA)&#30340;&#26368;&#31616;&#21333;&#24773;&#20917;&#12290;&#23545;&#20110;&#36825;&#31181;NNA&#24418;&#24335;&#65292;&#26377;&#20960;&#20010;&#33879;&#21517;&#30340;&#36924;&#36817;&#32467;&#26524;&#65292;&#24341;&#20837;&#20102;&#22312;&#937;&#19978;&#30340;&#20989;&#25968;&#30340;&#26032;&#22411;&#27169;&#22411;&#31867;&#65292;&#20854;&#36924;&#36817;&#36895;&#29575;&#36991;&#20813;&#20102;&#32500;&#25968;&#28798;&#38590;&#12290;&#36825;&#20123;&#26032;&#22411;&#27169;&#22411;&#31867;&#21253;&#25324;Barron&#31867;&#21644;&#22522;&#20110;&#31232;&#30095;&#24615;&#25110;&#21464;&#24046;&#30340;&#31867;&#65292;&#20363;&#22914;Radon&#22495;BV&#31867;&#12290;&#26412;&#25991;&#20851;&#27880;&#20110;&#22312;&#22495;&#937;&#19978;&#23450;&#20041;&#36825;&#20123;&#26032;&#22411;&#27169;&#22411;&#31867;&#12290;&#24403;&#21069;&#36825;&#20123;&#27169;&#22411;&#31867;&#30340;&#23450;&#20041;&#19981;&#20381;&#36182;&#20110;&#22495;&#937;&#12290;&#36890;&#36807;&#24341;&#20837;&#21152;&#26435;&#21464;&#24046;&#31354;&#38388;&#30340;&#27010;&#24565;&#65292;&#32473;&#20986;&#20102;&#20851;&#20110;&#22495;&#30340;&#26356;&#24688;&#24403;&#30340;&#27169;&#22411;&#31867;&#23450;&#20041;&#12290;&#36825;&#20123;&#26032;&#22411;&#27169;&#22411;&#31867;&#19982;&#22495;&#26412;&#36523;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the approximation of functions $f$ on a bounded domain $\Omega\subset \mathbb{R}^d$ by the outputs of single-hidden-layer ReLU neural networks of width $n$. This form of nonlinear $n$-term dictionary approximation has been intensely studied since it is the simplest case of neural network approximation (NNA). There are several celebrated approximation results for this form of NNA that introduce novel model classes of functions on $\Omega$ whose approximation rates avoid the curse of dimensionality. These novel classes include Barron classes, and classes based on sparsity or variation such as the Radon-domain BV classes.  The present paper is concerned with the definition of these novel model classes on domains $\Omega$. The current definition of these model classes does not depend on the domain $\Omega$. A new and more proper definition of model classes on domains is given by introducing the concept of weighted variation spaces. These new model classes are intrinsic to th
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20302;&#21442;&#25968;&#35757;&#32451;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#23558;&#21367;&#31215;&#20998;&#35299;&#20026;&#24352;&#37327;Tucker&#26684;&#24335;&#65292;&#24182;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#33258;&#36866;&#24212;&#22320;&#20462;&#21098;&#21367;&#31215;&#26680;&#30340;Tucker&#31209;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#38477;&#20302;&#35757;&#32451;&#25104;&#26412;&#12290;</title><link>http://arxiv.org/abs/2305.19059</link><description>&lt;p&gt;
&#35757;&#32451;&#26399;&#38388;&#30340;&#33258;&#36866;&#24212;&#31209;&#35889;&#21098;&#26525;&#21367;&#31215;&#23618;
&lt;/p&gt;
&lt;p&gt;
Rank-adaptive spectral pruning of convolutional layers during training. (arXiv:2305.19059v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19059
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20302;&#21442;&#25968;&#35757;&#32451;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#23558;&#21367;&#31215;&#20998;&#35299;&#20026;&#24352;&#37327;Tucker&#26684;&#24335;&#65292;&#24182;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#33258;&#36866;&#24212;&#22320;&#20462;&#21098;&#21367;&#31215;&#26680;&#30340;Tucker&#31209;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#38477;&#20302;&#35757;&#32451;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#22312;&#35745;&#31639;&#25104;&#26412;&#21644;&#20869;&#23384;&#38656;&#27714;&#26041;&#38754;&#22686;&#38271;&#36805;&#36895;&#65292;&#22240;&#27492;&#24050;&#32463;&#21457;&#23637;&#20102;&#21508;&#31181;&#21098;&#26525;&#25216;&#26415;&#20197;&#20943;&#23569;&#27169;&#22411;&#21442;&#25968;&#12290;&#22823;&#22810;&#25968;&#25216;&#26415;&#20391;&#37325;&#20110;&#36890;&#36807;&#22312;&#23436;&#25972;&#35757;&#32451;&#21518;&#23545;&#32593;&#32476;&#36827;&#34892;&#20462;&#21098;&#20197;&#20943;&#23569;&#25512;&#29702;&#25104;&#26412;&#12290;&#23569;&#37327;&#30340;&#26041;&#27861;&#35299;&#20915;&#20102;&#20943;&#23569;&#35757;&#32451;&#25104;&#26412;&#30340;&#38382;&#39064;&#65292;&#20027;&#35201;&#26159;&#36890;&#36807;&#20302;&#31209;&#23618;&#20998;&#35299;&#26469;&#21387;&#32553;&#32593;&#32476;&#12290;&#23613;&#31649;&#36825;&#20123;&#26041;&#27861;&#23545;&#20110;&#32447;&#24615;&#23618;&#26159;&#26377;&#25928;&#30340;&#65292;&#20294;&#26159;&#23427;&#20204;&#26080;&#27861;&#26377;&#25928;&#22788;&#29702;&#21367;&#31215;&#28388;&#27874;&#22120;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20302;&#21442;&#25968;&#35757;&#32451;&#26041;&#27861;&#65292;&#23558;&#21367;&#31215;&#20998;&#35299;&#20026;&#24352;&#37327;Tucker&#26684;&#24335;&#65292;&#24182;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#33258;&#36866;&#24212;&#22320;&#20462;&#21098;&#21367;&#31215;&#26680;&#30340;Tucker&#31209;&#12290;&#21033;&#29992;&#24494;&#20998;&#26041;&#31243;&#22312;&#24352;&#37327;&#27969;&#24418;&#19978;&#30340;&#20960;&#20309;&#31215;&#20998;&#29702;&#35770;&#30340;&#22522;&#26412;&#32467;&#26524;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#19968;&#20010;&#40065;&#26834;&#30340;&#35757;&#32451;&#31639;&#27861;&#65292;&#35777;&#26126;&#33021;&#22815;&#36924;&#36817;&#23436;&#25972;&#30340;&#22522;&#32447;&#24615;&#33021;&#24182;&#20445;&#35777;&#25439;&#22833;&#19979;&#38477;&#12290;
&lt;/p&gt;
&lt;p&gt;
The computing cost and memory demand of deep learning pipelines have grown fast in recent years and thus a variety of pruning techniques have been developed to reduce model parameters. The majority of these techniques focus on reducing inference costs by pruning the network after a pass of full training. A smaller number of methods address the reduction of training costs, mostly based on compressing the network via low-rank layer factorizations. Despite their efficiency for linear layers, these methods fail to effectively handle convolutional filters. In this work, we propose a low-parametric training method that factorizes the convolutions into tensor Tucker format and adaptively prunes the Tucker ranks of the convolutional kernel during training. Leveraging fundamental results from geometric integration theory of differential equations on tensor manifolds, we obtain a robust training algorithm that provably approximates the full baseline performance and guarantees loss descent. A var
&lt;/p&gt;</description></item></channel></rss>