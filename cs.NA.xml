<rss version="2.0"><channel><title>Chat Arxiv cs.NA</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NA</description><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#20687;&#32032;&#25968;&#25454;&#30340;&#39044;&#27979;&#65292;&#36890;&#36807;&#23545;&#31163;&#25955;&#21367;&#31215;&#21644;&#26377;&#38480;&#24046;&#20998;&#31639;&#23376;&#20043;&#38388;&#32852;&#31995;&#30340;&#21033;&#29992;&#65292;&#35777;&#26126;&#20102;&#36924;&#36817;&#33258;&#20559;&#24494;&#20998;&#26041;&#31243;&#31354;&#26102;&#31163;&#25955;&#20986;&#30340;&#24207;&#21015;&#21487;&#20197;&#20351;&#29992;&#30456;&#23545;&#36739;&#23567;&#30340;&#21367;&#31215;(&#27531;&#24046;)&#32593;&#32476;&#36827;&#34892;&#12290;</title><link>http://arxiv.org/abs/2305.00723</link><description>&lt;p&gt;
&#22522;&#20110;&#20687;&#32032;&#25968;&#25454;&#30340;&#39044;&#27979;: PDE&#21644;&#26377;&#38480;&#24046;&#20998;&#30340;&#28145;&#20837;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
Predictions Based on Pixel Data: Insights from PDEs and Finite Differences. (arXiv:2305.00723v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00723
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#20687;&#32032;&#25968;&#25454;&#30340;&#39044;&#27979;&#65292;&#36890;&#36807;&#23545;&#31163;&#25955;&#21367;&#31215;&#21644;&#26377;&#38480;&#24046;&#20998;&#31639;&#23376;&#20043;&#38388;&#32852;&#31995;&#30340;&#21033;&#29992;&#65292;&#35777;&#26126;&#20102;&#36924;&#36817;&#33258;&#20559;&#24494;&#20998;&#26041;&#31243;&#31354;&#26102;&#31163;&#25955;&#20986;&#30340;&#24207;&#21015;&#21487;&#20197;&#20351;&#29992;&#30456;&#23545;&#36739;&#23567;&#30340;&#21367;&#31215;(&#27531;&#24046;)&#32593;&#32476;&#36827;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#26159;&#39640;&#32500;&#31354;&#38388;&#20013;&#35768;&#22810;&#36924;&#36817;&#20219;&#21153;&#30340;&#26368;&#20808;&#36827;&#25216;&#26415;&#65292;&#36825;&#24471;&#21040;&#20102;&#22823;&#37327;&#23454;&#39564;&#35777;&#25454;&#30340;&#25903;&#25345;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#20173;&#38656;&#35201;&#23545;&#23427;&#20204;&#21487;&#20197;&#36924;&#36817;&#30340;&#20869;&#23481;&#20197;&#21450;&#20197;&#20309;&#31181;&#20195;&#20215;&#21644;&#31934;&#24230;&#36924;&#36817;&#26377;&#19968;&#20010;&#22362;&#23454;&#30340;&#29702;&#35770;&#29702;&#35299;&#12290;&#20854;&#20013;&#19968;&#20010;&#22312;&#28041;&#21450;&#22270;&#20687;&#30340;&#36924;&#36817;&#20219;&#21153;&#20013;&#26377;&#23454;&#38469;&#29992;&#36884;&#30340;&#32593;&#32476;&#20307;&#31995;&#32467;&#26500;&#26159;&#21367;&#31215;(&#27531;&#24046;)&#32593;&#32476;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#36825;&#20123;&#32593;&#32476;&#20013;&#28041;&#21450;&#30340;&#32447;&#24615;&#31639;&#23376;&#30340;&#23616;&#37096;&#24615;&#36136;&#65292;&#23427;&#20204;&#30340;&#20998;&#26512;&#27604;&#36890;&#29992;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#26356;&#20026;&#22797;&#26434;&#12290;&#26412;&#25991;&#37325;&#28857;&#20171;&#32461;&#30340;&#26159;&#24207;&#21015;&#36924;&#36817;&#20219;&#21153;&#65292;&#20854;&#20013;&#27599;&#20010;&#35266;&#23519;&#20540;&#30001;&#30697;&#38453;&#25110;&#39640;&#38454;&#24352;&#37327;&#34920;&#31034;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#24403;&#36924;&#36817;&#33258;&#20559;&#24494;&#20998;&#26041;&#31243;&#31354;&#26102;&#31163;&#25955;&#20986;&#30340;&#24207;&#21015;&#26102;&#65292;&#21487;&#20197;&#20351;&#29992;&#30456;&#23545;&#36739;&#23567;&#30340;&#32593;&#32476;&#12290;&#25105;&#20204;&#36890;&#36807;&#21033;&#29992;&#31163;&#25955;&#21367;&#31215;&#21644;&#26377;&#38480;&#24046;&#20998;&#31639;&#23376;&#20043;&#38388;&#30340;&#32852;&#31995;&#26469;&#26500;&#36896;&#36825;&#20123;&#32467;&#26524;&#12290;&#22312;&#25972;&#20010;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#25105;&#20204;&#30340;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural networks are the state-of-the-art for many approximation tasks in high-dimensional spaces, as supported by an abundance of experimental evidence. However, we still need a solid theoretical understanding of what they can approximate and, more importantly, at what cost and accuracy. One network architecture of practical use, especially for approximation tasks involving images, is convolutional (residual) networks. However, due to the locality of the linear operators involved in these networks, their analysis is more complicated than for generic fully connected neural networks. This paper focuses on sequence approximation tasks, where a matrix or a higher-order tensor represents each observation. We show that when approximating sequences arising from space-time discretisations of PDEs we may use relatively small networks. We constructively derive these results by exploiting connections between discrete convolution and finite difference operators. Throughout, we design our network a
&lt;/p&gt;</description></item></channel></rss>