<rss version="2.0"><channel><title>Chat Arxiv cs.NA</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NA</description><item><title>&#31639;&#23376;&#23398;&#20064;&#20013;&#23384;&#22312;&#32500;&#24230;&#35781;&#21650;&#65292;&#20294;&#23545;&#20110;&#30001;Hamilton-Jacobi&#26041;&#31243;&#23450;&#20041;&#30340;&#35299;&#31639;&#23376;&#21487;&#20197;&#20811;&#26381;&#32500;&#24230;&#35781;&#21650;&#12290;</title><link>http://arxiv.org/abs/2306.15924</link><description>&lt;p&gt;
&#36816;&#31639;&#23398;&#20064;&#20013;&#30340;&#32500;&#24230;&#35781;&#21650;
&lt;/p&gt;
&lt;p&gt;
The curse of dimensionality in operator learning. (arXiv:2306.15924v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15924
&lt;/p&gt;
&lt;p&gt;
&#31639;&#23376;&#23398;&#20064;&#20013;&#23384;&#22312;&#32500;&#24230;&#35781;&#21650;&#65292;&#20294;&#23545;&#20110;&#30001;Hamilton-Jacobi&#26041;&#31243;&#23450;&#20041;&#30340;&#35299;&#31639;&#23376;&#21487;&#20197;&#20811;&#26381;&#32500;&#24230;&#35781;&#21650;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#31639;&#23376;&#26550;&#26500;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#36817;&#20284;&#26144;&#23556;&#20989;&#25968;&#31354;&#38388;&#20043;&#38388;&#30340;&#31639;&#23376;&#65292;&#21487;&#20197;&#29992;&#20110;&#36890;&#36807;&#27169;&#25311;&#21152;&#36895;&#27169;&#22411;&#35780;&#20272;&#65292;&#25110;&#32773;&#20174;&#25968;&#25454;&#20013;&#21457;&#29616;&#27169;&#22411;&#12290;&#22240;&#27492;&#65292;&#36825;&#19968;&#26041;&#27861;&#22312;&#36817;&#24180;&#26469;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#65292;&#24341;&#21457;&#20102;&#31639;&#23376;&#23398;&#20064;&#39046;&#22495;&#30340;&#24555;&#36895;&#21457;&#23637;&#12290;&#26412;&#25991;&#30340;&#31532;&#19968;&#39033;&#36129;&#29486;&#26159;&#35777;&#26126;&#20102;&#23545;&#20110;&#19968;&#33324;&#30340;&#21482;&#30001;&#20854; $C^r$ &#25110; Lipschitz &#27491;&#21017;&#24615;&#29305;&#24449;&#21270;&#30340;&#31639;&#23376;&#31867;&#65292;&#31639;&#23376;&#23398;&#20064;&#36973;&#21463;&#20102;&#32500;&#24230;&#35781;&#21650;&#65292;&#36825;&#37324;&#36890;&#36807;&#26080;&#31351;&#32500;&#36755;&#20837;&#21644;&#36755;&#20986;&#20989;&#25968;&#31354;&#38388;&#30340;&#34920;&#24449;&#26469;&#31934;&#30830;&#23450;&#20041;&#32500;&#24230;&#35781;&#21650;&#12290;&#35813;&#32467;&#26524;&#36866;&#29992;&#20110;&#21253;&#25324; PCA-Net&#12289;DeepONet &#21644; FNO &#22312;&#20869;&#30340;&#22810;&#31181;&#29616;&#26377;&#31070;&#32463;&#31639;&#23376;&#12290;&#26412;&#25991;&#30340;&#31532;&#20108;&#39033;&#36129;&#29486;&#26159;&#35777;&#26126;&#20102;&#23545;&#20110;&#30001;Hamilton-Jacobi&#26041;&#31243;&#23450;&#20041;&#30340;&#35299;&#31639;&#23376;&#65292;&#21487;&#20197;&#20811;&#26381;&#19968;&#33324;&#30340;&#32500;&#24230;&#35781;&#21650;&#65307;&#36825;&#26159;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#34920;&#31034;&#26041;&#27861;&#26469;&#23454;&#29616;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural operator architectures employ neural networks to approximate operators mapping between Banach spaces of functions; they may be used to accelerate model evaluations via emulation, or to discover models from data. Consequently, the methodology has received increasing attention over recent years, giving rise to the rapidly growing field of operator learning. The first contribution of this paper is to prove that for general classes of operators which are characterized only by their $C^r$- or Lipschitz-regularity, operator learning suffers from a curse of dimensionality, defined precisely here in terms of representations of the infinite-dimensional input and output function spaces. The result is applicable to a wide variety of existing neural operators, including PCA-Net, DeepONet and the FNO. The second contribution of the paper is to prove that the general curse of dimensionality can be overcome for solution operators defined by the Hamilton-Jacobi equation; this is achieved by lev
&lt;/p&gt;</description></item></channel></rss>