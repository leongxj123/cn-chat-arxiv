<rss version="2.0"><channel><title>Chat Arxiv cs.NA</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NA</description><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#25805;&#20316;&#22120;&#32593;&#32476;&#30340;&#27867;&#21270;&#30028;&#38480;&#38382;&#39064;&#65292;&#22312;&#19968;&#31867;DeepONets&#20013;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;Rademacher&#22797;&#26434;&#24230;&#30340;&#30028;&#38480;&#19981;&#20250;&#38543;&#32593;&#32476;&#23485;&#24230;&#25193;&#23637;&#32780;&#26126;&#30830;&#21464;&#21270;&#65292;&#24182;&#21033;&#29992;&#36825;&#20010;&#32467;&#26524;&#23637;&#31034;&#20102;&#22914;&#20309;&#36873;&#25321;Huber&#25439;&#22833;&#26469;&#33719;&#24471;&#19981;&#26126;&#30830;&#20381;&#36182;&#20110;&#32593;&#32476;&#22823;&#23567;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2205.11359</link><description>&lt;p&gt;
&#38754;&#21521;&#23610;&#24230;&#26080;&#20851;&#30340;&#28145;&#24230;&#25805;&#20316;&#22120;&#32593;&#32476;&#30340;&#27867;&#21270;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Towards Size-Independent Generalization Bounds for Deep Operator Nets. (arXiv:2205.11359v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.11359
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#25805;&#20316;&#22120;&#32593;&#32476;&#30340;&#27867;&#21270;&#30028;&#38480;&#38382;&#39064;&#65292;&#22312;&#19968;&#31867;DeepONets&#20013;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;Rademacher&#22797;&#26434;&#24230;&#30340;&#30028;&#38480;&#19981;&#20250;&#38543;&#32593;&#32476;&#23485;&#24230;&#25193;&#23637;&#32780;&#26126;&#30830;&#21464;&#21270;&#65292;&#24182;&#21033;&#29992;&#36825;&#20010;&#32467;&#26524;&#23637;&#31034;&#20102;&#22914;&#20309;&#36873;&#25321;Huber&#25439;&#22833;&#26469;&#33719;&#24471;&#19981;&#26126;&#30830;&#20381;&#36182;&#20110;&#32593;&#32476;&#22823;&#23567;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26368;&#36817;&#30340;&#26102;&#26399;&#65292;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#20998;&#26512;&#29289;&#29702;&#31995;&#32479;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#35201;&#36827;&#23637;&#12290;&#22312;&#36825;&#20010;&#20027;&#39064;&#20013;&#29305;&#21035;&#27963;&#36291;&#30340;&#39046;&#22495;&#26159;"&#29289;&#29702;&#20449;&#24687;&#26426;&#22120;&#23398;&#20064;"&#65292;&#23427;&#19987;&#27880;&#20110;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#25968;&#20540;&#27714;&#35299;&#24494;&#20998;&#26041;&#31243;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#25512;&#36827;&#22312;&#35757;&#32451;DeepONets&#26102;&#27979;&#37327;&#26679;&#26412;&#22806;&#35823;&#24046;&#30340;&#29702;&#35770; - &#36825;&#26159;&#35299;&#20915;PDE&#31995;&#32479;&#26368;&#36890;&#29992;&#30340;&#26041;&#27861;&#20043;&#19968;&#12290;&#39318;&#20808;&#65292;&#38024;&#23545;&#19968;&#31867;DeepONets&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;Rademacher&#22797;&#26434;&#24230;&#26377;&#19968;&#20010;&#30028;&#38480;&#65292;&#35813;&#30028;&#38480;&#19981;&#20250;&#26126;&#30830;&#22320;&#38543;&#30528;&#28041;&#21450;&#30340;&#32593;&#32476;&#23485;&#24230;&#25193;&#23637;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#21033;&#29992;&#36825;&#19968;&#32467;&#26524;&#26469;&#23637;&#31034;&#22914;&#20309;&#36873;&#25321;Huber&#25439;&#22833;&#65292;&#20351;&#24471;&#23545;&#20110;&#36825;&#20123;DeepONet&#31867;&#65292;&#33021;&#22815;&#33719;&#24471;&#19981;&#26126;&#30830;&#20381;&#36182;&#20110;&#32593;&#32476;&#22823;&#23567;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#12290;&#25105;&#20204;&#25351;&#20986;&#65292;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#36866;&#29992;&#20110;&#20219;&#20309;&#30446;&#26631;&#26159;&#30001;DeepONets&#27714;&#35299;&#30340;PDE&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent times machine learning methods have made significant advances in becoming a useful tool for analyzing physical systems. A particularly active area in this theme has been "physics-informed machine learning" which focuses on using neural nets for numerically solving differential equations. In this work, we aim to advance the theory of measuring out-of-sample error while training DeepONets -- which is among the most versatile ways to solve PDE systems in one-shot.  Firstly, for a class of DeepONets, we prove a bound on their Rademacher complexity which does not explicitly scale with the width of the nets involved. Secondly, we use this to show how the Huber loss can be chosen so that for these DeepONet classes generalization error bounds can be obtained that have no explicit dependence on the size of the nets. We note that our theoretical results apply to any PDE being targeted to be solved by DeepONets.
&lt;/p&gt;</description></item></channel></rss>