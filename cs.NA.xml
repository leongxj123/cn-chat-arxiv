<rss version="2.0"><channel><title>Chat Arxiv cs.NA</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NA</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#27905;&#30340;&#31070;&#32463;&#31639;&#23376;&#26550;&#26500;&#65292;&#36890;&#36807;&#22810;&#37325;&#32593;&#26684;&#32467;&#26500;&#26377;&#25928;&#21442;&#25968;&#21270;&#32447;&#24615;&#31639;&#23376;&#65292;&#23454;&#29616;&#20102;&#31639;&#23376;&#23398;&#20064;&#30340;&#25968;&#23398;&#20005;&#23494;&#24615;&#21644;&#23454;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.19809</link><description>&lt;p&gt;
MgNO:&#36890;&#36807;&#22810;&#37325;&#32593;&#26684;&#26377;&#25928;&#21442;&#25968;&#21270;&#32447;&#24615;&#31639;&#23376;
&lt;/p&gt;
&lt;p&gt;
MgNO: Efficient Parameterization of Linear Operators via Multigrid. (arXiv:2310.19809v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19809
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#27905;&#30340;&#31070;&#32463;&#31639;&#23376;&#26550;&#26500;&#65292;&#36890;&#36807;&#22810;&#37325;&#32593;&#26684;&#32467;&#26500;&#26377;&#25928;&#21442;&#25968;&#21270;&#32447;&#24615;&#31639;&#23376;&#65292;&#23454;&#29616;&#20102;&#31639;&#23376;&#23398;&#20064;&#30340;&#25968;&#23398;&#20005;&#23494;&#24615;&#21644;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#27905;&#30340;&#31070;&#32463;&#31639;&#23376;&#26550;&#26500;&#26469;&#36827;&#34892;&#31639;&#23376;&#23398;&#20064;&#12290;&#23558;&#20854;&#19982;&#20256;&#32479;&#30340;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#31867;&#27604;&#65292;&#23558;&#31070;&#32463;&#31639;&#23376;&#23450;&#20041;&#20026;&#38750;&#32447;&#24615;&#31639;&#23376;&#23618;&#20013;&#31532;$i$&#20010;&#31070;&#32463;&#20803;&#30340;&#36755;&#20986;&#65292;&#35760;&#20316;$\mathcal O_i(u) = \sigma\left( \sum_j \mathcal W_{ij} u + \mathcal B_{ij}\right)$&#12290;&#20854;&#20013;&#65292;$\mathcal W_{ij}$&#34920;&#31034;&#36830;&#25509;&#31532;$j$&#20010;&#36755;&#20837;&#31070;&#32463;&#20803;&#21644;&#31532;$i$&#20010;&#36755;&#20986;&#31070;&#32463;&#20803;&#30340;&#26377;&#30028;&#32447;&#24615;&#31639;&#23376;&#65292;&#32780;&#20559;&#24046;$\mathcal B_{ij}$&#37319;&#29992;&#20989;&#25968;&#24418;&#24335;&#32780;&#38750;&#26631;&#37327;&#24418;&#24335;&#12290;&#36890;&#36807;&#22312;&#20004;&#20010;&#31070;&#32463;&#20803;&#65288;Banach&#31354;&#38388;&#65289;&#20043;&#38388;&#26377;&#25928;&#21442;&#25968;&#21270;&#26377;&#30028;&#32447;&#24615;&#31639;&#23376;&#65292;MgNO&#24341;&#20837;&#20102;&#22810;&#37325;&#32593;&#26684;&#32467;&#26500;&#12290;&#36825;&#31181;&#26041;&#27861;&#26082;&#20855;&#22791;&#20102;&#25968;&#23398;&#20005;&#23494;&#24615;&#65292;&#21448;&#20855;&#22791;&#20102;&#23454;&#29992;&#24615;&#12290;&#27492;&#22806;&#65292;MgNO&#28040;&#38500;&#20102;&#23545;&#20256;&#32479;&#30340;lifting&#21644;projecting&#25805;&#20316;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we propose a concise neural operator architecture for operator learning. Drawing an analogy with a conventional fully connected neural network, we define the neural operator as follows: the output of the $i$-th neuron in a nonlinear operator layer is defined by $\mathcal O_i(u) = \sigma\left( \sum_j \mathcal W_{ij} u + \mathcal B_{ij}\right)$. Here, $\mathcal W_{ij}$ denotes the bounded linear operator connecting $j$-th input neuron to $i$-th output neuron, and the bias $\mathcal B_{ij}$ takes the form of a function rather than a scalar. Given its new universal approximation property, the efficient parameterization of the bounded linear operators between two neurons (Banach spaces) plays a critical role. As a result, we introduce MgNO, utilizing multigrid structures to parameterize these linear operators between neurons. This approach offers both mathematical rigor and practical expressivity. Additionally, MgNO obviates the need for conventional lifting and projecting ope
&lt;/p&gt;</description></item></channel></rss>