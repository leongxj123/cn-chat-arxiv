<rss version="2.0"><channel><title>Chat Arxiv cs.NA</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NA</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#19981;&#36830;&#32493;Galerkin&#26041;&#27861;&#20013;&#21152;&#20837;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#65292;&#23398;&#20064;&#23376;&#32593;&#26684;&#23610;&#24230;&#27169;&#22411;&#30340;&#25928;&#26524;&#65292;&#20174;&#32780;&#25552;&#39640;&#27169;&#25311;&#30340;&#20934;&#30830;&#24615;&#21644;&#21152;&#36895;&#35745;&#31639;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2310.18897</link><description>&lt;p&gt;
&#20351;&#29992;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#22686;&#24378;&#20302;&#38454;&#19981;&#36830;&#32493;Galerkin&#26041;&#27861;&#22312;&#21487;&#21387;Navier-Stokes&#26041;&#31243;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Enhancing Low-Order Discontinuous Galerkin Methods with Neural Ordinary Differential Equations for Compressible Navier--Stokes Equations. (arXiv:2310.18897v2 [physics.flu-dyn] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18897
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#19981;&#36830;&#32493;Galerkin&#26041;&#27861;&#20013;&#21152;&#20837;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#65292;&#23398;&#20064;&#23376;&#32593;&#26684;&#23610;&#24230;&#27169;&#22411;&#30340;&#25928;&#26524;&#65292;&#20174;&#32780;&#25552;&#39640;&#27169;&#25311;&#30340;&#20934;&#30830;&#24615;&#21644;&#21152;&#36895;&#35745;&#31639;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#35745;&#31639;&#33021;&#21147;&#30340;&#22686;&#38271;&#65292;&#27169;&#25311;&#21464;&#24471;&#26356;&#21152;&#22797;&#26434;&#21644;&#20934;&#30830;&#12290;&#28982;&#32780;&#65292;&#39640;&#20445;&#30495;&#24230;&#30340;&#27169;&#25311;&#38656;&#35201;&#24040;&#22823;&#30340;&#35745;&#31639;&#36164;&#28304;&#12290;&#20026;&#20102;&#38477;&#20302;&#35745;&#31639;&#25104;&#26412;&#65292;&#36890;&#24120;&#20250;&#36816;&#34892;&#19968;&#20010;&#20302;&#20445;&#30495;&#24230;&#27169;&#22411;&#24182;&#37319;&#29992;&#23376;&#32593;&#26684;&#23610;&#24230;&#27169;&#22411;&#65292;&#20294;&#36873;&#25321;&#36866;&#24403;&#30340;&#23376;&#32593;&#26684;&#23610;&#24230;&#27169;&#22411;&#24182;&#23545;&#20854;&#36827;&#34892;&#35843;&#33410;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#25105;&#20204;&#22312;&#19981;&#36830;&#32493;Galerkin&#65288;DG&#65289;&#31354;&#38388;&#31163;&#25955;&#21270;&#30340;&#32972;&#26223;&#19979;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#20559;&#24494;&#20998;&#26041;&#31243;&#27169;&#25311;&#20013;&#24341;&#20837;&#31070;&#32463;&#24120;&#24494;&#20998;&#31639;&#23376;&#26469;&#23398;&#20064;&#23376;&#32593;&#26684;&#23610;&#24230;&#27169;&#22411;&#30340;&#25928;&#26524;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#36830;&#32493;&#32423;&#21035;&#19978;&#23398;&#20064;&#20302;&#38454;DG&#27714;&#35299;&#22120;&#20013;&#32570;&#22833;&#30340;&#23610;&#24230;&#65292;&#20174;&#32780;&#25552;&#39640;&#20302;&#38454;DG&#36817;&#20284;&#30340;&#20934;&#30830;&#24615;&#65292;&#21516;&#26102;&#20197;&#19968;&#23450;&#31243;&#24230;&#30340;&#31934;&#24230;&#21152;&#36895;&#28388;&#27874;&#39640;&#38454;DG&#27169;&#25311;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The growing computing power over the years has enabled simulations to become more complex and accurate. While immensely valuable for scientific discovery and problem-solving, however, high-fidelity simulations come with significant computational demands. As a result, it is common to run a low-fidelity model with a subgrid-scale model to reduce the computational cost, but selecting the appropriate subgrid-scale models and tuning them are challenging. We propose a novel method for learning the subgrid-scale model effects when simulating partial differential equations augmented by neural ordinary differential operators in the context of discontinuous Galerkin (DG) spatial discretization. Our approach learns the missing scales of the low-order DG solver at a continuous level and hence improves the accuracy of the low-order DG approximations as well as accelerates the filtered high-order DG simulations with a certain degree of precision. We demonstrate the performance of our approach throug
&lt;/p&gt;</description></item></channel></rss>