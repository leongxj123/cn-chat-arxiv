<rss version="2.0"><channel><title>Chat Arxiv cs.NA</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NA</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;Gromov-Monge&#23884;&#20837;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#36890;&#36807;&#35782;&#21035;&#25968;&#25454;&#32972;&#21518;&#30340;&#24213;&#23618;&#32467;&#26500;&#65292;&#24182;&#23558;&#20854;&#26144;&#23556;&#21040;&#20302;&#32500;&#28508;&#31354;&#38388;&#20013;&#65292;&#35299;&#20915;&#20102;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#20013;&#23545;&#21021;&#22987;&#26465;&#20214;&#25935;&#24863;&#24615;&#21644;&#27169;&#24335;&#23849;&#28291;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2311.01375</link><description>&lt;p&gt;
&#36890;&#36807;Gromov-Monge&#23884;&#20837;&#23454;&#29616;&#21333;&#35843;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Monotone Generative Modeling via a Gromov-Monge Embedding. (arXiv:2311.01375v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01375
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;Gromov-Monge&#23884;&#20837;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#36890;&#36807;&#35782;&#21035;&#25968;&#25454;&#32972;&#21518;&#30340;&#24213;&#23618;&#32467;&#26500;&#65292;&#24182;&#23558;&#20854;&#26144;&#23556;&#21040;&#20302;&#32500;&#28508;&#31354;&#38388;&#20013;&#65292;&#35299;&#20915;&#20102;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#20013;&#23545;&#21021;&#22987;&#26465;&#20214;&#25935;&#24863;&#24615;&#21644;&#27169;&#24335;&#23849;&#28291;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#26159;&#21019;&#24314;&#26032;&#20869;&#23481;&#30340;&#24378;&#22823;&#24037;&#20855;&#65292;&#20294;&#38754;&#20020;&#30528;&#23545;&#21021;&#22987;&#26465;&#20214;&#30340;&#25935;&#24863;&#24615;&#21644;&#27169;&#24335;&#23849;&#28291;&#31561;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;Gromov-Monge&#23884;&#20837;&#65288;GME&#65289;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#12290;&#23427;&#24110;&#21161;&#35782;&#21035;&#25968;&#25454;&#32972;&#21518;&#30340;&#24213;&#23618;&#27979;&#24230;&#30340;&#20302;&#32500;&#32467;&#26500;&#65292;&#28982;&#21518;&#23558;&#20854;&#26144;&#23556;&#21040;&#20445;&#25345;&#20960;&#20309;&#24615;&#36136;&#30340;&#20302;&#32500;&#28508;&#31354;&#38388;&#20013;&#30340;&#19968;&#20010;&#27979;&#24230;&#65292;&#24182;&#23558;&#20854;&#26368;&#20248;&#22320;&#20256;&#36755;&#21040;&#21442;&#32771;&#27979;&#24230;&#12290;&#36890;&#36807;GME&#30340;&#20445;&#25345;&#24213;&#23618;&#20960;&#20309;&#24615;&#36136;&#21644;&#29983;&#25104;&#26144;&#23556;&#30340;$c$-&#21608;&#26399;&#24615;&#21333;&#35843;&#24615;&#26469;&#20445;&#35777;&#23427;&#20204;&#12290;&#21518;&#19968;&#29305;&#24615;&#26159;&#30830;&#20445;&#26356;&#22909;&#30340;&#21442;&#25968;&#21021;&#22987;&#21270;&#40065;&#26834;&#24615;&#21644;&#27169;&#24335;&#23849;&#28291;&#30340;&#31532;&#19968;&#27493;&#12290;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#29983;&#25104;&#39640;&#36136;&#37327;&#22270;&#20687;&#12289;&#36991;&#20813;&#27169;&#24335;&#23849;&#28291;&#21644;&#23545;&#19981;&#21516;&#36215;&#22987;&#26465;&#20214;&#20855;&#26377;&#40065;&#26834;&#24615;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative Adversarial Networks (GANs) are powerful tools for creating new content, but they face challenges such as sensitivity to starting conditions and mode collapse. To address these issues, we propose a deep generative model that utilizes the Gromov-Monge embedding (GME). It helps identify the low-dimensional structure of the underlying measure of the data and then maps it, while preserving its geometry, into a measure in a low-dimensional latent space, which is then optimally transported to the reference measure. We guarantee the preservation of the underlying geometry by the GME and $c$-cyclical monotonicity of the generative map, where $c$ is an intrinsic embedding cost employed by the GME. The latter property is a first step in guaranteeing better robustness to initialization of parameters and mode collapse. Numerical experiments demonstrate the effectiveness of our approach in generating high-quality images, avoiding mode collapse, and exhibiting robustness to different star
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#21644;&#31354;&#38388;&#20998;&#35299;&#26469;&#36817;&#20284;&#30005;&#21147;&#31995;&#32479;&#21160;&#21147;&#23398;&#24494;&#20998;&#20195;&#25968;&#26041;&#31243;&#30340;&#26041;&#27861;&#65292;&#26088;&#22312;&#21152;&#36895;&#20223;&#30495;&#65292;&#25552;&#39640;&#25968;&#20540;&#31283;&#23450;&#24615;&#21644;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2303.10256</link><description>&lt;p&gt;
&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#21644;&#31354;&#38388;&#20998;&#35299;&#22312;&#30005;&#21147;&#31995;&#32479;&#21160;&#21147;&#23398;&#20013;&#27714;&#35299;&#24494;&#20998;&#20195;&#25968;&#26041;&#31243;
&lt;/p&gt;
&lt;p&gt;
Solving Differential-Algebraic Equations in Power Systems Dynamics with Neural Networks and Spatial Decomposition. (arXiv:2303.10256v1 [eess.SY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.10256
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#21644;&#31354;&#38388;&#20998;&#35299;&#26469;&#36817;&#20284;&#30005;&#21147;&#31995;&#32479;&#21160;&#21147;&#23398;&#24494;&#20998;&#20195;&#25968;&#26041;&#31243;&#30340;&#26041;&#27861;&#65292;&#26088;&#22312;&#21152;&#36895;&#20223;&#30495;&#65292;&#25552;&#39640;&#25968;&#20540;&#31283;&#23450;&#24615;&#21644;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30005;&#21147;&#31995;&#32479;&#30340;&#21160;&#21147;&#23398;&#30001;&#19968;&#32452;&#24494;&#20998;&#20195;&#25968;&#26041;&#31243;&#25551;&#36848;&#12290;&#26102;&#38388;&#22495;&#20223;&#30495;&#29992;&#20110;&#29702;&#35299;&#31995;&#32479;&#21160;&#24577;&#30340;&#28436;&#21464;&#12290;&#30001;&#20110;&#31995;&#32479;&#30340;&#21018;&#24230;&#38656;&#35201;&#20351;&#29992;&#31934;&#32454;&#31163;&#25955;&#21270;&#30340;&#26102;&#38388;&#27493;&#38271;&#65292;&#22240;&#27492;&#36825;&#20123;&#20223;&#30495;&#21487;&#33021;&#20855;&#26377;&#35745;&#31639;&#20195;&#20215;&#36739;&#39640;&#30340;&#29305;&#28857;&#12290;&#36890;&#36807;&#22686;&#21152;&#20801;&#35768;&#30340;&#26102;&#38388;&#27493;&#38271;&#65292;&#25105;&#20204;&#26088;&#22312;&#21152;&#24555;&#36825;&#26679;&#30340;&#20223;&#30495;&#12290;&#26412;&#25991;&#20351;&#29992;&#35266;&#23519;&#32467;&#26524;&#65292;&#21363;&#23613;&#31649;&#21508;&#20010;&#32452;&#20214;&#20351;&#29992;&#20195;&#25968;&#21644;&#24494;&#20998;&#26041;&#31243;&#26469;&#25551;&#36848;&#65292;&#20294;&#23427;&#20204;&#30340;&#32806;&#21512;&#20165;&#28041;&#21450;&#20195;&#25968;&#26041;&#31243;&#30340;&#35266;&#23519;&#32467;&#26524;&#65292;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#26469;&#36817;&#20284;&#32452;&#20214;&#29366;&#24577;&#28436;&#21464;&#65292;&#20174;&#32780;&#20135;&#29983;&#24555;&#36895;&#12289;&#20934;&#30830;&#21644;&#25968;&#20540;&#31283;&#23450;&#30340;&#36817;&#20284;&#22120;&#65292;&#20351;&#24471;&#21487;&#20197;&#20351;&#29992;&#26356;&#22823;&#30340;&#26102;&#38388;&#27493;&#38271;&#12290;&#20026;&#20102;&#35299;&#37322;&#32593;&#32476;&#23545;&#32452;&#20214;&#20197;&#21450;&#32452;&#20214;&#23545;&#32593;&#32476;&#30340;&#24433;&#21709;&#65292;NN&#23558;&#32806;&#21512;&#20195;&#25968;&#21464;&#37327;&#30340;&#26102;&#38388;&#28436;&#21270;&#20316;&#20026;&#20854;&#39044;&#27979;&#30340;&#36755;&#20837;&#12290;&#25105;&#20204;&#26368;&#21021;&#20351;&#29992;&#31354;&#38388;&#20998;&#35299;&#26041;&#27861;&#26469;&#20272;&#35745;NN&#65292;&#20854;&#20013;&#31995;&#32479;&#34987;&#20998;&#25104;&#31354;&#38388;&#21306;&#22495;&#65292;&#27599;&#20010;&#21306;&#22495;&#26377;&#21333;&#29420;&#30340;NN&#20272;&#35745;&#22120;&#12290;&#25105;&#20204;&#23558;&#22522;&#20110;NN&#30340;&#20223;&#30495;&#19982;&#20256;&#32479;&#30340;&#25968;&#20540;&#31215;&#20998;&#26041;&#26696;&#36827;&#34892;&#27604;&#36739;&#65292;&#20197;&#23637;&#31034;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The dynamics of the power system are described by a system of differential-algebraic equations. Time-domain simulations are used to understand the evolution of the system dynamics. These simulations can be computationally expensive due to the stiffness of the system which requires the use of finely discretized time-steps. By increasing the allowable time-step size, we aim to accelerate such simulations. In this paper, we use the observation that even though the individual components are described using both algebraic and differential equations, their coupling only involves algebraic equations. Following this observation, we use Neural Networks (NNs) to approximate the components' state evolution, leading to fast, accurate, and numerically stable approximators, which enable larger time-steps. To account for effects of the network on the components and vice-versa, the NNs take the temporal evolution of the coupling algebraic variables as an input for their prediction. We initially estima
&lt;/p&gt;</description></item></channel></rss>