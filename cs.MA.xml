<rss version="2.0"><channel><title>Chat Arxiv cs.MA</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.MA</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#22478;&#24066;&#29615;&#22659;&#19979;&#30340;&#33258;&#20027;&#22810;&#26234;&#33021;&#20307;&#20986;&#31199;&#36710;&#36335;&#24452;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#36817;&#20284;&#28378;&#21160;&#20026;&#22522;&#30784;&#30340;&#20004;&#38454;&#27573;&#31639;&#27861;&#26469;&#20943;&#23569;&#35745;&#31639;&#37327;&#12290;</title><link>http://arxiv.org/abs/2311.01534</link><description>&lt;p&gt;
&#22823;&#22411;&#22320;&#22270;&#19978;&#30340;&#25353;&#38656;&#22478;&#24066;&#20986;&#34892;&#38382;&#39064;&#30340;&#36817;&#20284;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#65288;&#25193;&#23637;&#29256;&#65289;
&lt;/p&gt;
&lt;p&gt;
Approximate Multiagent Reinforcement Learning for On-Demand Urban Mobility Problem on a Large Map (extended version). (arXiv:2311.01534v1 [cs.MA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01534
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#22478;&#24066;&#29615;&#22659;&#19979;&#30340;&#33258;&#20027;&#22810;&#26234;&#33021;&#20307;&#20986;&#31199;&#36710;&#36335;&#24452;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#36817;&#20284;&#28378;&#21160;&#20026;&#22522;&#30784;&#30340;&#20004;&#38454;&#27573;&#31639;&#27861;&#26469;&#20943;&#23569;&#35745;&#31639;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;&#22823;&#22411;&#22478;&#24066;&#29615;&#22659;&#19979;&#30340;&#33258;&#20027;&#22810;&#26234;&#33021;&#20307;&#20986;&#31199;&#36710;&#36335;&#24452;&#38382;&#39064;&#65292;&#26410;&#26469;&#20056;&#36710;&#35831;&#27714;&#30340;&#20301;&#32622;&#21644;&#25968;&#37327;&#20107;&#20808;&#26410;&#30693;&#65292;&#20294;&#36981;&#24490;&#20272;&#35745;&#30340;&#32463;&#39564;&#20998;&#24067;&#12290;&#26368;&#36817;&#30340;&#29702;&#35770;&#34920;&#26126;&#65292;&#22914;&#26524;&#22522;&#30784;&#31574;&#30053;&#26159;&#31283;&#23450;&#30340;&#65292;&#37027;&#20040;&#22522;&#20110;&#28378;&#21160;&#30340;&#31639;&#27861;&#19982;&#36825;&#26679;&#30340;&#22522;&#30784;&#31574;&#30053;&#20135;&#29983;&#25509;&#36817;&#26368;&#20248;&#30340;&#31283;&#23450;&#31574;&#30053;&#12290;&#23613;&#31649;&#22522;&#20110;&#28378;&#21160;&#30340;&#26041;&#27861;&#38750;&#24120;&#36866;&#21512;&#23398;&#20064;&#20855;&#26377;&#23545;&#26410;&#26469;&#38656;&#27714;&#32771;&#34385;&#30340;&#21512;&#20316;&#22810;&#26234;&#33021;&#20307;&#31574;&#30053;&#65292;&#20294;&#23558;&#36825;&#20123;&#26041;&#27861;&#24212;&#29992;&#20110;&#22823;&#22411;&#22478;&#24066;&#29615;&#22659;&#21487;&#33021;&#35745;&#31639;&#19978;&#24456;&#26114;&#36149;&#12290;&#22823;&#22411;&#29615;&#22659;&#24448;&#24448;&#26377;&#22823;&#37327;&#35831;&#27714;&#65292;&#22240;&#27492;&#38656;&#35201;&#22823;&#22411;&#30340;&#20986;&#31199;&#36710;&#38431;&#20445;&#35777;&#31283;&#23450;&#24615;&#12290;&#26412;&#25991;&#26088;&#22312;&#35299;&#20915;&#22810;&#26234;&#33021;&#20307;&#65288;&#36880;&#19968;&#65289;&#28378;&#21160;&#30340;&#35745;&#31639;&#29942;&#39048;&#38382;&#39064;&#65292;&#20854;&#20013;&#35745;&#31639;&#22797;&#26434;&#24615;&#38543;&#20195;&#29702;&#25968;&#37327;&#32447;&#24615;&#22686;&#38271;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20284;&#36880;&#19968;&#28378;&#21160;&#20026;&#22522;&#30784;&#30340;&#20004;&#38454;&#27573;&#31639;&#27861;&#65292;&#20943;&#23569;&#35745;&#31639;&#37327;
&lt;/p&gt;
&lt;p&gt;
In this paper, we focus on the autonomous multiagent taxi routing problem for a large urban environment where the location and number of future ride requests are unknown a-priori, but follow an estimated empirical distribution. Recent theory has shown that if a base policy is stable then a rollout-based algorithm with such a base policy produces a near-optimal stable policy. Although, rollout-based approaches are well-suited for learning cooperative multiagent policies with considerations for future demand, applying such methods to a large urban environment can be computationally expensive. Large environments tend to have a large volume of requests, and hence require a large fleet of taxis to guarantee stability. In this paper, we aim to address the computational bottleneck of multiagent (one-at-a-time) rollout, where the computational complexity grows linearly in the number of agents. We propose an approximate one-at-a-time rollout-based two-phase algorithm that reduces the computatio
&lt;/p&gt;</description></item></channel></rss>