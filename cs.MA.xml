<rss version="2.0"><channel><title>Chat Arxiv cs.MA</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.MA</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#28436;&#32462;&#24335;&#30340;&#22270;&#35889;&#36777;&#35770;&#26041;&#27861;&#65288;BDoG&#65289;&#65292;&#22312;&#22810;&#27169;&#24577;&#25512;&#29702;&#20013;&#38450;&#27490;&#24847;&#35265;&#38472;&#33104;&#21270;&#21644;&#20943;&#23569;&#30001;&#22270;&#20687;&#24341;&#20837;&#30340;&#20998;&#24515;&#27010;&#24565;&#65292;&#23454;&#39564;&#35777;&#26126;&#20854;&#22312;&#31185;&#23398;&#38382;&#31572;&#21644;MMBench&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2403.14972</link><description>&lt;p&gt;
&#19968;&#22270;&#32988;&#21315;&#35328;&#65306;&#22810;&#27169;&#24577;&#25512;&#29702;&#20013;&#30340;&#22270;&#35889;&#36777;&#35770;
&lt;/p&gt;
&lt;p&gt;
A Picture Is Worth a Graph: Blueprint Debate on Graph for Multimodal Reasoning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14972
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#28436;&#32462;&#24335;&#30340;&#22270;&#35889;&#36777;&#35770;&#26041;&#27861;&#65288;BDoG&#65289;&#65292;&#22312;&#22810;&#27169;&#24577;&#25512;&#29702;&#20013;&#38450;&#27490;&#24847;&#35265;&#38472;&#33104;&#21270;&#21644;&#20943;&#23569;&#30001;&#22270;&#20687;&#24341;&#20837;&#30340;&#20998;&#24515;&#27010;&#24565;&#65292;&#23454;&#39564;&#35777;&#26126;&#20854;&#22312;&#31185;&#23398;&#38382;&#31572;&#21644;MMBench&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#39033;&#26088;&#22312;&#23558;&#22810;&#26234;&#33021;&#20307;&#36777;&#35770;&#24341;&#20837;&#22810;&#27169;&#24577;&#25512;&#29702;&#30340;&#35797;&#28857;&#30740;&#31350;&#12290;&#35813;&#30740;&#31350;&#35299;&#20915;&#20102;&#20004;&#20010;&#20851;&#38190;&#25361;&#25112;&#65306;&#30001;&#20110;&#36807;&#24230;&#24635;&#32467;&#32780;&#23548;&#33268;&#24847;&#35265;&#38472;&#33104;&#21270;&#65292;&#20197;&#21450;&#30001;&#20110;&#22270;&#20687;&#24341;&#20837;&#36716;&#31227;&#24615;&#27010;&#24565;&#32780;&#23548;&#33268;&#27880;&#24847;&#21147;&#20998;&#25955;&#30340;&#38382;&#39064;&#12290;&#36825;&#20123;&#25361;&#25112;&#28304;&#33258;&#29616;&#26377;&#36777;&#35770;&#26041;&#26696;&#30340;&#24402;&#32435;&#65288;&#33258;&#19979;&#32780;&#19978;&#65289;&#24615;&#36136;&#12290;&#20026;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#28436;&#32462;&#65288;&#33258;&#19978;&#32780;&#19979;&#65289;&#30340;&#36777;&#35770;&#26041;&#27861;&#65292;&#31216;&#20026;&#22270;&#35889;&#36777;&#35770;&#65288;BDoG&#65289;&#12290;&#22312;BDoG&#20013;&#65292;&#36777;&#35770;&#20165;&#38480;&#20110;&#34013;&#22270;&#22270;&#20013;&#65292;&#20197;&#38450;&#27490;&#36890;&#36807;&#19990;&#30028;&#32423;&#25688;&#35201;&#32780;&#23548;&#33268;&#24847;&#35265;&#38472;&#33104;&#21270;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#22312;&#22270;&#20013;&#30340;&#20998;&#25903;&#20013;&#23384;&#20648;&#35777;&#25454;&#65292;BDoG&#32531;&#35299;&#20102;&#39057;&#32321;&#20294;&#26080;&#20851;&#30340;&#27010;&#24565;&#24102;&#26469;&#30340;&#20998;&#25955;&#27880;&#24847;&#21147;&#29616;&#35937;&#12290;&#22823;&#37327;&#23454;&#39564;&#39564;&#35777;&#20102;BDoG&#65292;&#22312;&#31185;&#23398;&#38382;&#31572;&#21644;MMBench&#20013;&#21462;&#24471;&#20102;&#26368;&#26032;&#25104;&#26524;&#65292;&#24182;&#30456;&#36739;&#20110;&#20808;&#21069;&#30340;&#26041;&#27861;&#20855;&#26377;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14972v1 Announce Type: new  Abstract: This paper presents a pilot study aimed at introducing multi-agent debate into multimodal reasoning. The study addresses two key challenges: the trivialization of opinions resulting from excessive summarization and the diversion of focus caused by distractor concepts introduced from images. These challenges stem from the inductive (bottom-up) nature of existing debating schemes. To address the issue, we propose a deductive (top-down) debating approach called Blueprint Debate on Graphs (BDoG). In BDoG, debates are confined to a blueprint graph to prevent opinion trivialization through world-level summarization. Moreover, by storing evidence in branches within the graph, BDoG mitigates distractions caused by frequent but irrelevant concepts. Extensive experiments validate BDoG, achieving state-of-the-art results in Science QA and MMBench with significant improvements over previous methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#22996;&#25176;&#28216;&#25103;&#20013;&#25506;&#35752;&#20102;&#25511;&#21046;&#38382;&#39064;&#65288;&#20195;&#29702;&#20154;&#26410;&#33021;&#25353;&#29031;&#20854;&#22996;&#25176;&#20154;&#30340;&#20559;&#22909;&#34892;&#20107;&#65289;&#21644;&#21512;&#20316;&#38382;&#39064;&#65288;&#20195;&#29702;&#20154;&#26410;&#33021;&#33391;&#22909;&#22320;&#21327;&#20316;&#65289;&#65292;&#24182;&#20998;&#26512;&#20102;&#23545;&#40784;&#21644;&#33021;&#21147;&#23545;&#22996;&#25176;&#20154;&#31119;&#21033;&#30340;&#24433;&#21709;&#12290;en_tdlr: This paper explores the issues of control (agents failing to act in line with their principals' preferences) and cooperation (agents failing to work well together) in delegation games, analyzing how alignment and capabilities impact principals' welfare.</title><link>https://arxiv.org/abs/2402.15821</link><description>&lt;p&gt;
&#22996;&#25176;&#28216;&#25103;&#20013;&#30340;&#21512;&#20316;&#19982;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Cooperation and Control in Delegation Games
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15821
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#22996;&#25176;&#28216;&#25103;&#20013;&#25506;&#35752;&#20102;&#25511;&#21046;&#38382;&#39064;&#65288;&#20195;&#29702;&#20154;&#26410;&#33021;&#25353;&#29031;&#20854;&#22996;&#25176;&#20154;&#30340;&#20559;&#22909;&#34892;&#20107;&#65289;&#21644;&#21512;&#20316;&#38382;&#39064;&#65288;&#20195;&#29702;&#20154;&#26410;&#33021;&#33391;&#22909;&#22320;&#21327;&#20316;&#65289;&#65292;&#24182;&#20998;&#26512;&#20102;&#23545;&#40784;&#21644;&#33021;&#21147;&#23545;&#22996;&#25176;&#20154;&#31119;&#21033;&#30340;&#24433;&#21709;&#12290;en_tdlr: This paper explores the issues of control (agents failing to act in line with their principals' preferences) and cooperation (agents failing to work well together) in delegation games, analyzing how alignment and capabilities impact principals' welfare.
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#28041;&#21450;&#20154;&#31867;&#21644;&#26426;&#22120;&#30340;&#24863;&#20852;&#36259;&#30340;&#22330;&#26223; - &#20174;&#34394;&#25311;&#20010;&#20154;&#21161;&#29702;&#21040;&#33258;&#21160;&#39550;&#39542;&#36710;&#36742; - &#21487;&#20197;&#33258;&#28982;&#22320;&#24314;&#27169;&#20026;&#22996;&#25176;&#20154;&#65288;&#20154;&#31867;&#65289;&#22996;&#25176;&#32473;&#20195;&#29702;&#20154;&#65288;&#26426;&#22120;&#65289;&#65292;&#36825;&#20123;&#20195;&#29702;&#20154;&#20043;&#21518;&#20195;&#34920;&#20182;&#20204;&#30340;&#22996;&#25176;&#20154;&#30456;&#20114;&#20132;&#20114;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#22810;&#22996;&#25176;&#20154;&#65292;&#22810;&#20195;&#29702;&#20154;&#30340;&#24773;&#20917;&#31216;&#20026;&#22996;&#25176;&#28216;&#25103;&#12290;&#22312;&#36825;&#31867;&#28216;&#25103;&#20013;&#65292;&#23384;&#22312;&#20004;&#31181;&#37325;&#35201;&#30340;&#22833;&#36133;&#27169;&#24335;&#65306;&#25511;&#21046;&#38382;&#39064;&#65288;&#20195;&#29702;&#20154;&#26410;&#33021;&#25353;&#29031;&#20854;&#22996;&#25176;&#20154;&#30340;&#20559;&#22909;&#34892;&#20107;&#65289;&#21644;&#21512;&#20316;&#38382;&#39064;&#65288;&#20195;&#29702;&#20154;&#26410;&#33021;&#33391;&#22909;&#22320;&#21327;&#20316;&#65289;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24418;&#24335;&#21270;&#21644;&#20998;&#26512;&#36825;&#20123;&#38382;&#39064;&#65292;&#36827;&#19968;&#27493;&#23558;&#20854;&#35299;&#37322;&#20026;&#23545;&#40784;&#65288;&#21442;&#19982;&#32773;&#26159;&#21542;&#20855;&#26377;&#30456;&#20284;&#30340;&#20559;&#22909;&#65311;&#65289;&#21644;&#33021;&#21147;&#65288;&#21442;&#19982;&#32773;&#22312;&#28385;&#36275;&#36825;&#20123;&#20559;&#22909;&#26041;&#38754;&#30340;&#33021;&#21147;&#22914;&#20309;&#65311;&#65289;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#29702;&#35770;&#19978;&#21644;&#32463;&#39564;&#19978;&#23637;&#31034;&#20102;&#36825;&#20123;&#25514;&#26045;&#22914;&#20309;&#30830;&#23450;&#22996;&#25176;&#20154;&#30340;&#31119;&#21033;&#65292;&#22914;&#20309;&#21487;&#20197;&#20351;&#29992;&#26377;&#38480;&#30340;&#35266;&#23519;&#26469;&#20272;&#35745;&#36825;&#20123;&#25514;&#26045;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15821v1 Announce Type: cross  Abstract: Many settings of interest involving humans and machines -- from virtual personal assistants to autonomous vehicles -- can naturally be modelled as principals (humans) delegating to agents (machines), which then interact with each other on their principals' behalf. We refer to these multi-principal, multi-agent scenarios as delegation games. In such games, there are two important failure modes: problems of control (where an agent fails to act in line their principal's preferences) and problems of cooperation (where the agents fail to work well together). In this paper we formalise and analyse these problems, further breaking them down into issues of alignment (do the players have similar preferences?) and capabilities (how competent are the players at satisfying those preferences?). We show -- theoretically and empirically -- how these measures determine the principals' welfare, how they can be estimated using limited observations, and 
&lt;/p&gt;</description></item></channel></rss>