<rss version="2.0"><channel><title>Chat Arxiv cs.MA</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.MA</description><item><title>&#36825;&#39033;&#30740;&#31350;&#38024;&#23545;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#25552;&#20986;&#20102;&#19968;&#31181;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#36890;&#20449;&#26041;&#26696;&#65292;&#36890;&#36807;&#20004;&#20010;&#38454;&#27573;&#30340;&#20132;&#27969;&#65292;&#20351;&#26234;&#33021;&#20307;&#33021;&#22815;&#21457;&#36865;&#20010;&#24615;&#21270;&#30340;&#28040;&#24687;&#65292;&#20174;&#32780;&#25552;&#39640;&#21512;&#20316;&#21644;&#22242;&#38431;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2312.15600</link><description>&lt;p&gt;
&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#36890;&#20449;
&lt;/p&gt;
&lt;p&gt;
Context-aware Communication for Multi-agent Reinforcement Learning. (arXiv:2312.15600v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.15600
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#38024;&#23545;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#25552;&#20986;&#20102;&#19968;&#31181;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#36890;&#20449;&#26041;&#26696;&#65292;&#36890;&#36807;&#20004;&#20010;&#38454;&#27573;&#30340;&#20132;&#27969;&#65292;&#20351;&#26234;&#33021;&#20307;&#33021;&#22815;&#21457;&#36865;&#20010;&#24615;&#21270;&#30340;&#28040;&#24687;&#65292;&#20174;&#32780;&#25552;&#39640;&#21512;&#20316;&#21644;&#22242;&#38431;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#65288;MARL&#65289;&#65292;&#26377;&#25928;&#30340;&#36890;&#20449;&#21327;&#35758;&#23545;&#20110;&#20419;&#36827;&#21512;&#20316;&#21644;&#25552;&#39640;&#22242;&#38431;&#24615;&#33021;&#33267;&#20851;&#37325;&#35201;&#12290;&#20026;&#20102;&#21033;&#29992;&#36890;&#20449;&#65292;&#35768;&#22810;&#20197;&#21069;&#30340;&#24037;&#20316;&#25552;&#20986;&#23558;&#26412;&#22320;&#20449;&#24687;&#21387;&#32553;&#25104;&#19968;&#26465;&#28040;&#24687;&#24182;&#24191;&#25773;&#32473;&#25152;&#26377;&#21487;&#36798;&#30340;&#26234;&#33021;&#20307;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#31616;&#21333;&#30340;&#28040;&#24687;&#20256;&#36882;&#26426;&#21046;&#21487;&#33021;&#26080;&#27861;&#20026;&#20010;&#20307;&#26234;&#33021;&#20307;&#25552;&#20379;&#36275;&#22815;&#12289;&#20851;&#38190;&#21644;&#30456;&#20851;&#30340;&#20449;&#24687;&#65292;&#29305;&#21035;&#26159;&#22312;&#24102;&#23485;&#20005;&#37325;&#26377;&#38480;&#30340;&#22330;&#26223;&#19979;&#12290;&#36825;&#28608;&#21169;&#25105;&#20204;&#20026;MARL&#24320;&#21457;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#36890;&#20449;&#26041;&#26696;&#65292;&#26088;&#22312;&#21521;&#19981;&#21516;&#30340;&#26234;&#33021;&#20307;&#21457;&#36865;&#20010;&#24615;&#21270;&#30340;&#28040;&#24687;&#12290;&#25105;&#20204;&#30340;&#36890;&#20449;&#21327;&#35758;&#21517;&#20026;CACOM&#65292;&#30001;&#20004;&#20010;&#38454;&#27573;&#32452;&#25104;&#12290;&#31532;&#19968;&#20010;&#38454;&#27573;&#20013;&#65292;&#26234;&#33021;&#20307;&#20197;&#24191;&#25773;&#26041;&#24335;&#20132;&#25442;&#31895;&#30053;&#34920;&#31034;&#65292;&#20026;&#31532;&#20108;&#20010;&#38454;&#27573;&#25552;&#20379;&#19978;&#19979;&#25991;&#20449;&#24687;&#12290;&#32039;&#38543;&#20854;&#21518;&#65292;&#26234;&#33021;&#20307;&#22312;&#31532;&#20108;&#20010;&#38454;&#27573;&#20013;&#21033;&#29992;&#27880;&#24847;&#26426;&#21046;&#20026;&#25509;&#25910;&#32773;&#36873;&#25321;&#24615;&#29983;&#25104;&#20010;&#24615;&#21270;&#30340;&#28040;&#24687;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#37319;&#29992;&#20102;&#23398;&#20064;&#30340;&#27493;&#38271;&#37327;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Effective communication protocols in multi-agent reinforcement learning (MARL) are critical to fostering cooperation and enhancing team performance. To leverage communication, many previous works have proposed to compress local information into a single message and broadcast it to all reachable agents. This simplistic messaging mechanism, however, may fail to provide adequate, critical, and relevant information to individual agents, especially in severely bandwidth-limited scenarios. This motivates us to develop context-aware communication schemes for MARL, aiming to deliver personalized messages to different agents. Our communication protocol, named CACOM, consists of two stages. In the first stage, agents exchange coarse representations in a broadcast fashion, providing context for the second stage. Following this, agents utilize attention mechanisms in the second stage to selectively generate messages personalized for the receivers. Furthermore, we employ the learned step size quant
&lt;/p&gt;</description></item></channel></rss>