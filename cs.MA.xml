<rss version="2.0"><channel><title>Chat Arxiv cs.MA</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.MA</description><item><title>&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#20026;&#22522;&#30784;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#29436;&#20154;&#26432;&#28216;&#25103;&#20013;&#24320;&#21457;&#20855;&#26377;&#28789;&#27963;&#35821;&#35328;&#34892;&#20026;&#21644;&#24378;&#22823;&#20915;&#31574;&#33021;&#21147;&#30340;&#25112;&#30053;&#35821;&#35328;&#20195;&#29702;</title><link>https://arxiv.org/abs/2310.18940</link><description>&lt;p&gt;
&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#30340;&#35821;&#35328;&#20195;&#29702;&#22312;&#29436;&#20154;&#26432;&#28216;&#25103;&#20013;&#36827;&#34892;&#25112;&#30053;&#23545;&#25112;
&lt;/p&gt;
&lt;p&gt;
Language Agents with Reinforcement Learning for Strategic Play in the Werewolf Game
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2310.18940
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#20026;&#22522;&#30784;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#29436;&#20154;&#26432;&#28216;&#25103;&#20013;&#24320;&#21457;&#20855;&#26377;&#28789;&#27963;&#35821;&#35328;&#34892;&#20026;&#21644;&#24378;&#22823;&#20915;&#31574;&#33021;&#21147;&#30340;&#25112;&#30053;&#35821;&#35328;&#20195;&#29702;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26500;&#24314;&#30340;&#20195;&#29702;&#22312;&#21508;&#39046;&#22495;&#23637;&#29616;&#20986;&#24040;&#22823;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#22312;&#22797;&#26434;&#20915;&#31574;&#20219;&#21153;&#20013;&#65292;&#32431;LLM&#20195;&#29702;&#24448;&#24448;&#34920;&#29616;&#20986;&#22266;&#26377;&#20559;&#35265;&#65292;&#36825;&#20123;&#20559;&#35265;&#26469;&#28304;&#20110;&#27169;&#22411;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#23548;&#33268;&#24615;&#33021;&#19981;&#20339;&#12290;&#20026;&#20102;&#24320;&#21457;&#20855;&#26377;&#28789;&#27963;&#35821;&#35328;&#34892;&#20026;&#21644;&#24378;&#22823;&#20915;&#31574;&#33021;&#21147;&#30340;&#25112;&#30053;&#35821;&#35328;&#20195;&#29702;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#25552;&#21319;LLM&#20195;&#29702;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#36873;&#25321;&#29436;&#20154;&#26432;&#20316;&#20026;&#20855;&#26377;&#22810;&#26679;&#27807;&#36890;&#21644;&#25112;&#30053;&#28216;&#25103;&#29609;&#27861;&#30340;&#25361;&#25112;&#27979;&#35797;&#24179;&#21488;&#12290;&#20026;&#20102;&#20943;&#36731;&#35821;&#35328;&#34892;&#20026;&#20013;&#30340;&#22266;&#26377;&#20559;&#35265;&#65292;&#25105;&#20204;&#30340;&#20195;&#29702;&#20351;&#29992;LLM&#36827;&#34892;&#28436;&#32462;&#25512;&#29702;&#24182;&#29983;&#25104;&#22810;&#26679;&#34892;&#20026;&#20505;&#36873;&#38598;&#12290;&#28982;&#21518;&#65292;&#32463;&#36807;&#35757;&#32451;&#20197;&#20248;&#21270;&#20915;&#31574;&#33021;&#21147;&#30340;RL&#31574;&#30053;&#20174;&#20505;&#36873;&#38598;&#20013;&#36873;&#25321;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2310.18940v3 Announce Type: replace  Abstract: Agents built with large language models (LLMs) have shown great potential across a wide range of domains. However, in complex decision-making tasks, pure LLM-based agents tend to exhibit intrinsic bias in their choice of actions, which is inherited from the model's training data and results in suboptimal performance. To develop strategic language agents, i.e., agents that generate flexible language actions and possess strong decision-making abilities, we propose a novel framework that powers LLM-based agents with reinforcement learning (RL). We consider Werewolf, a popular social deduction game, as a challenging testbed that emphasizes versatile communication and strategic gameplay. To mitigate the intrinsic bias in language actions, our agents use an LLM to perform deductive reasoning and generate a diverse set of action candidates. Then an RL policy trained to optimize the decision-making ability chooses an action from the candidat
&lt;/p&gt;</description></item></channel></rss>