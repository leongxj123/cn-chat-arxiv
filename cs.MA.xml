<rss version="2.0"><channel><title>Chat Arxiv cs.MA</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.MA</description><item><title>&#20351;&#29992;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;(MARL)&#35782;&#21035;&#26410;&#31934;&#32454;&#35299;&#26512;&#30340;PDEs&#20013;&#30340;&#38381;&#21512;&#39033;&#65292;&#36890;&#36807;&#37096;&#32626;&#20013;&#22830;&#31574;&#30053;&#21644;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;(CNN)&#65292;&#33021;&#22815;&#20934;&#30830;&#39044;&#27979;&#21644;&#21152;&#36895;&#27169;&#25311;&#12290;</title><link>https://rss.arxiv.org/abs/2402.00972</link><description>&lt;p&gt;
&#36890;&#36807;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#35782;&#21035;&#31895;&#31890;&#24230;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#38381;&#21512;&#39033;
&lt;/p&gt;
&lt;p&gt;
Closure Discovery for Coarse-Grained Partial Differential Equations using Multi-Agent Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.00972
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;(MARL)&#35782;&#21035;&#26410;&#31934;&#32454;&#35299;&#26512;&#30340;PDEs&#20013;&#30340;&#38381;&#21512;&#39033;&#65292;&#36890;&#36807;&#37096;&#32626;&#20013;&#22830;&#31574;&#30053;&#21644;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;(CNN)&#65292;&#33021;&#22815;&#20934;&#30830;&#39044;&#27979;&#21644;&#21152;&#36895;&#27169;&#25311;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#38752;&#22320;&#39044;&#27979;&#22825;&#27668;&#12289;&#37326;&#28779;&#21644;&#27969;&#34892;&#30149;&#31561;&#20851;&#38190;&#29616;&#35937;&#36890;&#24120;&#22522;&#20110;&#30001;&#20559;&#24494;&#20998;&#26041;&#31243;(PDEs)&#25551;&#36848;&#30340;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#25429;&#25417;&#36825;&#31181;PDEs&#20013;&#20840;&#38754;&#30340;&#26102;&#31354;&#23610;&#24230;&#33539;&#22260;&#30340;&#27169;&#25311;&#36890;&#24120;&#26159;&#20195;&#20215;&#39640;&#26114;&#30340;&#12290;&#22240;&#27492;&#65292;&#36890;&#24120;&#20250;&#20351;&#29992;&#21033;&#29992;&#21551;&#21457;&#24335;&#26041;&#27861;&#21644;&#32463;&#39564;&#38381;&#21512;&#39033;&#30340;&#31895;&#31890;&#24230;&#27169;&#25311;&#20316;&#20026;&#26367;&#20195;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;(MARL)&#35782;&#21035;&#26410;&#31934;&#32454;&#35299;&#26512;&#30340;PDEs&#20013;&#38381;&#21512;&#39033;&#30340;&#26032;&#39062;&#21644;&#31995;&#32479;&#30340;&#26041;&#27861;&#12290;MARL&#30340;&#24418;&#24335;&#21270;&#32467;&#21512;&#20102;&#24402;&#32435;&#20559;&#24046;&#65292;&#24182;&#21033;&#29992;&#37096;&#32626;&#20102;&#30001;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;(CNN)&#39640;&#25928;&#34920;&#31034;&#30340;&#20013;&#22830;&#31574;&#30053;&#26469;&#21033;&#29992;&#23616;&#37096;&#24615;&#12290;&#36890;&#36807;&#23545;&#23545;&#27969;&#26041;&#31243;&#21644;Burgers&#26041;&#31243;&#30340;&#25968;&#20540;&#35299;&#36827;&#34892;&#28436;&#31034;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;MARL&#30340;&#33021;&#21147;&#21644;&#38480;&#21046;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26174;&#31034;&#65292;MARL&#23545;&#20110;&#20869;&#22806;&#20998;&#24067;&#30340;&#27979;&#35797;&#26696;&#20363;&#21487;&#20197;&#20934;&#30830;&#39044;&#27979;&#65292;&#24182;&#19988;&#19982;&#31934;&#32454;&#35299;&#26512;&#30456;&#27604;&#26377;&#26174;&#33879;&#30340;&#21152;&#36895;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reliable predictions of critical phenomena, such as weather, wildfires and epidemics are often founded on models described by Partial Differential Equations (PDEs). However, simulations that capture the full range of spatio-temporal scales in such PDEs are often prohibitively expensive. Consequently, coarse-grained simulations that employ heuristics and empirical closure terms are frequently utilized as an alternative. We propose a novel and systematic approach for identifying closures in under-resolved PDEs using Multi-Agent Reinforcement Learning (MARL). The MARL formulation incorporates inductive bias and exploits locality by deploying a central policy represented efficiently by Convolutional Neural Networks (CNN). We demonstrate the capabilities and limitations of MARL through numerical solutions of the advection equation and the Burgers' equation. Our results show accurate predictions for in- and out-of-distribution test cases as well as a significant speedup compared to resolving
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22810;&#26234;&#33021;&#20307;&#21327;&#20316;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26694;&#26550;&#65292;&#26088;&#22312;&#25552;&#39640;&#22522;&#20110;&#30693;&#35782;&#30340;&#25512;&#29702;&#30340;&#24544;&#23454;&#24230;&#21644;&#22240;&#26524;&#24615;&#65292;&#36890;&#36807;&#25512;&#29702;&#22120;&#21644;&#22240;&#26524;&#35780;&#20272;&#22120;&#30340;&#21512;&#20316;&#26469;&#35299;&#20915;&#25512;&#29702;&#35884;&#35823;&#12290;</title><link>http://arxiv.org/abs/2308.11914</link><description>&lt;p&gt;
&#36808;&#21521;&#22240;&#26524;GPT&#65306;&#36890;&#36807;&#20419;&#36827;LLMs&#20013;&#30340;&#22240;&#26524;&#19968;&#33268;&#24615;&#65292;&#22522;&#20110;&#22810;&#26234;&#33021;&#20307;&#30340;&#26041;&#27861;&#23454;&#29616;&#24544;&#23454;&#30340;&#30693;&#35782;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Towards CausalGPT: A Multi-Agent Approach for Faithful Knowledge Reasoning via Promoting Causal Consistency in LLMs. (arXiv:2308.11914v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11914
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22810;&#26234;&#33021;&#20307;&#21327;&#20316;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26694;&#26550;&#65292;&#26088;&#22312;&#25552;&#39640;&#22522;&#20110;&#30693;&#35782;&#30340;&#25512;&#29702;&#30340;&#24544;&#23454;&#24230;&#21644;&#22240;&#26524;&#24615;&#65292;&#36890;&#36807;&#25512;&#29702;&#22120;&#21644;&#22240;&#26524;&#35780;&#20272;&#22120;&#30340;&#21512;&#20316;&#26469;&#35299;&#20915;&#25512;&#29702;&#35884;&#35823;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;LLMs&#30340;&#21457;&#23637;&#21462;&#24471;&#20102;&#19968;&#20123;&#36827;&#23637;&#65292;&#20294;&#22522;&#20110;&#30693;&#35782;&#30340;&#25512;&#29702;&#20173;&#28982;&#26159;&#19968;&#20010;&#38271;&#26399;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#36825;&#26159;&#30001;&#20110;&#30693;&#35782;&#22238;&#24518;&#21644;&#25512;&#29702;&#30340;&#33030;&#24369;&#24615;&#24341;&#36215;&#30340;&#12290;&#29616;&#26377;&#26041;&#27861;&#20027;&#35201;&#36890;&#36807;&#40723;&#21169;LLMs&#33258;&#20027;&#35745;&#21010;&#21644;&#35299;&#20915;&#38382;&#39064;&#25110;&#24191;&#27867;&#37319;&#26679;&#25512;&#29702;&#38142;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20294;&#26410;&#33021;&#35299;&#20915;&#27010;&#24565;&#21644;&#25512;&#29702;&#35884;&#35823;&#12290;&#20026;&#20102;&#20943;&#23569;&#25512;&#29702;&#35884;&#35823;&#65292;&#25105;&#20204;&#20174;&#22810;&#26234;&#33021;&#20307;&#21327;&#20316;&#20013;&#24471;&#21040;&#21551;&#21457;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#26469;&#22686;&#21152;&#22522;&#20110;&#30693;&#35782;&#30340;&#25512;&#29702;&#30340;&#24544;&#23454;&#24230;&#21644;&#22240;&#26524;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24314;&#35758;&#20351;&#29992;&#22810;&#20010;&#26234;&#33021;&#20307;&#65288;&#21363;&#25512;&#29702;&#22120;&#21644;&#22240;&#26524;&#35780;&#20272;&#22120;&#65289;&#22312;&#25512;&#29702;&#21644;&#19968;&#33268;&#24615;&#33539;&#24335;&#20013;&#21327;&#20316;&#24037;&#20316;&#65292;&#20197;&#25552;&#39640;&#25512;&#29702;&#30340;&#24544;&#23454;&#24230;&#12290;&#25512;&#29702;&#22120;&#19987;&#27880;&#20110;&#25552;&#20379;&#20855;&#26377;&#20154;&#31867;&#22240;&#26524;&#20851;&#31995;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#29992;&#20110;&#35299;&#20915;&#24320;&#25918;&#39046;&#22495;&#30340;&#38382;&#39064;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#22240;&#26524;&#35780;&#20272;&#22120;&#20195;&#29702;&#26816;&#26597;&#35299;&#20915;&#26041;&#26696;&#20013;&#30340;&#31572;&#26696;&#26159;&#21542;&#20174;&#38382;&#39064;&#20013;&#22240;&#26524;&#25512;&#23548;&#20986;&#26469;&#65292;&#21453;&#20043;&#20134;&#28982;&#65292;&#24182;&#29992;&#19968;&#20010;&#21453;&#20107;&#23454;&#30340;&#31572;&#26696;&#26469;&#26367;&#20195;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite advancements in LLMs, knowledge-based reasoning remains a longstanding issue due to the fragility of knowledge recall and inference. Existing methods primarily encourage LLMs to autonomously plan and solve problems or to extensively sample reasoning chains without addressing the conceptual and inferential fallacies. Attempting to alleviate inferential fallacies and drawing inspiration from multi-agent collaboration, we present a framework to increase faithfulness and causality for knowledge-based reasoning. Specifically, we propose to employ multiple intelligent agents (i.e., reasoner and causal evaluator) to work collaboratively in a reasoning-and-consensus paradigm for elevated reasoning faithfulness. The reasoners focus on providing solutions with human-like causality to solve open-domain problems. On the other hand, the causal evaluator agent scrutinizes if the answer in a solution is causally deducible from the question and vice versa, with a counterfactual answer replacin
&lt;/p&gt;</description></item></channel></rss>