<rss version="2.0"><channel><title>Chat Arxiv cs.MA</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.MA</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#35821;&#20041;&#35299;&#30721;&#30340;&#26032;&#35266;&#28857;&#65292;&#23558;LLM&#12289;&#20154;&#31867;&#36755;&#20837;&#21644;&#21508;&#31181;&#24037;&#20855;&#20043;&#38388;&#30340;&#21327;&#20316;&#36807;&#31243;&#26500;&#24314;&#20026;&#35821;&#20041;&#31354;&#38388;&#20013;&#30340;&#20248;&#21270;&#36807;&#31243;&#65292;&#20419;&#36827;&#20102;&#39640;&#25928;&#36755;&#20986;&#30340;&#26500;&#24314;&#12290;</title><link>https://arxiv.org/abs/2403.14562</link><description>&lt;p&gt;
&#35821;&#20041;&#35299;&#30721;&#26102;&#20195;
&lt;/p&gt;
&lt;p&gt;
The Era of Semantic Decoding
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14562
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#35821;&#20041;&#35299;&#30721;&#30340;&#26032;&#35266;&#28857;&#65292;&#23558;LLM&#12289;&#20154;&#31867;&#36755;&#20837;&#21644;&#21508;&#31181;&#24037;&#20855;&#20043;&#38388;&#30340;&#21327;&#20316;&#36807;&#31243;&#26500;&#24314;&#20026;&#35821;&#20041;&#31354;&#38388;&#20013;&#30340;&#20248;&#21270;&#36807;&#31243;&#65292;&#20419;&#36827;&#20102;&#39640;&#25928;&#36755;&#20986;&#30340;&#26500;&#24314;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#23637;&#29616;&#20102;&#22312;LLM&#65288;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65289;&#12289;&#20154;&#31867;&#36755;&#20837;&#21644;&#21508;&#31181;&#24037;&#20855;&#20043;&#38388;&#32534;&#25490;&#21327;&#20316;&#20197;&#35299;&#20915;LLM&#22266;&#26377;&#23616;&#38480;&#24615;&#30340;&#24819;&#27861;&#20855;&#26377;&#24040;&#22823;&#28508;&#21147;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;&#35821;&#20041;&#35299;&#30721;&#30340;&#26032;&#35266;&#28857;&#65292;&#23558;&#36825;&#20123;&#21327;&#20316;&#36807;&#31243;&#26500;&#24314;&#20026;&#35821;&#20041;&#31354;&#38388;&#20013;&#30340;&#20248;&#21270;&#36807;&#31243;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#23558;LLM&#27010;&#24565;&#21270;&#20026;&#25805;&#32437;&#25105;&#20204;&#31216;&#20043;&#20026;&#35821;&#20041;&#26631;&#35760;&#65288;&#24050;&#30693;&#24605;&#24819;&#65289;&#30340;&#26377;&#24847;&#20041;&#20449;&#24687;&#29255;&#27573;&#30340;&#35821;&#20041;&#22788;&#29702;&#22120;&#12290;LLM&#26159;&#20247;&#22810;&#20854;&#20182;&#35821;&#20041;&#22788;&#29702;&#22120;&#20043;&#19968;&#65292;&#21253;&#25324;&#20154;&#31867;&#21644;&#24037;&#20855;&#65292;&#27604;&#22914;&#25628;&#32034;&#24341;&#25806;&#25110;&#20195;&#30721;&#25191;&#34892;&#22120;&#12290;&#35821;&#20041;&#22788;&#29702;&#22120;&#38598;&#20307;&#21442;&#19982;&#35821;&#20041;&#26631;&#35760;&#30340;&#21160;&#24577;&#20132;&#27969;&#65292;&#36880;&#27493;&#26500;&#24314;&#39640;&#25928;&#36755;&#20986;&#12290;&#25105;&#20204;&#31216;&#36825;&#20123;&#22312;&#35821;&#20041;&#31354;&#38388;&#20013;&#36827;&#34892;&#20248;&#21270;&#21644;&#25628;&#32034;&#30340;&#21327;&#21516;&#20316;&#29992;&#65292;&#20026;&#35821;&#20041;&#35299;&#30721;&#31639;&#27861;&#12290;&#36825;&#20010;&#27010;&#24565;&#19982;&#24050;&#24191;&#20026;&#30740;&#31350;&#30340;&#35821;&#20041;&#35299;&#30721;&#38382;&#39064;&#30452;&#25509;&#24179;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14562v1 Announce Type: cross  Abstract: Recent work demonstrated great promise in the idea of orchestrating collaborations between LLMs, human input, and various tools to address the inherent limitations of LLMs. We propose a novel perspective called semantic decoding, which frames these collaborative processes as optimization procedures in semantic space. Specifically, we conceptualize LLMs as semantic processors that manipulate meaningful pieces of information that we call semantic tokens (known thoughts). LLMs are among a large pool of other semantic processors, including humans and tools, such as search engines or code executors. Collectively, semantic processors engage in dynamic exchanges of semantic tokens to progressively construct high-utility outputs. We refer to these orchestrated interactions among semantic processors, optimizing and searching in semantic space, as semantic decoding algorithms. This concept draws a direct parallel to the well-studied problem of s
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#26500;&#24314;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#26234;&#33021;&#20307;&#65292;&#24182;&#35780;&#20272;&#20854;&#22312;&#22810;&#26234;&#33021;&#20307;&#21327;&#35843;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;LLM-Co&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#19977;&#20010;&#28216;&#25103;&#29615;&#22659;&#20013;&#35780;&#20272;LLMs&#30340;&#21327;&#35843;&#33021;&#21147;&#12290;&#35780;&#20272;&#32467;&#26524;&#26174;&#31034;LLMs&#20855;&#26377;&#25512;&#26029;&#20249;&#20276;&#24847;&#22270;&#21644;&#29702;&#35299;&#20854;&#34892;&#21160;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.03903</link><description>&lt;p&gt;
&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#35780;&#20272;&#22810;&#26234;&#33021;&#20307;&#21327;&#35843;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Evaluating Multi-Agent Coordination Abilities in Large Language Models. (arXiv:2310.03903v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03903
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#26500;&#24314;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#26234;&#33021;&#20307;&#65292;&#24182;&#35780;&#20272;&#20854;&#22312;&#22810;&#26234;&#33021;&#20307;&#21327;&#35843;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;LLM-Co&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#19977;&#20010;&#28216;&#25103;&#29615;&#22659;&#20013;&#35780;&#20272;LLMs&#30340;&#21327;&#35843;&#33021;&#21147;&#12290;&#35780;&#20272;&#32467;&#26524;&#26174;&#31034;LLMs&#20855;&#26377;&#25512;&#26029;&#20249;&#20276;&#24847;&#22270;&#21644;&#29702;&#35299;&#20854;&#34892;&#21160;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#20195;&#20154;&#24037;&#26234;&#33021;&#30740;&#31350;&#30340;&#19968;&#20010;&#37325;&#35201;&#30446;&#26631;&#26159;&#24320;&#21457;&#33021;&#22815;&#29087;&#32451;&#36827;&#34892;&#22810;&#26234;&#33021;&#20307;&#21327;&#35843;&#12289;&#26377;&#25928;&#19982;&#20154;&#31867;&#21644;&#20854;&#20182;&#31995;&#32479;&#21512;&#20316;&#30340;&#26234;&#33021;&#20307;&#12290;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20197;&#20854;&#26174;&#33879;&#30340;&#29702;&#35299;&#12289;&#29983;&#25104;&#21644;&#35299;&#37322;&#35821;&#35328;&#30340;&#33021;&#21147;&#25104;&#20026;&#24320;&#21457;&#36825;&#31181;&#26234;&#33021;&#20307;&#30340;&#26377;&#24076;&#26395;&#30340;&#20505;&#36873;&#27169;&#22411;&#12290;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#20351;&#29992;LLM&#26500;&#24314;&#30340;&#26234;&#33021;&#20307;&#65292;&#24182;&#35780;&#20272;&#20854;&#22312;&#21508;&#31181;&#21327;&#35843;&#22330;&#26223;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#29305;&#21035;&#35774;&#35745;&#30340;LLM-Co&#26694;&#26550;&#65292;&#20351;LLM&#33021;&#22815;&#21442;&#19982;&#21327;&#35843;&#28216;&#25103;&#12290;&#36890;&#36807;LLM-Co&#26694;&#26550;&#65292;&#25105;&#20204;&#22312;&#19977;&#20010;&#28216;&#25103;&#29615;&#22659;&#20013;&#36827;&#34892;&#35780;&#20272;&#65292;&#24182;&#23558;&#35780;&#20272;&#20998;&#20026;&#20116;&#20010;&#26041;&#38754;&#65306;&#24515;&#26234;&#29702;&#35770;&#12289;&#24773;&#22659;&#25512;&#29702;&#12289;&#25345;&#32493;&#21327;&#35843;&#12289;&#23545;&#21512;&#20316;&#20249;&#20276;&#30340;&#31283;&#20581;&#24615;&#21644;&#26126;&#30830;&#36741;&#21161;&#12290;&#39318;&#20808;&#65292;&#24515;&#26234;&#29702;&#35770;&#21644;&#24773;&#22659;&#25512;&#29702;&#30340;&#35780;&#20272;&#25581;&#31034;&#20102;LLM&#25512;&#26029;&#20249;&#20276;&#24847;&#22270;&#21644;&#29702;&#35299;&#20854;&#34892;&#21160;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
A pivotal aim in contemporary AI research is to develop agents proficient in multi-agent coordination, enabling effective collaboration with both humans and other systems. Large Language Models (LLMs), with their notable ability to understand, generate, and interpret language in a human-like manner, stand out as promising candidates for the development of such agents. In this study, we build and assess the effectiveness of agents crafted using LLMs in various coordination scenarios. We introduce the LLM-Coordination (LLM-Co) Framework, specifically designed to enable LLMs to play coordination games. With the LLM-Co framework, we conduct our evaluation with three game environments and organize the evaluation into five aspects: Theory of Mind, Situated Reasoning, Sustained Coordination, Robustness to Partners, and Explicit Assistance. First, the evaluation of the Theory of Mind and Situated Reasoning reveals the capabilities of LLM to infer the partner's intention and reason actions acco
&lt;/p&gt;</description></item></channel></rss>