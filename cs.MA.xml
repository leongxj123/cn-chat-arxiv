<rss version="2.0"><channel><title>Chat Arxiv cs.MA</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.MA</description><item><title>MIXRTs&#26159;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#26550;&#26500;&#65292;&#36890;&#36807;&#28151;&#21512;&#24490;&#29615;&#36719;&#20915;&#31574;&#26641;&#30340;&#26041;&#24335;&#65292;&#33021;&#22815;&#34920;&#36798;&#26126;&#30830;&#30340;&#20915;&#31574;&#36807;&#31243;&#24182;&#23637;&#31034;&#27599;&#20010;&#26234;&#33021;&#20307;&#30340;&#36129;&#29486;&#12290;</title><link>http://arxiv.org/abs/2209.07225</link><description>&lt;p&gt;
MIXRTs:&#36890;&#36807;&#28151;&#21512;&#24490;&#29615;&#36719;&#20915;&#31574;&#26641;&#23454;&#29616;&#21487;&#35299;&#37322;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
MIXRTs: Toward Interpretable Multi-Agent Reinforcement Learning via Mixing Recurrent Soft Decision Trees. (arXiv:2209.07225v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.07225
&lt;/p&gt;
&lt;p&gt;
MIXRTs&#26159;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#26550;&#26500;&#65292;&#36890;&#36807;&#28151;&#21512;&#24490;&#29615;&#36719;&#20915;&#31574;&#26641;&#30340;&#26041;&#24335;&#65292;&#33021;&#22815;&#34920;&#36798;&#26126;&#30830;&#30340;&#20915;&#31574;&#36807;&#31243;&#24182;&#23637;&#31034;&#27599;&#20010;&#26234;&#33021;&#20307;&#30340;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21508;&#20010;&#39046;&#22495;&#21462;&#24471;&#24040;&#22823;&#25104;&#21151;&#30340;&#21516;&#26102;&#65292;&#29616;&#26377;&#30340;&#20855;&#26377;&#40657;&#30418;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#65288;MARL&#65289;&#20197;&#19981;&#36879;&#26126;&#30340;&#26041;&#24335;&#20570;&#20986;&#20915;&#31574;&#65292;&#38459;&#30861;&#20102;&#20154;&#20204;&#29702;&#35299;&#23398;&#20064;&#21040;&#30340;&#30693;&#35782;&#20197;&#21450;&#36755;&#20837;&#35266;&#27979;&#22914;&#20309;&#24433;&#21709;&#20915;&#31574;&#12290;&#19982;&#27492;&#30456;&#21453;&#65292;&#29616;&#26377;&#30340;&#21487;&#35299;&#37322;&#26041;&#27861;&#65292;&#22914;&#20256;&#32479;&#30340;&#32447;&#24615;&#27169;&#22411;&#21644;&#20915;&#31574;&#26641;&#65292;&#24448;&#24448;&#22312;&#34920;&#36798;&#33021;&#21147;&#21644;&#20934;&#30830;&#24615;&#26041;&#38754;&#23384;&#22312;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#24615;&#33021;&#21644;&#35299;&#37322;&#24615;&#20043;&#38388;&#30340;&#26126;&#26174;&#20108;&#20803;&#23545;&#31435;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21487;&#35299;&#37322;&#32467;&#26500;&#8212;&#8212;&#28151;&#21512;&#24490;&#29615;&#36719;&#20915;&#31574;&#26641;&#65288;MIXRTs&#65289;&#65292;&#23427;&#33021;&#22815;&#36890;&#36807;&#20174;&#26681;&#33410;&#28857;&#21040;&#21494;&#33410;&#28857;&#30340;&#36335;&#24452;&#34920;&#31034;&#26126;&#30830;&#30340;&#20915;&#31574;&#36807;&#31243;&#65292;&#24182;&#21453;&#26144;&#27599;&#20010;&#26234;&#33021;&#20307;&#23545;&#22242;&#38431;&#30340;&#36129;&#29486;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#36719;&#20915;&#31574;&#26641;&#26469;&#35299;&#20915;&#23616;&#37096;&#21487;&#35266;&#23519;&#24615;&#38382;&#39064;&#65292;&#21033;&#29992;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#30340;&#36827;&#23637;&#65292;&#24182;&#36890;&#36807;&#22522;&#20110;&#26641;&#30340;&#27169;&#22411;&#23637;&#31034;&#21738;&#20123;&#29305;&#24449;&#24433;&#21709;&#20915;&#31574;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
While achieving tremendous success in various fields, existing multi-agent reinforcement learning (MARL) with a black-box neural network architecture makes decisions in an opaque manner that hinders humans from understanding the learned knowledge and how input observations influence decisions. Instead, existing interpretable approaches, such as traditional linear models and decision trees, usually suffer from weak expressivity and low accuracy. To address this apparent dichotomy between performance and interpretability, our solution, MIXing Recurrent soft decision Trees (MIXRTs), is a novel interpretable architecture that can represent explicit decision processes via the root-to-leaf path and reflect each agent's contribution to the team. Specifically, we construct a novel soft decision tree to address partial observability by leveraging the advances in recurrent neural networks, and demonstrate which features influence the decision-making process through the tree-based model. Then, ba
&lt;/p&gt;</description></item></channel></rss>