<rss version="2.0"><channel><title>Chat Arxiv cs.MA</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.MA</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#20445;&#35777;&#26368;&#20248;&#24615;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#20998;&#24067;&#24335;&#22312;&#32447;&#23398;&#20064;&#20013;&#21516;&#26102;&#20445;&#35777;&#24046;&#20998;&#38544;&#31169;&#21644;&#23398;&#20064;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.14094</link><description>&lt;p&gt;
&#20855;&#26377;&#20445;&#35777;&#26368;&#20248;&#24615;&#30340;&#23616;&#37096;&#24046;&#20998;&#38544;&#31169;&#20998;&#24067;&#24335;&#22312;&#32447;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Locally Differentially Private Distributed Online Learning with Guaranteed Optimality. (arXiv:2306.14094v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14094
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#20445;&#35777;&#26368;&#20248;&#24615;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#20998;&#24067;&#24335;&#22312;&#32447;&#23398;&#20064;&#20013;&#21516;&#26102;&#20445;&#35777;&#24046;&#20998;&#38544;&#31169;&#21644;&#23398;&#20064;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#24335;&#22312;&#32447;&#23398;&#20064;&#30001;&#20110;&#20854;&#22788;&#29702;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#21644;&#27969;&#25968;&#25454;&#30340;&#33021;&#21147;&#32780;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#20026;&#20102;&#35299;&#20915;&#38544;&#31169;&#20445;&#25252;&#38382;&#39064;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#35768;&#22810;&#20010;&#20154;&#31169;&#23494;&#20998;&#24067;&#24335;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#22823;&#22810;&#25968;&#22522;&#20110;&#24046;&#20998;&#38544;&#31169;&#65292;&#24046;&#20998;&#38544;&#31169;&#24050;&#25104;&#20026;&#38544;&#31169;&#20445;&#25252;&#30340;&#8220;&#40644;&#37329;&#26631;&#20934;&#8221;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#31639;&#27861;&#24120;&#24120;&#38754;&#20020;&#20026;&#20102;&#38544;&#31169;&#20445;&#25252;&#32780;&#29306;&#29298;&#23398;&#20064;&#20934;&#30830;&#24615;&#30340;&#22256;&#22659;&#12290;&#26412;&#25991;&#21033;&#29992;&#22312;&#32447;&#23398;&#20064;&#30340;&#29420;&#29305;&#29305;&#24449;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#19968;&#22256;&#22659;&#65292;&#24182;&#30830;&#20445;&#20998;&#24067;&#24335;&#22312;&#32447;&#23398;&#20064;&#20013;&#30340;&#24046;&#20998;&#38544;&#31169;&#21644;&#23398;&#20064;&#20934;&#30830;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#35813;&#26041;&#27861;&#22312;&#30830;&#20445;&#39044;&#26399;&#30636;&#26102;&#36951;&#25022;&#31243;&#24230;&#36880;&#28176;&#20943;&#23567;&#30340;&#21516;&#26102;&#65292;&#36824;&#33021;&#20445;&#35777;&#26377;&#38480;&#30340;&#32047;&#31215;&#38544;&#31169;&#39044;&#31639;&#65292;&#21363;&#20351;&#22312;&#26080;&#38480;&#26102;&#38388;&#33539;&#22260;&#20869;&#12290;&#20026;&#20102;&#24212;&#23545;&#23436;&#20840;&#20998;&#24067;&#24335;&#29615;&#22659;&#65292;&#25105;&#20204;&#37319;&#29992;&#26412;&#22320;&#24046;&#20998;&#38544;&#31169;&#26694;&#26550;&#65292;&#36991;&#20813;&#20102;&#23545;&#20840;&#23616;&#25968;&#25454;&#30340;&#20381;&#36182;&#12290;
&lt;/p&gt;
&lt;p&gt;
Distributed online learning is gaining increased traction due to its unique ability to process large-scale datasets and streaming data. To address the growing public awareness and concern on privacy protection, plenty of private distributed online learning algorithms have been proposed, mostly based on differential privacy which has emerged as the ``gold standard" for privacy protection. However, these algorithms often face the dilemma of trading learning accuracy for privacy. By exploiting the unique characteristics of online learning, this paper proposes an approach that tackles the dilemma and ensures both differential privacy and learning accuracy in distributed online learning. More specifically, while ensuring a diminishing expected instantaneous regret, the approach can simultaneously ensure a finite cumulative privacy budget, even on the infinite time horizon. To cater for the fully distributed setting, we adopt the local differential-privacy framework which avoids the reliance
&lt;/p&gt;</description></item></channel></rss>