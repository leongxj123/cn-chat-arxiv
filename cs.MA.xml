<rss version="2.0"><channel><title>Chat Arxiv cs.MA</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.MA</description><item><title>&#25552;&#20986;&#20102;Ensembling Prioritized Hybrid Policies (EPH)&#26041;&#27861;&#65292;&#36890;&#36807;&#36873;&#25321;&#24615;&#36890;&#20449;&#27169;&#22359;&#21644;&#19977;&#31181;&#39640;&#32423;&#25512;&#29702;&#31574;&#30053;&#65292;&#25552;&#39640;&#20102;&#22522;&#20110;&#36890;&#20449;&#30340;&#22810;&#26234;&#33021;&#20307;&#36335;&#24452;&#35268;&#21010;&#35299;&#20915;&#26041;&#26696;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.07559</link><description>&lt;p&gt;
&#20026;&#22810;&#26234;&#33021;&#20307;&#36335;&#24452;&#35268;&#21010;&#38598;&#25104;&#20248;&#20808;&#32423;&#28151;&#21512;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Ensembling Prioritized Hybrid Policies for Multi-agent Pathfinding
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07559
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;Ensembling Prioritized Hybrid Policies (EPH)&#26041;&#27861;&#65292;&#36890;&#36807;&#36873;&#25321;&#24615;&#36890;&#20449;&#27169;&#22359;&#21644;&#19977;&#31181;&#39640;&#32423;&#25512;&#29702;&#31574;&#30053;&#65292;&#25552;&#39640;&#20102;&#22522;&#20110;&#36890;&#20449;&#30340;&#22810;&#26234;&#33021;&#20307;&#36335;&#24452;&#35268;&#21010;&#35299;&#20915;&#26041;&#26696;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#65288;MARL&#65289;&#30340;&#22810;&#26234;&#33021;&#20307;&#36335;&#24452;&#35268;&#21010;&#65288;MAPF&#65289;&#36817;&#26469;&#22240;&#20854;&#39640;&#25928;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#32780;&#21463;&#21040;&#20851;&#27880;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;Ensembling Prioritized Hybrid Policies (EPH)&#65292;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;&#22522;&#20110;&#36890;&#20449;&#30340;MARL-MAPF&#27714;&#35299;&#22120;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#19968;&#20010;&#36873;&#25321;&#24615;&#36890;&#20449;&#27169;&#22359;&#65292;&#20197;&#22312;&#22810;&#26234;&#33021;&#20307;&#29615;&#22659;&#20013;&#25910;&#38598;&#26356;&#20016;&#23500;&#30340;&#20449;&#24687;&#65292;&#20174;&#32780;&#23454;&#29616;&#26356;&#22909;&#30340;&#26234;&#33021;&#20307;&#21327;&#35843;&#65292;&#24182;&#20351;&#29992;&#22522;&#20110;Q-learning&#30340;&#31639;&#27861;&#23545;&#27169;&#22411;&#36827;&#34892;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07559v1 Announce Type: cross  Abstract: Multi-Agent Reinforcement Learning (MARL) based Multi-Agent Path Finding (MAPF) has recently gained attention due to its efficiency and scalability. Several MARL-MAPF methods choose to use communication to enrich the information one agent can perceive. However, existing works still struggle in structured environments with high obstacle density and a high number of agents. To further improve the performance of the communication-based MARL-MAPF solvers, we propose a new method, Ensembling Prioritized Hybrid Policies (EPH). We first propose a selective communication block to gather richer information for better agent coordination within multi-agent environments and train the model with a Q-learning-based algorithm. We further introduce three advanced inference strategies aimed at bolstering performance during the execution phase. First, we hybridize the neural policy with single-agent expert guidance for navigating conflict-free zones. Se
&lt;/p&gt;</description></item></channel></rss>