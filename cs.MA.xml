<rss version="2.0"><channel><title>Chat Arxiv cs.MA</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.MA</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24212;&#29992;&#20110;&#25968;&#23383;&#23402;&#29983;&#30340;&#31163;&#32447;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#26041;&#26696;&#65292;&#36890;&#36807;&#25972;&#21512;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#21644;&#20445;&#23432;Q&#23398;&#20064;&#26469;&#35299;&#20915;&#29615;&#22659;&#30340;&#19981;&#30830;&#23450;&#24615;&#21644;&#26377;&#38480;&#25968;&#25454;&#24102;&#26469;&#30340;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.08421</link><description>&lt;p&gt;
&#20445;&#23432;&#21644;&#39118;&#38505;&#24847;&#35782;&#30340;&#31163;&#32447;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#22312;&#25968;&#23383;&#23402;&#29983;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Conservative and Risk-Aware Offline Multi-Agent Reinforcement Learning for Digital Twins
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08421
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24212;&#29992;&#20110;&#25968;&#23383;&#23402;&#29983;&#30340;&#31163;&#32447;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#26041;&#26696;&#65292;&#36890;&#36807;&#25972;&#21512;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#21644;&#20445;&#23432;Q&#23398;&#20064;&#26469;&#35299;&#20915;&#29615;&#22659;&#30340;&#19981;&#30830;&#23450;&#24615;&#21644;&#26377;&#38480;&#25968;&#25454;&#24102;&#26469;&#30340;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#23383;&#23402;&#29983;&#65288;DT&#65289;&#24179;&#21488;&#34987;&#36234;&#26469;&#36234;&#35748;&#20026;&#26159;&#25511;&#21046;&#12289;&#20248;&#21270;&#21644;&#30417;&#25511;&#35832;&#22914;&#19979;&#19968;&#20195;&#26080;&#32447;&#32593;&#32476;&#20043;&#31867;&#30340;&#22797;&#26434;&#24037;&#31243;&#31995;&#32479;&#30340;&#26377;&#24076;&#26395;&#25216;&#26415;&#12290;&#37319;&#29992;DT&#35299;&#20915;&#26041;&#26696;&#38754;&#20020;&#30340;&#19968;&#20010;&#37325;&#35201;&#25361;&#25112;&#26159;&#23427;&#20204;&#20381;&#36182;&#20110;&#31163;&#32447;&#25910;&#38598;&#30340;&#25968;&#25454;&#65292;&#32570;&#20047;&#23545;&#29289;&#29702;&#29615;&#22659;&#30340;&#30452;&#25509;&#35775;&#38382;&#12290;&#36825;&#19968;&#38480;&#21046;&#22312;&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#20013;&#23588;&#20026;&#20005;&#37325;&#65292;&#22240;&#20026;&#20256;&#32479;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#65288;MARL&#65289;&#38656;&#35201;&#19982;&#29615;&#22659;&#36827;&#34892;&#22312;&#32447;&#20114;&#21160;&#12290;&#23558;&#22312;&#32447;MARL&#26041;&#26696;&#30452;&#25509;&#24212;&#29992;&#20110;&#31163;&#32447;&#29615;&#22659;&#36890;&#24120;&#20250;&#22240;&#26377;&#38480;&#25968;&#25454;&#30340;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#32780;&#22833;&#36133;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22522;&#20110;DT&#30340;&#26080;&#32447;&#32593;&#32476;&#30340;&#31163;&#32447;MARL&#26041;&#26696;&#65292;&#23427;&#25972;&#21512;&#20102;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#65288;distributional RL&#65289;&#21644;&#20445;&#23432;Q&#23398;&#20064;&#65292;&#20197;&#24212;&#23545;&#29615;&#22659;&#22266;&#26377;&#30340;&#26696;&#20363;&#24615;&#19981;&#30830;&#23450;&#24615;&#21644;&#26377;&#38480;&#25968;&#25454;&#24341;&#36215;&#30340;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#12290;&#20026;&#20102;&#36827;&#19968;&#27493;&#21033;&#29992;&#31163;&#32447;&#25968;&#25454;&#65292;&#25105;&#20204;&#25913;&#32534;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Digital twin (DT) platforms are increasingly regarded as a promising technology for controlling, optimizing, and monitoring complex engineering systems such as next-generation wireless networks. An important challenge in adopting DT solutions is their reliance on data collected offline, lacking direct access to the physical environment. This limitation is particularly severe in multi-agent systems, for which conventional multi-agent reinforcement (MARL) requires online interactions with the environment. A direct application of online MARL schemes to an offline setting would generally fail due to the epistemic uncertainty entailed by the limited availability of data. In this work, we propose an offline MARL scheme for DT-based wireless networks that integrates distributional RL and conservative Q-learning to address the environment's inherent aleatoric uncertainty and the epistemic uncertainty arising from limited data. To further exploit the offline data, we adapt the proposed scheme t
&lt;/p&gt;</description></item></channel></rss>