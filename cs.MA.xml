<rss version="2.0"><channel><title>Chat Arxiv cs.MA</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.MA</description><item><title>&#36890;&#36807;&#22810;&#26234;&#33021;&#20307;&#21327;&#20316;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26694;&#26550;&#65292;&#26088;&#22312;&#25552;&#39640;&#22522;&#20110;&#30693;&#35782;&#30340;&#25512;&#29702;&#30340;&#24544;&#23454;&#24230;&#21644;&#22240;&#26524;&#24615;&#65292;&#36890;&#36807;&#25512;&#29702;&#22120;&#21644;&#22240;&#26524;&#35780;&#20272;&#22120;&#30340;&#21512;&#20316;&#26469;&#35299;&#20915;&#25512;&#29702;&#35884;&#35823;&#12290;</title><link>http://arxiv.org/abs/2308.11914</link><description>&lt;p&gt;
&#36808;&#21521;&#22240;&#26524;GPT&#65306;&#36890;&#36807;&#20419;&#36827;LLMs&#20013;&#30340;&#22240;&#26524;&#19968;&#33268;&#24615;&#65292;&#22522;&#20110;&#22810;&#26234;&#33021;&#20307;&#30340;&#26041;&#27861;&#23454;&#29616;&#24544;&#23454;&#30340;&#30693;&#35782;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Towards CausalGPT: A Multi-Agent Approach for Faithful Knowledge Reasoning via Promoting Causal Consistency in LLMs. (arXiv:2308.11914v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11914
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22810;&#26234;&#33021;&#20307;&#21327;&#20316;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26694;&#26550;&#65292;&#26088;&#22312;&#25552;&#39640;&#22522;&#20110;&#30693;&#35782;&#30340;&#25512;&#29702;&#30340;&#24544;&#23454;&#24230;&#21644;&#22240;&#26524;&#24615;&#65292;&#36890;&#36807;&#25512;&#29702;&#22120;&#21644;&#22240;&#26524;&#35780;&#20272;&#22120;&#30340;&#21512;&#20316;&#26469;&#35299;&#20915;&#25512;&#29702;&#35884;&#35823;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;LLMs&#30340;&#21457;&#23637;&#21462;&#24471;&#20102;&#19968;&#20123;&#36827;&#23637;&#65292;&#20294;&#22522;&#20110;&#30693;&#35782;&#30340;&#25512;&#29702;&#20173;&#28982;&#26159;&#19968;&#20010;&#38271;&#26399;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#36825;&#26159;&#30001;&#20110;&#30693;&#35782;&#22238;&#24518;&#21644;&#25512;&#29702;&#30340;&#33030;&#24369;&#24615;&#24341;&#36215;&#30340;&#12290;&#29616;&#26377;&#26041;&#27861;&#20027;&#35201;&#36890;&#36807;&#40723;&#21169;LLMs&#33258;&#20027;&#35745;&#21010;&#21644;&#35299;&#20915;&#38382;&#39064;&#25110;&#24191;&#27867;&#37319;&#26679;&#25512;&#29702;&#38142;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20294;&#26410;&#33021;&#35299;&#20915;&#27010;&#24565;&#21644;&#25512;&#29702;&#35884;&#35823;&#12290;&#20026;&#20102;&#20943;&#23569;&#25512;&#29702;&#35884;&#35823;&#65292;&#25105;&#20204;&#20174;&#22810;&#26234;&#33021;&#20307;&#21327;&#20316;&#20013;&#24471;&#21040;&#21551;&#21457;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#26469;&#22686;&#21152;&#22522;&#20110;&#30693;&#35782;&#30340;&#25512;&#29702;&#30340;&#24544;&#23454;&#24230;&#21644;&#22240;&#26524;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24314;&#35758;&#20351;&#29992;&#22810;&#20010;&#26234;&#33021;&#20307;&#65288;&#21363;&#25512;&#29702;&#22120;&#21644;&#22240;&#26524;&#35780;&#20272;&#22120;&#65289;&#22312;&#25512;&#29702;&#21644;&#19968;&#33268;&#24615;&#33539;&#24335;&#20013;&#21327;&#20316;&#24037;&#20316;&#65292;&#20197;&#25552;&#39640;&#25512;&#29702;&#30340;&#24544;&#23454;&#24230;&#12290;&#25512;&#29702;&#22120;&#19987;&#27880;&#20110;&#25552;&#20379;&#20855;&#26377;&#20154;&#31867;&#22240;&#26524;&#20851;&#31995;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#29992;&#20110;&#35299;&#20915;&#24320;&#25918;&#39046;&#22495;&#30340;&#38382;&#39064;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#22240;&#26524;&#35780;&#20272;&#22120;&#20195;&#29702;&#26816;&#26597;&#35299;&#20915;&#26041;&#26696;&#20013;&#30340;&#31572;&#26696;&#26159;&#21542;&#20174;&#38382;&#39064;&#20013;&#22240;&#26524;&#25512;&#23548;&#20986;&#26469;&#65292;&#21453;&#20043;&#20134;&#28982;&#65292;&#24182;&#29992;&#19968;&#20010;&#21453;&#20107;&#23454;&#30340;&#31572;&#26696;&#26469;&#26367;&#20195;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite advancements in LLMs, knowledge-based reasoning remains a longstanding issue due to the fragility of knowledge recall and inference. Existing methods primarily encourage LLMs to autonomously plan and solve problems or to extensively sample reasoning chains without addressing the conceptual and inferential fallacies. Attempting to alleviate inferential fallacies and drawing inspiration from multi-agent collaboration, we present a framework to increase faithfulness and causality for knowledge-based reasoning. Specifically, we propose to employ multiple intelligent agents (i.e., reasoner and causal evaluator) to work collaboratively in a reasoning-and-consensus paradigm for elevated reasoning faithfulness. The reasoners focus on providing solutions with human-like causality to solve open-domain problems. On the other hand, the causal evaluator agent scrutinizes if the answer in a solution is causally deducible from the question and vice versa, with a counterfactual answer replacin
&lt;/p&gt;</description></item></channel></rss>