<rss version="2.0"><channel><title>Chat Arxiv cs.MA</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.MA</description><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38598;&#20013;&#35757;&#32451;&#21644;&#20998;&#25955;&#25191;&#34892;&#30340;&#22810;Agent&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#31649;&#29702;&#20132;&#36890;&#22522;&#30784;&#35774;&#26045;&#31995;&#32479;&#30340;&#25972;&#20010;&#29983;&#21629;&#21608;&#26399;&#65292;&#22312;&#22788;&#29702;&#39640;&#32500;&#24230;&#31354;&#38388;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#21644;&#32422;&#26463;&#26465;&#20214;&#26102;&#33021;&#22815;&#38477;&#20302;&#38271;&#26399;&#39118;&#38505;&#21644;&#25104;&#26412;&#12290;</title><link>http://arxiv.org/abs/2401.12455</link><description>&lt;p&gt;
&#22522;&#20110;&#38598;&#20013;&#35757;&#32451;&#21644;&#20998;&#25955;&#25191;&#34892;&#30340;&#22810;Agent&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#22312;&#20132;&#36890;&#22522;&#30784;&#35774;&#26045;&#31649;&#29702;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Multi-agent deep reinforcement learning with centralized training and decentralized execution for transportation infrastructure management. (arXiv:2401.12455v1 [cs.MA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12455
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38598;&#20013;&#35757;&#32451;&#21644;&#20998;&#25955;&#25191;&#34892;&#30340;&#22810;Agent&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#31649;&#29702;&#20132;&#36890;&#22522;&#30784;&#35774;&#26045;&#31995;&#32479;&#30340;&#25972;&#20010;&#29983;&#21629;&#21608;&#26399;&#65292;&#22312;&#22788;&#29702;&#39640;&#32500;&#24230;&#31354;&#38388;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#21644;&#32422;&#26463;&#26465;&#20214;&#26102;&#33021;&#22815;&#38477;&#20302;&#38271;&#26399;&#39118;&#38505;&#21644;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;Agent&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#20132;&#36890;&#22522;&#30784;&#35774;&#26045;&#30340;&#25972;&#20010;&#29983;&#21629;&#21608;&#26399;&#20869;&#36827;&#34892;&#31649;&#29702;&#12290;&#36825;&#31181;&#24037;&#31243;&#31995;&#32479;&#30340;&#29983;&#21629;&#21608;&#26399;&#31649;&#29702;&#26159;&#19968;&#20010;&#38656;&#35201;&#22823;&#37327;&#35745;&#31639;&#30340;&#20219;&#21153;&#65292;&#38656;&#35201;&#36866;&#24403;&#30340;&#39034;&#24207;&#26816;&#26597;&#21644;&#32500;&#25252;&#20915;&#31574;&#65292;&#33021;&#22815;&#22312;&#22788;&#29702;&#19981;&#21516;&#30340;&#19981;&#30830;&#23450;&#24615;&#21644;&#32422;&#26463;&#26465;&#20214;&#26102;&#38477;&#20302;&#38271;&#26399;&#39118;&#38505;&#21644;&#25104;&#26412;&#65292;&#36825;&#20123;&#19981;&#30830;&#23450;&#24615;&#21644;&#32422;&#26463;&#26465;&#20214;&#23384;&#22312;&#20110;&#39640;&#32500;&#31354;&#38388;&#20013;&#12290;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;&#38745;&#24577;&#30340;&#22522;&#20110;&#24180;&#40836;&#25110;&#26465;&#20214;&#30340;&#32500;&#25252;&#26041;&#27861;&#21644;&#22522;&#20110;&#39118;&#38505;&#25110;&#23450;&#26399;&#26816;&#26597;&#35745;&#21010;&#20027;&#35201;&#35299;&#20915;&#20102;&#36825;&#31867;&#20248;&#21270;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#20123;&#26041;&#27861;&#19979;&#65292;&#20248;&#21270;&#24615;&#12289;&#21487;&#25193;&#23637;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#38480;&#21046;&#32463;&#24120;&#26174;&#29616;&#20986;&#26469;&#12290;&#26412;&#24037;&#20316;&#20013;&#30340;&#20248;&#21270;&#38382;&#39064;&#20197;&#32422;&#26463;&#30340;&#37096;&#20998;&#21487;&#35266;&#23519;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;(POMDPs)&#26694;&#26550;&#20026;&#22522;&#30784;&#65292;&#20026;&#20855;&#26377;&#35266;&#23519;&#19981;&#30830;&#23450;&#24615;&#12289;&#39118;&#38505;&#32771;&#34385;&#21644;&#38543;&#26426;&#39034;&#24207;&#20915;&#31574;&#30340;&#38382;&#39064;&#25552;&#20379;&#20102;&#32508;&#21512;&#30340;&#25968;&#23398;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a multi-agent Deep Reinforcement Learning (DRL) framework for managing large transportation infrastructure systems over their life-cycle. Life-cycle management of such engineering systems is a computationally intensive task, requiring appropriate sequential inspection and maintenance decisions able to reduce long-term risks and costs, while dealing with different uncertainties and constraints that lie in high-dimensional spaces. To date, static age- or condition-based maintenance methods and risk-based or periodic inspection plans have mostly addressed this class of optimization problems. However, optimality, scalability, and uncertainty limitations are often manifested under such approaches. The optimization problem in this work is cast in the framework of constrained Partially Observable Markov Decision Processes (POMDPs), which provides a comprehensive mathematical basis for stochastic sequential decision settings with observation uncertainties, risk considerations, and l
&lt;/p&gt;</description></item></channel></rss>