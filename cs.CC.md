# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [CMAT: A Multi-Agent Collaboration Tuning Framework for Enhancing Small Language Models](https://arxiv.org/abs/2404.01663) | CMAT框架引入了TinyAgent模型，并提出了一种新颖的系统，通过环境反馈进行自适应权重更新，增强了语言智能体的能力和长期记忆。 |

# 详细

[^1]: CMAT: 用于增强小型语言模型的多智能体协作调整框架

    CMAT: A Multi-Agent Collaboration Tuning Framework for Enhancing Small Language Models

    [https://arxiv.org/abs/2404.01663](https://arxiv.org/abs/2404.01663)

    CMAT框架引入了TinyAgent模型，并提出了一种新颖的系统，通过环境反馈进行自适应权重更新，增强了语言智能体的能力和长期记忆。

    

    开放的大型语言模型（LLMs）显著推动了自然语言处理领域的发展，在各种任务中展现出卓越的性能。尽管LLMs取得了显著进展，但它们的有效操作仍然严重依赖于人类输入来准确引导对话流程，智能体调整是一种关键的优化技术，涉及人类对模型的调整，以更好地响应这种引导。针对这一依赖性，我们的工作引入了TinyAgent模型，该模型经过精心策划的高质量数据集训练。我们还提出了Collaborative Multi-Agent Tuning（CMAT）框架，这是一个创新性系统，旨在通过根据环境反馈进行自适应权重更新来增强语言智能体的能力。该框架促进了多个智能体之间的协作学习和实时适应，增强了它们的上下文感知和长期记忆。

    arXiv:2404.01663v1 Announce Type: new  Abstract: Open large language models (LLMs) have significantly advanced the field of natural language processing, showcasing impressive performance across various tasks.Despite the significant advancements in LLMs, their effective operation still relies heavily on human input to accurately guide the dialogue flow, with agent tuning being a crucial optimization technique that involves human adjustments to the model for better response to such guidance.Addressing this dependency, our work introduces the TinyAgent model, trained on a meticulously curated high-quality dataset. We also present the Collaborative Multi-Agent Tuning (CMAT) framework, an innovative system designed to augment language agent capabilities through adaptive weight updates based on environmental feedback. This framework fosters collaborative learning and real-time adaptation among multiple intelligent agents, enhancing their context-awareness and long-term memory. In this resear
    

