<rss version="2.0"><channel><title>Chat Arxiv cs.MM</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.MM</description><item><title>&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#30340;&#22810;&#27169;&#24577;&#39044;&#35757;&#32451;&#26694;&#26550;&#21033;&#29992;&#29992;&#25143;&#30340;&#24207;&#21015;&#34892;&#20026;&#21644;&#29289;&#21697;&#30340;&#22810;&#27169;&#24577;&#20869;&#23481;&#36827;&#34892;&#24207;&#21015;&#25512;&#33616;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39592;&#24178;&#32593;&#32476;&#36827;&#34892;&#29305;&#24449;&#34701;&#21512;&#65292;&#23454;&#39564;&#35777;&#26126;&#20854;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2303.11879</link><description>&lt;p&gt;
&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#30340;&#22810;&#27169;&#24577;&#39044;&#35757;&#32451;&#26694;&#26550;&#29992;&#20110;&#24207;&#21015;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Multimodal Pre-training Framework for Sequential Recommendation via Contrastive Learning. (arXiv:2303.11879v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11879
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#30340;&#22810;&#27169;&#24577;&#39044;&#35757;&#32451;&#26694;&#26550;&#21033;&#29992;&#29992;&#25143;&#30340;&#24207;&#21015;&#34892;&#20026;&#21644;&#29289;&#21697;&#30340;&#22810;&#27169;&#24577;&#20869;&#23481;&#36827;&#34892;&#24207;&#21015;&#25512;&#33616;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39592;&#24178;&#32593;&#32476;&#36827;&#34892;&#29305;&#24449;&#34701;&#21512;&#65292;&#23454;&#39564;&#35777;&#26126;&#20854;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24207;&#21015;&#25512;&#33616;&#31995;&#32479;&#21033;&#29992;&#29992;&#25143;&#19982;&#29289;&#21697;&#20043;&#38388;&#30340;&#24207;&#21015;&#20132;&#20114;&#20316;&#20026;&#20027;&#35201;&#30340;&#30417;&#30563;&#20449;&#21495;&#26469;&#23398;&#20064;&#29992;&#25143;&#30340;&#21916;&#22909;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#29992;&#25143;&#34892;&#20026;&#25968;&#25454;&#30340;&#31232;&#30095;&#24615;&#65292;&#29616;&#26377;&#26041;&#27861;&#36890;&#24120;&#29983;&#25104;&#19981;&#23613;&#22914;&#20154;&#24847;&#30340;&#32467;&#26524;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#39044;&#35757;&#32451;&#26694;&#26550;&#65292;&#21517;&#20026;&#22810;&#27169;&#24577;&#24207;&#21015;&#28151;&#21512;&#65288;MSM4SR&#65289;&#65292;&#23427;&#21033;&#29992;&#29992;&#25143;&#30340;&#24207;&#21015;&#34892;&#20026;&#21644;&#29289;&#21697;&#30340;&#22810;&#27169;&#24577;&#20869;&#23481;&#65288;&#21363;&#25991;&#26412;&#21644;&#22270;&#20687;&#65289;&#36827;&#34892;&#26377;&#25928;&#25512;&#33616;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;MSM4SR&#23558;&#27599;&#20010;&#29289;&#21697;&#22270;&#20687;&#26631;&#35760;&#25104;&#22810;&#20010;&#25991;&#26412;&#20851;&#38190;&#35789;&#65292;&#24182;&#20351;&#29992;&#39044;&#35757;&#32451;&#30340;BERT&#27169;&#22411;&#33719;&#21462;&#29289;&#21697;&#30340;&#21021;&#22987;&#25991;&#26412;&#21644;&#35270;&#35273;&#29305;&#24449;&#65292;&#20197;&#28040;&#38500;&#25991;&#26412;&#21644;&#22270;&#20687;&#27169;&#24577;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39592;&#24178;&#32593;&#32476;&#65292;&#21363;&#22810;&#27169;&#24577;&#28151;&#21512;&#24207;&#21015;&#32534;&#30721;&#22120;&#65288;M $^2$ SE&#65289;&#65292;&#23427;&#20351;&#29992;&#20114;&#34917;&#30340;&#24207;&#21015;&#28151;&#21512;&#31574;&#30053;&#26469;&#24357;&#21512;&#29289;&#21697;&#22810;&#27169;&#24577;&#20869;&#23481;&#21644;&#29992;&#25143;&#34892;&#20026;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#27492;&#22806;&#65292;&#24341;&#20837;&#23545;&#27604;&#23398;&#20064;&#26426;&#21046;&#26469;&#24378;&#21046;&#23398;&#20064;&#21040;&#30340;&#34920;&#31034;&#21464;&#24471;&#26356;&#26377;&#21306;&#20998;&#24230;&#65292;&#36827;&#19968;&#27493;&#25552;&#39640;&#20102;&#24207;&#21015;&#25512;&#33616;&#30340;&#24615;&#33021;&#12290;&#22312;&#20004;&#20010;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#39564;&#35777;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sequential recommendation systems utilize the sequential interactions of users with items as their main supervision signals in learning users' preferences. However, existing methods usually generate unsatisfactory results due to the sparsity of user behavior data. To address this issue, we propose a novel pre-training framework, named Multimodal Sequence Mixup for Sequential Recommendation (MSM4SR), which leverages both users' sequential behaviors and items' multimodal content (\ie text and images) for effectively recommendation. Specifically, MSM4SR tokenizes each item image into multiple textual keywords and uses the pre-trained BERT model to obtain initial textual and visual features of items, for eliminating the discrepancy between the text and image modalities. A novel backbone network, \ie Multimodal Mixup Sequence Encoder (M$^2$SE), is proposed to bridge the gap between the item multimodal content and the user behavior, using a complementary sequence mixup strategy. In addition,
&lt;/p&gt;</description></item></channel></rss>