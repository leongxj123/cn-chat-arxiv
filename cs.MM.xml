<rss version="2.0"><channel><title>Chat Arxiv cs.MM</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.MM</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#28436;&#32462;&#24335;&#30340;&#22270;&#35889;&#36777;&#35770;&#26041;&#27861;&#65288;BDoG&#65289;&#65292;&#22312;&#22810;&#27169;&#24577;&#25512;&#29702;&#20013;&#38450;&#27490;&#24847;&#35265;&#38472;&#33104;&#21270;&#21644;&#20943;&#23569;&#30001;&#22270;&#20687;&#24341;&#20837;&#30340;&#20998;&#24515;&#27010;&#24565;&#65292;&#23454;&#39564;&#35777;&#26126;&#20854;&#22312;&#31185;&#23398;&#38382;&#31572;&#21644;MMBench&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2403.14972</link><description>&lt;p&gt;
&#19968;&#22270;&#32988;&#21315;&#35328;&#65306;&#22810;&#27169;&#24577;&#25512;&#29702;&#20013;&#30340;&#22270;&#35889;&#36777;&#35770;
&lt;/p&gt;
&lt;p&gt;
A Picture Is Worth a Graph: Blueprint Debate on Graph for Multimodal Reasoning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14972
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#28436;&#32462;&#24335;&#30340;&#22270;&#35889;&#36777;&#35770;&#26041;&#27861;&#65288;BDoG&#65289;&#65292;&#22312;&#22810;&#27169;&#24577;&#25512;&#29702;&#20013;&#38450;&#27490;&#24847;&#35265;&#38472;&#33104;&#21270;&#21644;&#20943;&#23569;&#30001;&#22270;&#20687;&#24341;&#20837;&#30340;&#20998;&#24515;&#27010;&#24565;&#65292;&#23454;&#39564;&#35777;&#26126;&#20854;&#22312;&#31185;&#23398;&#38382;&#31572;&#21644;MMBench&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#39033;&#26088;&#22312;&#23558;&#22810;&#26234;&#33021;&#20307;&#36777;&#35770;&#24341;&#20837;&#22810;&#27169;&#24577;&#25512;&#29702;&#30340;&#35797;&#28857;&#30740;&#31350;&#12290;&#35813;&#30740;&#31350;&#35299;&#20915;&#20102;&#20004;&#20010;&#20851;&#38190;&#25361;&#25112;&#65306;&#30001;&#20110;&#36807;&#24230;&#24635;&#32467;&#32780;&#23548;&#33268;&#24847;&#35265;&#38472;&#33104;&#21270;&#65292;&#20197;&#21450;&#30001;&#20110;&#22270;&#20687;&#24341;&#20837;&#36716;&#31227;&#24615;&#27010;&#24565;&#32780;&#23548;&#33268;&#27880;&#24847;&#21147;&#20998;&#25955;&#30340;&#38382;&#39064;&#12290;&#36825;&#20123;&#25361;&#25112;&#28304;&#33258;&#29616;&#26377;&#36777;&#35770;&#26041;&#26696;&#30340;&#24402;&#32435;&#65288;&#33258;&#19979;&#32780;&#19978;&#65289;&#24615;&#36136;&#12290;&#20026;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#28436;&#32462;&#65288;&#33258;&#19978;&#32780;&#19979;&#65289;&#30340;&#36777;&#35770;&#26041;&#27861;&#65292;&#31216;&#20026;&#22270;&#35889;&#36777;&#35770;&#65288;BDoG&#65289;&#12290;&#22312;BDoG&#20013;&#65292;&#36777;&#35770;&#20165;&#38480;&#20110;&#34013;&#22270;&#22270;&#20013;&#65292;&#20197;&#38450;&#27490;&#36890;&#36807;&#19990;&#30028;&#32423;&#25688;&#35201;&#32780;&#23548;&#33268;&#24847;&#35265;&#38472;&#33104;&#21270;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#22312;&#22270;&#20013;&#30340;&#20998;&#25903;&#20013;&#23384;&#20648;&#35777;&#25454;&#65292;BDoG&#32531;&#35299;&#20102;&#39057;&#32321;&#20294;&#26080;&#20851;&#30340;&#27010;&#24565;&#24102;&#26469;&#30340;&#20998;&#25955;&#27880;&#24847;&#21147;&#29616;&#35937;&#12290;&#22823;&#37327;&#23454;&#39564;&#39564;&#35777;&#20102;BDoG&#65292;&#22312;&#31185;&#23398;&#38382;&#31572;&#21644;MMBench&#20013;&#21462;&#24471;&#20102;&#26368;&#26032;&#25104;&#26524;&#65292;&#24182;&#30456;&#36739;&#20110;&#20808;&#21069;&#30340;&#26041;&#27861;&#20855;&#26377;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14972v1 Announce Type: new  Abstract: This paper presents a pilot study aimed at introducing multi-agent debate into multimodal reasoning. The study addresses two key challenges: the trivialization of opinions resulting from excessive summarization and the diversion of focus caused by distractor concepts introduced from images. These challenges stem from the inductive (bottom-up) nature of existing debating schemes. To address the issue, we propose a deductive (top-down) debating approach called Blueprint Debate on Graphs (BDoG). In BDoG, debates are confined to a blueprint graph to prevent opinion trivialization through world-level summarization. Moreover, by storing evidence in branches within the graph, BDoG mitigates distractions caused by frequent but irrelevant concepts. Extensive experiments validate BDoG, achieving state-of-the-art results in Science QA and MMBench with significant improvements over previous methods.
&lt;/p&gt;</description></item></channel></rss>