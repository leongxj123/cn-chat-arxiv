<rss version="2.0"><channel><title>Chat Arxiv cs.MM</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.MM</description><item><title>&#35770;&#25991;&#25506;&#35752;&#20102;&#22522;&#20110;&#33258;&#28982;&#31354;&#38388;&#25551;&#36848;&#36827;&#34892;&#22810;&#23610;&#24230;&#31354;&#38388;&#20851;&#31995;&#25512;&#29702;&#30340;&#26041;&#27861;&#65292;&#21457;&#29616;&#36890;&#36807;&#33719;&#30693;&#22320;&#22270;&#30693;&#35782;&#24471;&#21040;&#30340;&#25551;&#36848;&#33021;&#22815;&#25552;&#20379;&#29615;&#22659;&#30340;&#25972;&#20307;&#32467;&#26500;&#12290;</title><link>https://arxiv.org/abs/2402.16364</link><description>&lt;p&gt;
&#20174;&#21738;&#37324;&#20986;&#21457;&#65311;&#26469;&#33258;&#33258;&#28982;&#31354;&#38388;&#25551;&#36848;&#20013;&#30340;&#22810;&#23610;&#24230;&#31354;&#38388;&#20851;&#31995;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Where Do We Go from Here? Multi-scale Allocentric Relational Inference from Natural Spatial Descriptions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16364
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#25506;&#35752;&#20102;&#22522;&#20110;&#33258;&#28982;&#31354;&#38388;&#25551;&#36848;&#36827;&#34892;&#22810;&#23610;&#24230;&#31354;&#38388;&#20851;&#31995;&#25512;&#29702;&#30340;&#26041;&#27861;&#65292;&#21457;&#29616;&#36890;&#36807;&#33719;&#30693;&#22320;&#22270;&#30693;&#35782;&#24471;&#21040;&#30340;&#25551;&#36848;&#33021;&#22815;&#25552;&#20379;&#29615;&#22659;&#30340;&#25972;&#20307;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#29992;&#33258;&#28982;&#35821;&#35328;&#20256;&#36798;&#36335;&#32447;&#26102;&#65292;&#8220;&#33719;&#24471;&#30340;&#31354;&#38388;&#30693;&#35782;&#8221;&#27010;&#24565;&#23545;&#22320;&#29702;&#20449;&#24687;&#26816;&#32034;&#65288;GIR&#65289;&#21644;&#31354;&#38388;&#35748;&#30693;&#30740;&#31350;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#23548;&#33322;&#30740;&#31350;&#32463;&#24120;&#24573;&#35270;&#36825;&#31181;&#33719;&#24471;&#30693;&#35782;&#23545;&#25991;&#26412;&#25551;&#36848;&#30340;&#24433;&#21709;&#12290;&#24403;&#21069;&#23548;&#33322;&#30740;&#31350;&#38598;&#20013;&#22312;&#20197;&#33258;&#25105;&#20026;&#20013;&#24515;&#30340;&#26412;&#22320;&#25551;&#36848;&#65288;&#20363;&#22914;&#65292;&#8220;&#23427;&#23558;&#22312;&#24744;&#30340;&#21491;&#36793;&#8221;&#65289;&#65292;&#36825;&#20123;&#25551;&#36848;&#38656;&#35201;&#23545;&#20195;&#29702;&#20154;&#30340;&#26412;&#22320;&#30693;&#35273;&#36827;&#34892;&#25512;&#29702;&#12290;&#22312;&#22320;&#22270;&#33719;&#24471;&#30340;&#30693;&#35782;&#22522;&#30784;&#19978;&#30340;&#25551;&#36848;&#25552;&#20379;&#20102;&#29615;&#22659;&#30340;&#25972;&#20307;&#35270;&#22270;&#65292;&#24182;&#25429;&#25417;&#20102;&#20854;&#24635;&#20307;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16364v1 Announce Type: new  Abstract: When communicating routes in natural language, the concept of {\em acquired spatial knowledge} is crucial for geographic information retrieval (GIR) and in spatial cognitive research. However, NLP navigation studies often overlook the impact of such acquired knowledge on textual descriptions. Current navigation studies concentrate on egocentric local descriptions (e.g., `it will be on your right') that require reasoning over the agent's local perception. These instructions are typically given as a sequence of steps, with each action-step explicitly mentioning and being followed by a landmark that the agent can use to verify they are on the right path (e.g., `turn right and then you will see...'). In contrast, descriptions based on knowledge acquired through a map provide a complete view of the environment and capture its overall structure. These instructions (e.g., `it is south of Central Park and a block north of a police station') are 
&lt;/p&gt;</description></item></channel></rss>