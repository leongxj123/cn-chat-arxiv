<rss version="2.0"><channel><title>Chat Arxiv cs.MM</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.MM</description><item><title>&#26412;&#25991;&#36890;&#36807;&#22312;&#38899;&#39057;&#20998;&#31867;&#20219;&#21153;&#20013;&#23398;&#20064;&#22810;&#26679;&#21270;&#30340;&#29305;&#24449;&#34920;&#31034;&#65292;&#21253;&#25324;&#39046;&#22495;&#29305;&#23450;&#30340;&#38899;&#39640;&#12289;&#38899;&#33394;&#21644;&#31070;&#32463;&#34920;&#31034;&#65292;&#20197;&#21450;&#31471;&#21040;&#31471;&#26550;&#26500;&#65292;&#20026;&#23398;&#20064;&#31283;&#20581;&#12289;&#22810;&#26679;&#21270;&#30340;&#34920;&#31034;&#38138;&#24179;&#20102;&#36947;&#36335;&#65292;&#24182;&#26174;&#33879;&#25552;&#39640;&#20102;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.08751</link><description>&lt;p&gt;
&#22810;&#26679;&#30340;&#31070;&#32463;&#38899;&#39057;&#23884;&#20837; - &#24674;&#22797;&#29305;&#24449;&#65281;
&lt;/p&gt;
&lt;p&gt;
Diverse Neural Audio Embeddings -- Bringing Features back !. (arXiv:2309.08751v1 [cs.SD])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08751
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#22312;&#38899;&#39057;&#20998;&#31867;&#20219;&#21153;&#20013;&#23398;&#20064;&#22810;&#26679;&#21270;&#30340;&#29305;&#24449;&#34920;&#31034;&#65292;&#21253;&#25324;&#39046;&#22495;&#29305;&#23450;&#30340;&#38899;&#39640;&#12289;&#38899;&#33394;&#21644;&#31070;&#32463;&#34920;&#31034;&#65292;&#20197;&#21450;&#31471;&#21040;&#31471;&#26550;&#26500;&#65292;&#20026;&#23398;&#20064;&#31283;&#20581;&#12289;&#22810;&#26679;&#21270;&#30340;&#34920;&#31034;&#38138;&#24179;&#20102;&#36947;&#36335;&#65292;&#24182;&#26174;&#33879;&#25552;&#39640;&#20102;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#29616;&#20195;&#20154;&#24037;&#26234;&#33021;&#26550;&#26500;&#30340;&#20986;&#29616;&#65292;&#20174;&#31471;&#21040;&#31471;&#30340;&#26550;&#26500;&#24320;&#22987;&#27969;&#34892;&#12290;&#36825;&#31181;&#36716;&#21464;&#23548;&#33268;&#20102;&#31070;&#32463;&#26550;&#26500;&#22312;&#27809;&#26377;&#39046;&#22495;&#29305;&#23450;&#20559;&#35265;/&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#35757;&#32451;&#65292;&#26681;&#25454;&#20219;&#21153;&#36827;&#34892;&#20248;&#21270;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#22810;&#26679;&#30340;&#29305;&#24449;&#34920;&#31034;&#65288;&#22312;&#26412;&#20363;&#20013;&#26159;&#39046;&#22495;&#29305;&#23450;&#30340;&#65289;&#23398;&#20064;&#38899;&#39057;&#23884;&#20837;&#12290;&#23545;&#20110;&#28041;&#21450;&#25968;&#30334;&#31181;&#22768;&#38899;&#20998;&#31867;&#30340;&#24773;&#20917;&#65292;&#25105;&#20204;&#23398;&#20064;&#20998;&#21035;&#38024;&#23545;&#38899;&#39640;&#12289;&#38899;&#33394;&#21644;&#31070;&#32463;&#34920;&#31034;&#31561;&#22810;&#26679;&#30340;&#38899;&#39057;&#23646;&#24615;&#24314;&#31435;&#31283;&#20581;&#30340;&#23884;&#20837;&#65292;&#21516;&#26102;&#20063;&#36890;&#36807;&#31471;&#21040;&#31471;&#26550;&#26500;&#36827;&#34892;&#23398;&#20064;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#25163;&#24037;&#21046;&#20316;&#30340;&#23884;&#20837;&#65292;&#20363;&#22914;&#22522;&#20110;&#38899;&#39640;&#21644;&#38899;&#33394;&#30340;&#23884;&#20837;&#65292;&#34429;&#28982;&#21333;&#29420;&#20351;&#29992;&#26102;&#26080;&#27861;&#20987;&#36133;&#23436;&#20840;&#31471;&#21040;&#31471;&#30340;&#34920;&#31034;&#65292;&#20294;&#23558;&#36825;&#20123;&#23884;&#20837;&#19982;&#31471;&#21040;&#31471;&#23884;&#20837;&#30456;&#32467;&#21512;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#24615;&#33021;&#12290;&#36825;&#39033;&#24037;&#20316;&#23558;&#20026;&#22312;&#31471;&#21040;&#31471;&#27169;&#22411;&#20013;&#24341;&#20837;&#19968;&#20123;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#26469;&#23398;&#20064;&#31283;&#20581;&#12289;&#22810;&#26679;&#21270;&#30340;&#34920;&#31034;&#38138;&#24179;&#36947;&#36335;&#65292;&#24182;&#36229;&#36234;&#20165;&#35757;&#32451;&#31471;&#21040;&#31471;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the advent of modern AI architectures, a shift has happened towards end-to-end architectures. This pivot has led to neural architectures being trained without domain-specific biases/knowledge, optimized according to the task. We in this paper, learn audio embeddings via diverse feature representations, in this case, domain-specific. For the case of audio classification over hundreds of categories of sound, we learn robust separate embeddings for diverse audio properties such as pitch, timbre, and neural representation, along with also learning it via an end-to-end architecture. We observe handcrafted embeddings, e.g., pitch and timbre-based, although on their own, are not able to beat a fully end-to-end representation, yet adding these together with end-to-end embedding helps us, significantly improve performance. This work would pave the way to bring some domain expertise with end-to-end models to learn robust, diverse representations, surpassing the performance of just training 
&lt;/p&gt;</description></item><item><title>JEN-1&#26159;&#19968;&#20010;&#39640;&#20445;&#30495;&#24230;&#36890;&#29992;&#38899;&#20048;&#29983;&#25104;&#27169;&#22411;&#65292;&#36890;&#36807;&#32467;&#21512;&#33258;&#22238;&#24402;&#21644;&#38750;&#33258;&#22238;&#24402;&#35757;&#32451;&#65292;&#23454;&#29616;&#20102;&#25991;&#26412;&#24341;&#23548;&#30340;&#38899;&#20048;&#29983;&#25104;&#12289;&#38899;&#20048;&#20462;&#34917;&#21644;&#24310;&#32493;&#31561;&#29983;&#25104;&#20219;&#21153;&#65292;&#22312;&#25991;&#26412;&#38899;&#20048;&#23545;&#40784;&#21644;&#38899;&#20048;&#36136;&#37327;&#26041;&#38754;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#65292;&#21516;&#26102;&#20445;&#25345;&#35745;&#31639;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2308.04729</link><description>&lt;p&gt;
JEN-1&#65306;&#20855;&#26377;&#20840;&#21521;&#25193;&#25955;&#27169;&#22411;&#30340;&#25991;&#26412;&#24341;&#23548;&#36890;&#29992;&#38899;&#20048;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
JEN-1: Text-Guided Universal Music Generation with Omnidirectional Diffusion Models. (arXiv:2308.04729v1 [cs.SD])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04729
&lt;/p&gt;
&lt;p&gt;
JEN-1&#26159;&#19968;&#20010;&#39640;&#20445;&#30495;&#24230;&#36890;&#29992;&#38899;&#20048;&#29983;&#25104;&#27169;&#22411;&#65292;&#36890;&#36807;&#32467;&#21512;&#33258;&#22238;&#24402;&#21644;&#38750;&#33258;&#22238;&#24402;&#35757;&#32451;&#65292;&#23454;&#29616;&#20102;&#25991;&#26412;&#24341;&#23548;&#30340;&#38899;&#20048;&#29983;&#25104;&#12289;&#38899;&#20048;&#20462;&#34917;&#21644;&#24310;&#32493;&#31561;&#29983;&#25104;&#20219;&#21153;&#65292;&#22312;&#25991;&#26412;&#38899;&#20048;&#23545;&#40784;&#21644;&#38899;&#20048;&#36136;&#37327;&#26041;&#38754;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#65292;&#21516;&#26102;&#20445;&#25345;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30340;&#36827;&#27493;&#65292;&#38899;&#20048;&#29983;&#25104;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#22522;&#20110;&#25991;&#26412;&#25551;&#36848;&#29983;&#25104;&#38899;&#20048;&#65288;&#21363;&#25991;&#26412;&#21040;&#38899;&#20048;&#65289;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#21407;&#22240;&#26159;&#38899;&#20048;&#32467;&#26500;&#30340;&#22797;&#26434;&#24615;&#21644;&#39640;&#37319;&#26679;&#29575;&#30340;&#35201;&#27714;&#12290;&#23613;&#31649;&#20219;&#21153;&#30340;&#37325;&#35201;&#24615;&#65292;&#24403;&#21069;&#30340;&#29983;&#25104;&#27169;&#22411;&#22312;&#38899;&#20048;&#36136;&#37327;&#12289;&#35745;&#31639;&#25928;&#29575;&#21644;&#27867;&#21270;&#33021;&#21147;&#26041;&#38754;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;JEN-1&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#25991;&#26412;&#21040;&#38899;&#20048;&#29983;&#25104;&#30340;&#36890;&#29992;&#39640;&#20445;&#30495;&#27169;&#22411;&#12290;JEN-1&#26159;&#19968;&#20010;&#32467;&#21512;&#20102;&#33258;&#22238;&#24402;&#21644;&#38750;&#33258;&#22238;&#24402;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#12290;&#36890;&#36807;&#19978;&#19979;&#25991;&#23398;&#20064;&#65292;JEN-1&#21487;&#20197;&#25191;&#34892;&#21508;&#31181;&#29983;&#25104;&#20219;&#21153;&#65292;&#21253;&#25324;&#25991;&#26412;&#24341;&#23548;&#30340;&#38899;&#20048;&#29983;&#25104;&#12289;&#38899;&#20048;&#20462;&#34917;&#20197;&#21450;&#24310;&#32493;&#12290;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126;&#65292;JEN-1&#22312;&#25991;&#26412;&#38899;&#20048;&#23545;&#40784;&#21644;&#38899;&#20048;&#36136;&#37327;&#26041;&#38754;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#65292;&#21516;&#26102;&#20445;&#25345;&#35745;&#31639;&#25928;&#29575;&#12290;&#25105;&#20204;&#30340;&#28436;&#31034;&#21487;&#22312;&#27492;&#32593;&#22336;&#33719;&#21462;&#65306;http://URL
&lt;/p&gt;
&lt;p&gt;
Music generation has attracted growing interest with the advancement of deep generative models. However, generating music conditioned on textual descriptions, known as text-to-music, remains challenging due to the complexity of musical structures and high sampling rate requirements. Despite the task's significance, prevailing generative models exhibit limitations in music quality, computational efficiency, and generalization. This paper introduces JEN-1, a universal high-fidelity model for text-to-music generation. JEN-1 is a diffusion model incorporating both autoregressive and non-autoregressive training. Through in-context learning, JEN-1 performs various generation tasks including text-guided music generation, music inpainting, and continuation. Evaluations demonstrate JEN-1's superior performance over state-of-the-art methods in text-music alignment and music quality while maintaining computational efficiency. Our demos are available at this http URL
&lt;/p&gt;</description></item></channel></rss>