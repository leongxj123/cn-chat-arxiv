<rss version="2.0"><channel><title>Chat Arxiv cs.MM</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.MM</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#36923;&#36753;&#30340;&#22810;&#27169;&#24577;&#34394;&#20551;&#20449;&#24687;&#26816;&#27979;&#31070;&#32463;&#27169;&#22411;&#65292;&#36890;&#36807;&#38598;&#25104;&#21487;&#35299;&#37322;&#24615;&#36923;&#36753;&#23376;&#21477;&#34920;&#36798;&#30446;&#26631;&#20219;&#21153;&#30340;&#25512;&#29702;&#36807;&#31243;&#65292;&#24182;&#20351;&#29992;&#31070;&#32463;&#34920;&#24449;&#21442;&#25968;&#21270;&#31526;&#21495;&#36923;&#36753;&#20803;&#32032;&#65292;&#20174;&#32780;&#20415;&#20110;&#33258;&#21160;&#29983;&#25104;&#21644;&#35780;&#20272;&#26377;&#24847;&#20041;&#30340;&#36923;&#36753;&#23376;&#21477;&#12290;&#27492;&#22806;&#65292;&#24341;&#20837;&#20102;&#20116;&#20010;&#20803;&#39044;&#27979;&#22120;&#26469;&#25429;&#33719;&#34394;&#20551;&#20449;&#24687;&#30340;&#22522;&#26412;&#27169;&#24335;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#27169;&#22411;&#19981;&#20165;&#24615;&#33021;&#26174;&#33879;&#20248;&#20110;&#24403;&#21069;&#26041;&#27861;&#65292;&#32780;&#19988;&#25552;&#20379;&#20102;&#36879;&#26126;&#19988;&#21487;&#35299;&#37322;&#30340;&#36923;&#36753;&#25512;&#29702;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2305.05964</link><description>&lt;p&gt;
&#22810;&#27169;&#24577;&#34394;&#20551;&#20449;&#24687;&#35299;&#37322;&#24615;&#26816;&#27979;&#19982;&#36923;&#36753;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Interpretable Multimodal Misinformation Detection with Logic Reasoning. (arXiv:2305.05964v1 [cs.MM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05964
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#36923;&#36753;&#30340;&#22810;&#27169;&#24577;&#34394;&#20551;&#20449;&#24687;&#26816;&#27979;&#31070;&#32463;&#27169;&#22411;&#65292;&#36890;&#36807;&#38598;&#25104;&#21487;&#35299;&#37322;&#24615;&#36923;&#36753;&#23376;&#21477;&#34920;&#36798;&#30446;&#26631;&#20219;&#21153;&#30340;&#25512;&#29702;&#36807;&#31243;&#65292;&#24182;&#20351;&#29992;&#31070;&#32463;&#34920;&#24449;&#21442;&#25968;&#21270;&#31526;&#21495;&#36923;&#36753;&#20803;&#32032;&#65292;&#20174;&#32780;&#20415;&#20110;&#33258;&#21160;&#29983;&#25104;&#21644;&#35780;&#20272;&#26377;&#24847;&#20041;&#30340;&#36923;&#36753;&#23376;&#21477;&#12290;&#27492;&#22806;&#65292;&#24341;&#20837;&#20102;&#20116;&#20010;&#20803;&#39044;&#27979;&#22120;&#26469;&#25429;&#33719;&#34394;&#20551;&#20449;&#24687;&#30340;&#22522;&#26412;&#27169;&#24335;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#27169;&#22411;&#19981;&#20165;&#24615;&#33021;&#26174;&#33879;&#20248;&#20110;&#24403;&#21069;&#26041;&#27861;&#65292;&#32780;&#19988;&#25552;&#20379;&#20102;&#36879;&#26126;&#19988;&#21487;&#35299;&#37322;&#30340;&#36923;&#36753;&#25512;&#29702;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#31038;&#20132;&#24179;&#21488;&#19978;&#30340;&#22810;&#27169;&#24577;&#34394;&#20551;&#20449;&#24687;&#30001;&#20110;&#22810;&#23186;&#20307;&#20869;&#23481;&#30340;&#21487;&#20449;&#24230;&#21644;&#20256;&#25773;&#26356;&#23481;&#26131;&#32780;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#34429;&#28982;&#29616;&#26377;&#30340;&#22810;&#27169;&#24577;&#26816;&#27979;&#26041;&#27861;&#24050;&#32463;&#36798;&#21040;&#20102;&#36739;&#39640;&#30340;&#24615;&#33021;&#65292;&#20294;&#32570;&#20047;&#35299;&#37322;&#24615;&#38459;&#30861;&#20102;&#36825;&#20123;&#31995;&#32479;&#30340;&#21487;&#38752;&#24615;&#21644;&#23454;&#38469;&#37096;&#32626;&#12290;&#21463;&#21040; NeuralSymbolic AI &#30340;&#21551;&#21457;&#65292;&#35813;&#26041;&#27861;&#32467;&#21512;&#20102;&#31070;&#32463;&#32593;&#32476;&#30340;&#23398;&#20064;&#33021;&#21147;&#21644;&#31526;&#21495;&#23398;&#20064;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#36923;&#36753;&#30340;&#22810;&#27169;&#24577;&#34394;&#20551;&#20449;&#24687;&#26816;&#27979;&#31070;&#32463;&#27169;&#22411;&#65292;&#23427;&#38598;&#25104;&#20102;&#21487;&#35299;&#37322;&#24615;&#36923;&#36753;&#23376;&#21477;&#20197;&#34920;&#36798;&#30446;&#26631;&#20219;&#21153;&#30340;&#25512;&#29702;&#36807;&#31243;&#12290;&#20026;&#20102;&#20351;&#23398;&#20064;&#26377;&#25928;&#65292;&#25105;&#20204;&#20351;&#29992;&#31070;&#32463;&#34920;&#24449;&#26469;&#21442;&#25968;&#21270;&#31526;&#21495;&#36923;&#36753;&#20803;&#32032;&#65292;&#20174;&#32780;&#20415;&#20110;&#33258;&#21160;&#29983;&#25104;&#21644;&#35780;&#20272;&#26377;&#24847;&#20041;&#30340;&#36923;&#36753;&#23376;&#21477;&#12290;&#21478;&#22806;&#65292;&#20026;&#20102;&#20351;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#36866;&#29992;&#20110;&#21508;&#31181;&#34394;&#20551;&#20449;&#24687;&#26469;&#28304;&#65292;&#25105;&#20204;&#22312;&#22810;&#27169;&#24577;&#34701;&#21512;&#32593;&#32476;&#20013;&#24341;&#20837;&#20102;&#20116;&#20010;&#20803;&#39044;&#27979;&#22120;&#26469;&#25429;&#33719;&#34394;&#20551;&#20449;&#24687;&#30340;&#22522;&#26412;&#27169;&#24335;&#12290;&#25105;&#20204;&#22312;&#23454;&#38469;&#30340;&#22810;&#27169;&#24577;&#34394;&#20551;&#20449;&#24687;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#65292;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#19981;&#20165;&#26174;&#30528;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#36824;&#20026;&#27599;&#20010;&#39044;&#27979;&#25552;&#20379;&#20102;&#36879;&#26126;&#19988;&#21487;&#35299;&#37322;&#30340;&#36923;&#36753;&#25512;&#29702;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multimodal misinformation on online social platforms is becoming a critical concern due to increasing credibility and easier dissemination brought by multimedia content, compared to traditional text-only information. While existing multimodal detection approaches have achieved high performance, the lack of interpretability hinders these systems' reliability and practical deployment. Inspired by NeuralSymbolic AI which combines the learning ability of neural networks with the explainability of symbolic learning, we propose a novel logic-based neural model for multimodal misinformation detection which integrates interpretable logic clauses to express the reasoning process of the target task. To make learning effective, we parameterize symbolic logical elements using neural representations, which facilitate the automatic generation and evaluation of meaningful logic clauses. Additionally, to make our framework generalizable across diverse misinformation sources, we introduce five meta-pre
&lt;/p&gt;</description></item></channel></rss>