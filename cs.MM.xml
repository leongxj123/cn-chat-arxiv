<rss version="2.0"><channel><title>Chat Arxiv cs.MM</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.MM</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;AVTENet&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#26159;&#19968;&#20010;&#22522;&#20110;&#38899;&#39057;-&#35270;&#35273;Transformer&#30340;&#22810;&#19987;&#23478;&#38598;&#25104;&#32593;&#32476;&#65292;&#29992;&#20110;&#22312;&#35270;&#39057;&#28145;&#24230;&#20266;&#36896;&#26816;&#27979;&#20013;&#32771;&#34385;&#22768;&#23398;&#21644;&#35270;&#35273;&#25805;&#20316;&#12290;</title><link>http://arxiv.org/abs/2310.13103</link><description>&lt;p&gt;
AVTENet: &#22522;&#20110;&#38899;&#39057;-&#35270;&#35273;Transformer&#30340;&#22810;&#19987;&#23478;&#38598;&#25104;&#32593;&#32476;&#22312;&#35270;&#39057;&#28145;&#24230;&#20266;&#36896;&#26816;&#27979;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
AVTENet: Audio-Visual Transformer-based Ensemble Network Exploiting Multiple Experts for Video Deepfake Detection. (arXiv:2310.13103v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13103
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;AVTENet&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#26159;&#19968;&#20010;&#22522;&#20110;&#38899;&#39057;-&#35270;&#35273;Transformer&#30340;&#22810;&#19987;&#23478;&#38598;&#25104;&#32593;&#32476;&#65292;&#29992;&#20110;&#22312;&#35270;&#39057;&#28145;&#24230;&#20266;&#36896;&#26816;&#27979;&#20013;&#32771;&#34385;&#22768;&#23398;&#21644;&#35270;&#35273;&#25805;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#19978;&#24191;&#27867;&#20998;&#20139;&#30340;&#20266;&#36896;&#20869;&#23481;&#26159;&#19968;&#20010;&#37325;&#22823;&#31038;&#20250;&#38382;&#39064;&#65292;&#35201;&#27714;&#21152;&#24378;&#30417;&#31649;&#24182;&#32473;&#30740;&#31350;&#31038;&#21306;&#24102;&#26469;&#26032;&#30340;&#25361;&#25112;&#12290;&#36817;&#24180;&#26469;&#65292;&#36229;&#30495;&#23454;&#30340;&#28145;&#24230;&#20266;&#36896;&#35270;&#39057;&#30340;&#26222;&#21450;&#24341;&#36215;&#20102;&#23545;&#38899;&#39057;&#21644;&#35270;&#35273;&#20266;&#36896;&#23041;&#32961;&#30340;&#20851;&#27880;&#12290;&#22823;&#22810;&#25968;&#20851;&#20110;&#26816;&#27979;AI&#29983;&#25104;&#30340;&#20266;&#36896;&#35270;&#39057;&#30340;&#20808;&#21069;&#24037;&#20316;&#21482;&#21033;&#29992;&#20102;&#35270;&#35273;&#27169;&#24577;&#25110;&#38899;&#39057;&#27169;&#24577;&#12290;&#34429;&#28982;&#25991;&#29486;&#20013;&#26377;&#19968;&#20123;&#26041;&#27861;&#21033;&#29992;&#38899;&#39057;&#21644;&#35270;&#35273;&#27169;&#24577;&#26469;&#26816;&#27979;&#20266;&#36896;&#35270;&#39057;&#65292;&#20294;&#23427;&#20204;&#23578;&#26410;&#22312;&#28041;&#21450;&#22768;&#23398;&#21644;&#35270;&#35273;&#25805;&#20316;&#30340;&#22810;&#27169;&#24577;&#28145;&#24230;&#20266;&#36896;&#35270;&#39057;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20840;&#38754;&#35780;&#20272;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#29616;&#26377;&#26041;&#27861;&#22823;&#22810;&#22522;&#20110;CNN&#65292;&#24182;&#19988;&#26816;&#27979;&#20934;&#30830;&#29575;&#36739;&#20302;&#12290;&#21463;&#21040;Transformer&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#26368;&#26032;&#25104;&#21151;&#21551;&#21457;&#65292;&#20026;&#20102;&#35299;&#20915;&#28145;&#24230;&#20266;&#36896;&#25216;&#26415;&#24102;&#26469;&#30340;&#25361;&#25112;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32771;&#34385;&#22768;&#23398;&#25805;&#20316;&#30340;&#38899;&#39057;-&#35270;&#35273;Transformer&#38598;&#25104;&#32593;&#32476;&#65288;AVTENet&#65289;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
Forged content shared widely on social media platforms is a major social problem that requires increased regulation and poses new challenges to the research community. The recent proliferation of hyper-realistic deepfake videos has drawn attention to the threat of audio and visual forgeries. Most previous work on detecting AI-generated fake videos only utilizes visual modality or audio modality. While there are some methods in the literature that exploit audio and visual modalities to detect forged videos, they have not been comprehensively evaluated on multi-modal datasets of deepfake videos involving acoustic and visual manipulations. Moreover, these existing methods are mostly based on CNN and suffer from low detection accuracy. Inspired by the recent success of Transformer in various fields, to address the challenges posed by deepfake technology, in this paper, we propose an Audio-Visual Transformer-based Ensemble Network (AVTENet) framework that considers both acoustic manipulatio
&lt;/p&gt;</description></item></channel></rss>