<rss version="2.0"><channel><title>Chat Arxiv cs.MM</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.MM</description><item><title>AnyV2V&#26159;&#19968;&#31181;&#36866;&#29992;&#20110;&#20219;&#20309;&#35270;&#39057;&#21040;&#35270;&#39057;&#32534;&#36753;&#20219;&#21153;&#30340;&#21363;&#25554;&#21363;&#29992;&#26694;&#26550;&#65292;&#36890;&#36807;&#20004;&#20010;&#20027;&#35201;&#27493;&#39588;&#31616;&#21270;&#35270;&#39057;&#32534;&#36753;&#65292;&#25903;&#25345;&#24191;&#27867;&#30340;&#35270;&#39057;&#32534;&#36753;&#20219;&#21153;&#65292;&#24182;&#33021;&#22815;&#22788;&#29702;&#20256;&#32479;&#21644;&#26032;&#39062;&#30340;&#32534;&#36753;&#38656;&#27714;&#12290;</title><link>https://arxiv.org/abs/2403.14468</link><description>&lt;p&gt;
AnyV2V&#65306;&#19968;&#31181;&#36866;&#29992;&#20110;&#20219;&#20309;&#35270;&#39057;&#21040;&#35270;&#39057;&#32534;&#36753;&#20219;&#21153;&#30340;&#21363;&#25554;&#21363;&#29992;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
AnyV2V: A Plug-and-Play Framework For Any Video-to-Video Editing Tasks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14468
&lt;/p&gt;
&lt;p&gt;
AnyV2V&#26159;&#19968;&#31181;&#36866;&#29992;&#20110;&#20219;&#20309;&#35270;&#39057;&#21040;&#35270;&#39057;&#32534;&#36753;&#20219;&#21153;&#30340;&#21363;&#25554;&#21363;&#29992;&#26694;&#26550;&#65292;&#36890;&#36807;&#20004;&#20010;&#20027;&#35201;&#27493;&#39588;&#31616;&#21270;&#35270;&#39057;&#32534;&#36753;&#65292;&#25903;&#25345;&#24191;&#27867;&#30340;&#35270;&#39057;&#32534;&#36753;&#20219;&#21153;&#65292;&#24182;&#33021;&#22815;&#22788;&#29702;&#20256;&#32479;&#21644;&#26032;&#39062;&#30340;&#32534;&#36753;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14468v1 &#20844;&#21578;&#31867;&#22411;: &#36328;&#36234; &#25688;&#35201;: &#35270;&#39057;&#21040;&#35270;&#39057;&#32534;&#36753;&#28041;&#21450;&#32534;&#36753;&#28304;&#35270;&#39057;&#20197;&#21450;&#39069;&#22806;&#30340;&#25511;&#21046;&#65288;&#20363;&#22914;&#25991;&#26412;&#25552;&#31034;&#12289;&#20027;&#39064;&#25110;&#39118;&#26684;&#65289;&#65292;&#20197;&#29983;&#25104;&#19982;&#28304;&#35270;&#39057;&#21644;&#25552;&#20379;&#30340;&#25511;&#21046;&#30456;&#21305;&#37197;&#30340;&#26032;&#35270;&#39057;&#12290;&#20256;&#32479;&#26041;&#27861;&#21463;&#38480;&#20110;&#29305;&#23450;&#30340;&#32534;&#36753;&#31867;&#22411;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#28385;&#36275;&#24191;&#27867;&#29992;&#25143;&#38656;&#27714;&#30340;&#33021;&#21147;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;AnyV2V&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#20813;&#35757;&#32451;&#26694;&#26550;&#65292;&#26088;&#22312;&#23558;&#35270;&#39057;&#32534;&#36753;&#31616;&#21270;&#20026;&#20004;&#20010;&#20027;&#35201;&#27493;&#39588;&#65306;&#65288;1&#65289;&#21033;&#29992;&#29616;&#25104;&#30340;&#22270;&#20687;&#32534;&#36753;&#27169;&#22411;&#65288;&#20363;&#22914;InstructPix2Pix&#12289;InstantID&#31561;&#65289;&#20462;&#25913;&#31532;&#19968;&#24103;&#65292;&#65288;2&#65289;&#21033;&#29992;&#29616;&#26377;&#30340;&#22270;&#20687;&#21040;&#35270;&#39057;&#29983;&#25104;&#27169;&#22411;&#65288;&#20363;&#22914;I2VGen-XL&#65289;&#36827;&#34892;DDIM&#36870;&#36716;&#21644;&#29305;&#24449;&#27880;&#20837;&#12290;&#22312;&#31532;&#19968;&#38454;&#27573;&#65292;AnyV2V&#21487;&#20197;&#25554;&#20837;&#20219;&#20309;&#29616;&#26377;&#30340;&#22270;&#20687;&#32534;&#36753;&#24037;&#20855;&#65292;&#20197;&#25903;&#25345;&#24191;&#27867;&#30340;&#35270;&#39057;&#32534;&#36753;&#20219;&#21153;&#12290;&#38500;&#20102;&#20256;&#32479;&#30340;&#22522;&#20110;&#25552;&#31034;&#30340;&#32534;&#36753;&#26041;&#27861;&#65292;AnyV2V&#36824;&#21487;&#20197;&#25903;&#25345;&#26032;&#39062;&#30340;&#35270;&#39057;&#32534;&#36753;&#20219;&#21153;&#65292;&#21253;&#25324;&#21442;&#32771;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14468v1 Announce Type: cross  Abstract: Video-to-video editing involves editing a source video along with additional control (such as text prompts, subjects, or styles) to generate a new video that aligns with the source video and the provided control. Traditional methods have been constrained to certain editing types, limiting their ability to meet the wide range of user demands. In this paper, we introduce AnyV2V, a novel training-free framework designed to simplify video editing into two primary steps: (1) employing an off-the-shelf image editing model (e.g. InstructPix2Pix, InstantID, etc) to modify the first frame, (2) utilizing an existing image-to-video generation model (e.g. I2VGen-XL) for DDIM inversion and feature injection. In the first stage, AnyV2V can plug in any existing image editing tools to support an extensive array of video editing tasks. Beyond the traditional prompt-based editing methods, AnyV2V also can support novel video editing tasks, including refe
&lt;/p&gt;</description></item></channel></rss>