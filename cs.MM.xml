<rss version="2.0"><channel><title>Chat Arxiv cs.MM</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.MM</description><item><title>OneAdapt&#36890;&#36807;&#26799;&#24230;&#19978;&#21319;&#31574;&#30053;&#26469;&#23454;&#29616;&#24555;&#36895;&#33258;&#36866;&#24212;&#65292;&#28385;&#36275;&#20102;&#28145;&#24230;&#23398;&#20064;&#24212;&#29992;&#22312;&#37197;&#32622;&#21442;&#25968;&#26041;&#38754;&#30340;&#19977;&#20010;&#35201;&#27714;&#12290;</title><link>http://arxiv.org/abs/2310.02422</link><description>&lt;p&gt;
OneAdapt&#65306;&#36890;&#36807;&#21453;&#21521;&#20256;&#25773;&#23454;&#29616;&#28145;&#24230;&#23398;&#20064;&#24212;&#29992;&#30340;&#24555;&#36895;&#33258;&#36866;&#24212;
&lt;/p&gt;
&lt;p&gt;
OneAdapt: Fast Adaptation for Deep Learning Applications via Backpropagation. (arXiv:2310.02422v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02422
&lt;/p&gt;
&lt;p&gt;
OneAdapt&#36890;&#36807;&#26799;&#24230;&#19978;&#21319;&#31574;&#30053;&#26469;&#23454;&#29616;&#24555;&#36895;&#33258;&#36866;&#24212;&#65292;&#28385;&#36275;&#20102;&#28145;&#24230;&#23398;&#20064;&#24212;&#29992;&#22312;&#37197;&#32622;&#21442;&#25968;&#26041;&#38754;&#30340;&#19977;&#20010;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#22312;&#27969;&#23186;&#20307;&#25968;&#25454;&#30340;&#25512;&#26029;&#26041;&#38754;&#24050;&#32463;&#26222;&#21450;&#65292;&#22914;&#35270;&#39057;&#20013;&#30340;&#30446;&#26631;&#26816;&#27979;&#12289;LiDAR&#25968;&#25454;&#21644;&#38899;&#39057;&#27874;&#24418;&#20013;&#30340;&#25991;&#26412;&#25552;&#21462;&#12290;&#20026;&#20102;&#23454;&#29616;&#39640;&#25512;&#26029;&#20934;&#30830;&#24615;&#65292;&#36825;&#20123;&#24212;&#29992;&#36890;&#24120;&#38656;&#35201;&#22823;&#37327;&#30340;&#32593;&#32476;&#24102;&#23485;&#26469;&#25910;&#38598;&#39640;&#20445;&#30495;&#25968;&#25454;&#65292;&#24182;&#19988;&#38656;&#35201;&#24191;&#27867;&#30340;GPU&#36164;&#28304;&#26469;&#36816;&#34892;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNN)&#12290;&#23613;&#31649;&#36890;&#36807;&#20248;&#21270;&#37197;&#32622;&#21442;&#25968;&#65288;&#22914;&#35270;&#39057;&#20998;&#36776;&#29575;&#21644;&#24103;&#29575;&#65289;&#21487;&#20197;&#22823;&#22823;&#20943;&#23569;&#23545;&#32593;&#32476;&#24102;&#23485;&#21644;GPU&#36164;&#28304;&#30340;&#38656;&#27714;&#65292;&#20294;&#30446;&#21069;&#30340;&#33258;&#36866;&#24212;&#25216;&#26415;&#26080;&#27861;&#21516;&#26102;&#28385;&#36275;&#19977;&#20010;&#35201;&#27714;&#65306;&#65288;i&#65289;&#20197;&#26368;&#23567;&#30340;&#39069;&#22806;GPU&#25110;&#24102;&#23485;&#24320;&#38144;&#26469;&#33258;&#36866;&#24212;&#37197;&#32622;&#65307;&#65288;ii&#65289;&#22522;&#20110;&#25968;&#25454;&#23545;&#26368;&#32456;DNN&#30340;&#20934;&#30830;&#24615;&#30340;&#24433;&#21709;&#26469;&#36798;&#21040;&#25509;&#36817;&#26368;&#20248;&#30340;&#20915;&#31574;&#65307;&#65288;iii&#65289;&#38024;&#23545;&#19968;&#31995;&#21015;&#37197;&#32622;&#21442;&#25968;&#36827;&#34892;&#33258;&#36866;&#24212;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;OneAdapt&#65292;&#36890;&#36807;&#21033;&#29992;&#26799;&#24230;&#19978;&#21319;&#31574;&#30053;&#26469;&#33258;&#36866;&#24212;&#37197;&#32622;&#21442;&#25968;&#65292;&#28385;&#36275;&#20102;&#36825;&#20123;&#35201;&#27714;&#12290;&#20851;&#38190;&#24605;&#24819;&#26159;&#20805;&#20998;&#21033;&#29992;DNN&#30340;&#19981;&#21516;
&lt;/p&gt;
&lt;p&gt;
Deep learning inference on streaming media data, such as object detection in video or LiDAR feeds and text extraction from audio waves, is now ubiquitous. To achieve high inference accuracy, these applications typically require significant network bandwidth to gather high-fidelity data and extensive GPU resources to run deep neural networks (DNNs). While the high demand for network bandwidth and GPU resources could be substantially reduced by optimally adapting the configuration knobs, such as video resolution and frame rate, current adaptation techniques fail to meet three requirements simultaneously: adapt configurations (i) with minimum extra GPU or bandwidth overhead; (ii) to reach near-optimal decisions based on how the data affects the final DNN's accuracy, and (iii) do so for a range of configuration knobs. This paper presents OneAdapt, which meets these requirements by leveraging a gradient-ascent strategy to adapt configuration knobs. The key idea is to embrace DNNs' different
&lt;/p&gt;</description></item></channel></rss>