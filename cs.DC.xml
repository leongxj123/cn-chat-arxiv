<rss version="2.0"><channel><title>Chat Arxiv cs.DC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.DC</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;EdgeOL&#65292;&#19968;&#31181;&#36793;&#32536;&#22312;&#32447;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#20869;&#37096;&#21644;&#22806;&#37096;&#35843;&#20248;&#26469;&#20248;&#21270;&#25512;&#29702;&#20934;&#30830;&#24615;&#12289;&#24494;&#35843;&#25191;&#34892;&#26102;&#38388;&#21644;&#33021;&#37327;&#25928;&#29575;&#65292;&#22312;&#36793;&#32536;&#35774;&#22791;&#19978;&#23454;&#29616;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2401.16694</link><description>&lt;p&gt;
EdgeOL: &#36793;&#32536;&#35774;&#22791;&#19978;&#39640;&#25928;&#30340;&#21407;&#20301;&#22312;&#32447;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
EdgeOL: Efficient in-situ Online Learning on Edge Devices. (arXiv:2401.16694v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16694
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;EdgeOL&#65292;&#19968;&#31181;&#36793;&#32536;&#22312;&#32447;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#20869;&#37096;&#21644;&#22806;&#37096;&#35843;&#20248;&#26469;&#20248;&#21270;&#25512;&#29702;&#20934;&#30830;&#24615;&#12289;&#24494;&#35843;&#25191;&#34892;&#26102;&#38388;&#21644;&#33021;&#37327;&#25928;&#29575;&#65292;&#22312;&#36793;&#32536;&#35774;&#22791;&#19978;&#23454;&#29616;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26032;&#20852;&#24212;&#29992;&#65292;&#22914;&#26426;&#22120;&#20154;&#36741;&#21161;&#20859;&#32769;&#21644;&#29289;&#20307;&#35782;&#21035;&#65292;&#36890;&#24120;&#37319;&#29992;&#28145;&#24230;&#23398;&#20064;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#24182;&#19988;&#33258;&#28982;&#38656;&#35201;&#65306;i) &#22788;&#29702;&#23454;&#26102;&#25512;&#29702;&#35831;&#27714;&#21644;ii) &#36866;&#24212;&#21487;&#33021;&#30340;&#37096;&#32626;&#22330;&#26223;&#21464;&#21270;&#12290;&#22312;&#32447;&#27169;&#22411;&#24494;&#35843;&#34987;&#24191;&#27867;&#37319;&#29992;&#20197;&#28385;&#36275;&#36825;&#20123;&#38656;&#27714;&#12290;&#28982;&#32780;&#65292;&#24494;&#35843;&#20250;&#23548;&#33268;&#26174;&#33879;&#30340;&#33021;&#37327;&#28040;&#32791;&#65292;&#20351;&#20854;&#38590;&#20197;&#37096;&#32626;&#22312;&#36793;&#32536;&#35774;&#22791;&#19978;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;EdgeOL&#65292;&#19968;&#31181;&#36793;&#32536;&#22312;&#32447;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#20869;&#37096;&#21644;&#22806;&#37096;&#35843;&#20248;&#26469;&#20248;&#21270;&#25512;&#29702;&#20934;&#30830;&#24615;&#12289;&#24494;&#35843;&#25191;&#34892;&#26102;&#38388;&#21644;&#33021;&#37327;&#25928;&#29575;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;EdgeOL&#24179;&#22343;&#20943;&#23569;&#20102;82%&#30340;&#24494;&#35843;&#25191;&#34892;&#26102;&#38388;&#65292;74%&#30340;&#33021;&#37327;&#28040;&#32791;&#65292;&#24182;&#25552;&#39640;&#20102;&#24179;&#22343;&#25512;&#29702;&#20934;&#30830;&#29575;1.70%&#65292;&#30456;&#23545;&#20110;&#21363;&#26102;&#22312;&#32447;&#23398;&#20064;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Emerging applications, such as robot-assisted eldercare and object recognition, generally employ deep learning neural networks (DNNs) models and naturally require: i) handling streaming-in inference requests and ii) adapting to possible deployment scenario changes. Online model fine-tuning is widely adopted to satisfy these needs. However, fine-tuning involves significant energy consumption, making it challenging to deploy on edge devices. In this paper, we propose EdgeOL, an edge online learning framework that optimizes inference accuracy, fine-tuning execution time, and energy efficiency through both inter-tuning and intra-tuning optimizations. Experimental results show that, on average, EdgeOL reduces overall fine-tuning execution time by 82%, energy consumption by 74%, and improves average inference accuracy by 1.70% over the immediate online learning strategy.
&lt;/p&gt;</description></item><item><title>&#22312;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#26102;&#20195;&#30340;&#29289;&#32852;&#32593;&#65292;Generative AI&#30340;&#36827;&#23637;&#24102;&#26469;&#20102;&#24040;&#22823;&#30340;&#24076;&#26395;&#65292;&#21516;&#26102;&#20063;&#38754;&#20020;&#30528;&#39640;&#36164;&#28304;&#38656;&#27714;&#12289;&#21450;&#26102;&#24037;&#31243;&#12289;&#35774;&#22791;&#31471;&#25512;&#29702;&#12289;&#23433;&#20840;&#31561;&#20851;&#38190;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2401.01923</link><description>&lt;p&gt;
&#22312;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#26102;&#20195;&#30340;&#29289;&#32852;&#32593;: &#35270;&#37326;&#19982;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;
IoT in the Era of Generative AI: Vision and Challenges. (arXiv:2401.01923v1 [cs.DC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01923
&lt;/p&gt;
&lt;p&gt;
&#22312;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#26102;&#20195;&#30340;&#29289;&#32852;&#32593;&#65292;Generative AI&#30340;&#36827;&#23637;&#24102;&#26469;&#20102;&#24040;&#22823;&#30340;&#24076;&#26395;&#65292;&#21516;&#26102;&#20063;&#38754;&#20020;&#30528;&#39640;&#36164;&#28304;&#38656;&#27714;&#12289;&#21450;&#26102;&#24037;&#31243;&#12289;&#35774;&#22791;&#31471;&#25512;&#29702;&#12289;&#23433;&#20840;&#31561;&#20851;&#38190;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24102;&#26377;&#24863;&#30693;&#12289;&#32593;&#32476;&#21644;&#35745;&#31639;&#33021;&#21147;&#30340;&#29289;&#32852;&#32593;&#35774;&#22791;&#65292;&#22914;&#26234;&#33021;&#25163;&#26426;&#12289;&#21487;&#31359;&#25140;&#35774;&#22791;&#12289;&#26234;&#33021;&#38899;&#31665;&#21644;&#23478;&#24237;&#26426;&#22120;&#20154;&#65292;&#24050;&#32463;&#26080;&#32541;&#22320;&#34701;&#20837;&#21040;&#25105;&#20204;&#30340;&#26085;&#24120;&#29983;&#27963;&#20013;&#12290;&#26368;&#36817;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#65288;Generative AI&#65289;&#30340;&#36827;&#23637;&#65292;&#22914;GPT&#12289;LLaMA&#12289;DALL-E&#21644;&#31283;&#23450;&#25193;&#25955;&#31561;&#65292;&#32473;&#29289;&#32852;&#32593;&#30340;&#21457;&#23637;&#24102;&#26469;&#20102;&#24040;&#22823;&#30340;&#24076;&#26395;&#12290;&#26412;&#25991;&#20998;&#20139;&#20102;&#25105;&#20204;&#23545;Generative AI&#22312;&#29289;&#32852;&#32593;&#20013;&#24102;&#26469;&#30340;&#22909;&#22788;&#30340;&#30475;&#27861;&#21644;&#24895;&#26223;&#65292;&#24182;&#35752;&#35770;&#20102;Generative AI&#22312;&#29289;&#32852;&#32593;&#30456;&#20851;&#39046;&#22495;&#30340;&#19968;&#20123;&#37325;&#35201;&#24212;&#29992;&#12290;&#20805;&#20998;&#21033;&#29992;Generative AI&#22312;&#29289;&#32852;&#32593;&#20013;&#26159;&#19968;&#20010;&#22797;&#26434;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#30830;&#23450;&#20102;&#19968;&#20123;&#26368;&#20851;&#38190;&#30340;&#25361;&#25112;&#65292;&#21253;&#25324;Generative AI&#27169;&#22411;&#30340;&#39640;&#36164;&#28304;&#38656;&#27714;&#12289;&#21450;&#26102;&#24037;&#31243;&#12289;&#35774;&#22791;&#31471;&#25512;&#29702;&#12289;&#21368;&#36733;&#12289;&#35774;&#22791;&#31471;&#24494;&#35843;&#12289;&#32852;&#37030;&#23398;&#20064;&#12289;&#23433;&#20840;&#20197;&#21450;&#24320;&#21457;&#24037;&#20855;&#21644;&#22522;&#20934;&#65292;&#24182;&#35752;&#35770;&#20102;&#24403;&#21069;&#23384;&#22312;&#30340;&#24046;&#36317;&#20197;&#21450;&#20351;Generative AI&#22312;&#29289;&#32852;&#32593;&#20013;&#23454;&#29616;&#30340;&#26377;&#24076;&#26395;&#30340;&#26426;&#20250;&#12290;&#25105;&#20204;&#24076;&#26395;&#36825;&#31687;&#25991;&#31456;&#33021;&#22815;&#28608;&#21457;&#26032;&#30340;&#30740;&#31350;&#21644;&#21019;&#26032;&#12290;
&lt;/p&gt;
&lt;p&gt;
Equipped with sensing, networking, and computing capabilities, Internet of Things (IoT) such as smartphones, wearables, smart speakers, and household robots have been seamlessly weaved into our daily lives. Recent advancements in Generative AI exemplified by GPT, LLaMA, DALL-E, and Stable Difussion hold immense promise to push IoT to the next level. In this article, we share our vision and views on the benefits that Generative AI brings to IoT, and discuss some of the most important applications of Generative AI in IoT-related domains. Fully harnessing Generative AI in IoT is a complex challenge. We identify some of the most critical challenges including high resource demands of the Generative AI models, prompt engineering, on-device inference, offloading, on-device fine-tuning, federated learning, security, as well as development tools and benchmarks, and discuss current gaps as well as promising opportunities on enabling Generative AI for IoT. We hope this article can inspire new res
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#24067;&#24335;&#22270;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#20013;&#20998;&#21306;&#31574;&#30053;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#25506;&#31350;&#20102;&#19981;&#21516;&#22240;&#32032;&#23545;&#20998;&#21306;&#25928;&#26524;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2308.15602</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#22270;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#30340;&#20998;&#21306;&#31574;&#30053;&#30340;&#23454;&#39564;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
An Experimental Comparison of Partitioning Strategies for Distributed Graph Neural Network Training. (arXiv:2308.15602v1 [cs.DC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15602
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#24067;&#24335;&#22270;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#20013;&#20998;&#21306;&#31574;&#30053;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#25506;&#31350;&#20102;&#19981;&#21516;&#22240;&#32032;&#23545;&#20998;&#21306;&#25928;&#26524;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#20316;&#20026;&#19968;&#31181;&#33021;&#22815;&#22312;&#22270;&#32467;&#26500;&#21270;&#25968;&#25454;&#19978;&#23398;&#20064;&#30340;&#28145;&#24230;&#23398;&#20064;&#39046;&#22495;&#65292;&#21463;&#21040;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#22823;&#35268;&#27169;&#22270;&#19978;&#30340;GNN&#35757;&#32451;&#65292;&#35745;&#31639;&#21644;&#20869;&#23384;&#35201;&#27714;&#21487;&#33021;&#36229;&#36807;&#21333;&#21488;&#26426;&#22120;&#25110;GPU&#30340;&#33021;&#21147;&#65292;&#22240;&#27492;&#20998;&#24067;&#24335;GNN&#35757;&#32451;&#25104;&#20026;&#22823;&#35268;&#27169;GNN&#35757;&#32451;&#30340;&#26377;&#21069;&#36884;&#30340;&#26041;&#21521;&#12290;&#20998;&#24067;&#24335;GNN&#35757;&#32451;&#30340;&#20808;&#20915;&#26465;&#20214;&#26159;&#23558;&#36755;&#20837;&#22270;&#20998;&#21106;&#25104;&#36739;&#23567;&#30340;&#37096;&#20998;&#65292;&#36825;&#20123;&#37096;&#20998;&#20998;&#24067;&#22312;&#35745;&#31639;&#38598;&#32676;&#30340;&#22810;&#21488;&#26426;&#22120;&#38388;&#12290;&#34429;&#28982;&#22270;&#20998;&#21306;&#22312;&#22270;&#20998;&#26512;&#21644;&#22270;&#25968;&#25454;&#24211;&#26041;&#38754;&#24050;&#32463;&#24471;&#21040;&#20102;&#24191;&#27867;&#30740;&#31350;&#65292;&#20294;&#20854;&#23545;GNN&#35757;&#32451;&#24615;&#33021;&#30340;&#24433;&#21709;&#23578;&#26410;&#24471;&#21040;&#28145;&#20837;&#25506;&#32034;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20998;&#21306;&#23545;&#20998;&#24067;&#24335;GNN&#35757;&#32451;&#30340;&#25928;&#26524;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#26088;&#22312;&#20102;&#35299;&#19981;&#21516;&#22240;&#32032;&#65288;&#22914;GNN&#21442;&#25968;&#12289;&#23567;&#25209;&#37327;&#22823;&#23567;&#12289;&#22270;&#31867;&#22411;&#12289;&#29305;&#24449;&#22823;&#23567;&#21644;&#25193;&#23637;&#22240;&#23376;&#65289;&#23545;&#20998;&#21306;&#25928;&#26524;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, graph neural networks (GNNs) have gained much attention as a growing area of deep learning capable of learning on graph-structured data. However, the computational and memory requirements for training GNNs on large-scale graphs can exceed the capabilities of single machines or GPUs, making distributed GNN training a promising direction for large-scale GNN training. A prerequisite for distributed GNN training is to partition the input graph into smaller parts that are distributed among multiple machines of a compute cluster. Although graph partitioning has been extensively studied with regard to graph analytics and graph databases, its effect on GNN training performance is largely unexplored.  In this paper, we study the effectiveness of graph partitioning for distributed GNN training. Our study aims to understand how different factors such as GNN parameters, mini-batch size, graph type, features size, and scale-out factor influence the effectiveness of graph partitioning. We 
&lt;/p&gt;</description></item><item><title>SE-MoE&#25552;&#20986;&#20102;&#19968;&#31181;&#24377;&#24615;&#30340;&#35757;&#32451;&#26041;&#24335;&#21644;&#19981;&#21516;&#20248;&#21270;&#25514;&#26045;&#65292;&#20197;&#25552;&#39640;&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#30340;&#20998;&#24067;&#24335;&#35757;&#32451;&#21644;&#25512;&#29702;&#25928;&#29575;&#65292;&#35299;&#20915;&#20102;&#36127;&#36733;&#24179;&#34913;&#12289;&#36890;&#20449;/&#35745;&#31639;&#25928;&#29575;&#21644;&#20869;&#23384;&#38480;&#21046;&#31561;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2205.10034</link><description>&lt;p&gt;
SE-MoE: &#19968;&#31181;&#21487;&#25193;&#23637;&#39640;&#25928;&#30340;&#20998;&#24067;&#24335;&#35757;&#32451;&#21644;&#25512;&#29702;&#28151;&#21512;&#19987;&#23478;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
SE-MoE: A Scalable and Efficient Mixture-of-Experts Distributed Training and Inference System. (arXiv:2205.10034v2 [cs.DC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.10034
&lt;/p&gt;
&lt;p&gt;
SE-MoE&#25552;&#20986;&#20102;&#19968;&#31181;&#24377;&#24615;&#30340;&#35757;&#32451;&#26041;&#24335;&#21644;&#19981;&#21516;&#20248;&#21270;&#25514;&#26045;&#65292;&#20197;&#25552;&#39640;&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#30340;&#20998;&#24067;&#24335;&#35757;&#32451;&#21644;&#25512;&#29702;&#25928;&#29575;&#65292;&#35299;&#20915;&#20102;&#36127;&#36733;&#24179;&#34913;&#12289;&#36890;&#20449;/&#35745;&#31639;&#25928;&#29575;&#21644;&#20869;&#23384;&#38480;&#21046;&#31561;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#26426;&#22120;&#23398;&#20064;&#26550;&#26500;&#30340;&#22810;&#26679;&#24615;&#22686;&#21152;&#65292;&#23558;&#27169;&#22411;&#20998;&#24067;&#24335;&#35757;&#32451;&#22312;&#24322;&#26500;&#35745;&#31639;&#31995;&#32479;&#19978;&#20197;&#26041;&#20415;&#29983;&#25104;&#22823;&#27169;&#22411;&#25104;&#20026;&#20102;&#19968;&#31181;&#36235;&#21183;&#12290;&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#21033;&#29992;&#20998;&#27835;&#31574;&#30053;&#36890;&#36807;&#38376;&#25511;&#21644;&#24182;&#34892;&#22788;&#29702;&#26041;&#24335;&#26469;&#38477;&#20302;&#35757;&#32451;&#25104;&#26412;&#24182;&#25511;&#21046;&#24635;&#20307;&#27169;&#22411;/&#25968;&#25454;&#22823;&#23567;&#12290;&#34429;&#28982; DeepSpeed &#22312;&#36827;&#34892;&#22823;&#35268;&#27169; MoE &#35757;&#32451;&#19978;&#36827;&#34892;&#20102;&#23581;&#35797;&#65292;&#20294;&#35757;&#32451;&#21644;&#25512;&#29702;&#30340;&#25928;&#29575;&#20173;&#26377;&#25552;&#21319;&#30340;&#31354;&#38388;&#65292;&#21253;&#25324;&#36127;&#36733;&#24179;&#34913;&#12289;&#36890;&#20449;/&#35745;&#31639;&#25928;&#29575;&#21644;&#20869;&#23384;&#38480;&#21046;&#31561;&#26041;&#38754;&#12290;&#26412;&#24037;&#20316;&#25552;&#20986;&#20102; SE-MoE&#65292;&#20351;&#29992;&#24377;&#24615; MoE &#35757;&#32451;&#12289;&#22522;&#20110;&#23618;&#27425;&#23384;&#20648;&#30340; 2D &#39044;&#21462;&#21644;&#34701;&#21512;&#36890;&#20449;&#31561;&#26041;&#27861;&#65292;&#20197;&#20415;&#22312;&#19981;&#21516;&#30340;&#31867;&#22411;&#20013;&#33719;&#24471;&#39640;&#25928;&#30340;&#24182;&#34892;&#22788;&#29702;&#12290;&#38024;&#23545;&#21333;&#33410;&#28857;&#30340;&#21487;&#25193;&#23637;&#25512;&#29702;&#65292;&#29305;&#21035;&#26159;&#24403;&#27169;&#22411;&#22823;&#23567;&#22823;&#20110; GPU &#20869;&#23384;&#26102;&#65292;SE-MoE &#23558; CPU-GPU &#23384;&#20648;&#32852;&#21512;&#24418;&#25104;&#19968;&#20010;&#26356;&#22823;&#30340;&#23384;&#20648;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the increasing diversity of ML infrastructures nowadays, distributed training over heterogeneous computing systems is desired to facilitate the production of big models. Mixture-of-Experts (MoE) models have been proposed to lower the cost of training subject to the overall size of models/data through gating and parallelism in a divide-and-conquer fashion. While DeepSpeed has made efforts in carrying out large-scale MoE training over heterogeneous infrastructures, the efficiency of training and inference could be further improved from several system aspects, including load balancing, communication/computation efficiency, and memory footprint limits. In this work, we present SE-MoE that proposes Elastic MoE training with 2D prefetch and Fusion communication over Hierarchical storage, so as to enjoy efficient parallelisms in various types. For scalable inference in a single node, especially when the model size is larger than GPU memory, SE-MoE forms the CPU-GPU memory jointly into a 
&lt;/p&gt;</description></item></channel></rss>