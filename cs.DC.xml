<rss version="2.0"><channel><title>Chat Arxiv cs.DC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.DC</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#21487;&#36866;&#24212;&#24615;CNC&#65288;ACNC&#65289;&#30340;&#27010;&#24565;&#65292;&#20316;&#20026;&#19968;&#31181;&#33258;&#20027;&#30340;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#36741;&#21161;&#26426;&#21046;&#65292;&#26088;&#22312;&#32852;&#21512;&#32534;&#25490;&#35745;&#31639;&#21644;&#32593;&#32476;&#36164;&#28304;&#65292;&#28385;&#36275;&#23545;&#21160;&#24577;&#21644;&#22823;&#37327;&#29992;&#25143;&#35831;&#27714;&#30340;&#20005;&#26684;&#35201;&#27714;&#12290;</title><link>https://arxiv.org/abs/2403.07573</link><description>&lt;p&gt;
&#36808;&#21521;&#20855;&#26377;&#21487;&#36866;&#24212;&#24615;&#35745;&#31639;&#21644;&#32593;&#32476;&#34701;&#21512;&#30340;&#21160;&#24577;&#26410;&#26469;&#65288;ACNC&#65289;
&lt;/p&gt;
&lt;p&gt;
Towards a Dynamic Future with Adaptable Computing and Network Convergence (ACNC)
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07573
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#21487;&#36866;&#24212;&#24615;CNC&#65288;ACNC&#65289;&#30340;&#27010;&#24565;&#65292;&#20316;&#20026;&#19968;&#31181;&#33258;&#20027;&#30340;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#36741;&#21161;&#26426;&#21046;&#65292;&#26088;&#22312;&#32852;&#21512;&#32534;&#25490;&#35745;&#31639;&#21644;&#32593;&#32476;&#36164;&#28304;&#65292;&#28385;&#36275;&#23545;&#21160;&#24577;&#21644;&#22823;&#37327;&#29992;&#25143;&#35831;&#27714;&#30340;&#20005;&#26684;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25512;&#36827;6G&#30340;&#32972;&#26223;&#19979;&#65292;&#39044;&#35745;&#20250;&#20986;&#29616;&#23454;&#36136;&#24615;&#30340;&#33539;&#24335;&#36716;&#21464;&#65292;&#31361;&#20986;&#20102;&#30001;&#22823;&#37327;&#36830;&#25509;&#21644;&#20005;&#26684;&#36981;&#23432;&#26381;&#21153;&#36136;&#37327;/&#20307;&#39564;&#65288;QoS/E&#65289;&#20808;&#20915;&#26465;&#20214;&#25152;&#29305;&#24449;&#21270;&#30340;&#20840;&#38754;&#30340;&#19968;&#20999;&#23545;&#19968;&#20999;&#20132;&#20114;&#12290;&#21363;&#23558;&#38754;&#20020;&#30340;&#25361;&#25112;&#28304;&#20110;&#36164;&#28304;&#31232;&#32570;&#65292;&#20419;&#20351;&#26377;&#24847;&#35782;&#22320;&#21521;&#35745;&#31639;-&#32593;&#32476;&#34701;&#21512;&#65288;CNC&#65289;&#36807;&#28193;&#65292;&#20316;&#20026;&#32852;&#21512;&#36164;&#28304;&#32534;&#25490;&#30340;&#26377;&#21069;&#36884;&#30340;&#26041;&#27861;&#12290;&#34429;&#28982;&#22522;&#20110;CNC&#30340;&#26426;&#21046;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20851;&#27880;&#65292;&#20294;&#23427;&#20204;&#22312;&#23454;&#29616;&#26410;&#26469;&#26381;&#21153;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#65292;&#29305;&#21035;&#26159;&#22312;&#31867;&#20284;Metaverse&#30340;&#20351;&#29992;&#24773;&#26223;&#20013;&#65292;&#21487;&#33021;&#20250;&#30001;&#20110;&#29992;&#25143;&#12289;&#26381;&#21153;&#21644;&#36164;&#28304;&#19981;&#26029;&#21464;&#21270;&#30340;&#29305;&#24615;&#32780;&#21463;&#21040;&#38480;&#21046;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#21487;&#36866;&#24212;&#24615;CNC&#65288;ACNC&#65289;&#30340;&#27010;&#24565;&#65292;&#20316;&#20026;&#19968;&#31181;&#33258;&#20027;&#30340;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#36741;&#21161;&#26426;&#21046;&#65292;&#26088;&#22312;&#32852;&#21512;&#32534;&#25490;&#35745;&#31639;&#21644;&#32593;&#32476;&#36164;&#28304;&#65292;&#28385;&#36275;&#23545;&#21160;&#24577;&#21644;&#22823;&#37327;&#29992;&#25143;&#35831;&#27714;&#30340;&#20005;&#26684;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07573v1 Announce Type: cross  Abstract: In the context of advancing 6G, a substantial paradigm shift is anticipated, highlighting comprehensive everything-to-everything interactions characterized by numerous connections and stringent adherence to Quality of Service/Experience (QoS/E) prerequisites. The imminent challenge stems from resource scarcity, prompting a deliberate transition to Computing-Network Convergence (CNC) as an auspicious approach for joint resource orchestration. While CNC-based mechanisms have garnered attention, their effectiveness in realizing future services, particularly in use cases like the Metaverse, may encounter limitations due to the continually changing nature of users, services, and resources. Hence, this paper presents the concept of Adaptable CNC (ACNC) as an autonomous Machine Learning (ML)-aided mechanism crafted for the joint orchestration of computing and network resources, catering to dynamic and voluminous user requests with stringent r
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;Zen&#65292;&#19968;&#31181;&#29992;&#20110;&#20998;&#24067;&#24335;DNN&#35757;&#32451;&#20013;&#36817;&#20284;&#26368;&#20248;&#31232;&#30095;&#24352;&#37327;&#21516;&#27493;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#20998;&#26512;&#27969;&#34892;&#30340;DNN&#27169;&#22411;&#20013;&#31232;&#30095;&#24352;&#37327;&#30340;&#29305;&#24615;&#65292;&#24182;&#31995;&#32479;&#22320;&#25506;&#32034;&#35774;&#35745;&#31354;&#38388;&#65292;&#25214;&#21040;&#20102;&#26368;&#20339;&#30340;&#36890;&#20449;&#26041;&#26696;&#12290;&#36890;&#36807;&#20943;&#23569;&#36890;&#20449;&#27969;&#37327;&#21644;&#25552;&#39640;&#35757;&#32451;&#25928;&#29575;&#65292;Zen&#26377;&#25928;&#22320;&#25552;&#21319;&#20102;&#20998;&#24067;&#24335;&#35757;&#32451;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.13254</link><description>&lt;p&gt;
Zen&#65306;&#29992;&#20110;&#20998;&#24067;&#24335;DNN&#35757;&#32451;&#30340;&#36817;&#20284;&#26368;&#20248;&#31232;&#30095;&#24352;&#37327;&#21516;&#27493;
&lt;/p&gt;
&lt;p&gt;
Zen: Near-Optimal Sparse Tensor Synchronization for Distributed DNN Training. (arXiv:2309.13254v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13254
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;Zen&#65292;&#19968;&#31181;&#29992;&#20110;&#20998;&#24067;&#24335;DNN&#35757;&#32451;&#20013;&#36817;&#20284;&#26368;&#20248;&#31232;&#30095;&#24352;&#37327;&#21516;&#27493;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#20998;&#26512;&#27969;&#34892;&#30340;DNN&#27169;&#22411;&#20013;&#31232;&#30095;&#24352;&#37327;&#30340;&#29305;&#24615;&#65292;&#24182;&#31995;&#32479;&#22320;&#25506;&#32034;&#35774;&#35745;&#31354;&#38388;&#65292;&#25214;&#21040;&#20102;&#26368;&#20339;&#30340;&#36890;&#20449;&#26041;&#26696;&#12290;&#36890;&#36807;&#20943;&#23569;&#36890;&#20449;&#27969;&#37327;&#21644;&#25552;&#39640;&#35757;&#32451;&#25928;&#29575;&#65292;Zen&#26377;&#25928;&#22320;&#25552;&#21319;&#20102;&#20998;&#24067;&#24335;&#35757;&#32451;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#24335;&#35757;&#32451;&#26159;&#20351;&#29992;&#22810;&#20010;GPU&#25193;&#23637;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNN)&#35757;&#32451;&#30340;&#20107;&#23454;&#26631;&#20934;&#12290;&#20998;&#24067;&#24335;&#35757;&#32451;&#30340;&#24615;&#33021;&#29942;&#39048;&#22312;&#20110;&#28176;&#21464;&#21516;&#27493;&#30340;&#36890;&#20449;&#12290;&#26368;&#36817;&#65292;&#23454;&#36341;&#32773;&#35266;&#23519;&#21040;&#28176;&#21464;&#24352;&#37327;&#20013;&#23384;&#22312;&#31232;&#30095;&#24615;&#65292;&#34920;&#26126;&#21487;&#20197;&#20943;&#23569;&#36890;&#20449;&#30340;&#27969;&#37327;&#24182;&#25552;&#39640;&#31471;&#21040;&#31471;&#30340;&#35757;&#32451;&#25928;&#29575;&#12290;&#28982;&#32780;&#65292;&#23436;&#20840;&#21457;&#25381;&#31232;&#30095;&#24615;&#30340;&#26368;&#20339;&#36890;&#20449;&#26041;&#26696;&#20173;&#28982;&#32570;&#22833;&#12290;&#26412;&#25991;&#26088;&#22312;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#20998;&#26512;&#20102;&#27969;&#34892;DNN&#27169;&#22411;&#20013;&#31232;&#30095;&#24352;&#37327;&#30340;&#29305;&#24615;&#65292;&#20197;&#20102;&#35299;&#31232;&#30095;&#24615;&#30340;&#22522;&#26412;&#21407;&#29702;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#31995;&#32479;&#22320;&#25506;&#32034;&#20102;&#31232;&#30095;&#24352;&#37327;&#36890;&#20449;&#26041;&#26696;&#30340;&#35774;&#35745;&#31354;&#38388;&#24182;&#25214;&#21040;&#20102;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Distributed training is the de facto standard to scale up the training of Deep Neural Networks (DNNs) with multiple GPUs. The performance bottleneck of distributed training lies in communications for gradient synchronization. Recently, practitioners have observed sparsity in gradient tensors, suggesting the potential to reduce the traffic volume in communication and improve end-to-end training efficiency. Yet, the optimal communication scheme to fully leverage sparsity is still missing. This paper aims to address this gap. We first analyze the characteristics of sparse tensors in popular DNN models to understand the fundamentals of sparsity. We then systematically explore the design space of communication schemes for sparse tensors and find the optimal one. % We then find the optimal scheme based on the characteristics by systematically exploring the design space. We also develop a gradient synchronization system called Zen that approximately realizes it for sparse tensors. We demonstr
&lt;/p&gt;</description></item></channel></rss>