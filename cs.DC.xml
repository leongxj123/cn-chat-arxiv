<rss version="2.0"><channel><title>Chat Arxiv cs.DC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.DC</description><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;Synergy&#65292;&#19968;&#20010;&#36890;&#36807;&#21160;&#24577;&#32452;&#21512;&#24494;&#22411;AI&#21152;&#36895;&#22120;&#26469;&#36827;&#34892;&#21327;&#20316;&#25512;&#26029;&#30340;&#31995;&#32479;&#65292;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#22312;&#35774;&#22791;&#19978;AI&#38656;&#27714;&#19981;&#26029;&#22686;&#38271;&#26102;tinyML&#38754;&#20020;&#30340;&#20851;&#38190;&#25361;&#25112;&#12290;Synergy&#36890;&#36807;&#25552;&#20379;&#34394;&#25311;&#35745;&#31639;&#31354;&#38388;&#21644;&#36816;&#34892;&#26102;&#32534;&#25490;&#27169;&#22359;&#65292;&#23454;&#29616;&#20102;&#36164;&#28304;&#30340;&#32479;&#19968;&#34394;&#25311;&#21270;&#35270;&#22270;&#21644;&#36328;&#21160;&#24577;/&#24322;&#26500;&#21152;&#36895;&#22120;&#30340;&#26368;&#20339;&#25512;&#26029;&#65292;&#20854;&#21534;&#21520;&#37327;&#24179;&#22343;&#25552;&#21319;&#20102;8.0&#20493;&#12290;</title><link>http://arxiv.org/abs/2401.08637</link><description>&lt;p&gt;
&#36890;&#36807;MCU&#19978;&#24494;&#22411;AI&#21152;&#36895;&#22120;&#30340;&#21160;&#24577;&#32452;&#21512;&#23454;&#29616;&#21327;&#20316;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Collaborative Inference via Dynamic Composition of Tiny AI Accelerators on MCUs. (arXiv:2401.08637v1 [cs.DC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.08637
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;Synergy&#65292;&#19968;&#20010;&#36890;&#36807;&#21160;&#24577;&#32452;&#21512;&#24494;&#22411;AI&#21152;&#36895;&#22120;&#26469;&#36827;&#34892;&#21327;&#20316;&#25512;&#26029;&#30340;&#31995;&#32479;&#65292;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#22312;&#35774;&#22791;&#19978;AI&#38656;&#27714;&#19981;&#26029;&#22686;&#38271;&#26102;tinyML&#38754;&#20020;&#30340;&#20851;&#38190;&#25361;&#25112;&#12290;Synergy&#36890;&#36807;&#25552;&#20379;&#34394;&#25311;&#35745;&#31639;&#31354;&#38388;&#21644;&#36816;&#34892;&#26102;&#32534;&#25490;&#27169;&#22359;&#65292;&#23454;&#29616;&#20102;&#36164;&#28304;&#30340;&#32479;&#19968;&#34394;&#25311;&#21270;&#35270;&#22270;&#21644;&#36328;&#21160;&#24577;/&#24322;&#26500;&#21152;&#36895;&#22120;&#30340;&#26368;&#20339;&#25512;&#26029;&#65292;&#20854;&#21534;&#21520;&#37327;&#24179;&#22343;&#25552;&#21319;&#20102;8.0&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24494;&#22411;AI&#21152;&#36895;&#22120;&#30340;&#20986;&#29616;&#20026;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#26497;&#38480;&#36793;&#32536;&#19978;&#30340;&#37096;&#32626;&#25552;&#20379;&#20102;&#26426;&#20250;&#65292;&#25552;&#20379;&#20102;&#36739;&#20302;&#30340;&#24310;&#36831;&#12289;&#36739;&#20302;&#30340;&#21151;&#32791;&#25104;&#26412;&#21644;&#25913;&#36827;&#30340;&#38544;&#31169;&#20445;&#25252;&#12290;&#23613;&#31649;&#21462;&#24471;&#20102;&#36825;&#20123;&#36827;&#23637;&#65292;&#20294;&#30001;&#20110;&#36825;&#20123;&#21152;&#36895;&#22120;&#30340;&#22266;&#26377;&#38480;&#21046;&#65292;&#22914;&#26377;&#38480;&#30340;&#20869;&#23384;&#21644;&#21333;&#35774;&#22791;&#28966;&#28857;&#65292;&#20173;&#23384;&#22312;&#25361;&#25112;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;Synergy&#65292;&#19968;&#20010;&#33021;&#22815;&#20026;&#22810;&#31199;&#25143;&#27169;&#22411;&#21160;&#24577;&#32452;&#21512;&#24494;&#22411;AI&#21152;&#36895;&#22120;&#30340;&#31995;&#32479;&#65292;&#26377;&#25928;&#35299;&#20915;&#20102;&#23545;&#20110;&#35774;&#22791;&#19978;AI&#30340;&#38656;&#27714;&#19981;&#26029;&#22686;&#38271;&#26102;tinyML&#38754;&#20020;&#30340;&#20851;&#38190;&#25361;&#25112;&#12290;Synergy&#30340;&#19968;&#20010;&#20851;&#38190;&#29305;&#24615;&#26159;&#20854;&#25552;&#20379;&#20102;&#34394;&#25311;&#35745;&#31639;&#31354;&#38388;&#65292;&#20026;&#36164;&#28304;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#34394;&#25311;&#21270;&#35270;&#22270;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#23545;&#29289;&#29702;&#35774;&#22791;&#30340;&#39640;&#25928;&#20219;&#21153;&#26144;&#23556;&#12290;Synergy&#30340;&#36816;&#34892;&#26102;&#32534;&#25490;&#27169;&#22359;&#30830;&#20445;&#20102;&#36328;&#21160;&#24577;&#21644;&#24322;&#26500;&#21152;&#36895;&#22120;&#30340;&#26368;&#20339;&#25512;&#26029;&#12290;&#25105;&#20204;&#30340;&#35780;&#20272;&#32467;&#26524;&#26174;&#31034;&#65292;&#19982;&#22522;&#20934;&#30456;&#27604;&#65292;Synergy&#30340;&#21534;&#21520;&#37327;&#24179;&#22343;&#25552;&#21319;&#20102;8.0&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;
The advent of tiny AI accelerators opens opportunities for deep neural network deployment at the extreme edge, offering reduced latency, lower power cost, and improved privacy in on-device ML inference. Despite these advancements, challenges persist due to inherent limitations of these accelerators, such as restricted onboard memory and single-device focus. This paper introduces Synergy, a system that dynamically composes tiny AI accelerators for multi-tenant models, effectively addressing tinyML's critical challenges for the increasing demand for on-device AI. A key feature of Synergy is its virtual computing space, providing a unified, virtualized view of resources and enabling efficient task mapping to physical devices. Synergy's runtime orchestration module ensures optimal inference across dynamic and heterogeneous accelerators. Our evaluations with 7 baselines and 8 models demonstrate that Synergy improves throughput by an average of 8.0X compared to baselines.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#19968;&#20010;&#26032;&#30340;&#21512;&#20316;&#22810;&#26234;&#33021;&#20307;&#32769;&#34382;&#26426;&#35774;&#32622;&#65292;&#24182;&#21457;&#23637;&#20102;&#21435;&#20013;&#24515;&#21270;&#31639;&#27861;&#20197;&#20943;&#23569;&#20195;&#29702;&#20043;&#38388;&#30340;&#38598;&#20307;&#36951;&#25022;&#65292;&#22312;&#25968;&#23398;&#20998;&#26512;&#20013;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#23454;&#29616;&#20102;&#36817;&#20046;&#26368;&#20248;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.18784</link><description>&lt;p&gt;
&#21512;&#20316;&#22810;&#26234;&#33021;&#20307;&#24322;&#26500;&#22810;&#33218;&#32769;&#34382;&#26426;&#32763;&#35793;&#35770;&#25991;
&lt;/p&gt;
&lt;p&gt;
Collaborative Multi-Agent Heterogeneous Multi-Armed Bandits. (arXiv:2305.18784v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18784
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#19968;&#20010;&#26032;&#30340;&#21512;&#20316;&#22810;&#26234;&#33021;&#20307;&#32769;&#34382;&#26426;&#35774;&#32622;&#65292;&#24182;&#21457;&#23637;&#20102;&#21435;&#20013;&#24515;&#21270;&#31639;&#27861;&#20197;&#20943;&#23569;&#20195;&#29702;&#20043;&#38388;&#30340;&#38598;&#20307;&#36951;&#25022;&#65292;&#22312;&#25968;&#23398;&#20998;&#26512;&#20013;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#23454;&#29616;&#20102;&#36817;&#20046;&#26368;&#20248;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#21512;&#20316;&#22810;&#26234;&#33021;&#20307;&#32769;&#34382;&#26426;&#30340;&#30740;&#31350;&#21560;&#24341;&#20102;&#24456;&#22810;&#20851;&#27880;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24320;&#22987;&#30740;&#31350;&#19968;&#20010;&#26032;&#30340;&#21512;&#20316;&#35774;&#32622;&#65292;&#20854;&#20013;$N$&#20010;&#26234;&#33021;&#20307;&#20013;&#30340;&#27599;&#20010;&#26234;&#33021;&#20307;&#27491;&#22312;&#23398;&#20064;$M$&#20010;&#20855;&#26377;&#38543;&#26426;&#24615;&#30340;&#22810;&#33218;&#32769;&#34382;&#26426;&#65292;&#20197;&#20943;&#23569;&#20182;&#20204;&#30340;&#38598;&#20307;&#32047;&#35745;&#36951;&#25022;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#21435;&#20013;&#24515;&#21270;&#31639;&#27861;&#65292;&#20419;&#36827;&#20102;&#20195;&#29702;&#20043;&#38388;&#30340;&#21512;&#20316;&#65292;&#24182;&#38024;&#23545;&#20004;&#31181;&#24773;&#20917;&#36827;&#34892;&#20102;&#24615;&#33021;&#34920;&#24449;&#12290;&#36890;&#36807;&#25512;&#23548;&#27599;&#20010;&#20195;&#29702;&#30340;&#32047;&#31215;&#36951;&#25022;&#21644;&#38598;&#20307;&#36951;&#25022;&#30340;&#19978;&#38480;&#65292;&#25105;&#20204;&#23545;&#36825;&#20123;&#31639;&#27861;&#30340;&#24615;&#33021;&#36827;&#34892;&#20102;&#34920;&#24449;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#36825;&#31181;&#24773;&#20917;&#19979;&#38598;&#20307;&#36951;&#25022;&#30340;&#19979;&#38480;&#65292;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#31639;&#27861;&#30340;&#36817;&#20046;&#26368;&#20248;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The study of collaborative multi-agent bandits has attracted significant attention recently. In light of this, we initiate the study of a new collaborative setting, consisting of $N$ agents such that each agent is learning one of $M$ stochastic multi-armed bandits to minimize their group cumulative regret. We develop decentralized algorithms which facilitate collaboration between the agents under two scenarios. We characterize the performance of these algorithms by deriving the per agent cumulative regret and group regret upper bounds. We also prove lower bounds for the group regret in this setting, which demonstrates the near-optimal behavior of the proposed algorithms.
&lt;/p&gt;</description></item></channel></rss>