<rss version="2.0"><channel><title>Chat Arxiv cs.DC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.DC</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22312;&#20998;&#24067;&#24335;&#23384;&#20648;&#22810;&#22788;&#29702;&#22120;&#19978;&#26368;&#22823;&#21270;&#23376;&#27169;&#20989;&#25968;&#30340;&#24182;&#34892;&#36817;&#20284;&#31639;&#27861;&#65292;&#20197;&#35299;&#20915;&#23454;&#38469;&#24212;&#29992;&#39046;&#22495;&#20013;&#28023;&#37327;&#25968;&#25454;&#38598;&#19978;&#30340;&#23376;&#27169;&#20248;&#21270;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.10332</link><description>&lt;p&gt;
GreedyML&#65306;&#19968;&#31181;&#29992;&#20110;&#26368;&#22823;&#21270;&#23376;&#27169;&#20989;&#25968;&#30340;&#24182;&#34892;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
GreedyML: A Parallel Algorithm for Maximizing Submodular Functions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10332
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22312;&#20998;&#24067;&#24335;&#23384;&#20648;&#22810;&#22788;&#29702;&#22120;&#19978;&#26368;&#22823;&#21270;&#23376;&#27169;&#20989;&#25968;&#30340;&#24182;&#34892;&#36817;&#20284;&#31639;&#27861;&#65292;&#20197;&#35299;&#20915;&#23454;&#38469;&#24212;&#29992;&#39046;&#22495;&#20013;&#28023;&#37327;&#25968;&#25454;&#38598;&#19978;&#30340;&#23376;&#27169;&#20248;&#21270;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#31181;&#29992;&#20110;&#22312;&#20998;&#24067;&#24335;&#23384;&#20648;&#22810;&#22788;&#29702;&#22120;&#19978;&#26368;&#22823;&#21270;&#21333;&#35843;&#23376;&#27169;&#20989;&#25968;&#30340;&#24182;&#34892;&#36817;&#20284;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#21463;&#21040;&#22312;&#28023;&#37327;&#25968;&#25454;&#38598;&#19978;&#35299;&#20915;&#23376;&#27169;&#20248;&#21270;&#38382;&#39064;&#30340;&#38656;&#27714;&#30340;&#21551;&#21457;&#65292;&#29992;&#20110;&#23454;&#38469;&#24212;&#29992;&#39046;&#22495;&#65292;&#22914;&#25968;&#25454;&#25688;&#35201;&#65292;&#26426;&#22120;&#23398;&#20064;&#21644;&#22270;&#31232;&#30095;&#21270;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#22522;&#20110;Barbosa&#12289;Ene&#12289;Nguyen&#21644;Ward&#65288;2015&#65289;&#25552;&#20986;&#30340;&#38543;&#26426;&#20998;&#24067;&#24335;RandGreedI&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#23558;&#25968;&#25454;&#38543;&#26426;&#20998;&#21306;&#21040;&#25152;&#26377;&#22788;&#29702;&#22120;&#20013;&#65292;&#28982;&#21518;&#20351;&#29992;&#21333;&#20010;&#32047;&#31215;&#27493;&#39588;&#35745;&#31639;&#20998;&#24067;&#24335;&#35299;&#20915;&#26041;&#26696;&#65292;&#20854;&#20013;&#25152;&#26377;&#22788;&#29702;&#22120;&#23558;&#23427;&#20204;&#30340;&#37096;&#20998;&#35299;&#20915;&#26041;&#26696;&#21457;&#36865;&#32473;&#19968;&#20010;&#22788;&#29702;&#22120;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#22823;&#38382;&#39064;&#65292;&#32047;&#31215;&#27493;&#39588;&#21487;&#33021;&#36229;&#36807;&#22788;&#29702;&#22120;&#19978;&#21487;&#29992;&#30340;&#20869;&#23384;&#65292;&#24182;&#19988;&#25191;&#34892;&#32047;&#31215;&#30340;&#22788;&#29702;&#22120;&#21487;&#33021;&#25104;&#20026;&#35745;&#31639;&#29942;&#39048;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10332v1 Announce Type: cross  Abstract: We describe a parallel approximation algorithm for maximizing monotone submodular functions subject to hereditary constraints on distributed memory multiprocessors. Our work is motivated by the need to solve submodular optimization problems on massive data sets, for practical applications in areas such as data summarization, machine learning, and graph sparsification. Our work builds on the randomized distributed RandGreedI algorithm, proposed by Barbosa, Ene, Nguyen, and Ward (2015). This algorithm computes a distributed solution by randomly partitioning the data among all the processors and then employing a single accumulation step in which all processors send their partial solutions to one processor. However, for large problems, the accumulation step could exceed the memory available on a processor, and the processor which performs the accumulation could become a computational bottleneck.   Here, we propose a generalization of the R
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;Solution Simplex Clustered Federated Learning&#65288;SosicFL&#65289;&#65292;&#36890;&#36807;&#23398;&#20064;&#35299;&#20915;&#26041;&#26696;&#21333;&#32431;&#24418;&#30340;&#24605;&#24819;&#65292;&#20026;&#27599;&#20010;&#23458;&#25143;&#31471;&#20998;&#37197;&#21333;&#19968;&#21306;&#22495;&#65292;&#20174;&#32780;&#21516;&#26102;&#23454;&#29616;&#20102;&#23398;&#20064;&#26412;&#22320;&#21644;&#20840;&#23616;&#27169;&#22411;&#30340;&#30446;&#26631;&#12290;</title><link>https://arxiv.org/abs/2403.03333</link><description>&lt;p&gt;
Solution Simplex Clustering for Heterogeneous Federated Learning
&lt;/p&gt;
&lt;p&gt;
Solution Simplex Clustering for Heterogeneous Federated Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03333
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;Solution Simplex Clustered Federated Learning&#65288;SosicFL&#65289;&#65292;&#36890;&#36807;&#23398;&#20064;&#35299;&#20915;&#26041;&#26696;&#21333;&#32431;&#24418;&#30340;&#24605;&#24819;&#65292;&#20026;&#27599;&#20010;&#23458;&#25143;&#31471;&#20998;&#37197;&#21333;&#19968;&#21306;&#22495;&#65292;&#20174;&#32780;&#21516;&#26102;&#23454;&#29616;&#20102;&#23398;&#20064;&#26412;&#22320;&#21644;&#20840;&#23616;&#27169;&#22411;&#30340;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#38024;&#23545;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#20013;&#30340;&#19968;&#20010;&#20027;&#35201;&#25361;&#25112;&#25552;&#20986;&#20102;&#35299;&#20915;&#26041;&#26696;&#65292;&#21363;&#22312;&#39640;&#24230;&#24322;&#26500;&#30340;&#23458;&#25143;&#20998;&#24067;&#19979;&#23454;&#29616;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;&#36825;&#31181;&#22256;&#38590;&#37096;&#20998;&#28304;&#20110;&#20004;&#20010;&#30475;&#20284;&#30683;&#30462;&#30340;&#30446;&#26631;&#65306;&#36890;&#36807;&#32858;&#21512;&#26469;&#33258;&#23458;&#25143;&#31471;&#30340;&#20449;&#24687;&#26469;&#23398;&#20064;&#19968;&#20010;&#36890;&#29992;&#27169;&#22411;&#65292;&#20197;&#21450;&#23398;&#20064;&#24212;&#36866;&#24212;&#27599;&#20010;&#26412;&#22320;&#20998;&#24067;&#30340;&#26412;&#22320;&#20010;&#24615;&#21270;&#27169;&#22411;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Solution Simplex Clustered Federated Learning&#65288;SosicFL&#65289;&#26469;&#28040;&#38500;&#36825;&#31181;&#30683;&#30462;&#12290;&#22522;&#20110;&#23398;&#20064;&#35299;&#20915;&#26041;&#26696;&#21333;&#32431;&#24418;&#30340;&#26368;&#26032;&#24605;&#24819;&#65292;SosicFL&#20026;&#27599;&#20010;&#23458;&#25143;&#31471;&#20998;&#37197;&#19968;&#20010;&#21333;&#32431;&#24418;&#20013;&#30340;&#23376;&#21306;&#22495;&#65292;&#24182;&#25191;&#34892;FL&#26469;&#23398;&#20064;&#19968;&#20010;&#36890;&#29992;&#35299;&#20915;&#26041;&#26696;&#21333;&#32431;&#24418;&#12290;&#36825;&#20351;&#24471;&#23458;&#25143;&#31471;&#27169;&#22411;&#22312;&#35299;&#20915;&#26041;&#26696;&#21333;&#32431;&#24418;&#30340;&#33258;&#30001;&#24230;&#33539;&#22260;&#20869;&#20855;&#26377;&#20854;&#29305;&#24449;&#65292;&#21516;&#26102;&#23454;&#29616;&#20102;&#23398;&#20064;&#19968;&#20010;&#20840;&#23616;&#36890;&#29992;&#27169;&#22411;&#30340;&#30446;&#26631;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;SosicFL&#25913;&#21892;&#20102;&#24615;&#33021;&#65292;&#24182;&#21152;&#36895;&#20102;&#20840;&#23616;&#21644;&#35757;&#32451;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03333v1 Announce Type: new  Abstract: We tackle a major challenge in federated learning (FL) -- achieving good performance under highly heterogeneous client distributions. The difficulty partially arises from two seemingly contradictory goals: learning a common model by aggregating the information from clients, and learning local personalized models that should be adapted to each local distribution. In this work, we propose Solution Simplex Clustered Federated Learning (SosicFL) for dissolving such contradiction. Based on the recent ideas of learning solution simplices, SosicFL assigns a subregion in a simplex to each client, and performs FL to learn a common solution simplex. This allows the client models to possess their characteristics within the degrees of freedom in the solution simplex, and at the same time achieves the goal of learning a global common model. Our experiments show that SosicFL improves the performance and accelerates the training process for global and 
&lt;/p&gt;</description></item></channel></rss>