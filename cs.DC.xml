<rss version="2.0"><channel><title>Chat Arxiv cs.DC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.DC</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BASS&#30340;&#22522;&#20110;&#24191;&#25773;&#30340;&#23376;&#22270;&#37319;&#26679;&#26041;&#27861;&#65292;&#29992;&#20110;&#21152;&#36895;&#21435;&#20013;&#24515;&#21270;&#23398;&#20064;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#20943;&#23569;&#36890;&#20449;&#25104;&#26412;&#12290;</title><link>http://arxiv.org/abs/2401.13779</link><description>&lt;p&gt;
&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#21644;&#26356;&#23569;&#30340;&#36890;&#20449;&#25104;&#26412;&#65306;&#29992;&#20110;&#26080;&#32447;&#32593;&#32476;&#30340;&#22522;&#20110;&#24191;&#25773;&#30340;&#23376;&#22270;&#37319;&#26679;&#30340;&#21435;&#20013;&#24515;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Faster Convergence with Less Communication: Broadcast-Based Subgraph Sampling for Decentralized Learning over Wireless Networks. (arXiv:2401.13779v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13779
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BASS&#30340;&#22522;&#20110;&#24191;&#25773;&#30340;&#23376;&#22270;&#37319;&#26679;&#26041;&#27861;&#65292;&#29992;&#20110;&#21152;&#36895;&#21435;&#20013;&#24515;&#21270;&#23398;&#20064;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#20943;&#23569;&#36890;&#20449;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20849;&#35782;&#30340;&#21435;&#20013;&#24515;&#21270;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;(D-SGD)&#26159;&#19968;&#31181;&#24191;&#27867;&#37319;&#29992;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#32593;&#32476;&#20195;&#29702;&#20043;&#38388;&#30340;&#21435;&#20013;&#24515;&#21270;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#35757;&#32451;&#12290;D-SGD&#30340;&#19968;&#20010;&#20851;&#38190;&#37096;&#20998;&#26159;&#22522;&#20110;&#20849;&#35782;&#30340;&#27169;&#22411;&#24179;&#22343;&#65292;&#23427;&#20005;&#37325;&#20381;&#36182;&#20110;&#33410;&#28857;&#20043;&#38388;&#30340;&#20449;&#24687;&#20132;&#25442;&#21644;&#34701;&#21512;&#12290;&#29305;&#21035;&#22320;&#65292;&#23545;&#20110;&#22312;&#26080;&#32447;&#32593;&#32476;&#19978;&#30340;&#20849;&#35782;&#24179;&#22343;&#65292;&#36890;&#20449;&#21327;&#35843;&#26159;&#24517;&#35201;&#30340;&#65292;&#20197;&#30830;&#23450;&#33410;&#28857;&#20309;&#26102;&#20197;&#21450;&#22914;&#20309;&#35775;&#38382;&#20449;&#36947;&#65292;&#24182;&#23558;&#20449;&#24687;&#20256;&#36755;&#65288;&#25110;&#25509;&#25910;&#65289;&#32473;&#65288;&#25110;&#20174;&#65289;&#37051;&#23621;&#33410;&#28857;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BASS&#30340;&#22522;&#20110;&#24191;&#25773;&#30340;&#23376;&#22270;&#37319;&#26679;&#26041;&#27861;&#65292;&#26088;&#22312;&#21152;&#24555;D-SGD&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#32771;&#34385;&#27599;&#36718;&#36845;&#20195;&#30340;&#23454;&#38469;&#36890;&#20449;&#25104;&#26412;&#12290;BASS&#21019;&#24314;&#19968;&#32452;&#28151;&#21512;&#30697;&#38453;&#20505;&#36873;&#39033;&#65292;&#34920;&#31034;&#22522;&#30784;&#25299;&#25169;&#30340;&#31232;&#30095;&#23376;&#22270;&#12290;&#22312;&#27599;&#20010;&#20849;&#35782;&#36845;&#20195;&#20013;&#65292;&#23558;&#37319;&#26679;&#19968;&#20010;&#28151;&#21512;&#30697;&#38453;&#65292;&#20174;&#32780;&#20135;&#29983;&#19968;&#20010;&#29305;&#23450;&#30340;&#35843;&#24230;&#20915;&#31574;&#65292;&#28608;&#27963;&#22810;&#20010;&#26080;&#30896;&#25758;&#30340;&#33410;&#28857;&#23376;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Consensus-based decentralized stochastic gradient descent (D-SGD) is a widely adopted algorithm for decentralized training of machine learning models across networked agents. A crucial part of D-SGD is the consensus-based model averaging, which heavily relies on information exchange and fusion among the nodes. Specifically, for consensus averaging over wireless networks, communication coordination is necessary to determine when and how a node can access the channel and transmit (or receive) information to (or from) its neighbors. In this work, we propose $\texttt{BASS}$, a broadcast-based subgraph sampling method designed to accelerate the convergence of D-SGD while considering the actual communication cost per iteration. $\texttt{BASS}$ creates a set of mixing matrix candidates that represent sparser subgraphs of the base topology. In each consensus iteration, one mixing matrix is sampled, leading to a specific scheduling decision that activates multiple collision-free subsets of node
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21322;&#20998;&#25955;&#32593;&#32476;&#30340;&#36890;&#20449;&#39640;&#25928;&#31639;&#27861;PISCO, &#36890;&#36807;&#27010;&#29575;&#24615;&#30340;&#20195;&#29702;&#38388;&#21644;&#20195;&#29702;&#19982;&#26381;&#21153;&#22120;&#20043;&#38388;&#30340;&#36890;&#20449;&#65292;&#23454;&#29616;&#20102;&#36890;&#20449;&#25928;&#29575;&#19982;&#25910;&#25947;&#36895;&#24230;&#30340;&#25240;&#34935;&#12290;</title><link>http://arxiv.org/abs/2311.18787</link><description>&lt;p&gt;
&#36890;&#20449;&#39640;&#25928;&#30340;&#21322;&#20998;&#25955;&#32593;&#32476;&#32852;&#37030;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Communication-Efficient Federated Optimization over Semi-Decentralized Networks. (arXiv:2311.18787v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.18787
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21322;&#20998;&#25955;&#32593;&#32476;&#30340;&#36890;&#20449;&#39640;&#25928;&#31639;&#27861;PISCO, &#36890;&#36807;&#27010;&#29575;&#24615;&#30340;&#20195;&#29702;&#38388;&#21644;&#20195;&#29702;&#19982;&#26381;&#21153;&#22120;&#20043;&#38388;&#30340;&#36890;&#20449;&#65292;&#23454;&#29616;&#20102;&#36890;&#20449;&#25928;&#29575;&#19982;&#25910;&#25947;&#36895;&#24230;&#30340;&#25240;&#34935;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22823;&#35268;&#27169;&#30340;&#32852;&#37030;&#21644;&#20998;&#25955;&#24335;&#23398;&#20064;&#20013;&#65292;&#36890;&#20449;&#25928;&#29575;&#26159;&#26368;&#20855;&#25361;&#25112;&#24615;&#30340;&#29942;&#39048;&#20043;&#19968;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#20998;&#25955;&#36890;&#20449;&#21327;&#35758;&#19979;&#30340;&#36890;&#20449;&#39640;&#25928;&#31639;&#27861;PISCO&#65292;&#36890;&#36807;&#27010;&#29575;&#24615;&#30340;&#20195;&#29702;&#38388;&#21644;&#20195;&#29702;&#19982;&#26381;&#21153;&#22120;&#20043;&#38388;&#30340;&#36890;&#20449;&#65292;&#23454;&#29616;&#20102;&#36890;&#20449;&#25928;&#29575;&#19982;&#25910;&#25947;&#36895;&#24230;&#30340;&#25240;&#34935;&#12290;PISCO&#31639;&#27861;&#36890;&#36807;&#26799;&#24230;&#36861;&#36394;&#21644;&#22810;&#20010;&#26412;&#22320;&#26356;&#26032;&#20445;&#35777;&#20102;&#23545;&#25968;&#25454;&#24322;&#36136;&#24615;&#30340;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;PISCO&#31639;&#27861;&#22312;&#38750;&#20984;&#38382;&#39064;&#19978;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#25968;&#37327;&#26041;&#38754;&#65292;PISCO&#31639;&#27861;&#20855;&#26377;&#32447;&#24615;&#21152;&#36895;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
In large-scale federated and decentralized learning, communication efficiency is one of the most challenging bottlenecks. While gossip communication -- where agents can exchange information with their connected neighbors -- is more cost-effective than communicating with the remote server, it often requires a greater number of communication rounds, especially for large and sparse networks. To tackle the trade-off, we examine the communication efficiency under a semi-decentralized communication protocol, in which agents can perform both agent-to-agent and agent-to-server communication in a probabilistic manner. We design a tailored communication-efficient algorithm over semi-decentralized networks, referred to as PISCO, which inherits the robustness to data heterogeneity thanks to gradient tracking and allows multiple local updates for saving communication. We establish the convergence rate of PISCO for nonconvex problems and show that PISCO enjoys a linear speedup in terms of the number
&lt;/p&gt;</description></item></channel></rss>