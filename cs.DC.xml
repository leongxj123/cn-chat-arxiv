<rss version="2.0"><channel><title>Chat Arxiv cs.DC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.DC</description><item><title>&#26412;&#25991;&#22635;&#34917;&#20102;&#20998;&#35010;&#32852;&#37030;&#23398;&#20064;&#22312;&#21508;&#24322;&#25968;&#25454;&#19978;&#25910;&#25947;&#20998;&#26512;&#30340;&#31354;&#30333;&#65292;&#25552;&#20379;&#20102;&#38024;&#23545;&#24378;&#20984;&#21644;&#19968;&#33324;&#20984;&#30446;&#26631;&#30340;SFL&#25910;&#25947;&#20998;&#26512;&#65292;&#25910;&#25947;&#36895;&#29575;&#20998;&#21035;&#20026;$O(1/T)$&#21644;$O(1/\sqrt[3]{T})&#12290;</title><link>https://arxiv.org/abs/2402.15166</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#24322;&#26500;&#25968;&#25454;&#19978;&#30340;&#20998;&#35010;&#32852;&#37030;&#23398;&#20064;&#30340;&#25910;&#25947;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Convergence Analysis of Split Federated Learning on Heterogeneous Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15166
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22635;&#34917;&#20102;&#20998;&#35010;&#32852;&#37030;&#23398;&#20064;&#22312;&#21508;&#24322;&#25968;&#25454;&#19978;&#25910;&#25947;&#20998;&#26512;&#30340;&#31354;&#30333;&#65292;&#25552;&#20379;&#20102;&#38024;&#23545;&#24378;&#20984;&#21644;&#19968;&#33324;&#20984;&#30446;&#26631;&#30340;SFL&#25910;&#25947;&#20998;&#26512;&#65292;&#25910;&#25947;&#36895;&#29575;&#20998;&#21035;&#20026;$O(1/T)$&#21644;$O(1/\sqrt[3]{T})&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#35010;&#32852;&#37030;&#23398;&#20064;&#65288;SFL&#65289;&#26159;&#19968;&#31181;&#26368;&#36817;&#30340;&#20998;&#24067;&#24335;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#22810;&#20010;&#23458;&#25143;&#31471;&#20043;&#38388;&#36827;&#34892;&#21327;&#20316;&#27169;&#22411;&#35757;&#32451;&#12290;&#22312;SFL&#20013;&#65292;&#20840;&#23616;&#27169;&#22411;&#36890;&#24120;&#34987;&#20998;&#20026;&#20004;&#37096;&#20998;&#65292;&#20854;&#20013;&#23458;&#25143;&#31471;&#20197;&#24182;&#34892;&#32852;&#37030;&#26041;&#24335;&#35757;&#32451;&#19968;&#37096;&#20998;&#65292;&#20027;&#26381;&#21153;&#22120;&#35757;&#32451;&#21478;&#19968;&#37096;&#20998;&#12290;&#23613;&#31649;&#26368;&#36817;&#20851;&#20110;SFL&#31639;&#27861;&#21457;&#23637;&#30340;&#30740;&#31350;&#24456;&#22810;&#65292;&#20294;SFL&#30340;&#25910;&#25947;&#20998;&#26512;&#22312;&#25991;&#29486;&#20013;&#36824;&#26410;&#26377;&#25552;&#21450;&#65292;&#26412;&#25991;&#26088;&#22312;&#24357;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;&#23545;SFL&#36827;&#34892;&#20998;&#26512;&#21487;&#33021;&#27604;&#23545;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#30340;&#20998;&#26512;&#26356;&#20855;&#25361;&#25112;&#24615;&#65292;&#36825;&#26159;&#30001;&#20110;&#23458;&#25143;&#31471;&#21644;&#20027;&#26381;&#21153;&#22120;&#20043;&#38388;&#21487;&#33021;&#23384;&#22312;&#21452;&#36895;&#26356;&#26032;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#38024;&#23545;&#24322;&#26500;&#25968;&#25454;&#19978;&#24378;&#20984;&#21644;&#19968;&#33324;&#20984;&#30446;&#26631;&#30340;SFL&#25910;&#25947;&#20998;&#26512;&#12290;&#25910;&#25947;&#36895;&#29575;&#20998;&#21035;&#20026;$O(1/T)$&#21644;$O(1/\sqrt[3]{T})$&#65292;&#20854;&#20013;$T$&#34920;&#31034;SFL&#35757;&#32451;&#30340;&#24635;&#36718;&#25968;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23558;&#20998;&#26512;&#25193;&#23637;&#21040;&#38750;&#20984;&#30446;&#26631;&#21644;&#19968;&#20123;&#23458;&#25143;&#31471;&#21487;&#33021;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#19981;&#21487;&#29992;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15166v1 Announce Type: cross  Abstract: Split federated learning (SFL) is a recent distributed approach for collaborative model training among multiple clients. In SFL, a global model is typically split into two parts, where clients train one part in a parallel federated manner, and a main server trains the other. Despite the recent research on SFL algorithm development, the convergence analysis of SFL is missing in the literature, and this paper aims to fill this gap. The analysis of SFL can be more challenging than that of federated learning (FL), due to the potential dual-paced updates at the clients and the main server. We provide convergence analysis of SFL for strongly convex and general convex objectives on heterogeneous data. The convergence rates are $O(1/T)$ and $O(1/\sqrt[3]{T})$, respectively, where $T$ denotes the total number of rounds for SFL training. We further extend the analysis to non-convex objectives and where some clients may be unavailable during trai
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#20113;&#27169;&#22411;&#30340;&#26816;&#32034;&#22686;&#24378;&#20869;&#23384;&#25972;&#21512;&#21040;&#23458;&#25143;&#31471;&#27169;&#22411;&#20013;&#65292;&#23454;&#29616;&#23454;&#26102;&#21709;&#24212;&#30340;&#20316;&#26354;&#36741;&#21161;&#12290;</title><link>http://arxiv.org/abs/2308.04215</link><description>&lt;p&gt;
&#23454;&#26102;&#20316;&#26354;&#36741;&#21161;&#30340;&#28151;&#21512;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Hybrid Retrieval-Augmented Generation for Real-time Composition Assistance. (arXiv:2308.04215v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04215
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#20113;&#27169;&#22411;&#30340;&#26816;&#32034;&#22686;&#24378;&#20869;&#23384;&#25972;&#21512;&#21040;&#23458;&#25143;&#31471;&#27169;&#22411;&#20013;&#65292;&#23454;&#29616;&#23454;&#26102;&#21709;&#24212;&#30340;&#20316;&#26354;&#36741;&#21161;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26816;&#32034;&#22686;&#24378;&#27169;&#22411;&#22312;&#25552;&#21319;&#20256;&#32479;&#35821;&#35328;&#27169;&#22411;&#30340;&#19978;&#19979;&#25991;&#29702;&#35299;&#12289;&#25972;&#21512;&#31169;&#20154;&#25968;&#25454;&#21644;&#20943;&#23569;&#24187;&#35273;&#26041;&#38754;&#26174;&#31034;&#20986;&#20102;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#24212;&#29992;&#20110;&#38656;&#35201;&#23454;&#26102;&#21709;&#24212;&#30340;&#20219;&#21153;&#65288;&#22914;&#20316;&#26354;&#36741;&#21161;&#65289;&#26102;&#65292;&#26816;&#32034;&#22686;&#24378;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25152;&#38656;&#30340;&#22788;&#29702;&#26102;&#38388;&#23384;&#22312;&#25361;&#25112;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#19968;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Hybrid Retrieval-Augmented Generation (HybridRAG)&#26694;&#26550;&#65292;&#21033;&#29992;&#20102;&#23558;&#23458;&#25143;&#31471;&#27169;&#22411;&#21644;&#20113;&#27169;&#22411;&#32467;&#21512;&#36215;&#26469;&#30340;&#28151;&#21512;&#35774;&#32622;&#12290;HybridRAG&#36890;&#36807;&#24322;&#27493;&#29983;&#25104;&#30340;&#26816;&#32034;&#22686;&#24378;&#20869;&#23384;&#65292;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#20113;&#31471;&#29983;&#25104;&#30340;&#26816;&#32034;&#22686;&#24378;&#20869;&#23384;&#25972;&#21512;&#21040;&#23458;&#25143;&#31471;&#27169;&#22411;&#20013;&#12290;&#36890;&#36807;&#25972;&#21512;&#36825;&#31181;&#26816;&#32034;&#22686;&#24378;&#20869;&#23384;&#65292;&#23458;&#25143;&#31471;&#27169;&#22411;&#33021;&#22815;&#29983;&#25104;&#39640;&#25928;&#30340;&#21709;&#24212;&#65292;&#20174;LLM&#30340;&#33021;&#21147;&#20013;&#21463;&#30410;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#24322;&#27493;&#20869;&#23384;&#38598;&#25104;&#65292;&#23458;&#25143;&#31471;&#27169;&#22411;&#33021;&#22815;&#23454;&#26102;&#21709;&#24212;&#29992;&#25143;&#35831;&#27714;&#65292;&#26080;&#38656;&#31561;&#24453;&#20113;&#31471;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
Retrieval augmented models show promise in enhancing traditional language models by improving their contextual understanding, integrating private data, and reducing hallucination. However, the processing time required for retrieval augmented large language models poses a challenge when applying them to tasks that require real-time responses, such as composition assistance.  To overcome this limitation, we propose the Hybrid Retrieval-Augmented Generation (HybridRAG) framework that leverages a hybrid setting that combines both client and cloud models. HybridRAG incorporates retrieval-augmented memory generated asynchronously by a Large Language Model (LLM) in the cloud. By integrating this retrieval augmented memory, the client model acquires the capability to generate highly effective responses, benefiting from the LLM's capabilities. Furthermore, through asynchronous memory integration, the client model is capable of delivering real-time responses to user requests without the need to 
&lt;/p&gt;</description></item></channel></rss>