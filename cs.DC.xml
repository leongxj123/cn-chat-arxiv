<rss version="2.0"><channel><title>Chat Arxiv cs.DC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.DC</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20005;&#26684;&#20998;&#21306;&#35843;&#24230;&#31574;&#30053;&#65292;&#29992;&#20110;&#38646;&#26143;&#21018;&#24615;&#27969;&#24335;&#20219;&#21153;&#65292;&#36890;&#36807;&#21019;&#24314;&#19981;&#30456;&#20132;&#30340;&#20219;&#21153;&#21644;&#22788;&#29702;&#22120;&#20998;&#21306;&#65292;&#24182;&#23581;&#35797;&#23558;&#30456;&#20284;&#23481;&#37327;&#30340;&#20219;&#21153;&#20998;&#37197;&#32473;&#21516;&#19968;&#20998;&#21306;&#65292;&#20197;&#20943;&#23569;&#24178;&#25200;&#12290;</title><link>https://arxiv.org/abs/2403.10726</link><description>&lt;p&gt;
&#38024;&#23545;&#38646;&#26143;&#21018;&#24615;&#27969;&#24335;&#20219;&#21153;&#30340;&#20005;&#26684;&#20998;&#21306;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Strict Partitioning for Sporadic Rigid Gang Tasks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10726
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20005;&#26684;&#20998;&#21306;&#35843;&#24230;&#31574;&#30053;&#65292;&#29992;&#20110;&#38646;&#26143;&#21018;&#24615;&#27969;&#24335;&#20219;&#21153;&#65292;&#36890;&#36807;&#21019;&#24314;&#19981;&#30456;&#20132;&#30340;&#20219;&#21153;&#21644;&#22788;&#29702;&#22120;&#20998;&#21306;&#65292;&#24182;&#23581;&#35797;&#23558;&#30456;&#20284;&#23481;&#37327;&#30340;&#20219;&#21153;&#20998;&#37197;&#32473;&#21516;&#19968;&#20998;&#21306;&#65292;&#20197;&#20943;&#23569;&#24178;&#25200;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21018;&#24615;&#27969;&#24335;&#20219;&#21153;&#27169;&#22411;&#22522;&#20110;&#22312;&#22266;&#23450;&#25968;&#37327;&#30340;&#22788;&#29702;&#22120;&#19978;&#21516;&#26102;&#25191;&#34892;&#22810;&#20010;&#32447;&#31243;&#20197;&#25552;&#39640;&#25928;&#29575;&#21644;&#24615;&#33021;&#30340;&#24605;&#24819;&#12290;&#34429;&#28982;&#20840;&#23616;&#21018;&#24615;&#27969;&#24335;&#35843;&#24230;&#26377;&#22823;&#37327;&#25991;&#29486;&#65292;&#20294;&#20998;&#21306;&#26041;&#27861;&#20855;&#26377;&#20960;&#20010;&#23454;&#38469;&#20248;&#21183;&#65288;&#20363;&#22914;&#20219;&#21153;&#38548;&#31163;&#21644;&#20943;&#23569;&#35843;&#24230;&#24320;&#38144;&#65289;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29992;&#20110;&#21018;&#24615;&#27969;&#24335;&#20219;&#21153;&#30340;&#20998;&#21306;&#35843;&#24230;&#31574;&#30053;&#65292;&#31216;&#20026;&#20005;&#26684;&#20998;&#21306;&#12290;&#35813;&#26041;&#27861;&#21019;&#24314;&#20219;&#21153;&#21644;&#22788;&#29702;&#22120;&#30340;&#19981;&#30456;&#20132;&#20998;&#21306;&#65292;&#20197;&#36991;&#20813;&#20998;&#21306;&#38388;&#24178;&#25200;&#12290;&#27492;&#22806;&#65292;&#23427;&#23581;&#35797;&#23558;&#20855;&#26377;&#30456;&#20284;&#23481;&#37327;&#65288;&#21363;&#24182;&#34892;&#24615;&#65289;&#30340;&#20219;&#21153;&#20998;&#37197;&#32473;&#21516;&#19968;&#20998;&#21306;&#65292;&#20197;&#20943;&#23569;&#20998;&#21306;&#20869;&#24178;&#25200;&#12290;&#22312;&#27599;&#20010;&#20998;&#21306;&#20869;&#65292;&#20219;&#21153;&#21487;&#20197;&#20351;&#29992;&#20219;&#20309;&#31867;&#22411;&#30340;&#35843;&#24230;&#22120;&#36827;&#34892;&#35843;&#24230;&#65292;&#36825;&#20801;&#35768;&#20351;&#29992;&#19981;&#37027;&#20040;&#24754;&#35266;&#30340;&#21487;&#35843;&#24230;&#27979;&#35797;&#12290;&#22823;&#37327;&#30340;&#21512;&#25104;&#23454;&#39564;&#35777;&#26126;&#21644;&#22522;&#20110;Edge TPU&#22522;&#20934;&#30340;&#26696;&#20363;&#30740;&#31350;&#26174;&#31034;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10726v1 Announce Type: cross  Abstract: The rigid gang task model is based on the idea of executing multiple threads simultaneously on a fixed number of processors to increase efficiency and performance. Although there is extensive literature on global rigid gang scheduling, partitioned approaches have several practical advantages (e.g., task isolation and reduced scheduling overheads). In this paper, we propose a new partitioned scheduling strategy for rigid gang tasks, named strict partitioning. The method creates disjoint partitions of tasks and processors to avoid inter-partition interference. Moreover, it tries to assign tasks with similar volumes (i.e., parallelisms) to the same partition so that the intra-partition interference can be reduced. Within each partition, the tasks can be scheduled using any type of scheduler, which allows the use of a less pessimistic schedulability test. Extensive synthetic experiments and a case study based on Edge TPU benchmarks show th
&lt;/p&gt;</description></item><item><title>Sentinel&#26159;&#19968;&#31181;&#29992;&#20110;&#20445;&#25252;&#20998;&#25955;&#24335;&#32852;&#37030;&#23398;&#20064;&#30340;&#38450;&#24481;&#31574;&#30053;&#65292;&#36890;&#36807;&#21033;&#29992;&#26412;&#22320;&#25968;&#25454;&#24182;&#23450;&#20041;&#19968;&#20010;&#19977;&#27493;&#32858;&#21512;&#21327;&#35758;&#26469;&#23545;&#25239;&#27745;&#26579;&#25915;&#20987;&#12290;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126;Sentinel&#22312;&#19981;&#21516;&#25968;&#25454;&#38598;&#21644;&#35780;&#20272;&#25351;&#26631;&#19979;&#34920;&#29616;&#33391;&#22909;&#12290;</title><link>http://arxiv.org/abs/2310.08097</link><description>&lt;p&gt;
Sentinel: &#19968;&#31181;&#29992;&#20110;&#20445;&#25252;&#20998;&#25955;&#24335;&#32852;&#37030;&#23398;&#20064;&#30340;&#32858;&#21512;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Sentinel: An Aggregation Function to Secure Decentralized Federated Learning. (arXiv:2310.08097v1 [cs.DC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08097
&lt;/p&gt;
&lt;p&gt;
Sentinel&#26159;&#19968;&#31181;&#29992;&#20110;&#20445;&#25252;&#20998;&#25955;&#24335;&#32852;&#37030;&#23398;&#20064;&#30340;&#38450;&#24481;&#31574;&#30053;&#65292;&#36890;&#36807;&#21033;&#29992;&#26412;&#22320;&#25968;&#25454;&#24182;&#23450;&#20041;&#19968;&#20010;&#19977;&#27493;&#32858;&#21512;&#21327;&#35758;&#26469;&#23545;&#25239;&#27745;&#26579;&#25915;&#20987;&#12290;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126;Sentinel&#22312;&#19981;&#21516;&#25968;&#25454;&#38598;&#21644;&#35780;&#20272;&#25351;&#26631;&#19979;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#24555;&#36895;&#25972;&#21512;&#21040;&#32593;&#32476;&#20013;&#28085;&#30422;&#20102;&#32593;&#32476;&#31649;&#29702;&#12289;&#26381;&#21153;&#36136;&#37327;&#21644;&#32593;&#32476;&#23433;&#20840;&#31561;&#21508;&#20010;&#26041;&#38754;&#65292;&#21516;&#26102;&#20445;&#25252;&#25968;&#25454;&#38544;&#31169;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#20998;&#25955;&#24335;&#32852;&#37030;&#23398;&#20064;&#65288;DFL&#65289;&#20316;&#20026;&#19968;&#31181;&#21019;&#26032;&#33539;&#24335;&#65292;&#29992;&#20110;&#35757;&#32451;&#21327;&#20316;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#21333;&#28857;&#22833;&#25928;&#30340;&#38480;&#21046;&#12290;&#28982;&#32780;&#65292;FL&#21644;DFL&#30340;&#23433;&#20840;&#24615;&#21644;&#21487;&#20449;&#24615;&#21463;&#21040;&#27745;&#26579;&#25915;&#20987;&#30340;&#24433;&#21709;&#65292;&#20174;&#32780;&#23545;&#20854;&#24615;&#33021;&#20135;&#29983;&#36127;&#38754;&#24433;&#21709;&#12290;&#29616;&#26377;&#30340;&#38450;&#24481;&#26426;&#21046;&#38024;&#23545;&#38598;&#20013;&#24335;FL&#36827;&#34892;&#35774;&#35745;&#65292;&#24182;&#26410;&#20805;&#20998;&#21033;&#29992;DFL&#30340;&#29305;&#28857;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#24341;&#20837;&#20102;Sentinel&#65292;&#19968;&#31181;&#22312;DFL&#20013;&#23545;&#25239;&#27745;&#26579;&#25915;&#20987;&#30340;&#38450;&#24481;&#31574;&#30053;&#12290;Sentinel&#21033;&#29992;&#26412;&#22320;&#25968;&#25454;&#30340;&#21487;&#35775;&#38382;&#24615;&#65292;&#23450;&#20041;&#20102;&#19968;&#20010;&#19977;&#27493;&#32858;&#21512;&#21327;&#35758;&#65292;&#21253;&#25324;&#30456;&#20284;&#24615;&#36807;&#28388;&#12289;&#24341;&#23548;&#39564;&#35777;&#21644;&#26631;&#20934;&#21270;&#65292;&#20197;&#38450;&#27490;&#24694;&#24847;&#27169;&#22411;&#26356;&#26032;&#12290;&#36890;&#36807;&#20351;&#29992;&#19981;&#21516;&#25968;&#25454;&#38598;&#21644;&#19981;&#21516;&#30340;&#35780;&#20272;&#25351;&#26631;&#23545;Sentinel&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
The rapid integration of Federated Learning (FL) into networking encompasses various aspects such as network management, quality of service, and cybersecurity while preserving data privacy. In this context, Decentralized Federated Learning (DFL) emerges as an innovative paradigm to train collaborative models, addressing the single point of failure limitation. However, the security and trustworthiness of FL and DFL are compromised by poisoning attacks, negatively impacting its performance. Existing defense mechanisms have been designed for centralized FL and they do not adequately exploit the particularities of DFL. Thus, this work introduces Sentinel, a defense strategy to counteract poisoning attacks in DFL. Sentinel leverages the accessibility of local data and defines a three-step aggregation protocol consisting of similarity filtering, bootstrap validation, and normalization to safeguard against malicious model updates. Sentinel has been evaluated with diverse datasets and various 
&lt;/p&gt;</description></item></channel></rss>