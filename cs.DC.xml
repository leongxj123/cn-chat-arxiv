<rss version="2.0"><channel><title>Chat Arxiv cs.DC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.DC</description><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#20998;&#24067;&#24335;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#30340;&#36890;&#20449;&#20248;&#21270;&#26550;&#26500;&#65292;&#24182;&#23545;&#24182;&#34892;&#21270;&#31574;&#30053;&#12289;&#38598;&#20307;&#36890;&#20449;&#24211;&#21644;&#32593;&#32476;&#20851;&#31995;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#24635;&#32467;&#20102;&#24403;&#21069;&#30340;&#30740;&#31350;&#36827;&#23637;&#12290;</title><link>https://arxiv.org/abs/2403.07585</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#35757;&#32451;&#30340;&#36890;&#20449;&#20248;&#21270;&#65306;&#26550;&#26500;&#12289;&#36827;&#23637;&#21644;&#26426;&#36935;
&lt;/p&gt;
&lt;p&gt;
Communication Optimization for Distributed Training: Architecture, Advances, and Opportunities
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07585
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#20998;&#24067;&#24335;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#30340;&#36890;&#20449;&#20248;&#21270;&#26550;&#26500;&#65292;&#24182;&#23545;&#24182;&#34892;&#21270;&#31574;&#30053;&#12289;&#38598;&#20307;&#36890;&#20449;&#24211;&#21644;&#32593;&#32476;&#20851;&#31995;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#24635;&#32467;&#20102;&#24403;&#21069;&#30340;&#30740;&#31350;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22823;&#35268;&#27169;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#30340;&#34028;&#21187;&#21457;&#23637;&#65292;&#21442;&#25968;&#37327;&#19981;&#26029;&#22686;&#38271;&#12290;&#35757;&#32451;&#36825;&#20123;&#22823;&#35268;&#27169;&#27169;&#22411;&#36890;&#24120;&#38656;&#35201;&#24222;&#22823;&#30340;&#20869;&#23384;&#21644;&#35745;&#31639;&#36164;&#28304;&#65292;&#36229;&#20986;&#20102;&#21333;&#20010;GPU&#30340;&#33539;&#22260;&#65292;&#38656;&#35201;&#36827;&#34892;&#20998;&#24067;&#24335;&#35757;&#32451;&#12290;&#30001;&#20110;&#36817;&#24180;&#26469;GPU&#24615;&#33021;&#36805;&#36895;&#21457;&#23637;&#65292;&#35745;&#31639;&#26102;&#38388;&#32553;&#30701;&#65292;&#22240;&#27492;&#36890;&#20449;&#22312;&#25972;&#20307;&#35757;&#32451;&#26102;&#38388;&#20013;&#30340;&#27604;&#20363;&#22686;&#21152;&#12290;&#22240;&#27492;&#65292;&#20248;&#21270;&#20998;&#24067;&#24335;&#35757;&#32451;&#30340;&#36890;&#20449;&#24050;&#32463;&#25104;&#20026;&#19968;&#20010;&#32039;&#36843;&#38382;&#39064;&#12290;&#26412;&#25991;&#31616;&#35201;&#20171;&#32461;&#20102;&#20998;&#24067;&#24335;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#30340;&#24635;&#20307;&#26550;&#26500;&#65292;&#24182;&#20174;&#36890;&#20449;&#20248;&#21270;&#30340;&#35282;&#24230;&#20998;&#26512;&#20102;&#24182;&#34892;&#21270;&#31574;&#30053;&#12289;&#38598;&#20307;&#36890;&#20449;&#24211;&#21644;&#32593;&#32476;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24418;&#25104;&#20102;&#19968;&#20010;&#19977;&#23618;&#33539;&#24335;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#22238;&#39038;&#20102;&#24403;&#21069;&#20855;&#26377;&#20195;&#34920;&#24615;&#30340;&#30740;&#31350;&#36827;&#23637;&#19982;&#36825;&#20010;&#19977;&#23618;&#33539;&#24335;&#12290;&#25105;&#20204;&#21457;&#29616;lay
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07585v1 Announce Type: cross  Abstract: The past few years have witnessed the flourishing of large-scale deep neural network models with ever-growing parameter numbers. Training such large-scale models typically requires massive memory and computing resources that exceed those of a single GPU, necessitating distributed training. As GPU performance has rapidly evolved in recent years, computation time has shrunk, thereby increasing the proportion of communication in the overall training time. Therefore, optimizing communication for distributed training has become an urgent issue. In this article, we briefly introduce the general architecture of distributed deep neural network training and analyze relationships among Parallelization Strategy, Collective Communication Library, and Network from the perspective of communication optimization, which forms a three-layer paradigm. We then review current representative research advances with this three-layer paradigm. We find that lay
&lt;/p&gt;</description></item></channel></rss>