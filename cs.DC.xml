<rss version="2.0"><channel><title>Chat Arxiv cs.DC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.DC</description><item><title>&#25552;&#20986;&#20102;Decoupled VFL&#65288;DVFL&#65289;&#65292;&#19968;&#31181;&#38754;&#21521;VFL&#30340;&#20998;&#27573;&#23398;&#20064;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#20998;&#25955;&#32858;&#21512;&#21644;&#38548;&#31163;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#23481;&#38169;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.03871</link><description>&lt;p&gt;
&#38754;&#21521;&#22402;&#30452;&#20998;&#21306;&#25968;&#25454;&#30340;&#35299;&#32806;&#24335;&#22402;&#30452;&#32852;&#37030;&#23398;&#20064;&#65292;&#29992;&#20110;&#23454;&#38469;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Decoupled Vertical Federated Learning for Practical Training on Vertically Partitioned Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03871
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;Decoupled VFL&#65288;DVFL&#65289;&#65292;&#19968;&#31181;&#38754;&#21521;VFL&#30340;&#20998;&#27573;&#23398;&#20064;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#20998;&#25955;&#32858;&#21512;&#21644;&#38548;&#31163;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#23481;&#38169;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22402;&#30452;&#32852;&#37030;&#23398;&#20064;&#65288;VFL&#65289;&#26159;&#19968;&#31181;&#26032;&#20852;&#30340;&#20998;&#24067;&#24335;&#26426;&#22120;&#23398;&#20064;&#33539;&#24335;&#65292;&#20854;&#20013;&#20849;&#21516;&#23454;&#20307;&#30340;&#19981;&#21516;&#29305;&#24449;&#25152;&#26377;&#32773;&#21512;&#20316;&#23398;&#20064;&#20840;&#23616;&#27169;&#22411;&#32780;&#26080;&#38656;&#20849;&#20139;&#25968;&#25454;&#12290;&#22312;VFL&#20013;&#65292;&#20027;&#26426;&#23458;&#25143;&#31471;&#25317;&#26377;&#27599;&#20010;&#23454;&#20307;&#30340;&#25968;&#25454;&#26631;&#31614;&#65292;&#24182;&#22522;&#20110;&#25152;&#26377;&#23458;&#25143;&#31471;&#30340;&#20013;&#38388;&#26412;&#22320;&#34920;&#31034;&#23398;&#20064;&#26368;&#32456;&#34920;&#31034;&#12290;&#22240;&#27492;&#65292;&#20027;&#26426;&#26159;&#19968;&#20010;&#21333;&#28857;&#25925;&#38556;&#65292;&#26631;&#31614;&#21453;&#39304;&#21487;&#20197;&#34987;&#24694;&#24847;&#23458;&#25143;&#31471;&#29992;&#26469;&#25512;&#26029;&#31169;&#26377;&#29305;&#24449;&#12290;&#35201;&#27714;&#25152;&#26377;&#21442;&#19982;&#32773;&#22312;&#25972;&#20010;&#35757;&#32451;&#36807;&#31243;&#20013;&#20445;&#25345;&#27963;&#36291;&#21644;&#20540;&#24471;&#20449;&#36182;&#36890;&#24120;&#26159;&#19981;&#20999;&#23454;&#38469;&#30340;&#65292;&#22312;&#21463;&#25511;&#29615;&#22659;&#20043;&#22806;&#23436;&#20840;&#19981;&#21487;&#34892;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;VFL&#30340;&#20998;&#27573;&#23398;&#20064;&#26041;&#27861;Decoupled VFL&#65288;DVFL&#65289;&#12290;&#36890;&#36807;&#22312;&#21508;&#33258;&#30340;&#30446;&#26631;&#19978;&#35757;&#32451;&#27599;&#20010;&#27169;&#22411;&#65292;DVFL&#20801;&#35768;&#29305;&#24449;&#23398;&#20064;&#21644;&#26631;&#31614;&#30417;&#30563;&#20043;&#38388;&#30340;&#20998;&#25955;&#32858;&#21512;&#21644;&#38548;&#31163;&#12290;&#20855;&#26377;&#36825;&#20123;&#23646;&#24615;&#65292;DVFL&#20855;&#26377;&#23481;&#38169;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03871v1 Announce Type: new  Abstract: Vertical Federated Learning (VFL) is an emergent distributed machine learning paradigm wherein owners of disjoint features of a common set of entities collaborate to learn a global model without sharing data. In VFL, a host client owns data labels for each entity and learns a final representation based on intermediate local representations from all guest clients. Therefore, the host is a single point of failure and label feedback can be used by malicious guest clients to infer private features. Requiring all participants to remain active and trustworthy throughout the entire training process is generally impractical and altogether infeasible outside of controlled environments. We propose Decoupled VFL (DVFL), a blockwise learning approach to VFL. By training each model on its own objective, DVFL allows for decentralized aggregation and isolation between feature learning and label supervision. With these properties, DVFL is fault tolerant
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#21435;&#20013;&#24515;&#21270;&#23398;&#20064;&#20013;&#65292;&#34987;&#21160;&#30340;&#22909;&#22855;&#25932;&#25163;&#21487;&#20197;&#22312;&#20960;&#27425;&#20445;&#25252;&#38544;&#31169;&#30340;&#27714;&#21644;&#25805;&#20316;&#21518;&#25512;&#26029;&#20986;&#20854;&#20182;&#29992;&#25143;&#30340;&#31169;&#20154;&#25968;&#25454;&#12290;</title><link>https://arxiv.org/abs/2312.05248</link><description>&lt;p&gt;
&#22522;&#20110;&#25299;&#25169;&#30340;&#21435;&#37325;&#24314;&#38450;&#25252;&#22312;&#21435;&#20013;&#24515;&#21270;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Topology-Based Reconstruction Prevention for Decentralised Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.05248
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#21435;&#20013;&#24515;&#21270;&#23398;&#20064;&#20013;&#65292;&#34987;&#21160;&#30340;&#22909;&#22855;&#25932;&#25163;&#21487;&#20197;&#22312;&#20960;&#27425;&#20445;&#25252;&#38544;&#31169;&#30340;&#27714;&#21644;&#25805;&#20316;&#21518;&#25512;&#26029;&#20986;&#20854;&#20182;&#29992;&#25143;&#30340;&#31169;&#20154;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#21435;&#20013;&#24515;&#21270;&#23398;&#20064;&#20316;&#20026;&#19968;&#31181;&#26367;&#20195;&#32852;&#37030;&#23398;&#20064;&#30340;&#26041;&#24335;&#65292;&#33719;&#24471;&#20102;&#20154;&#20204;&#30340;&#20851;&#27880;&#65292;&#20854;&#20013;&#25968;&#25454;&#21644;&#21327;&#35843;&#37117;&#20998;&#24067;&#22312;&#29992;&#25143;&#20043;&#38388;&#12290;&#20026;&#20102;&#20445;&#25252;&#25968;&#25454;&#30340;&#26426;&#23494;&#24615;&#65292;&#21435;&#20013;&#24515;&#21270;&#23398;&#20064;&#20381;&#36182;&#20110;&#24046;&#20998;&#38544;&#31169;&#12289;&#22810;&#26041;&#35745;&#31639;&#65292;&#25110;&#32773;&#20108;&#32773;&#30340;&#32467;&#21512;&#12290;&#28982;&#32780;&#65292;&#36830;&#32493;&#36816;&#34892;&#22810;&#20010;&#20445;&#25252;&#38544;&#31169;&#30340;&#27714;&#21644;&#25805;&#20316;&#21487;&#33021;&#20250;&#20351;&#23545;&#25163;&#36827;&#34892;&#37325;&#24314;&#25915;&#20987;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#24403;&#21069;&#30340;&#37325;&#24314;&#23545;&#31574;&#35201;&#20040;&#26080;&#27861;&#31616;&#21333;&#22320;&#36866;&#24212;&#20998;&#24067;&#24335;&#29615;&#22659;&#65292;&#35201;&#20040;&#20250;&#28155;&#21152;&#36807;&#22810;&#30340;&#22122;&#38899;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#34920;&#26126;&#65292;&#34987;&#21160;&#30340;&#22909;&#22855;&#25932;&#25163;&#21487;&#20197;&#22312;&#20960;&#27425;&#20445;&#25252;&#38544;&#31169;&#30340;&#27714;&#21644;&#20043;&#21518;&#25512;&#26029;&#20986;&#20854;&#20182;&#29992;&#25143;&#30340;&#31169;&#20154;&#25968;&#25454;&#12290;&#20363;&#22914;&#65292;&#22312;&#25299;&#25169;&#20013;&#26377;18&#20010;&#29992;&#25143;&#30340;&#23376;&#22270;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#21482;&#26377;&#19977;&#20010;&#34987;&#21160;&#30340;&#22909;&#22855;&#25932;&#25163;&#25104;&#21151;&#37325;&#24314;&#31169;&#20154;&#25968;&#25454;&#30340;&#27010;&#29575;&#20026;11.0%&#65292;&#24179;&#22343;&#27599;&#20010;&#23545;&#25163;&#38656;&#35201;8.8&#27425;&#27714;&#21644;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.05248v2 Announce Type: replace-cross  Abstract: Decentralised learning has recently gained traction as an alternative to federated learning in which both data and coordination are distributed over its users. To preserve data confidentiality, decentralised learning relies on differential privacy, multi-party computation, or a combination thereof. However, running multiple privacy-preserving summations in sequence may allow adversaries to perform reconstruction attacks. Unfortunately, current reconstruction countermeasures either cannot trivially be adapted to the distributed setting, or add excessive amounts of noise.   In this work, we first show that passive honest-but-curious adversaries can infer other users' private data after several privacy-preserving summations. For example, in subgraphs with 18 users, we show that only three passive honest-but-curious adversaries succeed at reconstructing private data 11.0% of the time, requiring an average of 8.8 summations per adve
&lt;/p&gt;</description></item></channel></rss>