<rss version="2.0"><channel><title>Chat Arxiv cs.DC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.DC</description><item><title>&#21160;&#24577;&#24207;&#21015;&#24182;&#34892;&#24615;&#65288;DSP&#65289;&#20026;&#22810;&#32500;Transformer&#27169;&#22411;&#24341;&#20837;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#24207;&#21015;&#24182;&#34892;&#26041;&#27861;&#65292;&#36890;&#36807;&#21160;&#24577;&#20999;&#25442;&#24182;&#34892;&#32500;&#24230;&#23454;&#29616;&#23545;&#22810;&#32500;&#27880;&#24847;&#21147;&#27169;&#22411;&#30340;&#20248;&#21270;&#12290;</title><link>https://arxiv.org/abs/2403.10266</link><description>&lt;p&gt;
DSP&#65306;&#22810;&#32500;Transformer&#30340;&#21160;&#24577;&#24207;&#21015;&#24182;&#34892;&#24615;
&lt;/p&gt;
&lt;p&gt;
DSP: Dynamic Sequence Parallelism for Multi-Dimensional Transformers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10266
&lt;/p&gt;
&lt;p&gt;
&#21160;&#24577;&#24207;&#21015;&#24182;&#34892;&#24615;&#65288;DSP&#65289;&#20026;&#22810;&#32500;Transformer&#27169;&#22411;&#24341;&#20837;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#24207;&#21015;&#24182;&#34892;&#26041;&#27861;&#65292;&#36890;&#36807;&#21160;&#24577;&#20999;&#25442;&#24182;&#34892;&#32500;&#24230;&#23454;&#29616;&#23545;&#22810;&#32500;&#27880;&#24847;&#21147;&#27169;&#22411;&#30340;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26412;&#25991;&#20171;&#32461;&#30340;&#21160;&#24577;&#24207;&#21015;&#24182;&#34892;&#24615;&#65288;DSP&#65289;&#26041;&#27861;&#65292;&#21487;&#20197;&#20026;&#22810;&#32500;Transformer&#27169;&#22411;&#23454;&#29616;&#39640;&#25928;&#30340;&#24207;&#21015;&#24182;&#34892;&#24615;&#12290;&#20854;&#20851;&#38190;&#24605;&#24819;&#26159;&#26681;&#25454;&#24403;&#21069;&#35745;&#31639;&#38454;&#27573;&#21160;&#24577;&#20999;&#25442;&#24182;&#34892;&#24615;&#32500;&#24230;&#65292;&#21033;&#29992;&#22810;&#32500;&#27880;&#24847;&#21147;&#30340;&#28508;&#22312;&#29305;&#24615;&#12290;&#36825;&#31181;&#21160;&#24577;&#32500;&#24230;&#20999;&#25442;&#20351;&#24471;&#24207;&#21015;&#24182;&#34892;&#24615;&#22312;&#22810;&#32500;&#27169;&#22411;&#20013;&#20855;&#26377;&#26368;&#23567;&#30340;&#36890;&#20449;&#24320;&#38144;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10266v1 Announce Type: cross  Abstract: Scaling large models with long sequences across applications like language generation, video generation and multimodal tasks requires efficient sequence parallelism. However, existing sequence parallelism methods all assume a single sequence dimension and fail to adapt to multi-dimensional transformer architectures that perform attention calculations across different dimensions. This paper introduces Dynamic Sequence Parallelism (DSP), a novel approach to enable efficient sequence parallelism for multi-dimensional transformer models. The key idea is to dynamically switch the parallelism dimension according to the current computation stage, leveraging the potential characteristics of multi-dimensional attention. This dynamic dimension switching allows sequence parallelism with minimal communication overhead compared to applying traditional single-dimension parallelism to multi-dimensional models. Experiments show DSP improves end-to-end
&lt;/p&gt;</description></item><item><title>&#22522;&#30784;&#27169;&#22411;&#19982;&#32852;&#37030;&#23398;&#20064;&#30340;&#20132;&#21449;&#25552;&#20379;&#20102;&#35299;&#38145;&#26032;&#21487;&#33021;&#24615;&#30340;&#29420;&#29305;&#26426;&#20250;&#65292;&#25193;&#23637;&#20102;&#25968;&#25454;&#21487;&#29992;&#24615;&#65292;&#20419;&#36827;&#20102;&#21327;&#20316;&#24335;&#27169;&#22411;&#21457;&#23637;&#65292;&#24182;&#25552;&#39640;&#20102;&#24615;&#33021;&#21644;&#38544;&#31169;&#20445;&#25252;&#12290;</title><link>http://arxiv.org/abs/2306.15546</link><description>&lt;p&gt;
&#24403;&#22522;&#30784;&#27169;&#22411;&#36935;&#21040;&#32852;&#37030;&#23398;&#20064;&#65306;&#21160;&#26426;&#12289;&#25361;&#25112;&#21644;&#26410;&#26469;&#26041;&#21521;
&lt;/p&gt;
&lt;p&gt;
When Foundation Model Meets Federated Learning: Motivations, Challenges, and Future Directions. (arXiv:2306.15546v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15546
&lt;/p&gt;
&lt;p&gt;
&#22522;&#30784;&#27169;&#22411;&#19982;&#32852;&#37030;&#23398;&#20064;&#30340;&#20132;&#21449;&#25552;&#20379;&#20102;&#35299;&#38145;&#26032;&#21487;&#33021;&#24615;&#30340;&#29420;&#29305;&#26426;&#20250;&#65292;&#25193;&#23637;&#20102;&#25968;&#25454;&#21487;&#29992;&#24615;&#65292;&#20419;&#36827;&#20102;&#21327;&#20316;&#24335;&#27169;&#22411;&#21457;&#23637;&#65292;&#24182;&#25552;&#39640;&#20102;&#24615;&#33021;&#21644;&#38544;&#31169;&#20445;&#25252;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#30784;&#27169;&#22411;&#65288;FM&#65289;&#19982;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#30340;&#20132;&#21449;&#25552;&#20379;&#20102;&#30456;&#20114;&#30340;&#22909;&#22788;&#65292;&#22312;AI&#30740;&#31350;&#20013;&#25552;&#20379;&#20102;&#35299;&#38145;&#26032;&#21487;&#33021;&#24615;&#30340;&#29420;&#29305;&#26426;&#20250;&#65292;&#35299;&#20915;&#20102;AI&#21644;&#29616;&#23454;&#19990;&#30028;&#24212;&#29992;&#20013;&#30340;&#20851;&#38190;&#25361;&#25112;&#12290;FL&#25193;&#23637;&#20102;FM&#30340;&#25968;&#25454;&#21487;&#29992;&#24615;&#65292;&#24182;&#23454;&#29616;&#20102;&#35745;&#31639;&#20849;&#20139;&#65292;&#20998;&#25955;&#20102;&#35757;&#32451;&#36807;&#31243;&#65292;&#24182;&#20943;&#36731;&#20102;FL&#21442;&#19982;&#32773;&#30340;&#36127;&#25285;&#12290;&#23427;&#20419;&#36827;&#20102;&#21327;&#20316;&#24335;FM&#21457;&#23637;&#65292;&#27665;&#20027;&#21270;&#20102;&#36825;&#19968;&#36807;&#31243;&#65292;&#20419;&#36827;&#20102;&#21253;&#23481;&#24615;&#21644;&#21019;&#26032;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;FM&#20197;&#20854;&#24222;&#22823;&#30340;&#35268;&#27169;&#12289;&#39044;&#35757;&#32451;&#30340;&#30693;&#35782;&#21644;&#20986;&#33394;&#30340;&#24615;&#33021;&#65292;&#20026;FL&#25552;&#20379;&#20102;&#19968;&#20010;&#24378;&#22823;&#30340;&#36215;&#28857;&#65292;&#20419;&#36827;&#20102;&#22312;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#19979;&#26356;&#24555;&#30340;&#25910;&#25947;&#21644;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#21033;&#29992;FM&#29983;&#25104;&#21512;&#25104;&#25968;&#25454;&#21487;&#20197;&#20016;&#23500;&#25968;&#25454;&#22810;&#26679;&#24615;&#65292;&#20943;&#23569;&#36807;&#25311;&#21512;&#65292;&#20445;&#25252;&#38544;&#31169;&#12290;&#36890;&#36807;&#30740;&#31350;FL&#21644;FM&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#26412;&#25991;&#26088;&#22312;&#21152;&#28145;&#23545;&#23427;&#20204;&#21327;&#21516;&#20851;&#31995;&#30340;&#29702;&#35299;&#65292;&#24378;&#35843;&#21160;&#26426;&#21644;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
The intersection of the Foundation Model (FM) and Federated Learning (FL) provides mutual benefits, presents a unique opportunity to unlock new possibilities in AI research, and address critical challenges in AI and real-world applications. FL expands the availability of data for FMs and enables computation sharing, distributing the training process and reducing the burden on FL participants. It promotes collaborative FM development, democratizing the process and fostering inclusivity and innovation. On the other hand, FM, with its enormous size, pre-trained knowledge, and exceptional performance, serves as a robust starting point for FL, facilitating faster convergence and better performance under non-iid data. Additionally, leveraging FM to generate synthetic data enriches data diversity, reduces overfitting, and preserves privacy. By examining the interplay between FL and FM, this paper aims to deepen the understanding of their synergistic relationship, highlighting the motivations,
&lt;/p&gt;</description></item></channel></rss>