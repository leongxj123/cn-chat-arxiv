<rss version="2.0"><channel><title>Chat Arxiv cs.DC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.DC</description><item><title>&#25552;&#20986;&#36731;&#37327;&#32423;&#32437;&#21521;&#32852;&#37030;&#23398;&#20064;&#65288;LVFL&#65289;&#30340;&#27010;&#24565;&#65292;&#38024;&#23545;&#35745;&#31639;&#21644;&#36890;&#20449;&#25928;&#29575;&#37319;&#29992;&#20998;&#31163;&#30340;&#36731;&#37327;&#21270;&#31574;&#30053;&#65292;&#24314;&#31435;&#20102;&#25910;&#25947;&#30028;&#38480;&#65292;&#24182;&#22312;&#22270;&#20687;&#20998;&#31867;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#20102;&#39564;&#35777;</title><link>https://arxiv.org/abs/2404.00466</link><description>&lt;p&gt;
&#35745;&#31639;&#21644;&#36890;&#20449;&#39640;&#25928;&#30340;&#36731;&#37327;&#32423;&#32437;&#21521;&#32852;&#37030;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Computation and Communication Efficient Lightweighting Vertical Federated Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00466
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#36731;&#37327;&#32423;&#32437;&#21521;&#32852;&#37030;&#23398;&#20064;&#65288;LVFL&#65289;&#30340;&#27010;&#24565;&#65292;&#38024;&#23545;&#35745;&#31639;&#21644;&#36890;&#20449;&#25928;&#29575;&#37319;&#29992;&#20998;&#31163;&#30340;&#36731;&#37327;&#21270;&#31574;&#30053;&#65292;&#24314;&#31435;&#20102;&#25910;&#25947;&#30028;&#38480;&#65292;&#24182;&#22312;&#22270;&#20687;&#20998;&#31867;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#20102;&#39564;&#35777;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#20013;&#25506;&#32034;&#35745;&#31639;&#21644;&#36890;&#20449;&#25928;&#29575;&#24050;&#25104;&#20026;&#19968;&#20010;&#31361;&#20986;&#21644;&#20851;&#38190;&#30340;&#30740;&#31350;&#39046;&#22495;&#12290;&#23613;&#31649;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#21162;&#21147;&#37117;&#38598;&#20013;&#22312;&#25552;&#39640;&#36825;&#20123;&#25928;&#29575;&#65292;&#20294;&#30001;&#20110;&#22402;&#30452;FL&#30340;&#19981;&#21516;&#36807;&#31243;&#21644;&#27169;&#22411;&#32467;&#26500;&#65292;&#26080;&#27861;&#30452;&#25509;&#24212;&#29992;&#22522;&#20110;&#27700;&#24179;FL&#30340;&#25216;&#26415;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#36731;&#37327;&#32423;&#32437;&#21521;&#32852;&#37030;&#23398;&#20064;&#65288;LVFL&#65289;&#30340;&#27010;&#24565;&#65292;&#26088;&#22312;&#25552;&#39640;&#35745;&#31639;&#21644;&#36890;&#20449;&#25928;&#29575;&#12290;&#36825;&#31181;&#26041;&#27861;&#28041;&#21450;&#38024;&#23545;&#29305;&#24449;&#27169;&#22411;&#30340;&#21333;&#29420;&#36731;&#37327;&#21270;&#31574;&#30053;&#65292;&#20197;&#25552;&#39640;&#35745;&#31639;&#25928;&#29575;&#65292;&#24182;&#38024;&#23545;&#29305;&#24449;&#23884;&#20837;&#36827;&#34892;&#36731;&#37327;&#21270;&#65292;&#20197;&#22686;&#24378;&#36890;&#20449;&#25928;&#29575;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20026;LVFL&#31639;&#27861;&#24314;&#31435;&#20102;&#25910;&#25947;&#30028;&#38480;&#65292;&#32771;&#34385;&#20102;&#36890;&#20449;&#21644;&#35745;&#31639;&#36731;&#37327;&#21270;&#27604;&#29575;&#12290;&#25105;&#20204;&#22312;&#22270;&#20687;&#20998;&#31867;&#25968;&#25454;&#38598;&#19978;&#23545;&#35813;&#31639;&#27861;&#36827;&#34892;&#35780;&#20272;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;LVFL&#26174;&#33879;&#20943;&#36731;&#20102;c
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00466v1 Announce Type: new  Abstract: The exploration of computational and communication efficiency within Federated Learning (FL) has emerged as a prominent and crucial field of study. While most existing efforts to enhance these efficiencies have focused on Horizontal FL, the distinct processes and model structures of Vertical FL preclude the direct application of Horizontal FL-based techniques. In response, we introduce the concept of Lightweight Vertical Federated Learning (LVFL), targeting both computational and communication efficiencies. This approach involves separate lightweighting strategies for the feature model, to improve computational efficiency, and for feature embedding, to enhance communication efficiency. Moreover, we establish a convergence bound for our LVFL algorithm, which accounts for both communication and computational lightweighting ratios. Our evaluation of the algorithm on a image classification dataset reveals that LVFL significantly alleviates c
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#20174;&#25968;&#25454;&#12289;&#26234;&#33021;&#21644;&#32593;&#32476;&#30340;&#35282;&#24230;&#26469;&#23454;&#29616;6G&#21407;&#29983;AI&#30340;&#25361;&#25112;&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;&#22522;&#30784;&#27169;&#22411;&#30340;6G&#21407;&#29983;AI&#26694;&#26550;&#65292;&#21253;&#25324;&#33258;&#23450;&#20041;&#26041;&#27861;&#21644;&#20219;&#21153;&#23548;&#21521;&#30340;AI&#24037;&#20855;&#21253;&#65292;&#20197;&#21450;&#26032;&#30340;&#20113;&#36793;&#32536;&#21327;&#21516;&#21512;&#20316;&#33539;&#24335;&#12290;</title><link>http://arxiv.org/abs/2310.17471</link><description>&lt;p&gt;
&#22522;&#20110;&#22522;&#30784;&#27169;&#22411;&#30340;6G&#21407;&#29983;AI&#26694;&#26550;&#19982;&#20113;&#36793;&#32536;&#21327;&#21516;&#21512;&#20316;
&lt;/p&gt;
&lt;p&gt;
Foundation Model Based Native AI Framework in 6G with Cloud-Edge-End Collaboration. (arXiv:2310.17471v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17471
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#20174;&#25968;&#25454;&#12289;&#26234;&#33021;&#21644;&#32593;&#32476;&#30340;&#35282;&#24230;&#26469;&#23454;&#29616;6G&#21407;&#29983;AI&#30340;&#25361;&#25112;&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;&#22522;&#30784;&#27169;&#22411;&#30340;6G&#21407;&#29983;AI&#26694;&#26550;&#65292;&#21253;&#25324;&#33258;&#23450;&#20041;&#26041;&#27861;&#21644;&#20219;&#21153;&#23548;&#21521;&#30340;AI&#24037;&#20855;&#21253;&#65292;&#20197;&#21450;&#26032;&#30340;&#20113;&#36793;&#32536;&#21327;&#21516;&#21512;&#20316;&#33539;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26410;&#26469;&#30340;&#26080;&#32447;&#36890;&#20449;&#32593;&#32476;&#26377;&#26395;&#36229;&#36234;&#20197;&#25968;&#25454;&#20026;&#20013;&#24515;&#12289;&#20197;&#35774;&#22791;&#20026;&#23548;&#21521;&#30340;&#36830;&#25509;&#26041;&#24335;&#65292;&#25552;&#20379;&#22522;&#20110;&#20219;&#21153;&#23548;&#21521;&#36830;&#25509;&#30340;&#26234;&#33021;&#27785;&#28024;&#24335;&#20307;&#39564;&#65292;&#29305;&#21035;&#26159;&#22312;&#39044;&#35757;&#32451;&#22522;&#30784;&#27169;&#22411;&#65288;PFM&#65289;&#30340;&#24555;&#36895;&#21457;&#23637;&#21644;6G&#21407;&#29983;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#30340;&#21457;&#23637;&#24895;&#26223;&#19979;&#12290;&#22240;&#27492;&#65292;&#22312;6G&#20013;&#65292;&#37325;&#26032;&#23450;&#20041;&#35774;&#22791;&#21644;&#26381;&#21153;&#22120;&#20043;&#38388;&#30340;&#21327;&#20316;&#27169;&#24335;&#65292;&#26500;&#24314;&#21407;&#29983;&#26234;&#33021;&#24211;&#21464;&#24471;&#38750;&#24120;&#37325;&#35201;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20174;&#25968;&#25454;&#12289;&#26234;&#33021;&#21644;&#32593;&#32476;&#30340;&#35282;&#24230;&#20998;&#26512;&#20102;&#23454;&#29616;6G&#21407;&#29983;AI&#30340;&#25361;&#25112;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#22522;&#20110;&#22522;&#30784;&#27169;&#22411;&#25552;&#20986;&#20102;&#19968;&#20010;6G&#21407;&#29983;AI&#26694;&#26550;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#24847;&#22270;&#24863;&#30693;PFM&#30340;&#23450;&#21046;&#26041;&#27861;&#65292;&#23637;&#31034;&#20102;&#19968;&#20010;&#38754;&#21521;&#20219;&#21153;&#30340;AI&#24037;&#20855;&#21253;&#30340;&#26500;&#24314;&#65292;&#24182;&#27010;&#36848;&#20102;&#19968;&#31181;&#20840;&#26032;&#30340;&#20113;&#36793;&#32536;&#21327;&#21516;&#21512;&#20316;&#33539;&#24335;&#12290;&#20316;&#20026;&#19968;&#20010;&#23454;&#38469;&#30340;&#20351;&#29992;&#26696;&#20363;&#65292;&#25105;&#20204;&#23558;&#35813;&#26694;&#26550;&#24212;&#29992;&#20110;&#32534;&#25490;&#65292;&#23454;&#29616;&#20102;&#26080;&#32447;&#36890;&#20449;&#20013;&#30340;&#26368;&#22823;&#36895;&#29575;&#20043;&#21644;&#12290;
&lt;/p&gt;
&lt;p&gt;
Future wireless communication networks are in a position to move beyond data-centric, device-oriented connectivity and offer intelligent, immersive experiences based on task-oriented connections, especially in the context of the thriving development of pre-trained foundation models (PFM) and the evolving vision of 6G native artificial intelligence (AI). Therefore, redefining modes of collaboration between devices and servers and constructing native intelligence libraries become critically important in 6G. In this paper, we analyze the challenges of achieving 6G native AI from the perspectives of data, intelligence, and networks. Then, we propose a 6G native AI framework based on foundation models, provide a customization approach for intent-aware PFM, present a construction of a task-oriented AI toolkit, and outline a novel cloud-edge-end collaboration paradigm. As a practical use case, we apply this framework for orchestration, achieving the maximum sum rate within a wireless communic
&lt;/p&gt;</description></item></channel></rss>