<rss version="2.0"><channel><title>Chat Arxiv cs.DC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.DC</description><item><title>UniAP&#26159;&#19968;&#31181;&#26032;&#22411;&#30340;&#33258;&#21160;&#24182;&#34892;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#28151;&#21512;&#25972;&#25968;&#20108;&#27425;&#35268;&#21010;&#32479;&#19968;&#36328;&#23618;&#21644;&#20869;&#23618;&#30340;&#33258;&#21160;&#24182;&#34892;&#21270;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;UniAP&#22312;&#21534;&#21520;&#37327;&#26041;&#38754;&#34920;&#29616;&#26356;&#22909;&#65292;&#24182;&#19988;&#20943;&#23569;&#20102;&#31574;&#30053;&#20248;&#21270;&#26102;&#38388;&#12290;</title><link>https://arxiv.org/abs/2307.16375</link><description>&lt;p&gt;
UniAP: &#36890;&#36807;&#28151;&#21512;&#25972;&#25968;&#20108;&#27425;&#35268;&#21010;&#32479;&#19968;&#36328;&#23618;&#21644;&#20869;&#23618;&#33258;&#21160;&#24182;&#34892;&#21270;
&lt;/p&gt;
&lt;p&gt;
UniAP: Unifying Inter- and Intra-Layer Automatic Parallelism by Mixed Integer Quadratic Programming
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2307.16375
&lt;/p&gt;
&lt;p&gt;
UniAP&#26159;&#19968;&#31181;&#26032;&#22411;&#30340;&#33258;&#21160;&#24182;&#34892;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#28151;&#21512;&#25972;&#25968;&#20108;&#27425;&#35268;&#21010;&#32479;&#19968;&#36328;&#23618;&#21644;&#20869;&#23618;&#30340;&#33258;&#21160;&#24182;&#34892;&#21270;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;UniAP&#22312;&#21534;&#21520;&#37327;&#26041;&#38754;&#34920;&#29616;&#26356;&#22909;&#65292;&#24182;&#19988;&#20943;&#23569;&#20102;&#31574;&#30053;&#20248;&#21270;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#24335;&#23398;&#20064;&#24120;&#29992;&#20110;&#35757;&#32451;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#29305;&#21035;&#26159;&#22823;&#22411;&#27169;&#22411;&#12290;&#22312;&#20998;&#24067;&#24335;&#23398;&#20064;&#20013;&#65292;&#25163;&#21160;&#24182;&#34892;&#21270;&#26041;&#27861;&#38656;&#35201;&#22823;&#37327;&#20154;&#21147;&#65292;&#24182;&#19988;&#28789;&#27963;&#24615;&#26377;&#38480;&#12290;&#22240;&#27492;&#65292;&#26368;&#36817;&#25552;&#20986;&#20102;&#33258;&#21160;&#24182;&#34892;&#21270;&#26041;&#27861;&#26469;&#33258;&#21160;&#21270;&#24182;&#34892;&#31574;&#30053;&#20248;&#21270;&#36807;&#31243;&#12290;&#29616;&#26377;&#30340;&#33258;&#21160;&#24182;&#34892;&#21270;&#26041;&#27861;&#23384;&#22312;&#27425;&#20248;&#35299;&#30340;&#38382;&#39064;&#65292;&#22240;&#20026;&#23427;&#20204;&#19981;&#20250;&#21516;&#26102;&#20248;&#21270;&#36328;&#23618;&#24182;&#34892;&#21270;&#21644;&#20869;&#23618;&#24182;&#34892;&#21270;&#36825;&#20004;&#20010;&#31867;&#21035;&#30340;&#24182;&#34892;&#31574;&#30053;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;UniAP&#30340;&#26032;&#22411;&#33258;&#21160;&#24182;&#34892;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#28151;&#21512;&#25972;&#25968;&#20108;&#27425;&#35268;&#21010;&#32479;&#19968;&#36328;&#23618;&#21644;&#20869;&#23618;&#30340;&#33258;&#21160;&#24182;&#34892;&#21270;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;UniAP&#26159;&#31532;&#19968;&#31181;&#33021;&#22815;&#21516;&#26102;&#20248;&#21270;&#36825;&#20004;&#20010;&#31867;&#21035;&#30340;&#24182;&#34892;&#31574;&#30053;&#20197;&#27714;&#24471;&#26368;&#20248;&#35299;&#30340;&#24182;&#34892;&#21270;&#26041;&#27861;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;UniAP&#22312;&#21534;&#21520;&#37327;&#26041;&#38754;&#32988;&#36807;&#20102;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#65292;&#25552;&#39640;&#20102;&#26368;&#22810;1.71&#20493;&#65292;&#24182;&#20943;&#23569;&#20102;&#31574;&#30053;&#20248;&#21270;&#30340;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
Distributed learning is commonly used for training deep learning models, especially large models. In distributed learning, manual parallelism (MP) methods demand considerable human effort and have limited flexibility. Hence, automatic parallelism (AP) methods have recently been proposed for automating the parallel strategy optimization process. Existing AP methods suffer from sub-optimal solutions because they do not jointly optimize the two categories of parallel strategies (i.e., inter-layer parallelism and intra-layer parallelism). In this paper, we propose a novel AP method called UniAP, which unifies inter- and intra-layer automatic parallelism by mixed integer quadratic programming. To the best of our knowledge, UniAP is the first parallel method that can jointly optimize the two categories of parallel strategies to find an optimal solution. Experimental results show that UniAP outperforms state-of-the-art methods by up to 1.71$\times$ in throughput and reduces strategy optimizat
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30772;&#20135;&#38382;&#39064;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#22402;&#30452;&#32852;&#37030;&#23398;&#20064;&#20013;&#28608;&#21169;&#20998;&#37197;&#30340;&#25361;&#25112;&#65292;&#20197;&#30830;&#20445;&#20844;&#24179;&#24615;&#21644;&#31283;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.03515</link><description>&lt;p&gt;
&#22522;&#20110;&#30772;&#20135;&#38382;&#39064;&#30340;&#22402;&#30452;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#28608;&#21169;&#20998;&#37197;
&lt;/p&gt;
&lt;p&gt;
Incentive Allocation in Vertical Federated Learning Based on Bankruptcy Problem. (arXiv:2307.03515v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03515
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30772;&#20135;&#38382;&#39064;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#22402;&#30452;&#32852;&#37030;&#23398;&#20064;&#20013;&#28608;&#21169;&#20998;&#37197;&#30340;&#25361;&#25112;&#65292;&#20197;&#30830;&#20445;&#20844;&#24179;&#24615;&#21644;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22402;&#30452;&#32852;&#37030;&#23398;&#20064;&#65288;VFL&#65289;&#26159;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#21512;&#20316;&#35757;&#32451;&#22312;&#19981;&#21516;&#21442;&#19982;&#26041;&#20043;&#38388;&#22402;&#30452;&#21010;&#20998;&#30340;&#31169;&#26377;&#25968;&#25454;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#12290;&#22312;VFL&#35774;&#32622;&#20013;&#65292;&#29702;&#24819;&#24773;&#20917;&#19979;&#65292;&#20027;&#21160;&#26041;&#65288;&#25317;&#26377;&#24102;&#26631;&#31614;&#26679;&#26412;&#29305;&#24449;&#30340;&#21442;&#19982;&#26041;&#65289;&#36890;&#36807;&#19982;&#26576;&#20123;&#34987;&#21160;&#26041;&#65288;&#25317;&#26377;&#30456;&#21516;&#26679;&#26412;&#20294;&#27809;&#26377;&#26631;&#31614;&#30340;&#39069;&#22806;&#29305;&#24449;&#30340;&#21442;&#19982;&#26041;&#65289;&#21512;&#20316;&#65292;&#22312;&#20445;&#25252;&#38544;&#31169;&#30340;&#24773;&#20917;&#19979;&#25913;&#36827;&#20854;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#28608;&#21169;&#34987;&#21160;&#26041;&#21442;&#19982;VFL&#21487;&#33021;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#37325;&#28857;&#30740;&#31350;&#20102;&#22522;&#20110;&#34987;&#21160;&#26041;&#22312;VFL&#36807;&#31243;&#20013;&#30340;&#36129;&#29486;&#26469;&#20026;&#20182;&#20204;&#20998;&#37197;&#28608;&#21169;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#38382;&#39064;&#23450;&#20041;&#20026;&#26680;&#24515;&#28216;&#25103;&#35770;&#27010;&#24565;&#30340;&#19968;&#31181;&#21464;&#20307;&#8212;&#8212;&#30772;&#20135;&#38382;&#39064;&#65292;&#24182;&#20351;&#29992;&#22612;&#26408;&#24503;&#21010;&#20998;&#35268;&#21017;&#26469;&#35299;&#20915;&#23427;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#23427;&#30830;&#20445;&#20102;&#28608;&#21169;&#30340;&#20844;&#24179;&#24615;&#21644;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Vertical federated learning (VFL) is a promising approach for collaboratively training machine learning models using private data partitioned vertically across different parties. Ideally in a VFL setting, the active party (party possessing features of samples with labels) benefits by improving its machine learning model through collaboration with some passive parties (parties possessing additional features of the same samples without labels) in a privacy preserving manner. However, motivating passive parties to participate in VFL can be challenging. In this paper, we focus on the problem of allocating incentives to the passive parties by the active party based on their contributions to the VFL process. We formulate this problem as a variant of the Nucleolus game theory concept, known as the Bankruptcy Problem, and solve it using the Talmud's division rule. We evaluate our proposed method on synthetic and real-world datasets and show that it ensures fairness and stability in incentive a
&lt;/p&gt;</description></item></channel></rss>