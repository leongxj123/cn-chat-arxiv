<rss version="2.0"><channel><title>Chat Arxiv cs.DC</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.DC</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#8212;&#8212;&#24378;&#21270;&#32852;&#37030;&#23398;&#20064;&#65288;RFL&#65289;&#65292;&#36890;&#36807;&#21033;&#29992;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#33258;&#36866;&#24212;&#22320;&#20248;&#21270;&#23458;&#25143;&#36129;&#29486;&#30340;&#32858;&#21512;&#36807;&#31243;&#65292;&#20197;&#22686;&#24378;&#27169;&#22411;&#40065;&#26834;&#24615;&#21644;&#22312;&#38750;&#30456;&#21516;&#20998;&#24067;&#29615;&#22659;&#19979;&#21442;&#19982;&#32773;&#20043;&#38388;&#30340;&#20844;&#24179;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.05541</link><description>&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#20316;&#20026;&#40065;&#26834;&#21644;&#20844;&#24179;&#32852;&#37030;&#23398;&#20064;&#30340;&#20652;&#21270;&#21058;&#65306;&#35299;&#23494;&#23458;&#25143;&#36129;&#29486;&#21160;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning as a Catalyst for Robust and Fair Federated Learning: Deciphering the Dynamics of Client Contributions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05541
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#8212;&#8212;&#24378;&#21270;&#32852;&#37030;&#23398;&#20064;&#65288;RFL&#65289;&#65292;&#36890;&#36807;&#21033;&#29992;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#33258;&#36866;&#24212;&#22320;&#20248;&#21270;&#23458;&#25143;&#36129;&#29486;&#30340;&#32858;&#21512;&#36807;&#31243;&#65292;&#20197;&#22686;&#24378;&#27169;&#22411;&#40065;&#26834;&#24615;&#21644;&#22312;&#38750;&#30456;&#21516;&#20998;&#24067;&#29615;&#22659;&#19979;&#21442;&#19982;&#32773;&#20043;&#38388;&#30340;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22312;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#26041;&#38754;&#30340;&#36827;&#23637;&#20135;&#29983;&#20102;&#27169;&#22411;&#65292;&#36890;&#36807;&#22312;&#22810;&#20010;&#20998;&#25955;&#30340;&#35774;&#22791;&#25110;&#31995;&#32479;&#19978;&#35757;&#32451;&#26469;&#20445;&#25252;&#29992;&#25143;&#38544;&#31169;&#24182;&#20445;&#30041;&#26412;&#22320;&#25968;&#25454;&#26679;&#26412;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#31574;&#30053;&#32463;&#24120;&#24573;&#35270;&#32479;&#35745;&#24322;&#36136;&#24615;&#21644;&#23545;&#25932;&#23545;&#25915;&#20987;&#30340;&#33030;&#24369;&#24615;&#25152;&#24102;&#26469;&#30340;&#22256;&#38590;&#65292;&#36825;&#20123;&#22240;&#32032;&#20250;&#38477;&#20302;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#21644;&#20844;&#24179;&#24615;&#12290;&#20010;&#24615;&#21270;&#30340;FL&#31574;&#30053;&#21487;&#20197;&#36890;&#36807;&#35843;&#25972;&#27169;&#22411;&#26469;&#36866;&#24212;&#20010;&#21035;&#23458;&#25143;&#30340;&#29305;&#28857;&#65292;&#20294;&#24448;&#24448;&#24573;&#35270;&#20102;&#26381;&#21153;&#22120;&#31471;&#32858;&#21512;&#30340;&#33030;&#24369;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#24378;&#21270;&#32852;&#37030;&#23398;&#20064;&#65288;RFL&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#21033;&#29992;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#26469;&#33258;&#36866;&#24212;&#20248;&#21270;&#32858;&#21512;&#36807;&#31243;&#20013;&#23458;&#25143;&#36129;&#29486;&#30340;&#26032;&#26694;&#26550;&#65292;&#20174;&#32780;&#22686;&#24378;&#24694;&#24847;&#23458;&#25143;&#19979;&#30340;&#27169;&#22411;&#40065;&#26834;&#24615;&#21644;&#21442;&#19982;&#32773;&#20043;&#38388;&#30340;&#20844;&#24179;&#24615;&#22312;&#38750;&#30456;&#21516;&#20998;&#24067;&#29615;&#22659;&#19979;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32454;&#33268;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;&#21253;&#25324;&#22522;&#20110;&#28145;&#24230;&#30830;&#23450;&#24615;&#31574;&#30053;&#26799;&#24230;&#31639;&#27861;&#30340;&#21327;&#21516;&#35757;&#32451;&#65292;&#20197;&#20248;&#21270;&#23458;&#25143;&#36129;&#29486;&#30340;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advancements in federated learning (FL) have produced models that retain user privacy by training across multiple decentralized devices or systems holding local data samples. However, these strategies often neglect the inherent challenges of statistical heterogeneity and vulnerability to adversarial attacks, which can degrade model robustness and fairness. Personalized FL strategies offer some respite by adjusting models to fit individual client profiles, yet they tend to neglect server-side aggregation vulnerabilities. To address these issues, we propose Reinforcement Federated Learning (RFL), a novel framework that leverages deep reinforcement learning to adaptively optimize client contribution during aggregation, thereby enhancing both model robustness against malicious clients and fairness across participants under non-identically distributed settings. To achieve this goal, we propose a meticulous approach involving a Deep Deterministic Policy Gradient-based algorithm for co
&lt;/p&gt;</description></item><item><title>OneAdapt&#36890;&#36807;&#26799;&#24230;&#19978;&#21319;&#31574;&#30053;&#26469;&#23454;&#29616;&#24555;&#36895;&#33258;&#36866;&#24212;&#65292;&#28385;&#36275;&#20102;&#28145;&#24230;&#23398;&#20064;&#24212;&#29992;&#22312;&#37197;&#32622;&#21442;&#25968;&#26041;&#38754;&#30340;&#19977;&#20010;&#35201;&#27714;&#12290;</title><link>http://arxiv.org/abs/2310.02422</link><description>&lt;p&gt;
OneAdapt&#65306;&#36890;&#36807;&#21453;&#21521;&#20256;&#25773;&#23454;&#29616;&#28145;&#24230;&#23398;&#20064;&#24212;&#29992;&#30340;&#24555;&#36895;&#33258;&#36866;&#24212;
&lt;/p&gt;
&lt;p&gt;
OneAdapt: Fast Adaptation for Deep Learning Applications via Backpropagation. (arXiv:2310.02422v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02422
&lt;/p&gt;
&lt;p&gt;
OneAdapt&#36890;&#36807;&#26799;&#24230;&#19978;&#21319;&#31574;&#30053;&#26469;&#23454;&#29616;&#24555;&#36895;&#33258;&#36866;&#24212;&#65292;&#28385;&#36275;&#20102;&#28145;&#24230;&#23398;&#20064;&#24212;&#29992;&#22312;&#37197;&#32622;&#21442;&#25968;&#26041;&#38754;&#30340;&#19977;&#20010;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#22312;&#27969;&#23186;&#20307;&#25968;&#25454;&#30340;&#25512;&#26029;&#26041;&#38754;&#24050;&#32463;&#26222;&#21450;&#65292;&#22914;&#35270;&#39057;&#20013;&#30340;&#30446;&#26631;&#26816;&#27979;&#12289;LiDAR&#25968;&#25454;&#21644;&#38899;&#39057;&#27874;&#24418;&#20013;&#30340;&#25991;&#26412;&#25552;&#21462;&#12290;&#20026;&#20102;&#23454;&#29616;&#39640;&#25512;&#26029;&#20934;&#30830;&#24615;&#65292;&#36825;&#20123;&#24212;&#29992;&#36890;&#24120;&#38656;&#35201;&#22823;&#37327;&#30340;&#32593;&#32476;&#24102;&#23485;&#26469;&#25910;&#38598;&#39640;&#20445;&#30495;&#25968;&#25454;&#65292;&#24182;&#19988;&#38656;&#35201;&#24191;&#27867;&#30340;GPU&#36164;&#28304;&#26469;&#36816;&#34892;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNN)&#12290;&#23613;&#31649;&#36890;&#36807;&#20248;&#21270;&#37197;&#32622;&#21442;&#25968;&#65288;&#22914;&#35270;&#39057;&#20998;&#36776;&#29575;&#21644;&#24103;&#29575;&#65289;&#21487;&#20197;&#22823;&#22823;&#20943;&#23569;&#23545;&#32593;&#32476;&#24102;&#23485;&#21644;GPU&#36164;&#28304;&#30340;&#38656;&#27714;&#65292;&#20294;&#30446;&#21069;&#30340;&#33258;&#36866;&#24212;&#25216;&#26415;&#26080;&#27861;&#21516;&#26102;&#28385;&#36275;&#19977;&#20010;&#35201;&#27714;&#65306;&#65288;i&#65289;&#20197;&#26368;&#23567;&#30340;&#39069;&#22806;GPU&#25110;&#24102;&#23485;&#24320;&#38144;&#26469;&#33258;&#36866;&#24212;&#37197;&#32622;&#65307;&#65288;ii&#65289;&#22522;&#20110;&#25968;&#25454;&#23545;&#26368;&#32456;DNN&#30340;&#20934;&#30830;&#24615;&#30340;&#24433;&#21709;&#26469;&#36798;&#21040;&#25509;&#36817;&#26368;&#20248;&#30340;&#20915;&#31574;&#65307;&#65288;iii&#65289;&#38024;&#23545;&#19968;&#31995;&#21015;&#37197;&#32622;&#21442;&#25968;&#36827;&#34892;&#33258;&#36866;&#24212;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;OneAdapt&#65292;&#36890;&#36807;&#21033;&#29992;&#26799;&#24230;&#19978;&#21319;&#31574;&#30053;&#26469;&#33258;&#36866;&#24212;&#37197;&#32622;&#21442;&#25968;&#65292;&#28385;&#36275;&#20102;&#36825;&#20123;&#35201;&#27714;&#12290;&#20851;&#38190;&#24605;&#24819;&#26159;&#20805;&#20998;&#21033;&#29992;DNN&#30340;&#19981;&#21516;
&lt;/p&gt;
&lt;p&gt;
Deep learning inference on streaming media data, such as object detection in video or LiDAR feeds and text extraction from audio waves, is now ubiquitous. To achieve high inference accuracy, these applications typically require significant network bandwidth to gather high-fidelity data and extensive GPU resources to run deep neural networks (DNNs). While the high demand for network bandwidth and GPU resources could be substantially reduced by optimally adapting the configuration knobs, such as video resolution and frame rate, current adaptation techniques fail to meet three requirements simultaneously: adapt configurations (i) with minimum extra GPU or bandwidth overhead; (ii) to reach near-optimal decisions based on how the data affects the final DNN's accuracy, and (iii) do so for a range of configuration knobs. This paper presents OneAdapt, which meets these requirements by leveraging a gradient-ascent strategy to adapt configuration knobs. The key idea is to embrace DNNs' different
&lt;/p&gt;</description></item></channel></rss>