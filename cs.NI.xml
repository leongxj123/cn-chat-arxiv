<rss version="2.0"><channel><title>Chat Arxiv cs.NI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NI</description><item><title>LAMBO&#26159;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#36793;&#32536;&#26234;&#33021;&#26694;&#26550;&#65292;&#29992;&#20110;&#31227;&#21160;&#36793;&#32536;&#35745;&#31639;&#12290;&#23427;&#35299;&#20915;&#20102;&#20256;&#32479;&#28145;&#24230;&#21368;&#36733;&#26550;&#26500;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#39640;&#24615;&#33021;&#30340;&#20915;&#31574;&#27169;&#22359;&#21644;&#24378;&#21270;&#23398;&#20064;&#27169;&#22359;&#12290;</title><link>http://arxiv.org/abs/2308.15078</link><description>&lt;p&gt;
LAMBO: &#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22686;&#24378;&#30340;&#36793;&#32536;&#26234;&#33021;
&lt;/p&gt;
&lt;p&gt;
LAMBO: Large Language Model Empowered Edge Intelligence. (arXiv:2308.15078v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15078
&lt;/p&gt;
&lt;p&gt;
LAMBO&#26159;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#36793;&#32536;&#26234;&#33021;&#26694;&#26550;&#65292;&#29992;&#20110;&#31227;&#21160;&#36793;&#32536;&#35745;&#31639;&#12290;&#23427;&#35299;&#20915;&#20102;&#20256;&#32479;&#28145;&#24230;&#21368;&#36733;&#26550;&#26500;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#39640;&#24615;&#33021;&#30340;&#20915;&#31574;&#27169;&#22359;&#21644;&#24378;&#21270;&#23398;&#20064;&#27169;&#22359;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35745;&#19979;&#19968;&#20195;&#36793;&#32536;&#26234;&#33021;&#23558;&#20026;&#21508;&#31181;&#24212;&#29992;&#24102;&#26469;&#24040;&#22823;&#30340;&#22909;&#22788;&#65292;&#20363;&#22914;&#21368;&#36733;&#31995;&#32479;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30340;&#28145;&#24230;&#21368;&#36733;&#26550;&#26500;&#38754;&#20020;&#22810;&#20010;&#38382;&#39064;&#65292;&#21253;&#25324;&#24322;&#26500;&#38480;&#21046;&#12289;&#37096;&#20998;&#24863;&#30693;&#12289;&#19981;&#30830;&#23450;&#30340;&#27867;&#21270;&#21644;&#32570;&#20047;&#21487;&#36861;&#28335;&#24615;&#12290;&#22312;&#36825;&#31181;&#32972;&#26223;&#19979;&#65292;&#23558;&#21368;&#36733;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#38598;&#25104;&#22312;&#19968;&#36215;&#20855;&#26377;&#35768;&#22810;&#20248;&#21183;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;LLM&#30340;&#21368;&#36733;&#65288;LAMBO&#65289;&#26694;&#26550;&#65292;&#29992;&#20110;&#31227;&#21160;&#36793;&#32536;&#35745;&#31639;&#65288;MEC&#65289;&#65292;&#23427;&#30001;&#22235;&#20010;&#32452;&#25104;&#37096;&#20998;&#32452;&#25104;&#65306;&#65288;i&#65289;&#36755;&#20837;&#23884;&#20837;&#65288;IE&#65289;&#65292;&#29992;&#20110;&#29992;&#39640;&#36136;&#37327;&#30340;&#21487;&#23398;&#20064;&#21521;&#37327;&#34920;&#31034;&#20855;&#26377;&#32422;&#26463;&#21644;&#25552;&#31034;&#30340;&#21368;&#36733;&#31995;&#32479;&#30340;&#20449;&#24687;&#65307;&#65288;ii&#65289;&#38750;&#23545;&#31216;&#32534;&#30721;&#35299;&#30721;&#65288;AED&#65289;&#27169;&#22411;&#65292;&#26159;&#19968;&#20010;&#20915;&#31574;&#27169;&#22359;&#65292;&#20855;&#26377;&#28145;&#24230;&#32534;&#30721;&#22120;&#21644;&#27973;&#23618;&#35299;&#30721;&#22120;&#12290;&#23427;&#21487;&#20197;&#22522;&#20110;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#23454;&#29616;&#39640;&#24615;&#33021;&#65307;&#65288;iii&#65289;&#28436;&#21592;-&#35780;&#35770;&#23478;&#24378;&#21270;&#23398;&#20064;&#65288;ACRL&#65289;&#27169;&#22359;&#65292;&#29992;&#20110;&#36827;&#34892;&#39044;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
Next-generation edge intelligence is anticipated to bring huge benefits to various applications, e.g., offloading systems. However, traditional deep offloading architectures face several issues, including heterogeneous constraints, partial perception, uncertain generalization, and lack of tractability. In this context, the integration of offloading with large language models (LLMs) presents numerous advantages. Therefore, we propose an LLM-Based Offloading (LAMBO) framework for mobile edge computing (MEC), which comprises four components: (i) Input embedding (IE), which is used to represent the information of the offloading system with constraints and prompts through learnable vectors with high quality; (ii) Asymmetric encoderdecoder (AED) model, which is a decision-making module with a deep encoder and a shallow decoder. It can achieve high performance based on multi-head self-attention schemes; (iii) Actor-critic reinforcement learning (ACRL) module, which is employed to pre-train th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;AI&#27169;&#22411;&#30340;&#35821;&#20041;&#36890;&#20449;&#26694;&#26550;&#65288;LAM-SC&#65289;&#65292;&#21033;&#29992;&#35813;&#26694;&#26550;&#21487;&#20197;&#20811;&#26381;&#30693;&#35782;&#24211;&#26500;&#24314;&#36807;&#31243;&#20013;&#38754;&#20020;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#22270;&#20687;&#25968;&#25454;&#39046;&#22495;&#23454;&#29616;&#20102;&#35821;&#20041;&#20998;&#21106;&#12289;&#35821;&#20041;&#38598;&#25104;&#21644;&#33258;&#36866;&#24212;&#35821;&#20041;&#21387;&#32553;&#12290;</title><link>http://arxiv.org/abs/2307.03492</link><description>&lt;p&gt;
&#22522;&#20110;&#22823;&#22411;AI&#27169;&#22411;&#30340;&#35821;&#20041;&#36890;&#20449;
&lt;/p&gt;
&lt;p&gt;
Large AI Model-Based Semantic Communications. (arXiv:2307.03492v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03492
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;AI&#27169;&#22411;&#30340;&#35821;&#20041;&#36890;&#20449;&#26694;&#26550;&#65288;LAM-SC&#65289;&#65292;&#21033;&#29992;&#35813;&#26694;&#26550;&#21487;&#20197;&#20811;&#26381;&#30693;&#35782;&#24211;&#26500;&#24314;&#36807;&#31243;&#20013;&#38754;&#20020;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#22270;&#20687;&#25968;&#25454;&#39046;&#22495;&#23454;&#29616;&#20102;&#35821;&#20041;&#20998;&#21106;&#12289;&#35821;&#20041;&#38598;&#25104;&#21644;&#33258;&#36866;&#24212;&#35821;&#20041;&#21387;&#32553;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#20041;&#36890;&#20449;&#65288;SC&#65289;&#26159;&#19968;&#31181;&#26032;&#20852;&#30340;&#26234;&#33021;&#33539;&#24335;&#65292;&#20026;&#20803;&#23431;&#23449;&#12289;&#28151;&#21512;&#29616;&#23454;&#21644;&#19975;&#29289;&#20114;&#32852;&#31561;&#26410;&#26469;&#24212;&#29992;&#25552;&#20379;&#35299;&#20915;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#22312;&#30446;&#21069;&#30340;SC&#31995;&#32479;&#20013;&#65292;&#30693;&#35782;&#24211;&#65288;KB&#65289;&#30340;&#26500;&#24314;&#38754;&#20020;&#30528;&#19968;&#20123;&#38382;&#39064;&#65292;&#21253;&#25324;&#30693;&#35782;&#34920;&#31034;&#26377;&#38480;&#12289;&#39057;&#32321;&#30340;&#30693;&#35782;&#26356;&#26032;&#21644;&#19981;&#23433;&#20840;&#30340;&#30693;&#35782;&#20849;&#20139;&#12290;&#24184;&#36816;&#30340;&#26159;&#65292;&#22823;&#22411;AI&#27169;&#22411;&#30340;&#21457;&#23637;&#25552;&#20379;&#20102;&#35299;&#20915;&#19978;&#36848;&#38382;&#39064;&#30340;&#26032;&#26041;&#26696;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;AI&#27169;&#22411;&#30340;SC&#26694;&#26550;&#65288;LAM-SC&#65289;&#65292;&#19987;&#38376;&#29992;&#20110;&#22270;&#20687;&#25968;&#25454;&#65292;&#25105;&#20204;&#39318;&#20808;&#35774;&#35745;&#20102;&#22522;&#20110;&#27573;&#33853;&#27169;&#22411;&#65288;SAM&#65289;&#30340;&#30693;&#35782;&#24211;&#65288;SKB&#65289;&#65292;&#23427;&#21487;&#20197;&#36890;&#36807;&#36890;&#29992;&#35821;&#20041;&#30693;&#35782;&#23558;&#21407;&#22987;&#22270;&#20687;&#21010;&#20998;&#20026;&#19981;&#21516;&#30340;&#35821;&#20041;&#27573;&#33853;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#35821;&#20041;&#38598;&#25104;&#65288;ASI&#65289;&#65292;&#36890;&#36807;&#26435;&#34913;&#30001;SKB&#29983;&#25104;&#30340;&#35821;&#20041;&#27573;&#33853;&#65292;&#26080;&#38656;&#20154;&#24037;&#21442;&#19982;&#24182;&#23558;&#23427;&#20204;&#38598;&#25104;&#20026;&#20855;&#26377;&#35821;&#20041;&#24863;&#30693;&#30340;&#22270;&#20687;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#35821;&#20041;&#21387;&#32553;&#65288;ASC&#65289;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Semantic communication (SC) is an emerging intelligent paradigm, offering solutions for various future applications like metaverse, mixed-reality, and the Internet of everything. However, in current SC systems, the construction of the knowledge base (KB) faces several issues, including limited knowledge representation, frequent knowledge updates, and insecure knowledge sharing. Fortunately, the development of the large AI model provides new solutions to overcome above issues. Here, we propose a large AI model-based SC framework (LAM-SC) specifically designed for image data, where we first design the segment anything model (SAM)-based KB (SKB) that can split the original image into different semantic segments by universal semantic knowledge. Then, we present an attention-based semantic integration (ASI) to weigh the semantic segments generated by SKB without human participation and integrate them as the semantic-aware image. Additionally, we propose an adaptive semantic compression (ASC
&lt;/p&gt;</description></item></channel></rss>