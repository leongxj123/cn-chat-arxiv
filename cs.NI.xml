<rss version="2.0"><channel><title>Chat Arxiv cs.NI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NI</description><item><title>ForestColl&#26159;&#19968;&#31181;&#38024;&#23545;&#20219;&#24847;&#32593;&#32476;&#25299;&#25169;&#29983;&#25104;&#39640;&#25928;&#35843;&#24230;&#30340;&#24037;&#20855;&#65292;&#36890;&#36807;&#26500;&#24314;&#24191;&#25773;/&#32858;&#21512;&#29983;&#25104;&#36328;&#36234;&#26641;&#30340;&#36890;&#20449;&#35843;&#24230;&#65292;&#23454;&#29616;&#20102;&#29702;&#35770;&#19978;&#30340;&#26368;&#23567;&#32593;&#32476;&#25317;&#22622;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#39640;&#20110;&#20379;&#24212;&#21830;&#33258;&#24102;&#36890;&#20449;&#24211;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.06787</link><description>&lt;p&gt;
ForestColl: &#24322;&#26500;&#32593;&#32476;&#32467;&#26500;&#19978;&#39640;&#25928;&#30340;&#38598;&#21512;&#36890;&#20449;
&lt;/p&gt;
&lt;p&gt;
ForestColl: Efficient Collective Communications on Heterogeneous Network Fabrics
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06787
&lt;/p&gt;
&lt;p&gt;
ForestColl&#26159;&#19968;&#31181;&#38024;&#23545;&#20219;&#24847;&#32593;&#32476;&#25299;&#25169;&#29983;&#25104;&#39640;&#25928;&#35843;&#24230;&#30340;&#24037;&#20855;&#65292;&#36890;&#36807;&#26500;&#24314;&#24191;&#25773;/&#32858;&#21512;&#29983;&#25104;&#36328;&#36234;&#26641;&#30340;&#36890;&#20449;&#35843;&#24230;&#65292;&#23454;&#29616;&#20102;&#29702;&#35770;&#19978;&#30340;&#26368;&#23567;&#32593;&#32476;&#25317;&#22622;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#39640;&#20110;&#20379;&#24212;&#21830;&#33258;&#24102;&#36890;&#20449;&#24211;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#29616;&#20195;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#36234;&#26469;&#36234;&#22823;&#65292;&#21152;&#36895;&#22120;&#20043;&#38388;&#30340;&#38598;&#21512;&#36890;&#20449;&#65288;&#22914;allreduce&#31561;&#65289;&#25104;&#20026;&#19968;&#20010;&#37325;&#35201;&#30340;&#24615;&#33021;&#29942;&#39048;&#12290;&#22312;&#24403;&#20170;&#39640;&#24230;&#22810;&#26679;&#21270;&#21644;&#24322;&#26500;&#30340;&#32593;&#32476;&#32467;&#26500;&#19979;&#35774;&#35745;&#39640;&#25928;&#30340;&#36890;&#20449;&#35843;&#24230;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ForestColl&#30340;&#24037;&#20855;&#65292;&#23427;&#33021;&#22815;&#20026;&#20219;&#24847;&#32593;&#32476;&#25299;&#25169;&#29983;&#25104;&#39640;&#25928;&#30340;&#35843;&#24230;&#12290;ForestColl&#20351;&#29992;&#24191;&#25773;/&#32858;&#21512;&#29983;&#25104;&#36328;&#36234;&#26641;&#20316;&#20026;&#36890;&#20449;&#35843;&#24230;&#65292;&#23454;&#29616;&#20102;&#29702;&#35770;&#19978;&#30340;&#26368;&#23567;&#32593;&#32476;&#25317;&#22622;&#12290;&#20854;&#35843;&#24230;&#29983;&#25104;&#36816;&#34892;&#22312;&#24378;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#65292;&#19988;&#20855;&#26377;&#39640;&#25193;&#23637;&#24615;&#12290;ForestColl&#25903;&#25345;&#21253;&#25324;&#20132;&#25442;&#32593;&#32476;&#21644;&#30452;&#25509;&#36830;&#25509;&#22312;&#20869;&#30340;&#20219;&#20309;&#32593;&#32476;&#32467;&#26500;&#65292;&#20197;&#21450;&#20219;&#20309;&#32593;&#32476;&#22270;&#32467;&#26500;&#12290;&#25105;&#20204;&#22312;&#22810;&#38598;&#32676;&#30340;AMD MI250&#21644;NVIDIA A100&#24179;&#21488;&#19978;&#35780;&#20272;&#20102;ForestColl&#12290;&#19982;&#20379;&#24212;&#21830;&#33258;&#24049;&#20248;&#21270;&#30340;&#36890;&#20449;&#24211;RCCL&#21644;NCCL&#30456;&#27604;&#65292;ForestColl&#30340;&#35843;&#24230;&#24615;&#33021;&#25552;&#39640;&#20102;&#39640;&#36798;52&#65285;&#12290;ForestColl&#36824;&#20248;&#20110;&#20854;&#20182;...
&lt;/p&gt;
&lt;p&gt;
As modern DNN models grow ever larger, collective communications between the accelerators (allreduce, etc.) emerge as a significant performance bottleneck. Designing efficient communication schedules is challenging given today's highly diverse and heterogeneous network fabrics. In this paper, we present ForestColl, a tool that generates efficient schedules for any network topology. ForestColl constructs broadcast/aggregation spanning trees as the communication schedule, achieving theoretically minimum network congestion. Its schedule generation runs in strongly polynomial time and is highly scalable. ForestColl supports any network fabrics, including both switching fabrics and direct connections, as well as any network graph structure. We evaluated ForestColl on multi-cluster AMD MI250 and NVIDIA A100 platforms. ForestColl's schedules achieved up to 52\% higher performance compared to the vendors' own optimized communication libraries, RCCL and NCCL. ForestColl also outperforms other s
&lt;/p&gt;</description></item></channel></rss>