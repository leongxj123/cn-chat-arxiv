<rss version="2.0"><channel><title>Chat Arxiv cs.NI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NI</description><item><title>&#35813;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#39640;&#31354;&#24179;&#21488;&#31449;&#65288;HAPS&#65289;&#20351;&#33021;&#30340;&#22402;&#30452;&#24322;&#26500;&#32593;&#32476;&#20013;&#25968;&#25454;&#20998;&#24067;&#19981;&#22343;&#38382;&#39064;&#30340;&#25112;&#30053;&#23458;&#25143;&#36873;&#25321;&#31574;&#30053;&#65292;&#36890;&#36807;&#21033;&#29992;&#29992;&#25143;&#30340;&#32593;&#32476;&#27969;&#37327;&#34892;&#20026;&#39044;&#27979;&#21644;&#20998;&#31867;&#65292;&#20248;&#20808;&#36873;&#25321;&#25968;&#25454;&#21576;&#29616;&#30456;&#20284;&#27169;&#24335;&#30340;&#23458;&#25143;&#21442;&#19982;&#65292;&#20197;&#25552;&#39640;&#32852;&#21512;&#23398;&#20064;&#65288;FL&#65289;&#27169;&#22411;&#30340;&#35757;&#32451;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2401.05308</link><description>&lt;p&gt;
&#38754;&#23545;HAPS&#20351;&#33021;&#30340;FL&#32593;&#32476;&#20013;&#30340;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#38382;&#39064;&#65292;&#25112;&#30053;&#23458;&#25143;&#36873;&#25321;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Strategic Client Selection to Address Non-IIDness in HAPS-enabled FL Networks. (arXiv:2401.05308v1 [cs.NI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05308
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#39640;&#31354;&#24179;&#21488;&#31449;&#65288;HAPS&#65289;&#20351;&#33021;&#30340;&#22402;&#30452;&#24322;&#26500;&#32593;&#32476;&#20013;&#25968;&#25454;&#20998;&#24067;&#19981;&#22343;&#38382;&#39064;&#30340;&#25112;&#30053;&#23458;&#25143;&#36873;&#25321;&#31574;&#30053;&#65292;&#36890;&#36807;&#21033;&#29992;&#29992;&#25143;&#30340;&#32593;&#32476;&#27969;&#37327;&#34892;&#20026;&#39044;&#27979;&#21644;&#20998;&#31867;&#65292;&#20248;&#20808;&#36873;&#25321;&#25968;&#25454;&#21576;&#29616;&#30456;&#20284;&#27169;&#24335;&#30340;&#23458;&#25143;&#21442;&#19982;&#65292;&#20197;&#25552;&#39640;&#32852;&#21512;&#23398;&#20064;&#65288;FL&#65289;&#27169;&#22411;&#30340;&#35757;&#32451;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#30001;&#39640;&#31354;&#24179;&#21488;&#31449;&#65288;HAPS&#65289;&#20351;&#33021;&#30340;&#22402;&#30452;&#24322;&#26500;&#32593;&#32476;&#20013;&#37096;&#32626;&#32852;&#21512;&#23398;&#20064;&#65288;FL&#65289;&#20026;&#21508;&#31181;&#19981;&#21516;&#36890;&#20449;&#21644;&#35745;&#31639;&#33021;&#21147;&#30340;&#23458;&#25143;&#25552;&#20379;&#20102;&#21442;&#19982;&#30340;&#26426;&#20250;&#12290;&#36825;&#31181;&#22810;&#26679;&#24615;&#19981;&#20165;&#25552;&#39640;&#20102;FL&#27169;&#22411;&#30340;&#35757;&#32451;&#31934;&#24230;&#65292;&#36824;&#21152;&#24555;&#20102;&#20854;&#25910;&#25947;&#36895;&#24230;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#20123;&#24191;&#38420;&#30340;&#32593;&#32476;&#20013;&#24212;&#29992;FL&#23384;&#22312;&#26174;&#33879;&#30340;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#38382;&#39064;&#12290;&#36825;&#31181;&#25968;&#25454;&#24322;&#36136;&#24615;&#24448;&#24448;&#23548;&#33268;&#25910;&#25947;&#36895;&#24230;&#36739;&#24930;&#21644;&#27169;&#22411;&#35757;&#32451;&#24615;&#33021;&#30340;&#38477;&#20302;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#38024;&#23545;&#27492;&#38382;&#39064;&#30340;&#23458;&#25143;&#36873;&#25321;&#31574;&#30053;&#65292;&#21033;&#29992;&#29992;&#25143;&#32593;&#32476;&#27969;&#37327;&#34892;&#20026;&#36827;&#34892;&#39044;&#27979;&#21644;&#20998;&#31867;&#12290;&#35813;&#31574;&#30053;&#36890;&#36807;&#25112;&#30053;&#24615;&#36873;&#25321;&#25968;&#25454;&#21576;&#29616;&#30456;&#20284;&#27169;&#24335;&#30340;&#23458;&#25143;&#21442;&#19982;&#65292;&#21516;&#26102;&#20248;&#20808;&#32771;&#34385;&#29992;&#25143;&#38544;&#31169;&#12290;
&lt;/p&gt;
&lt;p&gt;
The deployment of federated learning (FL) within vertical heterogeneous networks, such as those enabled by high-altitude platform station (HAPS), offers the opportunity to engage a wide array of clients, each endowed with distinct communication and computational capabilities. This diversity not only enhances the training accuracy of FL models but also hastens their convergence. Yet, applying FL in these expansive networks presents notable challenges, particularly the significant non-IIDness in client data distributions. Such data heterogeneity often results in slower convergence rates and reduced effectiveness in model training performance. Our study introduces a client selection strategy tailored to address this issue, leveraging user network traffic behaviour. This strategy involves the prediction and classification of clients based on their network usage patterns while prioritizing user privacy. By strategically selecting clients whose data exhibit similar patterns for participation
&lt;/p&gt;</description></item><item><title>OpsEval&#26159;&#19968;&#20010;&#20840;&#38754;&#20219;&#21153;&#23548;&#21521;&#30340;AIOps&#22522;&#20934;&#27979;&#35797;&#65292;&#35780;&#20272;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#26377;&#32447;&#32593;&#32476;&#25805;&#20316;&#12289;5G&#36890;&#20449;&#25805;&#20316;&#21644;&#25968;&#25454;&#24211;&#25805;&#20316;&#31561;&#20851;&#38190;&#22330;&#26223;&#19979;&#30340;&#33021;&#21147;&#27700;&#24179;&#65292;&#20026;&#25552;&#20379;&#38024;&#23545;AIOps&#23450;&#21046;&#30340;LLMs&#30340;&#20248;&#21270;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2310.07637</link><description>&lt;p&gt;
OpsEval: &#29992;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20840;&#38754;&#20219;&#21153;&#23548;&#21521;&#30340;AIOps&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
OpsEval: A Comprehensive Task-Oriented AIOps Benchmark for Large Language Models. (arXiv:2310.07637v2 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07637
&lt;/p&gt;
&lt;p&gt;
OpsEval&#26159;&#19968;&#20010;&#20840;&#38754;&#20219;&#21153;&#23548;&#21521;&#30340;AIOps&#22522;&#20934;&#27979;&#35797;&#65292;&#35780;&#20272;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#26377;&#32447;&#32593;&#32476;&#25805;&#20316;&#12289;5G&#36890;&#20449;&#25805;&#20316;&#21644;&#25968;&#25454;&#24211;&#25805;&#20316;&#31561;&#20851;&#38190;&#22330;&#26223;&#19979;&#30340;&#33021;&#21147;&#27700;&#24179;&#65292;&#20026;&#25552;&#20379;&#38024;&#23545;AIOps&#23450;&#21046;&#30340;LLMs&#30340;&#20248;&#21270;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(Large Language Models, LLMs)&#22312;&#32763;&#35793;&#12289;&#24635;&#32467;&#21644;&#29983;&#25104;&#31561;NLP&#30456;&#20851;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#20102;&#26174;&#33879;&#30340;&#33021;&#21147;&#12290;LLMs&#22312;&#29305;&#23450;&#39046;&#22495;&#20013;&#24212;&#29992;&#65292;&#29305;&#21035;&#26159;&#22312;AIOps&#65288;&#38754;&#21521;IT&#36816;&#32500;&#30340;&#20154;&#24037;&#26234;&#33021;&#65289;&#20013;&#65292;&#30001;&#20110;&#20854;&#20808;&#36827;&#30340;&#20449;&#24687;&#27719;&#24635;&#12289;&#25253;&#21578;&#20998;&#26512;&#21644;API&#35843;&#29992;&#33021;&#21147;&#32780;&#20855;&#26377;&#24040;&#22823;&#30340;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;LLMs&#22312;AIOps&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#23578;&#26410;&#30830;&#23450;&#12290;&#27492;&#22806;&#65292;&#38656;&#35201;&#19968;&#20010;&#20840;&#38754;&#30340;&#22522;&#20934;&#27979;&#35797;&#26469;&#24341;&#23548;&#38024;&#23545;AIOps&#23450;&#21046;&#30340;LLMs&#30340;&#20248;&#21270;&#12290;&#19982;&#29616;&#26377;&#30340;&#19987;&#27880;&#20110;&#35780;&#20272;&#32593;&#32476;&#37197;&#32622;&#31561;&#29305;&#23450;&#39046;&#22495;&#30340;&#22522;&#20934;&#27979;&#35797;&#19981;&#21516;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;OpsEval&#65292;&#36825;&#26159;&#19968;&#20010;&#19987;&#20026;LLMs&#35774;&#35745;&#30340;&#20840;&#38754;&#20219;&#21153;&#23548;&#21521;&#30340;AIOps&#22522;&#20934;&#27979;&#35797;&#12290;OpsEval&#39318;&#27425;&#23545;LLMs&#22312;&#19977;&#20010;&#20851;&#38190;&#22330;&#26223;&#65288;&#26377;&#32447;&#32593;&#32476;&#25805;&#20316;&#12289;5G&#36890;&#20449;&#25805;&#20316;&#21644;&#25968;&#25454;&#24211;&#25805;&#20316;&#65289;&#20197;&#21450;&#19981;&#21516;&#30340;&#33021;&#21147;&#27700;&#24179;&#65288;&#30693;&#35782;&#22238;&#24518;&#12289;&#20998;&#26512;&#24605;&#32771;&#65289;&#36827;&#34892;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have exhibited remarkable capabilities in NLP-related tasks such as translation, summarizing, and generation. The application of LLMs in specific areas, notably AIOps (Artificial Intelligence for IT Operations), holds great potential due to their advanced abilities in information summarizing, report analyzing, and ability of API calling. Nevertheless, the performance of current LLMs in AIOps tasks is yet to be determined. Furthermore, a comprehensive benchmark is required to steer the optimization of LLMs tailored for AIOps. Compared with existing benchmarks that focus on evaluating specific fields like network configuration, in this paper, we present \textbf{OpsEval}, a comprehensive task-oriented AIOps benchmark designed for LLMs. For the first time, OpsEval assesses LLMs' proficiency in three crucial scenarios (Wired Network Operation, 5G Communication Operation, and Database Operation) at various ability levels (knowledge recall, analytical thinking, an
&lt;/p&gt;</description></item></channel></rss>