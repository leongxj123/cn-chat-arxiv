<rss version="2.0"><channel><title>Chat Arxiv cs.NI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NI</description><item><title>&#26412;&#25991;&#39318;&#27425;&#30740;&#31350;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#36866;&#24212;&#32593;&#32476;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;LLM&#30340;&#39044;&#35757;&#32451;&#30693;&#35782;&#21644;&#24378;&#22823;&#25512;&#29702;&#33021;&#21147;&#65292;&#23454;&#29616;&#20102;&#8220;&#19968;&#27169;&#22411;&#36866;&#29992;&#20110;&#25152;&#26377;&#8221;&#30340;&#30446;&#26631;&#65292;&#24182;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#24615;&#33021;&#21644;&#26356;&#24378;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.02338</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29992;&#20110;&#32593;&#32476;&#30340;&#36866;&#24212;&#24615;
&lt;/p&gt;
&lt;p&gt;
Large Language Model Adaptation for Networking
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02338
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#27425;&#30740;&#31350;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#36866;&#24212;&#32593;&#32476;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;LLM&#30340;&#39044;&#35757;&#32451;&#30693;&#35782;&#21644;&#24378;&#22823;&#25512;&#29702;&#33021;&#21147;&#65292;&#23454;&#29616;&#20102;&#8220;&#19968;&#27169;&#22411;&#36866;&#29992;&#20110;&#25152;&#26377;&#8221;&#30340;&#30446;&#26631;&#65292;&#24182;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#24615;&#33021;&#21644;&#26356;&#24378;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#22312;&#35768;&#22810;&#32593;&#32476;&#20219;&#21153;&#37117;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#65288;DL&#65289;&#26469;&#35299;&#20915;&#22797;&#26434;&#30340;&#39044;&#27979;&#21644;&#31995;&#32479;&#20248;&#21270;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#22522;&#20110;DL&#30340;&#31639;&#27861;&#30340;&#35774;&#35745;&#21746;&#23398;&#38656;&#35201;&#36827;&#34892;&#22823;&#37327;&#30340;&#24037;&#31243;&#24320;&#38144;&#65292;&#22240;&#20026;&#38656;&#35201;&#20026;&#19981;&#21516;&#30340;&#32593;&#32476;&#20219;&#21153;&#25163;&#21160;&#35774;&#35745;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#12290;&#27492;&#22806;&#65292;DNN&#22312;&#26410;&#35265;&#36807;&#30340;&#25968;&#25454;&#20998;&#24067;/&#29615;&#22659;&#19978;&#30340;&#27867;&#21270;&#24615;&#33021;&#36739;&#24046;&#12290;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#26368;&#26032;&#25104;&#21151;&#30340;&#25512;&#21160;&#19979;&#65292;&#26412;&#25991;&#39318;&#27425;&#30740;&#31350;&#20102;LLM&#29992;&#20110;&#32593;&#32476;&#30340;&#36866;&#24212;&#24615;&#65292;&#20197;&#25506;&#32034;&#26356;&#21487;&#25345;&#32493;&#30340;&#35774;&#35745;&#21746;&#23398;&#12290;&#20973;&#20511;&#28023;&#37327;&#30340;&#39044;&#35757;&#32451;&#30693;&#35782;&#21644;&#24378;&#22823;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;LLM&#21487;&#20197;&#20316;&#20026;&#22522;&#30784;&#27169;&#22411;&#65292;&#24182;&#19988;&#26377;&#26395;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#23454;&#29616;&#8220;&#19968;&#27169;&#22411;&#36866;&#29992;&#20110;&#25152;&#26377;&#8221;&#65292;&#24182;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#21644;&#26356;&#24378;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;NetLLM&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#26377;&#25928;&#22320;&#23558;LLM&#24212;&#29992;&#20110;&#35299;&#20915;&#32593;&#32476;&#38382;&#39064;&#30340;&#36866;&#24212;&#24615;&#26694;&#26550;&#12290;NetLLM&#35299;&#20915;&#20102;&#35768;&#22810;&#23454;&#38469;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many networking tasks now employ deep learning (DL) to solve complex prediction and system optimization problems. However, current design philosophy of DL-based algorithms entails intensive engineering overhead due to the manual design of deep neural networks (DNNs) for different networking tasks. Besides, DNNs tend to achieve poor generalization performance on unseen data distributions/environments.   Motivated by the recent success of large language models (LLMs), for the first time, this work studies the LLM adaptation for networking to explore a more sustainable design philosophy. With the massive pre-trained knowledge and powerful inference ability, LLM can serve as the foundation model, and is expected to achieve "one model for all" with even better performance and stronger generalization for various tasks. In this paper, we present NetLLM, the first LLM adaptation framework that efficiently adapts LLMs to solve networking problems. NetLLM addresses many practical challenges in L
&lt;/p&gt;</description></item></channel></rss>