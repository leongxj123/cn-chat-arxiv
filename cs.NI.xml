<rss version="2.0"><channel><title>Chat Arxiv cs.NI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NI</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20248;&#21270;&#30340;&#32593;&#32476;&#26550;&#26500;&#65292;&#29992;&#20110;&#35757;&#32451;&#25317;&#26377;&#25968;&#21313;&#20159;&#21442;&#25968;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;&#36825;&#20010;&#26550;&#26500;&#26681;&#25454;&#35821;&#35328;&#27169;&#22411;&#30340;&#36890;&#20449;&#38656;&#27714;&#65292;&#23558;&#38598;&#32676;&#20998;&#21106;&#25104;&#19968;&#32452;&#36890;&#36807;&#38750;&#38459;&#22622;&#39640;&#24102;&#23485;&#20114;&#36830;&#30340;GPU&#38598;&#21512;&#65292;&#24182;&#36890;&#36807;&#36712;&#36947;&#36830;&#25509;&#20165;&#36830;&#25509;&#20855;&#26377;&#36890;&#20449;&#38656;&#27714;&#30340;GPU&#65292;&#20174;&#32780;&#38477;&#20302;&#32593;&#32476;&#25104;&#26412;&#39640;&#36798;75&#65285;&#65292;&#21516;&#26102;&#19981;&#24433;&#21709;&#35757;&#32451;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.12169</link><description>&lt;p&gt;
&#29992;&#20110;&#35757;&#32451;&#25317;&#26377;&#25968;&#21313;&#20159;&#21442;&#25968;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20248;&#21270;&#32593;&#32476;&#26550;&#26500;
&lt;/p&gt;
&lt;p&gt;
Optimized Network Architectures for Large Language Model Training with Billions of Parameters. (arXiv:2307.12169v1 [cs.NI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12169
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20248;&#21270;&#30340;&#32593;&#32476;&#26550;&#26500;&#65292;&#29992;&#20110;&#35757;&#32451;&#25317;&#26377;&#25968;&#21313;&#20159;&#21442;&#25968;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;&#36825;&#20010;&#26550;&#26500;&#26681;&#25454;&#35821;&#35328;&#27169;&#22411;&#30340;&#36890;&#20449;&#38656;&#27714;&#65292;&#23558;&#38598;&#32676;&#20998;&#21106;&#25104;&#19968;&#32452;&#36890;&#36807;&#38750;&#38459;&#22622;&#39640;&#24102;&#23485;&#20114;&#36830;&#30340;GPU&#38598;&#21512;&#65292;&#24182;&#36890;&#36807;&#36712;&#36947;&#36830;&#25509;&#20165;&#36830;&#25509;&#20855;&#26377;&#36890;&#20449;&#38656;&#27714;&#30340;GPU&#65292;&#20174;&#32780;&#38477;&#20302;&#32593;&#32476;&#25104;&#26412;&#39640;&#36798;75&#65285;&#65292;&#21516;&#26102;&#19981;&#24433;&#21709;&#35757;&#32451;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25361;&#25112;&#20102;&#20026;&#35757;&#32451;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26500;&#24314;&#20219;&#24847;&#21040;&#20219;&#24847;&#32593;&#32476;&#30340;&#20256;&#32479;&#33539;&#24335;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;LLMs&#21576;&#29616;&#20986;&#19968;&#31181;&#29420;&#29305;&#30340;&#36890;&#20449;&#27169;&#24335;&#65292;&#22312;&#20854;&#20013;&#65292;&#21482;&#26377;&#23567;&#32452;&#30340;GPU&#38656;&#35201;&#39640;&#24102;&#23485;&#30340;&#20219;&#24847;&#21040;&#20219;&#24847;&#36890;&#20449;&#65292;&#20197;&#23454;&#29616;&#25509;&#36817;&#26368;&#20248;&#30340;&#35757;&#32451;&#24615;&#33021;&#12290;&#22312;&#36825;&#20123;GPU&#23567;&#32452;&#20043;&#38388;&#65292;&#36890;&#20449;&#38750;&#24120;&#24494;&#19981;&#36275;&#36947;&#12289;&#31232;&#30095;&#19988;&#22343;&#21248;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#32593;&#32476;&#26550;&#26500;&#65292;&#32039;&#23494;&#21305;&#37197;LLMs&#30340;&#36890;&#20449;&#38656;&#27714;&#12290;&#25105;&#20204;&#30340;&#26550;&#26500;&#23558;&#38598;&#32676;&#20998;&#21106;&#20026;&#19968;&#32452;&#36890;&#36807;&#38750;&#38459;&#22622;&#20219;&#24847;&#21040;&#20219;&#24847;&#39640;&#24102;&#23485;&#20114;&#36830;&#30340;GPU&#38598;&#21512;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;HB&#22495;&#12290;&#22312;HB&#22495;&#20043;&#38388;&#65292;&#32593;&#32476;&#21482;&#36830;&#25509;&#20855;&#26377;&#36890;&#20449;&#38656;&#27714;&#30340;GPU&#12290;&#25105;&#20204;&#23558;&#36825;&#31181;&#32593;&#32476;&#36830;&#25509;&#31216;&#20026;&#8220;&#20165;&#36712;&#36947;&#36830;&#25509;&#8221;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26550;&#26500;&#30456;&#23545;&#20110;&#26368;&#20808;&#36827;&#30340;&#20219;&#24847;&#21040;&#20219;&#24847;Clos&#32593;&#32476;&#21487;&#20197;&#23558;&#32593;&#32476;&#25104;&#26412;&#38477;&#20302;&#39640;&#36798;75&#65285;&#65292;&#21516;&#26102;&#19981;&#25439;&#23475;LLM&#35757;&#32451;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper challenges the well-established paradigm for building any-to-any networks for training Large Language Models (LLMs). We show that LLMs exhibit a unique communication pattern where only small groups of GPUs require high-bandwidth any-to-any communication within them, to achieve near-optimal training performance. Across these groups of GPUs, the communication is insignificant, sparse, and homogeneous. We propose a new network architecture that closely resembles the communication requirement of LLMs. Our architecture partitions the cluster into sets of GPUs interconnected with non-blocking any-to-any high-bandwidth interconnects that we call HB domains. Across the HB domains, the network only connects GPUs with communication demands. We call this network a "rail-only" connection, and show that our proposed architecture reduces the network cost by up to 75% compared to the state-of-the-art any-to-any Clos networks without compromising the performance of LLM training.
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#21253;&#21547;&#31264;&#23494;&#22478;&#24066;&#29615;&#22659;&#20013;&#26080;&#32447;&#22320;&#22270;&#25968;&#25454;&#38598;&#30340;&#30740;&#31350;&#12290;&#36825;&#20010;&#25968;&#25454;&#38598;&#33021;&#22815;&#29992;&#20110;&#36335;&#24452;&#25439;&#32791;&#39044;&#27979;&#21644;&#26080;&#32447;&#23450;&#20301;&#65292;&#36890;&#36807;&#22312;&#30456;&#21516;&#30340;&#22478;&#24066;&#22320;&#22270;&#19978;&#35745;&#31639;&#24471;&#21040;RSS&#21644;ToA&#22320;&#22270;&#65292;&#21487;&#20197;&#20844;&#24179;&#27604;&#36739;&#20004;&#31181;&#23450;&#20301;&#26041;&#27861;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2212.11777</link><description>&lt;p&gt;
&#20855;&#26377;&#23450;&#20301;&#24212;&#29992;&#30340;&#36335;&#24452;&#25439;&#32791;&#21644;&#21040;&#36798;&#26102;&#38388;&#26080;&#32447;&#22320;&#22270;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
Dataset of Pathloss and ToA Radio Maps With Localization Application. (arXiv:2212.11777v2 [cs.NI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.11777
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#21253;&#21547;&#31264;&#23494;&#22478;&#24066;&#29615;&#22659;&#20013;&#26080;&#32447;&#22320;&#22270;&#25968;&#25454;&#38598;&#30340;&#30740;&#31350;&#12290;&#36825;&#20010;&#25968;&#25454;&#38598;&#33021;&#22815;&#29992;&#20110;&#36335;&#24452;&#25439;&#32791;&#39044;&#27979;&#21644;&#26080;&#32447;&#23450;&#20301;&#65292;&#36890;&#36807;&#22312;&#30456;&#21516;&#30340;&#22478;&#24066;&#22320;&#22270;&#19978;&#35745;&#31639;&#24471;&#21040;RSS&#21644;ToA&#22320;&#22270;&#65292;&#21487;&#20197;&#20844;&#24179;&#27604;&#36739;&#20004;&#31181;&#23450;&#20301;&#26041;&#27861;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22312;&#31264;&#23494;&#22478;&#24066;&#29615;&#22659;&#20013;&#29983;&#25104;&#24182;&#20844;&#24320;&#25552;&#20379;&#30340;&#19968;&#32452;&#26080;&#32447;&#22320;&#22270;&#25968;&#25454;&#38598;&#12290;&#36825;&#20123;&#25968;&#25454;&#38598;&#21253;&#25324;&#27169;&#25311;&#30340;&#36335;&#24452;&#25439;&#32791;/&#25509;&#25910;&#20449;&#21495;&#24378;&#24230;&#65288;RSS&#65289;&#21644;&#21040;&#36798;&#26102;&#38388;&#65288;ToA&#65289;&#26080;&#32447;&#22320;&#22270;&#65292;&#35206;&#30422;&#20102;&#22823;&#37327;&#30495;&#23454;&#22478;&#24066;&#22320;&#22270;&#30340;&#31264;&#23494;&#22478;&#24066;&#35774;&#32622;&#12290;&#35813;&#25968;&#25454;&#38598;&#30340;&#20004;&#20010;&#20027;&#35201;&#24212;&#29992;&#26159;1&#65289;&#20174;&#36755;&#20837;&#30340;&#22478;&#24066;&#22320;&#22270;&#39044;&#27979;&#36335;&#24452;&#25439;&#32791;&#30340;&#23398;&#20064;&#26041;&#27861;&#65288;&#21363;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#27169;&#25311;&#65289;&#65292;&#20197;&#21450;2&#65289;&#26080;&#32447;&#23450;&#20301;&#12290;RSS&#21644;ToA&#22320;&#22270;&#36890;&#36807;&#30456;&#21516;&#30340;&#27169;&#25311;&#22312;&#30456;&#21516;&#30340;&#22478;&#24066;&#22320;&#22270;&#19978;&#35745;&#31639;&#24471;&#20986;&#65292;&#21487;&#20197;&#23545;&#22522;&#20110;RSS&#21644;ToA&#30340;&#23450;&#20301;&#26041;&#27861;&#36827;&#34892;&#20844;&#24179;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this article, we present a collection of radio map datasets in dense urban setting, which we generated and made publicly available. The datasets include simulated pathloss/received signal strength (RSS) and time of arrival (ToA) radio maps over a large collection of realistic dense urban setting in real city maps. The two main applications of the presented dataset are 1) learning methods that predict the pathloss from input city maps (namely, deep learning-based simulations), and, 2) wireless localization. The fact that the RSS and ToA maps are computed by the same simulations over the same city maps allows for a fair comparison of the RSS and ToA-based localization methods.
&lt;/p&gt;</description></item></channel></rss>