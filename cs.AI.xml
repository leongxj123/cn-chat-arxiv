<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;MoPE&#25216;&#26415;&#65292;&#36890;&#36807;&#35299;&#24320;&#25552;&#31034;&#20197;&#33258;&#36866;&#24212;&#25429;&#33719;&#25968;&#25454;&#38598;&#32423;&#21644;&#23454;&#20363;&#32423;&#29305;&#24449;&#65292;&#24341;&#20837;&#20102;&#28151;&#21512;Prompt&#19987;&#23478;&#26469;&#22686;&#24378;&#34920;&#36798;&#33021;&#21147;&#65292;&#24182;&#19988;&#22312;&#22810;&#27169;&#24577;&#34701;&#21512;&#20013;&#34920;&#29616;&#20986;&#26356;&#22823;&#30340;&#34920;&#36798;&#33021;&#21147;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.10568</link><description>&lt;p&gt;
MoPE&#65306;&#36890;&#36807;Prompt&#19987;&#23478;&#28151;&#21512;&#23454;&#29616;&#21442;&#25968;&#39640;&#25928;&#21644;&#21487;&#25193;&#23637;&#30340;&#22810;&#27169;&#24577;&#34701;&#21512;
&lt;/p&gt;
&lt;p&gt;
MoPE: Parameter-Efficient and Scalable Multimodal Fusion via Mixture of Prompt Experts
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10568
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;MoPE&#25216;&#26415;&#65292;&#36890;&#36807;&#35299;&#24320;&#25552;&#31034;&#20197;&#33258;&#36866;&#24212;&#25429;&#33719;&#25968;&#25454;&#38598;&#32423;&#21644;&#23454;&#20363;&#32423;&#29305;&#24449;&#65292;&#24341;&#20837;&#20102;&#28151;&#21512;Prompt&#19987;&#23478;&#26469;&#22686;&#24378;&#34920;&#36798;&#33021;&#21147;&#65292;&#24182;&#19988;&#22312;&#22810;&#27169;&#24577;&#34701;&#21512;&#20013;&#34920;&#29616;&#20986;&#26356;&#22823;&#30340;&#34920;&#36798;&#33021;&#21147;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Prompt&#35843;&#25972;&#24050;&#32463;&#35777;&#26126;&#22312;&#34701;&#21512;&#22810;&#27169;&#24577;&#20219;&#21153;&#30340;&#21333;&#27169;&#22522;&#30784;&#27169;&#22411;&#26102;&#20855;&#26377;&#21442;&#25968;&#25928;&#29575;&#24615;&#12290;&#28982;&#32780;&#65292;&#20854;&#26377;&#38480;&#30340;&#36866;&#24212;&#24615;&#21644;&#34920;&#36798;&#33021;&#21147;&#23548;&#33268;&#24615;&#33021;&#19981;&#20339;&#19982;&#20854;&#20182;&#35843;&#25972;&#26041;&#27861;&#30456;&#27604;&#12290;&#26412;&#25991;&#36890;&#36807;&#23558;&#31616;&#21333;&#25552;&#31034;&#35299;&#24320;&#20197;&#33258;&#36866;&#24212;&#22320;&#25429;&#33719;&#25968;&#25454;&#38598;&#32423;&#21644;&#23454;&#20363;&#32423;&#29305;&#24449;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#24314;&#31435;&#22312;&#36825;&#31181;&#35299;&#24320;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;Prompt&#19987;&#23478;&#30340;&#28151;&#21512;&#65288;MoPE&#65289;&#25216;&#26415;&#26469;&#22686;&#24378;&#34920;&#36798;&#33021;&#21147;&#12290;MoPE&#21033;&#29992;&#22810;&#27169;&#24577;&#37197;&#23545;&#20808;&#39564;&#22312;&#27599;&#20010;&#23454;&#20363;&#22522;&#30784;&#19978;&#36335;&#30001;&#26368;&#26377;&#25928;&#30340;&#25552;&#31034;&#12290;&#19982;&#31616;&#21333;&#25552;&#31034;&#30456;&#27604;&#65292;&#25105;&#20204;&#22522;&#20110;MoPE&#30340;&#26465;&#20214;&#25552;&#31034;&#23545;&#22810;&#27169;&#24577;&#34701;&#21512;&#20855;&#26377;&#26356;&#22823;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#22312;&#35757;&#32451;&#25968;&#25454;&#21644;&#21487;&#35757;&#32451;&#21442;&#25968;&#24635;&#25968;&#19978;&#20855;&#26377;&#26356;&#22909;&#30340;&#25193;&#23637;&#24615;&#12290;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#19968;&#20010;&#19987;&#23478;&#36335;&#30001;&#30340;&#27491;&#21017;&#21270;&#39033;&#65292;&#23548;&#33268;&#19987;&#23478;&#30340;&#19981;&#26029;&#21457;&#23637;&#19987;&#38271;&#65292;&#19981;&#21516;&#19987;&#23478;&#19987;&#27880;&#20110;&#19981;&#21516;&#30340;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10568v1 Announce Type: cross  Abstract: Prompt-tuning has demonstrated parameter-efficiency in fusing unimodal foundation models for multimodal tasks. However, its limited adaptivity and expressiveness lead to suboptimal performance when compared with other tuning methods. In this paper, we address this issue by disentangling the vanilla prompts to adaptively capture dataset-level and instance-level features. Building upon this disentanglement, we introduce the mixture of prompt experts (MoPE) technique to enhance expressiveness. MoPE leverages multimodal pairing priors to route the most effective prompt on a per-instance basis. Compared to vanilla prompting, our MoPE-based conditional prompting exhibits greater expressiveness for multimodal fusion, scaling better with the training data and the overall number of trainable parameters. We also study a regularization term for expert routing, leading to emergent expert specialization, where different experts focus on different c
&lt;/p&gt;</description></item><item><title>MathGenie&#36890;&#36807;&#38382;&#39064;&#21453;&#21521;&#32763;&#35793;&#29983;&#25104;&#21512;&#25104;&#25968;&#25454;&#65292;&#29992;&#20110;&#22686;&#24378;LLMs&#30340;&#25968;&#23398;&#25512;&#29702;&#33021;&#21147;&#65292;&#24182;&#21019;&#36896;&#20102;&#19968;&#20010;&#23478;&#26063;&#21270;&#30340;&#27169;&#22411;&#31995;&#21015;MathGenieLM&#12290;</title><link>https://arxiv.org/abs/2402.16352</link><description>&lt;p&gt;
MathGenie: &#20351;&#29992;&#38382;&#39064;&#21453;&#21521;&#32763;&#35793;&#29983;&#25104;&#21512;&#25104;&#25968;&#25454;&#65292;&#20197;&#22686;&#24378;LLMs&#30340;&#25968;&#23398;&#25512;&#29702;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
MathGenie: Generating Synthetic Data with Question Back-translation for Enhancing Mathematical Reasoning of LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16352
&lt;/p&gt;
&lt;p&gt;
MathGenie&#36890;&#36807;&#38382;&#39064;&#21453;&#21521;&#32763;&#35793;&#29983;&#25104;&#21512;&#25104;&#25968;&#25454;&#65292;&#29992;&#20110;&#22686;&#24378;LLMs&#30340;&#25968;&#23398;&#25512;&#29702;&#33021;&#21147;&#65292;&#24182;&#21019;&#36896;&#20102;&#19968;&#20010;&#23478;&#26063;&#21270;&#30340;&#27169;&#22411;&#31995;&#21015;MathGenieLM&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#25968;&#23398;&#25512;&#29702;&#26041;&#38754;&#23637;&#29616;&#20986;&#24040;&#22823;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#24320;&#28304;&#27169;&#22411;&#21644;GPT-4&#31561;&#38381;&#28304;&#27169;&#22411;&#20043;&#38388;&#22312;&#36825;&#19968;&#39046;&#22495;&#20173;&#23384;&#22312;&#24615;&#33021;&#24046;&#36317;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;MathGenie&#65292;&#29992;&#20110;&#20174;&#23567;&#35268;&#27169;&#38382;&#39064;-&#35299;&#20915;&#26041;&#26696;&#25968;&#25454;&#38598;&#65288;&#31216;&#20026;&#31181;&#23376;&#25968;&#25454;&#65289;&#20013;&#29983;&#25104;&#22810;&#26679;&#19988;&#21487;&#38752;&#30340;&#25968;&#23398;&#38382;&#39064;&#12290;&#25105;&#20204;&#25193;&#20805;&#20102;&#31181;&#23376;&#25968;&#25454;&#30340;&#30495;&#23454;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#35757;&#32451;&#20102;&#19968;&#20010;&#21453;&#21521;&#32763;&#35793;&#27169;&#22411;&#65292;&#23558;&#25193;&#20805;&#30340;&#35299;&#20915;&#26041;&#26696;&#32763;&#35793;&#22238;&#26032;&#38382;&#39064;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#20026;&#26032;&#38382;&#39064;&#29983;&#25104;&#20102;&#38598;&#25104;&#20195;&#30721;&#35299;&#20915;&#26041;&#26696;&#12290;&#20026;&#30830;&#20445;&#38598;&#25104;&#20195;&#30721;&#35299;&#20915;&#26041;&#26696;&#30340;&#27491;&#30830;&#24615;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#22522;&#20110;&#21407;&#29702;&#30340;&#35299;&#20915;&#26041;&#26696;&#39564;&#35777;&#31574;&#30053;&#12290;&#25105;&#20204;&#22312;&#26032;&#31579;&#36873;&#30340;&#25968;&#25454;&#19978;&#23545;&#20174;7B&#21040;70B&#19981;&#31561;&#30340;&#21508;&#31181;&#39044;&#35757;&#32451;&#27169;&#22411;&#36827;&#34892;&#35757;&#32451;&#65292;&#20197;&#27979;&#35797;&#25152;&#25552;&#20986;&#30340;&#22686;&#24378;&#25216;&#26415;&#30340;&#26377;&#25928;&#24615;&#65292;&#20174;&#32780;&#20135;&#29983;&#20102;&#19968;&#20010;&#31216;&#20026;MathGenieLM&#30340;&#27169;&#22411;&#31995;&#21015;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16352v1 Announce Type: cross  Abstract: Large language models (LLMs) have exhibited great potential in mathematical reasoning. However, there remains a performance gap in this area between existing open-source models and closed-source models such as GPT-4. In this paper, we introduce MathGenie, a novel method for generating diverse and reliable math problems from a small-scale problem-solution dataset (denoted as seed data). We augment the ground-truth solutions of our seed data and train a back-translation model to translate the augmented solutions back into new questions. Subsequently, we generate code-integrated solutions for the new questions. To ensure the correctness of the code-integrated solutions, we employ rationale-based strategy for solution verification. Various pretrained models, ranging from 7B to 70B, are trained on the newly curated data to test the effectiveness of the proposed augmentation technique, resulting in a family of models known as MathGenieLM. Th
&lt;/p&gt;</description></item><item><title>CriticBench&#26159;&#19968;&#20010;&#26088;&#22312;&#20840;&#38754;&#21644;&#21487;&#38752;&#22320;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#35780;&#35770;&#33021;&#21147;&#30340;&#26032;&#22411;&#22522;&#20934;&#65292;&#23637;&#31034;&#20102;&#35780;&#35770;&#33021;&#21147;&#19982;&#20219;&#21153;&#12289;&#21709;&#24212;&#36136;&#37327;&#21644;&#27169;&#22411;&#35268;&#27169;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;</title><link>https://arxiv.org/abs/2402.13764</link><description>&lt;p&gt;
CriticBench: &#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#35780;&#35770;&#23478;&#36827;&#34892;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
CriticBench: Evaluating Large Language Models as Critic
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13764
&lt;/p&gt;
&lt;p&gt;
CriticBench&#26159;&#19968;&#20010;&#26088;&#22312;&#20840;&#38754;&#21644;&#21487;&#38752;&#22320;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#35780;&#35770;&#33021;&#21147;&#30340;&#26032;&#22411;&#22522;&#20934;&#65292;&#23637;&#31034;&#20102;&#35780;&#35770;&#33021;&#21147;&#19982;&#20219;&#21153;&#12289;&#21709;&#24212;&#36136;&#37327;&#21644;&#27169;&#22411;&#35268;&#27169;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#25552;&#20986;&#20102; CriticBench&#65292;&#36825;&#26159;&#19968;&#20010;&#26088;&#22312;&#20840;&#38754;&#21644;&#21487;&#38752;&#22320;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#22235;&#20010;&#20851;&#38190;&#35780;&#35770;&#33021;&#21147;&#32500;&#24230;&#65288;&#21453;&#39304;&#12289;&#27604;&#36739;&#12289;&#25913;&#36827;&#21644;&#20803;&#21453;&#39304;&#65289;&#30340;&#26032;&#22411;&#22522;&#20934;&#12290;CriticBench&#21253;&#21547;&#20061;&#20010;&#19981;&#21516;&#30340;&#20219;&#21153;&#65292;&#27599;&#20010;&#20219;&#21153;&#35780;&#20272;LLMs&#22312;&#19981;&#21516;&#36136;&#37327;&#32454;&#31890;&#24230;&#27700;&#24179;&#19978;&#35780;&#35770;&#21709;&#24212;&#30340;&#33021;&#21147;&#12290;&#23545;&#24320;&#28304;&#21644;&#38381;&#28304;LLMs&#36827;&#34892;&#30340;&#24191;&#27867;&#35780;&#20272;&#25581;&#31034;&#20102;&#35780;&#35770;&#33021;&#21147;&#19982;&#20219;&#21153;&#12289;&#21709;&#24212;&#36136;&#37327;&#21644;&#27169;&#22411;&#35268;&#27169;&#20043;&#38388;&#26377;&#36259;&#30340;&#20851;&#31995;&#12290;CriticBench&#30340;&#25968;&#25454;&#38598;&#12289;&#36164;&#28304;&#21644;&#35780;&#20272;&#24037;&#20855;&#21253;&#23558;&#22312;https://github.com/gmftbyGMFTBY/Cri&#19978;&#20844;&#24320;&#21457;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13764v1 Announce Type: cross  Abstract: Critique ability are crucial in the scalable oversight and self-improvement of Large Language Models (LLMs). While many recent studies explore the critique ability of LLMs to judge and refine flaws in generations, how to comprehensively and reliably measure the critique abilities of LLMs is under-explored. This paper introduces \shortname, a novel benchmark designed to comprehensively and reliably evaluate four key critique ability dimensions of LLMs: feedback, comparison, refinement and meta-feedback. \shortname~encompasses nine diverse tasks, each assessing the LLMs' ability to critique responses at varying levels of quality granularity. Our extensive evaluations of open-source and closed-source LLMs reveal intriguing relationships between the critique ability and tasks, response qualities, and model scales. Datasets, resources and evaluation toolkit for \shortname~will be publicly released at \url{https://github.com/gmftbyGMFTBY/Cri
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23545;&#27604;&#21407;&#22987;&#36712;&#36857;&#21644;&#21453;&#20107;&#23454;&#37096;&#20998;&#36712;&#36857;&#30340;&#22870;&#21169;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#37322;&#24378;&#21270;&#23398;&#20064;&#20013;&#22870;&#21169;&#20989;&#25968;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#29983;&#25104;&#31526;&#21512;&#36136;&#37327;&#26631;&#20934;&#30340;&#21453;&#20107;&#23454;&#36712;&#36857;&#35299;&#37322;&#65288;CTEs&#65289;&#65292;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;CTEs&#23545;&#20110;&#20195;&#29702;&#20154;&#27169;&#22411;&#20855;&#26377;&#26126;&#26174;&#30340;&#20449;&#24687;&#24615;&#65292;&#33021;&#25552;&#39640;&#20854;&#39044;&#27979;&#19982;&#22870;&#21169;&#20989;&#25968;&#30340;&#19968;&#33268;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.04856</link><description>&lt;p&gt;
&#36890;&#36807;&#21453;&#20107;&#23454;&#36712;&#36857;&#35299;&#37322;&#23398;&#20064;&#21040;&#30340;&#22870;&#21169;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Explaining Learned Reward Functions with Counterfactual Trajectories
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04856
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;&#27604;&#21407;&#22987;&#36712;&#36857;&#21644;&#21453;&#20107;&#23454;&#37096;&#20998;&#36712;&#36857;&#30340;&#22870;&#21169;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#37322;&#24378;&#21270;&#23398;&#20064;&#20013;&#22870;&#21169;&#20989;&#25968;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#29983;&#25104;&#31526;&#21512;&#36136;&#37327;&#26631;&#20934;&#30340;&#21453;&#20107;&#23454;&#36712;&#36857;&#35299;&#37322;&#65288;CTEs&#65289;&#65292;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;CTEs&#23545;&#20110;&#20195;&#29702;&#20154;&#27169;&#22411;&#20855;&#26377;&#26126;&#26174;&#30340;&#20449;&#24687;&#24615;&#65292;&#33021;&#25552;&#39640;&#20854;&#39044;&#27979;&#19982;&#22870;&#21169;&#20989;&#25968;&#30340;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#20154;&#31867;&#34892;&#20026;&#25110;&#21453;&#39304;&#20013;&#23398;&#20064;&#22870;&#21169;&#26159;&#23558;AI&#31995;&#32479;&#19982;&#20154;&#31867;&#20215;&#20540;&#35266;&#19968;&#33268;&#30340;&#19968;&#31181;&#26377;&#24076;&#26395;&#30340;&#26041;&#27861;&#65292;&#20294;&#26080;&#27861;&#22987;&#32456;&#25552;&#21462;&#27491;&#30830;&#30340;&#22870;&#21169;&#20989;&#25968;&#12290;&#21487;&#35299;&#37322;&#24615;&#24037;&#20855;&#21487;&#20197;&#24110;&#21161;&#29992;&#25143;&#29702;&#35299;&#21644;&#35780;&#20272;&#23398;&#20064;&#21040;&#30340;&#22870;&#21169;&#20989;&#25968;&#20013;&#21487;&#33021;&#23384;&#22312;&#30340;&#32570;&#38519;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#21453;&#20107;&#23454;&#36712;&#36857;&#35299;&#37322;&#65288;CTEs&#65289;&#65292;&#36890;&#36807;&#23545;&#27604;&#21407;&#22987;&#36712;&#36857;&#21644;&#21453;&#20107;&#23454;&#37096;&#20998;&#36712;&#36857;&#20197;&#21450;&#23427;&#20204;&#21508;&#33258;&#25509;&#25910;&#30340;&#22870;&#21169;&#26469;&#35299;&#37322;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#22870;&#21169;&#20989;&#25968;&#12290;&#25105;&#20204;&#20026;CTEs&#21046;&#23450;&#20102;&#20845;&#20010;&#36136;&#37327;&#26631;&#20934;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Monte-Carlo&#30340;&#26032;&#31639;&#27861;&#26469;&#29983;&#25104;&#20248;&#21270;&#36825;&#20123;&#36136;&#37327;&#26631;&#20934;&#30340;CTEs&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#35757;&#32451;&#20195;&#29702;&#20154;&#27169;&#22411;&#26469;&#34913;&#37327;&#29983;&#25104;&#30340;&#35299;&#37322;&#23545;&#20854;&#30340;&#20449;&#24687;&#24615;&#12290;CTEs&#23545;&#20110;&#20195;&#29702;&#20154;&#27169;&#22411;&#20855;&#26377;&#26126;&#26174;&#30340;&#20449;&#24687;&#24615;&#65292;&#22686;&#21152;&#20102;&#20854;&#39044;&#27979;&#19982;&#26410;&#35265;&#36712;&#36857;&#19978;&#30340;&#22870;&#21169;&#20989;&#25968;&#30340;&#30456;&#20284;&#24615;&#12290;&#27492;&#22806;&#65292;&#23427;&#23398;&#20250;&#20102;&#20934;&#30830;&#21028;&#26029;&#36712;&#36857;&#20043;&#38388;&#30340;&#22870;&#21169;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning rewards from human behaviour or feedback is a promising approach to aligning AI systems with human values but fails to consistently extract correct reward functions. Interpretability tools could enable users to understand and evaluate possible flaws in learned reward functions. We propose Counterfactual Trajectory Explanations (CTEs) to interpret reward functions in reinforcement learning by contrasting an original with a counterfactual partial trajectory and the rewards they each receive. We derive six quality criteria for CTEs and propose a novel Monte-Carlo-based algorithm for generating CTEs that optimises these quality criteria. Finally, we measure how informative the generated explanations are to a proxy-human model by training it on CTEs. CTEs are demonstrably informative for the proxy-human model, increasing the similarity between its predictions and the reward function on unseen trajectories. Further, it learns to accurately judge differences in rewards between trajec
&lt;/p&gt;</description></item><item><title>Temp-Lora&#26041;&#27861;&#36890;&#36807;&#22312;&#38271;&#25991;&#26412;&#29983;&#25104;&#36807;&#31243;&#20013;&#36880;&#27493;&#35757;&#32451;&#20020;&#26102;Lora&#27169;&#22359;&#65292;&#26377;&#25928;&#20445;&#30041;&#19978;&#19979;&#25991;&#30693;&#35782;&#24182;&#36991;&#20813;&#23545;&#27169;&#22411;&#21442;&#25968;&#30340;&#27704;&#20037;&#24615;&#25913;&#21464;&#12290;</title><link>https://arxiv.org/abs/2401.11504</link><description>&lt;p&gt;
&#38543;&#30528;&#25991;&#26412;&#37327;&#22686;&#21152;&#65292;&#25512;&#26029;&#35757;&#32451;&#26377;&#21161;&#20110;&#38271;&#25991;&#26412;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
With Greater Text Comes Greater Necessity: Inference-Time Training Helps Long Text Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.11504
&lt;/p&gt;
&lt;p&gt;
Temp-Lora&#26041;&#27861;&#36890;&#36807;&#22312;&#38271;&#25991;&#26412;&#29983;&#25104;&#36807;&#31243;&#20013;&#36880;&#27493;&#35757;&#32451;&#20020;&#26102;Lora&#27169;&#22359;&#65292;&#26377;&#25928;&#20445;&#30041;&#19978;&#19979;&#25991;&#30693;&#35782;&#24182;&#36991;&#20813;&#23545;&#27169;&#22411;&#21442;&#25968;&#30340;&#27704;&#20037;&#24615;&#25913;&#21464;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38271;&#25991;&#26412;&#29983;&#25104;&#65292;&#22914;&#23567;&#35828;&#21019;&#20316;&#21644;&#20855;&#26377;&#26497;&#38271;&#19978;&#19979;&#25991;&#30340;&#31687;&#31456;&#32423;&#32763;&#35793;&#65292;&#23545;&#24403;&#21069;&#30340;&#35821;&#35328;&#27169;&#22411;&#25552;&#20986;&#20102;&#37325;&#22823;&#25361;&#25112;&#12290;&#29616;&#26377;&#26041;&#27861;&#20027;&#35201;&#38598;&#20013;&#22312;&#36890;&#36807;&#38271;&#24230;&#22806;&#25512;&#31561;&#31574;&#30053;&#25193;&#23637;&#27169;&#22411;&#30340;&#19978;&#19979;&#25991;&#31383;&#21475;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#35757;&#32451;&#21644;/&#25110;&#25512;&#26029;&#38454;&#27573;&#35201;&#27714;&#22823;&#37327;&#30828;&#20214;&#36164;&#28304;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;Temp-Lora&#24341;&#20837;&#20102;&#19968;&#20010;&#26367;&#20195;&#27010;&#24565;&#12290;&#25105;&#20204;&#19981;&#20381;&#36182;&#20110;KV&#32531;&#23384;&#23384;&#20648;&#25152;&#26377;&#19978;&#19979;&#25991;&#20449;&#24687;&#65292;&#32780;&#26159;&#23558;&#36825;&#20123;&#20449;&#24687;&#30452;&#25509;&#23884;&#20837;&#20020;&#26102;Lora&#27169;&#22359;&#20013;&#12290;&#22312;&#38271;&#25991;&#26412;&#29983;&#25104;&#36807;&#31243;&#20013;&#65292;&#36825;&#20010;&#27169;&#22359;&#20250;&#38543;&#30528;&#20808;&#21069;&#29983;&#25104;&#30340;&#25991;&#26412;&#36880;&#28176;&#36827;&#34892;&#35757;&#32451;&#12290;&#36825;&#31181;&#26041;&#27861;&#19981;&#20165;&#26377;&#25928;&#22320;&#20445;&#30041;&#19978;&#19979;&#25991;&#30693;&#35782;&#65292;&#36824;&#38450;&#27490;&#20102;&#23545;&#27169;&#22411;&#21442;&#25968;&#30340;&#20219;&#20309;&#27704;&#20037;&#24615;&#25913;&#21464;&#65292;&#22240;&#20026;&#27169;&#22359;&#22312;&#29983;&#25104;&#21518;&#34987;&#20002;&#24323;&#12290;&#22312;PG19&#35821;&#35328;&#24314;&#27169;&#19978;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2401.11504v2 Announce Type: replace-cross  Abstract: Long text generation, such as novel writing and discourse-level translation with extremely long contexts, presents significant challenges to current language models. Existing methods mainly focus on extending the model's context window through strategies like length extrapolation. However, these approaches demand substantial hardware resources during the training and/or inference phases. Our proposed method, Temp-Lora, introduces an alternative concept. Instead of relying on the KV cache to store all context information, we embeds this information directly into a temporary Lora module. In the process of long text generation, this module is progressively trained with text generated previously. This approach not only efficiently preserves contextual knowledge but also prevents any permanent alteration to the model's parameters given that the module is discarded post-generation. Extensive experiments on the PG19 language modeling 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#27169;&#22411;&#24066;&#22330;&#30340;&#35843;&#33410;&#38382;&#39064;&#65292;&#20998;&#26512;&#20102;AI&#20013;&#20171;&#24179;&#21488;&#38754;&#20020;&#30340;&#24179;&#21488;&#27835;&#29702;&#25361;&#25112;&#65292;&#24182;&#24635;&#32467;&#20102;&#19994;&#30028;&#30340;&#30456;&#20851;&#23454;&#36341;&#65292;&#21253;&#25324;&#35768;&#21487;&#12289;&#35775;&#38382;&#21644;&#20351;&#29992;&#38480;&#21046;&#12289;&#33258;&#21160;&#20869;&#23481;&#35843;&#33410;&#20197;&#21450;&#20844;&#24320;&#25919;&#31574;&#21046;&#23450;&#12290;</title><link>https://arxiv.org/abs/2311.12573</link><description>&lt;p&gt;
&#27169;&#22411;&#24066;&#22330;&#30340;&#35843;&#33410;: AI&#20013;&#20171;&#24179;&#21488;&#30340;&#24179;&#21488;&#27835;&#29702;&#38590;&#39064;
&lt;/p&gt;
&lt;p&gt;
Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.12573
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#27169;&#22411;&#24066;&#22330;&#30340;&#35843;&#33410;&#38382;&#39064;&#65292;&#20998;&#26512;&#20102;AI&#20013;&#20171;&#24179;&#21488;&#38754;&#20020;&#30340;&#24179;&#21488;&#27835;&#29702;&#25361;&#25112;&#65292;&#24182;&#24635;&#32467;&#20102;&#19994;&#30028;&#30340;&#30456;&#20851;&#23454;&#36341;&#65292;&#21253;&#25324;&#35768;&#21487;&#12289;&#35775;&#38382;&#21644;&#20351;&#29992;&#38480;&#21046;&#12289;&#33258;&#21160;&#20869;&#23481;&#35843;&#33410;&#20197;&#21450;&#20844;&#24320;&#25919;&#31574;&#21046;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv: 2311.12573v2 &#20844;&#21578;&#31867;&#22411;: replace-cross &#25688;&#35201;: AI&#24320;&#21457;&#31038;&#21306;&#36234;&#26469;&#36234;&#22810;&#22320;&#21033;&#29992;&#25176;&#31649;&#20013;&#20171;&#24179;&#21488;&#65292;&#22914;Hugging Face&#65292;&#20026;&#29992;&#25143;&#19978;&#20256;&#30340;&#27169;&#22411;&#21644;&#35757;&#32451;&#25968;&#25454;&#25552;&#20379;&#20415;&#25463;&#35775;&#38382;&#12290;&#36825;&#20123;&#27169;&#22411;&#24066;&#22330;&#38477;&#20302;&#20102;&#25104;&#21315;&#19978;&#19975;&#29992;&#25143;&#30340;&#25216;&#26415;&#37096;&#32626;&#38376;&#27099;&#65292;&#20294;&#20063;&#21487;&#33021;&#34987;&#29992;&#20110;&#35768;&#22810;&#28508;&#22312;&#26377;&#23475;&#21644;&#38750;&#27861;&#30340;&#26041;&#24335;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35299;&#37322;&#20102;AI&#31995;&#32479;&#22914;&#20309;&#26082;&#33021;&#8220;&#21253;&#21547;&#8221;&#20869;&#23481;&#21448;&#33021;&#26159;&#24320;&#25918;&#24335;&#24037;&#20855;&#65292;&#20174;&#32780;&#25104;&#20026;&#36804;&#20170;&#20026;&#27490;&#26368;&#26840;&#25163;&#30340;&#24179;&#21488;&#27835;&#29702;&#25361;&#25112;&#20043;&#19968;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20960;&#20010;&#26696;&#20363;&#30740;&#31350;&#26469;&#20998;&#26512;&#27169;&#22411;&#24066;&#22330;&#22914;&#20309;&#31649;&#29702;&#27169;&#22411;&#65292;&#36825;&#20123;&#26696;&#20363;&#36328;&#36234;&#20102;&#19977;&#20010;&#20855;&#26377;&#20195;&#34920;&#24615;&#30340;&#24179;&#21488;&#65292;&#21363;Hugging Face&#12289;GitHub&#21644;Civitai&#12290;&#22522;&#20110;&#36825;&#20123;&#20998;&#26512;&#65292;&#25105;&#20204;&#24635;&#32467;&#20102;&#19994;&#30028;&#27491;&#22312;&#21046;&#23450;&#30340;&#37325;&#35201;&#65288;&#20294;&#20173;&#28982;&#26377;&#38480;&#65289;&#24212;&#23545;&#35843;&#33410;&#38656;&#27714;&#30340;&#20570;&#27861;&#65306;&#35768;&#21487;&#12289;&#35775;&#38382;&#21644;&#20351;&#29992;&#38480;&#21046;&#12289;&#33258;&#21160;&#20869;&#23481;&#35843;&#33410;&#20197;&#21450;&#20844;&#24320;&#25919;&#31574;&#21046;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.12573v2 Announce Type: replace-cross  Abstract: The AI development community is increasingly making use of hosting intermediaries such as Hugging Face provide easy access to user-uploaded models and training data. These model marketplaces lower technical deployment barriers for hundreds of thousands of users, yet can be used in numerous potentially harmful and illegal ways. In this article, we explain ways in which AI systems, which can both `contain' content and be open-ended tools, present one of the trickiest platform governance challenges seen to date. We provide case studies of several incidents across three illustrative platforms -- Hugging Face, GitHub and Civitai -- to examine how model marketplaces moderate models. Building on this analysis, we outline important (and yet nevertheless limited) practices that industry has been developing to respond to moderation demands: licensing, access and use restrictions, automated content moderation, and open policy development.
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#35299;&#37322;&#21644;&#35782;&#21035;&#20234;&#26031;&#20848;&#25945;&#20167;&#24680;&#35328;&#35770;&#65292;&#27169;&#22411;&#22312;&#20445;&#25345;&#20986;&#33394;&#24615;&#33021;&#30340;&#21516;&#26102;&#33021;&#22815;&#35299;&#37322;&#30456;&#20851;&#24615;&#21644;&#22240;&#26524;&#20851;&#31995;&#12290;</title><link>https://arxiv.org/abs/2311.04916</link><description>&lt;p&gt;
&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#35299;&#37322;&#20234;&#26031;&#20848;&#25945;&#20167;&#24680;&#35328;&#35770;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Explainable Identification of Hate Speech towards Islam using Graph Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.04916
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#35299;&#37322;&#21644;&#35782;&#21035;&#20234;&#26031;&#20848;&#25945;&#20167;&#24680;&#35328;&#35770;&#65292;&#27169;&#22411;&#22312;&#20445;&#25345;&#20986;&#33394;&#24615;&#33021;&#30340;&#21516;&#26102;&#33021;&#22815;&#35299;&#37322;&#30456;&#20851;&#24615;&#21644;&#22240;&#26524;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20234;&#26031;&#20848;&#25945;&#20167;&#24680;&#35328;&#35770;&#22312;&#22312;&#32447;&#31038;&#20132;&#20114;&#21160;&#24179;&#21488;&#19978;&#26159;&#19968;&#20010;&#26222;&#36941;&#23384;&#22312;&#30340;&#25361;&#25112;&#12290;&#35782;&#21035;&#21644;&#28040;&#38500;&#36825;&#31181;&#20167;&#24680;&#26159;&#36808;&#21521;&#21644;&#35856;&#19982;&#21644;&#24179;&#26410;&#26469;&#30340;&#20851;&#38190;&#19968;&#27493;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33539;&#20363;&#65292;&#21033;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#26469;&#35782;&#21035;&#21644;&#35299;&#37322;&#38024;&#23545;&#20234;&#26031;&#20848;&#25945;&#30340;&#20167;&#24680;&#35328;&#35770;&#12290;&#21033;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#21457;&#29616;&#12289;&#25552;&#21462;&#24182;&#21033;&#29992;&#19981;&#21516;&#25968;&#25454;&#28857;&#20043;&#38388;&#30340;&#20851;&#31995;&#30340;&#20869;&#22312;&#33021;&#21147;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#22987;&#32456;&#33021;&#22815;&#22312;&#20445;&#25345;&#20986;&#33394;&#24615;&#33021;&#30340;&#21516;&#26102;&#25552;&#20379;&#23545;&#28508;&#22312;&#30456;&#20851;&#24615;&#21644;&#22240;&#26524;&#20851;&#31995;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.04916v2 Announce Type: cross  Abstract: Islamophobic language is a prevalent challenge on online social interaction platforms. Identifying and eliminating such hatred is a crucial step towards a future of harmony and peace. This study presents a novel paradigm for identifying and explaining hate speech towards Islam using graph neural networks. Utilizing the intrinsic ability of graph neural networks to find, extract, and use relationships across disparate data points, our model consistently achieves outstanding performance while offering explanations for the underlying correlations and causation.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#32508;&#21512;&#32479;&#35745;&#20915;&#31574;&#29702;&#35770;&#21644;&#20449;&#24687;&#32463;&#27982;&#23398;&#65292;&#25552;&#20986;&#20102;&#20915;&#31574;&#38382;&#39064;&#30340;&#24191;&#27867;&#36866;&#29992;&#23450;&#20041;&#12290;&#20026;&#20102;&#23558;&#20154;&#31867;&#20915;&#31574;&#30340;&#19979;&#38477;&#24402;&#21646;&#20110;&#20559;&#35265;&#24418;&#24335;&#65292;&#23454;&#39564;&#24517;&#39035;&#21521;&#21442;&#19982;&#32773;&#25552;&#20379;&#36275;&#22815;&#30340;&#20449;&#24687;&#26469;&#35782;&#21035;&#35268;&#33539;&#20915;&#31574;&#12290;&#28982;&#32780;&#65292;&#26681;&#25454;&#20316;&#32773;&#23545;AI&#36741;&#21161;&#20915;&#31574;&#30340;&#30740;&#31350;&#30340;&#35780;&#20272;&#65292;&#21482;&#26377;17%&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#36275;&#22815;&#30340;&#20449;&#24687;&#26469;&#25551;&#36848;&#21442;&#19982;&#32773;&#30340;&#34892;&#20026;&#20559;&#31163;&#20102;&#33391;&#22909;&#30340;&#20915;&#31574;&#12290;</title><link>http://arxiv.org/abs/2401.15106</link><description>&lt;p&gt;
&#20915;&#31574;&#29702;&#35770;&#22522;&#30784;&#23545;&#35780;&#20272;&#20154;&#31867;&#20915;&#31574;&#30340;&#23454;&#39564;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Decision Theoretic Foundations for Experiments Evaluating Human Decisions. (arXiv:2401.15106v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15106
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#32508;&#21512;&#32479;&#35745;&#20915;&#31574;&#29702;&#35770;&#21644;&#20449;&#24687;&#32463;&#27982;&#23398;&#65292;&#25552;&#20986;&#20102;&#20915;&#31574;&#38382;&#39064;&#30340;&#24191;&#27867;&#36866;&#29992;&#23450;&#20041;&#12290;&#20026;&#20102;&#23558;&#20154;&#31867;&#20915;&#31574;&#30340;&#19979;&#38477;&#24402;&#21646;&#20110;&#20559;&#35265;&#24418;&#24335;&#65292;&#23454;&#39564;&#24517;&#39035;&#21521;&#21442;&#19982;&#32773;&#25552;&#20379;&#36275;&#22815;&#30340;&#20449;&#24687;&#26469;&#35782;&#21035;&#35268;&#33539;&#20915;&#31574;&#12290;&#28982;&#32780;&#65292;&#26681;&#25454;&#20316;&#32773;&#23545;AI&#36741;&#21161;&#20915;&#31574;&#30340;&#30740;&#31350;&#30340;&#35780;&#20272;&#65292;&#21482;&#26377;17%&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#36275;&#22815;&#30340;&#20449;&#24687;&#26469;&#25551;&#36848;&#21442;&#19982;&#32773;&#30340;&#34892;&#20026;&#20559;&#31163;&#20102;&#33391;&#22909;&#30340;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20449;&#24687;&#23637;&#31034;&#30340;&#20915;&#31574;&#26159;&#21487;&#35299;&#37322;AI&#12289;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#30340;&#21512;&#20316;&#20197;&#21450;&#25968;&#25454;&#21487;&#35270;&#21270;&#31561;&#39046;&#22495;&#30740;&#31350;&#30340;&#37325;&#28857;&#12290;&#28982;&#32780;&#65292;&#20915;&#31574;&#38382;&#39064;&#30340;&#23450;&#20041;&#20197;&#21450;&#23454;&#39564;&#24517;&#39035;&#20855;&#22791;&#30340;&#26465;&#20214;&#20197;&#24471;&#20986;&#20154;&#31867;&#20915;&#31574;&#23384;&#22312;&#32570;&#38519;&#30340;&#32467;&#35770;&#20173;&#28982;&#23384;&#22312;&#20105;&#35758;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#24191;&#27867;&#36866;&#29992;&#30340;&#20915;&#31574;&#38382;&#39064;&#23450;&#20041;&#65292;&#35813;&#23450;&#20041;&#26159;&#20174;&#32479;&#35745;&#20915;&#31574;&#29702;&#35770;&#21644;&#20449;&#24687;&#32463;&#27982;&#23398;&#20013;&#32508;&#21512;&#25552;&#28860;&#32780;&#26469;&#30340;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#35201;&#23558;&#20154;&#31867;&#32489;&#25928;&#19979;&#38477;&#24402;&#21646;&#20110;&#26576;&#31181;&#20559;&#35265;&#24418;&#24335;&#65292;&#23454;&#39564;&#24517;&#39035;&#21521;&#21442;&#19982;&#32773;&#25552;&#20379;&#36275;&#22815;&#30340;&#20449;&#24687;&#65292;&#20197;&#20415;&#21512;&#29702;&#30340;&#20195;&#29702;&#33021;&#22815;&#35782;&#21035;&#35268;&#33539;&#20915;&#31574;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#26368;&#36817;&#26377;&#20851;AI&#36741;&#21161;&#20915;&#31574;&#30340;&#25991;&#29486;&#20013;&#23545;&#20915;&#31574;&#21046;&#23450;&#36827;&#34892;&#30340;&#35780;&#20272;&#22312;&#22810;&#22823;&#31243;&#24230;&#19978;&#36798;&#21040;&#20102;&#36825;&#19968;&#26631;&#20934;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#21482;&#26377;35&#39033;&#22768;&#31216;&#30830;&#23450;&#20102;&#26377;&#20559;&#24046;&#34892;&#20026;&#30340;&#30740;&#31350;&#20013;&#30340;6&#39033;&#65288;17%&#65289;&#21521;&#21442;&#19982;&#32773;&#25552;&#20379;&#20102;&#36275;&#22815;&#20449;&#24687;&#26469;&#25551;&#36848;&#20854;&#34892;&#20026;&#20559;&#31163;&#33391;&#22909;&#20915;&#31574;
&lt;/p&gt;
&lt;p&gt;
Decision-making with information displays is a key focus of research in areas like explainable AI, human-AI teaming, and data visualization. However, what constitutes a decision problem, and what is required for an experiment to be capable of concluding that human decisions are flawed in some way, remain open to speculation. We present a widely applicable definition of a decision problem synthesized from statistical decision theory and information economics. We argue that to attribute loss in human performance to forms of bias, an experiment must provide participants with the information that a rational agent would need to identify the normative decision. We evaluate the extent to which recent evaluations of decision-making from the literature on AI-assisted decisions achieve this criteria. We find that only 6 (17\%) of 35 studies that claim to identify biased behavior present participants with sufficient information to characterize their behavior as deviating from good decision-making
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#24515;&#29702;&#27979;&#37327;&#29702;&#35770;&#25581;&#31034;&#20102;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#26222;&#36941;&#26234;&#33021;&#22240;&#23376;g&#30340;&#23384;&#22312;&#65292;&#24182;&#21457;&#29616;&#20102;&#35813;&#22240;&#23376;&#35299;&#37322;&#27169;&#22411;&#24615;&#33021;&#26041;&#24046;&#30340;85%&#65292;&#20026;&#27169;&#22411;&#35780;&#20272;&#21644;&#24320;&#21457;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#25351;&#26631;&#12290;</title><link>http://arxiv.org/abs/2310.11616</link><description>&lt;p&gt;
&#25581;&#31034;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#26222;&#36941;&#26234;&#33021;&#22240;&#23376;&#65306;&#19968;&#31181;&#24515;&#29702;&#27979;&#37327;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Unveiling the General Intelligence Factor in Language Models: A Psychometric Approach. (arXiv:2310.11616v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11616
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#24515;&#29702;&#27979;&#37327;&#29702;&#35770;&#25581;&#31034;&#20102;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#26222;&#36941;&#26234;&#33021;&#22240;&#23376;g&#30340;&#23384;&#22312;&#65292;&#24182;&#21457;&#29616;&#20102;&#35813;&#22240;&#23376;&#35299;&#37322;&#27169;&#22411;&#24615;&#33021;&#26041;&#24046;&#30340;85%&#65292;&#20026;&#27169;&#22411;&#35780;&#20272;&#21644;&#24320;&#21457;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#37319;&#29992;&#24515;&#29702;&#27979;&#37327;&#29702;&#35770;&#65292;&#25581;&#31034;&#20102;&#35821;&#35328;&#27169;&#22411;&#20013;&#26222;&#36941;&#26234;&#33021;&#22240;&#23376;g&#30340;&#23384;&#22312;&#65292;&#24182;&#25193;&#23637;&#20102;&#35813;&#29702;&#35770;&#22312;&#20154;&#31867;&#21644;&#26576;&#20123;&#21160;&#29289;&#29289;&#31181;&#20013;&#30340;&#24212;&#29992;&#12290;&#36890;&#36807;&#23545;&#20004;&#20010;&#22823;&#22411;&#25968;&#25454;&#38598;Open LLM Leaderboard&#65288;&#21253;&#21547;1,232&#20010;&#27169;&#22411;&#65289;&#21644;General Language Understanding Evaluation&#65288;GLUE&#65289;Leaderboard&#65288;&#21253;&#21547;88&#20010;&#27169;&#22411;&#65289;&#36827;&#34892;&#22240;&#23376;&#20998;&#26512;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#19968;&#20010;&#20855;&#26377;&#19968;&#32500;&#24615;&#21644;&#39640;&#24230;&#31283;&#23450;&#24615;&#30340;g&#22240;&#23376;&#65292;&#21487;&#20197;&#35299;&#37322;&#27169;&#22411;&#24615;&#33021;&#26041;&#24046;&#30340;85%&#12290;&#30740;&#31350;&#36824;&#21457;&#29616;&#27169;&#22411;&#22823;&#23567;&#21644;g&#20043;&#38388;&#30340;&#20013;&#24230;&#30456;&#20851;&#24615;&#20026;0.48&#12290;&#22312;&#35821;&#35328;&#27169;&#22411;&#20013;&#21457;&#29616;g&#22240;&#23376;&#20026;&#27169;&#22411;&#35780;&#20272;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#25351;&#26631;&#65292;&#20026;&#26356;&#24378;&#22823;&#12289;&#22522;&#20110;g&#22240;&#23376;&#30340;&#27169;&#22411;&#33021;&#21147;&#35780;&#20272;&#24320;&#36767;&#20102;&#26032;&#30340;&#36884;&#24452;&#12290;&#36825;&#20123;&#21457;&#29616;&#20026;&#20174;&#24515;&#29702;&#27979;&#37327;&#30340;&#35282;&#24230;&#29702;&#35299;&#21644;&#26410;&#26469;&#30740;&#31350;&#20154;&#24037;&#26234;&#33021;&#25552;&#20379;&#20102;&#22522;&#30784;&#65292;&#24182;&#23545;&#27169;&#22411;&#35780;&#20272;&#21644;&#24320;&#21457;&#20855;&#26377;&#23454;&#38469;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study uncovers the factor of general intelligence, or g, in language models, extending the psychometric theory traditionally applied to humans and certain animal species. Utilizing factor analysis on two extensive datasets Open LLM Leaderboard with 1,232 models and General Language Understanding Evaluation (GLUE) Leaderboard with 88 models - we find compelling evidence for a unidimensional, highly stable g factor that accounts for 85% of the variance in model performance. The study also finds a moderate correlation of .48 between model size and g. The discovery of g in language models offers a unified metric for model evaluation and opens new avenues for more robust, g-based model ability assessment. These findings lay the foundation for understanding and future research on artificial general intelligence from a psychometric perspective and have practical implications for model evaluation and development.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#32508;&#36848;&#37325;&#26032;&#24605;&#32771;&#20102;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#33258;&#21160;&#39550;&#39542;&#31995;&#32479;&#20013;&#39044;&#27979;&#21644;&#35268;&#21010;&#30340;&#25972;&#21512;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#23558;&#20854;&#20316;&#20026;&#30456;&#20114;&#20381;&#36182;&#30340;&#32852;&#21512;&#27493;&#39588;&#26469;&#25552;&#39640;&#23433;&#20840;&#24615;&#12289;&#25928;&#29575;&#24615;&#21644;&#33298;&#36866;&#24615;&#30340;&#24517;&#35201;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.05731</link><description>&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#33258;&#21160;&#39550;&#39542;&#31995;&#32479;&#20013;&#30340;&#39044;&#27979;&#21644;&#35268;&#21010;&#30340;&#25972;&#21512;&#65306;&#19968;&#39033;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Rethinking Integration of Prediction and Planning in Deep Learning-Based Automated Driving Systems: A Review. (arXiv:2308.05731v1 [cs.RO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05731
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#32508;&#36848;&#37325;&#26032;&#24605;&#32771;&#20102;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#33258;&#21160;&#39550;&#39542;&#31995;&#32479;&#20013;&#39044;&#27979;&#21644;&#35268;&#21010;&#30340;&#25972;&#21512;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#23558;&#20854;&#20316;&#20026;&#30456;&#20114;&#20381;&#36182;&#30340;&#32852;&#21512;&#27493;&#39588;&#26469;&#25552;&#39640;&#23433;&#20840;&#24615;&#12289;&#25928;&#29575;&#24615;&#21644;&#33298;&#36866;&#24615;&#30340;&#24517;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#39550;&#39542;&#26377;&#21487;&#33021;&#24443;&#24213;&#25913;&#21464;&#20010;&#20154;&#12289;&#20844;&#20849;&#21644;&#36135;&#36816;&#20132;&#36890;&#30340;&#26041;&#24335;&#12290;&#38500;&#20102;&#24863;&#30693;&#29615;&#22659;&#30340;&#24040;&#22823;&#25361;&#25112;&#22806;&#65292;&#21363;&#20934;&#30830;&#22320;&#20351;&#29992;&#21487;&#29992;&#30340;&#20256;&#24863;&#22120;&#25968;&#25454;&#24863;&#30693;&#29615;&#22659;&#65292;&#33258;&#21160;&#39550;&#39542;&#36824;&#21253;&#25324;&#35268;&#21010;&#19968;&#20010;&#23433;&#20840;&#12289;&#33298;&#36866;&#21644;&#39640;&#25928;&#30340;&#36816;&#21160;&#36712;&#36857;&#12290;&#20026;&#20102;&#20419;&#36827;&#23433;&#20840;&#21644;&#36827;&#27493;&#65292;&#35768;&#22810;&#24037;&#20316;&#20381;&#36182;&#20110;&#27169;&#22359;&#21270;&#30340;&#20132;&#36890;&#26410;&#26469;&#36816;&#21160;&#30340;&#39044;&#27979;&#12290;&#27169;&#22359;&#21270;&#30340;&#33258;&#21160;&#39550;&#39542;&#31995;&#32479;&#36890;&#24120;&#23558;&#39044;&#27979;&#21644;&#35268;&#21010;&#20316;&#20026;&#39034;&#24207;&#30340;&#29420;&#31435;&#20219;&#21153;&#22788;&#29702;&#12290;&#34429;&#28982;&#36825;&#32771;&#34385;&#20102;&#21608;&#22260;&#20132;&#36890;&#23545;&#33258;&#36710;&#30340;&#24433;&#21709;&#65292;&#20294;&#23427;&#26410;&#33021;&#39044;&#27979;&#20132;&#36890;&#21442;&#19982;&#32773;&#23545;&#33258;&#36710;&#34892;&#20026;&#30340;&#21453;&#24212;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#23558;&#39044;&#27979;&#21644;&#35268;&#21010;&#25972;&#21512;&#20026;&#30456;&#20114;&#20381;&#36182;&#30340;&#32852;&#21512;&#27493;&#39588;&#26159;&#23454;&#29616;&#23433;&#20840;&#12289;&#39640;&#25928;&#21644;&#33298;&#36866;&#39550;&#39542;&#25152;&#24517;&#38656;&#30340;&#12290;&#34429;&#28982;&#26377;&#21508;&#31181;&#27169;&#22411;&#23454;&#29616;&#20102;&#36825;&#31181;&#38598;&#25104;&#31995;&#32479;&#65292;&#20294;&#23545;&#19981;&#21516;&#21407;&#29702;&#30340;&#20840;&#38754;&#27010;&#36848;&#21644;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#32570;&#20047;&#12290;
&lt;/p&gt;
&lt;p&gt;
Automated driving has the potential to revolutionize personal, public, and freight mobility. Besides the enormous challenge of perception, i.e. accurately perceiving the environment using available sensor data, automated driving comprises planning a safe, comfortable, and efficient motion trajectory. To promote safety and progress, many works rely on modules that predict the future motion of surrounding traffic. Modular automated driving systems commonly handle prediction and planning as sequential separate tasks. While this accounts for the influence of surrounding traffic on the ego-vehicle, it fails to anticipate the reactions of traffic participants to the ego-vehicle's behavior. Recent works suggest that integrating prediction and planning in an interdependent joint step is necessary to achieve safe, efficient, and comfortable driving. While various models implement such integrated systems, a comprehensive overview and theoretical understanding of different principles are lacking.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;RRWKV&#26550;&#26500;&#65292;&#23427;&#22312;&#20445;&#25345;&#35760;&#24518;&#21644;&#35745;&#31639;&#25928;&#29575;&#30340;&#21516;&#26102;&#65292;&#36890;&#36807;&#21152;&#20837;&#22238;&#39038;&#33021;&#21147;&#26377;&#25928;&#22320;&#25429;&#25417;&#38271;&#36317;&#31163;&#20381;&#36182;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2306.05176</link><description>&lt;p&gt;
RRWKV&#65306;&#22312;RWKV&#20013;&#25429;&#25417;&#38271;&#36317;&#31163;&#20381;&#36182;&#20851;&#31995;
&lt;/p&gt;
&lt;p&gt;
RRWKV: Capturing Long-range Dependencies in RWKV. (arXiv:2306.05176v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05176
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;RRWKV&#26550;&#26500;&#65292;&#23427;&#22312;&#20445;&#25345;&#35760;&#24518;&#21644;&#35745;&#31639;&#25928;&#29575;&#30340;&#21516;&#26102;&#65292;&#36890;&#36807;&#21152;&#20837;&#22238;&#39038;&#33021;&#21147;&#26377;&#25928;&#22320;&#25429;&#25417;&#38271;&#36317;&#31163;&#20381;&#36182;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;Transformer&#24778;&#20154;&#30340;&#28857;&#31215;&#27880;&#24847;&#21147;&#65292;&#23427;&#24050;&#32463;&#25104;&#20026;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20219;&#21153;&#20013;&#30340;&#20027;&#35201;&#26550;&#26500;&#12290;&#26368;&#36817;&#65292;Receptance Weighted Key Value&#65288;RWKV&#65289;&#26550;&#26500;&#36981;&#24490;&#38750;Transformer&#26550;&#26500;&#65292;&#28040;&#38500;&#20102;&#28857;&#31215;&#27880;&#24847;&#21147;&#30340;&#32570;&#28857;&#65292;&#20854;&#20013;&#23384;&#20648;&#21644;&#35745;&#31639;&#22797;&#26434;&#24230;&#38543;&#30528;&#24207;&#21015;&#38271;&#24230;&#21576;&#20108;&#27425;&#25193;&#23637;&#12290;&#23613;&#31649;RWKV&#21033;&#29992;&#20102;&#32447;&#24615;&#24352;&#37327;&#31215;&#27880;&#24847;&#26426;&#21046;&#24182;&#36890;&#36807;&#37096;&#32626;&#26102;&#38388;&#24207;&#21015;&#27169;&#24335;&#23454;&#29616;&#20102;&#24182;&#34892;&#35745;&#31639;&#65292;&#20294;&#19982;&#26631;&#20934;Transformer&#20013;&#30452;&#25509;&#20132;&#20114;&#33719;&#24471;&#30340;&#23436;&#25972;&#20449;&#24687;&#30456;&#27604;&#65292;&#23427;&#26080;&#27861;&#25429;&#25417;&#38271;&#36317;&#31163;&#20381;&#36182;&#20851;&#31995;&#65292;&#22240;&#20026;&#20854;&#21463;&#38480;&#20110;&#21521;&#21518;&#26597;&#30475;&#20808;&#21069;&#20449;&#24687;&#30340;&#33021;&#21147;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#36890;&#36807;&#23558;&#22238;&#39038;&#33021;&#21147;&#32435;&#20837;RWKV&#20013;&#26469;&#35774;&#35745;Retrospected Receptance Weighted Key Value&#65288;RRWKV&#65289;&#26550;&#26500;&#65292;&#20197;&#26377;&#25928;&#22320;&#21560;&#25910;&#20449;&#24687;&#65292;&#21516;&#26102;&#20445;&#25345;&#35760;&#24518;&#21644;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Owing to the impressive dot-product attention, the Transformers have been the dominant architectures in various natural language processing (NLP) tasks. Recently, the Receptance Weighted Key Value (RWKV) architecture follows a non-transformer architecture to eliminate the drawbacks of dot-product attention, where memory and computational complexity exhibits quadratic scaling with sequence length. Although RWKV has exploited a linearly tensor-product attention mechanism and achieved parallelized computations by deploying the time-sequential mode, it fails to capture long-range dependencies because of its limitation on looking back at previous information, compared with full information obtained by direct interactions in the standard transformer. Therefore, the paper devises the Retrospected Receptance Weighted Key Value (RRWKV) architecture via incorporating the retrospecting ability into the RWKV to effectively absorb information, which maintains memory and computational efficiency as 
&lt;/p&gt;</description></item></channel></rss>