<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#20855;&#26377;&#28508;&#22312;&#20248;&#21183;&#65292;&#36890;&#36807;&#32467;&#26500;&#21270;&#20998;&#31867;&#21644;&#35282;&#33394;&#20998;&#26512;&#65292;&#20026;&#26410;&#26469;&#30740;&#31350;&#25552;&#20379;&#25351;&#23548;&#12290;</title><link>https://arxiv.org/abs/2404.00282</link><description>&lt;p&gt;
&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22686;&#24378;&#24378;&#21270;&#23398;&#20064;&#30340;&#35843;&#26597;:&#27010;&#24565;&#12289;&#20998;&#31867;&#21644;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Survey on Large Language Model-Enhanced Reinforcement Learning: Concept, Taxonomy, and Methods
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00282
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#20855;&#26377;&#28508;&#22312;&#20248;&#21183;&#65292;&#36890;&#36807;&#32467;&#26500;&#21270;&#20998;&#31867;&#21644;&#35282;&#33394;&#20998;&#26512;&#65292;&#20026;&#26410;&#26469;&#30740;&#31350;&#25552;&#20379;&#25351;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;(LLMs)&#25317;&#26377;&#24191;&#27867;&#30340;&#39044;&#35757;&#32451;&#30693;&#35782;&#21644;&#39640;&#32423;&#36890;&#29992;&#33021;&#21147;&#65292;&#23427;&#20204;&#22312;&#22686;&#24378;&#23398;&#20064;&#26041;&#38754;&#22914;&#22810;&#20219;&#21153;&#23398;&#20064;&#12289;&#26679;&#26412;&#25928;&#29575;&#21644;&#20219;&#21153;&#35268;&#21010;&#31561;&#26041;&#38754;&#23637;&#29616;&#20986;&#28508;&#21147;&#12290;&#26412;&#35843;&#26597;&#32508;&#36848;&#20102;&#29616;&#26377;$\textit{LLM&#22686;&#24378;RL}$&#25991;&#29486;&#65292;&#24635;&#32467;&#20102;&#20854;&#19982;&#20256;&#32479;RL&#26041;&#27861;&#30340;&#29305;&#24449;&#65292;&#26088;&#22312;&#28548;&#28165;&#30740;&#31350;&#33539;&#22260;&#21644;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#12290;&#21033;&#29992;&#32463;&#20856;&#30340;Agent-&#29615;&#22659;&#20132;&#20114;&#33539;&#20363;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32467;&#26500;&#21270;&#30340;&#20998;&#31867;&#27861;&#65292;&#31995;&#32479;&#22320;&#23558;LLMs&#22312;RL&#20013;&#30340;&#21151;&#33021;&#20998;&#31867;&#65292;&#21253;&#25324;&#22235;&#31181;&#35282;&#33394;&#65306;&#20449;&#24687;&#22788;&#29702;&#22120;&#12289;&#22870;&#21169;&#35774;&#35745;&#32773;&#12289;&#20915;&#31574;&#32773;&#21644;&#29983;&#25104;&#22120;&#12290;&#27492;&#22806;&#65292;&#38024;&#23545;&#27599;&#20010;&#35282;&#33394;&#65292;&#25105;&#20204;&#24635;&#32467;&#20102;&#26041;&#27861;&#35770;&#65292;&#20998;&#26512;&#20102;&#32531;&#35299;&#30340;&#29305;&#23450;RL&#25361;&#25112;&#65292;&#24182;&#25552;&#20379;&#20102;&#26410;&#26469;&#26041;&#21521;&#30340;&#35265;&#35299;&#12290;&#26368;&#21518;&#65292;&#28508;&#22312;&#24212;&#29992;&#12289;&#21069;&#26223;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00282v1 Announce Type: cross  Abstract: With extensive pre-trained knowledge and high-level general capabilities, large language models (LLMs) emerge as a promising avenue to augment reinforcement learning (RL) in aspects such as multi-task learning, sample efficiency, and task planning. In this survey, we provide a comprehensive review of the existing literature in $\textit{LLM-enhanced RL}$ and summarize its characteristics compared to conventional RL methods, aiming to clarify the research scope and directions for future studies. Utilizing the classical agent-environment interaction paradigm, we propose a structured taxonomy to systematically categorize LLMs' functionalities in RL, including four roles: information processor, reward designer, decision-maker, and generator. Additionally, for each role, we summarize the methodologies, analyze the specific RL challenges that are mitigated, and provide insights into future directions. Lastly, potential applications, prospecti
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#28982;&#24341;&#23548;&#30340;&#35748;&#30693;&#36827;&#21270;&#31574;&#30053;&#65292;&#36890;&#36807;&#22810;&#23618;&#34701;&#21512;&#33258;&#36866;&#24212;&#23398;&#20064;&#21644;&#33258;&#28982;&#36807;&#31243;&#65292;&#26377;&#25928;&#39044;&#27979;&#21271;&#28201;&#24102;&#28246;&#27850;&#20013;&#30340;&#28342;&#35299;&#27687;&#27987;&#24230;</title><link>https://arxiv.org/abs/2403.18923</link><description>&lt;p&gt;
&#33258;&#28982;&#24341;&#23548;&#30340;&#35748;&#30693;&#36827;&#21270;&#29992;&#20110;&#39044;&#27979;&#21271;&#28201;&#24102;&#28246;&#27850;&#20013;&#30340;&#28342;&#35299;&#27687;&#27987;&#24230;
&lt;/p&gt;
&lt;p&gt;
Nature-Guided Cognitive Evolution for Predicting Dissolved Oxygen Concentrations in North Temperate Lakes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18923
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#28982;&#24341;&#23548;&#30340;&#35748;&#30693;&#36827;&#21270;&#31574;&#30053;&#65292;&#36890;&#36807;&#22810;&#23618;&#34701;&#21512;&#33258;&#36866;&#24212;&#23398;&#20064;&#21644;&#33258;&#28982;&#36807;&#31243;&#65292;&#26377;&#25928;&#39044;&#27979;&#21271;&#28201;&#24102;&#28246;&#27850;&#20013;&#30340;&#28342;&#35299;&#27687;&#27987;&#24230;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#27979;&#21271;&#28201;&#24102;&#28246;&#27850;&#20013;&#30340;&#28342;&#35299;&#27687;&#65288;DO&#65289;&#27987;&#24230;&#38656;&#35201;&#23545;&#19981;&#21516;&#29983;&#24577;&#31995;&#32479;&#20013;&#30340;&#29289;&#20505;&#27169;&#24335;&#36827;&#34892;&#20840;&#38754;&#30740;&#31350;&#65292;&#36825;&#20984;&#26174;&#20102;&#36873;&#25321;&#29289;&#20505;&#29305;&#24449;&#21644;&#29305;&#24449;&#20132;&#20114;&#30340;&#37325;&#35201;&#24615;&#12290;&#22522;&#20110;&#36807;&#31243;&#30340;&#27169;&#22411;&#21463;&#37096;&#20998;&#36807;&#31243;&#30693;&#35782;&#38480;&#21046;&#25110;&#29305;&#24449;&#34920;&#31034;&#36807;&#20110;&#31616;&#21270;&#65292;&#32780;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#26377;&#25928;&#36873;&#25321;&#19981;&#21516;&#28246;&#27850;&#31867;&#22411;&#21644;&#20219;&#21153;&#30340;&#30456;&#20851;&#29305;&#24449;&#20132;&#20114;&#26041;&#38754;&#38754;&#20020;&#25361;&#25112;&#65292;&#23588;&#20854;&#26159;&#22312;DO&#25968;&#25454;&#25910;&#38598;&#19981;&#39057;&#32321;&#30340;&#24773;&#20917;&#19979;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#28982;&#24341;&#23548;&#30340;&#35748;&#30693;&#36827;&#21270;&#65288;NGCE&#65289;&#31574;&#30053;&#65292;&#36825;&#20195;&#34920;&#20102;&#33258;&#36866;&#24212;&#23398;&#20064;&#19982;&#33258;&#28982;&#36807;&#31243;&#22810;&#23618;&#34701;&#21512;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#21033;&#29992;&#20195;&#35874;&#36807;&#31243;&#20026;&#22522;&#30784;&#30340;&#27169;&#22411;&#29983;&#25104;&#27169;&#25311;DO&#26631;&#31614;&#12290;&#21033;&#29992;&#36825;&#20123;&#27169;&#25311;&#26631;&#31614;&#65292;&#25105;&#20204;&#23454;&#26045;&#20102;&#19968;&#20010;&#22810;&#31181;&#32676;&#35748;&#30693;&#36827;&#21270;&#25628;&#32034;&#65292;&#27169;&#22411;&#21453;&#26144;&#33258;&#28982;&#26377;&#26426;&#20307;&#65292;&#36866;&#24212;&#24615;&#22320;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18923v1 Announce Type: cross  Abstract: Predicting dissolved oxygen (DO) concentrations in north temperate lakes requires a comprehensive study of phenological patterns across various ecosystems, which highlights the significance of selecting phenological features and feature interactions. Process-based models are limited by partial process knowledge or oversimplified feature representations, while machine learning models face challenges in efficiently selecting relevant feature interactions for different lake types and tasks, especially under the infrequent nature of DO data collection. In this paper, we propose a Nature-Guided Cognitive Evolution (NGCE) strategy, which represents a multi-level fusion of adaptive learning with natural processes. Specifically, we utilize metabolic process-based models to generate simulated DO labels. Using these simulated labels, we implement a multi-population cognitive evolutionary search, where models, mirroring natural organisms, adaptiv
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32858;&#31867;&#30340;&#31070;&#32463;&#32593;&#32476;&#35268;&#33539;&#21270;&#26041;&#27861;CB-Norm&#65292;&#36890;&#36807;&#24341;&#20837;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#26799;&#24230;&#31283;&#23450;&#24615;&#21644;&#23398;&#20064;&#21152;&#36895;&#26041;&#38754;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2403.16798</link><description>&lt;p&gt;
&#22522;&#20110;&#32858;&#31867;&#30340;&#31070;&#32463;&#32593;&#32476;&#35268;&#33539;&#21270;&#23618;
&lt;/p&gt;
&lt;p&gt;
Cluster-Based Normalization Layer for Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16798
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32858;&#31867;&#30340;&#31070;&#32463;&#32593;&#32476;&#35268;&#33539;&#21270;&#26041;&#27861;CB-Norm&#65292;&#36890;&#36807;&#24341;&#20837;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#26799;&#24230;&#31283;&#23450;&#24615;&#21644;&#23398;&#20064;&#21152;&#36895;&#26041;&#38754;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#22312;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#36807;&#31243;&#20013;&#38754;&#20020;&#37325;&#35201;&#25361;&#25112;&#65292;&#21253;&#25324;&#20869;&#37096;&#21327;&#21464;&#37327;&#28418;&#31227;&#12289;&#26631;&#31614;&#28418;&#31227;&#12289;&#26799;&#24230;&#28040;&#22833;/&#29190;&#28856;&#12289;&#36807;&#25311;&#21512;&#21644;&#35745;&#31639;&#22797;&#26434;&#24615;&#12290;&#20256;&#32479;&#30340;&#35268;&#33539;&#21270;&#26041;&#27861;&#65292;&#22914;&#25209;&#26631;&#20934;&#21270;&#65292;&#26088;&#22312;&#35299;&#20915;&#20854;&#20013;&#19968;&#20123;&#38382;&#39064;&#65292;&#20294;&#36890;&#24120;&#20381;&#36182;&#20110;&#38480;&#21046;&#20854;&#36866;&#24212;&#24615;&#30340;&#20551;&#35774;&#12290;&#28151;&#21512;&#35268;&#33539;&#21270;&#22312;&#22788;&#29702;&#22810;&#20010;&#39640;&#26031;&#20998;&#24067;&#26102;&#38754;&#20020;&#35745;&#31639;&#38556;&#30861;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#32858;&#31867;&#30340;&#35268;&#33539;&#21270;&#65288;CB-Norm&#65289;&#30340;&#20004;&#20010;&#21464;&#20307;&#8212;&#8212;&#30417;&#30563;&#24335;&#22522;&#20110;&#32858;&#31867;&#30340;&#35268;&#33539;&#21270;&#65288;SCB-Norm&#65289;&#21644;&#26080;&#30417;&#30563;&#24335;&#22522;&#20110;&#32858;&#31867;&#30340;&#35268;&#33539;&#21270;&#65288;UCB-Norm&#65289;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#24320;&#21019;&#24615;&#30340;&#19968;&#27493;&#35268;&#33539;&#21270;&#26041;&#27861;&#12290;CB-Norm&#21033;&#29992;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#26469;&#19987;&#38376;&#35299;&#20915;&#19982;&#26799;&#24230;&#31283;&#23450;&#24615;&#21644;&#23398;&#20064;&#21152;&#36895;&#26377;&#20851;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16798v1 Announce Type: cross  Abstract: Deep learning faces significant challenges during the training of neural networks, including internal covariate shift, label shift, vanishing/exploding gradients, overfitting, and computational complexity. While conventional normalization methods, such as Batch Normalization, aim to tackle some of these issues, they often depend on assumptions that constrain their adaptability. Mixture Normalization faces computational hurdles in its pursuit of handling multiple Gaussian distributions.   This paper introduces Cluster-Based Normalization (CB-Norm) in two variants - Supervised Cluster-Based Normalization (SCB-Norm) and Unsupervised Cluster-Based Normalization (UCB-Norm) - proposing a groundbreaking one-step normalization approach. CB-Norm leverages a Gaussian mixture model to specifically address challenges related to gradient stability and learning acceleration.   For SCB-Norm, a supervised variant, the novel mechanism involves introduc
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#24443;&#24213;&#37325;&#26657;&#20934;&#20559;&#22909;&#25968;&#25454;&#38598;&#20013;&#30340;&#20215;&#20540;&#35266;&#65292;&#20197;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#38382;&#39064;&#30340;&#38887;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.02745</link><description>&lt;p&gt;
CURATRON&#65306;&#23436;&#25972;&#20581;&#22766;&#20559;&#22909;&#25968;&#25454;&#29992;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20581;&#22766;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
CURATRON: Complete Robust Preference Data for Robust Alignment of Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02745
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#24443;&#24213;&#37325;&#26657;&#20934;&#20559;&#22909;&#25968;&#25454;&#38598;&#20013;&#30340;&#20215;&#20540;&#35266;&#65292;&#20197;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#38382;&#39064;&#30340;&#38887;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#35299;&#20915;&#20102;&#36890;&#36807;&#20559;&#22909;&#23398;&#20064;&#65288;PL&#65289;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#19982;&#20154;&#31867;&#20215;&#20540;&#35266;&#23545;&#40784;&#30340;&#25361;&#25112;&#65292;&#37325;&#28857;&#20851;&#27880;&#20559;&#22909;&#25968;&#25454;&#38598;&#20013;&#19981;&#23436;&#25972;&#21644;&#25439;&#22351;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#24443;&#24213;&#21644;&#23436;&#20840;&#22320;&#37325;&#26032;&#26657;&#20934;&#36825;&#20123;&#25968;&#25454;&#38598;&#20013;&#30340;&#20215;&#20540;&#35266;&#65292;&#20197;&#22686;&#24378;LLMs&#23545;&#38382;&#39064;&#30340;&#38887;&#24615;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#26377;&#20445;&#35777;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#25490;&#21517;&#31639;&#27861;&#65292;&#21487;&#20197;&#22686;&#24378;&#20960;&#31181;&#29616;&#26377;&#27169;&#22411;&#30340;&#20581;&#22766;&#24615;&#65292;&#27604;&#22914;&#32463;&#20856;&#30340;Bradley&#8211;Terry&#8211;Luce&#65288;BTL&#65289;&#65288;Bradley&#21644;Terry&#65292;1952&#65289;&#27169;&#22411;&#20197;&#21450;&#23545;&#20854;&#26576;&#20123;&#25512;&#24191;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#26159;&#31532;&#19968;&#20010;&#25552;&#20986;&#19968;&#31181;&#21487;&#35777;&#26126;&#22312;&#39640;&#27010;&#29575;&#19979;&#24674;&#22797;{\epsilon}-&#26368;&#20248;&#25490;&#24207;&#30340;&#31639;&#27861;&#65292;&#21516;&#26102;&#20801;&#35768;&#27599;&#20010;&#27169;&#22411;&#21709;&#24212;&#22810;&#36798;O(n)&#25200;&#21160;&#30340;&#25104;&#23545;&#27604;&#36739;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#37096;&#20998;&#35266;&#23519;&#35774;&#32622;&#19979;&#30340;&#20581;&#22766;&#24674;&#22797;&#32467;&#26524;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#23454;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02745v1 Announce Type: new  Abstract: This paper addresses the challenges of aligning large language models (LLMs) with human values via preference learning (PL), with a focus on the issues of incomplete and corrupted data in preference datasets. We propose a novel method for robustly and completely recalibrating values within these datasets to enhance LLMs resilience against the issues. In particular, we devise a guaranteed polynomial time ranking algorithm that robustifies several existing models, such as the classic Bradley--Terry--Luce (BTL) (Bradley and Terry, 1952) model and certain generalizations of it. To the best of our knowledge, our present work is the first to propose an algorithm that provably recovers an {\epsilon}-optimal ranking with high probability while allowing as large as O(n) perturbed pairwise comparison results per model response. Furthermore, we show robust recovery results in the partially observed setting. Our experiments confirm that our algorith
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;DGMed&#26694;&#26550;&#65292;&#21033;&#29992;&#22240;&#26524;&#25512;&#26029;&#21644;&#21019;&#26032;&#30340;&#29305;&#24449;&#23545;&#40784;&#26041;&#27861;&#36827;&#34892;&#21452;&#31890;&#24230;&#33647;&#29289;&#25512;&#33616;</title><link>https://arxiv.org/abs/2403.00880</link><description>&lt;p&gt;
&#22522;&#20110;&#22240;&#26524;&#25512;&#26029;&#30340;&#21452;&#31890;&#24230;&#33647;&#29289;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Dual-Granularity Medication Recommendation Based on Causal Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00880
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;DGMed&#26694;&#26550;&#65292;&#21033;&#29992;&#22240;&#26524;&#25512;&#26029;&#21644;&#21019;&#26032;&#30340;&#29305;&#24449;&#23545;&#40784;&#26041;&#27861;&#36827;&#34892;&#21452;&#31890;&#24230;&#33647;&#29289;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#21307;&#30103;&#38656;&#27714;&#22686;&#38271;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#30340;&#36827;&#27493;&#65292;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#30340;&#35786;&#26029;&#21644;&#27835;&#30103;&#31995;&#32479;&#22791;&#21463;&#20851;&#27880;&#12290;&#33647;&#29289;&#25512;&#33616;&#26088;&#22312;&#23558;&#24739;&#32773;&#30340;&#38271;&#26399;&#20581;&#24247;&#35760;&#24405;&#19982;&#21307;&#23398;&#30693;&#35782;&#25972;&#21512;&#65292;&#20026;&#29305;&#23450;&#30142;&#30149;&#25512;&#33616;&#20934;&#30830;&#21644;&#23433;&#20840;&#30340;&#33647;&#29289;&#32452;&#21512;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30740;&#31350;&#23558;&#33647;&#29289;&#25512;&#33616;&#31995;&#32479;&#20165;&#35270;&#20026;&#20256;&#32479;&#25512;&#33616;&#31995;&#32479;&#30340;&#21464;&#20307;&#65292;&#24573;&#35270;&#20102;&#33647;&#29289;&#21644;&#30142;&#30149;&#20043;&#38388;&#30340;&#24322;&#36136;&#24615;&#12290;&#20026;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;DGMed&#65292;&#19968;&#20010;&#29992;&#20110;&#33647;&#29289;&#25512;&#33616;&#30340;&#26694;&#26550;&#12290;DGMed&#21033;&#29992;&#22240;&#26524;&#25512;&#26029;&#25581;&#31034;&#21307;&#23398;&#23454;&#20307;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#29305;&#24449;&#23545;&#40784;&#26041;&#27861;&#26469;&#35299;&#20915;&#24322;&#36136;&#24615;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#35813;&#30740;&#31350;&#39318;&#20808;&#24212;&#29992;&#22240;&#26524;&#25512;&#26029;&#20998;&#26512;&#21382;&#21490;&#35760;&#24405;&#20013;&#33647;&#29289;&#23545;&#29305;&#23450;&#30142;&#30149;&#30340;&#37327;&#21270;&#27835;&#30103;&#25928;&#26524;&#65292;&#25581;&#31034;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00880v1 Announce Type: cross  Abstract: As medical demands grow and machine learning technology advances, AI-based diagnostic and treatment systems are garnering increasing attention. Medication recommendation aims to integrate patients' long-term health records with medical knowledge, recommending accuracy and safe medication combinations for specific conditions. However, most existing researches treat medication recommendation systems merely as variants of traditional recommendation systems, overlooking the heterogeneity between medications and diseases. To address this challenge, we propose DGMed, a framework for medication recommendation. DGMed utilizes causal inference to uncover the connections among medical entities and presents an innovative feature alignment method to tackle heterogeneity issues. Specifically, this study first applies causal inference to analyze the quantified therapeutic effects of medications on specific diseases from historical records, uncoverin
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#22810;&#36718;&#23545;&#35805;&#20013;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23433;&#20840;&#24615;&#28431;&#27934;&#65292;&#25351;&#20986;&#20154;&#31867;&#21487;&#20197;&#36890;&#36807;&#22810;&#36718;&#23545;&#35805;&#35825;&#20351;&#20854;&#29983;&#25104;&#26377;&#23475;&#20449;&#24687;&#12290;</title><link>https://arxiv.org/abs/2402.17262</link><description>&lt;p&gt;
&#22833;&#35328;&#65306;&#22810;&#36718;&#23545;&#35805;&#20013;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23433;&#20840;&#28431;&#27934;
&lt;/p&gt;
&lt;p&gt;
Speak Out of Turn: Safety Vulnerability of Large Language Models in Multi-turn Dialogue
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17262
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#22810;&#36718;&#23545;&#35805;&#20013;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23433;&#20840;&#24615;&#28431;&#27934;&#65292;&#25351;&#20986;&#20154;&#31867;&#21487;&#20197;&#36890;&#36807;&#22810;&#36718;&#23545;&#35805;&#35825;&#20351;&#20854;&#29983;&#25104;&#26377;&#23475;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#24050;&#34987;&#35777;&#26126;&#22312;&#38754;&#20020;"&#36234;&#29425;"&#26102;&#20250;&#20135;&#29983;&#38750;&#27861;&#25110;&#19981;&#36947;&#24503;&#30340;&#22238;&#24212;&#12290; "&#36234;&#29425;"&#30740;&#31350;&#24378;&#35843;&#20102;LLMs&#30340;&#23433;&#20840;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#21333;&#36718;&#23545;&#35805;&#19978;&#65292;&#24573;&#35270;&#20102;&#22810;&#36718;&#23545;&#35805;&#21487;&#33021;&#24102;&#26469;&#30340;&#22797;&#26434;&#24615;&#21644;&#39118;&#38505;&#65292;&#36825;&#26159;&#20154;&#31867;&#20174;LLMs&#33719;&#21462;&#20449;&#24687;&#30340;&#20851;&#38190;&#26041;&#24335;&#12290;&#26412;&#25991;&#35748;&#20026;&#20154;&#31867;&#21487;&#20197;&#21033;&#29992;&#22810;&#36718;&#23545;&#35805;&#35825;&#20351;LLMs&#29983;&#25104;&#26377;&#23475;&#20449;&#24687;&#12290;LLMs&#21487;&#33021;&#19981;&#20250;&#25298;&#32477;&#35686;&#21578;&#24615;&#25110;&#36793;&#30028;&#19981;&#23433;&#20840;&#30340;&#26597;&#35810;&#65292;&#21363;&#20351;&#22312;&#22810;&#36718;&#23545;&#35805;&#20013;&#27599;&#20010;&#22238;&#21512;&#37117;&#34987;&#26381;&#21153;&#20110;&#19968;&#20010;&#24694;&#24847;&#30446;&#30340;&#12290;&#22240;&#27492;&#65292;&#36890;&#36807;&#23558;&#19968;&#20010;&#19981;&#23433;&#20840;&#26597;&#35810;&#20998;&#35299;&#20026;&#22810;&#20010;&#23376;&#26597;&#35810;&#29992;&#20110;&#22810;&#36718;&#23545;&#35805;&#65292;&#25105;&#20204;&#36880;&#28176;&#35825;&#20351;LLMs&#22238;&#31572;&#26377;&#23475;&#30340;&#23376;&#38382;&#39064;&#65292;&#26368;&#32456;&#23548;&#33268;&#24635;&#20307;&#26377;&#23475;&#21709;&#24212;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#36328;&#36234;&#20102;&#24191;&#27867;&#30340;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17262v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have been demonstrated to generate illegal or unethical responses, particularly when subjected to "jailbreak." Research on jailbreak has highlighted the safety issues of LLMs. However, prior studies have predominantly focused on single-turn dialogue, ignoring the potential complexities and risks presented by multi-turn dialogue, a crucial mode through which humans derive information from LLMs. In this paper, we argue that humans could exploit multi-turn dialogue to induce LLMs into generating harmful information. LLMs may not intend to reject cautionary or borderline unsafe queries, even if each turn is closely served for one malicious purpose in a multi-turn dialogue. Therefore, by decomposing an unsafe query into several sub-queries for multi-turn dialogue, we induced LLMs to answer harmful sub-questions incrementally, culminating in an overall harmful response. Our experiments, conducted across a wide ra
&lt;/p&gt;</description></item><item><title>NeuralThink &#26159;&#19968;&#31181;&#26032;&#30340;&#36882;&#24402;&#26550;&#26500;&#65292;&#21487;&#20197;&#19968;&#36143;&#22320;&#23545;&#23545;&#31216;&#21644;&#19981;&#23545;&#31216;&#20219;&#21153;&#36827;&#34892;&#22806;&#25512;&#65292;&#30456;&#36739;&#20110;&#20043;&#21069;&#30340;&#26368;&#20808;&#36827;&#30340;&#28145;&#24230;&#24605;&#32500;&#26550;&#26500;&#22312;&#31283;&#23450;&#22320;&#20174;&#36739;&#23567;&#30340;&#35757;&#32451;&#35268;&#27169;&#23545;&#22823;&#35266;&#27979;&#36827;&#34892;&#22806;&#25512;&#26041;&#38754;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.15393</link><description>&lt;p&gt;
NeuralThink: &#22312;&#19968;&#33324;&#20219;&#21153;&#20013;&#36827;&#34892;&#22806;&#25512;&#30340;&#31639;&#27861;&#32508;&#21512;
&lt;/p&gt;
&lt;p&gt;
NeuralThink: Algorithm Synthesis that Extrapolates in General Tasks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15393
&lt;/p&gt;
&lt;p&gt;
NeuralThink &#26159;&#19968;&#31181;&#26032;&#30340;&#36882;&#24402;&#26550;&#26500;&#65292;&#21487;&#20197;&#19968;&#36143;&#22320;&#23545;&#23545;&#31216;&#21644;&#19981;&#23545;&#31216;&#20219;&#21153;&#36827;&#34892;&#22806;&#25512;&#65292;&#30456;&#36739;&#20110;&#20043;&#21069;&#30340;&#26368;&#20808;&#36827;&#30340;&#28145;&#24230;&#24605;&#32500;&#26550;&#26500;&#22312;&#31283;&#23450;&#22320;&#20174;&#36739;&#23567;&#30340;&#35757;&#32451;&#35268;&#27169;&#23545;&#22823;&#35266;&#27979;&#36827;&#34892;&#22806;&#25512;&#26041;&#38754;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#25797;&#38271;&#27169;&#24335;&#35782;&#21035;&#65292;&#20294;&#22312;&#21487;&#25193;&#23637;&#30340;&#31639;&#27861;&#26041;&#24335;&#19978;&#22788;&#29702;&#22797;&#26434;&#30340;&#25512;&#29702;&#20219;&#21153;&#26102;&#20173;&#28982;&#38754;&#20020;&#22256;&#38590;&#12290;&#26368;&#36817;&#30340;&#28145;&#24230;&#24605;&#32500;&#26041;&#27861;&#23637;&#29616;&#20102;&#23398;&#20064;&#21487;&#20197;&#22806;&#25512;&#30340;&#31639;&#27861;&#30340;&#28508;&#21147;&#65306;&#22312;&#36739;&#23567;&#30340;&#29615;&#22659;&#20013;&#23398;&#20064;&#24182;&#22312;&#36739;&#22823;&#30340;&#29615;&#22659;&#20013;&#25191;&#34892;&#23398;&#21040;&#30340;&#31639;&#27861;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#24037;&#20316;&#23616;&#38480;&#20110;&#23545;&#31216;&#20219;&#21153;&#65292;&#21363;&#36755;&#20837;&#21644;&#36755;&#20986;&#30340;&#32500;&#24230;&#30456;&#21516;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102; NeuralThink&#65292;&#19968;&#31181;&#26032;&#30340;&#36882;&#24402;&#26550;&#26500;&#65292;&#21487;&#20197;&#19968;&#36143;&#22320;&#23545;&#23545;&#31216;&#21644;&#19981;&#23545;&#31216;&#20219;&#21153;&#36827;&#34892;&#22806;&#25512;&#65292;&#20854;&#20013;&#36755;&#20837;&#21644;&#36755;&#20986;&#30340;&#32500;&#24230;&#19981;&#21516;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#19981;&#23545;&#31216;&#20219;&#21153;&#22806;&#25512;&#22522;&#20934;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102; NeuralThink &#22312;&#31283;&#23450;&#22320;&#20174;&#36739;&#23567;&#30340;&#35757;&#32451;&#35268;&#27169;&#23545;&#22823;&#35266;&#27979;&#36827;&#34892;&#22806;&#25512;&#26041;&#38754;&#19968;&#30452;&#20248;&#20110;&#20043;&#21069;&#30340;&#26368;&#20808;&#36827;&#30340;&#28145;&#24230;&#24605;&#32500;&#26550;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15393v1 Announce Type: cross  Abstract: While machine learning methods excel at pattern recognition, they struggle with complex reasoning tasks in a scalable, algorithmic manner. Recent Deep Thinking methods show promise in learning algorithms that extrapolate: learning in smaller environments and executing the learned algorithm in larger environments. However, these works are limited to symmetrical tasks, where the input and output dimensionalities are the same. To address this gap, we propose NeuralThink, a new recurrent architecture that can consistently extrapolate to both symmetrical and asymmetrical tasks, where the dimensionality of the input and output are different. We contribute with a novel benchmark of asymmetrical tasks for extrapolation. We show that NeuralThink consistently outperforms the prior state-of-the-art Deep Thinking architectures, in regards to stable extrapolation to large observations from smaller training sizes.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#26080;&#38480;&#26102;&#22495;&#24179;&#22343;&#22238;&#25253;&#21463;&#38480;MDPs&#30340;&#21442;&#25968;&#21270;&#36890;&#29992;&#31574;&#30053;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21407;&#22987;-&#23545;&#20598;&#31574;&#30053;&#26799;&#24230;&#31639;&#27861;&#65292;&#21487;&#22312;&#20445;&#35777;&#20302;&#36951;&#25022;&#30340;&#24773;&#20917;&#19979;&#31649;&#29702;&#32422;&#26463;&#26465;&#20214;&#65292;&#36798;&#21040;&#20840;&#23616;&#26368;&#20248;&#31574;&#30053;&#12290;&#31639;&#27861;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#20854;&#30446;&#26631;&#36951;&#25022;&#21644;&#32422;&#26463;&#36829;&#21453;&#22343;&#20026; $\tilde{\mathcal{O}}({T}^{3/4})$&#12290;</title><link>https://arxiv.org/abs/2402.02042</link><description>&lt;p&gt;
&#23398;&#20064;&#36890;&#36807;&#21407;&#22987;-&#23545;&#20598;&#31574;&#30053;&#26799;&#24230;&#31639;&#27861;&#23545;&#26080;&#38480;&#26102;&#22495;&#24179;&#22343;&#22238;&#25253;&#21463;&#38480;MDP&#36827;&#34892;&#21442;&#25968;&#21270;&#36890;&#29992;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Learning General Parameterized Policies for Infinite Horizon Average Reward Constrained MDPs via Primal-Dual Policy Gradient Algorithm
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02042
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#26080;&#38480;&#26102;&#22495;&#24179;&#22343;&#22238;&#25253;&#21463;&#38480;MDPs&#30340;&#21442;&#25968;&#21270;&#36890;&#29992;&#31574;&#30053;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21407;&#22987;-&#23545;&#20598;&#31574;&#30053;&#26799;&#24230;&#31639;&#27861;&#65292;&#21487;&#22312;&#20445;&#35777;&#20302;&#36951;&#25022;&#30340;&#24773;&#20917;&#19979;&#31649;&#29702;&#32422;&#26463;&#26465;&#20214;&#65292;&#36798;&#21040;&#20840;&#23616;&#26368;&#20248;&#31574;&#30053;&#12290;&#31639;&#27861;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#20854;&#30446;&#26631;&#36951;&#25022;&#21644;&#32422;&#26463;&#36829;&#21453;&#22343;&#20026; $\tilde{\mathcal{O}}({T}^{3/4})$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#32034;&#20102;&#26080;&#38480;&#26102;&#22495;&#24179;&#22343;&#22238;&#25253;&#21463;&#38480;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;CMDP&#65289;&#30340;&#39046;&#22495;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#39033;&#24037;&#20316;&#26159;&#39318;&#27425;&#30740;&#31350;&#20855;&#26377;&#36890;&#29992;&#31574;&#30053;&#21442;&#25968;&#21270;&#30340;&#24179;&#22343;&#22238;&#25253;CMDP&#30340;&#36951;&#25022;&#21644;&#32422;&#26463;&#36829;&#35268;&#20998;&#26512;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21407;&#22987;&#23545;&#20598;&#30340;&#31574;&#30053;&#26799;&#24230;&#31639;&#27861;&#65292;&#33021;&#22815;&#28789;&#27963;&#22320;&#31649;&#29702;&#32422;&#26463;&#26465;&#20214;&#65292;&#24182;&#30830;&#20445;&#20302;&#36951;&#25022;&#20445;&#35777;&#20197;&#23454;&#29616;&#20840;&#23616;&#26368;&#20248;&#31574;&#30053;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#22312;&#30446;&#26631;&#36951;&#25022;&#21644;&#32422;&#26463;&#36829;&#21453;&#19978;&#20855;&#26377; $\tilde{\mathcal{O}}({T}^{3/4})$ &#30340;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper explores the realm of infinite horizon average reward Constrained Markov Decision Processes (CMDP). To the best of our knowledge, this work is the first to delve into the regret and constraint violation analysis of average reward CMDPs with a general policy parametrization. To address this challenge, we propose a primal dual based policy gradient algorithm that adeptly manages the constraints while ensuring a low regret guarantee toward achieving a global optimal policy. In particular, we demonstrate that our proposed algorithm achieves $\tilde{\mathcal{O}}({T}^{3/4})$ objective regret and $\tilde{\mathcal{O}}({T}^{3/4})$ constraint violation bounds.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#23558;&#20154;&#31867;&#19987;&#19994;&#30693;&#35782;&#32435;&#20837;&#31639;&#27861;&#39044;&#27979;&#20013;&#65292;&#37325;&#28857;&#22312;&#20110;&#21033;&#29992;&#20154;&#30340;&#21028;&#26029;&#21147;&#21306;&#20998;&#23545;&#20110;&#20219;&#20309;&#21487;&#34892;&#30340;&#39044;&#27979;&#31639;&#27861;&#26469;&#35828;&#8220;&#30475;&#36215;&#26469;&#30456;&#21516;&#8221;&#30340;&#36755;&#20837;&#12290;</title><link>https://arxiv.org/abs/2402.00793</link><description>&lt;p&gt;
&#26080;&#27861;&#21306;&#20998;&#30340;&#21306;&#20998;&#65306;&#31639;&#27861;&#39044;&#27979;&#20013;&#30340;&#20154;&#31867;&#19987;&#19994;&#30693;&#35782;
&lt;/p&gt;
&lt;p&gt;
Distinguishing the Indistinguishable: Human Expertise in Algorithmic Prediction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00793
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#23558;&#20154;&#31867;&#19987;&#19994;&#30693;&#35782;&#32435;&#20837;&#31639;&#27861;&#39044;&#27979;&#20013;&#65292;&#37325;&#28857;&#22312;&#20110;&#21033;&#29992;&#20154;&#30340;&#21028;&#26029;&#21147;&#21306;&#20998;&#23545;&#20110;&#20219;&#20309;&#21487;&#34892;&#30340;&#39044;&#27979;&#31639;&#27861;&#26469;&#35828;&#8220;&#30475;&#36215;&#26469;&#30456;&#21516;&#8221;&#30340;&#36755;&#20837;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#23558;&#20154;&#31867;&#19987;&#19994;&#30693;&#35782;&#32435;&#20837;&#31639;&#27861;&#39044;&#27979;&#30340;&#26032;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20027;&#35201;&#20851;&#27880;&#21033;&#29992;&#20154;&#30340;&#21028;&#26029;&#21147;&#26469;&#21306;&#20998;&#37027;&#20123;&#23545;&#20110;&#20219;&#20309;&#21487;&#34892;&#30340;&#39044;&#27979;&#31639;&#27861;&#26469;&#35828;&#8220;&#30475;&#36215;&#26469;&#30456;&#21516;&#8221;&#30340;&#36755;&#20837;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#36825;&#31181;&#26694;&#26550;&#33021;&#22815;&#28548;&#28165;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#21327;&#20316;&#39044;&#27979;&#20219;&#21153;&#20013;&#30340;&#38382;&#39064;&#65292;&#22240;&#20026;&#19987;&#23478;&#36890;&#24120;&#20855;&#26377;&#20449;&#24687;&#30340;&#35775;&#38382;&#26435;&#38480;&#8212;&#8212;&#29305;&#21035;&#26159;&#20027;&#35266;&#20449;&#24687;&#8212;&#8212;&#32780;&#36825;&#20123;&#20449;&#24687;&#26159;&#31639;&#27861;&#35757;&#32451;&#25968;&#25454;&#20013;&#27809;&#26377;&#32534;&#30721;&#30340;&#12290;&#22522;&#20110;&#36825;&#19968;&#35748;&#35782;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#32452;&#26377;&#21407;&#21017;&#30340;&#31639;&#27861;&#65292;&#20165;&#22312;&#20219;&#20309;&#21487;&#34892;&#30340;&#39044;&#27979;&#22120;&#30340;&#24615;&#33021;&#26377;&#25152;&#25913;&#21892;&#26102;&#25165;&#36873;&#25321;&#24615;&#22320;&#32435;&#20837;&#20154;&#31867;&#21453;&#39304;&#12290;&#32463;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#23613;&#31649;&#31639;&#27861;&#22312;&#24179;&#22343;&#27700;&#24179;&#19978;&#24448;&#24448;&#20248;&#20110;&#20154;&#31867;&#23545;&#24212;&#20219;&#21153;&#30340;&#33021;&#21147;&#65292;&#20294;&#20154;&#31867;&#21028;&#26029;&#22312;&#29305;&#23450;&#24773;&#20917;&#19979;&#65288;&#21487;&#20197;&#39044;&#20808;&#30830;&#23450;&#65289;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#31639;&#27861;&#39044;&#27979;&#30340;&#24615;&#33021;&#12290;&#22312;&#19968;&#20010;X&#23556;&#32447;&#20998;&#31867;&#20219;&#21153;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#36825;&#20010;&#23376;&#38598;&#22312;&#24739;&#32773;&#32676;&#20307;&#20013;&#21344;&#25454;&#20102;&#36817;30%&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#31181;&#33258;&#28982;&#30340;&#26041;&#24335;&#65292;
&lt;/p&gt;
&lt;p&gt;
We introduce a novel framework for incorporating human expertise into algorithmic predictions. Our approach focuses on the use of human judgment to distinguish inputs which `look the same' to any feasible predictive algorithm. We argue that this framing clarifies the problem of human/AI collaboration in prediction tasks, as experts often have access to information -- particularly subjective information -- which is not encoded in the algorithm's training data. We use this insight to develop a set of principled algorithms for selectively incorporating human feedback only when it improves the performance of any feasible predictor. We find empirically that although algorithms often outperform their human counterparts on average, human judgment can significantly improve algorithmic predictions on specific instances (which can be identified ex-ante). In an X-ray classification task, we find that this subset constitutes nearly 30% of the patient population. Our approach provides a natural way
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#20154;&#31867;&#27807;&#36890;&#30340;&#24433;&#21709;&#65292;&#20351;&#29992;&#20102;&#28040;&#36153;&#32773;&#37329;&#34701;&#25237;&#35785;&#25968;&#25454;&#65292;&#24182;&#21457;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20351;&#29992;&#21487;&#33021;&#22686;&#24378;&#20102;&#19968;&#25972;&#22871;&#35821;&#35328;&#29305;&#24449;&#65292;&#25552;&#39640;&#20102;&#20449;&#24687;&#35828;&#26381;&#21147;&#12290;</title><link>https://arxiv.org/abs/2311.16466</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36890;&#36807;&#35821;&#35328;&#29305;&#24449;&#23545;&#40784;&#21487;&#20197;&#22686;&#24378;&#35828;&#26381;&#21147;
&lt;/p&gt;
&lt;p&gt;
Large language models can enhance persuasion through linguistic feature alignment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.16466
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#20154;&#31867;&#27807;&#36890;&#30340;&#24433;&#21709;&#65292;&#20351;&#29992;&#20102;&#28040;&#36153;&#32773;&#37329;&#34701;&#25237;&#35785;&#25968;&#25454;&#65292;&#24182;&#21457;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20351;&#29992;&#21487;&#33021;&#22686;&#24378;&#20102;&#19968;&#25972;&#22871;&#35821;&#35328;&#29305;&#24449;&#65292;&#25552;&#39640;&#20102;&#20449;&#24687;&#35828;&#26381;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411; (LLMs)&#27491;&#22312;&#37325;&#26032;&#22609;&#36896;&#20154;&#31867;&#29983;&#27963;&#30340;&#21508;&#20010;&#26041;&#38754;&#65292;&#20294;&#25105;&#20204;&#23545;&#23427;&#20204;&#30340;&#24433;&#21709;&#30340;&#29702;&#35299;&#20173;&#28982;&#26377;&#20123;&#21463;&#38480;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;LLMs&#23545;&#20154;&#31867;&#27807;&#36890;&#30340;&#24433;&#21709;&#65292;&#20351;&#29992;&#20102;&#28040;&#36153;&#32773;&#37329;&#34701;&#25237;&#35785;&#30340;&#25968;&#25454;&#12290;&#36890;&#36807;&#23545;&#28040;&#36153;&#32773;&#37329;&#34701;&#20445;&#25252;&#23616; (CFPB) &#25910;&#38598;&#30340;&#36229;&#36807;820,000&#20010;&#25237;&#35785;&#36827;&#34892;AI&#26816;&#27979;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;ChatGPT&#21457;&#24067;&#21518;&#19981;&#20037;&#65292;LLMs&#30340;&#20351;&#29992;&#21487;&#33021;&#24615;&#24613;&#21095;&#22686;&#21152;&#12290;&#27492;&#22806;&#65292;LLMs&#30340;&#20351;&#29992;&#21487;&#33021;&#24615;&#19982;&#20449;&#24687;&#35828;&#26381;&#21147;&#65288;&#21363;&#20174;&#37329;&#34701;&#20844;&#21496;&#33719;&#24471;&#25937;&#27982;&#30340;&#21487;&#33021;&#24615;&#22686;&#21152;&#65289;&#21576;&#27491;&#30456;&#20851;&#12290;&#35745;&#31639;&#35821;&#35328;&#20998;&#26512;&#34920;&#26126;&#65292;&#36825;&#31181;&#27491;&#30456;&#20851;&#21487;&#33021;&#26159;&#30001;LLMs&#22686;&#24378;&#20102;&#21508;&#31181;&#35821;&#35328;&#29305;&#24449;&#25152;&#35299;&#37322;&#30340;&#12290;&#26681;&#25454;&#36825;&#20123;&#35266;&#23519;&#30740;&#31350;&#30340;&#32467;&#26524;&#65292;&#25105;&#20204;&#20551;&#35774;LLMs&#30340;&#20351;&#29992;&#21487;&#33021;&#22686;&#24378;&#20102;&#19968;&#25972;&#22871;&#35821;&#35328;&#29305;&#24449;&#65292;&#25552;&#39640;&#20102;&#23545;&#20855;&#26377;&#19981;&#21516;&#35821;&#35328;&#32972;&#26223;&#30340;&#25509;&#25910;&#32773;&#30340;&#20449;&#24687;&#35828;&#26381;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Although large language models (LLMs) are reshaping various aspects of human life, our current understanding of their impacts remains somewhat constrained. Here we investigate the impact of LLMs on human communication, using data on consumer complaints in the financial industry. By employing an AI detection tool on more than 820K complaints gathered by the Consumer Financial Protection Bureau (CFPB), we find a sharp increase in the likely use of LLMs shortly after the release of ChatGPT. Moreover, the likely LLM usage was positively correlated with message persuasiveness (i.e., increased likelihood of obtaining relief from financial firms). Computational linguistic analyses suggest that the positive correlation may be explained by LLMs' enhancement of various linguistic features. Based on the results of these observational studies, we hypothesize that LLM usage may enhance a comprehensive set of linguistic features, increasing message persuasiveness to receivers with heterogeneous ling
&lt;/p&gt;</description></item><item><title>HyperSense&#26159;&#19968;&#20010;&#21327;&#21516;&#35774;&#35745;&#30340;&#30828;&#20214;&#21644;&#36719;&#20214;&#31995;&#32479;&#65292;&#33021;&#22815;&#26681;&#25454;&#20256;&#24863;&#22120;&#25968;&#25454;&#20013;&#30340;&#29289;&#20307;&#23384;&#22312;&#39044;&#27979;&#26377;&#25928;&#22320;&#25511;&#21046;&#25968;&#25454;&#29983;&#25104;&#36895;&#29575;&#65292;&#36890;&#36807;&#20351;&#29992;&#20302;&#31934;&#24230;ADC&#20943;&#23569;&#20887;&#20313;&#25968;&#25454;&#38477;&#20302;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#30340;&#25104;&#26412;&#65292;&#21033;&#29992;&#36229;&#32500;&#24230;&#35745;&#31639;&#30340;&#29305;&#28857;&#20998;&#26512;&#23454;&#26102;&#30340;&#20302;&#31934;&#24230;&#20256;&#24863;&#22120;&#25968;&#25454;&#65292;&#22312;&#22788;&#29702;&#22122;&#22768;&#12289;&#20197;&#20869;&#23384;&#20026;&#20013;&#24515;&#21644;&#23454;&#26102;&#23398;&#20064;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;&#35813;&#31995;&#32479;&#32467;&#21512;&#20102;&#39640;&#24615;&#33021;&#30340;&#29289;&#20307;&#26816;&#27979;&#36719;&#20214;&#21644;&#23454;&#26102;&#30340;&#30828;&#20214;&#39044;&#27979;&#65292;&#24341;&#20837;&#20102;&#26234;&#33021;&#20256;&#24863;&#22120;&#25511;&#21046;&#30340;&#26032;&#27010;&#24565;&#12290;&#22312;&#36719;&#20214;&#21644;&#30828;&#20214;&#35780;&#20272;&#20013;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.10267</link><description>&lt;p&gt;
HyperSense: &#21152;&#36895;&#36229;&#32500;&#24230;&#35745;&#31639;&#20197;&#29992;&#20110;&#26234;&#33021;&#20256;&#24863;&#22120;&#25968;&#25454;&#22788;&#29702;
&lt;/p&gt;
&lt;p&gt;
HyperSense: Accelerating Hyper-Dimensional Computing for Intelligent Sensor Data Processing. (arXiv:2401.10267v1 [cs.AR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10267
&lt;/p&gt;
&lt;p&gt;
HyperSense&#26159;&#19968;&#20010;&#21327;&#21516;&#35774;&#35745;&#30340;&#30828;&#20214;&#21644;&#36719;&#20214;&#31995;&#32479;&#65292;&#33021;&#22815;&#26681;&#25454;&#20256;&#24863;&#22120;&#25968;&#25454;&#20013;&#30340;&#29289;&#20307;&#23384;&#22312;&#39044;&#27979;&#26377;&#25928;&#22320;&#25511;&#21046;&#25968;&#25454;&#29983;&#25104;&#36895;&#29575;&#65292;&#36890;&#36807;&#20351;&#29992;&#20302;&#31934;&#24230;ADC&#20943;&#23569;&#20887;&#20313;&#25968;&#25454;&#38477;&#20302;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#30340;&#25104;&#26412;&#65292;&#21033;&#29992;&#36229;&#32500;&#24230;&#35745;&#31639;&#30340;&#29305;&#28857;&#20998;&#26512;&#23454;&#26102;&#30340;&#20302;&#31934;&#24230;&#20256;&#24863;&#22120;&#25968;&#25454;&#65292;&#22312;&#22788;&#29702;&#22122;&#22768;&#12289;&#20197;&#20869;&#23384;&#20026;&#20013;&#24515;&#21644;&#23454;&#26102;&#23398;&#20064;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;&#35813;&#31995;&#32479;&#32467;&#21512;&#20102;&#39640;&#24615;&#33021;&#30340;&#29289;&#20307;&#26816;&#27979;&#36719;&#20214;&#21644;&#23454;&#26102;&#30340;&#30828;&#20214;&#39044;&#27979;&#65292;&#24341;&#20837;&#20102;&#26234;&#33021;&#20256;&#24863;&#22120;&#25511;&#21046;&#30340;&#26032;&#27010;&#24565;&#12290;&#22312;&#36719;&#20214;&#21644;&#30828;&#20214;&#35780;&#20272;&#20013;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;HyperSense&#65292;&#25105;&#20204;&#21327;&#21516;&#35774;&#35745;&#30340;&#30828;&#20214;&#21644;&#36719;&#20214;&#31995;&#32479;&#26681;&#25454;&#20256;&#24863;&#22120;&#25968;&#25454;&#20013;&#30340;&#29289;&#20307;&#23384;&#22312;&#39044;&#27979;&#26377;&#25928;&#22320;&#25511;&#21046;&#27169;&#25311;&#21040;&#25968;&#23383;&#36716;&#25442;&#22120;&#65288;ADC&#65289;&#27169;&#22359;&#30340;&#25968;&#25454;&#29983;&#25104;&#36895;&#29575;&#12290;&#38024;&#23545;&#19981;&#26029;&#22686;&#21152;&#30340;&#20256;&#24863;&#22120;&#25968;&#37327;&#21644;&#25968;&#25454;&#36895;&#29575;&#25152;&#24102;&#26469;&#30340;&#25361;&#25112;&#65292;HyperSense&#20351;&#29992;&#39640;&#25928;&#30340;&#20302;&#31934;&#24230;ADC&#20943;&#23569;&#20887;&#20313;&#30340;&#25968;&#23383;&#25968;&#25454;&#65292;&#38477;&#20302;&#20102;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#30340;&#25104;&#26412;&#12290;&#21033;&#29992;&#31070;&#32463;&#21551;&#21457;&#30340;&#36229;&#32500;&#24230;&#35745;&#31639;&#65288;HDC&#65289;&#65292;HyperSense&#20998;&#26512;&#23454;&#26102;&#30340;&#21407;&#22987;&#20302;&#31934;&#24230;&#20256;&#24863;&#22120;&#25968;&#25454;&#65292;&#22312;&#22788;&#29702;&#22122;&#22768;&#12289;&#20197;&#20869;&#23384;&#20026;&#20013;&#24515;&#21644;&#23454;&#26102;&#23398;&#20064;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;HyperSense&#27169;&#22411;&#23558;&#39640;&#24615;&#33021;&#30340;&#29289;&#20307;&#26816;&#27979;&#36719;&#20214;&#19982;&#23454;&#26102;&#30340;&#30828;&#20214;&#39044;&#27979;&#32467;&#21512;&#36215;&#26469;&#65292;&#24341;&#20837;&#20102;&#26234;&#33021;&#20256;&#24863;&#22120;&#25511;&#21046;&#30340;&#26032;&#27010;&#24565;&#12290;&#20840;&#38754;&#30340;&#36719;&#20214;&#21644;&#30828;&#20214;&#35780;&#20272;&#23637;&#31034;&#20102;&#25105;&#20204;&#35299;&#20915;&#26041;&#26696;&#30340;&#21331;&#36234;&#24615;&#33021;&#65292;&#36890;&#36807;&#26368;&#39640;&#30340;&#26354;&#32447;&#19979;&#38754;&#31215;&#65288;AUC&#65289;&#21644;&#26368;&#38497;&#30340;&#25509;&#25910;&#22120;&#25805;&#20316;&#29305;&#24615;&#65288;ROC&#65289;&#26354;&#32447;&#35777;&#26126;&#20102;&#36825;&#19968;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Introducing HyperSense, our co-designed hardware and software system efficiently controls Analog-to-Digital Converter (ADC) modules' data generation rate based on object presence predictions in sensor data. Addressing challenges posed by escalating sensor quantities and data rates, HyperSense reduces redundant digital data using energy-efficient low-precision ADC, diminishing machine learning system costs. Leveraging neurally-inspired HyperDimensional Computing (HDC), HyperSense analyzes real-time raw low-precision sensor data, offering advantages in handling noise, memory-centricity, and real-time learning.  Our proposed HyperSense model combines high-performance software for object detection with real-time hardware prediction, introducing the novel concept of Intelligent Sensor Control. Comprehensive software and hardware evaluations demonstrate our solution's superior performance, evidenced by the highest Area Under the Curve (AUC) and sharpest Receiver Operating Characteristic (ROC
&lt;/p&gt;</description></item><item><title>ChatQA&#26159;&#19968;&#31995;&#21015;&#23545;&#35805;&#38382;&#31572;&#27169;&#22411;&#65292;&#21487;&#20197;&#36798;&#21040;GPT-4&#32423;&#21035;&#30340;&#20934;&#30830;&#24615;&#12290;&#36890;&#36807;&#20004;&#38454;&#27573;&#30340;&#25351;&#20196;&#35843;&#25972;&#26041;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#38646;-shot&#23545;&#35805;&#38382;&#31572;&#20013;&#30340;&#32467;&#26524;&#12290;&#20351;&#29992;&#23494;&#38598;&#26816;&#32034;&#22120;&#36827;&#34892;&#38382;&#31572;&#25968;&#25454;&#38598;&#30340;&#24494;&#35843;&#21487;&#20197;&#23454;&#29616;&#19982;&#26368;&#20808;&#36827;&#30340;&#26597;&#35810;&#37325;&#20889;&#27169;&#22411;&#30456;&#24403;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#38477;&#20302;&#37096;&#32626;&#25104;&#26412;&#12290;ChatQA-70B&#22312;10&#20010;&#23545;&#35805;&#38382;&#31572;&#25968;&#25454;&#38598;&#19978;&#30340;&#24179;&#22343;&#24471;&#20998;&#36229;&#36807;&#20102;GPT-4&#65292;&#19988;&#19981;&#20381;&#36182;&#20110;&#20219;&#20309;&#26469;&#33258;OpenAI GPT&#27169;&#22411;&#30340;&#21512;&#25104;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2401.10225</link><description>&lt;p&gt;
ChatQA: &#26500;&#24314;GPT-4&#32423;&#23545;&#35805;&#38382;&#31572;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
ChatQA: Building GPT-4 Level Conversational QA Models. (arXiv:2401.10225v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10225
&lt;/p&gt;
&lt;p&gt;
ChatQA&#26159;&#19968;&#31995;&#21015;&#23545;&#35805;&#38382;&#31572;&#27169;&#22411;&#65292;&#21487;&#20197;&#36798;&#21040;GPT-4&#32423;&#21035;&#30340;&#20934;&#30830;&#24615;&#12290;&#36890;&#36807;&#20004;&#38454;&#27573;&#30340;&#25351;&#20196;&#35843;&#25972;&#26041;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#38646;-shot&#23545;&#35805;&#38382;&#31572;&#20013;&#30340;&#32467;&#26524;&#12290;&#20351;&#29992;&#23494;&#38598;&#26816;&#32034;&#22120;&#36827;&#34892;&#38382;&#31572;&#25968;&#25454;&#38598;&#30340;&#24494;&#35843;&#21487;&#20197;&#23454;&#29616;&#19982;&#26368;&#20808;&#36827;&#30340;&#26597;&#35810;&#37325;&#20889;&#27169;&#22411;&#30456;&#24403;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#38477;&#20302;&#37096;&#32626;&#25104;&#26412;&#12290;ChatQA-70B&#22312;10&#20010;&#23545;&#35805;&#38382;&#31572;&#25968;&#25454;&#38598;&#19978;&#30340;&#24179;&#22343;&#24471;&#20998;&#36229;&#36807;&#20102;GPT-4&#65292;&#19988;&#19981;&#20381;&#36182;&#20110;&#20219;&#20309;&#26469;&#33258;OpenAI GPT&#27169;&#22411;&#30340;&#21512;&#25104;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;ChatQA&#65292;&#19968;&#31995;&#21015;&#20855;&#26377;GPT-4&#32423;&#21035;&#20934;&#30830;&#24615;&#30340;&#23545;&#35805;&#38382;&#31572;&#27169;&#22411;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#30340;&#25351;&#20196;&#35843;&#25972;&#26041;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#38646;-shot&#23545;&#35805;&#38382;&#31572;&#20013;&#30340;&#32467;&#26524;&#12290;&#20026;&#20102;&#22788;&#29702;&#23545;&#35805;&#38382;&#31572;&#20013;&#30340;&#26816;&#32034;&#38382;&#39064;&#65292;&#25105;&#20204;&#22312;&#22810;&#36718;&#38382;&#31572;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23494;&#38598;&#26816;&#32034;&#22120;&#30340;&#24494;&#35843;&#65292;&#36825;&#26679;&#21487;&#20197;&#25552;&#20379;&#19982;&#20351;&#29992;&#26368;&#20808;&#36827;&#30340;&#26597;&#35810;&#37325;&#20889;&#27169;&#22411;&#30456;&#24403;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#22823;&#22823;&#38477;&#20302;&#37096;&#32626;&#25104;&#26412;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;ChatQA-70B&#21487;&#20197;&#22312;10&#20010;&#23545;&#35805;&#38382;&#31572;&#25968;&#25454;&#38598;&#30340;&#24179;&#22343;&#20998;&#19978;&#36229;&#36807;GPT-4&#65288;54.14 vs. 53.90&#65289;&#65292;&#32780;&#19981;&#20381;&#36182;&#20110;OpenAI GPT&#27169;&#22411;&#30340;&#20219;&#20309;&#21512;&#25104;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we introduce ChatQA, a family of conversational question answering (QA) models, that obtain GPT-4 level accuracies. Specifically, we propose a two-stage instruction tuning method that can significantly improve the zero-shot conversational QA results from large language models (LLMs). To handle retrieval in conversational QA, we fine-tune a dense retriever on a multi-turn QA dataset, which provides comparable results to using the state-of-the-art query rewriting model while largely reducing deployment cost. Notably, our ChatQA-70B can outperform GPT-4 in terms of average score on 10 conversational QA datasets (54.14 vs. 53.90), without relying on any synthetic data from OpenAI GPT models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35843;&#26597;&#20102;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#23384;&#22312;&#36807;&#25311;&#21512;&#38382;&#39064;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#30340;&#40065;&#26834;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;&#30740;&#31350;&#24418;&#24335;&#21270;&#21644;&#32479;&#19968;&#20102;&#25552;&#39640;&#27867;&#21270;&#24615;&#21644;&#20811;&#26381;&#36807;&#25311;&#21512;&#30340;&#19981;&#21516;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2401.02349</link><description>&lt;p&gt;
&#20998;&#26512;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#27867;&#21270;&#24615;&#33021;&#30340;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
A Survey Analyzing Generalization in Deep Reinforcement Learning. (arXiv:2401.02349v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02349
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35843;&#26597;&#20102;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#23384;&#22312;&#36807;&#25311;&#21512;&#38382;&#39064;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#30340;&#40065;&#26834;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;&#30740;&#31350;&#24418;&#24335;&#21270;&#21644;&#32479;&#19968;&#20102;&#25552;&#39640;&#27867;&#21270;&#24615;&#21644;&#20811;&#26381;&#36807;&#25311;&#21512;&#30340;&#19981;&#21516;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#35299;&#20915;&#39640;&#32500;&#29366;&#24577;&#25110;&#21160;&#20316;&#31354;&#38388;&#20013;&#30340;&#38382;&#39064;&#65292;&#24378;&#21270;&#23398;&#20064;&#30740;&#31350;&#22312;&#23454;&#36341;&#20013;&#21462;&#24471;&#20102;&#37325;&#35201;&#30340;&#25104;&#21151;&#21644;&#20851;&#27880;&#12290;&#23613;&#31649;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#30446;&#21069;&#22312;&#35768;&#22810;&#39046;&#22495;&#20013;&#27491;&#22312;&#34987;&#24212;&#29992;&#65292;&#20174;&#21307;&#30103;&#24212;&#29992;&#21040;&#33258;&#21160;&#39550;&#39542;&#36710;&#36742;&#65292;&#20294;&#20851;&#20110;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#30340;&#27867;&#21270;&#33021;&#21147;&#20173;&#26377;&#35768;&#22810;&#24453;&#35299;&#31572;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#27010;&#36848;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#36935;&#21040;&#36807;&#25311;&#21512;&#38382;&#39064;&#30340;&#26681;&#26412;&#21407;&#22240;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#30340;&#40065;&#26834;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#23545;&#25552;&#39640;&#27867;&#21270;&#24615;&#21644;&#20811;&#26381;&#29366;&#24577;-&#21160;&#20316;&#20540;&#20989;&#25968;&#20013;&#30340;&#36807;&#25311;&#21512;&#30340;&#19981;&#21516;&#35299;&#20915;&#26041;&#26696;&#36827;&#34892;&#24418;&#24335;&#21270;&#21644;&#32479;&#19968;&#12290;&#25105;&#20204;&#30456;&#20449;&#25105;&#20204;&#30340;&#30740;&#31350;&#21487;&#20197;&#20026;&#24403;&#21069;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;&#36827;&#23637;&#25552;&#20379;&#19968;&#20010;&#31616;&#27905;&#31995;&#32479;&#30340;&#32479;&#19968;&#20998;&#26512;&#65292;&#24182;&#26377;&#21161;&#20110;&#26500;&#24314;&#20581;&#22766;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement learning research obtained significant success and attention with the utilization of deep neural networks to solve problems in high dimensional state or action spaces. While deep reinforcement learning policies are currently being deployed in many different fields from medical applications to self driving vehicles, there are still ongoing questions the field is trying to answer on the generalization capabilities of deep reinforcement learning policies. In this paper, we will outline the fundamental reasons why deep reinforcement learning policies encounter overfitting problems that limit their robustness and generalization capabilities. Furthermore, we will formalize and unify the diverse solution approaches to increase generalization, and overcome overfitting in state-action value functions. We believe our study can provide a compact systematic unified analysis for the current advancements in deep reinforcement learning, and help to construct robust deep neural policies 
&lt;/p&gt;</description></item><item><title>ChatKBQA&#26159;&#19968;&#20010;&#22522;&#20110;&#31934;&#35843;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#29983;&#25104;-&#26816;&#32034;&#26694;&#26550;&#65292;&#29992;&#20110;&#25913;&#36827;&#30693;&#35782;&#24211;&#38382;&#31572;&#30340;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#26032;&#30340;&#26368;&#22909;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2310.08975</link><description>&lt;p&gt;
ChatKBQA: &#19968;&#20010;&#22522;&#20110;&#31934;&#35843;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#29983;&#25104;-&#26816;&#32034;&#26694;&#26550;&#29992;&#20110;&#30693;&#35782;&#24211;&#38382;&#31572;
&lt;/p&gt;
&lt;p&gt;
ChatKBQA: A Generate-then-Retrieve Framework for Knowledge Base Question Answering with Fine-tuned Large Language Models. (arXiv:2310.08975v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08975
&lt;/p&gt;
&lt;p&gt;
ChatKBQA&#26159;&#19968;&#20010;&#22522;&#20110;&#31934;&#35843;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#29983;&#25104;-&#26816;&#32034;&#26694;&#26550;&#65292;&#29992;&#20110;&#25913;&#36827;&#30693;&#35782;&#24211;&#38382;&#31572;&#30340;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#26032;&#30340;&#26368;&#22909;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#24211;&#38382;&#31572;&#65288;KBQA&#65289;&#26088;&#22312;&#36890;&#36807;&#22823;&#35268;&#27169;&#30693;&#35782;&#24211;&#65288;KB&#65289;&#33719;&#21462;&#33258;&#28982;&#35821;&#35328;&#38382;&#39064;&#30340;&#31572;&#26696;&#65292;&#36890;&#24120;&#20998;&#20026;&#20004;&#20010;&#30740;&#31350;&#32452;&#25104;&#37096;&#20998;&#65306;&#30693;&#35782;&#26816;&#32034;&#21644;&#35821;&#20041;&#35299;&#26512;&#12290;&#28982;&#32780;&#65292;&#20173;&#28982;&#23384;&#22312;&#19977;&#20010;&#26680;&#24515;&#25361;&#25112;&#65292;&#21253;&#25324;&#20302;&#25928;&#30340;&#30693;&#35782;&#26816;&#32034;&#12289;&#26816;&#32034;&#38169;&#35823;&#23545;&#35821;&#20041;&#35299;&#26512;&#30340;&#19981;&#21033;&#24433;&#21709;&#20197;&#21450;&#20043;&#21069;&#30340;KBQA&#26041;&#27861;&#30340;&#22797;&#26434;&#24615;&#12290;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#26102;&#20195;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;ChatKBQA&#65292;&#36825;&#26159;&#19968;&#20010;&#26032;&#39062;&#30340;&#22522;&#20110;&#31934;&#35843;&#24320;&#28304;LLMs&#65288;&#22914;Llama-2&#12289;ChatGLM2&#21644;Baichuan2&#65289;&#26500;&#24314;&#30340;&#29983;&#25104;-&#26816;&#32034;KBQA&#26694;&#26550;&#12290;ChatKBQA&#25552;&#35758;&#39318;&#20808;&#20351;&#29992;&#31934;&#35843;&#30340;LLMs&#29983;&#25104;&#36923;&#36753;&#24418;&#24335;&#65292;&#28982;&#21518;&#36890;&#36807;&#26080;&#30417;&#30563;&#26816;&#32034;&#26041;&#27861;&#26816;&#32034;&#21644;&#26367;&#25442;&#23454;&#20307;&#21644;&#20851;&#31995;&#65292;&#20174;&#32780;&#26356;&#30452;&#35266;&#22320;&#25913;&#36827;&#20102;&#29983;&#25104;&#21644;&#26816;&#32034;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;ChatKBQA&#22312;&#26631;&#20934;KBQA&#25968;&#25454;&#38598;WebQSP&#21644;ComplexWebQuestions (CWQ)&#19978;&#21462;&#24471;&#20102;&#26032;&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Knowledge Base Question Answering (KBQA) aims to derive answers to natural language questions over large-scale knowledge bases (KBs), which are generally divided into two research components: knowledge retrieval and semantic parsing. However, three core challenges remain, including inefficient knowledge retrieval, retrieval errors adversely affecting semantic parsing, and the complexity of previous KBQA methods. In the era of large language models (LLMs), we introduce ChatKBQA, a novel generate-then-retrieve KBQA framework built on fine-tuning open-source LLMs such as Llama-2, ChatGLM2 and Baichuan2. ChatKBQA proposes generating the logical form with fine-tuned LLMs first, then retrieving and replacing entities and relations through an unsupervised retrieval method, which improves both generation and retrieval more straightforwardly. Experimental results reveal that ChatKBQA achieves new state-of-the-art performance on standard KBQA datasets, WebQSP, and ComplexWebQuestions (CWQ). This
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#32454;&#21270;&#20998;&#26512;&#23398;&#20064;&#29575;&#35843;&#24230;&#26469;&#35299;&#20915;&#23454;&#36341;&#20013;&#23398;&#20064;&#29575;&#35843;&#25972;&#19982;&#29702;&#35770;&#30340;&#19981;&#19968;&#33268;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#35266;&#23519;&#21040;&#30340;&#26799;&#24230;&#33539;&#25968;&#36827;&#34892;&#20998;&#26512;&#65292;&#24471;&#21040;&#20102;&#36866;&#24212;&#20110;&#29305;&#23450;&#20219;&#21153;&#30340;&#32454;&#21270;&#35843;&#24230;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#25913;&#21892;&#20248;&#21270;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.07831</link><description>&lt;p&gt;
&#20309;&#26102;&#65292;&#20026;&#20160;&#20040;&#20197;&#21450;&#22810;&#23569;&#65311;&#36890;&#36807;&#32454;&#21270;&#36827;&#34892;&#30340;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#35843;&#24230;
&lt;/p&gt;
&lt;p&gt;
When, Why and How Much? Adaptive Learning Rate Scheduling by Refinement. (arXiv:2310.07831v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07831
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#32454;&#21270;&#20998;&#26512;&#23398;&#20064;&#29575;&#35843;&#24230;&#26469;&#35299;&#20915;&#23454;&#36341;&#20013;&#23398;&#20064;&#29575;&#35843;&#25972;&#19982;&#29702;&#35770;&#30340;&#19981;&#19968;&#33268;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#35266;&#23519;&#21040;&#30340;&#26799;&#24230;&#33539;&#25968;&#36827;&#34892;&#20998;&#26512;&#65292;&#24471;&#21040;&#20102;&#36866;&#24212;&#20110;&#29305;&#23450;&#20219;&#21153;&#30340;&#32454;&#21270;&#35843;&#24230;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#25913;&#21892;&#20248;&#21270;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#36341;&#20013;&#20351;&#29992;&#30340;&#23398;&#20064;&#29575;&#35843;&#24230;&#19982;&#29702;&#35770;&#25512;&#33616;&#30340;&#20960;&#20046;&#23436;&#20840;&#19981;&#21516;&#12290;&#25105;&#20204;&#32553;&#23567;&#20102;&#22823;&#37096;&#20998;&#29702;&#35770;&#19982;&#23454;&#36341;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#24182;&#22240;&#27492;&#33021;&#22815;&#25512;&#23548;&#20986;&#26032;&#30340;&#38382;&#39064;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#35843;&#24230;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#25216;&#26415;&#36129;&#29486;&#26159;&#23545;&#24191;&#27867;&#31867;&#21035;&#30340;&#20248;&#21270;&#31639;&#27861;&#65288;&#21253;&#25324;SGD&#65289;&#30340;&#23398;&#20064;&#29575;&#35843;&#24230;&#36827;&#34892;&#32454;&#21270;&#20998;&#26512;&#12290;&#19982;&#22823;&#22810;&#25968;&#21069;&#26399;&#30740;&#31350;&#21482;&#30740;&#31350;&#24179;&#22343;&#36845;&#20195;&#30340;&#25910;&#25947;&#24615;&#19981;&#21516;&#65292;&#25105;&#20204;&#30740;&#31350;&#26368;&#21518;&#19968;&#27425;&#36845;&#20195;&#65292;&#36825;&#26159;&#22823;&#22810;&#25968;&#20154;&#22312;&#23454;&#36341;&#20013;&#20351;&#29992;&#30340;&#12290;&#24403;&#20165;&#32771;&#34385;&#26368;&#22351;&#24773;&#20917;&#20998;&#26512;&#26102;&#65292;&#25105;&#20204;&#30340;&#29702;&#35770;&#39044;&#27979;&#26368;&#20339;&#36873;&#25321;&#26159;&#32447;&#24615;&#34928;&#20943;&#35843;&#24230;&#65306;&#36825;&#26159;&#19968;&#31181;&#23454;&#36341;&#20013;&#24120;&#29992;&#30340;&#36873;&#25321;&#65292;&#20854;&#23558;&#27493;&#38271;&#19982;&#24403;&#21069;&#36845;&#20195;&#27425;&#25968;t&#21644;&#24635;&#27493;&#25968;T&#25104;&#27604;&#20363;&#22320;&#35774;&#32622;&#20026;1 - t/T&#12290;&#20026;&#20102;&#36229;&#36234;&#36825;&#31181;&#26368;&#22351;&#24773;&#20917;&#20998;&#26512;&#65292;&#25105;&#20204;&#20351;&#29992;&#35266;&#23519;&#21040;&#30340;&#26799;&#24230;&#33539;&#25968;&#26469;&#25512;&#23548;&#36866;&#24212;&#20110;&#29305;&#23450;&#20219;&#21153;&#30340;&#32454;&#21270;&#35843;&#24230;&#12290;&#36825;&#20123;&#32454;&#21270;&#35843;&#24230;&#34920;&#29616;&#20986;&#23398;&#20064;&#29575;&#36880;&#28176;&#22686;&#21152;&#21644;&#23398;&#20064;&#29575;&#36805;&#36895;&#36864;&#28779;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning rate schedules used in practice bear little resemblance to those recommended by theory. We close much of this theory/practice gap, and as a consequence are able to derive new problem-adaptive learning rate schedules. Our key technical contribution is a refined analysis of learning rate schedules for a wide class of optimization algorithms (including SGD). In contrast to most prior works that study the convergence of the average iterate, we study the last iterate, which is what most people use in practice. When considering only worst-case analysis, our theory predicts that the best choice is the linear decay schedule: a popular choice in practice that sets the stepsize proportionally to $1 - t/T$, where $t$ is the current iteration and $T$ is the total number of steps. To go beyond this worst-case analysis, we use the observed gradient norms to derive schedules refined for any particular task. These refined schedules exhibit learning rate warm-up and rapid learning rate anneali
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#39044;&#27979;&#36741;&#21161;&#30446;&#26631;&#23545;&#34920;&#31034;&#23398;&#20064;&#21644;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#22312;&#36164;&#28304;&#21463;&#38480;&#30340;&#24773;&#20917;&#19979;&#65292;&#39044;&#27979;&#30446;&#26631;&#33021;&#26174;&#33879;&#25552;&#39640;&#21644;&#31283;&#23450;&#23398;&#20064;&#65292;&#24182;&#19988;&#33021;&#25903;&#25345;&#34920;&#24449;&#36801;&#31227;&#12290;&#27492;&#22806;&#65292;&#19982;&#31070;&#32463;&#27963;&#21160;&#21464;&#21270;&#30456;&#20284;&#65292;&#36825;&#20123;&#36741;&#21161;&#30446;&#26631;&#20063;&#27169;&#25311;&#20102;&#22823;&#33041;&#20013;&#30340;&#34920;&#24449;&#21464;&#21270;&#12290;</title><link>http://arxiv.org/abs/2310.06089</link><description>&lt;p&gt;
&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#39044;&#27979;&#36741;&#21161;&#30446;&#26631;&#27169;&#20223;&#22823;&#33041;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Predictive auxiliary objectives in deep RL mimic learning in the brain. (arXiv:2310.06089v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06089
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#39044;&#27979;&#36741;&#21161;&#30446;&#26631;&#23545;&#34920;&#31034;&#23398;&#20064;&#21644;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#22312;&#36164;&#28304;&#21463;&#38480;&#30340;&#24773;&#20917;&#19979;&#65292;&#39044;&#27979;&#30446;&#26631;&#33021;&#26174;&#33879;&#25552;&#39640;&#21644;&#31283;&#23450;&#23398;&#20064;&#65292;&#24182;&#19988;&#33021;&#25903;&#25345;&#34920;&#24449;&#36801;&#31227;&#12290;&#27492;&#22806;&#65292;&#19982;&#31070;&#32463;&#27963;&#21160;&#21464;&#21270;&#30456;&#20284;&#65292;&#36825;&#20123;&#36741;&#21161;&#30446;&#26631;&#20063;&#27169;&#25311;&#20102;&#22823;&#33041;&#20013;&#30340;&#34920;&#24449;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#27979;&#21363;&#23558;&#21457;&#29983;&#30340;&#20107;&#20214;&#30340;&#33021;&#21147;&#34987;&#20551;&#35774;&#20026;&#33258;&#28982;&#21644;&#26426;&#22120;&#35748;&#30693;&#30340;&#20851;&#38190;&#26041;&#38754;&#12290;&#36825;&#22312;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#24471;&#21040;&#20102;&#25903;&#25345;&#65292;&#20854;&#20013;&#33258;&#30417;&#30563;&#36741;&#21161;&#30446;&#26631;&#65288;&#22914;&#39044;&#27979;&#65289;&#34987;&#24191;&#27867;&#29992;&#20110;&#25903;&#25345;&#34920;&#31034;&#23398;&#20064;&#21644;&#25552;&#39640;&#20219;&#21153;&#24615;&#33021;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#39044;&#27979;&#36741;&#21161;&#30446;&#26631;&#23545;RL&#31995;&#32479;&#20013;&#19981;&#21516;&#27169;&#22359;&#30340;&#34920;&#31034;&#23398;&#20064;&#30340;&#24433;&#21709;&#65292;&#20197;&#21450;&#36825;&#20123;&#27169;&#25311;&#22823;&#33041;&#35266;&#23519;&#21040;&#30340;&#34920;&#24449;&#21464;&#21270;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#36164;&#28304;&#21463;&#38480;&#30340;&#26550;&#26500;&#20013;&#65292;&#39044;&#27979;&#30446;&#26631;&#29305;&#21035;&#25552;&#39640;&#21644;&#31283;&#23450;&#23398;&#20064;&#65292;&#24182;&#19988;&#25105;&#20204;&#30830;&#23450;&#20102;&#26356;&#38271;&#30340;&#39044;&#27979;&#26102;&#27573;&#22312;&#25903;&#25345;&#34920;&#24449;&#36801;&#31227;&#26041;&#38754;&#26356;&#22909;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21457;&#29616;&#36825;&#20010;RL&#31995;&#32479;&#20013;&#30340;&#34920;&#24449;&#21464;&#21270;&#19982;&#22823;&#33041;&#20013;&#35266;&#23519;&#21040;&#30340;&#31070;&#32463;&#27963;&#21160;&#21464;&#21270;&#26377;&#24778;&#20154;&#30340;&#30456;&#20284;&#20043;&#22788;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#22312;&#36741;&#21161;&#39044;&#27979;&#27169;&#22411;&#21644;&#22823;&#33041;&#20013;&#30340;&#34920;&#24449;&#21464;&#21270;&#20043;&#38388;&#24314;&#31435;&#20102;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
The ability to predict upcoming events has been hypothesized to comprise a key aspect of natural and machine cognition. This is supported by trends in deep reinforcement learning (RL), where self-supervised auxiliary objectives such as prediction are widely used to support representation learning and improve task performance. Here, we study the effects predictive auxiliary objectives have on representation learning across different modules of an RL system and how these mimic representational changes observed in the brain. We find that predictive objectives improve and stabilize learning particularly in resource-limited architectures, and we identify settings where longer predictive horizons better support representational transfer. Furthermore, we find that representational changes in this RL system bear a striking resemblance to changes in neural activity observed in the brain across various experiments. Specifically, we draw a connection between the auxiliary predictive model of the 
&lt;/p&gt;</description></item><item><title>Text2NKG&#26159;&#19968;&#31181;&#29992;&#20110;&#26500;&#24314;N&#20803;&#20851;&#31995;&#30693;&#35782;&#22270;&#30340;&#32454;&#31890;&#24230;N&#20803;&#20851;&#31995;&#25277;&#21462;&#26694;&#26550;&#65292;&#25903;&#25345;&#22810;&#31181;NKG&#27169;&#24335;&#65292;&#20855;&#26377;&#39640;&#28789;&#27963;&#24615;&#21644;&#23454;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.05185</link><description>&lt;p&gt;
Text2NKG: &#38754;&#21521;N&#20803;&#20851;&#31995;&#30693;&#35782;&#22270;&#26500;&#24314;&#30340;&#32454;&#31890;&#24230;N&#20803;&#20851;&#31995;&#25277;&#21462;
&lt;/p&gt;
&lt;p&gt;
Text2NKG: Fine-Grained N-ary Relation Extraction for N-ary relational Knowledge Graph Construction. (arXiv:2310.05185v2 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05185
&lt;/p&gt;
&lt;p&gt;
Text2NKG&#26159;&#19968;&#31181;&#29992;&#20110;&#26500;&#24314;N&#20803;&#20851;&#31995;&#30693;&#35782;&#22270;&#30340;&#32454;&#31890;&#24230;N&#20803;&#20851;&#31995;&#25277;&#21462;&#26694;&#26550;&#65292;&#25903;&#25345;&#22810;&#31181;NKG&#27169;&#24335;&#65292;&#20855;&#26377;&#39640;&#28789;&#27963;&#24615;&#21644;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38500;&#20102;&#20256;&#32479;&#30340;&#20108;&#20803;&#20851;&#31995;&#20107;&#23454;&#22806;&#65292;N&#20803;&#20851;&#31995;&#30693;&#35782;&#22270;(NKGs)&#30001;&#21253;&#21547;&#20004;&#20010;&#20197;&#19978;&#23454;&#20307;&#30340;N&#20803;&#20851;&#31995;&#20107;&#23454;&#32452;&#25104;&#65292;&#26356;&#25509;&#36817;&#20110;&#20855;&#26377;&#24191;&#27867;&#24212;&#29992;&#30340;&#30495;&#23454;&#19990;&#30028;&#20107;&#23454;&#12290;&#28982;&#32780;&#65292;NKG&#30340;&#26500;&#24314;&#20173;&#28982;&#20005;&#37325;&#20381;&#36182;&#20110;&#20154;&#24037;&#21171;&#21160;&#65292;&#24182;&#19988;N&#20803;&#20851;&#31995;&#25277;&#21462;&#20173;&#28982;&#20572;&#30041;&#22312;&#31895;&#31890;&#24230;&#27700;&#24179;&#65292;&#36890;&#24120;&#26159;&#22312;&#21333;&#19968;&#27169;&#24335;&#21644;&#22266;&#23450;&#30340;&#23454;&#20307;&#25968;&#37327;&#19978;&#25805;&#20316;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Text2NKG&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#38754;&#21521;N&#20803;&#20851;&#31995;&#30693;&#35782;&#22270;&#26500;&#24314;&#30340;&#32454;&#31890;&#24230;N&#20803;&#20851;&#31995;&#25277;&#21462;&#26694;&#26550;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#36328;&#24230;&#20803;&#32452;&#20998;&#31867;&#26041;&#27861;&#65292;&#24182;&#37319;&#29992;&#24322;&#26500;&#25490;&#24207;&#21512;&#24182;&#26469;&#23454;&#29616;&#19981;&#21516;&#24230;&#30340;&#32454;&#31890;&#24230;N&#20803;&#20851;&#31995;&#25277;&#21462;&#12290;&#27492;&#22806;&#65292;Text2NKG&#25903;&#25345;&#22235;&#31181;&#20856;&#22411;&#30340;NKG&#27169;&#24335;&#65306;&#36229;&#20851;&#31995;&#27169;&#24335;&#12289;&#22522;&#20110;&#20107;&#20214;&#30340;&#27169;&#24335;&#12289;&#22522;&#20110;&#35282;&#33394;&#30340;&#27169;&#24335;&#21644;&#36229;&#22270;&#27169;&#24335;&#65292;&#20855;&#26377;&#36739;&#39640;&#30340;&#28789;&#27963;&#24615;&#21644;&#23454;&#29992;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;Text2NKG&#30340;&#34920;&#29616;&#20248;&#20110;&#20256;&#32479;&#30340;N&#20803;&#20851;&#31995;&#25277;&#21462;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Beyond traditional binary relational facts, n-ary relational knowledge graphs (NKGs) are comprised of n-ary relational facts containing more than two entities, which are closer to real-world facts with broader applications. However, the construction of NKGs still significantly relies on manual labor, and n-ary relation extraction still remains at a course-grained level, which is always in a single schema and fixed arity of entities. To address these restrictions, we propose Text2NKG, a novel fine-grained n-ary relation extraction framework for n-ary relational knowledge graph construction. We introduce a span-tuple classification approach with hetero-ordered merging to accomplish fine-grained n-ary relation extraction in different arity. Furthermore, Text2NKG supports four typical NKG schemas: hyper-relational schema, event-based schema, role-based schema, and hypergraph-based schema, with high flexibility and practicality. Experimental results demonstrate that Text2NKG outperforms the
&lt;/p&gt;</description></item><item><title>&#22312;&#38646;&#26679;&#26412;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#30740;&#31350;&#20154;&#21592;&#25506;&#32034;&#20102;&#22312;&#23567;&#26679;&#26412;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#26102;&#65292;&#21069;&#21521;-&#21518;&#21521;&#31639;&#27861;&#24615;&#33021;&#19979;&#38477;&#30340;&#38382;&#39064;&#65292;&#24182;&#20351;&#29992;&#20445;&#23432;&#24615;&#31639;&#27861;&#26469;&#32531;&#35299;&#27492;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#20445;&#23432;&#30340;&#21069;&#21521;-&#21518;&#21521;&#31639;&#27861;&#22312;&#24635;&#20307;&#19978;&#34920;&#29616;&#26356;&#22909;&#65292;&#29978;&#33267;&#36229;&#36807;&#20102;&#29305;&#23450;&#20219;&#21153;&#30340;&#22522;&#20934;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2309.15178</link><description>&lt;p&gt;
&#20445;&#23432;&#30340;&#19990;&#30028;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Conservative World Models. (arXiv:2309.15178v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15178
&lt;/p&gt;
&lt;p&gt;
&#22312;&#38646;&#26679;&#26412;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#30740;&#31350;&#20154;&#21592;&#25506;&#32034;&#20102;&#22312;&#23567;&#26679;&#26412;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#26102;&#65292;&#21069;&#21521;-&#21518;&#21521;&#31639;&#27861;&#24615;&#33021;&#19979;&#38477;&#30340;&#38382;&#39064;&#65292;&#24182;&#20351;&#29992;&#20445;&#23432;&#24615;&#31639;&#27861;&#26469;&#32531;&#35299;&#27492;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#20445;&#23432;&#30340;&#21069;&#21521;-&#21518;&#21521;&#31639;&#27861;&#22312;&#24635;&#20307;&#19978;&#34920;&#29616;&#26356;&#22909;&#65292;&#29978;&#33267;&#36229;&#36807;&#20102;&#29305;&#23450;&#20219;&#21153;&#30340;&#22522;&#20934;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38646;&#26679;&#26412;&#24378;&#21270;&#23398;&#20064;&#25215;&#35834;&#22312;&#31163;&#32447;&#39044;&#35757;&#32451;&#38454;&#27573;&#21518;&#65292;&#25552;&#20379;&#33021;&#22815;&#22312;&#20219;&#20309;&#29615;&#22659;&#20013;&#25191;&#34892;&#20219;&#20309;&#20219;&#21153;&#30340;&#20195;&#29702;&#12290;&#21069;&#21521;-&#21518;&#21521;&#65288;FB&#65289;&#34920;&#31034;&#22312;&#36825;&#20010;&#29702;&#24819;&#30340;&#23454;&#29616;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#21487;&#20197;&#22312;&#36825;&#31181;&#35774;&#32622;&#20013;&#36798;&#21040;&#29305;&#23450;&#20219;&#21153;&#20195;&#29702;&#30340;85%&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#36825;&#26679;&#30340;&#24615;&#33021;&#21462;&#20915;&#20110;&#23545;&#20110;&#22823;&#35268;&#27169;&#19988;&#22810;&#26679;&#21270;&#30340;&#25968;&#25454;&#38598;&#30340;&#35775;&#38382;&#65292;&#32780;&#22823;&#22810;&#25968;&#30495;&#23454;&#38382;&#39064;&#26080;&#27861;&#26399;&#26395;&#36825;&#26679;&#30340;&#25968;&#25454;&#38598;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#22312;&#35757;&#32451;&#38598;&#32570;&#20047;&#22810;&#26679;&#24615;&#30340;&#24773;&#20917;&#19979;FB&#24615;&#33021;&#22914;&#20309;&#38477;&#20302;&#65292;&#24182;&#36890;&#36807;&#20445;&#23432;&#24615;&#26469;&#20943;&#36731;&#36825;&#31181;&#24773;&#20917;&#65292;&#36825;&#26159;&#19968;&#20010;&#25104;&#29087;&#30340;&#31163;&#32447;RL&#31639;&#27861;&#30340;&#29305;&#28857;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#12289;&#39046;&#22495;&#21644;&#20219;&#21153;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#23478;&#26063;&#65292;&#22312;&#24635;&#20307;&#19978;&#36798;&#21040;&#20102;150%&#30340;&#26222;&#36890;FB&#24615;&#33021;&#12290;&#26377;&#20123;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#20445;&#23432;&#30340;FB&#31639;&#27861;&#22312;&#27809;&#26377;&#35775;&#38382;&#22870;&#21169;&#26631;&#31614;&#19988;&#38656;&#35201;&#32500;&#25252;&#25152;&#26377;&#20219;&#21153;&#31574;&#30053;&#30340;&#24773;&#20917;&#19979;&#65292;&#20063;&#20248;&#20110;&#29305;&#23450;&#20219;&#21153;&#22522;&#32447;&#12290;
&lt;/p&gt;
&lt;p&gt;
Zero-shot reinforcement learning (RL) promises to provide agents that can perform any task in an environment after an offline pre-training phase. Forward-backward (FB) representations represent remarkable progress towards this ideal, achieving 85% of the performance of task-specific agents in this setting. However, such performance is contingent on access to large and diverse datasets for pre-training, which cannot be expected for most real problems. Here, we explore how FB performance degrades when trained on small datasets that lack diversity, and mitigate it with conservatism, a well-established feature of performant offline RL algorithms. We evaluate our family of methods across various datasets, domains and tasks, reaching 150% of vanilla FB performance in aggregate. Somewhat surprisingly, conservative FB algorithms also outperform the task-specific baseline, despite lacking access to reward labels and being required to maintain policies for all tasks. Conservative FB algorithms p
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#32852;&#37030;&#24335;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30340;&#27010;&#24565;&#65292;&#36890;&#36807;&#32852;&#37030;&#23398;&#20064;&#23454;&#29616;&#20998;&#25955;&#25968;&#25454;&#30340;&#20849;&#21516;&#35757;&#32451;&#20849;&#20139;&#27169;&#22411;&#65292;&#20197;&#24212;&#23545;&#20844;&#20849;&#25968;&#25454;&#21487;&#29992;&#24615;&#30340;&#38480;&#21046;&#21644;&#31169;&#26377;&#25968;&#25454;&#30340;&#38544;&#31169;&#20445;&#25252;&#38656;&#27714;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#39044;&#35757;&#32451;&#12289;&#24494;&#35843;&#21644;&#25552;&#31034;&#24037;&#31243;&#36825;&#19977;&#20010;&#32452;&#20214;&#30340;&#20248;&#21183;&#65292;&#24182;&#25552;&#20986;&#20102;&#23454;&#26045;&#31574;&#30053;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;FL&#21644;LLM&#38598;&#25104;&#24102;&#26469;&#30340;&#26032;&#25361;&#25112;&#65292;&#24182;&#20998;&#26512;&#20102;&#29616;&#26377;&#35299;&#20915;&#26041;&#26696;&#21644;&#28508;&#22312;&#38556;&#30861;&#12290;</title><link>http://arxiv.org/abs/2307.08925</link><description>&lt;p&gt;
&#32852;&#37030;&#24335;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65306;&#19968;&#20010;&#31435;&#22330;&#35770;&#25991;
&lt;/p&gt;
&lt;p&gt;
Federated Large Language Model: A Position Paper. (arXiv:2307.08925v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08925
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#32852;&#37030;&#24335;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30340;&#27010;&#24565;&#65292;&#36890;&#36807;&#32852;&#37030;&#23398;&#20064;&#23454;&#29616;&#20998;&#25955;&#25968;&#25454;&#30340;&#20849;&#21516;&#35757;&#32451;&#20849;&#20139;&#27169;&#22411;&#65292;&#20197;&#24212;&#23545;&#20844;&#20849;&#25968;&#25454;&#21487;&#29992;&#24615;&#30340;&#38480;&#21046;&#21644;&#31169;&#26377;&#25968;&#25454;&#30340;&#38544;&#31169;&#20445;&#25252;&#38656;&#27714;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#39044;&#35757;&#32451;&#12289;&#24494;&#35843;&#21644;&#25552;&#31034;&#24037;&#31243;&#36825;&#19977;&#20010;&#32452;&#20214;&#30340;&#20248;&#21183;&#65292;&#24182;&#25552;&#20986;&#20102;&#23454;&#26045;&#31574;&#30053;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;FL&#21644;LLM&#38598;&#25104;&#24102;&#26469;&#30340;&#26032;&#25361;&#25112;&#65292;&#24182;&#20998;&#26512;&#20102;&#29616;&#26377;&#35299;&#20915;&#26041;&#26696;&#21644;&#28508;&#22312;&#38556;&#30861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#21508;&#20010;&#39046;&#22495;&#33719;&#24471;&#20102;&#30456;&#24403;&#22823;&#30340;&#20851;&#27880;&#24182;&#25214;&#21040;&#20102;&#22810;&#26679;&#21270;&#30340;&#24212;&#29992;&#65292;&#20294;&#22312;&#30495;&#23454;&#22330;&#26223;&#20013;&#24320;&#21457;&#26102;&#38754;&#20020;&#25361;&#25112;&#12290;&#36825;&#20123;&#25361;&#25112;&#28304;&#20110;&#20844;&#20849;&#39046;&#22495;&#25968;&#25454;&#21487;&#29992;&#24615;&#30340;&#21294;&#20047;&#20197;&#21450;&#23545;&#31169;&#26377;&#39046;&#22495;&#25968;&#25454;&#30340;&#38544;&#31169;&#20445;&#25252;&#38656;&#27714;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#20316;&#20026;&#19968;&#39033;&#26377;&#21069;&#26223;&#30340;&#25216;&#26415;&#20986;&#29616;&#20102;&#65292;&#23427;&#33021;&#22815;&#22312;&#20445;&#25345;&#20998;&#25955;&#25968;&#25454;&#30340;&#21516;&#26102;&#23454;&#29616;&#20849;&#21516;&#35757;&#32451;&#20849;&#20139;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#32852;&#37030;&#24335;LLM&#30340;&#27010;&#24565;&#65292;&#21253;&#25324;&#19977;&#20010;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#65292;&#21363;&#32852;&#37030;&#24335;LLM&#39044;&#35757;&#32451;&#12289;&#32852;&#37030;&#24335;LLM&#24494;&#35843;&#21644;&#32852;&#37030;&#24335;LLM&#25552;&#31034;&#24037;&#31243;&#12290;&#23545;&#20110;&#27599;&#20010;&#32452;&#20214;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#23427;&#30456;&#23545;&#20110;&#20256;&#32479;LLM&#35757;&#32451;&#26041;&#27861;&#30340;&#20248;&#21183;&#65292;&#24182;&#25552;&#20986;&#20102;&#20855;&#20307;&#30340;&#24037;&#31243;&#31574;&#30053;&#26469;&#23454;&#26045;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;FL&#21644;LLM&#38598;&#25104;&#24102;&#26469;&#30340;&#26032;&#25361;&#25112;&#12290;&#25105;&#20204;&#20998;&#26512;&#29616;&#26377;&#30340;&#35299;&#20915;&#26041;&#26696;&#24182;&#30830;&#23450;&#21487;&#33021;&#30340;&#38556;&#30861;
&lt;/p&gt;
&lt;p&gt;
Large scale language models (LLM) have received significant attention and found diverse applications across various domains, but their development encounters challenges in real-world scenarios. These challenges arise due to the scarcity of public domain data availability and the need to maintain privacy with respect to private domain data. To address these issues, federated learning (FL) has emerged as a promising technology that enables collaborative training of shared models while preserving decentralized data. We propose the concept of federated LLM, which comprises three key components, i.e., federated LLM pre-training, federated LLM fine-tuning, and federated LLM prompt engineering. For each component, we discuss its advantage over traditional LLM training methods and propose specific engineering strategies for implementation. Furthermore, we explore the novel challenges introduced by the integration of FL and LLM. We analyze existing solutions and identify potential obstacles fac
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20195;&#30721;&#30456;&#20114;&#36716;&#25442;&#26041;&#27861;&#65292;&#21033;&#29992;&#27880;&#24847;&#21147;&#26426;&#21046;&#12289;&#32534;&#35793;&#21644;&#31526;&#21495;&#25191;&#34892;&#27979;&#35797;&#29983;&#25104;&#36827;&#34892;&#31561;&#20215;&#27979;&#35797;&#12290;&#22312;&#24191;&#27867;&#30340;&#23454;&#39564;&#20013;&#65292;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#32534;&#35793;&#21644;&#36816;&#34892;&#26102;&#31561;&#20215;&#20934;&#30830;&#24615;&#31561;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#36716;&#25442;&#22120;&#21644;&#32763;&#35793;&#24037;&#20855;&#12290;</title><link>http://arxiv.org/abs/2306.06755</link><description>&lt;p&gt;
&#27880;&#24847;&#21147;&#12289;&#32534;&#35793;&#21644;&#22522;&#20110;&#27714;&#35299;&#22120;&#30340;&#31526;&#21495;&#20998;&#26512;&#26159;&#24744;&#25152;&#38656;&#35201;&#30340;&#19968;&#20999;
&lt;/p&gt;
&lt;p&gt;
Attention, Compilation, and Solver-based Symbolic Analysis are All You Need. (arXiv:2306.06755v2 [cs.PL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06755
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20195;&#30721;&#30456;&#20114;&#36716;&#25442;&#26041;&#27861;&#65292;&#21033;&#29992;&#27880;&#24847;&#21147;&#26426;&#21046;&#12289;&#32534;&#35793;&#21644;&#31526;&#21495;&#25191;&#34892;&#27979;&#35797;&#29983;&#25104;&#36827;&#34892;&#31561;&#20215;&#27979;&#35797;&#12290;&#22312;&#24191;&#27867;&#30340;&#23454;&#39564;&#20013;&#65292;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#32534;&#35793;&#21644;&#36816;&#34892;&#26102;&#31561;&#20215;&#20934;&#30830;&#24615;&#31561;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#36716;&#25442;&#22120;&#21644;&#32763;&#35793;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;Java&#21040;Python&#65288;J2P&#65289;&#21644;Python&#21040;Java&#65288;P2J&#65289;&#20195;&#30721;&#30456;&#20114;&#36716;&#25442;&#26041;&#27861;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#20010;&#21517;&#20026;CoTran&#30340;&#30456;&#20851;&#24037;&#20855;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#12289;&#32534;&#35793;&#21644;&#22522;&#20110;&#31526;&#21495;&#25191;&#34892;&#30340;&#27979;&#35797;&#29983;&#25104;&#65292;&#29992;&#20110;&#36755;&#20837;&#21644;&#36755;&#20986;&#31243;&#24207;&#20043;&#38388;&#30340;&#31561;&#20215;&#27979;&#35797;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20462;&#25913;&#20102;&#20856;&#22411;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35757;&#32451;&#24490;&#29615;&#65292;&#21152;&#20837;&#20102;&#32534;&#35793;&#22120;&#21644;&#31526;&#21495;&#25191;&#34892;&#25439;&#22833;&#12290;&#36890;&#36807;&#22312;&#36229;&#36807;57,000&#20010;Java-Python&#31561;&#20215;&#23545;&#30340;&#22522;&#20934;&#27979;&#35797;&#20013;&#23558;CoTran&#19982;&#20854;&#20182;12&#20010;&#36716;&#25442;&#22120;&#21644;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#32763;&#35793;&#24037;&#20855;&#36827;&#34892;&#24191;&#27867;&#30340;&#23454;&#39564;&#27604;&#36739;&#65292;&#25105;&#20204;&#21457;&#29616;CoTran&#22312;&#35832;&#22914;&#32534;&#35793;&#21644;&#36816;&#34892;&#26102;&#31561;&#20215;&#20934;&#30830;&#24615;&#31561;&#30456;&#20851;&#25351;&#26631;&#19978;&#34920;&#29616;&#20248;&#20110;&#23427;&#20204;&#12290;&#20363;&#22914;&#65292;&#25105;&#20204;&#30340;&#24037;&#20855;&#22312;J2P&#36716;&#25442;&#20013;&#33719;&#24471;97.43%&#30340;&#32534;&#35793;&#20934;&#30830;&#24615;&#21644;49.66%&#30340;&#36816;&#34892;&#26102;&#31561;&#20215;&#20934;&#30830;&#24615;&#65292;&#32780;&#26368;&#25509;&#36817;&#30340;&#31454;&#20105;&#24037;&#20855;&#20998;&#21035;&#21482;&#26377;92.84%&#21644;40.95%&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present a Java-to-Python (J2P) and Python-to-Java (P2J) back-to-back code translation method, and an associated tool called CoTran, based on large language models (LLMs). Our method leverages the attention mechanism of LLMs, compilation, and symbolic execution-based test generation for equivalence testing between the input and output programs. More precisely, we modify the typical LLM training loop to incorporate compiler and symbolic execution loss. Via extensive experiments comparing CoTran with 12 other transpilers and LLM-based translation tools over a benchmark of more than 57,000 Java-Python equivalent pairs, we show that CoTran outperforms them on relevant metrics such as compilation and runtime equivalence accuracy. For example, our tool gets 97.43% compilation accuracy and 49.66% runtime equivalence accuracy for J2P translation, whereas the nearest competing tool only gets 92.84% and 40.95% respectively.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#38598;&#21512;&#21270;&#22320;&#32534;&#30721;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#26435;&#37325;&#32534;&#30721;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#36880;&#23618;&#32534;&#30721;&#26041;&#26696;&#26469;&#32771;&#34385;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#23618;&#35745;&#31639;&#32467;&#26500;&#12290;&#21516;&#26102;&#24341;&#20837;&#20102;&#8220;pad-chunk-encode&#8221;&#27969;&#27700;&#32447;&#36827;&#34892;&#31070;&#32463;&#32593;&#32476;&#23618;&#30340;&#39640;&#25928;&#32534;&#30721;&#22788;&#29702;&#65292;&#36824;&#25552;&#20986;&#20102;&#26032;&#30340;&#31070;&#32463;&#32593;&#32476;&#27867;&#21270;&#24615;&#33021;&#39044;&#27979;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2305.16625</link><description>&lt;p&gt;
&#38598;&#21512;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#32534;&#30721;
&lt;/p&gt;
&lt;p&gt;
Set-based Neural Network Encoding. (arXiv:2305.16625v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16625
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#38598;&#21512;&#21270;&#22320;&#32534;&#30721;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#26435;&#37325;&#32534;&#30721;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#36880;&#23618;&#32534;&#30721;&#26041;&#26696;&#26469;&#32771;&#34385;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#23618;&#35745;&#31639;&#32467;&#26500;&#12290;&#21516;&#26102;&#24341;&#20837;&#20102;&#8220;pad-chunk-encode&#8221;&#27969;&#27700;&#32447;&#36827;&#34892;&#31070;&#32463;&#32593;&#32476;&#23618;&#30340;&#39640;&#25928;&#32534;&#30721;&#22788;&#29702;&#65292;&#36824;&#25552;&#20986;&#20102;&#26032;&#30340;&#31070;&#32463;&#32593;&#32476;&#27867;&#21270;&#24615;&#33021;&#39044;&#27979;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#38598;&#21512;&#21040;&#38598;&#21512;&#21644;&#38598;&#21512;&#21040;&#21521;&#37327;&#20989;&#25968;&#26469;&#26377;&#25928;&#32534;&#30721;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#65292;&#36827;&#34892;&#27867;&#21270;&#24615;&#33021;&#39044;&#27979;&#30340;&#31070;&#32463;&#32593;&#32476;&#26435;&#37325;&#32534;&#30721;&#26041;&#27861;&#12290;&#19982;&#20043;&#21069;&#38656;&#35201;&#23545;&#19981;&#21516;&#26550;&#26500;&#32534;&#20889;&#33258;&#23450;&#20041;&#32534;&#30721;&#27169;&#22411;&#30340;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#23545;&#28151;&#21512;&#26550;&#26500;&#21644;&#19981;&#21516;&#21442;&#25968;&#22823;&#23567;&#30340;&#27169;&#22411;&#21160;&#24577;&#32534;&#30721;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340; SNE&#65288;&#38598;&#21512;&#21270;&#31070;&#32463;&#32593;&#32476;&#32534;&#30721;&#22120;&#65289;&#36890;&#36807;&#20351;&#29992;&#19968;&#31181;&#36880;&#23618;&#32534;&#30721;&#26041;&#26696;&#65292;&#32771;&#34385;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#23618;&#35745;&#31639;&#32467;&#26500;&#12290;&#26368;&#32456;&#23558;&#25152;&#26377;&#23618;&#27425;&#32534;&#30721;&#21512;&#24182;&#21040;&#19968;&#36215;&#65292;&#20197;&#33719;&#21462;&#31070;&#32463;&#32593;&#32476;&#32534;&#30721;&#30690;&#37327;&#12290;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#8220;pad-chunk-encode&#8221;&#27969;&#27700;&#32447;&#26469;&#26377;&#25928;&#22320;&#32534;&#30721;&#31070;&#32463;&#32593;&#32476;&#23618;&#65292;&#35813;&#27969;&#27700;&#32447;&#21487;&#26681;&#25454;&#35745;&#31639;&#21644;&#20869;&#23384;&#38480;&#21046;&#36827;&#34892;&#35843;&#25972;&#12290;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#20004;&#20010;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#27867;&#21270;&#24615;&#33021;&#39044;&#27979;&#30340;&#26032;&#20219;&#21153;&#65306;&#36328;&#25968;&#25454;&#38598;&#21644;&#26550;&#26500;&#36866;&#24212;&#24615;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose an approach to neural network weight encoding for generalization performance prediction that utilizes set-to-set and set-to-vector functions to efficiently encode neural network parameters. Our approach is capable of encoding neural networks in a modelzoo of mixed architecture and different parameter sizes as opposed to previous approaches that require custom encoding models for different architectures. Furthermore, our \textbf{S}et-based \textbf{N}eural network \textbf{E}ncoder (SNE) takes into consideration the hierarchical computational structure of neural networks by utilizing a layer-wise encoding scheme that culminates to encoding all layer-wise encodings to obtain the neural network encoding vector. Additionally, we introduce a \textit{pad-chunk-encode} pipeline to efficiently encode neural network layers that is adjustable to computational and memory constraints. We also introduce two new tasks for neural network generalization performance prediction: cross-dataset a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19981;&#31934;&#30830;&#26631;&#31614;&#23398;&#20064;&#65288;ILL&#65289;&#26694;&#26550;&#65292;&#21033;&#29992;&#26399;&#26395;&#26368;&#22823;&#21270;&#31639;&#27861;&#23545;&#19981;&#31934;&#30830;&#26631;&#31614;&#20449;&#24687;&#36827;&#34892;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65292;&#20026;&#21508;&#31181;&#19981;&#31934;&#30830;&#26631;&#31614;&#37197;&#32622;&#38382;&#39064;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2305.12715</link><description>&lt;p&gt;
&#19981;&#31934;&#30830;&#26631;&#31614;&#23398;&#20064;&#65306;&#23398;&#20064;&#21508;&#31181;&#19981;&#31934;&#30830;&#26631;&#31614;&#37197;&#32622;&#30340;&#32479;&#19968;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations. (arXiv:2305.12715v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12715
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19981;&#31934;&#30830;&#26631;&#31614;&#23398;&#20064;&#65288;ILL&#65289;&#26694;&#26550;&#65292;&#21033;&#29992;&#26399;&#26395;&#26368;&#22823;&#21270;&#31639;&#27861;&#23545;&#19981;&#31934;&#30830;&#26631;&#31614;&#20449;&#24687;&#36827;&#34892;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65292;&#20026;&#21508;&#31181;&#19981;&#31934;&#30830;&#26631;&#31614;&#37197;&#32622;&#38382;&#39064;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19981;&#31934;&#30830;&#26631;&#31614;&#23398;&#20064;&#65288;ILL&#65289;&#26694;&#26550;&#65292;&#36825;&#26159;&#19968;&#31181;&#22788;&#29702;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#26222;&#36941;&#23384;&#22312;&#30340;&#21508;&#31181;&#19981;&#31934;&#30830;&#26631;&#31614;&#37197;&#32622;&#30340;&#32479;&#19968;&#26041;&#27861;&#12290;ILL&#21033;&#29992;&#26399;&#26395;&#26368;&#22823;&#21270;&#65288;EM&#65289;&#31639;&#27861;&#23545;&#19981;&#31934;&#30830;&#26631;&#31614;&#20449;&#24687;&#36827;&#34892;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65288;MLE&#65289;&#65292;&#23558;&#31934;&#30830;&#26631;&#31614;&#35270;&#20026;&#28508;&#22312;&#21464;&#37327;&#12290;&#19982;&#20197;&#21069;&#35797;&#22270;&#20174;&#19981;&#31934;&#30830;&#26631;&#31614;&#20449;&#24687;&#20013;&#25512;&#26029;&#27491;&#30830;&#26631;&#31614;&#30340;&#22810;&#21151;&#33021;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;ILL&#26694;&#26550;&#32771;&#34385;&#20102;&#19981;&#31934;&#30830;&#26631;&#31614;&#20449;&#24687;&#24378;&#21152;&#30340;&#25152;&#26377;&#21487;&#33021;&#26631;&#31614;&#65292;&#20801;&#35768;&#23545;&#20219;&#20309;&#19981;&#31934;&#30830;&#26631;&#31614;&#30340;&#32479;&#19968;&#35299;&#20915;&#26041;&#26696;&#12290;&#36890;&#36807;&#20840;&#38754;&#30340;&#23454;&#39564;&#32467;&#26524;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;ILL&#21487;&#20197;&#26080;&#32541;&#22320;&#36866;&#24212;&#21508;&#31181;&#24773;&#20917;&#65292;&#21253;&#25324;&#37096;&#20998;&#26631;&#31614;&#23398;&#20064;&#12289;&#21322;&#30417;&#30563;&#23398;&#20064;&#12289;&#22122;&#22768;&#26631;&#31614;&#23398;&#20064;&#20197;&#21450;&#36825;&#20123;&#37197;&#32622;&#30340;&#28151;&#21512;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#31616;&#21333;&#26041;&#27861;&#36229;&#36807;&#20102;&#29616;&#26377;&#30340;&#22788;&#29702;&#19981;&#31934;&#30830;&#26631;&#31614;&#30340;&#25216;&#26415;&#65292;&#26631;&#24535;&#30528;&#31532;&#19968;&#20010;&#32479;&#19968;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce the imprecise label learning (ILL) framework, a unified approach to handle various imprecise label configurations, which are commonplace challenges in machine learning tasks. ILL leverages an expectation-maximization (EM) algorithm for the maximum likelihood estimation (MLE) of the imprecise label information, treating the precise labels as latent variables. Compared to previous versatile methods attempting to infer correct labels from the imprecise label information, our ILL framework considers all possible labeling imposed by the imprecise label information, allowing a unified solution to deal with any imprecise labels. With comprehensive experimental results, we demonstrate that ILL can seamlessly adapt to various situations, including partial label learning, semi-supervised learning, noisy label learning, and a mixture of these settings. Notably, our simple method surpasses the existing techniques for handling imprecise labels, marking the first unified 
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#24418;&#24335;&#20027;&#20041;&#26469;&#25805;&#20316;&#21644;&#20998;&#26512;&#35777;&#26126;&#65292;&#29992;&#20110;&#29983;&#25104;&#26356;&#30701;&#30340;&#35777;&#26126;&#21644;&#20943;&#23569;&#25628;&#32034;&#24037;&#20316;&#37327;&#12290;</title><link>http://arxiv.org/abs/2304.12827</link><description>&lt;p&gt;
&#35777;&#26126;&#32467;&#26500;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Investigations into Proof Structures. (arXiv:2304.12827v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12827
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#24418;&#24335;&#20027;&#20041;&#26469;&#25805;&#20316;&#21644;&#20998;&#26512;&#35777;&#26126;&#65292;&#29992;&#20110;&#29983;&#25104;&#26356;&#30701;&#30340;&#35777;&#26126;&#21644;&#20943;&#23569;&#25628;&#32034;&#24037;&#20316;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#24182;&#35814;&#32454;&#38416;&#36848;&#20102;&#19968;&#31181;&#26032;&#22411;&#24418;&#24335;&#20027;&#20041;&#26469;&#25805;&#20316;&#21644;&#20998;&#26512;&#35777;&#26126;&#20316;&#20026;&#19968;&#20010;&#25972;&#20307;&#30340;&#23545;&#35937;&#12290;&#22312;&#36825;&#31532;&#19968;&#27425;&#23581;&#35797;&#20013;&#65292;&#36825;&#20010;&#24418;&#24335;&#20027;&#20041;&#20165;&#38480;&#20110;&#30001;&#27987;&#32553;&#25512;&#23548;&#29305;&#24449;&#30340;&#19968;&#38454;&#38382;&#39064;&#12290;&#25105;&#20204;&#20197;&#19968;&#20010;&#20840;&#38754;&#30340;&#24418;&#24335;&#37325;&#26500;&#21644;&#20998;&#26512;&#21382;&#21490;&#19978;{\L}ukasiewicz&#24191;&#27867;&#30740;&#31350;&#36807;&#30340;&#38382;&#39064;&#30340;&#35777;&#26126;&#20026;&#20363;&#36827;&#34892;&#20102;&#38416;&#36848;&#12290;&#36825;&#31181;&#26041;&#27861;&#20026;&#22312;&#35777;&#26126;&#25628;&#32034;&#36807;&#31243;&#20013;&#29983;&#25104;&#24341;&#29702;&#25552;&#20379;&#20102;&#26032;&#30340;&#31995;&#32479;&#26041;&#27861;&#65292;&#20197;&#20943;&#23569;&#25628;&#32034;&#24037;&#20316;&#37327;&#24182;&#25214;&#21040;&#26356;&#30701;&#30340;&#35777;&#26126;&#12290;&#22312;&#36825;&#26465;&#36335;&#32447;&#19978;&#25253;&#21578;&#20102;&#35768;&#22810;&#23454;&#39564;&#65292;&#20854;&#20013;&#33258;&#21160;&#21457;&#29616;&#20102;&#19968;&#20010;&#35777;&#26126;{\L}ukasiewicz&#30340;&#38382;&#39064;&#65292;&#23427;&#27604;&#20197;&#21069;&#20219;&#20309;&#30001;&#20154;&#25110;&#26426;&#22120;&#21457;&#29616;&#30340;&#35777;&#26126;&#37117;&#35201;&#30701;&#24471;&#22810;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce and elaborate a novel formalism for the manipulation and analysis of proofs as objects in a global manner. In this first approach the formalism is restricted to first-order problems characterized by condensed detachment. It is applied in an exemplary manner to a coherent and comprehensive formal reconstruction and analysis of historical proofs of a widely-studied problem due to {\L}ukasiewicz. The underlying approach opens the door towards new systematic ways of generating lemmas in the course of proof search to the effects of reducing the search effort and finding shorter proofs. Among the numerous reported experiments along this line, a proof of {\L}ukasiewicz's problem was automatically discovered that is much shorter than any proof found before by man or machine.
&lt;/p&gt;</description></item></channel></rss>