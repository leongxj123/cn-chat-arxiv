<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#36830;&#32493;&#39046;&#22495;&#30340;&#26032;&#30340;&#35745;&#25968;&#26041;&#27861;&#65292;&#31216;&#20026;&#26684;&#28857;&#26144;&#23556;&#20266;&#35745;&#25968;&#26041;&#27861;&#65288;GPC&#65289;&#65292;&#20197;&#36866;&#24212;&#31163;&#32447;&#29615;&#22659;&#20013;&#30340;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#22312;&#24809;&#32602;Q&#20540;&#30340;&#21516;&#26102;&#20943;&#23569;&#35745;&#31639;&#25104;&#26412;&#12290;</title><link>https://arxiv.org/abs/2404.02545</link><description>&lt;p&gt;
&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#26684;&#28857;&#26144;&#23556;&#20266;&#35745;&#25968;&#32422;&#26463;
&lt;/p&gt;
&lt;p&gt;
Grid-Mapping Pseudo-Count Constraint for Offline Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02545
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#36830;&#32493;&#39046;&#22495;&#30340;&#26032;&#30340;&#35745;&#25968;&#26041;&#27861;&#65292;&#31216;&#20026;&#26684;&#28857;&#26144;&#23556;&#20266;&#35745;&#25968;&#26041;&#27861;&#65288;GPC&#65289;&#65292;&#20197;&#36866;&#24212;&#31163;&#32447;&#29615;&#22659;&#20013;&#30340;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#22312;&#24809;&#32602;Q&#20540;&#30340;&#21516;&#26102;&#20943;&#23569;&#35745;&#31639;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#26159;&#20174;&#38745;&#24577;&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#32780;&#19981;&#19982;&#29615;&#22659;&#36827;&#34892;&#20132;&#20114;&#30340;&#26041;&#27861;&#65292;&#36825;&#30830;&#20445;&#20102;&#23433;&#20840;&#24615;&#24182;&#22240;&#27492;&#20855;&#26377;&#33391;&#22909;&#30340;&#24212;&#29992;&#21069;&#26223;&#12290;&#28982;&#32780;&#65292;&#30452;&#25509;&#24212;&#29992;&#26420;&#32032;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#36890;&#24120;&#22312;&#31163;&#32447;&#29615;&#22659;&#20013;&#22833;&#36133;&#65292;&#22240;&#20026;&#30001;&#20110;&#36229;&#20986;&#20998;&#24067;&#65288;OOD&#65289;&#34892;&#20026;&#24341;&#36215;&#30340;&#20989;&#25968;&#36924;&#36817;&#35823;&#24046;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#29616;&#26377;&#31639;&#27861;&#20027;&#35201;&#24809;&#32602;OOD&#34892;&#20026;&#30340;Q&#20540;&#65292;&#20854;&#32422;&#26463;&#30340;&#36136;&#37327;&#20063;&#24456;&#37325;&#35201;&#12290;&#19981;&#31934;&#30830;&#30340;&#32422;&#26463;&#21487;&#33021;&#23548;&#33268;&#27425;&#20248;&#35299;&#65292;&#32780;&#31934;&#30830;&#30340;&#32422;&#26463;&#21017;&#38656;&#35201;&#26174;&#33879;&#30340;&#35745;&#31639;&#25104;&#26412;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#36830;&#32493;&#39046;&#22495;&#35745;&#25968;&#26041;&#27861;&#65292;&#31216;&#20026;&#26684;&#28857;&#26144;&#23556;&#20266;&#35745;&#25968;&#26041;&#27861;&#65288;GPC&#65289;&#65292;&#20197;&#36866;&#24403;&#22320;&#24809;&#32602;Q&#20540;&#24182;&#20943;&#23569;&#35745;&#31639;&#25104;&#26412;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#23558;&#29366;&#24577;&#21644;&#21160;&#20316;&#31354;&#38388;&#26144;&#23556;&#21040;&#31163;&#25955;&#31354;&#38388;&#65292;&#24182;&#36890;&#36807;&#20266;&#35745;&#25968;&#32422;&#26463;&#23427;&#20204;&#30340;Q&#20540;&#12290;&#36825;&#26159;&#19968;&#20010;&#29702;&#35770;&#24615;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02545v1 Announce Type: cross  Abstract: Offline reinforcement learning learns from a static dataset without interacting with the environment, which ensures security and thus owns a good prospect of application. However, directly applying naive reinforcement learning methods usually fails in an offline environment due to function approximation errors caused by out-of-distribution(OOD) actions. To solve this problem, existing algorithms mainly penalize the Q-value of OOD actions, the quality of whose constraints also matter. Imprecise constraints may lead to suboptimal solutions, while precise constraints require significant computational costs. In this paper, we propose a novel count-based method for continuous domains, called Grid-Mapping Pseudo-Count method(GPC), to penalize the Q-value appropriately and reduce the computational cost. The proposed method maps the state and action space to discrete space and constrains their Q-values through the pseudo-count. It is theoretic
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23558;&#38271;&#31687;&#22238;&#24212;&#20998;&#35299;&#20026;&#21333;&#20010;&#20107;&#23454;&#65292;&#24182;&#36890;&#36807;&#21457;&#36865;&#25628;&#32034;&#26597;&#35810;&#21040;Google&#25628;&#32034;&#65292;&#35780;&#20272;&#20107;&#23454;&#20934;&#30830;&#24615;&#30340;&#26041;&#27861;&#65292;&#24182;&#25193;&#23637;&#20102;F1&#20998;&#25968;&#20316;&#20026;&#38271;&#31687;&#20107;&#23454;&#24615;&#30340;&#32858;&#21512;&#24230;&#37327;&#12290;</title><link>https://arxiv.org/abs/2403.18802</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#38271;&#31687;&#20107;&#23454;&#24615;
&lt;/p&gt;
&lt;p&gt;
Long-form factuality in large language models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18802
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23558;&#38271;&#31687;&#22238;&#24212;&#20998;&#35299;&#20026;&#21333;&#20010;&#20107;&#23454;&#65292;&#24182;&#36890;&#36807;&#21457;&#36865;&#25628;&#32034;&#26597;&#35810;&#21040;Google&#25628;&#32034;&#65292;&#35780;&#20272;&#20107;&#23454;&#20934;&#30830;&#24615;&#30340;&#26041;&#27861;&#65292;&#24182;&#25193;&#23637;&#20102;F1&#20998;&#25968;&#20316;&#20026;&#38271;&#31687;&#20107;&#23454;&#24615;&#30340;&#32858;&#21512;&#24230;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#22238;&#31572;&#24320;&#25918;&#24615;&#20027;&#39064;&#30340;&#20107;&#23454;&#24615;&#25552;&#31034;&#26102;&#65292;&#32463;&#24120;&#29983;&#25104;&#21253;&#21547;&#20107;&#23454;&#38169;&#35823;&#30340;&#20869;&#23481;&#12290;&#20026;&#20102;&#22312;&#24320;&#25918;&#39046;&#22495;&#20013;&#23545;&#27169;&#22411;&#30340;&#38271;&#31687;&#20107;&#23454;&#24615;&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;&#65292;&#25105;&#20204;&#39318;&#20808;&#20351;&#29992;GPT-4&#29983;&#25104;&#20102;&#19968;&#20010;&#21517;&#20026;LongFact&#30340;&#25552;&#31034;&#38598;&#65292;&#20854;&#20013;&#21253;&#21547;&#25968;&#21315;&#20010;&#22218;&#25324;38&#20010;&#20027;&#39064;&#30340;&#38382;&#39064;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;LLM&#20195;&#29702;&#21487;&#20197;&#36890;&#36807;&#19968;&#31181;&#21517;&#20026;Search-Augmented Factuality Evaluator&#65288;SAFE&#65289;&#30340;&#26041;&#27861;&#20316;&#20026;&#38271;&#31687;&#20107;&#23454;&#24615;&#30340;&#33258;&#21160;&#35780;&#20272;&#22120;&#12290;SAFE&#21033;&#29992;LLM&#23558;&#38271;&#31687;&#22238;&#24212;&#20998;&#35299;&#20026;&#19968;&#32452;&#21333;&#29420;&#30340;&#20107;&#23454;&#65292;&#24182;&#36890;&#36807;&#21457;&#36865;&#25628;&#32034;&#26597;&#35810;&#21040;Google&#25628;&#32034;&#20197;&#21450;&#30830;&#23450;&#19968;&#20010;&#20107;&#23454;&#26159;&#21542;&#24471;&#21040;&#25628;&#32034;&#32467;&#26524;&#25903;&#25345;&#30340;&#22810;&#27493;&#25512;&#29702;&#36807;&#31243;&#26469;&#35780;&#20272;&#27599;&#20010;&#20107;&#23454;&#30340;&#20934;&#30830;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#35758;&#23558;F1&#20998;&#25968;&#25193;&#23637;&#20026;&#38271;&#31687;&#20107;&#23454;&#24615;&#30340;&#32858;&#21512;&#24230;&#37327;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24179;&#34913;&#20102;&#22238;&#24212;&#20013;&#25903;&#25345;&#20107;&#23454;&#30340;&#30334;&#20998;&#27604;&#65288;&#31934;&#24230;&#65289;&#19982;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18802v1 Announce Type: cross  Abstract: Large language models (LLMs) often generate content that contains factual errors when responding to fact-seeking prompts on open-ended topics. To benchmark a model's long-form factuality in open domains, we first use GPT-4 to generate LongFact, a prompt set comprising thousands of questions spanning 38 topics. We then propose that LLM agents can be used as automated evaluators for long-form factuality through a method which we call Search-Augmented Factuality Evaluator (SAFE). SAFE utilizes an LLM to break down a long-form response into a set of individual facts and to evaluate the accuracy of each fact using a multi-step reasoning process comprising sending search queries to Google Search and determining whether a fact is supported by the search results. Furthermore, we propose extending F1 score as an aggregated metric for long-form factuality. To do so, we balance the percentage of supported facts in a response (precision) with the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Gradient Cuff&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25506;&#32034;&#25298;&#32477;&#25439;&#22833;&#22320;&#24418;&#22270;&#26469;&#26816;&#27979;&#23545;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#36234;&#29425;&#25915;&#20987;&#65292;&#25104;&#21151;&#35774;&#35745;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#20004;&#27493;&#26816;&#27979;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2403.00867</link><description>&lt;p&gt;
&#26799;&#24230;&#34987;&#32602;&#65306;&#36890;&#36807;&#25506;&#32034;&#25298;&#32477;&#25439;&#22833;&#22320;&#24418;&#22270;&#26469;&#26816;&#27979;&#38024;&#23545;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#36234;&#29425;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Gradient Cuff: Detecting Jailbreak Attacks on Large Language Models by Exploring Refusal Loss Landscapes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00867
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Gradient Cuff&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25506;&#32034;&#25298;&#32477;&#25439;&#22833;&#22320;&#24418;&#22270;&#26469;&#26816;&#27979;&#23545;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#36234;&#29425;&#25915;&#20987;&#65292;&#25104;&#21151;&#35774;&#35745;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#20004;&#27493;&#26816;&#27979;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#27491;&#25104;&#20026;&#19968;&#31181;&#31361;&#20986;&#30340;&#29983;&#25104;&#24335;AI&#24037;&#20855;&#65292;&#29992;&#25143;&#36755;&#20837;&#26597;&#35810;&#65292;LLM&#29983;&#25104;&#31572;&#26696;&#12290;&#20026;&#20102;&#20943;&#23569;&#20260;&#23475;&#21644;&#28389;&#29992;&#65292;&#20154;&#20204;&#36890;&#36807;&#20351;&#29992;&#20808;&#36827;&#30340;&#35757;&#32451;&#25216;&#26415;&#22914;&#26469;&#33258;&#20154;&#31867;&#21453;&#39304;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288;RLHF&#65289;&#26469;&#23558;&#36825;&#20123;LLMs&#19982;&#20154;&#31867;&#20215;&#20540;&#35266;&#20445;&#25345;&#19968;&#33268;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#31361;&#26174;&#20102;LLMs&#23545;&#20110;&#35797;&#22270;&#39072;&#35206;&#23884;&#20837;&#30340;&#23433;&#20840;&#38450;&#25252;&#25514;&#26045;&#30340;&#23545;&#25239;&#24615;&#36234;&#29425;&#23581;&#35797;&#30340;&#33030;&#24369;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#26412;&#25991;&#23450;&#20041;&#24182;&#35843;&#26597;&#20102;LLMs&#30340;&#25298;&#32477;&#25439;&#22833;&#65292;&#28982;&#21518;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Gradient Cuff&#30340;&#26041;&#27861;&#26469;&#26816;&#27979;&#36234;&#29425;&#23581;&#35797;&#12290;Gradient Cuff&#21033;&#29992;&#25298;&#32477;&#25439;&#22833;&#22320;&#24418;&#22270;&#20013;&#35266;&#23519;&#21040;&#30340;&#29420;&#29305;&#29305;&#24615;&#65292;&#21253;&#25324;&#21151;&#33021;&#20540;&#21450;&#20854;&#20809;&#28369;&#24615;&#65292;&#35774;&#35745;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#20004;&#27493;&#26816;&#27979;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00867v1 Announce Type: cross  Abstract: Large Language Models (LLMs) are becoming a prominent generative AI tool, where the user enters a query and the LLM generates an answer. To reduce harm and misuse, efforts have been made to align these LLMs to human values using advanced training techniques such as Reinforcement Learning from Human Feedback (RLHF). However, recent studies have highlighted the vulnerability of LLMs to adversarial jailbreak attempts aiming at subverting the embedded safety guardrails. To address this challenge, this paper defines and investigates the Refusal Loss of LLMs and then proposes a method called Gradient Cuff to detect jailbreak attempts. Gradient Cuff exploits the unique properties observed in the refusal loss landscape, including functional values and its smoothness, to design an effective two-step detection strategy. Experimental results on two aligned LLMs (LLaMA-2-7B-Chat and Vicuna-7B-V1.5) and six types of jailbreak attacks (GCG, AutoDAN,
&lt;/p&gt;</description></item><item><title>&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#22312;&#31227;&#21160;&#36793;&#32536;&#35745;&#31639;&#20013;&#30340;&#20219;&#21153;&#21368;&#36733;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;&#38754;&#20020;&#30528;&#36830;&#32493;&#21644;&#31163;&#25955;&#36164;&#28304;&#32422;&#26463;&#30340;&#25361;&#25112;&#65292;&#20294;&#26377;&#26395;&#23454;&#29616;&#39640;&#25928;&#30340;&#20219;&#21153;&#20998;&#37197;&#12290;</title><link>https://arxiv.org/abs/2402.11653</link><description>&lt;p&gt;
&#31227;&#21160;&#36793;&#32536;&#35745;&#31639;&#20013;&#32452;&#21512;&#24335;&#23458;&#25143;&#31471;-&#20027;&#25511;&#22810;&#26234;&#33021;&#20307;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#29992;&#20110;&#20219;&#21153;&#21368;&#36733;
&lt;/p&gt;
&lt;p&gt;
Combinatorial Client-Master Multiagent Deep Reinforcement Learning for Task Offloading in Mobile Edge Computing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11653
&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#22312;&#31227;&#21160;&#36793;&#32536;&#35745;&#31639;&#20013;&#30340;&#20219;&#21153;&#21368;&#36733;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;&#38754;&#20020;&#30528;&#36830;&#32493;&#21644;&#31163;&#25955;&#36164;&#28304;&#32422;&#26463;&#30340;&#25361;&#25112;&#65292;&#20294;&#26377;&#26395;&#23454;&#29616;&#39640;&#25928;&#30340;&#20219;&#21153;&#20998;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#20986;&#29616;&#20102;&#22823;&#37327;&#25191;&#34892;&#35745;&#31639;&#23494;&#38598;&#22411;&#20219;&#21153;&#30340;&#31227;&#21160;&#24212;&#29992;&#31243;&#24207;&#65292;&#22914;&#35270;&#39057;&#27969;&#23186;&#20307;&#12289;&#25968;&#25454;&#25366;&#25496;&#12289;&#34394;&#25311;&#29616;&#23454;&#12289;&#22686;&#24378;&#29616;&#23454;&#12289;&#22270;&#20687;&#22788;&#29702;&#12289;&#35270;&#39057;&#22788;&#29702;&#12289;&#20154;&#33080;&#35782;&#21035;&#21644;&#22312;&#32447;&#28216;&#25103;&#12290;&#31227;&#21160;&#36793;&#32536;&#35745;&#31639;&#65288;MEC&#65289;&#24050;&#32463;&#25104;&#20026;&#19968;&#31181;&#28385;&#36275;&#29992;&#25143;&#35774;&#22791;&#65288;UDs&#65289;&#26085;&#30410;&#22686;&#38271;&#30340;&#35745;&#31639;&#38656;&#27714;&#30340;&#26377;&#21069;&#36884;&#30340;&#25216;&#26415;&#12290;MEC&#20013;&#30340;&#20219;&#21153;&#21368;&#36733;&#26159;&#19968;&#31181;&#31574;&#30053;&#65292;&#36890;&#36807;&#22312;UDs&#21644;MEC&#26381;&#21153;&#22120;&#20043;&#38388;&#20998;&#37197;&#20219;&#21153;&#26469;&#28385;&#36275;UDs&#30340;&#38656;&#27714;&#12290;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#65288;DRL&#65289;&#22312;&#20219;&#21153;&#21368;&#36733;&#38382;&#39064;&#20013;&#21463;&#21040;&#20851;&#27880;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#36866;&#24212;&#21160;&#24577;&#21464;&#21270;&#24182;&#26368;&#23567;&#21270;&#22312;&#32447;&#35745;&#31639;&#22797;&#26434;&#24615;&#12290;&#28982;&#32780;&#65292;UDs&#21644;MEC&#26381;&#21153;&#22120;&#19978;&#30340;&#21508;&#31181;&#31867;&#22411;&#30340;&#36830;&#32493;&#21644;&#31163;&#25955;&#36164;&#28304;&#32422;&#26463;&#23545;&#26377;&#25928;&#30340;&#22522;&#20110;DRL&#30340;&#20219;&#21153;&#21368;&#36733;&#35774;&#35745;&#26500;&#25104;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11653v1 Announce Type: new  Abstract: Recently, there has been an explosion of mobile applications that perform computationally intensive tasks such as video streaming, data mining, virtual reality, augmented reality, image processing, video processing, face recognition, and online gaming. However, user devices (UDs), such as tablets and smartphones, have a limited ability to perform the computation needs of the tasks. Mobile edge computing (MEC) has emerged as a promising technology to meet the increasing computing demands of UDs. Task offloading in MEC is a strategy that meets the demands of UDs by distributing tasks between UDs and MEC servers. Deep reinforcement learning (DRL) is gaining attention in task-offloading problems because it can adapt to dynamic changes and minimize online computational complexity. However, the various types of continuous and discrete resource constraints on UDs and MEC servers pose challenges to the design of an efficient DRL-based task-offlo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20010;&#24615;&#21270;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#27604;&#36739;&#24494;&#35843;&#21644;&#38646;&#26679;&#26412;&#25512;&#29702;&#30340;&#26041;&#27861;&#65292;&#22312;&#20027;&#35266;&#20219;&#21153;&#20013;&#21457;&#29616;&#20010;&#24615;&#21270;&#24494;&#35843;&#33021;&#25552;&#39640;&#27169;&#22411;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#22312;&#24773;&#24863;&#35782;&#21035;&#21644;&#20167;&#24680;&#35328;&#35770;&#26816;&#27979;&#26041;&#38754;&#20063;&#33719;&#24471;&#20102;&#19968;&#33268;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;</title><link>https://arxiv.org/abs/2402.09269</link><description>&lt;p&gt;
&#20010;&#24615;&#21270;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Personalized Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09269
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20010;&#24615;&#21270;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#27604;&#36739;&#24494;&#35843;&#21644;&#38646;&#26679;&#26412;&#25512;&#29702;&#30340;&#26041;&#27861;&#65292;&#22312;&#20027;&#35266;&#20219;&#21153;&#20013;&#21457;&#29616;&#20010;&#24615;&#21270;&#24494;&#35843;&#33021;&#25552;&#39640;&#27169;&#22411;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#22312;&#24773;&#24863;&#35782;&#21035;&#21644;&#20167;&#24680;&#35328;&#35770;&#26816;&#27979;&#26041;&#38754;&#20063;&#33719;&#24471;&#20102;&#19968;&#33268;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#36890;&#29992;&#24615;&#22312;&#38656;&#35201;&#20010;&#24615;&#21270;&#22238;&#24212;&#30340;&#22330;&#26223;&#65288;&#22914;&#25512;&#33616;&#31995;&#32479;&#21644;&#32842;&#22825;&#26426;&#22120;&#20154;&#65289;&#20013;&#23384;&#22312;&#19968;&#23450;&#30340;&#23616;&#38480;&#24615;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20010;&#24615;&#21270;LLM&#30340;&#26041;&#27861;&#65292;&#27604;&#36739;&#20102;&#24494;&#35843;&#21644;&#38646;&#26679;&#26412;&#25512;&#29702;&#26041;&#27861;&#22312;&#20027;&#35266;&#20219;&#21153;&#20013;&#30340;&#25928;&#26524;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#38750;&#20010;&#24615;&#21270;&#27169;&#22411;&#30456;&#27604;&#65292;&#20010;&#24615;&#21270;&#24494;&#35843;&#25913;&#21892;&#20102;&#27169;&#22411;&#30340;&#25512;&#29702;&#33021;&#21147;&#12290;&#22312;&#24773;&#24863;&#35782;&#21035;&#21644;&#20167;&#24680;&#35328;&#35770;&#26816;&#27979;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#20010;&#24615;&#21270;&#26041;&#27861;&#22312;&#19981;&#21516;&#30340;LLM&#26550;&#26500;&#19978;&#33719;&#24471;&#20102;&#19968;&#33268;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;&#36825;&#20123;&#21457;&#29616;&#24378;&#35843;&#20102;&#22312;&#20027;&#35266;&#25991;&#26412;&#29702;&#35299;&#20219;&#21153;&#20013;&#25552;&#21319;LLM&#33021;&#21147;&#30340;&#20010;&#24615;&#21270;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09269v1 Announce Type: cross Abstract: Large language models (LLMs) have significantly advanced Natural Language Processing (NLP) tasks in recent years. However, their universal nature poses limitations in scenarios requiring personalized responses, such as recommendation systems and chatbots. This paper investigates methods to personalize LLMs, comparing fine-tuning and zero-shot reasoning approaches on subjective tasks. Results demonstrate that personalized fine-tuning improves model reasoning compared to non-personalized models. Experiments on datasets for emotion recognition and hate speech detection show consistent performance gains with personalized methods across different LLM architectures. These findings underscore the importance of personalization for enhancing LLM capabilities in subjective text perception tasks.
&lt;/p&gt;</description></item><item><title>&#20581;&#22766;&#30340;&#22810;&#27169;&#24577;&#27169;&#22411;&#23637;&#31034;&#20102;&#24322;&#24120;&#29305;&#24449;&#21644;&#26356;&#22810;&#27010;&#24565;&#30340;&#32534;&#30721;&#26041;&#24335;&#12290;</title><link>http://arxiv.org/abs/2310.13040</link><description>&lt;p&gt;
&#20581;&#22766;&#30340;&#22810;&#27169;&#24577;&#27169;&#22411;&#20855;&#26377;&#24322;&#24120;&#29305;&#24449;&#24182;&#32534;&#30721;&#26356;&#22810;&#27010;&#24565;
&lt;/p&gt;
&lt;p&gt;
Robust multimodal models have outlier features and encode more concepts. (arXiv:2310.13040v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13040
&lt;/p&gt;
&lt;p&gt;
&#20581;&#22766;&#30340;&#22810;&#27169;&#24577;&#27169;&#22411;&#23637;&#31034;&#20102;&#24322;&#24120;&#29305;&#24449;&#21644;&#26356;&#22810;&#27010;&#24565;&#30340;&#32534;&#30721;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20160;&#20040;&#21306;&#20998;&#20581;&#22766;&#27169;&#22411;&#19982;&#38750;&#20581;&#22766;&#27169;&#22411;&#65311;&#38543;&#30528;&#22823;&#35268;&#27169;&#22810;&#27169;&#24577;&#27169;&#22411;&#65288;&#22914;CLIP&#65289;&#30340;&#20986;&#29616;&#65292;&#36825;&#20010;&#38382;&#39064;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20851;&#27880;&#12290;&#36825;&#20123;&#27169;&#22411;&#22312;&#33258;&#28982;&#20998;&#24067;&#36716;&#21464;&#26041;&#38754;&#34920;&#29616;&#20986;&#20102;&#21069;&#25152;&#26410;&#26377;&#30340;&#20581;&#22766;&#24615;&#12290;&#23613;&#31649;&#24050;&#32463;&#35777;&#26126;&#20102;&#20581;&#22766;&#24615;&#30340;&#24046;&#24322;&#21487;&#20197;&#36861;&#28335;&#21040;&#35757;&#32451;&#25968;&#25454;&#19978;&#30340;&#24046;&#24322;&#65292;&#20294;&#36804;&#20170;&#20026;&#27490;&#36824;&#19981;&#28165;&#26970;&#36825;&#23545;&#20110;&#27169;&#22411;&#23398;&#20064;&#21040;&#20102;&#20160;&#20040;&#24847;&#21619;&#30528;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#25506;&#27979;12&#20010;&#20855;&#26377;&#19981;&#21516;&#39592;&#24178;&#65288;ResNets&#21644;ViTs&#65289;&#21644;&#39044;&#35757;&#32451;&#38598;&#65288;OpenAI&#65292;LAION-400M&#65292;LAION-2B&#65292;YFCC15M&#65292;CC12M&#21644;DataComp&#65289;&#30340;&#20581;&#22766;&#22810;&#27169;&#24577;&#27169;&#22411;&#30340;&#34920;&#31034;&#31354;&#38388;&#26469;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;&#25105;&#20204;&#21457;&#29616;&#36825;&#20123;&#27169;&#22411;&#30340;&#34920;&#31034;&#31354;&#38388;&#20013;&#23384;&#22312;&#20004;&#20010;&#20581;&#22766;&#24615;&#30340;&#29305;&#24449;&#65306;&#65288;1&#65289;&#20581;&#22766;&#27169;&#22411;&#20855;&#26377;&#30001;&#20854;&#28608;&#27963;&#29305;&#24449;&#34920;&#24449;&#30340;&#24322;&#24120;&#29305;&#24449;&#65292;&#20854;&#20013;&#19968;&#20123;&#29305;&#24449;&#20540;&#27604;&#24179;&#22343;&#20540;&#39640;&#20960;&#20010;&#25968;&#37327;&#32423;&#12290;&#36825;&#20123;&#24322;&#24120;&#29305;&#24449;&#22312;&#27169;&#22411;&#30340;&#34920;&#31034;&#31354;&#38388;&#20013;&#24341;&#20837;&#20102;&#29305;&#26435;&#26041;&#21521;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;...
&lt;/p&gt;
&lt;p&gt;
What distinguishes robust models from non-robust ones? This question has gained traction with the appearance of large-scale multimodal models, such as CLIP. These models have demonstrated unprecedented robustness with respect to natural distribution shifts. While it has been shown that such differences in robustness can be traced back to differences in training data, so far it is not known what that translates to in terms of what the model has learned. In this work, we bridge this gap by probing the representation spaces of 12 robust multimodal models with various backbones (ResNets and ViTs) and pretraining sets (OpenAI, LAION-400M, LAION-2B, YFCC15M, CC12M and DataComp). We find two signatures of robustness in the representation spaces of these models: (1) Robust models exhibit outlier features characterized by their activations, with some being several orders of magnitude above average. These outlier features induce privileged directions in the model's representation space. We demon
&lt;/p&gt;</description></item><item><title>&#35821;&#35328;&#23545;&#40784;&#30340;&#35270;&#35273;&#34920;&#31034;&#26041;&#24335;&#27604;&#32431;&#35270;&#35273;&#34920;&#31034;&#26041;&#24335;&#26356;&#26377;&#25928;&#22320;&#39044;&#27979;&#20154;&#31867;&#22312;&#33258;&#28982;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#34892;&#20026;&#12290;</title><link>http://arxiv.org/abs/2306.09377</link><description>&lt;p&gt;
&#23545;&#40784;&#35821;&#35328;&#30340;&#35270;&#35273;&#34920;&#31034;&#39044;&#27979;&#20154;&#31867;&#22312;&#33258;&#28982;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#34892;&#20026;
&lt;/p&gt;
&lt;p&gt;
Language Aligned Visual Representations Predict Human Behavior in Naturalistic Learning Tasks. (arXiv:2306.09377v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09377
&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#23545;&#40784;&#30340;&#35270;&#35273;&#34920;&#31034;&#26041;&#24335;&#27604;&#32431;&#35270;&#35273;&#34920;&#31034;&#26041;&#24335;&#26356;&#26377;&#25928;&#22320;&#39044;&#27979;&#20154;&#31867;&#22312;&#33258;&#28982;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#31867;&#20855;&#22791;&#35782;&#21035;&#21644;&#27010;&#25324;&#33258;&#28982;&#29289;&#20307;&#30456;&#20851;&#29305;&#24449;&#30340;&#33021;&#21147;&#65292;&#22312;&#21508;&#31181;&#24773;&#22659;&#20013;&#26377;&#25152;&#24110;&#21161;&#12290;&#20026;&#20102;&#30740;&#31350;&#36825;&#31181;&#29616;&#35937;&#24182;&#30830;&#23450;&#26368;&#26377;&#25928;&#30340;&#34920;&#31034;&#26041;&#24335;&#20197;&#39044;&#27979;&#20154;&#31867;&#34892;&#20026;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#20004;&#20010;&#28041;&#21450;&#31867;&#21035;&#23398;&#20064;&#21644;&#22870;&#21169;&#23398;&#20064;&#30340;&#23454;&#39564;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#20351;&#29992;&#36924;&#30495;&#30340;&#22270;&#20687;&#20316;&#20026;&#21050;&#28608;&#29289;&#65292;&#24182;&#35201;&#27714;&#21442;&#19982;&#32773;&#22522;&#20110;&#25152;&#26377;&#35797;&#39564;&#30340;&#26032;&#22411;&#21050;&#28608;&#29289;&#20316;&#20986;&#20934;&#30830;&#30340;&#20915;&#31574;&#65292;&#22240;&#27492;&#38656;&#35201;&#27867;&#21270;&#12290;&#22312;&#20004;&#20010;&#20219;&#21153;&#20013;&#65292;&#24213;&#23618;&#35268;&#21017;&#26159;&#20351;&#29992;&#20154;&#31867;&#30456;&#20284;&#24615;&#21028;&#26029;&#25552;&#21462;&#30340;&#21050;&#28608;&#32500;&#24230;&#29983;&#25104;&#30340;&#31616;&#21333;&#32447;&#24615;&#20989;&#25968;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#21442;&#19982;&#32773;&#22312;&#20960;&#27425;&#35797;&#39564;&#20869;&#23601;&#25104;&#21151;&#22320;&#30830;&#23450;&#20102;&#30456;&#20851;&#30340;&#21050;&#28608;&#29305;&#24449;&#65292;&#35777;&#26126;&#20102;&#26377;&#25928;&#30340;&#27867;&#21270;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#27169;&#22411;&#27604;&#36739;&#65292;&#35780;&#20272;&#20102;&#21508;&#31181;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#34920;&#31034;&#23545;&#20154;&#31867;&#36873;&#25321;&#30340;&#36880;&#27425;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#65288;&#22914;&#35821;&#35328;&#24314;&#27169;&#21644;&#26426;&#22120;&#32763;&#35793;&#65289;&#35757;&#32451;&#30340;&#27169;&#22411;&#34920;&#31034;&#20248;&#20110;&#35270;&#35273;&#20219;&#21153;&#35757;&#32451;&#30340;&#27169;&#22411;&#34920;&#31034;&#65292;&#34920;&#26126;&#23545;&#40784;&#35821;&#35328;&#30340;&#35270;&#35273;&#34920;&#31034;&#21487;&#33021;&#26356;&#26377;&#25928;&#22320;&#39044;&#27979;&#20154;&#31867;&#22312;&#33258;&#28982;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
Humans possess the ability to identify and generalize relevant features of natural objects, which aids them in various situations. To investigate this phenomenon and determine the most effective representations for predicting human behavior, we conducted two experiments involving category learning and reward learning. Our experiments used realistic images as stimuli, and participants were tasked with making accurate decisions based on novel stimuli for all trials, thereby necessitating generalization. In both tasks, the underlying rules were generated as simple linear functions using stimulus dimensions extracted from human similarity judgments. Notably, participants successfully identified the relevant stimulus features within a few trials, demonstrating effective generalization. We performed an extensive model comparison, evaluating the trial-by-trial predictive accuracy of diverse deep learning models' representations of human choices. Intriguingly, representations from models train
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#30340;&#12289;&#29992;&#20110;&#22810;&#26234;&#33021;&#20307;&#20132;&#20114;&#24335;&#28023;&#27915;&#24223;&#24323;&#29289;&#28165;&#29702;&#30340;&#36890;&#20449;&#26426;&#21046;&#65292;&#20351;&#24471;&#19981;&#21516;&#20195;&#29702;&#20043;&#38388;&#21487;&#20197;&#21327;&#20316;&#31454;&#20105;&#24182;&#23454;&#29616;&#25910;&#38598;&#24223;&#24323;&#29289;&#30340;&#26368;&#22823;&#21270;&#12290;</title><link>http://arxiv.org/abs/2304.05872</link><description>&lt;p&gt;
&#22312;&#31454;&#20105;&#24615;&#22810;&#26234;&#33021;&#20307;&#29615;&#22659;&#20013;&#23398;&#20064;&#27807;&#36890;&#21644;&#21327;&#20316;&#20197;&#28165;&#29702;&#28023;&#27915;&#24223;&#24323;&#22609;&#26009;
&lt;/p&gt;
&lt;p&gt;
Learning to Communicate and Collaborate in a Competitive Multi-Agent Setup to Clean the Ocean from Macroplastics. (arXiv:2304.05872v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05872
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#30340;&#12289;&#29992;&#20110;&#22810;&#26234;&#33021;&#20307;&#20132;&#20114;&#24335;&#28023;&#27915;&#24223;&#24323;&#29289;&#28165;&#29702;&#30340;&#36890;&#20449;&#26426;&#21046;&#65292;&#20351;&#24471;&#19981;&#21516;&#20195;&#29702;&#20043;&#38388;&#21487;&#20197;&#21327;&#20316;&#31454;&#20105;&#24182;&#23454;&#29616;&#25910;&#38598;&#24223;&#24323;&#29289;&#30340;&#26368;&#22823;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#21327;&#20316;&#19982;&#31454;&#20105;&#20043;&#38388;&#30340;&#24179;&#34913;&#23545;&#20110;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#20351;&#29992;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#65288;MARL&#65289;&#24314;&#31435;&#22312;&#19968;&#20010;&#39640;&#24433;&#21709;&#38382;&#39064;&#19978;&#65292;&#36890;&#36807;&#23545;&#28023;&#27915;&#24223;&#24323;&#22609;&#26009;&#30340;&#25910;&#38598;&#23454;&#29616;&#20102;&#21327;&#20316;&#19982;&#31454;&#20105;&#30340;&#24179;&#34913;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#30340;&#36890;&#20449;&#26426;&#21046;&#65292;&#23427;&#22686;&#21152;&#20102;&#20195;&#29702;&#30340;&#35266;&#23519;&#31354;&#38388;&#12290;&#22312;&#25105;&#20204;&#33258;&#23450;&#20041;&#30340;&#29615;&#22659;&#20013;&#65292;&#20195;&#29702;&#25511;&#21046;&#30528;&#25910;&#38598;&#22609;&#26009;&#30340;&#33337;&#21482;&#12290;&#36825;&#31181;&#36890;&#20449;&#26426;&#21046;&#20351;&#20195;&#29702;&#33021;&#22815;&#20351;&#29992;&#20108;&#36827;&#21046;&#20449;&#21495;&#26469;&#24320;&#21457;&#36890;&#20449;&#21327;&#35758;&#12290;&#34429;&#28982;&#20195;&#29702;&#30340;&#38598;&#20307;&#30446;&#26631;&#26159;&#23613;&#21487;&#33021;&#22320;&#28165;&#29702;&#28023;&#27915;&#24223;&#24323;&#22609;&#26009;&#65292;&#20294;&#20195;&#29702;&#20250;&#22240;&#20010;&#20154;&#25910;&#38598;&#21040;&#30340;&#24223;&#24323;&#22609;&#26009;&#25968;&#37327;&#32780;&#33719;&#24471;&#22870;&#21169;&#12290;&#22240;&#27492;&#65292;&#20195;&#29702;&#24517;&#39035;&#23398;&#20250;&#26377;&#25928;&#22320;&#27807;&#36890;&#24182;&#20445;&#25345;&#31454;&#20105;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Finding a balance between collaboration and competition is crucial for artificial agents in many real-world applications. We investigate this using a Multi-Agent Reinforcement Learning (MARL) setup on the back of a high-impact problem. The accumulation and yearly growth of plastic in the ocean cause irreparable damage to many aspects of oceanic health and the marina system. To prevent further damage, we need to find ways to reduce macroplastics from known plastic patches in the ocean. Here we propose a Graph Neural Network (GNN) based communication mechanism that increases the agents' observation space. In our custom environment, agents control a plastic collecting vessel. The communication mechanism enables agents to develop a communication protocol using a binary signal. While the goal of the agent collective is to clean up as much as possible, agents are rewarded for the individual amount of macroplastics collected. Hence agents have to learn to communicate effectively while maintai
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#27169;&#22411;&#26080;&#20851;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#29992;&#20110;&#35780;&#20272;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#39044;&#27979;&#32467;&#26524;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;&#36825;&#20123;&#24230;&#37327;&#26631;&#20934;&#23558;&#21508;&#20010;&#35299;&#37322;&#33021;&#21147;&#26041;&#38754;&#24635;&#32467;&#25104;&#26631;&#37327;&#65292;&#25552;&#20379;&#20840;&#38754;&#30340;&#29702;&#35299;&#24182;&#20419;&#36827;&#20915;&#31574;&#32773;&#21644;&#21033;&#30410;&#30456;&#20851;&#32773;&#20043;&#38388;&#30340;&#27807;&#36890;&#65292;&#20174;&#32780;&#25552;&#39640;&#25972;&#20307;&#30340;&#36879;&#26126;&#24230;&#12290;</title><link>http://arxiv.org/abs/2302.12094</link><description>&lt;p&gt;
&#35780;&#20272;&#20351;&#29992;&#27169;&#22411;&#26080;&#20851;&#30340;&#24230;&#37327;&#26631;&#20934;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#39044;&#27979;&#30340;&#21487;&#35299;&#37322;&#24615;
&lt;/p&gt;
&lt;p&gt;
Evaluating explainability for machine learning predictions using model-agnostic metrics. (arXiv:2302.12094v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.12094
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#27169;&#22411;&#26080;&#20851;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#29992;&#20110;&#35780;&#20272;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#39044;&#27979;&#32467;&#26524;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;&#36825;&#20123;&#24230;&#37327;&#26631;&#20934;&#23558;&#21508;&#20010;&#35299;&#37322;&#33021;&#21147;&#26041;&#38754;&#24635;&#32467;&#25104;&#26631;&#37327;&#65292;&#25552;&#20379;&#20840;&#38754;&#30340;&#29702;&#35299;&#24182;&#20419;&#36827;&#20915;&#31574;&#32773;&#21644;&#21033;&#30410;&#30456;&#20851;&#32773;&#20043;&#38388;&#30340;&#27807;&#36890;&#65292;&#20174;&#32780;&#25552;&#39640;&#25972;&#20307;&#30340;&#36879;&#26126;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#30340;&#24555;&#36895;&#21457;&#23637;&#24102;&#26469;&#20102;&#31649;&#29702;&#21644;&#30417;&#31649;&#26041;&#38754;&#30340;&#20247;&#22810;&#25361;&#25112;&#12290;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#27491;&#22312;&#34987;&#25972;&#21512;&#21040;&#21508;&#20010;&#34892;&#19994;&#21644;&#39046;&#22495;&#65292;&#20915;&#31574;&#32773;&#38656;&#20840;&#38754;&#32454;&#33268;&#22320;&#20102;&#35299;&#36825;&#20123;&#31995;&#32479;&#30340;&#33021;&#21147;&#21644;&#38480;&#21046;&#12290;&#36825;&#20010;&#38656;&#27714;&#30340;&#19968;&#20010;&#20851;&#38190;&#26041;&#38754;&#26159;&#33021;&#22815;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#32467;&#26524;&#65292;&#36825;&#23545;&#20110;&#25552;&#39640;&#36879;&#26126;&#24230;&#21644;&#20449;&#20219;&#24230;&#20197;&#21450;&#24110;&#21161;&#27169;&#22411;&#22312;&#36947;&#24503;&#19978;&#36827;&#34892;&#35757;&#32451;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#26032;&#39062;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#29992;&#20110;&#37327;&#21270;AI&#27169;&#22411;&#39044;&#27979;&#32467;&#26524;&#26159;&#21542;&#21487;&#20197;&#36890;&#36807;&#20854;&#29305;&#24449;&#36827;&#34892;&#26131;&#20110;&#35299;&#37322;&#12290;&#25105;&#20204;&#30340;&#24230;&#37327;&#26631;&#20934;&#23558;&#35299;&#37322;&#33021;&#21147;&#30340;&#19981;&#21516;&#26041;&#38754;&#24635;&#32467;&#20026;&#26631;&#37327;&#65292;&#25552;&#20379;&#23545;&#27169;&#22411;&#39044;&#27979;&#30340;&#26356;&#20840;&#38754;&#30340;&#29702;&#35299;&#65292;&#20419;&#36827;&#20915;&#31574;&#32773;&#21644;&#21033;&#30410;&#30456;&#20851;&#32773;&#20043;&#38388;&#30340;&#27807;&#36890;&#65292;&#20174;&#32780;&#25552;&#39640;&#25972;&#20307;&#30340;&#36879;&#26126;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Rapid advancements in artificial intelligence (AI) technology have brought about a plethora of new challenges in terms of governance and regulation. AI systems are being integrated into various industries and sectors, creating a demand from decision-makers to possess a comprehensive and nuanced understanding of the capabilities and limitations of these systems. One critical aspect of this demand is the ability to explain the results of machine learning models, which is crucial to promoting transparency and trust in AI systems, as well as fundamental in helping machine learning models to be trained ethically. In this paper, we present novel metrics to quantify the degree of which AI model predictions can be easily explainable by its features. Our metrics summarize different aspects of explainability into scalars, providing a more comprehensive understanding of model predictions and facilitating communication between decision-makers and stakeholders, thereby increasing the overall transp
&lt;/p&gt;</description></item></channel></rss>