<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#36890;&#36807;&#23545;&#36890;&#36947;&#36827;&#34892;&#32858;&#31867;&#65292;&#23454;&#29616;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#36890;&#36947;&#31574;&#30053;&#65292;&#26377;&#25928;&#24179;&#34913;&#20102;&#20010;&#20307;&#36890;&#36947;&#22788;&#29702;&#21644;&#36890;&#36947;&#20043;&#38388;&#24517;&#35201;&#20132;&#20114;&#20316;&#29992;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2404.01340</link><description>&lt;p&gt;
&#20174;&#30456;&#20284;&#21040;&#20248;&#36234;&#65306;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#36890;&#36947;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
From Similarity to Superiority: Channel Clustering for Time Series Forecasting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01340
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;&#36890;&#36947;&#36827;&#34892;&#32858;&#31867;&#65292;&#23454;&#29616;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#36890;&#36947;&#31574;&#30053;&#65292;&#26377;&#25928;&#24179;&#34913;&#20102;&#20010;&#20307;&#36890;&#36947;&#22788;&#29702;&#21644;&#36890;&#36947;&#20043;&#38388;&#24517;&#35201;&#20132;&#20114;&#20316;&#29992;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#22312;&#26368;&#36817;&#20960;&#21313;&#24180;&#21560;&#24341;&#20102;&#24456;&#22810;&#20851;&#27880;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#29420;&#31435;&#36890;&#36947;&#31574;&#30053;&#36890;&#36807;&#21333;&#29420;&#22788;&#29702;&#19981;&#21516;&#36890;&#36947;&#26469;&#25552;&#39640;&#39044;&#27979;&#24615;&#33021;&#65292;&#20294;&#22312;&#26410;&#30693;&#23454;&#20363;&#19978;&#23548;&#33268;&#20102;&#24046;&#21170;&#30340;&#27867;&#21270;&#65292;&#24182;&#24573;&#30053;&#20102;&#36890;&#36947;&#20043;&#38388;&#28508;&#22312;&#30340;&#24517;&#35201;&#20132;&#20114;&#20316;&#29992;&#12290;&#30456;&#21453;&#65292;&#20381;&#36182;&#36890;&#36947;&#31574;&#30053;&#23558;&#25152;&#26377;&#36890;&#36947;&#28151;&#21512;&#22312;&#19968;&#36215;&#65292;&#29978;&#33267;&#21253;&#21547;&#26080;&#20851;&#32039;&#35201;&#21644;&#38543;&#24847;&#30340;&#20449;&#24687;&#65292;&#28982;&#32780;&#36825;&#20250;&#23548;&#33268;&#36807;&#24230;&#24179;&#28369;&#30340;&#38382;&#39064;&#24182;&#38480;&#21046;&#20102;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#12290;&#30446;&#21069;&#32570;&#20047;&#19968;&#31181;&#33021;&#22815;&#26377;&#25928;&#24179;&#34913;&#20010;&#20307;&#36890;&#36947;&#22788;&#29702;&#20197;&#25552;&#39640;&#39044;&#27979;&#24615;&#33021;&#32780;&#21448;&#19981;&#24573;&#35270;&#36890;&#36947;&#20043;&#38388;&#24517;&#35201;&#20132;&#20114;&#20316;&#29992;&#30340;&#36890;&#36947;&#31574;&#30053;&#12290;&#21463;&#21040;&#25105;&#20204;&#35266;&#23519;&#21040;&#30340;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#32451;&#20064;&#25552;&#39640;&#23545;&#28151;&#21512;&#36890;&#36947;&#30340;&#32467;&#26524;&#19982;&#19968;&#23545;&#36890;&#36947;&#20043;&#38388;&#26412;&#36136;&#30456;&#20284;&#24615;&#20043;&#38388;&#30340;&#20851;&#32852;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#19988;&#36866;&#24212;&#24615;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01340v1 Announce Type: cross  Abstract: Time series forecasting has attracted significant attention in recent decades. Previous studies have demonstrated that the Channel-Independent (CI) strategy improves forecasting performance by treating different channels individually, while it leads to poor generalization on unseen instances and ignores potentially necessary interactions between channels. Conversely, the Channel-Dependent (CD) strategy mixes all channels with even irrelevant and indiscriminate information, which, however, results in oversmoothing issues and limits forecasting accuracy. There is a lack of channel strategy that effectively balances individual channel treatment for improved forecasting performance without overlooking essential interactions between channels. Motivated by our observation of a correlation between the time series model's performance boost against channel mixing and the intrinsic similarity on a pair of channels, we developed a novel and adapt
&lt;/p&gt;</description></item><item><title>&#20998;&#25955;&#24335;&#32852;&#37030;&#23398;&#20064;&#30340;&#26377;&#25928;&#24615;&#21463;&#21040;&#36830;&#25509;&#35774;&#22791;&#32593;&#32476;&#25299;&#25169;&#32467;&#26500;&#30340;&#26174;&#33879;&#24433;&#21709;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#24213;&#23618;&#32593;&#32476;&#33410;&#28857;&#29305;&#24449;&#21521;&#37327;&#20013;&#24515;&#24615;&#20998;&#24067;&#30340;&#25913;&#36827;&#31070;&#32463;&#32593;&#32476;&#21021;&#22987;&#21270;&#31574;&#30053;&#65292;&#22823;&#22823;&#25552;&#39640;&#20102;&#35757;&#32451;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.15855</link><description>&lt;p&gt;
&#21021;&#22987;&#20540;&#21644;&#25299;&#25169;&#32467;&#26500;&#22312;&#20998;&#25955;&#24335;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Initialisation and Topology Effects in Decentralised Federated Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15855
&lt;/p&gt;
&lt;p&gt;
&#20998;&#25955;&#24335;&#32852;&#37030;&#23398;&#20064;&#30340;&#26377;&#25928;&#24615;&#21463;&#21040;&#36830;&#25509;&#35774;&#22791;&#32593;&#32476;&#25299;&#25169;&#32467;&#26500;&#30340;&#26174;&#33879;&#24433;&#21709;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#24213;&#23618;&#32593;&#32476;&#33410;&#28857;&#29305;&#24449;&#21521;&#37327;&#20013;&#24515;&#24615;&#20998;&#24067;&#30340;&#25913;&#36827;&#31070;&#32463;&#32593;&#32476;&#21021;&#22987;&#21270;&#31574;&#30053;&#65292;&#22823;&#22823;&#25552;&#39640;&#20102;&#35757;&#32451;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20855;&#26377;&#23436;&#20840;&#20998;&#25955;&#24335;&#29305;&#24449;&#30340;&#32852;&#37030;&#23398;&#20064;&#20351;&#24471;&#22312;&#32593;&#32476;&#19978;&#20998;&#24067;&#24335;&#35774;&#22791;&#19978;&#23545;&#20010;&#20307;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#21327;&#20316;&#35757;&#32451;&#65292;&#21516;&#26102;&#20445;&#25345;&#35757;&#32451;&#25968;&#25454;&#26412;&#22320;&#21270;&#12290;&#36825;&#31181;&#26041;&#27861;&#22686;&#24378;&#20102;&#25968;&#25454;&#38544;&#31169;&#24615;&#65292;&#28040;&#38500;&#20102;&#21333;&#28857;&#25925;&#38556;&#21644;&#20013;&#22830;&#21327;&#35843;&#30340;&#24517;&#35201;&#24615;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#24378;&#35843;&#20102;&#20998;&#25955;&#24335;&#32852;&#37030;&#23398;&#20064;&#30340;&#26377;&#25928;&#24615;&#21463;&#21040;&#36830;&#25509;&#35774;&#22791;&#30340;&#32593;&#32476;&#25299;&#25169;&#32467;&#26500;&#30340;&#26174;&#33879;&#24433;&#21709;&#12290;&#19968;&#20010;&#31616;&#21270;&#30340;&#25968;&#20540;&#27169;&#22411;&#29992;&#20110;&#30740;&#31350;&#36825;&#20123;&#31995;&#32479;&#30340;&#26089;&#26399;&#34892;&#20026;&#65292;&#20351;&#25105;&#20204;&#24471;&#20986;&#20102;&#19968;&#20010;&#21033;&#29992;&#24213;&#23618;&#32593;&#32476;&#33410;&#28857;&#30340;&#29305;&#24449;&#21521;&#37327;&#20013;&#24515;&#24615;&#20998;&#24067;&#30340;&#25913;&#36827;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#21021;&#22987;&#20540;&#31574;&#30053;&#65292;&#20174;&#32780;&#22823;&#22823;&#25552;&#39640;&#20102;&#35757;&#32451;&#25928;&#29575;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#25105;&#20204;&#25552;&#20986;&#30340;&#21021;&#22987;&#21270;&#31574;&#30053;&#19979;&#30340;&#27604;&#20363;&#34892;&#20026;&#21644;&#29615;&#22659;&#21442;&#25968;&#30340;&#36873;&#25321;&#12290;&#36825;&#39033;&#24037;&#20316;&#20026;&#26356;&#22810;&#30740;&#31350;&#25171;&#24320;&#20102;&#36947;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15855v1 Announce Type: cross  Abstract: Fully decentralised federated learning enables collaborative training of individual machine learning models on distributed devices on a network while keeping the training data localised. This approach enhances data privacy and eliminates both the single point of failure and the necessity for central coordination. Our research highlights that the effectiveness of decentralised federated learning is significantly influenced by the network topology of connected devices. A simplified numerical model for studying the early behaviour of these systems leads us to an improved artificial neural network initialisation strategy, which leverages the distribution of eigenvector centralities of the nodes of the underlying network, leading to a radically improved training efficiency. Additionally, our study explores the scaling behaviour and choice of environmental parameters under our proposed initialisation strategy. This work paves the way for mor
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31867;&#21035;&#30340;&#31574;&#30053;&#38236;&#20687;&#19979;&#38477;&#31639;&#27861;$h$-PMD&#65292;&#23427;&#36890;&#36807;&#22312;PMD&#26356;&#26032;&#35268;&#21017;&#20013;&#32467;&#21512;&#22810;&#27493;&#36138;&#24515;&#31574;&#30053;&#25913;&#36827;&#21644;&#21069;&#30651;&#28145;&#24230;$h&#65292;&#20197;&#35299;&#20915;&#25240;&#25187;&#26080;&#38480;&#26102;&#38388;&#35270;&#35282;&#19979;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#12290;</title><link>https://arxiv.org/abs/2403.14156</link><description>&lt;p&gt;
&#20855;&#26377;&#21069;&#30651;&#29305;&#24615;&#30340;&#31574;&#30053;&#38236;&#20687;&#19979;&#38477;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Policy Mirror Descent with Lookahead
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14156
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31867;&#21035;&#30340;&#31574;&#30053;&#38236;&#20687;&#19979;&#38477;&#31639;&#27861;$h$-PMD&#65292;&#23427;&#36890;&#36807;&#22312;PMD&#26356;&#26032;&#35268;&#21017;&#20013;&#32467;&#21512;&#22810;&#27493;&#36138;&#24515;&#31574;&#30053;&#25913;&#36827;&#21644;&#21069;&#30651;&#28145;&#24230;$h&#65292;&#20197;&#35299;&#20915;&#25240;&#25187;&#26080;&#38480;&#26102;&#38388;&#35270;&#35282;&#19979;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31574;&#30053;&#38236;&#20687;&#19979;&#38477;&#65288;PMD&#65289;&#20316;&#20026;&#19968;&#31181;&#22810;&#21151;&#33021;&#31639;&#27861;&#26694;&#26550;&#65292;&#21253;&#25324;&#20960;&#31181;&#37325;&#35201;&#30340;&#31574;&#30053;&#26799;&#24230;&#31639;&#27861;&#65292;&#22914;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#65292;&#24182;&#19982;&#26368;&#20808;&#36827;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#31639;&#27861;&#65288;&#22914;TRPO&#21644;PPO&#65289;&#30456;&#32852;&#31995;&#12290;PMD&#21487;&#20197;&#30475;&#20316;&#26159;&#23454;&#29616;&#27491;&#21017;&#21270;1&#27493;&#36138;&#24515;&#31574;&#30053;&#25913;&#36827;&#30340;&#36719;&#31574;&#30053;&#36845;&#20195;&#31639;&#27861;&#12290;&#28982;&#32780;&#65292;1&#27493;&#36138;&#24515;&#31574;&#30053;&#21487;&#33021;&#19981;&#26159;&#26368;&#20339;&#36873;&#25321;&#65292;&#26368;&#36817;&#22312;RL&#39046;&#22495;&#21462;&#24471;&#20102;&#26174;&#30528;&#30340;&#23454;&#35777;&#25104;&#21151;&#65292;&#22914;AlphaGo&#21644;AlphaZero&#24050;&#32463;&#35777;&#26126;&#65292;&#30456;&#23545;&#20110;&#22810;&#27493;&#39588;&#65292;&#36138;&#24515;&#26041;&#27861;&#21487;&#20197;&#36229;&#36234;&#23427;&#20204;&#30340;1&#27493;&#39588;&#23545;&#24212;&#29289;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31867;&#21035;&#30340;PMD&#31639;&#27861;&#65292;&#31216;&#20026;$h$-PMD&#65292;&#23427;&#23558;&#20855;&#26377;&#21069;&#30651;&#28145;&#24230;$h$&#30340;&#22810;&#27493;&#36138;&#24515;&#31574;&#30053;&#25913;&#36827;&#32467;&#21512;&#21040;PMD&#26356;&#26032;&#35268;&#21017;&#20013;&#12290;&#20026;&#20102;&#35299;&#20915;&#25240;&#25187;&#26080;&#38480;&#26102;&#38388;&#35270;&#35282;&#19979;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65292;&#20854;&#20013;&#25240;&#25187;&#22240;&#23376;&#20026;$\gamma$&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;$h$-PMD&#21487;&#20197;&#25512;&#24191;&#26631;&#20934;&#30340;PMD&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14156v1 Announce Type: cross  Abstract: Policy Mirror Descent (PMD) stands as a versatile algorithmic framework encompassing several seminal policy gradient algorithms such as natural policy gradient, with connections with state-of-the-art reinforcement learning (RL) algorithms such as TRPO and PPO. PMD can be seen as a soft Policy Iteration algorithm implementing regularized 1-step greedy policy improvement. However, 1-step greedy policies might not be the best choice and recent remarkable empirical successes in RL such as AlphaGo and AlphaZero have demonstrated that greedy approaches with respect to multiple steps outperform their 1-step counterpart. In this work, we propose a new class of PMD algorithms called $h$-PMD which incorporates multi-step greedy policy improvement with lookahead depth $h$ to the PMD update rule. To solve discounted infinite horizon Markov Decision Processes with discount factor $\gamma$, we show that $h$-PMD which generalizes the standard PMD enj
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#20197;&#32467;&#21512;&#28145;&#24230;&#23398;&#20064;&#38598;&#25104;&#36827;&#34892;&#21021;&#22987;&#21442;&#25968;&#20272;&#35745;&#65292;&#20419;&#36827;&#20102;&#26377;&#25928;&#30340;&#19979;&#28216;&#28436;&#21270;&#25277;&#26679;&#65292;&#26377;&#25928;&#22320;&#20272;&#35745;&#20102;&#20174;&#30913;&#20849;&#25391;&#22270;&#20687;&#20013;&#33041;&#32959;&#30244;&#32454;&#32990;&#27987;&#24230;&#65292;DL-Prior&#22312;&#20854;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;</title><link>https://arxiv.org/abs/2403.04500</link><description>&lt;p&gt;
&#19968;&#31181;&#21487;&#23398;&#20064;&#30340;&#20808;&#39564;&#25913;&#36827;&#20102;&#36870;&#32959;&#30244;&#29983;&#38271;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
A Learnable Prior Improves Inverse Tumor Growth Modeling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04500
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#20197;&#32467;&#21512;&#28145;&#24230;&#23398;&#20064;&#38598;&#25104;&#36827;&#34892;&#21021;&#22987;&#21442;&#25968;&#20272;&#35745;&#65292;&#20419;&#36827;&#20102;&#26377;&#25928;&#30340;&#19979;&#28216;&#28436;&#21270;&#25277;&#26679;&#65292;&#26377;&#25928;&#22320;&#20272;&#35745;&#20102;&#20174;&#30913;&#20849;&#25391;&#22270;&#20687;&#20013;&#33041;&#32959;&#30244;&#32454;&#32990;&#27987;&#24230;&#65292;DL-Prior&#22312;&#20854;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#29289;&#29289;&#29702;&#24314;&#27169;&#65292;&#29305;&#21035;&#26159;&#28041;&#21450;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDEs&#65289;&#30340;&#24314;&#27169;&#65292;&#20026;&#20010;&#20307;&#21270;&#30142;&#30149;&#27835;&#30103;&#26041;&#26696;&#25552;&#20379;&#20102;&#24040;&#22823;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#30340;&#36870;&#38382;&#39064;&#27714;&#35299;&#26041;&#38754;&#25552;&#20986;&#20102;&#24040;&#22823;&#25361;&#25112;&#65292;&#35201;&#20040;&#26159;&#30001;&#20110;&#22522;&#20110;&#27169;&#22411;&#30340;&#26041;&#27861;&#30340;&#39640;&#35745;&#31639;&#35201;&#27714;&#65292;&#35201;&#20040;&#26159;&#28145;&#24230;&#23398;&#20064;&#65288;DL&#65289;&#26041;&#27861;&#30340;&#26377;&#38480;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#20197;&#19968;&#31181;&#21327;&#21516;&#30340;&#26041;&#24335;&#21033;&#29992;&#20004;&#31181;&#26041;&#27861;&#30340;&#29420;&#29305;&#20248;&#21183;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#32467;&#21512;&#20102;DL&#38598;&#25104;&#36827;&#34892;&#21021;&#22987;&#21442;&#25968;&#20272;&#35745;&#65292;&#20174;&#32780;&#20419;&#36827;&#20102;&#21021;&#22987;&#21270;&#20026;&#22522;&#20110;DL&#30340;&#20808;&#39564;&#30340;&#26377;&#25928;&#19979;&#28216;&#36827;&#21270;&#25277;&#26679;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#23558;&#24555;&#36895;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#19982;&#39640;&#31934;&#24230;&#28436;&#21270;&#31574;&#30053;&#32467;&#21512;&#36215;&#26469;&#22312;&#20174;&#30913;&#20849;&#25391;&#22270;&#20687;&#20013;&#20272;&#35745;&#33041;&#32959;&#30244;&#32454;&#32990;&#27987;&#24230;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;DL-Prior&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#65292;&#26174;&#33879;&#32422;&#26463;&#20102;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04500v1 Announce Type: cross  Abstract: Biophysical modeling, particularly involving partial differential equations (PDEs), offers significant potential for tailoring disease treatment protocols to individual patients. However, the inverse problem-solving aspect of these models presents a substantial challenge, either due to the high computational requirements of model-based approaches or the limited robustness of deep learning (DL) methods. We propose a novel framework that leverages the unique strengths of both approaches in a synergistic manner. Our method incorporates a DL ensemble for initial parameter estimation, facilitating efficient downstream evolutionary sampling initialized with this DL-based prior. We showcase the effectiveness of integrating a rapid deep-learning algorithm with a high-precision evolution strategy in estimating brain tumor cell concentrations from magnetic resonance images. The DL-Prior plays a pivotal role, significantly constraining the effect
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26641;&#24179;&#22343;&#27861;&#26500;&#24314;&#38598;&#25104;&#35299;&#26512;&#22120;&#65292;&#31283;&#23450;&#24182;&#25552;&#21319;&#26080;&#30417;&#30563;&#19981;&#36830;&#32493;&#25104;&#20998;&#21477;&#27861;&#20998;&#26512;&#24615;&#33021;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#25152;&#26377;&#25351;&#26631;&#19978;&#22343;&#20248;&#20110;&#22522;&#20934;&#32447;</title><link>https://arxiv.org/abs/2403.00143</link><description>&lt;p&gt;
&#22522;&#20110;&#38598;&#25104;&#30340;&#26080;&#30417;&#30563;&#19981;&#36830;&#32493;&#25104;&#20998;&#21477;&#27861;&#20998;&#26512;&#65306;&#26641;&#24179;&#22343;&#27861;
&lt;/p&gt;
&lt;p&gt;
Ensemble-Based Unsupervised Discontinuous Constituency Parsing by Tree Averaging
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00143
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26641;&#24179;&#22343;&#27861;&#26500;&#24314;&#38598;&#25104;&#35299;&#26512;&#22120;&#65292;&#31283;&#23450;&#24182;&#25552;&#21319;&#26080;&#30417;&#30563;&#19981;&#36830;&#32493;&#25104;&#20998;&#21477;&#27861;&#20998;&#26512;&#24615;&#33021;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#25152;&#26377;&#25351;&#26631;&#19978;&#22343;&#20248;&#20110;&#22522;&#20934;&#32447;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35299;&#20915;&#20102;&#26080;&#30417;&#30563;&#19981;&#36830;&#32493;&#25104;&#20998;&#21477;&#27861;&#20998;&#26512;&#30340;&#38382;&#39064;&#65292;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#25105;&#20204;&#35266;&#23519;&#21040;&#20808;&#21069;&#21807;&#19968;&#27169;&#22411;&#30340;&#24615;&#33021;&#23384;&#22312;&#39640;&#26041;&#24046;&#12290;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#23545;&#29616;&#26377;&#19981;&#36830;&#32493;&#35299;&#26512;&#22120;&#30340;&#19981;&#21516;&#36816;&#34892;&#26500;&#24314;&#19968;&#20010;&#38598;&#25104;&#65292;&#24182;&#36890;&#36807;&#24179;&#22343;&#39044;&#27979;&#26641;&#26469;&#31283;&#23450;&#21644;&#25552;&#21319;&#24615;&#33021;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#38024;&#23545;&#19981;&#21516;&#30340;&#20108;&#20803;&#24615;&#21644;&#36830;&#32493;&#24615;&#35774;&#32622;&#25552;&#20379;&#20102;&#20840;&#38754;&#30340;&#26641;&#24179;&#22343;&#35745;&#31639;&#22797;&#26434;&#24230;&#20998;&#26512;&#65288;&#20197;P&#21644;NP&#23436;&#20840;&#20026;&#21333;&#20301;&#65289;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#31934;&#30830;&#31639;&#27861;&#26469;&#22788;&#29702;&#36825;&#19968;&#20219;&#21153;&#65292;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#23545;&#25152;&#26377;&#26679;&#26412;&#36816;&#34892;&#26102;&#38388;&#22343;&#21512;&#29702;&#12290;&#22312;&#19977;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#32467;&#26524;&#26174;&#31034;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#25152;&#26377;&#25351;&#26631;&#19978;&#22343;&#20248;&#20110;&#25152;&#26377;&#22522;&#20934;&#32447;&#65292;&#25105;&#20204;&#36824;&#23545;&#25105;&#20204;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#28145;&#20837;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00143v1 Announce Type: cross  Abstract: We address unsupervised discontinuous constituency parsing, where we observe a high variance in the performance of the only previous model. We propose to build an ensemble of different runs of the existing discontinuous parser by averaging the predicted trees, to stabilize and boost performance. To begin with, we provide comprehensive computational complexity analysis (in terms of P and NP-complete) for tree averaging under different setups of binarity and continuity. We then develop an efficient exact algorithm to tackle the task, which runs in a reasonable time for all samples in our experiments. Results on three datasets show our method outperforms all baselines in all metrics; we also provide in-depth analyses of our approach.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#38463;&#22982;&#21704;&#25289;&#35821;&#24120;&#35265;&#38382;&#39064;&#35299;&#31572;&#32842;&#22825;&#26426;&#22120;&#20154;&#27169;&#22411;&#65292;&#21487;&#20197;&#24110;&#21161;&#22823;&#23398;&#29983;&#35299;&#31572;&#24120;&#35265;&#38382;&#39064;&#65292;&#36890;&#36807;&#20351;&#29992;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#65292;&#37319;&#29992;&#22810;&#31181;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#31639;&#27861;&#36827;&#34892;&#20998;&#26512;&#21644;&#20998;&#31867;&#65292;&#21462;&#24471;&#20102;&#26368;&#22909;&#30340;&#25104;&#32489;&#12290;</title><link>https://arxiv.org/abs/2402.01720</link><description>&lt;p&gt;
&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#38463;&#22982;&#21704;&#25289;&#35821;&#24120;&#35265;&#38382;&#39064;&#35299;&#31572;&#32842;&#22825;&#26426;&#22120;&#20154;
&lt;/p&gt;
&lt;p&gt;
Deep Learning Based Amharic Chatbot for FAQs in Universities
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01720
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#38463;&#22982;&#21704;&#25289;&#35821;&#24120;&#35265;&#38382;&#39064;&#35299;&#31572;&#32842;&#22825;&#26426;&#22120;&#20154;&#27169;&#22411;&#65292;&#21487;&#20197;&#24110;&#21161;&#22823;&#23398;&#29983;&#35299;&#31572;&#24120;&#35265;&#38382;&#39064;&#65292;&#36890;&#36807;&#20351;&#29992;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#65292;&#37319;&#29992;&#22810;&#31181;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#31639;&#27861;&#36827;&#34892;&#20998;&#26512;&#21644;&#20998;&#31867;&#65292;&#21462;&#24471;&#20102;&#26368;&#22909;&#30340;&#25104;&#32489;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#23398;&#29983;&#24120;&#24120;&#33457;&#36153;&#22823;&#37327;&#26102;&#38388;&#21521;&#31649;&#29702;&#21592;&#25110;&#25945;&#24072;&#23547;&#27714;&#24120;&#35265;&#38382;&#39064;&#30340;&#31572;&#26696;&#12290;&#36825;&#23545;&#21452;&#26041;&#26469;&#35828;&#37117;&#24456;&#32321;&#29712;&#65292;&#38656;&#35201;&#25214;&#21040;&#19968;&#20010;&#35299;&#20915;&#26041;&#26696;&#12290;&#20026;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32842;&#22825;&#26426;&#22120;&#20154;&#27169;&#22411;&#65292;&#21033;&#29992;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#65292;&#22312;&#38463;&#22982;&#21704;&#25289;&#35821;&#20013;&#22238;&#31572;&#24120;&#35265;&#38382;&#39064;&#12290;&#32842;&#22825;&#26426;&#22120;&#20154;&#26159;&#36890;&#36807;&#20154;&#24037;&#26234;&#33021;&#27169;&#25311;&#20154;&#31867;&#23545;&#35805;&#30340;&#35745;&#31639;&#26426;&#31243;&#24207;&#65292;&#20316;&#20026;&#34394;&#25311;&#21161;&#25163;&#22788;&#29702;&#38382;&#39064;&#21644;&#20854;&#20182;&#20219;&#21153;&#12290;&#25152;&#25552;&#20986;&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;&#31243;&#24207;&#20351;&#29992;&#26631;&#35760;&#21270;&#12289;&#35268;&#33539;&#21270;&#12289;&#21435;&#38500;&#20572;&#29992;&#35789;&#21644;&#35789;&#24178;&#25552;&#21462;&#23545;&#38463;&#22982;&#21704;&#25289;&#35821;&#36755;&#20837;&#21477;&#23376;&#36827;&#34892;&#20998;&#26512;&#21644;&#20998;&#31867;&#12290;&#37319;&#29992;&#20102;&#19977;&#31181;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#31639;&#27861;&#26469;&#20998;&#31867;&#26631;&#35760;&#21644;&#26816;&#32034;&#21512;&#36866;&#30340;&#22238;&#31572;&#65306;&#25903;&#25345;&#21521;&#37327;&#26426;&#65288;SVM&#65289;&#12289;&#22810;&#39033;&#24335;&#26420;&#32032;&#36125;&#21494;&#26031;&#21644;&#36890;&#36807;TensorFlow&#12289;Keras&#21644;NLTK&#23454;&#29616;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#12290;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#21462;&#24471;&#20102;&#26368;&#22909;&#30340;&#25104;&#32489;&#12290;
&lt;/p&gt;
&lt;p&gt;
University students often spend a considerable amount of time seeking answers to common questions from administrators or teachers. This can become tedious for both parties, leading to a need for a solution. In response, this paper proposes a chatbot model that utilizes natural language processing and deep learning techniques to answer frequently asked questions (FAQs) in the Amharic language. Chatbots are computer programs that simulate human conversation through the use of artificial intelligence (AI), acting as a virtual assistant to handle questions and other tasks. The proposed chatbot program employs tokenization, normalization, stop word removal, and stemming to analyze and categorize Amharic input sentences. Three machine learning model algorithms were used to classify tokens and retrieve appropriate responses: Support Vector Machine (SVM), Multinomial Na\"ive Bayes, and deep neural networks implemented through TensorFlow, Keras, and NLTK. The deep learning model achieved the be
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20219;&#21153;&#21453;&#39304;&#30340;&#21160;&#24577;&#21098;&#35009;&#26041;&#27861;&#65292;&#36890;&#36807;&#22686;&#21152;&#26368;&#22823;&#32047;&#31215;&#22238;&#25253;&#26469;&#20248;&#21270;&#36817;&#31471;&#31574;&#30053;&#20248;&#21270;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2312.07624</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#20219;&#21153;&#21453;&#39304;&#30340;&#21160;&#24577;&#21098;&#35009;&#26041;&#27861;&#29992;&#20110;&#36817;&#31471;&#31574;&#30053;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
A dynamical clipping approach with task feedback for Proximal Policy Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.07624
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20219;&#21153;&#21453;&#39304;&#30340;&#21160;&#24577;&#21098;&#35009;&#26041;&#27861;&#65292;&#36890;&#36807;&#22686;&#21152;&#26368;&#22823;&#32047;&#31215;&#22238;&#25253;&#26469;&#20248;&#21270;&#36817;&#31471;&#31574;&#30053;&#20248;&#21270;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#31471;&#31574;&#30053;&#20248;&#21270;&#65288;PPO&#65289;&#24050;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#21508;&#20010;&#39046;&#22495;&#65292;&#21253;&#25324;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20248;&#21270;&#21644;&#26426;&#22120;&#20154;&#23398;&#20064;&#31561;&#12290;&#28982;&#32780;&#65292;PPO&#21463;&#21040;&#22266;&#23450;&#21098;&#35009;&#36793;&#30028;&#30340;&#38480;&#21046;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#30446;&#21069;&#27809;&#26377;&#29702;&#35770;&#35777;&#26126;&#26368;&#20339;&#21098;&#35009;&#36793;&#30028;&#22312;&#25972;&#20010;&#35757;&#32451;&#36807;&#31243;&#20013;&#22987;&#32456;&#20445;&#25345;&#19968;&#33268;&#12290;&#36890;&#36807;&#29992;&#19968;&#20010;&#29420;&#29305;&#30340;&#21098;&#35009;&#36793;&#30028;&#25130;&#26029;&#26032;&#26087;&#31574;&#30053;&#30340;&#27604;&#29575;&#65292;&#21487;&#20197;&#30830;&#20445;&#31283;&#23450;&#30340;&#35757;&#32451;&#24182;&#23454;&#29616;&#26368;&#20339;&#30340;&#35757;&#32451;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22266;&#23450;&#30340;&#21098;&#35009;&#36793;&#30028;&#38480;&#21046;&#20102;agent&#30340;&#25506;&#32034;&#12290;&#22240;&#27492;&#65292;&#30740;&#31350;&#19968;&#31181;&#21160;&#24577;&#21098;&#35009;&#36793;&#30028;&#20197;&#22686;&#24378;PPO&#30340;&#24615;&#33021;&#26159;&#38750;&#24120;&#26377;&#30410;&#30340;&#12290;&#19982;&#20197;&#24448;&#30340;&#21098;&#35009;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#32771;&#34385;&#23558;&#22312;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#20219;&#21153;&#20013;&#22686;&#21152;&#26368;&#22823;&#32047;&#31215;&#22238;&#25253;&#35270;&#20316;RL&#20219;&#21153;&#30340;&#20559;&#22909;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#21452;&#23618;&#36817;&#31471;&#31574;&#30053;&#20248;&#21270;&#33539;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.07624v2 Announce Type: replace-cross  Abstract: Proximal Policy Optimization (PPO) has been broadly applied to various domains, including Large Language Model (LLM) optimization and Robotics learning, etc. However, PPO is limited by a fixed setting for the clipping bound. Specifically, there is no theoretical proof that the optimal clipping bound remains consistent throughout the entire training process. Truncating the ratio of the new and old policies with a unique clipping bound ensures stable training and can achieve the best training performance. Additionally, previous research suggests that a fixed clipping bound limits the agent's exploration. Therefore, researching a dynamical clipping bound to enhance PPO's performance can be highly beneficial. Different from previous clipping approaches, we consider increasing the maximum cumulative Return in reinforcement learning (RL) tasks as the preference of the RL task, and propose a bi-level proximal policy optimization parad
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#40654;&#26364;&#20960;&#20309;&#29305;&#24449;&#24212;&#29992;&#20110;&#23398;&#20064;&#32764;&#38754;&#21387;&#21147;&#31995;&#25968;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#20197;&#25552;&#39640;&#27668;&#21160;&#31995;&#25968;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.09452</link><description>&lt;p&gt;
&#20351;&#29992;&#40654;&#26364;&#20960;&#20309;&#29305;&#24449;&#23398;&#20064;&#39134;&#26426;&#26426;&#32764;&#19978;&#30340;&#21387;&#21147;&#31995;&#25968;
&lt;/p&gt;
&lt;p&gt;
Incorporating Riemannian Geometric Features for Learning Coefficient of Pressure Distributions on Airplane Wings. (arXiv:2401.09452v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09452
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#40654;&#26364;&#20960;&#20309;&#29305;&#24449;&#24212;&#29992;&#20110;&#23398;&#20064;&#32764;&#38754;&#21387;&#21147;&#31995;&#25968;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#20197;&#25552;&#39640;&#27668;&#21160;&#31995;&#25968;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39134;&#26426;&#30340;&#27668;&#21160;&#31995;&#25968;&#21463;&#20854;&#20960;&#20309;&#24418;&#29366;&#30340;&#26174;&#33879;&#24433;&#21709;&#65292;&#23588;&#20854;&#26159;&#24403;&#25915;&#35282;&#36739;&#22823;&#26102;&#12290;&#22312;&#31354;&#27668;&#21160;&#21147;&#23398;&#39046;&#22495;&#65292;&#20256;&#32479;&#30340;&#22522;&#20110;&#22810;&#39033;&#24335;&#30340;&#21442;&#25968;&#21270;&#26041;&#27861;&#20351;&#29992;&#23613;&#21487;&#33021;&#23569;&#30340;&#21442;&#25968;&#26469;&#25551;&#36848;&#32764;&#22411;&#30340;&#20960;&#20309;&#24418;&#29366;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#32764;&#30340;&#19977;&#32500;&#20960;&#20309;&#24418;&#29366;&#27604;&#20108;&#32500;&#32764;&#22411;&#22797;&#26434;&#65292;&#22522;&#20110;&#22810;&#39033;&#24335;&#30340;&#21442;&#25968;&#21270;&#26041;&#27861;&#38590;&#20197;&#20934;&#30830;&#34920;&#31034;&#32764;&#22312;&#19977;&#32500;&#31354;&#38388;&#20013;&#30340;&#25972;&#20307;&#24418;&#29366;&#12290;&#29616;&#26377;&#30340;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#21487;&#20197;&#25552;&#21462;&#29992;&#20110;&#25551;&#36848;&#20108;&#32500;&#32764;&#22411;&#25110;&#32764;&#25130;&#38754;&#24418;&#29366;&#30340;&#22823;&#37327;&#28508;&#22312;&#31070;&#32463;&#34920;&#31034;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#30452;&#25509;&#23558;&#20960;&#20309;&#29305;&#24449;&#20316;&#20026;&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20837;&#21487;&#20197;&#25552;&#39640;&#39044;&#27979;&#30340;&#27668;&#21160;&#31995;&#25968;&#30340;&#20934;&#30830;&#24615;&#12290;&#21463;&#20960;&#20309;&#29702;&#35770;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23558;&#40654;&#26364;&#20960;&#20309;&#29305;&#24449;&#32435;&#20837;&#23398;&#20064;&#32764;&#38754;&#21387;&#21147;&#31995;&#25968;&#20998;&#24067;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#35745;&#31639;&#20960;&#20309;&#29305;&#24449;&#65288;&#40654;&#26364;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
The aerodynamic coefficients of aircrafts are significantly impacted by its geometry, especially when the angle of attack (AoA) is large. In the field of aerodynamics, traditional polynomial-based parameterization uses as few parameters as possible to describe the geometry of an airfoil. However, because the 3D geometry of a wing is more complicated than the 2D airfoil, polynomial-based parameterizations have difficulty in accurately representing the entire shape of a wing in 3D space. Existing deep learning-based methods can extract massive latent neural representations for the shape of 2D airfoils or 2D slices of wings. Recent studies highlight that directly taking geometric features as inputs to the neural networks can improve the accuracy of predicted aerodynamic coefficients. Motivated by geometry theory, we propose to incorporate Riemannian geometric features for learning Coefficient of Pressure (CP) distributions on wing surfaces. Our method calculates geometric features (Rieman
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;Prompt2Forget&#65288;P2F&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#25945;&#23548;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#24536;&#35760;&#38544;&#31169;&#20449;&#24687;&#65292;&#35299;&#20915;&#20102;LLM&#26412;&#22320;&#38544;&#31169;&#25361;&#25112;&#12290;P2F&#26041;&#27861;&#23558;&#38382;&#39064;&#20998;&#35299;&#20026;&#29255;&#27573;&#24182;&#29983;&#25104;&#34394;&#26500;&#31572;&#26696;&#65292;&#27169;&#31946;&#21270;&#27169;&#22411;&#23545;&#21407;&#22987;&#36755;&#20837;&#30340;&#35760;&#24518;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;P2F&#20855;&#26377;&#24456;&#24378;&#30340;&#27169;&#31946;&#21270;&#33021;&#21147;&#65292;&#24182;&#19988;&#21487;&#20197;&#22312;&#21508;&#31181;&#24212;&#29992;&#22330;&#26223;&#19979;&#33258;&#36866;&#24212;&#20351;&#29992;&#65292;&#26080;&#38656;&#25163;&#21160;&#35774;&#32622;&#12290;</title><link>http://arxiv.org/abs/2401.00870</link><description>&lt;p&gt;
&#25945;&#23548;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24536;&#35760;&#38544;&#31169;
&lt;/p&gt;
&lt;p&gt;
Teach Large Language Models to Forget Privacy. (arXiv:2401.00870v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.00870
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;Prompt2Forget&#65288;P2F&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#25945;&#23548;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#24536;&#35760;&#38544;&#31169;&#20449;&#24687;&#65292;&#35299;&#20915;&#20102;LLM&#26412;&#22320;&#38544;&#31169;&#25361;&#25112;&#12290;P2F&#26041;&#27861;&#23558;&#38382;&#39064;&#20998;&#35299;&#20026;&#29255;&#27573;&#24182;&#29983;&#25104;&#34394;&#26500;&#31572;&#26696;&#65292;&#27169;&#31946;&#21270;&#27169;&#22411;&#23545;&#21407;&#22987;&#36755;&#20837;&#30340;&#35760;&#24518;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;P2F&#20855;&#26377;&#24456;&#24378;&#30340;&#27169;&#31946;&#21270;&#33021;&#21147;&#65292;&#24182;&#19988;&#21487;&#20197;&#22312;&#21508;&#31181;&#24212;&#29992;&#22330;&#26223;&#19979;&#33258;&#36866;&#24212;&#20351;&#29992;&#65292;&#26080;&#38656;&#25163;&#21160;&#35774;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#24050;&#34987;&#35777;&#26126;&#20855;&#26377;&#24378;&#22823;&#30340;&#33021;&#21147;&#65292;&#20294;&#38544;&#31169;&#27844;&#38706;&#30340;&#39118;&#38505;&#20173;&#28982;&#26159;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#12290;&#20256;&#32479;&#30340;&#20445;&#25252;&#38544;&#31169;&#26041;&#27861;&#65292;&#22914;&#24046;&#20998;&#38544;&#31169;&#21644;&#21516;&#24577;&#21152;&#23494;&#65292;&#22312;&#21482;&#26377;&#40657;&#30418;API&#30340;&#29615;&#22659;&#19979;&#26159;&#19981;&#36275;&#22815;&#30340;&#65292;&#35201;&#27714;&#27169;&#22411;&#36879;&#26126;&#24615;&#25110;&#22823;&#37327;&#35745;&#31639;&#36164;&#28304;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;Prompt2Forget&#65288;P2F&#65289;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#35774;&#35745;&#29992;&#20110;&#35299;&#20915;LLM&#26412;&#22320;&#38544;&#31169;&#25361;&#25112;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#25945;&#23548;LLM&#24536;&#35760;&#26469;&#23454;&#29616;&#12290;&#35813;&#26041;&#27861;&#28041;&#21450;&#23558;&#23436;&#25972;&#38382;&#39064;&#20998;&#35299;&#20026;&#36739;&#23567;&#30340;&#29255;&#27573;&#65292;&#29983;&#25104;&#34394;&#26500;&#30340;&#31572;&#26696;&#65292;&#24182;&#20351;&#27169;&#22411;&#23545;&#21407;&#22987;&#36755;&#20837;&#30340;&#35760;&#24518;&#27169;&#31946;&#21270;&#12290;&#25105;&#20204;&#26681;&#25454;&#19981;&#21516;&#39046;&#22495;&#30340;&#21253;&#21547;&#38544;&#31169;&#25935;&#24863;&#20449;&#24687;&#30340;&#38382;&#39064;&#21019;&#24314;&#20102;&#22522;&#20934;&#25968;&#25454;&#38598;&#12290;P2F&#23454;&#29616;&#20102;&#38646;-shot&#27867;&#21270;&#65292;&#21487;&#20197;&#22312;&#22810;&#31181;&#24212;&#29992;&#22330;&#26223;&#19979;&#33258;&#36866;&#24212;&#65292;&#26080;&#38656;&#25163;&#21160;&#35843;&#25972;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;P2F&#20855;&#26377;&#24456;&#24378;&#30340;&#27169;&#31946;&#21270;LLM&#35760;&#24518;&#30340;&#33021;&#21147;&#65292;&#32780;&#19981;&#20250;&#25439;&#22833;&#20219;&#20309;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have proven powerful, but the risk of privacy leakage remains a significant concern. Traditional privacy-preserving methods, such as Differential Privacy and Homomorphic Encryption, are inadequate for black-box API-only settings, demanding either model transparency or heavy computational resources. We propose Prompt2Forget (P2F), the first framework designed to tackle the LLM local privacy challenge by teaching LLM to forget. The method involves decomposing full questions into smaller segments, generating fabricated answers, and obfuscating the model's memory of the original input. A benchmark dataset was crafted with questions containing privacy-sensitive information from diverse fields. P2F achieves zero-shot generalization, allowing adaptability across a wide range of use cases without manual adjustments. Experimental results indicate P2F's robust capability to obfuscate LLM's memory, attaining a forgetfulness score of around 90\% without any utility los
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#35270;&#35273;&#38382;&#31572;&#20013;&#31995;&#32479;&#19968;&#33324;&#21270;&#30340;&#20851;&#38190;&#22240;&#32032;&#65292;&#21457;&#29616;&#31616;&#21333;&#20219;&#21153;&#30340;&#22810;&#26679;&#24615;&#22312;&#23454;&#29616;&#31995;&#32479;&#19968;&#33324;&#21270;&#20013;&#36215;&#21040;&#20102;&#37325;&#35201;&#30340;&#20316;&#29992;&#65292;&#36825;&#24847;&#21619;&#30528;&#19981;&#24517;&#25910;&#38598;&#22823;&#37327;&#21644;&#22810;&#26679;&#30340;&#22797;&#26434;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2309.08798</link><description>&lt;p&gt;
D3: &#25968;&#25454;&#22810;&#26679;&#24615;&#35774;&#35745;&#20026;&#31995;&#32479;&#19968;&#33324;&#21270;&#22312;&#35270;&#35273;&#38382;&#31572;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
D3: Data Diversity Design for Systematic Generalization in Visual Question Answering. (arXiv:2309.08798v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08798
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#35270;&#35273;&#38382;&#31572;&#20013;&#31995;&#32479;&#19968;&#33324;&#21270;&#30340;&#20851;&#38190;&#22240;&#32032;&#65292;&#21457;&#29616;&#31616;&#21333;&#20219;&#21153;&#30340;&#22810;&#26679;&#24615;&#22312;&#23454;&#29616;&#31995;&#32479;&#19968;&#33324;&#21270;&#20013;&#36215;&#21040;&#20102;&#37325;&#35201;&#30340;&#20316;&#29992;&#65292;&#36825;&#24847;&#21619;&#30528;&#19981;&#24517;&#25910;&#38598;&#22823;&#37327;&#21644;&#22810;&#26679;&#30340;&#22797;&#26434;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31995;&#32479;&#19968;&#33324;&#21270;&#26159;&#26234;&#33021;&#30340;&#20851;&#38190;&#26041;&#38754;&#65292;&#23427;&#25351;&#30340;&#26159;&#36890;&#36807;&#32467;&#21512;&#24050;&#30693;&#30340;&#23376;&#20219;&#21153;&#21644;&#27010;&#24565;&#26469;&#25512;&#24191;&#21040;&#26032;&#20219;&#21153;&#30340;&#33021;&#21147;&#12290;&#24050;&#32463;&#26174;&#31034;&#24433;&#21709;&#31995;&#32479;&#19968;&#33324;&#21270;&#30340;&#19968;&#20010;&#20851;&#38190;&#22240;&#32032;&#26159;&#35757;&#32451;&#25968;&#25454;&#30340;&#22810;&#26679;&#24615;&#12290;&#28982;&#32780;&#65292;&#22810;&#26679;&#24615;&#21487;&#20197;&#20197;&#22810;&#31181;&#26041;&#24335;&#23450;&#20041;&#65292;&#22240;&#20026;&#25968;&#25454;&#20855;&#26377;&#35768;&#22810;&#21464;&#21270;&#22240;&#32032;&#12290;&#23545;&#20110;&#19981;&#21516;&#26041;&#38754;&#30340;&#25968;&#25454;&#22810;&#26679;&#24615;&#22914;&#20309;&#24433;&#21709;&#31995;&#32479;&#19968;&#33324;&#21270;&#30340;&#26356;&#32454;&#33268;&#30340;&#29702;&#35299;&#23578;&#32570;&#20047;&#12290;&#25105;&#20204;&#22312;&#35270;&#35273;&#38382;&#31572;&#65288;VQA&#65289;&#38382;&#39064;&#20013;&#25552;&#20379;&#20102;&#26032;&#30340;&#35777;&#25454;&#65292;&#25581;&#31034;&#20102;&#31616;&#21333;&#20219;&#21153;&#30340;&#22810;&#26679;&#24615;&#65288;&#21363;&#30001;&#20960;&#20010;&#23376;&#20219;&#21153;&#21644;&#27010;&#24565;&#32452;&#25104;&#30340;&#20219;&#21153;&#65289;&#22312;&#23454;&#29616;&#31995;&#32479;&#19968;&#33324;&#21270;&#20013;&#30340;&#20851;&#38190;&#20316;&#29992;&#12290;&#36825;&#24847;&#21619;&#30528;&#25910;&#38598;&#22823;&#37327;&#21644;&#22810;&#26679;&#21270;&#30340;&#22797;&#26434;&#20219;&#21153;&#21487;&#33021;&#24182;&#38750;&#24517;&#35201;&#65292;&#36825;&#21487;&#33021;&#25104;&#26412;&#39640;&#26114;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20010;&#32467;&#26524;&#19982;&#35757;&#32451;&#21644;&#27979;&#35797;&#25968;&#25454;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#26080;&#20851;&#65292;&#24182;&#36866;&#29992;&#20110;&#20247;&#25152;&#21608;&#30693;&#30340;&#31070;&#32463;&#32593;&#32476;&#23478;&#26063;&#12290;
&lt;/p&gt;
&lt;p&gt;
Systematic generalization is a crucial aspect of intelligence, which refers to the ability to generalize to novel tasks by combining known subtasks and concepts. One critical factor that has been shown to influence systematic generalization is the diversity of training data. However, diversity can be defined in various ways, as data have many factors of variation. A more granular understanding of how different aspects of data diversity affect systematic generalization is lacking. We present new evidence in the problem of Visual Question Answering (VQA) that reveals that the diversity of simple tasks (i.e. tasks formed by a few subtasks and concepts) plays a key role in achieving systematic generalization. This implies that it may not be essential to gather a large and varied number of complex tasks, which could be costly to obtain. We demonstrate that this result is independent of the similarity between the training and testing data and applies to well-known families of neural network 
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#31038;&#20250;&#36873;&#25321;&#20013;&#30340;&#24230;&#37327;&#25197;&#26354;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#25237;&#31080;&#35268;&#21017;&#65292;&#35813;&#35268;&#21017;&#21487;&#20197;&#36873;&#25321;&#36317;&#31163;&#36873;&#27665;&#24179;&#22343;&#36317;&#31163;&#36739;&#23567;&#30340;&#20505;&#36873;&#20154;&#12290;&#20043;&#21069;&#30340;&#30740;&#31350;&#21457;&#29616;&#30830;&#23450;&#24615;&#25237;&#31080;&#35268;&#21017;&#30340;&#24230;&#37327;&#25197;&#26354;&#38480;&#21046;&#20026;3&#65292;&#20294;&#22312;&#26080;&#38480;&#21046;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#23545;&#35813;&#38382;&#39064;&#20173;&#28982;&#20102;&#35299;&#26377;&#38480;&#12290;</title><link>http://arxiv.org/abs/2306.17838</link><description>&lt;p&gt;
&#25171;&#30772;&#24230;&#37327;&#25237;&#31080;&#25197;&#26354;&#30340;&#38556;&#30861;
&lt;/p&gt;
&lt;p&gt;
Breaking the Metric Voting Distortion Barrier. (arXiv:2306.17838v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17838
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#31038;&#20250;&#36873;&#25321;&#20013;&#30340;&#24230;&#37327;&#25197;&#26354;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#25237;&#31080;&#35268;&#21017;&#65292;&#35813;&#35268;&#21017;&#21487;&#20197;&#36873;&#25321;&#36317;&#31163;&#36873;&#27665;&#24179;&#22343;&#36317;&#31163;&#36739;&#23567;&#30340;&#20505;&#36873;&#20154;&#12290;&#20043;&#21069;&#30340;&#30740;&#31350;&#21457;&#29616;&#30830;&#23450;&#24615;&#25237;&#31080;&#35268;&#21017;&#30340;&#24230;&#37327;&#25197;&#26354;&#38480;&#21046;&#20026;3&#65292;&#20294;&#22312;&#26080;&#38480;&#21046;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#23545;&#35813;&#38382;&#39064;&#20173;&#28982;&#20102;&#35299;&#26377;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#31038;&#20250;&#36873;&#25321;&#20013;&#24230;&#37327;&#25197;&#26354;&#30340;&#32463;&#20856;&#38382;&#39064;&#12290;&#20551;&#35774;&#25105;&#20204;&#26377;&#19968;&#20010;&#36873;&#20030;&#65292;&#26377;n&#21517;&#36873;&#27665;&#21644;m&#21517;&#20505;&#36873;&#20154;&#65292;&#20182;&#20204;&#20301;&#20110;&#19968;&#20010;&#20849;&#20139;&#30340;&#24230;&#37327;&#31354;&#38388;&#20013;&#12290;&#25105;&#20204;&#24076;&#26395;&#35774;&#35745;&#19968;&#20010;&#25237;&#31080;&#35268;&#21017;&#65292;&#36873;&#25321;&#19968;&#20010;&#24179;&#22343;&#36317;&#31163;&#36873;&#27665;&#36739;&#23567;&#30340;&#20505;&#36873;&#20154;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#19981;&#33021;&#30452;&#25509;&#33719;&#24471;&#24230;&#37327;&#31354;&#38388;&#20013;&#30340;&#36317;&#31163;&#20449;&#24687;&#65292;&#27599;&#20010;&#36873;&#27665;&#21482;&#33021;&#32473;&#20986;&#20505;&#36873;&#20154;&#30340;&#25490;&#24207;&#21015;&#34920;&#12290;&#25105;&#20204;&#33021;&#21542;&#35774;&#35745;&#19968;&#26465;&#35268;&#21017;&#65292;&#26080;&#35770;&#36873;&#20030;&#23454;&#20363;&#21644;&#24213;&#23618;&#24230;&#37327;&#31354;&#38388;&#22914;&#20309;&#65292;&#37117;&#33021;&#36873;&#25321;&#20986;&#19968;&#20010;&#19982;&#30495;&#27491;&#26368;&#20248;&#35299;&#30340;&#20195;&#20215;&#21482;&#30456;&#24046;&#19968;&#20010;&#23567;&#22240;&#23376;&#65288;&#31216;&#20026;&#25197;&#26354;&#24230;&#65289;&#30340;&#20505;&#36873;&#20154;&#65311;&#35768;&#22810;&#30740;&#31350;&#30340;&#25104;&#26524;&#23558;&#30830;&#23450;&#24615;&#25237;&#31080;&#35268;&#21017;&#30340;&#24230;&#37327;&#25197;&#26354;&#38480;&#21046;&#20026;3&#65292;&#36825;&#26159;&#30830;&#23450;&#24615;&#35268;&#21017;&#21644;&#35768;&#22810;&#20854;&#20182;&#25237;&#31080;&#35268;&#21017;&#31867;&#21035;&#30340;&#26368;&#20339;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#22312;&#27809;&#26377;&#20219;&#20309;&#38480;&#21046;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#23545;&#35813;&#38382;&#39064;&#20173;&#28982;&#20102;&#35299;&#26377;&#38480;&#65306;&#23613;&#31649;&#26368;&#20339;&#19979;&#30028;&#24050;&#32463;&#38477;&#20302;&#21040;2.112&#65292;&#20294;&#29616;&#26377;&#35268;&#21017;&#30340;&#25197;&#26354;&#24230;&#20173;&#28982;&#30456;&#23545;&#36739;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the following well studied problem of metric distortion in social choice. Suppose we have an election with $n$ voters and $m$ candidates who lie in a shared metric space. We would like to design a voting rule that chooses a candidate whose average distance to the voters is small. However, instead of having direct access to the distances in the metric space, each voter gives us a ranked list of the candidates in order of distance. Can we design a rule that regardless of the election instance and underlying metric space, chooses a candidate whose cost differs from the true optimum by only a small factor (known as the distortion)?  A long line of work culminated in finding deterministic voting rules with metric distortion $3$, which is the best possible for deterministic rules and many other classes of voting rules. However, without any restrictions, there is still a significant gap in our understanding: Even though the best lower bound is substantially lower at $2.112$, the b
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;VHGM&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#22522;&#20110;&#25513;&#30721;&#24314;&#27169;&#30340;&#26041;&#27861;&#26469;&#23398;&#20064;&#20581;&#24247;&#23646;&#24615;&#12289;&#29983;&#27963;&#26041;&#24335;&#21644;&#20154;&#26684;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#36890;&#36807;&#20351;&#29992;&#24322;&#26500;&#34920;&#26684;&#25968;&#25454;&#38598;&#65292;VHGM&#26377;&#25928;&#22320;&#23398;&#20064;&#20102;&#36229;&#36807;1,800&#20010;&#23646;&#24615;&#12290;&#35813;&#27169;&#22411;&#20855;&#26377;&#28508;&#22312;&#30340;&#24212;&#29992;&#21069;&#26223;&#65292;&#20363;&#22914;&#29992;&#20110;&#21307;&#30103;&#23646;&#24615;&#30340;&#34394;&#25311;&#27979;&#37327;&#21644;&#29983;&#27963;&#26041;&#24335;&#30340;&#20551;&#35774;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2306.10656</link><description>&lt;p&gt;
&#34394;&#25311;&#20154;&#31867;&#29983;&#25104;&#27169;&#22411;&#65306;&#22522;&#20110;&#25513;&#30721;&#24314;&#27169;&#30340;&#26041;&#27861;&#26469;&#23398;&#20064;&#20154;&#31867;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
Virtual Human Generative Model: Masked Modeling Approach for Learning Human Characteristics. (arXiv:2306.10656v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10656
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;VHGM&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#22522;&#20110;&#25513;&#30721;&#24314;&#27169;&#30340;&#26041;&#27861;&#26469;&#23398;&#20064;&#20581;&#24247;&#23646;&#24615;&#12289;&#29983;&#27963;&#26041;&#24335;&#21644;&#20154;&#26684;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#36890;&#36807;&#20351;&#29992;&#24322;&#26500;&#34920;&#26684;&#25968;&#25454;&#38598;&#65292;VHGM&#26377;&#25928;&#22320;&#23398;&#20064;&#20102;&#36229;&#36807;1,800&#20010;&#23646;&#24615;&#12290;&#35813;&#27169;&#22411;&#20855;&#26377;&#28508;&#22312;&#30340;&#24212;&#29992;&#21069;&#26223;&#65292;&#20363;&#22914;&#29992;&#20110;&#21307;&#30103;&#23646;&#24615;&#30340;&#34394;&#25311;&#27979;&#37327;&#21644;&#29983;&#27963;&#26041;&#24335;&#30340;&#20551;&#35774;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35782;&#21035;&#21307;&#30103;&#23646;&#24615;&#12289;&#29983;&#27963;&#26041;&#24335;&#21644;&#20154;&#26684;&#20043;&#38388;&#30340;&#20851;&#31995;&#23545;&#20110;&#29702;&#35299;&#21644;&#25913;&#21892;&#36523;&#20307;&#21644;&#31934;&#31070;&#29366;&#20917;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#34394;&#25311;&#20154;&#31867;&#29983;&#25104;&#27169;&#22411;&#65288;VHGM&#65289;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#29992;&#20110;&#20272;&#35745;&#26377;&#20851;&#21307;&#30103;&#20445;&#20581;&#12289;&#29983;&#27963;&#26041;&#24335;&#21644;&#20010;&#24615;&#30340;&#23646;&#24615;&#12290;VHGM&#26159;&#19968;&#20010;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#20351;&#29992;&#25513;&#30721;&#24314;&#27169;&#35757;&#32451;&#65292;&#22312;&#24050;&#30693;&#23646;&#24615;&#30340;&#26465;&#20214;&#19979;&#23398;&#20064;&#23646;&#24615;&#30340;&#32852;&#21512;&#20998;&#24067;&#12290;&#21033;&#29992;&#24322;&#26500;&#34920;&#26684;&#25968;&#25454;&#38598;&#65292;VHGM&#39640;&#25928;&#22320;&#23398;&#20064;&#20102;&#36229;&#36807;1,800&#20010;&#23646;&#24615;&#12290;&#25105;&#20204;&#25968;&#20540;&#35780;&#20272;&#20102;VHGM&#21450;&#20854;&#35757;&#32451;&#25216;&#26415;&#30340;&#24615;&#33021;&#12290;&#20316;&#20026;VHGM&#30340;&#27010;&#24565;&#39564;&#35777;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20960;&#20010;&#24212;&#29992;&#31243;&#24207;&#65292;&#28436;&#31034;&#20102;&#29992;&#25143;&#24773;&#22659;&#65292;&#20363;&#22914;&#21307;&#30103;&#23646;&#24615;&#30340;&#34394;&#25311;&#27979;&#37327;&#21644;&#29983;&#27963;&#26041;&#24335;&#30340;&#20551;&#35774;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Identifying the relationship between healthcare attributes, lifestyles, and personality is vital for understanding and improving physical and mental conditions. Machine learning approaches are promising for modeling their relationships and offering actionable suggestions. In this paper, we propose Virtual Human Generative Model (VHGM), a machine learning model for estimating attributes about healthcare, lifestyles, and personalities. VHGM is a deep generative model trained with masked modeling to learn the joint distribution of attributes conditioned on known ones. Using heterogeneous tabular datasets, VHGM learns more than 1,800 attributes efficiently. We numerically evaluate the performance of VHGM and its training techniques. As a proof-of-concept of VHGM, we present several applications demonstrating user scenarios, such as virtual measurements of healthcare attributes and hypothesis verifications of lifestyles.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#33539;&#30068;&#35770;&#35821;&#20041;&#30340;&#26041;&#27861;CatE&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#39640;&#25928;&#22320;&#23558;&#26412;&#20307;&#20844;&#29702;&#25237;&#24433;&#21040;&#22270;&#24418;&#20013;&#65292;&#24182;&#29983;&#25104;&#26412;&#20307;&#35770;&#30340;&#23884;&#20837;&#65292;&#20174;&#32780;&#22312;&#30693;&#35782;&#22270;&#35889;&#30340;&#38142;&#25509;&#39044;&#27979;&#20219;&#21153;&#19978;&#21462;&#24471;&#26356;&#22909;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2305.07163</link><description>&lt;p&gt;
CatE&#65306;&#20351;&#29992;&#33539;&#30068;&#35770;&#35821;&#20041;&#23884;&#20837;$\mathcal{ALC}$&#26412;&#20307;&#35770;
&lt;/p&gt;
&lt;p&gt;
CatE: Embedding $\mathcal{ALC}$ ontologies using category-theoretical semantics. (arXiv:2305.07163v1 [cs.LO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07163
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#33539;&#30068;&#35770;&#35821;&#20041;&#30340;&#26041;&#27861;CatE&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#39640;&#25928;&#22320;&#23558;&#26412;&#20307;&#20844;&#29702;&#25237;&#24433;&#21040;&#22270;&#24418;&#20013;&#65292;&#24182;&#29983;&#25104;&#26412;&#20307;&#35770;&#30340;&#23884;&#20837;&#65292;&#20174;&#32780;&#22312;&#30693;&#35782;&#22270;&#35889;&#30340;&#38142;&#25509;&#39044;&#27979;&#20219;&#21153;&#19978;&#21462;&#24471;&#26356;&#22909;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19982;&#35821;&#20041;Web&#26412;&#20307;&#19968;&#36215;&#36827;&#34892;&#26426;&#22120;&#23398;&#20064;&#36981;&#24490;&#20960;&#20010;&#31574;&#30053;&#20043;&#19968;&#65292;&#20854;&#20013;&#21253;&#25324;&#23558;&#26412;&#20307;&#25237;&#24433;&#21040;&#22270;&#24418;&#32467;&#26500;&#20013;&#65292;&#24182;&#23558;&#22270;&#24418;&#23884;&#20837;&#25110;&#22522;&#20110;&#22270;&#24418;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#24212;&#29992;&#20110;&#29983;&#25104;&#30340;&#22270;&#24418;&#12290;&#24050;&#32463;&#24320;&#21457;&#20986;&#20102;&#20960;&#31181;&#23558;&#26412;&#20307;&#20844;&#29702;&#25237;&#24433;&#21040;&#22270;&#24418;&#20013;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#23427;&#20204;&#21487;&#20197;&#25237;&#24433;&#30340;&#20844;&#29702;&#31867;&#22411;&#65288;&#20840;&#38754;&#24615;&#65289;&#12289;&#23427;&#20204;&#26159;&#21542;&#21487;&#36870;&#65288;&#21333;&#23556;&#24615;&#65289;&#20197;&#21450;&#23427;&#20204;&#22914;&#20309;&#21033;&#29992;&#35821;&#20041;&#20449;&#24687;&#26041;&#38754;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#36825;&#20123;&#38480;&#21046;&#38480;&#21046;&#20102;&#23427;&#20204;&#21487;&#20197;&#24212;&#29992;&#30340;&#20219;&#21153;&#31867;&#22411;&#12290;&#36923;&#36753;&#35821;&#35328;&#30340;&#33539;&#30068;&#35770;&#35821;&#20041;&#20197;&#33539;&#30068;&#32780;&#19981;&#26159;&#38598;&#21512;&#30340;&#24418;&#24335;&#24418;&#24335;&#21270;&#35299;&#37322;&#65292;&#24182;&#19988;&#33539;&#30068;&#20855;&#26377;&#31867;&#20284;&#20110;&#22270;&#24418;&#30340;&#32467;&#26500;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;CatE&#65292;&#23427;&#20351;&#29992;$\mathcal{ALC}$&#25551;&#36848;&#36923;&#36753;&#30340;&#33539;&#30068;&#35770;&#20844;&#24335;&#26469;&#29983;&#25104;&#26412;&#20307;&#20844;&#29702;&#30340;&#22270;&#24418;&#34920;&#31034;&#12290;CatE&#25237;&#24433;&#20855;&#26377;&#20840;&#38754;&#24615;&#21644;&#21333;&#23556;&#24615;&#65292;&#22240;&#27492;&#20811;&#26381;&#20102;&#20854;&#20182;&#22522;&#20110;&#22270;&#24418;&#26412;&#20307;&#35770;&#30340;&#26041;&#27861;&#30340;&#38480;&#21046;&#12290;CatE&#36824;&#36890;&#36807;&#23558;$\mathcal{ALC}$&#30340;&#35821;&#27861;&#32534;&#30721;&#20026;&#19968;&#31181;&#33539;&#30068;&#26469;&#21033;&#29992;&#35821;&#20041;&#20449;&#24687;&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#20026;&#26412;&#20307;&#35770;&#29983;&#25104;&#23884;&#20837;&#12290;&#25105;&#20204;&#22312;&#30693;&#35782;&#22270;&#35889;&#30340;&#38142;&#25509;&#39044;&#27979;&#20219;&#21153;&#19978;&#35780;&#20272;&#20102;CatE&#65292;&#24182;&#34920;&#26126;&#23427;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning with Semantic Web ontologies follows several strategies, one of which involves projecting ontologies into graph structures and applying graph embeddings or graph-based machine learning methods to the resulting graphs. Several methods have been developed that project ontology axioms into graphs. However, these methods are limited in the type of axioms they can project (totality), whether they are invertible (injectivity), and how they exploit semantic information. These limitations restrict the kind of tasks to which they can be applied. Category-theoretical semantics of logic languages formalizes interpretations using categories instead of sets, and categories have a graph-like structure. We developed CatE, which uses the category-theoretical formulation of the semantics of the Description Logic $\mathcal{ALC}$ to generate a graph representation for ontology axioms. The CatE projection is total and injective, and therefore overcomes limitations of other graph-based ont
&lt;/p&gt;</description></item></channel></rss>