<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#26412;&#25991;&#25581;&#31034;&#20102;&#25991;&#26412;&#21040;&#22270;&#20687;&#29983;&#25104;&#27169;&#22411;&#23545;&#20559;&#35265;&#25805;&#32437;&#30340;&#25935;&#24863;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#23450;&#37327;&#25511;&#21046;&#27169;&#22411;&#20559;&#35265;&#26469;&#25805;&#32437;&#36755;&#20986;&#20005;&#37325;&#24615;&#30340;&#25216;&#26415;&#65292;&#20174;&#32780;&#23454;&#29616;&#31934;&#30830;&#25552;&#31034;&#24037;&#31243;&#29983;&#25104;&#26032;&#39062;&#22270;&#20687;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2404.02530</link><description>&lt;p&gt;
&#20005;&#37325;&#25511;&#21046;&#30340;&#25991;&#26412;&#21040;&#22270;&#20687;&#29983;&#25104;&#27169;&#22411;&#20559;&#35265;&#25805;&#32437;
&lt;/p&gt;
&lt;p&gt;
Severity Controlled Text-to-Image Generative Model Bias Manipulation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02530
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25581;&#31034;&#20102;&#25991;&#26412;&#21040;&#22270;&#20687;&#29983;&#25104;&#27169;&#22411;&#23545;&#20559;&#35265;&#25805;&#32437;&#30340;&#25935;&#24863;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#23450;&#37327;&#25511;&#21046;&#27169;&#22411;&#20559;&#35265;&#26469;&#25805;&#32437;&#36755;&#20986;&#20005;&#37325;&#24615;&#30340;&#25216;&#26415;&#65292;&#20174;&#32780;&#23454;&#29616;&#31934;&#30830;&#25552;&#31034;&#24037;&#31243;&#29983;&#25104;&#26032;&#39062;&#22270;&#20687;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25991;&#26412;&#21040;&#22270;&#20687;&#65288;T2I&#65289;&#29983;&#25104;&#27169;&#22411;&#27491;&#22312;&#24191;&#27867;&#27969;&#34892;&#65292;&#23588;&#20854;&#26159;&#22312;&#20844;&#20849;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#22266;&#26377;&#30340;&#20559;&#35265;&#21644;&#28508;&#22312;&#30340;&#24694;&#24847;&#25805;&#32437;&#36824;&#26410;&#34987;&#20805;&#20998;&#25506;&#35752;&#12290;&#26412;&#25991;&#25581;&#31034;&#20102;T2I&#27169;&#22411;&#23545;&#27492;&#31867;&#25805;&#32437;&#30340;&#26131;&#24863;&#24615;&#65292;&#24182;&#39318;&#27425;&#25552;&#20986;&#20102;&#36890;&#36807;&#38024;&#23545;&#23884;&#20837;&#24335;&#35821;&#35328;&#27169;&#22411;&#21160;&#24577;&#19988;&#39640;&#25928;&#22320;&#21033;&#29992;&#27169;&#22411;&#20559;&#35265;&#30340;&#26032;&#21487;&#33021;&#24615;&#12290;&#36890;&#36807;&#21033;&#29992;&#21521;&#37327;&#20195;&#25968;&#30340;&#25968;&#23398;&#22522;&#30784;&#65292;&#25105;&#20204;&#30340;&#25216;&#26415;&#23454;&#29616;&#20102;&#23545;&#27169;&#22411;&#20559;&#35265;&#36890;&#36807;&#20005;&#37325;&#24615;&#30340;&#36755;&#20986;&#25805;&#32437;&#30340;&#21487;&#25193;&#23637;&#21644;&#26041;&#20415;&#25511;&#21046;&#12290;&#20316;&#20026;&#21103;&#20135;&#21697;&#65292;&#35813;&#25511;&#21046;&#36824;&#20801;&#35768;&#19968;&#31181;&#31934;&#30830;&#30340;&#25552;&#31034;&#24037;&#31243;&#65292;&#20197;&#29983;&#25104;&#36890;&#24120;&#19981;&#22826;&#21487;&#33021;&#36890;&#36807;&#24120;&#35268;&#25991;&#26412;&#25552;&#31034;&#29983;&#25104;&#30340;&#22270;&#20687;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#25805;&#32437;&#25216;&#26415;&#22312;&#24179;&#34913;&#29983;&#25104;&#31867;&#21035;&#39057;&#29575;&#26041;&#38754;&#30340;&#24314;&#35774;&#24212;&#29992; - &#22914;&#22312;&#27169;&#22411;&#21435;&#20559;&#12290;&#25105;&#20204;&#30340;&#25216;&#26415;&#19981;&#38656;&#35201;&#35757;&#32451;&#65292;&#24182;&#19988;&#20063;&#20197;&#21518;&#38376;&#30340;&#24418;&#24335;&#26500;&#24314;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02530v1 Announce Type: cross  Abstract: Text-to-image (T2I) generative models are gaining wide popularity, especially in public domains. However, their intrinsic bias and potential malicious manipulations remain under-explored. Charting the susceptibility of T2I models to such manipulation, we first expose the new possibility of a dynamic and computationally efficient exploitation of model bias by targeting the embedded language models. By leveraging mathematical foundations of vector algebra, our technique enables a scalable and convenient control over the severity of output manipulation through model bias. As a by-product, this control also allows a form of precise prompt engineering to generate images which are generally implausible with regular text prompts. We also demonstrate a constructive application of our manipulation for balancing the frequency of generated classes - as in model debiasing. Our technique does not require training and is also framed as a backdoor at
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;CF-SimCLR&#65292;&#19968;&#31181;&#21453;&#20107;&#23454;&#23545;&#29031;&#23398;&#20064;&#26041;&#27861;&#65292;&#21033;&#29992;&#36817;&#20284;&#21453;&#20107;&#23454;&#25512;&#26029;&#21019;&#36896;&#27491;&#26679;&#26412;&#65292;&#22823;&#22823;&#25552;&#39640;&#20102;&#27169;&#22411;&#23545;&#37319;&#38598;&#20559;&#31227;&#30340;&#31283;&#20581;&#24615;&#65292;&#24182;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#36739;&#39640;&#30340;&#19979;&#28216;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.09605</link><description>&lt;p&gt;
&#21453;&#20107;&#23454;&#23545;&#29031;&#23398;&#20064;&#65306;&#36890;&#36807;&#22240;&#26524;&#22270;&#20687;&#21512;&#25104;&#33719;&#24471;&#31283;&#20581;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Counterfactual contrastive learning: robust representations via causal image synthesis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09605
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;CF-SimCLR&#65292;&#19968;&#31181;&#21453;&#20107;&#23454;&#23545;&#29031;&#23398;&#20064;&#26041;&#27861;&#65292;&#21033;&#29992;&#36817;&#20284;&#21453;&#20107;&#23454;&#25512;&#26029;&#21019;&#36896;&#27491;&#26679;&#26412;&#65292;&#22823;&#22823;&#25552;&#39640;&#20102;&#27169;&#22411;&#23545;&#37319;&#38598;&#20559;&#31227;&#30340;&#31283;&#20581;&#24615;&#65292;&#24182;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#36739;&#39640;&#30340;&#19979;&#28216;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#27604;&#39044;&#35757;&#32451;&#24050;&#34987;&#24191;&#27867;&#35748;&#20026;&#33021;&#22815;&#25552;&#39640;&#19979;&#28216;&#20219;&#21153;&#24615;&#33021;&#21644;&#27169;&#22411;&#27867;&#21270;&#33021;&#21147;&#65292;&#29305;&#21035;&#26159;&#22312;&#26377;&#38480;&#26631;&#31614;&#35774;&#32622;&#20013;&#12290;&#28982;&#32780;&#65292;&#23427;&#23545;&#22686;&#24378;&#31649;&#36947;&#30340;&#36873;&#25321;&#25935;&#24863;&#12290;&#27491;&#26679;&#26412;&#24212;&#20445;&#30041;&#35821;&#20041;&#20449;&#24687;&#21516;&#26102;&#30772;&#22351;&#22495;&#29305;&#23450;&#20449;&#24687;&#12290;&#26631;&#20934;&#22686;&#24378;&#31649;&#36947;&#36890;&#36807;&#39044;&#23450;&#20041;&#30340;&#20809;&#24230;&#21464;&#25442;&#27169;&#25311;&#22495;&#29305;&#23450;&#21464;&#21270;&#65292;&#20294;&#22914;&#26524;&#25105;&#20204;&#33021;&#22815;&#27169;&#25311;&#30495;&#23454;&#30340;&#39046;&#22495;&#21464;&#21270;&#21602;&#65311;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#26368;&#36817;&#22312;&#21453;&#20107;&#23454;&#22270;&#20687;&#29983;&#25104;&#26041;&#38754;&#30340;&#36827;&#23637;&#26469;&#23454;&#29616;&#36825;&#19968;&#30446;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;CF-SimCLR&#65292;&#19968;&#31181;&#21453;&#20107;&#23454;&#23545;&#29031;&#23398;&#20064;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;&#36817;&#20284;&#21453;&#20107;&#23454;&#25512;&#26029;&#36827;&#34892;&#27491;&#26679;&#26412;&#21019;&#24314;&#12290;&#23545;&#33016;&#37096;X&#20809;&#21644;&#20083;&#33146;X&#20809;&#31561;&#20116;&#20010;&#25968;&#25454;&#38598;&#30340;&#20840;&#38754;&#35780;&#20272;&#34920;&#26126;&#65292;CF-SimCLR&#26174;&#33879;&#25552;&#39640;&#20102;&#23545;&#33719;&#21462;&#20559;&#31227;&#30340;&#31283;&#20581;&#24615;&#65292;&#22312;&#20004;&#31181;&#25968;&#25454;&#38598;&#19978;&#30340;&#19979;&#28216;&#24615;&#33021;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09605v1 Announce Type: cross  Abstract: Contrastive pretraining is well-known to improve downstream task performance and model generalisation, especially in limited label settings. However, it is sensitive to the choice of augmentation pipeline. Positive pairs should preserve semantic information while destroying domain-specific information. Standard augmentation pipelines emulate domain-specific changes with pre-defined photometric transformations, but what if we could simulate realistic domain changes instead? In this work, we show how to utilise recent progress in counterfactual image generation to this effect. We propose CF-SimCLR, a counterfactual contrastive learning approach which leverages approximate counterfactual inference for positive pair creation. Comprehensive evaluation across five datasets, on chest radiography and mammography, demonstrates that CF-SimCLR substantially improves robustness to acquisition shift with higher downstream performance on both in- an
&lt;/p&gt;</description></item><item><title>&#25968;&#25454;&#22686;&#24378;&#19981;&#36807;&#26159;&#26356;&#22909;&#22320;&#24494;&#35843;&#27169;&#22411;&#65292;&#38646;&#21761;&#24577;&#21644;&#23569;&#26679;&#26412;&#25968;&#25454;&#29983;&#25104;&#21487;&#25552;&#39640;&#24615;&#33021;</title><link>https://arxiv.org/abs/2402.14895</link><description>&lt;p&gt;
&#25968;&#25454;&#22686;&#24378;&#24050;&#27515;&#65292;&#25968;&#25454;&#22686;&#24378;&#19975;&#23681;
&lt;/p&gt;
&lt;p&gt;
Data Augmentation is Dead, Long Live Data Augmentation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14895
&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#22686;&#24378;&#19981;&#36807;&#26159;&#26356;&#22909;&#22320;&#24494;&#35843;&#27169;&#22411;&#65292;&#38646;&#21761;&#24577;&#21644;&#23569;&#26679;&#26412;&#25968;&#25454;&#29983;&#25104;&#21487;&#25552;&#39640;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25991;&#26412;&#25968;&#25454;&#22686;&#24378;&#65288;DA&#65289;&#26159;&#19968;&#20010;&#32321;&#33635;&#30340;&#30740;&#31350;&#39046;&#22495;&#65292;&#19981;&#26029;&#25552;&#20986;&#26032;&#39062;&#30340;&#25216;&#26415;&#26469;&#21019;&#24314;&#20154;&#24037;&#25968;&#25454;&#65292;&#24050;&#32463;&#22312;&#23567;&#25968;&#25454;&#29615;&#22659;&#20013;&#34920;&#29616;&#20986;&#24456;&#39640;&#30340;&#25928;&#29575;&#65292;&#33267;&#23569;&#23545;&#20110;&#25991;&#26412;&#20998;&#31867;&#20219;&#21153;&#32780;&#35328;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36136;&#30097;&#36825;&#20123;&#32467;&#26524;&#65292;&#34920;&#26126;&#32463;&#20856;&#30340;&#25968;&#25454;&#22686;&#24378;&#21482;&#26159;&#19968;&#31181;&#26356;&#22909;&#22320;&#36827;&#34892;&#24494;&#35843;&#30340;&#26041;&#24335;&#65292;&#24182;&#19988;&#22312;&#24212;&#29992;&#25968;&#25454;&#22686;&#24378;&#20043;&#21069;&#33457;&#26356;&#22810;&#26102;&#38388;&#36827;&#34892;&#24494;&#35843;&#20250;&#25269;&#28040;&#20854;&#25928;&#26524;&#12290;&#36825;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#36129;&#29486;&#65292;&#22240;&#20026;&#23427;&#22238;&#31572;&#20102;&#26368;&#36817;&#20960;&#24180;&#30041;&#19979;&#30340;&#20960;&#20010;&#38382;&#39064;&#65292;&#21363;&#65306;&#21738;&#31181;DA&#25216;&#26415;&#34920;&#29616;&#26368;&#20339;&#65288;&#21482;&#35201;&#23427;&#20204;&#29983;&#25104;&#30340;&#25968;&#25454;&#19982;&#35757;&#32451;&#38598;&#36275;&#22815;&#25509;&#36817;&#65292;&#19981;&#20250;&#25439;&#23475;&#35757;&#32451;&#65289;&#65292;&#20026;&#20160;&#20040;DA&#34920;&#29616;&#20986;&#31215;&#26497;&#30340;&#32467;&#26524;&#65288;&#31616;&#21270;&#32593;&#32476;&#35757;&#32451;&#65289;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#36890;&#36807;&#23545;&#35805;&#20195;&#29702;&#65288;&#22914;ChatGPT&#25110;LLama2&#65289;&#38646;&#21761;&#24577;&#21644;&#23569;&#26679;&#26412;&#25968;&#25454;&#29983;&#25104;&#21487;&#20197;&#25552;&#39640;&#24615;&#33021;&#65292;&#20174;&#32780;&#24471;&#20986;&#20102;&#32467;&#35770;&#65292;&#27492;&#27861;&#21487;&#20197;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14895v1 Announce Type: cross  Abstract: Textual data augmentation (DA) is a prolific field of study where novel techniques to create artificial data are regularly proposed, and that has demonstrated great efficiency on small data settings, at least for text classification tasks. In this paper, we challenge those results, showing that classical data augmentation is simply a way of performing better fine-tuning, and that spending more time fine-tuning before applying data augmentation negates its effect. This is a significant contribution as it answers several questions that were left open in recent years, namely~: which DA technique performs best (all of them as long as they generate data close enough to the training set as to not impair training) and why did DA show positive results (facilitates training of network). We furthermore show that zero and few-shot data generation via conversational agents such as ChatGPT or LLama2 can increase performances, concluding that this f
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;COBIAS&#65292;&#26088;&#22312;&#36890;&#36807;&#32771;&#34385;&#22810;&#26679;&#24773;&#22659;&#30340;&#29992;&#25143;&#36755;&#20837;&#20869;&#23481;&#65292;&#34913;&#37327;&#35821;&#21477;&#30340;&#24773;&#22659;&#21487;&#38752;&#24615;&#65292;&#20174;&#32780;&#22521;&#20859;&#20559;&#35265;&#24847;&#35782;&#12290;</title><link>https://arxiv.org/abs/2402.14889</link><description>&lt;p&gt;
COBIAS&#65306;&#20559;&#35265;&#35780;&#20272;&#20013;&#30340;&#24773;&#22659;&#21487;&#38752;&#24615;
&lt;/p&gt;
&lt;p&gt;
COBIAS: Contextual Reliability in Bias Assessment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14889
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;COBIAS&#65292;&#26088;&#22312;&#36890;&#36807;&#32771;&#34385;&#22810;&#26679;&#24773;&#22659;&#30340;&#29992;&#25143;&#36755;&#20837;&#20869;&#23481;&#65292;&#34913;&#37327;&#35821;&#21477;&#30340;&#24773;&#22659;&#21487;&#38752;&#24615;&#65292;&#20174;&#32780;&#22521;&#20859;&#20559;&#35265;&#24847;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26159;&#22522;&#20110;&#22266;&#26377;&#20559;&#35265;&#25968;&#25454;&#35757;&#32451;&#30340;&#12290;&#20197;&#24448;&#30340;&#21435;&#20559;&#35265;&#27169;&#22411;&#30740;&#31350;&#20381;&#36182;&#22522;&#20934;&#25968;&#25454;&#38598;&#26469;&#34913;&#37327;&#27169;&#22411;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#25968;&#25454;&#38598;&#30001;&#20110;&#23545;&#20559;&#35265;&#30340;&#26497;&#20854;&#20027;&#35266;&#29702;&#35299;&#32780;&#23384;&#22312;&#22810;&#20010;&#32570;&#38519;&#65292;&#20984;&#26174;&#20986;&#23545;&#24773;&#22659;&#25506;&#32034;&#30340;&#36843;&#20999;&#38656;&#27714;&#12290;&#25105;&#20204;&#25552;&#20986;&#32771;&#34385;&#36755;&#20837;&#29992;&#25143;&#20869;&#23481;&#30340;&#24773;&#22659;&#65292;&#32771;&#34385;&#21040;&#36755;&#20837;&#35821;&#21477;&#21487;&#33021;&#23384;&#22312;&#30340;&#22810;&#31181;&#24773;&#20917;&#12290;&#36825;&#31181;&#26041;&#27861;&#23558;&#20801;&#35768;&#22521;&#20859;&#20559;&#35265;&#24847;&#35782;&#30340;&#26694;&#26550;&#65292;&#32780;&#19981;&#26159;&#20260;&#23475;&#29992;&#25143;&#21442;&#19982;&#30340;&#38450;&#25252;&#35774;&#26045;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#26377;&#20004;&#20010;&#26041;&#38754;&#65306;(i) &#25105;&#20204;&#21019;&#24314;&#20102;&#19968;&#20010;&#21253;&#21547;2287&#20010;&#38472;&#35789;&#28389;&#35843;&#35821;&#21477;&#20197;&#21450;&#28155;&#21152;&#24773;&#22659;&#35201;&#28857;&#30340;&#25968;&#25454;&#38598;&#65307;(ii) &#25105;&#20204;&#24320;&#21457;&#20102;&#38754;&#21521;&#24773;&#22659;&#30340;&#20559;&#35265;&#25351;&#26631;&#21644;&#35780;&#20272;&#20998;&#25968;&#65288;COBIAS&#65289;&#26469;&#35780;&#20272;&#35821;&#21477;&#22312;&#34913;&#37327;&#20559;&#35265;&#26041;&#38754;&#30340;&#24773;&#22659;&#21487;&#38752;&#24615;&#12290;&#25105;&#20204;&#30340;&#24230;&#37327;&#26159;&#34913;&#37327;&#20559;&#35265;&#22522;&#20934;&#25968;&#25454;&#38598;&#24773;&#22659;&#21487;&#38752;&#24615;&#30340;&#37325;&#35201;&#39044;&#27979;&#22240;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14889v1 Announce Type: cross  Abstract: Large Language Models (LLMs) are trained on inherently biased data. Previous works on debiasing models rely on benchmark datasets to measure model performance. However, these datasets suffer from several pitfalls due to the extremely subjective understanding of bias, highlighting a critical need for contextual exploration. We propose understanding the context of user inputs with consideration of the diverse situations in which input statements are possible. This approach would allow for frameworks that foster bias awareness rather than guardrails that hurt user engagement. Our contribution is twofold: (i) we create a dataset of 2287 stereotyped statements augmented with points for adding context; (ii) we develop the Context-Oriented Bias Indicator and Assessment Score (COBIAS) to assess statements' contextual reliability in measuring bias. Our metric is a significant predictor of the contextual reliability of bias-benchmark datasets ($
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21021;&#27493;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#20116;&#20010;&#20851;&#38190;&#20027;&#39064;&#30340;&#20998;&#26512;&#21644;&#32531;&#35299;&#31574;&#30053;&#26469;&#24314;&#31435;&#31185;&#23398;&#30740;&#31350;&#20013;&#29983;&#25104;AI&#30340;&#20262;&#29702;&#25351;&#21335;&#12290;&#20840;&#29699;&#20849;&#35782;&#12289;&#19987;&#19994;&#22521;&#35757;&#21644;&#21512;&#29702;&#30340;&#25191;&#34892;&#23545;&#20110;&#20419;&#36827;AI&#30340;&#30410;&#22788;&#21644;&#32500;&#25252;&#30740;&#31350;&#35802;&#20449;&#33267;&#20851;&#37325;&#35201;&#12290;</title><link>http://arxiv.org/abs/2401.15284</link><description>&lt;p&gt;
&#22312;&#31185;&#23398;&#30740;&#31350;&#20013;&#24314;&#31435;&#29983;&#25104;AI&#30340;&#20262;&#29702;&#25351;&#21335;
&lt;/p&gt;
&lt;p&gt;
Building ethical guidelines for generative AI in scientific research. (arXiv:2401.15284v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15284
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21021;&#27493;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#20116;&#20010;&#20851;&#38190;&#20027;&#39064;&#30340;&#20998;&#26512;&#21644;&#32531;&#35299;&#31574;&#30053;&#26469;&#24314;&#31435;&#31185;&#23398;&#30740;&#31350;&#20013;&#29983;&#25104;AI&#30340;&#20262;&#29702;&#25351;&#21335;&#12290;&#20840;&#29699;&#20849;&#35782;&#12289;&#19987;&#19994;&#22521;&#35757;&#21644;&#21512;&#29702;&#30340;&#25191;&#34892;&#23545;&#20110;&#20419;&#36827;AI&#30340;&#30410;&#22788;&#21644;&#32500;&#25252;&#30740;&#31350;&#35802;&#20449;&#33267;&#20851;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#20154;&#24037;&#26234;&#33021;&#24037;&#20855;&#65288;&#22914;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65289;&#27491;&#22312;&#36805;&#36895;&#25913;&#21464;&#23398;&#26415;&#30740;&#31350;&#21644;&#23454;&#38469;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;&#31185;&#23398;&#20013;&#29983;&#25104;AI&#30340;&#20262;&#29702;&#25351;&#21335;&#30340;&#35752;&#35770;&#20173;&#28982;&#38646;&#25955;&#65292;&#24378;&#35843;&#20102;&#21327;&#21830;&#19968;&#33268;&#24615;&#26631;&#20934;&#30340;&#32039;&#36843;&#24615;&#12290;&#26412;&#25991;&#36890;&#36807;&#23545;&#20116;&#20010;&#20851;&#38190;&#20027;&#39064;&#30340;&#20998;&#26512;&#21644;&#32531;&#35299;&#31574;&#30053;&#30340;&#24320;&#21457;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#21021;&#27493;&#30340;&#26694;&#26550;&#65306;&#20102;&#35299;&#27169;&#22411;&#22312;&#30495;&#23454;&#24615;&#21644;&#20559;&#35265;&#26041;&#38754;&#30340;&#23616;&#38480;&#24615;&#65307;&#23562;&#37325;&#38544;&#31169;&#12289;&#26426;&#23494;&#21644;&#29256;&#26435;&#65307;&#22312;&#34701;&#20837;&#27169;&#22411;&#36755;&#20986;&#26102;&#36991;&#20813;&#25220;&#34989;&#21644;&#36829;&#21453;&#25919;&#31574;&#65307;&#30830;&#20445;&#24212;&#29992;&#24102;&#26469;&#24635;&#20307;&#21033;&#30410;&#65307;&#20197;&#21450;&#36879;&#26126;&#12289;&#21487;&#22797;&#21046;&#22320;&#20351;&#29992;&#20154;&#24037;&#26234;&#33021;&#12290;&#36890;&#36807;&#21015;&#20030;&#24120;&#35265;&#22330;&#26223;&#26469;&#23637;&#31034;&#28508;&#22312;&#30340;&#20262;&#29702;&#36829;&#35268;&#34892;&#20026;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#20840;&#29699;&#20849;&#35782;&#20197;&#21450;&#19987;&#19994;&#22521;&#35757;&#21644;&#21512;&#29702;&#30340;&#25191;&#34892;&#26159;&#20419;&#36827;AI&#30340;&#30410;&#22788;&#24182;&#32500;&#25252;&#30740;&#31350;&#35802;&#20449;&#30340;&#20851;&#38190;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative artificial intelligence tools like large language models are rapidly transforming academic research and real world applications. However, discussions on ethical guidelines for generative AI in science remain fragmented, underscoring the urgent need for consensus based standards. This paper offers an initial framework by developing analyses and mitigation strategies across five key themes: understanding model limitations regarding truthfulness and bias; respecting privacy, confidentiality, and copyright; avoiding plagiarism and policy violations when incorporating model output; ensuring applications provide overall benefit; and using AI transparently and reproducibly. Common scenarios are outlined to demonstrate potential ethical violations. We argue that global consensus coupled with professional training and reasonable enforcement are critical to promoting the benefits of AI while safeguarding research integrity.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35843;&#26597;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#20013;&#30446;&#26631;&#23548;&#21521;&#25552;&#31034;&#24037;&#31243;&#30340;&#37325;&#35201;&#24615;&#12290;&#36890;&#36807;&#23545;35&#20010;&#20195;&#34920;&#24615;&#30740;&#31350;&#30340;&#22238;&#39038;&#65292;&#25105;&#20204;&#21457;&#29616;&#24341;&#23548;LLM&#36981;&#24490;&#20154;&#31867;&#30340;&#36923;&#36753;&#24605;&#32500;&#30340;&#30446;&#26631;&#23548;&#21521;&#25552;&#31034;&#20844;&#24335;&#26174;&#33879;&#25552;&#39640;&#20102;LLM&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20998;&#31867;&#20307;&#31995;&#65292;&#24182;&#24635;&#32467;&#20102;&#21313;&#20010;&#36866;&#29992;&#20219;&#21153;&#26469;&#23637;&#31034;&#25105;&#20204;&#26694;&#26550;&#30340;&#24191;&#27867;&#36866;&#29992;&#24615;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22235;&#20010;&#26410;&#26469;&#30340;&#26041;&#21521;&#65292;&#20197;&#25512;&#21160;&#30446;&#26631;&#23548;&#21521;&#25552;&#31034;&#24037;&#31243;&#30340;&#36827;&#19968;&#27493;&#21457;&#23637;&#12290;</title><link>http://arxiv.org/abs/2401.14043</link><description>&lt;p&gt;
&#26397;&#30528;&#30446;&#26631;&#23548;&#21521;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25552;&#31034;&#26041;&#27861;&#65306;&#19968;&#39033;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Towards Goal-oriented Large Language Model Prompting: A Survey. (arXiv:2401.14043v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14043
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35843;&#26597;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#20013;&#30446;&#26631;&#23548;&#21521;&#25552;&#31034;&#24037;&#31243;&#30340;&#37325;&#35201;&#24615;&#12290;&#36890;&#36807;&#23545;35&#20010;&#20195;&#34920;&#24615;&#30740;&#31350;&#30340;&#22238;&#39038;&#65292;&#25105;&#20204;&#21457;&#29616;&#24341;&#23548;LLM&#36981;&#24490;&#20154;&#31867;&#30340;&#36923;&#36753;&#24605;&#32500;&#30340;&#30446;&#26631;&#23548;&#21521;&#25552;&#31034;&#20844;&#24335;&#26174;&#33879;&#25552;&#39640;&#20102;LLM&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20998;&#31867;&#20307;&#31995;&#65292;&#24182;&#24635;&#32467;&#20102;&#21313;&#20010;&#36866;&#29992;&#20219;&#21153;&#26469;&#23637;&#31034;&#25105;&#20204;&#26694;&#26550;&#30340;&#24191;&#27867;&#36866;&#29992;&#24615;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22235;&#20010;&#26410;&#26469;&#30340;&#26041;&#21521;&#65292;&#20197;&#25512;&#21160;&#30446;&#26631;&#23548;&#21521;&#25552;&#31034;&#24037;&#31243;&#30340;&#36827;&#19968;&#27493;&#21457;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#22312;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#20013;&#26174;&#31034;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#65292;&#32780;&#25552;&#31034;&#24037;&#31243;&#22312;&#20248;&#21270;LLM&#24615;&#33021;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#26412;&#25991;&#26088;&#22312;&#24378;&#35843;&#35774;&#35745;&#25552;&#31034;&#30340;&#38480;&#21046;&#65292;&#21516;&#26102;&#20445;&#25345;&#20154;&#31867;&#36861;&#27714;LLM&#20687;&#20154;&#31867;&#24605;&#32771;&#30340;&#20154;&#31867;&#23398;&#20551;&#35774;&#12290;&#36890;&#36807;&#23545;35&#20010;&#20195;&#34920;&#24615;&#30740;&#31350;&#30340;&#22238;&#39038;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#30446;&#26631;&#23548;&#21521;&#25552;&#31034;&#20844;&#24335;&#30340;&#37325;&#35201;&#24615;&#65292;&#35813;&#20844;&#24335;&#25351;&#23548;LLM&#36981;&#24490;&#20154;&#31867;&#30340;&#36923;&#36753;&#24605;&#32500;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;LLM&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#20998;&#31867;&#20307;&#31995;&#65292;&#23558;&#30446;&#26631;&#23548;&#21521;&#25552;&#31034;&#26041;&#27861;&#20998;&#20026;&#20116;&#20010;&#30456;&#20114;&#20851;&#32852;&#30340;&#38454;&#27573;&#65292;&#24182;&#36890;&#36807;&#24635;&#32467;&#21313;&#20010;&#36866;&#29992;&#20219;&#21153;&#26469;&#23637;&#31034;&#25105;&#20204;&#26694;&#26550;&#30340;&#24191;&#27867;&#36866;&#29992;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22235;&#20010;&#26410;&#26469;&#30340;&#26041;&#21521;&#65292;&#24076;&#26395;&#36827;&#19968;&#27493;&#24378;&#35843;&#21644;&#25512;&#21160;&#30446;&#26631;&#23548;&#21521;&#25552;&#31034;&#24037;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have shown prominent performance in various downstream tasks in which prompt engineering plays a pivotal role in optimizing LLMs' performance. This paper, not as an overview of current prompt engineering methods, aims to highlight the limitation of designing prompts while holding an anthropomorphic assumption that expects LLMs to think like humans. From our review of 35 representative studies, we demonstrate that a goal-oriented prompt formulation, which guides LLMs to follow established human logical thinking, significantly improves the performance of LLMs. Furthermore, We introduce a novel taxonomy that categorizes goal-oriented prompting methods into five interconnected stages and we demonstrate the broad applicability of our framework by summarizing ten applicable tasks. With four future directions proposed, we hope to further emphasize and promote goal-oriented prompt engineering.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#21463;&#31639;&#27861;&#20915;&#31574;&#24433;&#21709;&#30340;&#20154;&#30340;&#20449;&#24687;&#38656;&#27714;&#65292;&#21457;&#29616;&#35299;&#37322;&#24448;&#24448;&#19981;&#33021;&#28385;&#36275;&#20182;&#20204;&#30340;&#20851;&#27880;&#28857;&#65292;&#23548;&#33268;&#23545;&#30417;&#31649;&#26694;&#26550;&#30340;&#29702;&#35299;&#21644;&#36981;&#23432;&#20135;&#29983;&#38556;&#30861;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#30740;&#31350;&#22242;&#38431;&#25552;&#20986;&#20102;XAI&#21021;&#23398;&#32773;&#38382;&#39064;&#24211;&#65292;&#28085;&#30422;&#20102;&#23601;&#19994;&#39044;&#27979;&#21644;&#20581;&#24247;&#30417;&#27979;&#20004;&#20010;&#39046;&#22495;&#20013;&#21463;&#24433;&#21709;&#21033;&#30410;&#30456;&#20851;&#32773;&#30340;&#20449;&#24687;&#38656;&#27714;&#12290;</title><link>http://arxiv.org/abs/2401.13324</link><description>&lt;p&gt;
&#26377;&#20851;&#31639;&#27861;&#20915;&#31574;&#30340;&#20449;&#24687;&#65306;&#25506;&#32034;&#21463;&#21040;&#31639;&#27861;&#20915;&#31574;&#24433;&#21709;&#30340;&#20154;&#30340;&#20449;&#24687;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions. (arXiv:2401.13324v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13324
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#21463;&#31639;&#27861;&#20915;&#31574;&#24433;&#21709;&#30340;&#20154;&#30340;&#20449;&#24687;&#38656;&#27714;&#65292;&#21457;&#29616;&#35299;&#37322;&#24448;&#24448;&#19981;&#33021;&#28385;&#36275;&#20182;&#20204;&#30340;&#20851;&#27880;&#28857;&#65292;&#23548;&#33268;&#23545;&#30417;&#31649;&#26694;&#26550;&#30340;&#29702;&#35299;&#21644;&#36981;&#23432;&#20135;&#29983;&#38556;&#30861;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#30740;&#31350;&#22242;&#38431;&#25552;&#20986;&#20102;XAI&#21021;&#23398;&#32773;&#38382;&#39064;&#24211;&#65292;&#28085;&#30422;&#20102;&#23601;&#19994;&#39044;&#27979;&#21644;&#20581;&#24247;&#30417;&#27979;&#20004;&#20010;&#39046;&#22495;&#20013;&#21463;&#24433;&#21709;&#21033;&#30410;&#30456;&#20851;&#32773;&#30340;&#20449;&#24687;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
AI&#31995;&#32479;&#30340;&#35299;&#37322;&#24456;&#23569;&#28041;&#21450;&#21040;&#21463;&#31639;&#27861;&#20915;&#31574;&#24433;&#21709;&#30340;&#20154;&#30340;&#20449;&#24687;&#38656;&#27714;&#12290;&#36825;&#31181;&#20256;&#36798;&#20449;&#24687;&#19982;&#21463;&#24433;&#21709;&#21033;&#30410;&#30456;&#20851;&#32773;&#25152;&#20851;&#24515;&#30340;&#20449;&#24687;&#20043;&#38388;&#30340;&#24046;&#36317;&#21487;&#33021;&#38459;&#30861;&#23545;&#30417;&#31649;&#26694;&#26550;&#65288;&#22914;AI&#27861;&#26696;&#65289;&#30340;&#29702;&#35299;&#21644;&#36981;&#23432;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#24046;&#36317;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#8220;XAI&#21021;&#23398;&#32773;&#38382;&#39064;&#24211;&#8221;&#65306;&#36825;&#26159;&#19968;&#20010;&#28085;&#30422;&#20004;&#20010;&#31639;&#27861;&#20915;&#31574;&#24212;&#29992;&#39046;&#22495;&#65288;&#23601;&#19994;&#39044;&#27979;&#21644;&#20581;&#24247;&#30417;&#27979;&#65289;&#20013;&#21463;&#24433;&#21709;&#21033;&#30410;&#30456;&#20851;&#32773;&#20449;&#24687;&#38656;&#27714;&#30340;&#30446;&#24405;&#65292;&#21253;&#25324;&#25968;&#25454;&#12289;&#31995;&#32479;&#32972;&#26223;&#12289;&#31995;&#32479;&#20351;&#29992;&#21644;&#31995;&#32479;&#35268;&#33539;&#31561;&#31867;&#21035;&#12290;&#20449;&#24687;&#38656;&#27714;&#26159;&#36890;&#36807;&#35775;&#35848;&#30740;&#31350;&#25910;&#38598;&#30340;&#65292;&#21442;&#19982;&#32773;&#26681;&#25454;&#33258;&#24049;&#30340;&#38382;&#39064;&#33719;&#24471;&#35299;&#37322;&#12290;&#21442;&#19982;&#32773;&#36824;&#25253;&#21578;&#20102;&#20182;&#20204;&#30340;&#29702;&#35299;&#21644;&#20915;&#31574;&#20449;&#24515;&#65292;&#32467;&#26524;&#26174;&#31034;&#65292;&#23613;&#31649;&#22312;&#25509;&#21463;&#35299;&#37322;&#21518;&#20449;&#24515;&#20542;&#21521;&#20110;&#22686;&#21152;&#65292;&#20294;&#21442;&#19982;&#32773;&#20063;&#38754;&#20020;&#30528;&#29702;&#35299;&#19978;&#30340;&#25361;&#25112;&#65292;&#22914;&#26080;&#27861;&#35299;&#37322;&#20026;&#20160;&#20040;&#33258;&#24049;&#30340;&#29702;&#35299;&#24863;&#35273;&#19981;&#23436;&#25972;&#12290;&#35299;&#37322;&#36824;&#23545;&#29702;&#35299;&#20135;&#29983;&#20102;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Explanations of AI systems rarely address the information needs of people affected by algorithmic decision-making (ADM). This gap between conveyed information and information that matters to affected stakeholders can impede understanding and adherence to regulatory frameworks such as the AI Act. To address this gap, we present the "XAI Novice Question Bank": A catalog of affected stakeholders' information needs in two ADM use cases (employment prediction and health monitoring), covering the categories data, system context, system usage, and system specifications. Information needs were gathered in an interview study where participants received explanations in response to their inquiries. Participants further reported their understanding and decision confidence, showing that while confidence tended to increase after receiving explanations, participants also met understanding challenges, such as being unable to tell why their understanding felt incomplete. Explanations further influenced
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20851;&#27880;AI&#22312;&#30028;&#38754;&#35774;&#35745;&#21644;&#35780;&#20272;&#20013;&#30340;&#23545;&#40784;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#35268;&#33539;&#23545;&#40784;&#12289;&#36807;&#31243;&#23545;&#40784;&#21644;&#35780;&#20272;&#25903;&#25345;&#31561;&#19977;&#20010;&#23545;&#40784;&#30446;&#26631;&#65292;&#24182;&#20171;&#32461;&#20102;&#20195;&#29702;&#36807;&#31243;&#21644;&#36807;&#31243;&#28023;&#28286;&#30340;&#27010;&#24565;&#12290;</title><link>http://arxiv.org/abs/2311.00710</link><description>&lt;p&gt;
AI&#20114;&#21160;&#20013;&#30340;AI&#23545;&#40784;&#65306;&#35268;&#33539;&#23545;&#40784;&#65292;&#36807;&#31243;&#23545;&#40784;&#21644;&#35780;&#20272;&#25903;&#25345;
&lt;/p&gt;
&lt;p&gt;
AI Alignment in the Design of Interactive AI: Specification Alignment, Process Alignment, and Evaluation Support. (arXiv:2311.00710v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00710
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;AI&#22312;&#30028;&#38754;&#35774;&#35745;&#21644;&#35780;&#20272;&#20013;&#30340;&#23545;&#40784;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#35268;&#33539;&#23545;&#40784;&#12289;&#36807;&#31243;&#23545;&#40784;&#21644;&#35780;&#20272;&#25903;&#25345;&#31561;&#19977;&#20010;&#23545;&#40784;&#30446;&#26631;&#65292;&#24182;&#20171;&#32461;&#20102;&#20195;&#29702;&#36807;&#31243;&#21644;&#36807;&#31243;&#28023;&#28286;&#30340;&#27010;&#24565;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
AI&#23545;&#40784;&#26159;&#30830;&#20445;AI&#20135;&#29983;&#26399;&#26395;&#32467;&#26524;&#32780;&#36991;&#20813;&#19981;&#33391;&#21103;&#20316;&#29992;&#30340;&#25972;&#20307;&#38382;&#39064;&#12290;&#34429;&#28982;&#36890;&#24120;&#20174;&#23433;&#20840;&#21644;&#20154;&#31867;&#20215;&#20540;&#30340;&#35282;&#24230;&#32771;&#34385;AI&#23545;&#40784;&#65292;&#20294;&#20063;&#21487;&#20197;&#22312;&#35774;&#35745;&#21644;&#35780;&#20272;&#20132;&#20114;&#24335;AI&#31995;&#32479;&#30340;&#30028;&#38754;&#30340;&#32972;&#26223;&#19979;&#32771;&#34385;AI&#23545;&#40784;&#12290;&#26412;&#25991;&#23558;AI&#23545;&#40784;&#30340;&#27010;&#24565;&#26144;&#23556;&#21040;&#22522;&#26412;&#30340;&#19977;&#27493;&#20132;&#20114;&#24490;&#29615;&#20013;&#65292;&#24471;&#20986;&#30456;&#24212;&#30340;&#23545;&#40784;&#30446;&#26631;&#65306;1&#65289;&#35268;&#33539;&#23545;&#40784;&#65306;&#30830;&#20445;&#29992;&#25143;&#33021;&#22815;&#39640;&#25928;&#21487;&#38752;&#22320;&#23558;&#30446;&#26631;&#20256;&#36798;&#32473;AI&#65307;2&#65289;&#36807;&#31243;&#23545;&#40784;&#65306;&#25552;&#20379;&#39564;&#35777;&#21644;&#21487;&#36873;&#25321;&#25511;&#21046;AI&#25191;&#34892;&#36807;&#31243;&#30340;&#33021;&#21147;&#65307;3&#65289;&#35780;&#20272;&#25903;&#25345;&#65306;&#30830;&#20445;&#29992;&#25143;&#33021;&#22815;&#39564;&#35777;&#21644;&#29702;&#35299;AI&#30340;&#36755;&#20986;&#12290;&#25105;&#20204;&#36824;&#20171;&#32461;&#20102;&#20195;&#29702;&#36807;&#31243;&#30340;&#27010;&#24565;&#65292;&#23427;&#34987;&#23450;&#20041;&#20026;AI&#23454;&#38469;&#36807;&#31243;&#30340;&#31616;&#21270;&#12289;&#20998;&#31163;&#27966;&#29983;&#20294;&#21487;&#25511;&#21046;&#30340;&#34920;&#31034;&#65307;&#20197;&#21450;&#36807;&#31243;&#28023;&#28286;&#30340;&#27010;&#24565;&#65292;&#23427;&#31361;&#26174;&#20154;&#31867;&#21644;AI&#36807;&#31243;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
AI alignment considers the overall problem of ensuring an AI produces desired outcomes, without undesirable side effects. While often considered from the perspectives of safety and human values, AI alignment can also be considered in the context of designing and evaluating interfaces for interactive AI systems. This paper maps concepts from AI alignment onto a basic, three step interaction cycle, yielding a corresponding set of alignment objectives: 1) specification alignment: ensuring the user can efficiently and reliably communicate objectives to the AI, 2) process alignment: providing the ability to verify and optionally control the AI's execution process, and 3) evaluation support: ensuring the user can verify and understand the AI's output. We also introduce the concepts of a surrogate process, defined as a simplified, separately derived, but controllable representation of the AI's actual process; and the notion of a Process Gulf, which highlights how differences between human and
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;GPT-4&#25104;&#21151;&#22797;&#21046;&#20102;&#20351;&#29992;&#21313;&#39033;&#20154;&#26684;&#38382;&#21367;&#27979;&#37327;&#30340;&#22823;&#20116;&#20154;&#26684;&#30340;&#36328;&#25991;&#21270;&#24046;&#24322;&#65292;&#20294;&#20854;&#32467;&#26524;&#34920;&#26126;&#24179;&#22343;&#35780;&#32423;&#26377;&#19978;&#21319;&#20559;&#24046;&#21644;&#36739;&#20302;&#30340;&#21464;&#24322;&#24615;&#19982;&#32467;&#26500;&#25928;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.10679</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#22797;&#21046;&#36328;&#25991;&#21270;&#20010;&#24615;&#24046;&#24322;
&lt;/p&gt;
&lt;p&gt;
Large language models can replicate cross-cultural differences in personality. (arXiv:2310.10679v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10679
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;GPT-4&#25104;&#21151;&#22797;&#21046;&#20102;&#20351;&#29992;&#21313;&#39033;&#20154;&#26684;&#38382;&#21367;&#27979;&#37327;&#30340;&#22823;&#20116;&#20154;&#26684;&#30340;&#36328;&#25991;&#21270;&#24046;&#24322;&#65292;&#20294;&#20854;&#32467;&#26524;&#34920;&#26126;&#24179;&#22343;&#35780;&#32423;&#26377;&#19978;&#21319;&#20559;&#24046;&#21644;&#36739;&#20302;&#30340;&#21464;&#24322;&#24615;&#19982;&#32467;&#26500;&#25928;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20351;&#29992;&#19968;&#39033;&#22823;&#35268;&#27169;&#23454;&#39564;(N=8000)&#26469;&#30830;&#23450;GPT-4&#26159;&#21542;&#21487;&#20197;&#22797;&#21046;&#20351;&#29992;&#21313;&#39033;&#20154;&#26684;&#38382;&#21367;&#27979;&#37327;&#30340;&#22823;&#20116;&#20154;&#26684;&#30340;&#36328;&#25991;&#21270;&#24046;&#24322;&#12290;&#25105;&#20204;&#36873;&#25321;&#32654;&#22269;&#21644;&#38889;&#22269;&#20316;&#20026;&#25991;&#21270;&#23545;&#27604;&#65292;&#22240;&#20026;&#20808;&#21069;&#30340;&#30740;&#31350;&#34920;&#26126;&#36825;&#20004;&#20010;&#22269;&#23478;&#30340;&#20154;&#20043;&#38388;&#23384;&#22312;&#26174;&#33879;&#30340;&#20154;&#26684;&#24046;&#24322;&#12290;&#25105;&#20204;&#25805;&#32437;&#20102;&#27169;&#25311;&#30340;&#30446;&#26631;&#65288;&#32654;&#22269; vs. &#38889;&#22269;&#65289;&#65292;&#38382;&#21367;&#30340;&#35821;&#35328;&#65288;&#33521;&#35821; vs. &#38889;&#35821;&#65289;&#20197;&#21450;&#35821;&#35328;&#27169;&#22411;&#65288;GPT-4 vs. GPT-3.5&#65289;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;GPT-4&#22797;&#21046;&#20102;&#27599;&#20010;&#22240;&#23376;&#30340;&#36328;&#25991;&#21270;&#24046;&#24322;&#12290;&#28982;&#32780;&#65292;&#24179;&#22343;&#35780;&#32423;&#20855;&#26377;&#19978;&#21319;&#20559;&#24046;&#65292;&#24182;&#19988;&#27604;&#20154;&#31867;&#26679;&#26412;&#30340;&#21464;&#24322;&#24615;&#26356;&#20302;&#65292;&#20197;&#21450;&#32467;&#26500;&#25928;&#24230;&#36739;&#20302;&#12290;&#24635;&#30340;&#26469;&#35828;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#21021;&#27493;&#30340;&#35777;&#25454;&#35828;&#26126;LLMs&#21487;&#20197;&#20419;&#36827;&#36328;&#25991;&#21270;&#24515;&#29702;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
We use a large-scale experiment (N=8000) to determine whether GPT-4 can replicate cross-cultural differences in the Big Five, measured using the Ten-Item Personality Inventory. We used the US and South Korea as the cultural pair, given that prior research suggests substantial personality differences between people from these two countries. We manipulated the target of the simulation (US vs. Korean), the language of the inventory (English vs. Korean), and the language model (GPT-4 vs. GPT-3.5). Our results show that GPT-4 replicated the cross-cultural differences for each factor. However, mean ratings had an upward bias and exhibited lower variation than in the human samples, as well as lower structural validity. Overall, we provide preliminary evidence that LLMs can aid cross-cultural psychological research.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#22312;&#38899;&#39057;&#20998;&#31867;&#20219;&#21153;&#20013;&#23398;&#20064;&#22810;&#26679;&#21270;&#30340;&#29305;&#24449;&#34920;&#31034;&#65292;&#21253;&#25324;&#39046;&#22495;&#29305;&#23450;&#30340;&#38899;&#39640;&#12289;&#38899;&#33394;&#21644;&#31070;&#32463;&#34920;&#31034;&#65292;&#20197;&#21450;&#31471;&#21040;&#31471;&#26550;&#26500;&#65292;&#20026;&#23398;&#20064;&#31283;&#20581;&#12289;&#22810;&#26679;&#21270;&#30340;&#34920;&#31034;&#38138;&#24179;&#20102;&#36947;&#36335;&#65292;&#24182;&#26174;&#33879;&#25552;&#39640;&#20102;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.08751</link><description>&lt;p&gt;
&#22810;&#26679;&#30340;&#31070;&#32463;&#38899;&#39057;&#23884;&#20837; - &#24674;&#22797;&#29305;&#24449;&#65281;
&lt;/p&gt;
&lt;p&gt;
Diverse Neural Audio Embeddings -- Bringing Features back !. (arXiv:2309.08751v1 [cs.SD])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08751
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#22312;&#38899;&#39057;&#20998;&#31867;&#20219;&#21153;&#20013;&#23398;&#20064;&#22810;&#26679;&#21270;&#30340;&#29305;&#24449;&#34920;&#31034;&#65292;&#21253;&#25324;&#39046;&#22495;&#29305;&#23450;&#30340;&#38899;&#39640;&#12289;&#38899;&#33394;&#21644;&#31070;&#32463;&#34920;&#31034;&#65292;&#20197;&#21450;&#31471;&#21040;&#31471;&#26550;&#26500;&#65292;&#20026;&#23398;&#20064;&#31283;&#20581;&#12289;&#22810;&#26679;&#21270;&#30340;&#34920;&#31034;&#38138;&#24179;&#20102;&#36947;&#36335;&#65292;&#24182;&#26174;&#33879;&#25552;&#39640;&#20102;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#29616;&#20195;&#20154;&#24037;&#26234;&#33021;&#26550;&#26500;&#30340;&#20986;&#29616;&#65292;&#20174;&#31471;&#21040;&#31471;&#30340;&#26550;&#26500;&#24320;&#22987;&#27969;&#34892;&#12290;&#36825;&#31181;&#36716;&#21464;&#23548;&#33268;&#20102;&#31070;&#32463;&#26550;&#26500;&#22312;&#27809;&#26377;&#39046;&#22495;&#29305;&#23450;&#20559;&#35265;/&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#35757;&#32451;&#65292;&#26681;&#25454;&#20219;&#21153;&#36827;&#34892;&#20248;&#21270;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#22810;&#26679;&#30340;&#29305;&#24449;&#34920;&#31034;&#65288;&#22312;&#26412;&#20363;&#20013;&#26159;&#39046;&#22495;&#29305;&#23450;&#30340;&#65289;&#23398;&#20064;&#38899;&#39057;&#23884;&#20837;&#12290;&#23545;&#20110;&#28041;&#21450;&#25968;&#30334;&#31181;&#22768;&#38899;&#20998;&#31867;&#30340;&#24773;&#20917;&#65292;&#25105;&#20204;&#23398;&#20064;&#20998;&#21035;&#38024;&#23545;&#38899;&#39640;&#12289;&#38899;&#33394;&#21644;&#31070;&#32463;&#34920;&#31034;&#31561;&#22810;&#26679;&#30340;&#38899;&#39057;&#23646;&#24615;&#24314;&#31435;&#31283;&#20581;&#30340;&#23884;&#20837;&#65292;&#21516;&#26102;&#20063;&#36890;&#36807;&#31471;&#21040;&#31471;&#26550;&#26500;&#36827;&#34892;&#23398;&#20064;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#25163;&#24037;&#21046;&#20316;&#30340;&#23884;&#20837;&#65292;&#20363;&#22914;&#22522;&#20110;&#38899;&#39640;&#21644;&#38899;&#33394;&#30340;&#23884;&#20837;&#65292;&#34429;&#28982;&#21333;&#29420;&#20351;&#29992;&#26102;&#26080;&#27861;&#20987;&#36133;&#23436;&#20840;&#31471;&#21040;&#31471;&#30340;&#34920;&#31034;&#65292;&#20294;&#23558;&#36825;&#20123;&#23884;&#20837;&#19982;&#31471;&#21040;&#31471;&#23884;&#20837;&#30456;&#32467;&#21512;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#24615;&#33021;&#12290;&#36825;&#39033;&#24037;&#20316;&#23558;&#20026;&#22312;&#31471;&#21040;&#31471;&#27169;&#22411;&#20013;&#24341;&#20837;&#19968;&#20123;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#26469;&#23398;&#20064;&#31283;&#20581;&#12289;&#22810;&#26679;&#21270;&#30340;&#34920;&#31034;&#38138;&#24179;&#36947;&#36335;&#65292;&#24182;&#36229;&#36234;&#20165;&#35757;&#32451;&#31471;&#21040;&#31471;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the advent of modern AI architectures, a shift has happened towards end-to-end architectures. This pivot has led to neural architectures being trained without domain-specific biases/knowledge, optimized according to the task. We in this paper, learn audio embeddings via diverse feature representations, in this case, domain-specific. For the case of audio classification over hundreds of categories of sound, we learn robust separate embeddings for diverse audio properties such as pitch, timbre, and neural representation, along with also learning it via an end-to-end architecture. We observe handcrafted embeddings, e.g., pitch and timbre-based, although on their own, are not able to beat a fully end-to-end representation, yet adding these together with end-to-end embedding helps us, significantly improve performance. This work would pave the way to bring some domain expertise with end-to-end models to learn robust, diverse representations, surpassing the performance of just training 
&lt;/p&gt;</description></item><item><title>&#23398;&#20064;&#36890;&#36807;&#33258;&#25105;&#35299;&#37322;&#65288;LSX&#65289;&#26159;&#19968;&#31181;&#26032;&#30340;&#23398;&#20064;&#33539;&#24335;&#65292;&#36890;&#36807;&#32473;&#20104;&#35299;&#37322;&#21644;&#25209;&#35780;&#32773;&#30340;&#21453;&#39304;&#26469;&#25913;&#36827;&#23398;&#20064;&#32773;&#30340;&#24615;&#33021;&#12290;&#36825;&#31181;&#26041;&#27861;&#36866;&#29992;&#20110;&#22270;&#20687;&#20998;&#31867;&#31561;&#22522;&#26412;&#20219;&#21153;&#65292;&#24182;&#26377;&#28508;&#21147;&#22312;&#20154;&#24037;&#26234;&#33021;&#30740;&#31350;&#20013;&#21457;&#25381;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2309.08395</link><description>&lt;p&gt;
&#23398;&#20064;&#36890;&#36807;&#33258;&#25105;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Learning by Self-Explaining. (arXiv:2309.08395v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08395
&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#36890;&#36807;&#33258;&#25105;&#35299;&#37322;&#65288;LSX&#65289;&#26159;&#19968;&#31181;&#26032;&#30340;&#23398;&#20064;&#33539;&#24335;&#65292;&#36890;&#36807;&#32473;&#20104;&#35299;&#37322;&#21644;&#25209;&#35780;&#32773;&#30340;&#21453;&#39304;&#26469;&#25913;&#36827;&#23398;&#20064;&#32773;&#30340;&#24615;&#33021;&#12290;&#36825;&#31181;&#26041;&#27861;&#36866;&#29992;&#20110;&#22270;&#20687;&#20998;&#31867;&#31561;&#22522;&#26412;&#20219;&#21153;&#65292;&#24182;&#26377;&#28508;&#21147;&#22312;&#20154;&#24037;&#26234;&#33021;&#30740;&#31350;&#20013;&#21457;&#25381;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#30740;&#31350;&#38271;&#26399;&#20197;&#26469;&#19968;&#30452;&#20174;&#29983;&#29289;&#23398;&#20013;&#23547;&#25214;&#28789;&#24863;&#65292;&#29305;&#21035;&#26159;&#20154;&#31867;&#26234;&#33021;&#12290;&#19982;&#30446;&#21069;&#20027;&#35201;&#23558;&#35299;&#37322;&#35270;&#20026;&#27169;&#22411;&#26816;&#26597;&#25163;&#27573;&#30340;&#20154;&#24037;&#26234;&#33021;&#30740;&#31350;&#30456;&#27604;&#65292;&#20174;&#24515;&#29702;&#23398;&#20013;&#21457;&#29616;&#33258;&#25105;&#35299;&#37322;&#22312;&#20195;&#29702;&#23398;&#20064;&#36807;&#31243;&#20013;&#30340;&#22909;&#22788;&#26377;&#20123;&#34987;&#24573;&#35270;&#20102;&#12290;&#21463;&#21040;&#36825;&#20010;&#21551;&#21457;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#23398;&#20064;&#33539;&#24335;&#65292;&#31216;&#20026;&#23398;&#20064;&#36890;&#36807;&#33258;&#25105;&#35299;&#37322; (LSX)&#12290;&#20854;&#20013;&#30340;&#22522;&#26412;&#24605;&#24819;&#26159;&#65292;&#19968;&#20010;&#23398;&#20064;&#27169;&#22359; (&#23398;&#20064;&#32773;) &#25191;&#34892;&#19968;&#20010;&#22522;&#26412;&#20219;&#21153;&#65292;&#27604;&#22914;&#22270;&#20687;&#20998;&#31867;&#65292;&#24182;&#23545;&#20854;&#20915;&#31574;&#36827;&#34892;&#35299;&#37322;&#12290;&#38543;&#21518;&#65292;&#19968;&#20010;&#20869;&#37096;&#25209;&#35780;&#32773;&#27169;&#22359;&#22522;&#20110;&#21407;&#22987;&#20219;&#21153;&#35780;&#20272;&#36825;&#20123;&#35299;&#37322;&#30340;&#36136;&#37327;&#12290;&#26368;&#21518;&#65292;&#23398;&#20064;&#32773;&#36890;&#36807;&#25209;&#35780;&#32773;&#30340;&#21453;&#39304;&#24471;&#21040;&#25913;&#36827;&#65292;&#24182;&#26681;&#25454;&#38656;&#35201;&#37325;&#22797;&#36825;&#20010;&#24490;&#29615;&#12290;&#32972;&#21518;&#30340;&#30452;&#35273;&#26159;&#65292;&#22914;&#26524;&#25209;&#35780;&#32773;&#33021;&#22815;&#26681;&#25454;&#30456;&#24212;&#30340;&#35299;&#37322;&#25191;&#34892;&#30456;&#21516;&#30340;&#20219;&#21153;&#65292;&#21017;&#35813;&#35299;&#37322;&#34987;&#35748;&#20026;&#26159;&#8220;&#22909;&#8221;&#30340;&#12290;&#23613;&#31649;&#26377;&#35768;&#22810;&#23454;&#29616;&#21487;&#33021;&#24615;&#65292;&#20294;&#26412;&#25991;&#26088;&#22312;&#25552;&#20379;&#20851;&#20110;&#23454;&#26045;&#23398;&#20064;&#36890;&#36807;&#33258;&#25105;&#35299;&#37322;&#30340;&#19968;&#33324;&#25351;&#23548;&#21407;&#21017;&#12290;&#26377;&#24453;&#36827;&#19968;&#27493;&#30340;&#30740;&#31350;&#21644;&#23454;&#36341;&#26469;&#25506;&#32034;&#36825;&#19968;&#23398;&#20064;&#33539;&#24335;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Artificial intelligence (AI) research has a long track record of drawing inspirations from findings from biology, in particular human intelligence. In contrast to current AI research that mainly treats explanations as a means for model inspection, a somewhat neglected finding from human psychology is the benefit of self-explaining in an agents' learning process. Motivated by this, we introduce a novel learning paradigm, termed Learning by Self-Explaining (LSX). The underlying idea is that a learning module (learner) performs a base task, e.g. image classification, and provides explanations to its decisions. An internal critic module next evaluates the quality of these explanations given the original task. Finally, the learner is refined with the critic's feedback and the loop is repeated as required. The intuition behind this is that an explanation is considered "good" if the critic can perform the same task given the respective explanation. Despite many implementation possibilities th
&lt;/p&gt;</description></item></channel></rss>