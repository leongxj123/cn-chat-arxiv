<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BehAVE&#30340;&#35270;&#39057;&#29702;&#35299;&#26694;&#26550;&#65292;&#20511;&#21161;&#29616;&#26377;&#30340;&#21830;&#19994;&#35270;&#39057;&#28216;&#25103;&#23454;&#29616;&#39046;&#22495;&#38543;&#26426;&#21270;&#65292;&#26080;&#38656;&#20223;&#30495;&#22120;&#30340;&#25903;&#25345;&#12290;&#36890;&#36807;&#21033;&#29992;&#28216;&#25103;&#20013;&#20016;&#23500;&#30340;&#35270;&#35273;&#22810;&#26679;&#24615;&#36827;&#34892;&#38543;&#26426;&#21270;&#65292;&#20197;&#21450;&#36890;&#36807;&#29609;&#23478;&#34892;&#20026;&#30340;&#25991;&#26412;&#25551;&#36848;&#26469;&#25351;&#23548;&#20855;&#26377;&#30456;&#20284;&#20869;&#23481;&#30340;&#35270;&#39057;&#30340;&#23545;&#40784;&#65292;BehAVE&#22312;&#39046;&#22495;&#38543;&#26426;&#21270;&#26041;&#38754;&#23637;&#29616;&#20102;&#40065;&#26834;&#24615;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01335</link><description>&lt;p&gt;
&#36890;&#36807;&#35270;&#39057;&#28216;&#25103;&#23454;&#29616;&#26080;&#20223;&#30495;&#22120;&#35270;&#35273;&#39046;&#22495;&#38543;&#26426;&#21270;
&lt;/p&gt;
&lt;p&gt;
Simulator-Free Visual Domain Randomization via Video Games
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01335
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BehAVE&#30340;&#35270;&#39057;&#29702;&#35299;&#26694;&#26550;&#65292;&#20511;&#21161;&#29616;&#26377;&#30340;&#21830;&#19994;&#35270;&#39057;&#28216;&#25103;&#23454;&#29616;&#39046;&#22495;&#38543;&#26426;&#21270;&#65292;&#26080;&#38656;&#20223;&#30495;&#22120;&#30340;&#25903;&#25345;&#12290;&#36890;&#36807;&#21033;&#29992;&#28216;&#25103;&#20013;&#20016;&#23500;&#30340;&#35270;&#35273;&#22810;&#26679;&#24615;&#36827;&#34892;&#38543;&#26426;&#21270;&#65292;&#20197;&#21450;&#36890;&#36807;&#29609;&#23478;&#34892;&#20026;&#30340;&#25991;&#26412;&#25551;&#36848;&#26469;&#25351;&#23548;&#20855;&#26377;&#30456;&#20284;&#20869;&#23481;&#30340;&#35270;&#39057;&#30340;&#23545;&#40784;&#65292;BehAVE&#22312;&#39046;&#22495;&#38543;&#26426;&#21270;&#26041;&#38754;&#23637;&#29616;&#20102;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39046;&#22495;&#38543;&#26426;&#21270;&#26159;&#19968;&#31181;&#26377;&#25928;&#30340;&#35745;&#31639;&#26426;&#35270;&#35273;&#25216;&#26415;&#65292;&#29992;&#20110;&#25552;&#39640;&#35270;&#35273;&#27169;&#22411;&#22312;&#35270;&#35273;&#19978;&#25130;&#28982;&#19981;&#21516;&#20294;&#20869;&#23481;&#30456;&#20284;&#30340;&#39046;&#22495;&#20013;&#30340;&#20256;&#36882;&#24615;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#26041;&#27861;&#22823;&#37327;&#20381;&#36182;&#20110;&#35843;&#25972;&#22797;&#26434;&#21644;&#19987;&#38376;&#30340;&#20223;&#30495;&#24341;&#25806;&#65292;&#36825;&#20123;&#24341;&#25806;&#30340;&#26500;&#24314;&#24456;&#22256;&#38590;&#65292;&#36827;&#32780;&#24433;&#21709;&#20102;&#23427;&#20204;&#30340;&#21487;&#34892;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;BehAVE&#65292;&#19968;&#31181;&#35270;&#39057;&#29702;&#35299;&#26694;&#26550;&#65292;&#23427;&#29420;&#29305;&#22320;&#21033;&#29992;&#29616;&#26377;&#30340;&#21830;&#19994;&#35270;&#39057;&#28216;&#25103;&#26469;&#23454;&#29616;&#39046;&#22495;&#38543;&#26426;&#21270;&#65292;&#32780;&#26080;&#38656;&#35775;&#38382;&#23427;&#20204;&#30340;&#20223;&#30495;&#24341;&#25806;&#12290;&#22312;BehAVE&#19979;&#65292;(1) &#35270;&#39057;&#28216;&#25103;&#22266;&#26377;&#30340;&#20016;&#23500;&#35270;&#35273;&#22810;&#26679;&#24615;&#25104;&#20026;&#38543;&#26426;&#21270;&#30340;&#26469;&#28304;&#65292;(2) &#29609;&#23478;&#34892;&#20026; - &#36890;&#36807;&#21160;&#20316;&#30340;&#25991;&#26412;&#25551;&#36848;&#36827;&#34892;&#35821;&#20041;&#34920;&#31034; - &#24341;&#23548;&#20855;&#26377;&#30456;&#20284;&#20869;&#23481;&#30340;&#35270;&#39057;&#30340;&#23545;&#40784;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#35270;&#39057;&#21644;&#25991;&#26412;&#22522;&#30784;&#27169;&#22411;&#19978;&#27979;&#35797;&#20102;BehAVE&#65292;&#24182;&#25253;&#21578;&#20102;&#23427;&#22312;&#39046;&#22495;&#38543;&#26426;&#21270;&#26041;&#38754;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Domain randomization is an effective computer vision technique for improving transferability of vision models across visually distinct domains exhibiting similar content. Existing approaches, however, rely extensively on tweaking complex and specialized simulation engines that are difficult to construct, subsequently affecting their feasibility and scalability. This paper introduces BehAVE, a video understanding framework that uniquely leverages the plethora of existing commercial video games for domain randomization, without requiring access to their simulation engines. Under BehAVE (1) the inherent rich visual diversity of video games acts as the source of randomization and (2) player behavior -- represented semantically via textual descriptions of actions -- guides the *alignment* of videos with similar content. We test BehAVE on 25 games of the first-person shooter (FPS) genre across various video and text foundation models and we report its robustness for domain randomization. Beh
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#20010;&#33258;&#21160;&#21270;&#26694;&#26550;&#8220;ChemBench&#8221;&#65292;&#26088;&#22312;&#35780;&#20272;&#26368;&#20808;&#36827;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#21270;&#23398;&#30693;&#35782;&#21644;&#25512;&#29702;&#33021;&#21147;&#26041;&#38754;&#19982;&#20154;&#31867;&#21270;&#23398;&#23478;&#19987;&#19994;&#30693;&#35782;&#30340;&#23545;&#27604;&#12290;</title><link>https://arxiv.org/abs/2404.01475</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#26159;&#36229;&#20154;&#31867;&#21270;&#23398;&#23478;&#65311;
&lt;/p&gt;
&lt;p&gt;
Are large language models superhuman chemists?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01475
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#20010;&#33258;&#21160;&#21270;&#26694;&#26550;&#8220;ChemBench&#8221;&#65292;&#26088;&#22312;&#35780;&#20272;&#26368;&#20808;&#36827;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#21270;&#23398;&#30693;&#35782;&#21644;&#25512;&#29702;&#33021;&#21147;&#26041;&#38754;&#19982;&#20154;&#31867;&#21270;&#23398;&#23478;&#19987;&#19994;&#30693;&#35782;&#30340;&#23545;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22240;&#20854;&#22788;&#29702;&#20154;&#31867;&#35821;&#35328;&#24182;&#25191;&#34892;&#26410;&#32463;&#26126;&#30830;&#35757;&#32451;&#30340;&#20219;&#21153;&#30340;&#33021;&#21147;&#32780;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#36825;&#23545;&#21270;&#23398;&#31185;&#23398;&#26159;&#30456;&#20851;&#30340;&#65292;&#22240;&#20026;&#21270;&#23398;&#38754;&#20020;&#30528;&#25968;&#25454;&#38598;&#23567;&#19988;&#22810;&#26679;&#30340;&#38382;&#39064;&#65292;&#36825;&#20123;&#25968;&#25454;&#38598;&#36890;&#24120;&#20197;&#25991;&#26412;&#24418;&#24335;&#21576;&#29616;&#12290; LLMs&#22312;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#26041;&#38754;&#34920;&#29616;&#20986;&#28508;&#21147;&#65292;&#24182;&#19988;&#36234;&#26469;&#36234;&#22810;&#22320;&#34987;&#21033;&#29992;&#26469;&#39044;&#27979;&#21270;&#23398;&#24615;&#36136;&#65292;&#20248;&#21270;&#21453;&#24212;&#65292;&#29978;&#33267;&#33258;&#20027;&#35774;&#35745;&#21644;&#36827;&#34892;&#23454;&#39564;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#23545;LLMs&#30340;&#21270;&#23398;&#25512;&#29702;&#33021;&#21147;&#20165;&#26377;&#38750;&#24120;&#26377;&#38480;&#30340;&#31995;&#32479;&#24615;&#29702;&#35299;&#65292;&#36825;&#26159;&#25913;&#36827;&#27169;&#22411;&#21644;&#20943;&#36731;&#28508;&#22312;&#21361;&#23475;&#25152;&#24517;&#38656;&#30340;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#8220;ChemBench&#8221;&#65292;&#36825;&#26159;&#19968;&#20010;&#33258;&#21160;&#21270;&#26694;&#26550;&#65292;&#26088;&#22312;&#20005;&#26684;&#35780;&#20272;&#26368;&#20808;&#36827;&#30340;LLMs&#30340;&#21270;&#23398;&#30693;&#35782;&#21644;&#25512;&#29702;&#33021;&#21147;&#65292;&#20197;&#19982;&#20154;&#31867;&#21270;&#23398;&#23478;&#30340;&#19987;&#19994;&#30693;&#35782;&#30456;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01475v1 Announce Type: cross  Abstract: Large language models (LLMs) have gained widespread interest due to their ability to process human language and perform tasks on which they have not been explicitly trained. This is relevant for the chemical sciences, which face the problem of small and diverse datasets that are frequently in the form of text. LLMs have shown promise in addressing these issues and are increasingly being harnessed to predict chemical properties, optimize reactions, and even design and conduct experiments autonomously. However, we still have only a very limited systematic understanding of the chemical reasoning capabilities of LLMs, which would be required to improve models and mitigate potential harms. Here, we introduce "ChemBench," an automated framework designed to rigorously evaluate the chemical knowledge and reasoning abilities of state-of-the-art LLMs against the expertise of human chemists. We curated more than 7,000 question-answer pairs for a 
&lt;/p&gt;</description></item><item><title>ProSwitch&#36890;&#36807;&#30693;&#35782;&#24341;&#23548;&#30340;&#25351;&#20196;&#24494;&#35843;&#65292;&#22312;&#19987;&#19994;&#21644;&#38750;&#19987;&#19994;&#39118;&#26684;&#20043;&#38388;&#29983;&#25104;&#25991;&#26412;&#65292;&#24182;&#22312;&#19987;&#19994;&#24615;&#35780;&#20272;&#21644;&#36136;&#37327;&#35780;&#20272;&#26041;&#38754;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.09131</link><description>&lt;p&gt;
ProSwitch&#65306;&#30693;&#35782;&#24341;&#23548;&#30340;&#35821;&#35328;&#27169;&#22411;&#24494;&#35843;&#65292;&#29983;&#25104;&#19987;&#19994;&#21644;&#38750;&#19987;&#19994;&#39118;&#26684;&#30340;&#25991;&#26412;
&lt;/p&gt;
&lt;p&gt;
ProSwitch: Knowledge-Guided Language Model Fine-Tuning to Generate Professional and Non-Professional Styled Text
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09131
&lt;/p&gt;
&lt;p&gt;
ProSwitch&#36890;&#36807;&#30693;&#35782;&#24341;&#23548;&#30340;&#25351;&#20196;&#24494;&#35843;&#65292;&#22312;&#19987;&#19994;&#21644;&#38750;&#19987;&#19994;&#39118;&#26684;&#20043;&#38388;&#29983;&#25104;&#25991;&#26412;&#65292;&#24182;&#22312;&#19987;&#19994;&#24615;&#35780;&#20272;&#21644;&#36136;&#37327;&#35780;&#20272;&#26041;&#38754;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#21508;&#31181;&#35821;&#35328;&#24212;&#29992;&#20013;&#34920;&#29616;&#20986;&#26377;&#25928;&#24615;&#65292;&#21253;&#25324;&#25991;&#26412;&#25688;&#35201;&#21644;&#21487;&#25511;&#25991;&#26412;&#29983;&#25104;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;&#23427;&#20204;&#36890;&#36807;&#24494;&#35843;&#22312;&#19981;&#21516;&#39118;&#26684;&#38388;&#20999;&#25442;&#30340;&#33021;&#21147;&#30340;&#30740;&#31350;&#20173;&#26410;&#34987;&#20805;&#20998;&#25506;&#35752;&#12290;&#26412;&#30740;&#31350;&#32858;&#28966;&#20110;&#25991;&#26412;&#19987;&#19994;&#24615;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#21517;&#20026;ProSwitch&#65292;&#36890;&#36807;&#30693;&#35782;&#24341;&#23548;&#30340;&#25351;&#20196;&#24494;&#35843;&#65292;&#20351;&#35821;&#35328;&#27169;&#22411;&#20855;&#22791;&#29983;&#25104;&#19987;&#19994;&#21644;&#38750;&#19987;&#19994;&#22238;&#22797;&#30340;&#33021;&#21147;&#12290;ProSwitch&#20998;&#20026;&#19977;&#20010;&#38454;&#27573;&#65306;&#25968;&#25454;&#20934;&#22791;&#65292;&#29992;&#20110;&#25910;&#38598;&#39046;&#22495;&#30693;&#35782;&#21644;&#35757;&#32451;&#35821;&#26009;&#24211;&#65307;&#25351;&#20196;&#24494;&#35843;&#65292;&#29992;&#20110;&#20248;&#21270;&#24102;&#26377;&#22810;&#31181;&#25351;&#20196;&#26684;&#24335;&#30340;&#35821;&#35328;&#27169;&#22411;&#65307;&#20840;&#38754;&#35780;&#20272;&#65292;&#29992;&#20110;&#35780;&#20272;&#29983;&#25104;&#25991;&#26412;&#30340;&#19987;&#19994;&#24615;&#21306;&#20998;&#33021;&#21147;&#21644;&#22522;&#20110;&#21442;&#32771;&#30340;&#36136;&#37327;&#12290; ProSwitch&#30456;&#23545;&#20110;&#36890;&#29992;&#21644;&#19987;&#38376;&#35821;&#35328;&#27169;&#22411;&#30340;&#27604;&#36739;&#20998;&#26512;&#26174;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09131v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have demonstrated efficacy in various linguistic applications, including text summarization and controlled text generation. However, studies into their capacity of switching between styles via fine-tuning remain underexplored. This study concentrates on textual professionalism and introduces a novel methodology, named ProSwitch, which equips a language model with the ability to produce both professional and non-professional responses through knowledge-guided instruction tuning. ProSwitch unfolds across three phases: data preparation for gathering domain knowledge and training corpus; instruction tuning for optimizing language models with multiple levels of instruction formats; and comprehensive evaluation for assessing the professionalism discrimination and reference-based quality of generated text. Comparative analysis of ProSwitch against both general and specialized language models reveals that our appro
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;&#28145;&#24230;&#23376;&#27169;&#36870;&#28857;&#32593;&#32476;&#65288;DSPNs&#65289;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#21551;&#21457;&#30340;GPC-ready&#31574;&#30053;&#36827;&#34892;&#35757;&#32451;&#30340;&#26041;&#27861;&#65292;&#20197;&#24212;&#23545;&#23376;&#27169;&#20989;&#25968;&#23398;&#20064;&#20013;&#30340;&#20004;&#22823;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2403.08199</link><description>&lt;p&gt;
&#28145;&#24230;&#23376;&#27169;&#36870;&#28857;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Deep Submodular Peripteral Network
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08199
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#28145;&#24230;&#23376;&#27169;&#36870;&#28857;&#32593;&#32476;&#65288;DSPNs&#65289;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#21551;&#21457;&#30340;GPC-ready&#31574;&#30053;&#36827;&#34892;&#35757;&#32451;&#30340;&#26041;&#27861;&#65292;&#20197;&#24212;&#23545;&#23376;&#27169;&#20989;&#25968;&#23398;&#20064;&#20013;&#30340;&#20004;&#22823;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23376;&#27169;&#20989;&#25968;&#23545;&#21508;&#31181;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#65292;&#20294;&#36890;&#24120;&#32570;&#20047;&#23454;&#29992;&#30340;&#23398;&#20064;&#26041;&#27861;&#26469;&#33719;&#21462;&#23427;&#20204;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#28145;&#24230;&#23376;&#27169;&#36870;&#28857;&#32593;&#32476;&#65288;DSPNs&#65289;&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#23376;&#27169;&#20989;&#25968;&#21442;&#25968;&#21270;&#26063;&#65292;&#24182;&#25552;&#20986;&#20102;&#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#21551;&#21457;&#30340;GPC-ready&#31574;&#30053;&#23545;&#20854;&#36827;&#34892;&#35757;&#32451;&#30340;&#26041;&#27861;&#65292;&#20197;&#36830;&#25509;&#24182;&#35299;&#20915;&#19978;&#36848;&#20004;&#20010;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08199v1 Announce Type: cross  Abstract: Submodular functions, crucial for various applications, often lack practical learning methods for their acquisition. Seemingly unrelated, learning a scaling from oracles offering graded pairwise preferences (GPC) is underexplored, despite a rich history in psychometrics. In this paper, we introduce deep submodular peripteral networks (DSPNs), a novel parametric family of submodular functions, and methods for their training using a contrastive-learning inspired GPC-ready strategy to connect and then tackle both of the above challenges. We introduce newly devised GPC-style "peripteral" loss which leverages numerically graded relationships between pairs of objects (sets in our case). Unlike traditional contrastive learning, our method utilizes graded comparisons, extracting more nuanced information than just binary-outcome comparisons, and contrasts sets of any size (not just two). We also define a novel suite of automatic sampling strate
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#36719;&#32422;&#26463;&#21462;&#20195;&#30828;&#32422;&#26463;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19987;&#23478;&#28151;&#21512;&#20808;&#39564;&#65292;&#25913;&#21892;&#20102;&#22810;&#27169;&#24577;VAEs&#20013;&#30340;&#34920;&#31034;&#23398;&#20064;&#12290;</title><link>https://arxiv.org/abs/2403.05300</link><description>&lt;p&gt;
&#22810;&#27169;&#24577;VAEs&#20013;&#30340;&#32479;&#19968;&#22810;&#26679;&#24615;&#65306;&#25913;&#36827;&#30340;&#34920;&#31034;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Unity by Diversity: Improved Representation Learning in Multimodal VAEs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05300
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#36719;&#32422;&#26463;&#21462;&#20195;&#30828;&#32422;&#26463;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19987;&#23478;&#28151;&#21512;&#20808;&#39564;&#65292;&#25913;&#21892;&#20102;&#22810;&#27169;&#24577;VAEs&#20013;&#30340;&#34920;&#31034;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24577;&#25968;&#25454;&#30340;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#22312;&#25968;&#25454;&#20998;&#26512;&#30340;&#35768;&#22810;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#28508;&#21147;&#65292;&#22914;&#34920;&#31034;&#23398;&#20064;&#12289;&#26377;&#26465;&#20214;&#29983;&#25104;&#21644;&#22635;&#34917;&#12290;&#30446;&#21069;&#30340;&#26550;&#26500;&#35201;&#20040;&#36328;&#27169;&#24577;&#20849;&#20139;&#32534;&#30721;&#22120;&#36755;&#20986;&#12289;&#35299;&#30721;&#22120;&#36755;&#20837;&#65292;&#35201;&#20040;&#20004;&#32773;&#37117;&#35201;&#23398;&#20064;&#20849;&#20139;&#34920;&#31034;&#12290;&#36825;&#26679;&#30340;&#26550;&#26500;&#23545;&#27169;&#22411;&#26045;&#21152;&#20102;&#20005;&#26684;&#32422;&#26463;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#29992;&#36719;&#32422;&#26463;&#21462;&#20195;&#36825;&#20123;&#30828;&#32422;&#26463;&#21487;&#20197;&#33719;&#24471;&#26356;&#22909;&#30340;&#28508;&#22312;&#34920;&#31034;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19987;&#23478;&#28151;&#21512;&#20808;&#39564;&#65292;&#36719;&#24615;&#22320;&#24341;&#23548;&#27599;&#20010;&#27169;&#24577;&#30340;&#28508;&#22312;&#34920;&#31034;&#26397;&#30528;&#20849;&#20139;&#30340;&#21518;&#39564;&#12290;&#36825;&#31181;&#26041;&#27861;&#23548;&#33268;&#20102;&#20248;&#31168;&#30340;&#28508;&#22312;&#34920;&#31034;&#65292;&#24182;&#20801;&#35768;&#27599;&#20010;&#32534;&#30721;&#20445;&#30041;&#26469;&#33258;&#20854;&#26410;&#21387;&#32553;&#21407;&#22987;&#29305;&#24449;&#26356;&#22909;&#30340;&#20449;&#24687;&#12290;&#36890;&#36807;&#23545;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#21644;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#29616;&#23454;&#19990;&#30028;&#31070;&#32463;&#31185;&#23398;&#25968;&#25454;&#38598;&#36827;&#34892;&#30340;&#24191;&#27867;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25913;&#36827;&#30340;&#23398;&#20064;&#28508;&#22312;&#34920;&#31034;&#21644;&#22635;&#34917;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05300v1 Announce Type: cross  Abstract: Variational Autoencoders for multimodal data hold promise for many tasks in data analysis, such as representation learning, conditional generation, and imputation. Current architectures either share the encoder output, decoder input, or both across modalities to learn a shared representation. Such architectures impose hard constraints on the model. In this work, we show that a better latent representation can be obtained by replacing these hard constraints with a soft constraint. We propose a new mixture-of-experts prior, softly guiding each modality's latent representation towards a shared aggregate posterior. This approach results in a superior latent representation and allows each encoding to preserve information from its uncompressed original features better. In extensive experiments on multiple benchmark datasets and a challenging real-world neuroscience data set, we show improved learned latent representations and imputation of m
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#24230;&#37327;&#24863;&#30693;&#30340;LLM&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#20248;&#21270;&#33258;&#23450;&#20041;&#25351;&#26631;&#26469;&#25913;&#36827;&#25512;&#26029;&#24615;&#33021;</title><link>https://arxiv.org/abs/2403.04182</link><description>&lt;p&gt;
&#24230;&#37327;&#24863;&#30693;&#30340;LLM&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Metric-aware LLM inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04182
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#24230;&#37327;&#24863;&#30693;&#30340;LLM&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#20248;&#21270;&#33258;&#23450;&#20041;&#25351;&#26631;&#26469;&#25913;&#36827;&#25512;&#26029;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24050;&#32463;&#22312;&#21508;&#31181;NLP&#20219;&#21153;&#20013;&#23637;&#31034;&#20986;&#24378;&#22823;&#30340;&#32467;&#26524;&#12290;&#36890;&#24120;&#65292;&#36755;&#20986;&#26159;&#36890;&#36807;&#20174;LLM&#30340;&#22522;&#30784;&#20998;&#24067;&#20013;&#36827;&#34892;&#33258;&#22238;&#24402;&#37319;&#26679;&#33719;&#24471;&#30340;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#36825;&#31181;&#25512;&#26029;&#31574;&#30053;&#23545;&#20110;&#19968;&#31995;&#21015;&#20219;&#21153;&#21644;&#30456;&#20851;&#30340;&#35780;&#20272;&#25351;&#26631;&#21487;&#33021;&#26159;&#27425;&#20248;&#30340;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#24230;&#37327;&#24863;&#30693;&#30340;LLM&#25512;&#26029;&#65306;&#19968;&#31181;&#22312;&#25512;&#26029;&#26102;&#38024;&#23545;&#33258;&#23450;&#20041;&#25351;&#26631;&#36827;&#34892;&#20248;&#21270;&#30340;&#20915;&#31574;&#29702;&#35770;&#26041;&#27861;&#12290;&#25105;&#20204;&#22312;&#23398;&#26415;&#22522;&#20934;&#25968;&#25454;&#38598;&#21644;&#20844;&#24320;&#21487;&#29992;&#27169;&#22411;&#19978;&#25253;&#21578;&#20102;&#30456;&#23545;&#22522;&#32447;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04182v1 Announce Type: cross  Abstract: Large language models (LLMs) have demonstrated strong results on a range of NLP tasks. Typically, outputs are obtained via autoregressive sampling from the LLM's underlying distribution. We show that this inference strategy can be suboptimal for a range of tasks and associated evaluation metrics. As a remedy, we propose metric aware LLM inference: a decision theoretic approach optimizing for custom metrics at inference time. We report improvements over baselines on academic benchmarks and publicly available models.
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#24067;&#24335;&#20581;&#22766;&#24230;&#37327;&#65288;DRM&#65289;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#36873;&#25321;&#29702;&#24819;&#22240;&#26524;&#25512;&#26029;&#27169;&#22411;&#20013;&#20581;&#22766;&#20272;&#35745;&#22120;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.18392</link><description>&lt;p&gt;
&#25581;&#31034;&#20581;&#22766;&#24615;&#22312;&#35780;&#20272;&#22240;&#26524;&#25512;&#26029;&#27169;&#22411;&#20013;&#30340;&#28508;&#21147;
&lt;/p&gt;
&lt;p&gt;
Unveiling the Potential of Robustness in Evaluating Causal Inference Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18392
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#24067;&#24335;&#20581;&#22766;&#24230;&#37327;&#65288;DRM&#65289;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#36873;&#25321;&#29702;&#24819;&#22240;&#26524;&#25512;&#26029;&#27169;&#22411;&#20013;&#20581;&#22766;&#20272;&#35745;&#22120;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36234;&#26469;&#36234;&#22810;&#23545;&#20010;&#24615;&#21270;&#20915;&#31574;&#21046;&#23450;&#30340;&#38656;&#27714;&#23548;&#33268;&#20154;&#20204;&#23545;&#20272;&#35745;&#26465;&#20214;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;CATE&#65289;&#20135;&#29983;&#20102;&#20852;&#36259;&#12290;&#26426;&#22120;&#23398;&#20064;&#21644;&#22240;&#26524;&#25512;&#26029;&#30340;&#20132;&#21449;&#39046;&#22495;&#24050;&#32463;&#20135;&#29983;&#20102;&#21508;&#31181;&#26377;&#25928;&#30340;CATE&#20272;&#35745;&#22120;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#20351;&#29992;&#36825;&#20123;&#20272;&#35745;&#22120;&#36890;&#24120;&#21463;&#21046;&#20110;&#32570;&#20047;&#21453;&#20107;&#23454;&#26631;&#31614;&#65292;&#22240;&#27492;&#20351;&#29992;&#20256;&#32479;&#30340;&#20132;&#21449;&#39564;&#35777;&#31561;&#27169;&#22411;&#36873;&#25321;&#31243;&#24207;&#26469;&#36873;&#25321;&#29702;&#24819;&#30340;CATE&#20272;&#35745;&#22120;&#21464;&#24471;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#29616;&#26377;&#30340;CATE&#20272;&#35745;&#22120;&#36873;&#25321;&#26041;&#27861;&#65292;&#22914;&#25554;&#20540;&#21644;&#20266;&#32467;&#26524;&#24230;&#37327;&#65292;&#38754;&#20020;&#30528;&#20004;&#20010;&#22266;&#26377;&#25361;&#25112;&#12290;&#39318;&#20808;&#65292;&#23427;&#20204;&#38656;&#35201;&#30830;&#23450;&#24230;&#37327;&#24418;&#24335;&#21644;&#25311;&#21512;&#24178;&#25200;&#21442;&#25968;&#25110;&#25554;&#20214;&#23398;&#20064;&#32773;&#30340;&#22522;&#30784;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#12290;&#20854;&#27425;&#65292;&#23427;&#20204;&#32570;&#20047;&#38024;&#23545;&#36873;&#25321;&#20581;&#22766;&#20272;&#35745;&#22120;&#30340;&#29305;&#23450;&#37325;&#28857;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#20998;&#24067;&#24335;&#20581;&#22766;&#24230;&#37327;&#65288;DRM&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18392v1 Announce Type: cross  Abstract: The growing demand for personalized decision-making has led to a surge of interest in estimating the Conditional Average Treatment Effect (CATE). The intersection of machine learning and causal inference has yielded various effective CATE estimators. However, deploying these estimators in practice is often hindered by the absence of counterfactual labels, making it challenging to select the desirable CATE estimator using conventional model selection procedures like cross-validation. Existing approaches for CATE estimator selection, such as plug-in and pseudo-outcome metrics, face two inherent challenges. Firstly, they are required to determine the metric form and the underlying machine learning models for fitting nuisance parameters or plug-in learners. Secondly, they lack a specific focus on selecting a robust estimator. To address these challenges, this paper introduces a novel approach, the Distributionally Robust Metric (DRM), for 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#31163;&#32447;&#25968;&#25454;&#20013;&#31471;&#21040;&#31471;&#22320;&#24378;&#21270;&#23398;&#20064;&#40657;&#30418;&#20248;&#21270;&#31639;&#27861;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#34920;&#36798;&#33021;&#21147;&#24378;&#30340;&#24207;&#21015;&#27169;&#22411;&#21644;&#21518;&#24724;-&#21069;&#36827;&#20196;&#29260;&#26469;&#33719;&#21462;&#20219;&#21153;&#20449;&#24687;&#24182;&#20570;&#20986;&#20915;&#31574;&#12290;</title><link>https://arxiv.org/abs/2402.17423</link><description>&lt;p&gt;
&#21152;&#24378;&#19978;&#19979;&#25991;&#40657;&#30418;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Reinforced In-Context Black-Box Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17423
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#31163;&#32447;&#25968;&#25454;&#20013;&#31471;&#21040;&#31471;&#22320;&#24378;&#21270;&#23398;&#20064;&#40657;&#30418;&#20248;&#21270;&#31639;&#27861;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#34920;&#36798;&#33021;&#21147;&#24378;&#30340;&#24207;&#21015;&#27169;&#22411;&#21644;&#21518;&#24724;-&#21069;&#36827;&#20196;&#29260;&#26469;&#33719;&#21462;&#20219;&#21153;&#20449;&#24687;&#24182;&#20570;&#20986;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#40657;&#30418;&#20248;&#21270;&#65288;BBO&#65289;&#24050;&#32463;&#22312;&#35768;&#22810;&#31185;&#23398;&#21644;&#24037;&#31243;&#39046;&#22495;&#21462;&#24471;&#25104;&#21151;&#24212;&#29992;&#12290;&#26368;&#36817;&#65292;&#20154;&#20204;&#36234;&#26469;&#36234;&#20851;&#27880;&#20803;&#23398;&#20064;BBO&#31639;&#27861;&#30340;&#29305;&#23450;&#32452;&#20214;&#65292;&#20197;&#21152;&#24555;&#20248;&#21270;&#36895;&#24230;&#24182;&#25670;&#33073;&#32321;&#29712;&#30340;&#25163;&#24037;&#21551;&#21457;&#24335;&#31639;&#27861;&#12290;&#20316;&#20026;&#25193;&#23637;&#65292;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#25972;&#20010;&#31639;&#27861;&#38656;&#35201;&#19987;&#23478;&#26368;&#23569;&#30340;&#24037;&#20316;&#37327;&#65292;&#24182;&#19988;&#21487;&#20197;&#25552;&#20379;&#26368;&#22823;&#30340;&#28789;&#27963;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;RIBBO&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#20197;&#31471;&#21040;&#31471;&#30340;&#26041;&#24335;&#20174;&#31163;&#32447;&#25968;&#25454;&#20013;&#24378;&#21270;&#23398;&#20064;BBO&#31639;&#27861;&#12290;RIBBO&#21033;&#29992;&#34920;&#36798;&#33021;&#21147;&#24378;&#30340;&#24207;&#21015;&#27169;&#22411;&#26469;&#23398;&#20064;&#22810;&#20010;&#34892;&#20026;&#31639;&#27861;&#21644;&#20219;&#21153;&#20135;&#29983;&#30340;&#20248;&#21270;&#21382;&#21490;&#65292;&#21033;&#29992;&#22823;&#22411;&#27169;&#22411;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#33021;&#21147;&#26469;&#25552;&#21462;&#20219;&#21153;&#20449;&#24687;&#24182;&#30456;&#24212;&#22320;&#20570;&#20986;&#20915;&#31574;&#12290;&#25105;&#20204;&#26041;&#27861;&#30340;&#26680;&#24515;&#26159;&#36890;&#36807;&#22686;&#21152;&#21518;&#24724;-&#21069;&#36827;&#20196;&#29260;&#26469;&#22686;&#24378;&#20248;&#21270;&#21382;&#21490;&#65292;&#36825;&#20123;&#20196;&#29260;&#26088;&#22312;&#22522;&#20110;&#32047;&#31215;&#34920;&#29616;&#26469;&#34920;&#31034;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17423v1 Announce Type: cross  Abstract: Black-Box Optimization (BBO) has found successful applications in many fields of science and engineering. Recently, there has been a growing interest in meta-learning particular components of BBO algorithms to speed up optimization and get rid of tedious hand-crafted heuristics. As an extension, learning the entire algorithm from data requires the least labor from experts and can provide the most flexibility. In this paper, we propose RIBBO, a method to reinforce-learn a BBO algorithm from offline data in an end-to-end fashion. RIBBO employs expressive sequence models to learn the optimization histories produced by multiple behavior algorithms and tasks, leveraging the in-context learning ability of large models to extract task information and make decisions accordingly. Central to our method is to augment the optimization histories with regret-to-go tokens, which are designed to represent the performance of an algorithm based on cumul
&lt;/p&gt;</description></item><item><title>&#22312;&#19968;&#20010;&#37325;&#22797;&#30340;&#36125;&#21494;&#26031;&#35828;&#26381;&#38382;&#39064;&#20013;&#65292;&#21363;&#20351;&#27809;&#26377;&#25215;&#35834;&#33021;&#21147;&#65292;&#22996;&#25176;&#20154;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#19978;&#19979;&#25991;&#26080;&#36951;&#25022;&#23398;&#20064;&#31639;&#27861;&#26469;&#23454;&#29616;&#19982;&#32463;&#20856;&#26080;&#23398;&#20064;&#27169;&#22411;&#20013;&#20855;&#26377;&#25215;&#35834;&#30340;&#22996;&#25176;&#20154;&#30340;&#26368;&#20248;&#25928;&#29992;&#26080;&#38480;&#25509;&#36817;&#30340;&#25928;&#26524;&#65307;&#22312;&#20195;&#29702;&#20154;&#20351;&#29992;&#19978;&#19979;&#25991;&#26080;&#20132;&#25442;&#36951;&#25022;&#23398;&#20064;&#31639;&#27861;&#30340;&#24773;&#20917;&#19979;&#65292;&#22996;&#25176;&#20154;&#26080;&#27861;&#33719;&#24471;&#27604;&#20855;&#26377;&#25215;&#35834;&#30340;&#26080;&#23398;&#20064;&#27169;&#22411;&#20013;&#30340;&#26368;&#20248;&#25928;&#29992;&#26356;&#39640;&#30340;&#25928;&#29992;&#12290;</title><link>https://arxiv.org/abs/2402.09721</link><description>&lt;p&gt;
&#35828;&#26381;&#19968;&#20301;&#23398;&#20064;&#20195;&#29702;
&lt;/p&gt;
&lt;p&gt;
Persuading a Learning Agent
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09721
&lt;/p&gt;
&lt;p&gt;
&#22312;&#19968;&#20010;&#37325;&#22797;&#30340;&#36125;&#21494;&#26031;&#35828;&#26381;&#38382;&#39064;&#20013;&#65292;&#21363;&#20351;&#27809;&#26377;&#25215;&#35834;&#33021;&#21147;&#65292;&#22996;&#25176;&#20154;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#19978;&#19979;&#25991;&#26080;&#36951;&#25022;&#23398;&#20064;&#31639;&#27861;&#26469;&#23454;&#29616;&#19982;&#32463;&#20856;&#26080;&#23398;&#20064;&#27169;&#22411;&#20013;&#20855;&#26377;&#25215;&#35834;&#30340;&#22996;&#25176;&#20154;&#30340;&#26368;&#20248;&#25928;&#29992;&#26080;&#38480;&#25509;&#36817;&#30340;&#25928;&#26524;&#65307;&#22312;&#20195;&#29702;&#20154;&#20351;&#29992;&#19978;&#19979;&#25991;&#26080;&#20132;&#25442;&#36951;&#25022;&#23398;&#20064;&#31639;&#27861;&#30340;&#24773;&#20917;&#19979;&#65292;&#22996;&#25176;&#20154;&#26080;&#27861;&#33719;&#24471;&#27604;&#20855;&#26377;&#25215;&#35834;&#30340;&#26080;&#23398;&#20064;&#27169;&#22411;&#20013;&#30340;&#26368;&#20248;&#25928;&#29992;&#26356;&#39640;&#30340;&#25928;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#37325;&#22797;&#30340;&#36125;&#21494;&#26031;&#35828;&#26381;&#38382;&#39064;&#65288;&#26356;&#19968;&#33324;&#22320;&#65292;&#20219;&#20309;&#20855;&#26377;&#23436;&#20840;&#20449;&#24687;&#30340;&#24191;&#20041;&#22996;&#25176;-&#20195;&#29702;&#38382;&#39064;&#65289;&#65292;&#20854;&#20013;&#22996;&#25176;&#20154;&#27809;&#26377;&#25215;&#35834;&#33021;&#21147;&#65292;&#20195;&#29702;&#20154;&#20351;&#29992;&#31639;&#27861;&#26469;&#23398;&#20064;&#22914;&#20309;&#23545;&#22996;&#25176;&#20154;&#30340;&#20449;&#21495;&#20570;&#20986;&#21709;&#24212;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#38382;&#39064;&#31616;&#21270;&#20026;&#19968;&#20010;&#19968;&#27425;&#24615;&#30340;&#24191;&#20041;&#22996;&#25176;-&#20195;&#29702;&#38382;&#39064;&#65292;&#20195;&#29702;&#20154;&#36817;&#20284;&#22320;&#26368;&#20339;&#21709;&#24212;&#12290;&#36890;&#36807;&#36825;&#20010;&#31616;&#21270;&#65292;&#25105;&#20204;&#21487;&#20197;&#35777;&#26126;&#65306;&#22914;&#26524;&#20195;&#29702;&#20154;&#20351;&#29992;&#19978;&#19979;&#25991;&#26080;&#36951;&#25022;&#23398;&#20064;&#31639;&#27861;&#65292;&#21017;&#22996;&#25176;&#20154;&#21487;&#20197;&#20445;&#35777;&#20854;&#25928;&#29992;&#19982;&#32463;&#20856;&#26080;&#23398;&#20064;&#27169;&#22411;&#20013;&#20855;&#26377;&#25215;&#35834;&#30340;&#22996;&#25176;&#20154;&#30340;&#26368;&#20248;&#25928;&#29992;&#20043;&#38388;&#21487;&#20197;&#26080;&#38480;&#25509;&#36817;&#65307;&#22914;&#26524;&#20195;&#29702;&#20154;&#20351;&#29992;&#19978;&#19979;&#25991;&#26080;&#20132;&#25442;&#36951;&#25022;&#23398;&#20064;&#31639;&#27861;&#65292;&#21017;&#22996;&#25176;&#20154;&#26080;&#27861;&#33719;&#24471;&#27604;&#20855;&#26377;&#25215;&#35834;&#30340;&#26080;&#23398;&#20064;&#27169;&#22411;&#20013;&#30340;&#26368;&#20248;&#25928;&#29992;&#26356;&#39640;&#30340;&#25928;&#29992;&#12290;&#22996;&#25176;&#20154;&#22312;&#23398;&#20064;&#27169;&#22411;&#19982;&#38750;&#23398;&#20064;&#27169;&#22411;&#20013;&#21487;&#20197;&#33719;&#24471;&#30340;&#25928;&#29992;&#20043;&#38388;&#30340;&#24046;&#36317;&#26159;&#26377;&#30028;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09721v1 Announce Type: cross  Abstract: We study a repeated Bayesian persuasion problem (and more generally, any generalized principal-agent problem with complete information) where the principal does not have commitment power and the agent uses algorithms to learn to respond to the principal's signals. We reduce this problem to a one-shot generalized principal-agent problem with an approximately-best-responding agent. This reduction allows us to show that: if the agent uses contextual no-regret learning algorithms, then the principal can guarantee a utility that is arbitrarily close to the principal's optimal utility in the classic non-learning model with commitment; if the agent uses contextual no-swap-regret learning algorithms, then the principal cannot obtain any utility significantly more than the optimal utility in the non-learning model with commitment. The difference between the principal's obtainable utility in the learning model and the non-learning model is bound
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;InfoRM&#30340;&#22870;&#21169;&#24314;&#27169;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#21464;&#20998;&#20449;&#24687;&#29942;&#39048;&#30446;&#26631;&#21644;&#27169;&#22411;&#22797;&#26434;&#24230;&#35843;&#33410;&#26426;&#21046;&#65292;&#35299;&#20915;&#20102;&#22870;&#21169;&#20316;&#24330;&#38382;&#39064;&#65292;&#24182;&#21033;&#29992;&#38598;&#25104;&#32858;&#31867;&#20559;&#24046;&#24471;&#20998;&#65288;ICDS&#65289;&#26469;&#26816;&#27979;&#22870;&#21169;&#36807;&#24230;&#20248;&#21270;&#12290;</title><link>https://arxiv.org/abs/2402.09345</link><description>&lt;p&gt;
&#36890;&#36807;&#20449;&#24687;&#35770;&#22870;&#21169;&#24314;&#27169;&#26469;&#20943;&#36731;&#22870;&#21169;&#20316;&#24330;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Mitigating Reward Hacking via Information-Theoretic Reward Modeling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09345
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;InfoRM&#30340;&#22870;&#21169;&#24314;&#27169;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#21464;&#20998;&#20449;&#24687;&#29942;&#39048;&#30446;&#26631;&#21644;&#27169;&#22411;&#22797;&#26434;&#24230;&#35843;&#33410;&#26426;&#21046;&#65292;&#35299;&#20915;&#20102;&#22870;&#21169;&#20316;&#24330;&#38382;&#39064;&#65292;&#24182;&#21033;&#29992;&#38598;&#25104;&#32858;&#31867;&#20559;&#24046;&#24471;&#20998;&#65288;ICDS&#65289;&#26469;&#26816;&#27979;&#22870;&#21169;&#36807;&#24230;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#24378;&#21270;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#65288;RLHF&#65289;&#20013;&#30340;&#25104;&#21151;&#22312;&#19982;&#20154;&#31867;&#20215;&#20540;&#35266;&#30340;&#35821;&#35328;&#27169;&#22411;&#30340;&#23545;&#40784;&#26041;&#38754;&#65292;&#22870;&#21169;&#20316;&#24330;&#38382;&#39064;&#65292;&#20063;&#34987;&#31216;&#20026;&#22870;&#21169;&#36807;&#24230;&#20248;&#21270;&#65292;&#20173;&#28982;&#26159;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#65292;&#20027;&#35201;&#28304;&#20110;&#22870;&#21169;&#24314;&#27169;&#30340;&#23616;&#38480;&#24615;&#65292;&#21363;&#22870;&#21169;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#21644;&#20559;&#22909;&#25968;&#25454;&#38598;&#30340;&#19981;&#19968;&#33268;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20174;&#20449;&#24687;&#35770;&#30340;&#35270;&#35282;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25512;&#24191;&#21644;&#40065;&#26834;&#30340;&#22870;&#21169;&#24314;&#27169;&#26694;&#26550;&#65292;&#31216;&#20026;InfoRM&#65292;&#36890;&#36807;&#24341;&#20837;&#21464;&#20998;&#20449;&#24687;&#29942;&#39048;&#30446;&#26631;&#26469;&#36807;&#28388;&#20986;&#19981;&#30456;&#20851;&#30340;&#20449;&#24687;&#65292;&#24182;&#24320;&#21457;&#19968;&#31181;&#27169;&#22411;&#22797;&#26434;&#24230;&#35843;&#33410;&#26426;&#21046;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#21457;&#29616;&#20102;&#36807;&#24230;&#20248;&#21270;&#19982;&#28508;&#21464;&#37327;&#31354;&#38388;&#30340;&#24322;&#24120;&#20540;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#23558;InfoRM&#20316;&#20026;&#26816;&#27979;&#22870;&#21169;&#36807;&#24230;&#20248;&#21270;&#30340;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#24037;&#20855;&#12290;&#21463;&#21040;&#36825;&#19968;&#21457;&#29616;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#38598;&#25104;&#32858;&#31867;&#20559;&#24046;&#24471;&#20998;&#65288;ICDS&#65289;&#65292;&#29992;&#20110;&#37327;&#21270;&#36807;&#20248;&#21270;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09345v1 Announce Type: cross Abstract: Despite the success of reinforcement learning from human feedback (RLHF) in aligning language models with human values, reward hacking, also termed reward overoptimization, remains a critical challenge, which primarily stems from limitations in reward modeling, i.e., generalizability of the reward model and inconsistency in the preference dataset. In this work, we tackle this problem from an information theoretic-perspective, and propose a generalizable and robust framework for reward modeling, namely InfoRM, by introducing a variational information bottleneck objective to filter out irrelevant information and developing a mechanism for model complexity modulation. Notably, we further identify a correlation between overoptimization and outliers in the latent space, establishing InfoRM as a promising tool for detecting reward overoptimization. Inspired by this finding, we propose the Integrated Cluster Deviation Score (ICDS), which quant
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23637;&#31034;&#20102;&#36890;&#36807;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#30340;&#25512;&#36827;&#35745;&#31639;&#21487;&#20197;&#35745;&#31639;&#20219;&#20309;&#21487;&#36776;&#35782;&#30340;&#22240;&#26524;&#25928;&#24212;&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;&#25193;&#25955;&#30340;&#26041;&#27861;&#29992;&#20110;&#20174;&#22270;&#20687;&#30340;&#20219;&#20309;&#65288;&#26465;&#20214;&#65289;&#24178;&#39044;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;</title><link>https://arxiv.org/abs/2402.07419</link><description>&lt;p&gt;
&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#36275;&#20197;&#20174;&#20219;&#20309;&#22240;&#26524;&#25928;&#24212;&#27979;&#24230;&#20013;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Conditional Generative Models are Sufficient to Sample from Any Causal Effect Estimand
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07419
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23637;&#31034;&#20102;&#36890;&#36807;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#30340;&#25512;&#36827;&#35745;&#31639;&#21487;&#20197;&#35745;&#31639;&#20219;&#20309;&#21487;&#36776;&#35782;&#30340;&#22240;&#26524;&#25928;&#24212;&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;&#25193;&#25955;&#30340;&#26041;&#27861;&#29992;&#20110;&#20174;&#22270;&#20687;&#30340;&#20219;&#20309;&#65288;&#26465;&#20214;&#65289;&#24178;&#39044;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#20174;&#35266;&#27979;&#25968;&#25454;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#24471;&#21040;&#20102;&#24191;&#27867;&#24212;&#29992;&#12290;&#34429;&#28982;&#23384;&#22312;&#35745;&#31639;&#22240;&#26524;&#25928;&#24212;&#30340;&#21487;&#38752;&#19988;&#23436;&#22791;&#30340;&#31639;&#27861;&#65292;&#20294;&#20854;&#20013;&#35768;&#22810;&#31639;&#27861;&#38656;&#35201;&#26174;&#24335;&#35775;&#38382;&#35266;&#27979;&#20998;&#24067;&#19978;&#30340;&#26465;&#20214;&#20284;&#28982;&#65292;&#32780;&#22312;&#39640;&#32500;&#22330;&#26223;&#20013;&#65288;&#20363;&#22914;&#22270;&#20687;&#65289;&#65292;&#20272;&#35745;&#36825;&#20123;&#20284;&#28982;&#26159;&#22256;&#38590;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#30740;&#31350;&#20154;&#21592;&#36890;&#36807;&#20351;&#29992;&#31070;&#32463;&#27169;&#22411;&#27169;&#25311;&#22240;&#26524;&#20851;&#31995;&#65292;&#24182;&#21462;&#24471;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#29616;&#26377;&#26041;&#27861;&#20013;&#27809;&#26377;&#19968;&#20010;&#21487;&#20197;&#24212;&#29992;&#20110;&#36890;&#29992;&#22330;&#26223;&#65292;&#20363;&#22914;&#20855;&#26377;&#28508;&#22312;&#28151;&#28102;&#22240;&#32032;&#30340;&#22270;&#20687;&#25968;&#25454;&#30340;&#22240;&#26524;&#22270;&#65292;&#25110;&#32773;&#33719;&#24471;&#26465;&#20214;&#24178;&#39044;&#26679;&#26412;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#20219;&#24847;&#22240;&#26524;&#22270;&#19979;&#65292;&#36890;&#36807;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#30340;&#25512;&#36827;&#35745;&#31639;&#21487;&#20197;&#35745;&#31639;&#20219;&#20309;&#21487;&#36776;&#35782;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#22522;&#20110;&#27492;&#32467;&#26524;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#22522;&#20110;&#25193;&#25955;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#20174;&#20219;&#20309;&#65288;&#26465;&#20214;&#65289;&#24178;&#39044;&#20998;&#24067;&#20013;&#37319;&#26679;&#22270;&#20687;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal inference from observational data has recently found many applications in machine learning. While sound and complete algorithms exist to compute causal effects, many of these algorithms require explicit access to conditional likelihoods over the observational distribution, which is difficult to estimate in the high-dimensional regime, such as with images. To alleviate this issue, researchers have approached the problem by simulating causal relations with neural models and obtained impressive results. However, none of these existing approaches can be applied to generic scenarios such as causal graphs on image data with latent confounders, or obtain conditional interventional samples. In this paper, we show that any identifiable causal effect given an arbitrary causal graph can be computed through push-forward computations of conditional generative models. Based on this result, we devise a diffusion-based approach to sample from any (conditional) interventional distribution on ima
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26641;&#38598;&#25104;&#30340;&#24773;&#22659;&#22810;&#33218;&#32769;&#34382;&#26426;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#25972;&#21512;&#20004;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#32769;&#34382;&#26426;&#26041;&#27861;&#65292;&#22312;&#26631;&#20934;&#21644;&#32452;&#21512;&#35774;&#32622;&#20013;&#23454;&#29616;&#20102;&#20248;&#20110;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#30340;&#24615;&#33021;&#65292;&#22312;&#20943;&#23569;&#21518;&#24724;&#21644;&#35745;&#31639;&#26102;&#38388;&#26041;&#38754;&#34920;&#29616;&#20986;&#26356;&#20986;&#33394;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.06963</link><description>&lt;p&gt;
&#22522;&#20110;&#26641;&#38598;&#25104;&#30340;&#24773;&#22659;&#22810;&#33218;&#32769;&#34382;&#26426;
&lt;/p&gt;
&lt;p&gt;
Tree Ensembles for Contextual Bandits
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06963
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26641;&#38598;&#25104;&#30340;&#24773;&#22659;&#22810;&#33218;&#32769;&#34382;&#26426;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#25972;&#21512;&#20004;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#32769;&#34382;&#26426;&#26041;&#27861;&#65292;&#22312;&#26631;&#20934;&#21644;&#32452;&#21512;&#35774;&#32622;&#20013;&#23454;&#29616;&#20102;&#20248;&#20110;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#30340;&#24615;&#33021;&#65292;&#22312;&#20943;&#23569;&#21518;&#24724;&#21644;&#35745;&#31639;&#26102;&#38388;&#26041;&#38754;&#34920;&#29616;&#20986;&#26356;&#20986;&#33394;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#26641;&#38598;&#25104;&#30340;&#24773;&#22659;&#22810;&#33218;&#32769;&#34382;&#26426;&#30340;&#26032;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#23558;&#20004;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#32769;&#34382;&#26426;&#26041;&#27861;&#65292;&#19978;&#20449;&#24515;&#30028;&#21644;&#27748;&#26222;&#26862;&#25277;&#26679;&#65292;&#25972;&#21512;&#21040;&#26631;&#20934;&#21644;&#32452;&#21512;&#35774;&#32622;&#20013;&#12290;&#36890;&#36807;&#20351;&#29992;&#27969;&#34892;&#30340;&#26641;&#38598;&#25104;&#26041;&#27861;XGBoost&#36827;&#34892;&#22810;&#27425;&#23454;&#39564;&#30740;&#31350;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;&#12290;&#24403;&#24212;&#29992;&#20110;&#22522;&#20934;&#25968;&#25454;&#38598;&#21644;&#36947;&#36335;&#32593;&#32476;&#23548;&#33322;&#30340;&#30495;&#23454;&#19990;&#30028;&#24212;&#29992;&#26102;&#65292;&#19982;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20943;&#23569;&#21518;&#24724;&#21644;&#35745;&#31639;&#26102;&#38388;&#26041;&#38754;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel framework for contextual multi-armed bandits based on tree ensembles. Our framework integrates two widely used bandit methods, Upper Confidence Bound and Thompson Sampling, for both standard and combinatorial settings. We demonstrate the effectiveness of our framework via several experimental studies, employing XGBoost, a popular tree ensemble method. Compared to state-of-the-art methods based on neural networks, our methods exhibit superior performance in terms of both regret minimization and computational runtime, when applied to benchmark datasets and the real-world application of navigation over road networks.
&lt;/p&gt;</description></item><item><title>&#22823;&#35821;&#35328;&#27169;&#22411;&#20195;&#29702;&#33021;&#22815;&#27169;&#25311;&#20154;&#31867;&#30340;&#20449;&#20219;&#34892;&#20026;&#65292;&#34920;&#29616;&#20986;&#22312;&#20449;&#20219;&#28216;&#25103;&#20013;&#30340;&#20449;&#20219;&#34892;&#20026;&#65292;&#24182;&#19988;&#19982;&#20154;&#31867;&#34892;&#20026;&#20855;&#26377;&#39640;&#24230;&#19968;&#33268;&#24615;&#65292;&#20294;&#23384;&#22312;&#19968;&#20123;&#20559;&#35265;&#21644;&#23545;&#20195;&#29702;&#19982;&#20154;&#31867;&#30340;&#24046;&#24322;&#12290;</title><link>https://arxiv.org/abs/2402.04559</link><description>&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;&#20195;&#29702;&#33021;&#22815;&#27169;&#25311;&#20154;&#31867;&#30340;&#20449;&#20219;&#34892;&#20026;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can Large Language Model Agents Simulate Human Trust Behaviors?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04559
&lt;/p&gt;
&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;&#20195;&#29702;&#33021;&#22815;&#27169;&#25311;&#20154;&#31867;&#30340;&#20449;&#20219;&#34892;&#20026;&#65292;&#34920;&#29616;&#20986;&#22312;&#20449;&#20219;&#28216;&#25103;&#20013;&#30340;&#20449;&#20219;&#34892;&#20026;&#65292;&#24182;&#19988;&#19982;&#20154;&#31867;&#34892;&#20026;&#20855;&#26377;&#39640;&#24230;&#19968;&#33268;&#24615;&#65292;&#20294;&#23384;&#22312;&#19968;&#20123;&#20559;&#35265;&#21644;&#23545;&#20195;&#29702;&#19982;&#20154;&#31867;&#30340;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20195;&#29702;&#24050;&#32463;&#36234;&#26469;&#36234;&#22810;&#22320;&#34987;&#37319;&#29992;&#20316;&#20026;&#27169;&#25311;&#24037;&#20855;&#65292;&#29992;&#20110;&#27169;&#25311;&#20154;&#31867;&#22312;&#31038;&#20250;&#31185;&#23398;&#31561;&#39046;&#22495;&#20013;&#30340;&#34892;&#20026;&#12290;&#28982;&#32780;&#65292;&#19968;&#20010;&#22522;&#26412;&#30340;&#38382;&#39064;&#20173;&#28982;&#23384;&#22312;&#65306;LLM&#20195;&#29702;&#26159;&#21542;&#30495;&#30340;&#33021;&#22815;&#27169;&#25311;&#20154;&#31867;&#34892;&#20026;&#65311;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#20154;&#31867;&#20114;&#21160;&#20013;&#26368;&#20851;&#38190;&#30340;&#34892;&#20026;&#20043;&#19968;&#65292;&#20449;&#20219;&#65292;&#26088;&#22312;&#35843;&#26597;LLM&#20195;&#29702;&#26159;&#21542;&#33021;&#22815;&#27169;&#25311;&#20154;&#31867;&#30340;&#20449;&#20219;&#34892;&#20026;&#12290;&#25105;&#20204;&#39318;&#20808;&#21457;&#29616;&#65292;&#22312;&#34987;&#34892;&#20026;&#32463;&#27982;&#23398;&#24191;&#27867;&#25509;&#21463;&#30340;&#20449;&#20219;&#28216;&#25103;&#26694;&#26550;&#19979;&#65292;LLM&#20195;&#29702;&#36890;&#24120;&#34920;&#29616;&#20986;&#20449;&#20219;&#34892;&#20026;&#65292;&#31216;&#20026;&#20195;&#29702;&#20449;&#20219;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#21457;&#29616;LLM&#20195;&#29702;&#22312;&#20449;&#20219;&#34892;&#20026;&#26041;&#38754;&#19982;&#20154;&#31867;&#20855;&#26377;&#36739;&#39640;&#30340;&#34892;&#20026;&#19968;&#33268;&#24615;&#65292;&#34920;&#26126;&#20351;&#29992;LLM&#20195;&#29702;&#27169;&#25311;&#20154;&#31867;&#30340;&#20449;&#20219;&#34892;&#20026;&#26159;&#21487;&#34892;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25506;&#32034;&#20102;&#20195;&#29702;&#20449;&#20219;&#20013;&#30340;&#20559;&#35265;&#20197;&#21450;&#20195;&#29702;&#20449;&#20219;&#22312;&#23545;&#20195;&#29702;&#21644;&#20154;&#31867;&#20043;&#38388;&#30340;&#24046;&#24322;&#26041;&#38754;&#30340;&#20869;&#22312;&#29305;&#24615;&#12290;&#25105;&#20204;&#36824;&#25506;&#35752;&#20102;&#21253;&#25324;&#39640;&#32423;&#25512;&#29702;&#31574;&#30053;&#22312;&#20869;&#30340;&#26465;&#20214;&#19979;&#20195;&#29702;&#20449;&#20219;&#30340;&#20869;&#22312;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Model (LLM) agents have been increasingly adopted as simulation tools to model humans in applications such as social science. However, one fundamental question remains: can LLM agents really simulate human behaviors? In this paper, we focus on one of the most critical behaviors in human interactions, trust, and aim to investigate whether or not LLM agents can simulate human trust behaviors. We first find that LLM agents generally exhibit trust behaviors, referred to as agent trust, under the framework of Trust Games, which are widely recognized in behavioral economics. Then, we discover that LLM agents can have high behavioral alignment with humans regarding trust behaviors, indicating the feasibility to simulate human trust behaviors with LLM agents. In addition, we probe into the biases in agent trust and the differences in agent trust towards agents and humans. We also explore the intrinsic properties of agent trust under conditions including advanced reasoning strate
&lt;/p&gt;</description></item><item><title>Neur2BiLO&#26159;&#19968;&#20010;&#38024;&#23545;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#31070;&#32463;&#32593;&#32476;&#36817;&#20284;&#24341;&#20837;&#21040;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#20013;&#65292;&#21487;&#20197;&#24555;&#36895;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>https://arxiv.org/abs/2402.02552</link><description>&lt;p&gt;
Neur2BiLO: &#31070;&#32463;&#21452;&#23618;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Neur2BiLO: Neural Bilevel Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02552
&lt;/p&gt;
&lt;p&gt;
Neur2BiLO&#26159;&#19968;&#20010;&#38024;&#23545;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#31070;&#32463;&#32593;&#32476;&#36817;&#20284;&#24341;&#20837;&#21040;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#20013;&#65292;&#21487;&#20197;&#24555;&#36895;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21452;&#23618;&#20248;&#21270;&#22788;&#29702;&#23884;&#22871;&#38382;&#39064;&#65292;&#22312;&#36825;&#20123;&#38382;&#39064;&#20013;&#65292;&#39046;&#23548;&#32773;&#39318;&#20808;&#20570;&#20986;&#20915;&#31574;&#20197;&#26368;&#23567;&#21270;&#33258;&#24049;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#21516;&#26102;&#32771;&#34385;&#21040;&#36861;&#38543;&#32773;&#30340;&#26368;&#22909;&#21453;&#24212;&#12290;&#25972;&#25968;&#21464;&#37327;&#32422;&#26463;&#30340;&#21452;&#23618;&#38382;&#39064;&#29305;&#21035;&#38590;&#20197;&#22788;&#29702;&#12290;&#23613;&#31649;&#24050;&#32463;&#25552;&#20986;&#20102;&#29992;&#20110;&#28151;&#21512;&#25972;&#25968;&#32447;&#24615;&#21452;&#23618;&#20248;&#21270;&#30340;&#31934;&#30830;&#27714;&#35299;&#22120;&#65292;&#20294;&#23427;&#20204;&#22312;&#38382;&#39064;&#35268;&#27169;&#36739;&#22823;&#26102;&#24448;&#24448;&#26080;&#27861;&#25193;&#23637;&#65292;&#24182;&#19988;&#38590;&#20197;&#25512;&#24191;&#21040;&#38750;&#32447;&#24615;&#24773;&#20917;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#38382;&#39064;&#29305;&#23450;&#30340;&#31639;&#27861;&#65288;&#31934;&#30830;&#21644;&#21551;&#21457;&#24335;&#65289;&#23616;&#38480;&#20110;&#29305;&#23450;&#33539;&#22260;&#12290;&#22312;&#20197;&#25968;&#25454;&#39537;&#21160;&#30340;&#29615;&#22659;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;Neur2BiLO&#23558;&#36890;&#36807;&#30417;&#30563;&#22238;&#24402;&#35757;&#32451;&#30340;&#39046;&#23548;&#32773;&#25110;&#36861;&#38543;&#32773;&#30340;&#20540;&#20989;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#36817;&#20284;&#23884;&#20837;&#21040;&#26131;&#20110;&#35299;&#20915;&#30340;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#20013;&#12290; Neur2BiLO&#20316;&#20026;&#19968;&#31181;&#21551;&#21457;&#24335;&#31639;&#27861;&#65292;&#21487;&#20197;&#24555;&#36895;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36866;&#29992;&#20110;&#21452;&#23618;&#32972;&#21253;&#25318;&#25130;&#38382;&#39064;&#65292;&#21363;&#8220;&#20851;&#38190;n&#20010;&#38382;&#39064;&#8221;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bilevel optimization deals with nested problems in which a leader takes the first decision to minimize their objective function while accounting for a follower's best-response reaction. Constrained bilevel problems with integer variables are particularly notorious for their hardness. While exact solvers have been proposed for mixed-integer linear bilevel optimization, they tend to scale poorly with problem size and are hard to generalize to the non-linear case. On the other hand, problem-specific algorithms (exact and heuristic) are limited in scope. Under a data-driven setting in which similar instances of a bilevel problem are solved routinely, our proposed framework, Neur2BiLO, embeds a neural network approximation of the leader's or follower's value function, trained via supervised regression, into an easy-to-solve mixed-integer program. Neur2BiLO serves as a heuristic that produces high-quality solutions extremely fast for the bilevel knapsack interdiction problem, the "critical n
&lt;/p&gt;</description></item><item><title>&#26412;&#32508;&#36848;&#35770;&#25991;&#28145;&#20837;&#20998;&#26512;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#21521;&#37327;&#25968;&#25454;&#24211;&#20043;&#38388;&#30340;&#20132;&#21449;&#28857;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#31361;&#30772;&#24102;&#26469;&#20102;&#26032;&#30340;&#25361;&#25112;&#65292;&#32780;&#21521;&#37327;&#25968;&#25454;&#24211;&#25552;&#20379;&#20102;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#21487;&#20197;&#26174;&#33879;&#22686;&#24378;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#31649;&#29702;&#21644;&#21033;&#29992;&#22810;&#26679;&#25968;&#25454;&#30340;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.01763</link><description>&lt;p&gt;
&#24403;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36935;&#19978;&#21521;&#37327;&#25968;&#25454;&#24211;&#65306;&#19968;&#39033;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
When Large Language Models Meet Vector Databases: A Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01763
&lt;/p&gt;
&lt;p&gt;
&#26412;&#32508;&#36848;&#35770;&#25991;&#28145;&#20837;&#20998;&#26512;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#21521;&#37327;&#25968;&#25454;&#24211;&#20043;&#38388;&#30340;&#20132;&#21449;&#28857;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#31361;&#30772;&#24102;&#26469;&#20102;&#26032;&#30340;&#25361;&#25112;&#65292;&#32780;&#21521;&#37327;&#25968;&#25454;&#24211;&#25552;&#20379;&#20102;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#21487;&#20197;&#26174;&#33879;&#22686;&#24378;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#31649;&#29702;&#21644;&#21033;&#29992;&#22810;&#26679;&#25968;&#25454;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#31361;&#30772;&#22312;&#20154;&#31867;&#25991;&#23383;&#22788;&#29702;&#21644;&#29983;&#25104;&#26041;&#38754;&#24320;&#21551;&#20102;&#26032;&#30340;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#23427;&#20204;&#30340;&#26174;&#33879;&#22686;&#38271;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#38754;&#20020;&#30528;&#21253;&#25324;&#24187;&#35273;&#12289;&#20559;&#35265;&#12289;&#23454;&#26102;&#30693;&#35782;&#26356;&#26032;&#20197;&#21450;&#22312;&#21830;&#19994;&#29615;&#22659;&#20013;&#23454;&#26045;&#21644;&#32500;&#25252;&#30340;&#39640;&#25104;&#26412;&#31561;&#37325;&#35201;&#25361;&#25112;&#12290;&#32780;&#21478;&#19968;&#31181;&#26085;&#30410;&#27969;&#34892;&#30340;&#24037;&#20855;&#65292;&#21521;&#37327;&#25968;&#25454;&#24211;&#21017;&#20026;&#36825;&#20123;&#25361;&#25112;&#25552;&#20379;&#20102;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#36825;&#20123;&#25968;&#25454;&#24211;&#25797;&#38271;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#65292;&#24182;&#19988;&#23545;&#20110;&#39640;&#25928;&#30340;&#20449;&#24687;&#26816;&#32034;&#21644;&#35821;&#20041;&#25628;&#32034;&#31561;&#20219;&#21153;&#33267;&#20851;&#37325;&#35201;&#12290;&#36890;&#36807;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25972;&#21512;&#65292;&#23427;&#20204;&#26174;&#33879;&#22686;&#24378;&#20102;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#31649;&#29702;&#21644;&#26356;&#26377;&#25928;&#22320;&#21033;&#29992;&#22810;&#26679;&#25968;&#25454;&#30340;&#33021;&#21147;&#12290;&#26412;&#32508;&#36848;&#35770;&#25991;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#21521;&#37327;&#25968;&#25454;&#24211;&#20043;&#38388;&#30340;&#20132;&#21449;&#28857;&#36827;&#34892;&#20102;&#28145;&#20837;&#32780;&#29420;&#29305;&#30340;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
The recent burst in Large Language Models has opened new frontiers in human-like text processing and generation. However, alongside their remarkable growth, Large Language Models have encountered critical challenges including issues of hallucination, bias, real-time knowledge updates, and the high costs of implementation and maintenance in commercial settings. Vector Databases, another increasingly popular tool, offer potential solutions to these challenges. These databases are adept at handling high-dimensional data and are crucial for tasks such as efficient information retrieval and semantic search. By integrating with Large Language Models, they significantly enhance AI systems' ability to manage and utilize diverse data more effectively. This survey paper provides an in-depth and unique analysis of the intersection between Large Language Models and Vector Databases.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;AI&#22312;&#24651;&#29233;&#35299;&#20307;&#36807;&#31243;&#20013;&#30340;&#20316;&#29992;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#24403;&#21069;&#25216;&#26415;&#22312;&#20449;&#24687;&#25910;&#38598;&#12289;&#31038;&#32676;&#25903;&#25345;&#21644;&#20419;&#36827;&#27807;&#36890;&#26041;&#38754;&#21457;&#25381;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#21442;&#19982;&#32773;&#39044;&#35745;AI&#21487;&#20197;&#28385;&#36275;&#19981;&#21516;&#38454;&#27573;&#30340;&#38656;&#27714;&#65292;&#24110;&#21161;&#35299;&#20307;&#24651;&#24773;&#12290;</title><link>http://arxiv.org/abs/2401.09695</link><description>&lt;p&gt;
&#22312;&#32467;&#26463;&#24651;&#24773;&#36807;&#31243;&#20013;&#65292;ChatGPT&#26159;&#21542;&#24212;&#35813;&#26367;&#20320;&#20889;&#20998;&#25163;&#30701;&#20449;&#65311;&#25506;&#32034;AI&#22312;&#24651;&#29233;&#35299;&#20307;&#20013;&#30340;&#35282;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;
Should ChatGPT Write Your Breakup Text? Exploring the Role of AI in Relationship Dissolution. (arXiv:2401.09695v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09695
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;AI&#22312;&#24651;&#29233;&#35299;&#20307;&#36807;&#31243;&#20013;&#30340;&#20316;&#29992;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#24403;&#21069;&#25216;&#26415;&#22312;&#20449;&#24687;&#25910;&#38598;&#12289;&#31038;&#32676;&#25903;&#25345;&#21644;&#20419;&#36827;&#27807;&#36890;&#26041;&#38754;&#21457;&#25381;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#21442;&#19982;&#32773;&#39044;&#35745;AI&#21487;&#20197;&#28385;&#36275;&#19981;&#21516;&#38454;&#27573;&#30340;&#38656;&#27714;&#65292;&#24110;&#21161;&#35299;&#20307;&#24651;&#24773;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24651;&#29233;&#20851;&#31995;&#23545;&#25105;&#20204;&#30340;&#24184;&#31119;&#21644;&#24184;&#31119;&#24863;&#33267;&#20851;&#37325;&#35201;&#12290;&#24651;&#29233;&#35299;&#20307;&#26159;&#24651;&#29233;&#29983;&#21629;&#21608;&#26399;&#30340;&#26368;&#21518;&#38454;&#27573;&#65292;&#20063;&#26159;&#20010;&#20154;&#29983;&#27963;&#20013;&#26368;&#20855;&#21387;&#21147;&#30340;&#20107;&#20214;&#20043;&#19968;&#65292;&#21487;&#33021;&#23545;&#20154;&#20204;&#20135;&#29983;&#28145;&#36828;&#32780;&#25345;&#20037;&#30340;&#24433;&#21709;&#12290;&#38543;&#30528;&#36890;&#36807;&#35745;&#31639;&#26426;&#20171;&#36136;&#20256;&#36798;&#30340;&#35299;&#20307;&#36807;&#31243;&#36234;&#26469;&#36234;&#21463;&#21040;&#25903;&#25345;&#65292;&#20197;&#21450;AI&#20171;&#20837;&#30340;&#20256;&#25773;&#26041;&#24335;&#30340;&#21487;&#33021;&#26410;&#26469;&#24433;&#21709;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#39033;&#21322;&#32467;&#26500;&#21270;&#35775;&#35848;&#30740;&#31350;&#65292;&#20849;&#26377;21&#21517;&#21442;&#19982;&#32773;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#26088;&#22312;&#20102;&#35299;&#65306;1&#65289;&#25216;&#26415;&#22312;&#35299;&#20307;&#36807;&#31243;&#20013;&#30340;&#24403;&#21069;&#35282;&#33394;&#65292;2&#65289;&#20010;&#20154;&#22312;&#36807;&#31243;&#20013;&#30340;&#38656;&#27714;&#21644;&#25903;&#25345;&#65292;&#20197;&#21450;3&#65289;AI&#22914;&#20309;&#28385;&#36275;&#36825;&#20123;&#38656;&#27714;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#26174;&#31034;&#65292;&#20154;&#20204;&#22312;&#32467;&#26463;&#24651;&#24773;&#30340;&#19981;&#21516;&#38454;&#27573;&#26377;&#19981;&#21516;&#30340;&#38656;&#27714;&#12290;&#30446;&#21069;&#65292;&#25216;&#26415;&#34987;&#29992;&#20110;&#20449;&#24687;&#25910;&#38598;&#21644;&#31038;&#32676;&#25903;&#25345;&#65292;&#22312;&#20419;&#25104;&#20998;&#25163;&#12289;&#20351;&#39740;&#39746;&#24335;&#20998;&#25163;&#21644;&#25289;&#40657;&#25104;&#20026;&#21487;&#33021;&#65292;&#20197;&#21450;&#20419;&#36827;&#27807;&#36890;&#12290;&#21442;&#19982;&#32773;&#39044;&#35745;AI&#21487;&#20197;&#24110;&#21161;&#23454;&#29616;&#24863;&#30693;&#25216;&#24039;&#12290;
&lt;/p&gt;
&lt;p&gt;
Relationships are essential to our happiness and wellbeing. The dissolution of a relationship, the final stage of relationship's lifecycle and one of the most stressful events in an individual's life, can have profound and long-lasting impacts on people. With the breakup process increasingly facilitated by computer-mediated communication (CMC), and the likely future influence of AI-mediated communication (AIMC) tools, we conducted a semi-structured interview study with 21 participants. We aim to understand: 1) the current role of technology in the breakup process, 2) the needs and support individuals have during the process, and 3) how AI might address these needs. Our research shows that people have distinct needs at various stages of ending a relationship. Presently, technology is used for information gathering and community support, acting as a catalyst for breakups, enabling ghosting and blocking, and facilitating communication. Participants anticipate that AI could aid in sense-ma
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#22270;&#21367;&#31215;&#26469;&#25913;&#36827;Transformer&#27169;&#22411;&#20013;&#30340;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#24182;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#31561;&#22810;&#20010;&#39046;&#22495;&#23637;&#31034;&#20102;&#20854;&#24615;&#33021;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2312.04234</link><description>&lt;p&gt;
&#22270;&#21367;&#31215;&#22312;Transformer&#30340;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#20013;&#36215;&#21040;&#20102;&#25913;&#36827;&#30340;&#20316;&#29992;&#65281;&#65288;arXiv&#65306;2312.04234v2 [cs.LG]&#24050;&#26356;&#26032;&#65289;
&lt;/p&gt;
&lt;p&gt;
Graph Convolutions Enrich the Self-Attention in Transformers!. (arXiv:2312.04234v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.04234
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#22270;&#21367;&#31215;&#26469;&#25913;&#36827;Transformer&#27169;&#22411;&#20013;&#30340;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#24182;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#31561;&#22810;&#20010;&#39046;&#22495;&#23637;&#31034;&#20102;&#20854;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformer&#22240;&#20854;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#32780;&#38395;&#21517;&#65292;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#12289;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#31561;&#21508;&#31181;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#28145;&#24230;Transformer&#27169;&#22411;&#38754;&#20020;&#30340;&#25361;&#25112;&#20043;&#19968;&#26159;&#36807;&#24230;&#24179;&#28369;&#38382;&#39064;&#65292;&#21363;&#34920;&#31034;&#22312;&#21508;&#20010;&#23618;&#20043;&#38388;&#36235;&#20110;&#26080;&#27861;&#21306;&#20998;&#30340;&#20540;&#65292;&#23548;&#33268;&#24615;&#33021;&#20005;&#37325;&#19979;&#38477;&#12290;&#25105;&#20204;&#23558;&#21407;&#22987;&#30340;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#35299;&#37322;&#20026;&#19968;&#31181;&#31616;&#21333;&#30340;&#22270;&#28388;&#27874;&#22120;&#65292;&#24182;&#20174;&#22270;&#20449;&#21495;&#22788;&#29702;&#65288;GSP&#65289;&#30340;&#35282;&#24230;&#37325;&#26032;&#35774;&#35745;&#23427;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#22270;&#28388;&#27874;&#22120;&#30340;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#65288;GFSA&#65289;&#65292;&#20197;&#23398;&#20064;&#19968;&#31181;&#26082;&#36890;&#29992;&#21448;&#26377;&#25928;&#30340;&#26426;&#21046;&#65292;&#20854;&#22797;&#26434;&#24230;&#30053;&#39640;&#20110;&#21407;&#22987;&#30340;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;GFSA&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#12289;&#22270;&#27169;&#24335;&#20998;&#31867;&#12289;&#35821;&#38899;&#35782;&#21035;&#21644;&#20195;&#30721;&#20998;&#31867;&#31561;&#22810;&#20010;&#39046;&#22495;&#20013;&#25913;&#36827;&#20102;Transformer&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transformers, renowned for their self-attention mechanism, have achieved state-of-the-art performance across various tasks in natural language processing, computer vision, time-series modeling, etc. However, one of the challenges with deep Transformer models is the oversmoothing problem, where representations across layers converge to indistinguishable values, leading to significant performance degradation. We interpret the original self-attention as a simple graph filter and redesign it from a graph signal processing (GSP) perspective. We propose graph-filter-based self-attention (GFSA) to learn a general yet effective one, whose complexity, however, is slightly larger than that of the original self-attention mechanism. We demonstrate that GFSA improves the performance of Transformers in various fields, including computer vision, natural language processing, graph pattern classification, speech recognition, and code classification.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#23545;&#35821;&#20041;&#20998;&#21106;&#20013;&#30340;&#32463;&#20856;&#27979;&#35797;&#26102;&#36866;&#24212;&#26041;&#27861;&#36827;&#34892;&#20102;&#25209;&#21028;&#24615;&#25506;&#31350;&#65292;&#25581;&#31034;&#20102;&#20998;&#21106;TTA&#25152;&#38754;&#20020;&#30340;&#29420;&#29305;&#25361;&#25112;&#65292;&#24182;&#21457;&#29616;&#32463;&#20856;TTA&#31574;&#30053;&#22312;&#36825;&#19968;&#20219;&#21153;&#20013;&#24182;&#19981;&#26377;&#25928;&#12290;</title><link>http://arxiv.org/abs/2310.05341</link><description>&lt;p&gt;
&#23545;&#35821;&#20041;&#20998;&#21106;&#20013;&#32463;&#20856;&#30340;&#27979;&#35797;&#26102;&#36866;&#24212;&#26041;&#27861;&#30340;&#25209;&#21028;&#24615;&#25506;&#31350;
&lt;/p&gt;
&lt;p&gt;
A Critical Look at Classic Test-Time Adaptation Methods in Semantic Segmentation. (arXiv:2310.05341v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05341
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#23545;&#35821;&#20041;&#20998;&#21106;&#20013;&#30340;&#32463;&#20856;&#27979;&#35797;&#26102;&#36866;&#24212;&#26041;&#27861;&#36827;&#34892;&#20102;&#25209;&#21028;&#24615;&#25506;&#31350;&#65292;&#25581;&#31034;&#20102;&#20998;&#21106;TTA&#25152;&#38754;&#20020;&#30340;&#29420;&#29305;&#25361;&#25112;&#65292;&#24182;&#21457;&#29616;&#32463;&#20856;TTA&#31574;&#30053;&#22312;&#36825;&#19968;&#20219;&#21153;&#20013;&#24182;&#19981;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27979;&#35797;&#26102;&#36866;&#24212;&#65288;TTA&#65289;&#26088;&#22312;&#23558;&#26368;&#21021;&#22312;&#35757;&#32451;&#25968;&#25454;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#36866;&#24212;&#20110;&#27979;&#35797;&#25968;&#25454;&#20013;&#30340;&#21487;&#33021;&#20998;&#24067;&#21464;&#21270;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;TTA&#30740;&#31350;&#37117;&#38598;&#20013;&#22312;&#20998;&#31867;&#20219;&#21153;&#19978;&#65292;&#23545;&#20110;&#35821;&#20041;&#20998;&#21106;&#30340;TTA&#25506;&#32034;&#38750;&#24120;&#26377;&#38480;&#12290;&#36825;&#31181;&#23545;&#20998;&#31867;&#30340;&#31361;&#20986;&#37325;&#35270;&#21487;&#33021;&#23548;&#33268;&#35768;&#22810;&#26032;&#25163;&#21644;&#24037;&#31243;&#24072;&#38169;&#35823;&#22320;&#35748;&#20026;&#20026;&#20998;&#31867;&#35774;&#35745;&#30340;&#32463;&#20856;TTA&#26041;&#27861;&#21487;&#20197;&#30452;&#25509;&#24212;&#29992;&#20110;&#20998;&#21106;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#36825;&#19968;&#20551;&#35774;&#20173;&#26410;&#32463;&#39564;&#35777;&#65292;&#26159;&#19968;&#20010;&#24453;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#39033;&#31995;&#32479;&#30340;&#23454;&#35777;&#30740;&#31350;&#65292;&#25581;&#31034;&#20102;&#20998;&#21106;TTA&#30340;&#29420;&#29305;&#25361;&#25112;&#65292;&#24182;&#30830;&#23450;&#32463;&#20856;TTA&#31574;&#30053;&#26159;&#21542;&#21487;&#20197;&#26377;&#25928;&#24212;&#23545;&#36825;&#19968;&#20219;&#21153;&#12290;&#25105;&#20204;&#20840;&#38754;&#30340;&#32467;&#26524;&#24471;&#20986;&#20102;&#19977;&#20010;&#20851;&#38190;&#35266;&#23519;&#32467;&#26524;&#12290;&#39318;&#20808;&#65292;&#24120;&#29992;&#20110;&#20998;&#31867;TTA&#30340;&#32463;&#20856;&#25209;&#24402;&#19968;&#21270;&#26356;&#26032;&#31574;&#30053;&#21482;&#33021;&#24102;&#26469;&#36731;&#24494;&#30340;&#24615;&#33021;&#25913;&#21892;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#29978;&#33267;&#20250;&#23545;&#32467;&#26524;&#20135;&#29983;&#36870;&#21521;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Test-time adaptation (TTA) aims to adapt a model, initially trained on training data, to potential distribution shifts in the test data. Most existing TTA studies, however, focus on classification tasks, leaving a notable gap in the exploration of TTA for semantic segmentation. This pronounced emphasis on classification might lead numerous newcomers and engineers to mistakenly assume that classic TTA methods designed for classification can be directly applied to segmentation. Nonetheless, this assumption remains unverified, posing an open question. To address this, we conduct a systematic, empirical study to disclose the unique challenges of segmentation TTA, and to determine whether classic TTA strategies can effectively address this task. Our comprehensive results have led to three key observations. First, the classic batch norm updating strategy, commonly used in classification TTA, only brings slight performance improvement, and in some cases it might even adversely affect the resu
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#35774;&#35745;&#20102;&#19968;&#31181;&#20197;&#29992;&#25143;&#20026;&#20013;&#24515;&#30340;&#34892;&#20026;&#24178;&#39044;&#26041;&#27861;&#65292;&#36890;&#36807;&#25552;&#20379;&#26032;&#39062;&#30340;&#21453;&#20107;&#23454;&#35299;&#37322;&#26469;&#39044;&#38450;&#34880;&#31958;&#24322;&#24120;&#65292;&#26377;&#26395;&#23545;&#31038;&#20250;&#20135;&#29983;&#37325;&#35201;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2310.01684</link><description>&lt;p&gt;
&#35774;&#35745;&#20197;&#29992;&#25143;&#20026;&#20013;&#24515;&#30340;&#34892;&#20026;&#24178;&#39044;&#26469;&#39044;&#38450;&#34880;&#31958;&#24322;&#24120;&#65292;&#24182;&#25552;&#20379;&#26032;&#39062;&#30340;&#21453;&#20107;&#23454;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Designing User-Centric Behavioral Interventions to Prevent Dysglycemia with Novel Counterfactual Explanations. (arXiv:2310.01684v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01684
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#35774;&#35745;&#20102;&#19968;&#31181;&#20197;&#29992;&#25143;&#20026;&#20013;&#24515;&#30340;&#34892;&#20026;&#24178;&#39044;&#26041;&#27861;&#65292;&#36890;&#36807;&#25552;&#20379;&#26032;&#39062;&#30340;&#21453;&#20107;&#23454;&#35299;&#37322;&#26469;&#39044;&#38450;&#34880;&#31958;&#24322;&#24120;&#65292;&#26377;&#26395;&#23545;&#31038;&#20250;&#20135;&#29983;&#37325;&#35201;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#29983;&#27963;&#26041;&#24335;&#34892;&#20026;&#32500;&#25345;&#27491;&#24120;&#34880;&#31958;&#27700;&#24179;&#23545;&#20110;&#20445;&#25345;&#20581;&#24247;&#21644;&#39044;&#38450;&#30142;&#30149;&#33267;&#20851;&#37325;&#35201;&#12290;&#39057;&#32321;&#25509;&#35302;&#34880;&#31958;&#24322;&#24120;&#65288;&#21363;&#39640;&#34880;&#31958;&#21644;&#20302;&#34880;&#31958;&#31561;&#24322;&#24120;&#20107;&#20214;&#65289;&#20250;&#23548;&#33268;&#24930;&#24615;&#24182;&#21457;&#30151;&#65292;&#21253;&#25324;&#31958;&#23615;&#30149;&#12289;&#32958;&#33039;&#30142;&#30149;&#21450;&#38656;&#36879;&#26512;&#27835;&#30103;&#12289;&#24515;&#32908;&#26775;&#27515;&#12289;&#20013;&#39118;&#12289;&#25130;&#32930;&#21644;&#27515;&#20129;&#12290;&#22240;&#27492;&#65292;&#33021;&#22815;&#39044;&#27979;&#34880;&#31958;&#24322;&#24120;&#24182;&#21521;&#29992;&#25143;&#25552;&#20379;&#34892;&#21160;&#21453;&#39304;&#20197;&#25913;&#21464;&#39278;&#39135;&#12289;&#36816;&#21160;&#21644;&#33647;&#29289;&#27835;&#30103;&#26469;&#39044;&#38450;&#24322;&#24120;&#34880;&#31958;&#20107;&#20214;&#30340;&#24037;&#20855;&#21487;&#33021;&#20855;&#26377;&#37325;&#35201;&#30340;&#31038;&#20250;&#24433;&#21709;&#12290;&#21453;&#20107;&#23454;&#35299;&#37322;&#21487;&#20197;&#36890;&#36807;&#29983;&#25104;&#31867;&#20284;&#20110;&#21407;&#22987;&#36755;&#20837;&#20294;&#23548;&#33268;&#19981;&#21516;&#39044;&#27979;&#32467;&#26524;&#30340;&#20551;&#35774;&#23454;&#20363;&#65292;&#25552;&#20379;&#27169;&#22411;&#20026;&#20309;&#23545;&#29305;&#23450;&#39044;&#27979;&#30340;&#35265;&#35299;&#12290;&#22240;&#27492;&#65292;&#21453;&#20107;&#23454;&#35299;&#37322;&#21487;&#20197;&#34987;&#35270;&#20026;&#35774;&#35745;AI&#39537;&#21160;&#30340;&#20581;&#24247;&#24178;&#39044;&#26469;&#39044;&#38450;&#19981;&#33391;&#20581;&#24247;&#32467;&#26524;&#65288;&#22914;&#34880;&#31958;&#24322;&#24120;&#65289;&#30340;&#19968;&#31181;&#25163;&#27573;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;GlyCoa...
&lt;/p&gt;
&lt;p&gt;
Maintaining normal blood glucose levels through lifestyle behaviors is central to maintaining health and preventing disease. Frequent exposure to dysglycemia (i.e., abnormal glucose events such as hyperlycemia and hypoglycemia) leads to chronic complications including diabetes, kidney disease and need for dialysis, myocardial infarction, stroke, amputation, and death. Therefore, a tool capable of predicting dysglycemia and offering users actionable feedback about how to make changes in their diet, exercise, and medication to prevent abnormal glycemic events could have significant societal impacts. Counterfactual explanations can provide insights into why a model made a particular prediction by generating hypothetical instances that are similar to the original input but lead to a different prediction outcome. Therefore, counterfactuals can be viewed as a means to design AI-driven health interventions to prevent adverse health outcomes such as dysglycemia. In this paper, we design GlyCoa
&lt;/p&gt;</description></item><item><title>MAPLE&#26159;&#19968;&#20010;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23884;&#20837;&#36827;&#34892;&#31227;&#21160;&#24212;&#29992;&#39044;&#27979;&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;&#20005;&#26684;&#27979;&#35797;&#39564;&#35777;&#20102;&#20854;&#22312;&#35299;&#23494;&#22797;&#26434;&#27169;&#24335;&#21644;&#29702;&#35299;&#29992;&#25143;&#29615;&#22659;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#24182;&#24378;&#35843;&#20102;&#35821;&#35328;&#27169;&#22411;&#22312;&#19981;&#21516;&#39046;&#22495;&#20013;&#30340;&#24191;&#27867;&#36866;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.08648</link><description>&lt;p&gt;
MAPLE: &#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23884;&#20837;&#30340;&#31227;&#21160;&#24212;&#29992;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
MAPLE: Mobile App Prediction Leveraging Large Language model Embeddings. (arXiv:2309.08648v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08648
&lt;/p&gt;
&lt;p&gt;
MAPLE&#26159;&#19968;&#20010;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23884;&#20837;&#36827;&#34892;&#31227;&#21160;&#24212;&#29992;&#39044;&#27979;&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;&#20005;&#26684;&#27979;&#35797;&#39564;&#35777;&#20102;&#20854;&#22312;&#35299;&#23494;&#22797;&#26434;&#27169;&#24335;&#21644;&#29702;&#35299;&#29992;&#25143;&#29615;&#22659;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#24182;&#24378;&#35843;&#20102;&#35821;&#35328;&#27169;&#22411;&#22312;&#19981;&#21516;&#39046;&#22495;&#20013;&#30340;&#24191;&#27867;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#31227;&#21160;&#24212;&#29992;&#30340;&#21457;&#23637;&#36805;&#36895;&#65292;&#20294;&#30001;&#20110;&#22797;&#26434;&#30340;&#29992;&#25143;&#34892;&#20026;&#21644;&#19981;&#26029;&#28436;&#21464;&#30340;&#29615;&#22659;&#65292;&#39044;&#27979;&#24212;&#29992;&#30340;&#20351;&#29992;&#20173;&#28982;&#26159;&#19968;&#20010;&#20005;&#23803;&#30340;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#26412;&#25991;&#20171;&#32461;&#20102;Mobile App Prediction Leveraging Large Language Model Embeddings (MAPLE)&#27169;&#22411;&#12290;&#36825;&#31181;&#21019;&#26032;&#30340;&#26041;&#27861;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#26469;&#20934;&#30830;&#39044;&#27979;&#24212;&#29992;&#30340;&#20351;&#29992;&#24773;&#20917;&#12290;&#36890;&#36807;&#23545;&#20004;&#20010;&#20844;&#24320;&#25968;&#25454;&#38598;&#36827;&#34892;&#20005;&#26684;&#27979;&#35797;&#65292;MAPLE&#30340;&#33021;&#21147;&#22312;&#35299;&#23494;&#22797;&#26434;&#27169;&#24335;&#21644;&#29702;&#35299;&#29992;&#25143;&#29615;&#22659;&#26041;&#38754;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;&#36825;&#20123;&#24378;&#22823;&#30340;&#32467;&#26524;&#35777;&#23454;&#20102;MAPLE&#22312;&#19981;&#21516;&#22330;&#26223;&#20013;&#30340;&#22810;&#21151;&#33021;&#24615;&#21644;&#24377;&#24615;&#12290;&#23613;&#31649;&#20854;&#20027;&#35201;&#35774;&#35745;&#38754;&#21521;&#24212;&#29992;&#39044;&#27979;&#65292;&#20294;&#32467;&#26524;&#20063;&#24378;&#35843;&#20102;LLM&#22312;&#19981;&#21516;&#39046;&#22495;&#20013;&#30340;&#24191;&#27867;&#36866;&#29992;&#24615;&#12290;&#36890;&#36807;&#36825;&#39033;&#30740;&#31350;&#65292;&#25105;&#20204;&#24378;&#35843;&#20102;LLM&#22312;&#24212;&#29992;&#20351;&#29992;&#39044;&#27979;&#20013;&#30340;&#28508;&#21147;&#65292;&#24182;&#24314;&#35758;&#22312;&#24314;&#27169;&#21508;&#31181;&#39046;&#22495;&#20013;&#30340;&#20154;&#31867;&#34892;&#20026;&#26041;&#38754;&#65292;&#23427;&#20204;&#20855;&#26377;&#21464;&#38761;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the rapid advancement of mobile applications, predicting app usage remains a formidable challenge due to intricate user behaviours and ever-evolving contexts. To address these issues, this paper introduces the Mobile App Prediction Leveraging Large Language Model Embeddings (MAPLE) model. This innovative approach utilizes Large Language Models (LLMs) to predict app usage accurately. Rigorous testing on two public datasets highlights MAPLE's capability to decipher intricate patterns and comprehend user contexts. These robust results confirm MAPLE's versatility and resilience across various scenarios. While its primary design caters to app prediction, the outcomes also emphasize the broader applicability of LLMs in different domains. Through this research, we emphasize the potential of LLMs in app usage prediction and suggest their transformative capacity in modelling human behaviours across diverse fields.
&lt;/p&gt;</description></item></channel></rss>