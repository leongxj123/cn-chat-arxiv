<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#25552;&#20986;&#20102;&#19968;&#27454;&#20851;&#20110;&#21152;&#25343;&#22823;&#31354;&#20013;&#26053;&#23458;&#26435;&#21033;&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;&#65292;&#24110;&#21161;&#26053;&#23458;&#29702;&#35299;&#21644;&#21033;&#29992;&#30456;&#20851;&#31354;&#20013;&#26053;&#34892;&#27861;&#35268;&#65292;&#25104;&#21151;&#35299;&#20915;&#20102;&#29992;&#25143;&#36755;&#20837;&#22797;&#26434;&#21644;&#20934;&#30830;&#22238;&#31572;&#38382;&#39064;&#30340;&#25361;&#25112;</title><link>https://arxiv.org/abs/2403.12678</link><description>&lt;p&gt;
&#20026;&#21152;&#25343;&#22823;&#31354;&#20013;&#26053;&#34892;&#32773;&#36171;&#26435;&#65306;&#19968;&#27454;&#20851;&#20110;&#21152;&#25343;&#22823;&#31354;&#20013;&#26053;&#23458;&#26435;&#21033;&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;
&lt;/p&gt;
&lt;p&gt;
Empowering Air Travelers: A Chatbot for Canadian Air Passenger Rights
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12678
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#27454;&#20851;&#20110;&#21152;&#25343;&#22823;&#31354;&#20013;&#26053;&#23458;&#26435;&#21033;&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;&#65292;&#24110;&#21161;&#26053;&#23458;&#29702;&#35299;&#21644;&#21033;&#29992;&#30456;&#20851;&#31354;&#20013;&#26053;&#34892;&#27861;&#35268;&#65292;&#25104;&#21151;&#35299;&#20915;&#20102;&#29992;&#25143;&#36755;&#20837;&#22797;&#26434;&#21644;&#20934;&#30830;&#22238;&#31572;&#38382;&#39064;&#30340;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21152;&#25343;&#22823;&#33322;&#31354;&#26053;&#34892;&#39046;&#22495;&#30340;&#33322;&#29677;&#24310;&#35823;&#12289;&#21462;&#28040;&#21644;&#20854;&#20182;&#20851;&#20110;&#26053;&#23458;&#26435;&#21033;&#30340;&#38382;&#39064;&#26377;&#20102;&#26174;&#33879;&#22686;&#21152;&#12290;&#35748;&#35782;&#21040;&#36825;&#19968;&#38656;&#27714;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32842;&#22825;&#26426;&#22120;&#20154;&#26469;&#21327;&#21161;&#26053;&#23458;&#24182;&#25945;&#32946;&#20182;&#20204;&#20102;&#35299;&#33258;&#24049;&#30340;&#26435;&#21033;&#12290;&#25105;&#20204;&#30340;&#31995;&#32479;&#23558;&#22797;&#26434;&#30340;&#29992;&#25143;&#36755;&#20837;&#20998;&#35299;&#20026;&#31616;&#21333;&#30340;&#26597;&#35810;&#65292;&#29992;&#20110;&#26816;&#32034;&#35814;&#32454;&#31354;&#20013;&#26053;&#34892;&#27861;&#35268;&#30340;&#25991;&#26723;&#38598;&#20013;&#30340;&#20449;&#24687;&#12290;&#20174;&#36825;&#20123;&#25991;&#26723;&#20013;&#25552;&#21462;&#26368;&#30456;&#20851;&#30340;&#27573;&#33853;&#65292;&#24182;&#25552;&#20379;&#21407;&#22987;&#25991;&#26723;&#21644;&#29983;&#25104;&#30340;&#26597;&#35810;&#30340;&#38142;&#25509;&#65292;&#20351;&#29992;&#25143;&#33021;&#22815;&#23558;&#20449;&#24687;&#32454;&#20998;&#24182;&#21033;&#29992;&#20110;&#20854;&#29420;&#29305;&#24773;&#20917;&#12290;&#35813;&#31995;&#32479;&#25104;&#21151;&#20811;&#26381;&#20102;&#20004;&#20010;&#20027;&#35201;&#25361;&#25112;&#65306;&#29702;&#35299;&#22797;&#26434;&#30340;&#29992;&#25143;&#36755;&#20837;&#65292;&#24182;&#25552;&#20379;&#20934;&#30830;&#31572;&#26696;&#65292;&#27809;&#26377;&#24187;&#35273;&#65292;&#36825;&#20123;&#31572;&#26696;&#21487;&#20197;&#20379;&#26053;&#23458;&#20381;&#36182;&#20197;&#20570;&#20986;&#26126;&#26234;&#20915;&#31574;&#12290;&#19968;&#39033;&#27604;&#36739;&#32842;&#22825;&#26426;&#22120;&#20154;&#21644;&#35895;&#27468;&#25628;&#32034;&#30340;&#29992;&#25143;&#30740;&#31350;&#23637;&#31034;&#20102;&#32842;&#22825;&#26426;&#22120;&#20154;&#30340;&#23454;&#29992;&#24615;&#21644;&#26131;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12678v1 Announce Type: cross  Abstract: The Canadian air travel sector has seen a significant increase in flight delays, cancellations, and other issues concerning passenger rights. Recognizing this demand, we present a chatbot to assist passengers and educate them about their rights. Our system breaks a complex user input into simple queries which are used to retrieve information from a collection of documents detailing air travel regulations. The most relevant passages from these documents are presented along with links to the original documents and the generated queries, enabling users to dissect and leverage the information for their unique circumstances. The system successfully overcomes two predominant challenges: understanding complex user inputs, and delivering accurate answers, free of hallucinations, that passengers can rely on for making informed decisions. A user study comparing the chatbot to a Google search demonstrated the chatbot's usefulness and ease of use.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#23545;&#21307;&#30103;&#20445;&#20581;NLP&#20013;&#30340;&#28145;&#24230;&#23398;&#20064;&#36827;&#34892;&#20102;&#20840;&#38754;&#23457;&#26597;&#65292;&#25552;&#20986;&#20102;&#21487;&#35299;&#37322;&#21644;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#65288;XIAI&#65289;&#27010;&#24565;&#65292;&#24182;&#21457;&#29616;&#27880;&#24847;&#26426;&#21046;&#26159;&#20027;&#35201;&#26032;&#20852;IAI&#65292;&#21516;&#26102;&#38754;&#20020;&#30528;&#32570;&#20047;&#20840;&#23616;&#24314;&#27169;&#12289;&#26368;&#20339;&#23454;&#36341;&#20197;&#21450;&#31995;&#32479;&#35780;&#20272;&#21644;&#22522;&#20934;&#27979;&#35797;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2403.11894</link><description>&lt;p&gt;
&#20174;&#21487;&#35299;&#37322;&#21040;&#21487;&#35299;&#37322;&#30340;&#28145;&#24230;&#23398;&#20064;&#22312;&#21307;&#30103;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#30340;&#24212;&#29992;&#65306;&#29616;&#23454;&#26377;&#22810;&#36828;&#65311;
&lt;/p&gt;
&lt;p&gt;
From explainable to interpretable deep learning for natural language processing in healthcare: how far from reality?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11894
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#23545;&#21307;&#30103;&#20445;&#20581;NLP&#20013;&#30340;&#28145;&#24230;&#23398;&#20064;&#36827;&#34892;&#20102;&#20840;&#38754;&#23457;&#26597;&#65292;&#25552;&#20986;&#20102;&#21487;&#35299;&#37322;&#21644;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#65288;XIAI&#65289;&#27010;&#24565;&#65292;&#24182;&#21457;&#29616;&#27880;&#24847;&#26426;&#21046;&#26159;&#20027;&#35201;&#26032;&#20852;IAI&#65292;&#21516;&#26102;&#38754;&#20020;&#30528;&#32570;&#20047;&#20840;&#23616;&#24314;&#27169;&#12289;&#26368;&#20339;&#23454;&#36341;&#20197;&#21450;&#31995;&#32479;&#35780;&#20272;&#21644;&#22522;&#20934;&#27979;&#35797;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#65288;DL&#65289;&#36890;&#36807;&#35299;&#20915;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20219;&#21153;&#65292;&#26497;&#22823;&#22320;&#22686;&#24378;&#20102;&#21307;&#30103;&#20445;&#20581;&#30740;&#31350;&#12290;&#28982;&#32780;&#65292;&#22522;&#20110;DL&#30340;NLP&#26041;&#27861;&#26085;&#30410;&#22797;&#26434;&#65292;&#38656;&#35201;&#36879;&#26126;&#30340;&#27169;&#22411;&#35299;&#37322;&#24615;&#65292;&#25110;&#33267;&#23569;&#26159;&#21487;&#35299;&#37322;&#24615;&#65292;&#20197;&#36827;&#34892;&#21487;&#38752;&#30340;&#20915;&#31574;&#21046;&#23450;&#12290;&#26412;&#25991;&#23545;&#21307;&#30103;&#20581;&#24247;NLP&#20013;&#30340;&#21487;&#35299;&#37322;&#21644;&#21487;&#35299;&#37322;&#30340;DL&#36827;&#34892;&#20102;&#24443;&#24213;&#30340;&#33539;&#22260;&#23457;&#26597;&#12290;&#24341;&#20837;&#20102;&#26415;&#35821;&#8220;XIAI&#8221;&#65288;eXplainable&#21644;Interpretable Artificial Intelligence&#65289;&#20197;&#21306;&#20998;XAI&#21644;IAI&#12290;&#26041;&#27861;&#26681;&#25454;&#20854;&#21151;&#33021;&#65288;&#27169;&#22411;&#12289;&#36755;&#20837;&#12289;&#36755;&#20986;&#20026;&#22522;&#30784;&#65289;&#21644;&#33539;&#22260;&#65288;&#23616;&#37096;&#12289;&#20840;&#23616;&#65289;&#36827;&#19968;&#27493;&#20998;&#31867;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#27880;&#24847;&#26426;&#21046;&#26159;&#26368;&#20027;&#35201;&#30340;&#26032;&#20852;IAI&#12290;&#27492;&#22806;&#65292;IAI&#36234;&#26469;&#36234;&#22810;&#22320;&#29992;&#20110;&#23545;&#25239;XAI&#12290;&#30830;&#23450;&#30340;&#20027;&#35201;&#25361;&#25112;&#26159;&#22823;&#22810;&#25968;XIAI&#19981;&#25506;&#32034;&#8220;&#20840;&#23616;&#8221;&#24314;&#27169;&#36807;&#31243;&#65292;&#32570;&#20047;&#26368;&#20339;&#23454;&#36341;&#65292;&#24182;&#19988;&#38656;&#35201;&#31995;&#32479;&#35780;&#20272;&#21644;&#22522;&#20934;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11894v1 Announce Type: cross  Abstract: Deep learning (DL) has substantially enhanced healthcare research by addressing various natural language processing (NLP) tasks. Yet, the increasing complexity of DL-based NLP methods necessitates transparent model interpretability, or at least explainability, for reliable decision-making. This work presents a thorough scoping review on explainable and interpretable DL in healthcare NLP. The term "XIAI" (eXplainable and Interpretable Artificial Intelligence) was introduced to distinguish XAI from IAI. Methods were further categorized based on their functionality (model-, input-, output-based) and scope (local, global). Our analysis shows that attention mechanisms were the most dominant emerging IAI. Moreover, IAI is increasingly used against XAI. The major challenges identified are that most XIAI do not explore "global" modeling processes, the lack of best practices, and the unmet need for systematic evaluation and benchmarks. Importan
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25191;&#34892;&#25968;&#20540;&#35745;&#31639;&#26102;&#32463;&#24120;&#20986;&#38169;&#65292;&#36890;&#36807;&#29983;&#25104;&#21487;&#25191;&#34892;&#20195;&#30721;&#26469;&#35299;&#20915;&#38382;&#39064;&#21487;&#20197;&#20943;&#23569;&#35745;&#31639;&#38169;&#35823;&#65292;&#20294;&#35266;&#23519;&#21040;&#24403;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20351;&#29992;&#20195;&#30721;&#35299;&#20915;&#25968;&#23398;&#38382;&#39064;&#26102;&#65292;&#20250;&#29983;&#25104;&#26356;&#22810;&#19981;&#27491;&#30830;&#25512;&#29702;&#65307;&#20026;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21463;&#20154;&#31867;&#32534;&#30721;&#23454;&#36341;&#21551;&#21457;&#30340;&#31616;&#21333;&#32780;&#39640;&#25928;&#26041;&#27861;Human-Think Language&#65288;HTL&#65289;&#12290;</title><link>https://arxiv.org/abs/2402.15729</link><description>&lt;p&gt;
&#20154;&#31867;&#26159;&#22914;&#20309;&#32534;&#20889;&#20195;&#30721;&#30340;&#65311;&#22823;&#22411;&#27169;&#22411;&#20063;&#20197;&#21516;&#26679;&#30340;&#26041;&#24335;&#36827;&#34892;
&lt;/p&gt;
&lt;p&gt;
How Do Humans Write Code? Large Models Do It the Same Way Too
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15729
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25191;&#34892;&#25968;&#20540;&#35745;&#31639;&#26102;&#32463;&#24120;&#20986;&#38169;&#65292;&#36890;&#36807;&#29983;&#25104;&#21487;&#25191;&#34892;&#20195;&#30721;&#26469;&#35299;&#20915;&#38382;&#39064;&#21487;&#20197;&#20943;&#23569;&#35745;&#31639;&#38169;&#35823;&#65292;&#20294;&#35266;&#23519;&#21040;&#24403;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20351;&#29992;&#20195;&#30721;&#35299;&#20915;&#25968;&#23398;&#38382;&#39064;&#26102;&#65292;&#20250;&#29983;&#25104;&#26356;&#22810;&#19981;&#27491;&#30830;&#25512;&#29702;&#65307;&#20026;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21463;&#20154;&#31867;&#32534;&#30721;&#23454;&#36341;&#21551;&#21457;&#30340;&#31616;&#21333;&#32780;&#39640;&#25928;&#26041;&#27861;Human-Think Language&#65288;HTL&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#25191;&#34892;&#25968;&#20540;&#35745;&#31639;&#26102;&#32463;&#24120;&#20986;&#38169;&#12290;&#19982;&#20256;&#32479;&#30340;&#24605;&#32500;&#38142;&#25512;&#29702;&#30456;&#27604;&#65292;&#31243;&#24207;&#21270;&#24605;&#32500;&#26041;&#27861;&#28041;&#21450;&#29983;&#25104;&#21487;&#25191;&#34892;&#20195;&#30721;&#26469;&#35299;&#20915;&#38382;&#39064;&#12290;&#36890;&#36807;&#25191;&#34892;&#36825;&#20123;&#20195;&#30721;&#65292;&#23427;&#21487;&#20197;&#33719;&#24471;&#26356;&#31934;&#30830;&#30340;&#32467;&#26524;&#12290;&#20351;&#29992;&#29983;&#25104;&#30340;&#21487;&#25191;&#34892;&#20195;&#30721;&#32780;&#19981;&#26159;&#33258;&#28982;&#35821;&#35328;&#21487;&#20197;&#20943;&#23569;&#35745;&#31639;&#38169;&#35823;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#24403;LLMs&#20351;&#29992;&#20195;&#30721;&#35299;&#20915;&#25968;&#23398;&#38382;&#39064;&#26102;&#65292;&#20182;&#20204;&#24448;&#24448;&#29983;&#25104;&#27604;&#20351;&#29992;&#33258;&#28982;&#35821;&#35328;&#26356;&#22810;&#30340;&#19981;&#27491;&#30830;&#25512;&#29702;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Human-Think Language&#65288;HTL&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#21463;&#21040;&#20154;&#31867;&#32534;&#30721;&#23454;&#36341;&#21551;&#21457;&#30340;&#31616;&#21333;&#32780;&#39640;&#25928;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#39318;&#20808;&#30001;&#27169;&#22411;&#29983;&#25104;&#29992;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#30340;&#35299;&#20915;&#38382;&#39064;&#26041;&#27861;&#65292;&#28982;&#21518;&#23558;&#20854;&#36716;&#25442;&#20026;&#20195;&#30721;&#65292;&#21453;&#26144;&#20986;&#20154;&#20204;&#22312;&#23558;&#36923;&#36753;&#20197;&#33258;&#28982;&#35821;&#35328;&#24418;&#24335;&#24605;&#32771;&#21518;&#20877;&#23558;&#20854;&#20889;&#25104;&#20195;&#30721;&#30340;&#36807;&#31243;&#12290;&#27492;&#22806;&#65292;&#23427;&#21033;&#29992;&#20102;P
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15729v1 Announce Type: new  Abstract: Large Language Models (LLMs) often make errors when performing numerical calculations. In contrast to traditional chain-of-thought reasoning, the program-of-thoughts approach involves generating executable code to solve problems. By executing this code, it achieves more precise results. Using generated executable code instead of natural language can reduce computational errors. However, we observe that when LLMs solve mathematical problems using code, they tend to generate more incorrect reasoning than when using natural language. To address this issue, we propose Human-Think Language (HTL), a straightforward yet highly efficient approach inspired by human coding practices. The approach first generates problem-solving methods described in the natural language by the model, then converts them into code, mirroring the process where people think through the logic in natural language before writing it as code. Additionally, it utilizes the P
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;COMPASS&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#20998;&#26512;&#24515;&#29702;&#27835;&#30103;&#20250;&#35805;&#20013;&#30340;&#33258;&#28982;&#35821;&#35328;&#65292;&#30452;&#25509;&#25512;&#26029;&#27835;&#30103;&#24037;&#20316;&#32852;&#30431;&#65292;&#20026;&#20020;&#24202;&#31934;&#31070;&#30149;&#23398;&#25552;&#20379;&#20102;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#22312;&#35782;&#21035;&#19982;&#27491;&#22312;&#27835;&#30103;&#30340;&#30142;&#30149;&#30456;&#20851;&#30340;&#26032;&#20852;&#27169;&#24335;&#26041;&#38754;&#21457;&#25381;&#20316;&#29992;&#12290;</title><link>https://arxiv.org/abs/2402.14701</link><description>&lt;p&gt;
COMPASS&#65306;&#21033;&#29992;&#35821;&#35328;&#24314;&#27169;&#23545;&#24739;&#32773;-&#27835;&#30103;&#24072;&#32852;&#30431;&#31574;&#30053;&#36827;&#34892;&#35745;&#31639;&#26144;&#23556;
&lt;/p&gt;
&lt;p&gt;
COMPASS: Computational Mapping of Patient-Therapist Alliance Strategies with Language Modeling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14701
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;COMPASS&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#20998;&#26512;&#24515;&#29702;&#27835;&#30103;&#20250;&#35805;&#20013;&#30340;&#33258;&#28982;&#35821;&#35328;&#65292;&#30452;&#25509;&#25512;&#26029;&#27835;&#30103;&#24037;&#20316;&#32852;&#30431;&#65292;&#20026;&#20020;&#24202;&#31934;&#31070;&#30149;&#23398;&#25552;&#20379;&#20102;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#22312;&#35782;&#21035;&#19982;&#27491;&#22312;&#27835;&#30103;&#30340;&#30142;&#30149;&#30456;&#20851;&#30340;&#26032;&#20852;&#27169;&#24335;&#26041;&#38754;&#21457;&#25381;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27835;&#30103;&#24037;&#20316;&#32852;&#30431;&#26159;&#39044;&#27979;&#24515;&#29702;&#27835;&#30103;&#27835;&#30103;&#25104;&#21151;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;&#20256;&#32479;&#19978;&#65292;&#24037;&#20316;&#32852;&#30431;&#35780;&#20272;&#20381;&#36182;&#20110;&#27835;&#30103;&#24072;&#21644;&#24739;&#32773;&#22635;&#20889;&#30340;&#38382;&#21367;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;COMPASS&#65292;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#21487;&#30452;&#25509;&#20174;&#24515;&#29702;&#27835;&#30103;&#35838;&#31243;&#20013;&#20351;&#29992;&#30340;&#33258;&#28982;&#35821;&#35328;&#20013;&#25512;&#26029;&#27835;&#30103;&#24037;&#20316;&#32852;&#30431;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#20808;&#36827;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20998;&#26512;&#24515;&#29702;&#27835;&#30103;&#20250;&#35805;&#30340;&#36716;&#24405;&#65292;&#24182;&#23558;&#20854;&#19982;&#24037;&#20316;&#32852;&#30431;&#28165;&#21333;&#20013;&#38472;&#36848;&#30340;&#20998;&#24067;&#24335;&#34920;&#31034;&#36827;&#34892;&#27604;&#36739;&#12290;&#36890;&#36807;&#20998;&#26512;&#28085;&#30422;&#22810;&#31181;&#31934;&#31070;&#30142;&#30149;&#30340;&#36229;&#36807;950&#20010;&#20250;&#35805;&#30340;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#26174;&#24494;&#22320;&#26144;&#23556;&#24739;&#32773;-&#27835;&#30103;&#24072;&#23545;&#40784;&#36712;&#36857;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#20026;&#20020;&#24202;&#31934;&#31070;&#30149;&#23398;&#25552;&#20379;&#35299;&#37322;&#24615;&#65292;&#24182;&#22312;&#35782;&#21035;&#19982;&#27491;&#22312;&#27835;&#30103;&#30340;&#30142;&#30149;&#30456;&#20851;&#30340;&#26032;&#20852;&#27169;&#24335;&#26041;&#38754;&#25552;&#20379;&#21487;&#35299;&#37322;&#24615;&#12290;&#36890;&#36807;&#20351;&#29992;&#21508;&#31181;&#31070;&#32463;&#20027;&#39064;&#27169;&#24335;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14701v1 Announce Type: cross  Abstract: The therapeutic working alliance is a critical factor in predicting the success of psychotherapy treatment. Traditionally, working alliance assessment relies on questionnaires completed by both therapists and patients. In this paper, we present COMPASS, a novel framework to directly infer the therapeutic working alliance from the natural language used in psychotherapy sessions. Our approach utilizes advanced large language models to analyze transcripts of psychotherapy sessions and compare them with distributed representations of statements in the working alliance inventory. Analyzing a dataset of over 950 sessions covering diverse psychiatric conditions, we demonstrate the effectiveness of our method in microscopically mapping patient-therapist alignment trajectories and providing interpretability for clinical psychiatry and in identifying emerging patterns related to the condition being treated. By employing various neural topic mode
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;token-ensemble&#29983;&#25104;&#31574;&#30053;&#65292;&#25361;&#25112;&#20102;&#24403;&#21069;AI&#20869;&#23481;&#26816;&#27979;&#26041;&#27861;&#30340;&#40065;&#26834;&#24615;&#65292;&#23545;&#24403;&#21069;&#26816;&#27979;&#27169;&#22411;&#26500;&#25104;&#20102;&#37325;&#35201;&#25361;&#25112;&#65292;&#38656;&#35201;&#36827;&#19968;&#27493;&#25913;&#36827;&#26816;&#27979;&#25216;&#26415;&#20197;&#24212;&#23545;&#22797;&#26434;&#23545;&#25239;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2402.11167</link><description>&lt;p&gt;
Token-Ensemble&#25991;&#26412;&#29983;&#25104;&#65306;&#23545;&#33258;&#21160;AI&#29983;&#25104;&#25991;&#26412;&#26816;&#27979;&#30340;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Token-Ensemble Text Generation: On Attacking the Automatic AI-Generated Text Detection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11167
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;token-ensemble&#29983;&#25104;&#31574;&#30053;&#65292;&#25361;&#25112;&#20102;&#24403;&#21069;AI&#20869;&#23481;&#26816;&#27979;&#26041;&#27861;&#30340;&#40065;&#26834;&#24615;&#65292;&#23545;&#24403;&#21069;&#26816;&#27979;&#27169;&#22411;&#26500;&#25104;&#20102;&#37325;&#35201;&#25361;&#25112;&#65292;&#38656;&#35201;&#36827;&#19968;&#27493;&#25913;&#36827;&#26816;&#27979;&#25216;&#26415;&#20197;&#24212;&#23545;&#22797;&#26434;&#23545;&#25239;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
AI&#20869;&#23481;&#26816;&#27979;&#27169;&#22411;&#23545;&#32463;&#36807;&#31934;&#24515;&#35774;&#35745;&#30340;&#25915;&#20987;&#65288;&#20363;&#22914;&#25913;&#20889;&#25110;&#35789;&#35821;&#26367;&#25442;&#65289;&#30340;&#40065;&#26834;&#24615;&#20173;&#28982;&#26159;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;token-ensemble&#29983;&#25104;&#31574;&#30053;&#65292;&#25361;&#25112;&#20102;&#24403;&#21069;AI&#20869;&#23481;&#26816;&#27979;&#26041;&#27861;&#30340;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#20174;&#38543;&#26426;&#20505;&#36873;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#30340;&#19979;&#19968;&#20010;token&#23436;&#25104;&#25552;&#31034;&#26469;&#25506;&#32034;&#38598;&#25104;&#25915;&#20987;&#31574;&#30053;&#12290;&#25105;&#20204;&#21457;&#29616;token-ensemble&#26041;&#27861;&#26174;&#33879;&#38477;&#20302;&#20102;AI&#20869;&#23481;&#26816;&#27979;&#27169;&#22411;&#30340;&#24615;&#33021;&#65288;&#20195;&#30721;&#21644;&#27979;&#35797;&#38598;&#23558;&#21457;&#24067;&#65289;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#34920;&#26126;&#65292;token-ensemble&#29983;&#25104;&#23545;&#24403;&#21069;&#26816;&#27979;&#27169;&#22411;&#26500;&#25104;&#20102;&#37325;&#35201;&#25361;&#25112;&#65292;&#24182;&#24378;&#35843;&#20102;&#25913;&#36827;&#26816;&#27979;&#25216;&#26415;&#20197;&#24212;&#23545;&#22797;&#26434;&#23545;&#25239;&#31574;&#30053;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11167v1 Announce Type: cross  Abstract: The robustness of AI-content detection models against cultivated attacks (e.g., paraphrasing or word switching) remains a significant concern. This study proposes a novel token-ensemble generation strategy to challenge the robustness of current AI-content detection approaches. We explore the ensemble attack strategy by completing the prompt with the next token generated from random candidate LLMs. We find the token-ensemble approach significantly drops the performance of AI-content detection models (The code and test sets will be released). Our findings reveal that token-ensemble generation poses a vital challenge to current detection models and underlines the need for advancing detection technologies to counter sophisticated adversarial strategies.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36951;&#24536;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#25105;&#33976;&#39311;&#21644;&#26377;&#24847;&#35782;&#30340;&#24819;&#35937;&#65292;&#26377;&#25928;&#22320;&#36951;&#24536;&#30446;&#26631;&#25991;&#26412;&#65292;&#24182;&#22312;&#29983;&#25104;&#20219;&#21153;&#21644;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#20219;&#21153;&#20013;&#20445;&#30041;&#27169;&#22411;&#30340;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.10052</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36890;&#36807;&#33258;&#25105;&#33976;&#39311;&#21644;&#26377;&#24847;&#35782;&#30340;&#24819;&#35937;&#36827;&#34892;&#36951;&#24536;
&lt;/p&gt;
&lt;p&gt;
Unmemorization in Large Language Models via Self-Distillation and Deliberate Imagination
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10052
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36951;&#24536;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#25105;&#33976;&#39311;&#21644;&#26377;&#24847;&#35782;&#30340;&#24819;&#35937;&#65292;&#26377;&#25928;&#22320;&#36951;&#24536;&#30446;&#26631;&#25991;&#26412;&#65292;&#24182;&#22312;&#29983;&#25104;&#20219;&#21153;&#21644;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#20219;&#21153;&#20013;&#20445;&#30041;&#27169;&#22411;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#22312;&#35768;&#22810;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#29983;&#25104;&#33021;&#21147;&#65292;&#20294;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20173;&#28982;&#23384;&#22312;&#38544;&#31169;&#20405;&#29359;&#21644;&#25935;&#24863;&#25968;&#25454;&#19981;&#21463;&#25511;&#21046;&#30340;&#38382;&#39064;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#21363;&#22312;LLM&#36951;&#24536;&#30340;&#36807;&#31243;&#20013;&#37319;&#29992;&#26377;&#24847;&#35782;&#30340;&#24819;&#35937;&#12290;&#25105;&#20204;&#19981;&#26159;&#35797;&#22270;&#24536;&#35760;&#24050;&#35760;&#24518;&#30340;&#25968;&#25454;&#65292;&#32780;&#26159;&#36890;&#36807;&#33258;&#25105;&#33976;&#39311;&#30340;&#26694;&#26550;&#24341;&#23548;LLM&#26377;&#24847;&#35782;&#22320;&#24819;&#35937;&#26367;&#20195;&#24773;&#22659;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#19981;&#20165;&#21487;&#20197;&#26377;&#25928;&#22320;&#36951;&#24536;&#30446;&#26631;&#25991;&#26412;&#65292;&#36824;&#21487;&#20197;&#20445;&#30041;LLM&#22312;&#24320;&#25918;&#24335;&#29983;&#25104;&#20219;&#21153;&#21644;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#65288;NLU&#65289;&#20219;&#21153;&#20013;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#23637;&#31034;&#20102;&#36825;&#31181;&#26041;&#27861;&#22312;&#19981;&#21516;&#27169;&#22411;&#21644;&#35268;&#27169;&#20013;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10052v1 Announce Type: cross  Abstract: While displaying impressive generation capabilities across many tasks, Large Language Models (LLMs) still struggle with crucial issues of privacy violation and unwanted exposure of sensitive data. This raises an essential question: how should we prevent such undesired behavior of LLMs while maintaining their strong generation and natural language understanding (NLU) capabilities? In this work, we introduce a novel approach termed deliberate imagination in the context of LLM unlearning. Instead of trying to forget memorized data, we employ a self-distillation framework, guiding LLMs to deliberately imagine alternative scenarios. As demonstrated in a wide range of experiments, the proposed method not only effectively unlearns targeted text but also preserves the LLMs' capabilities in open-ended generation tasks as well as in NLU tasks. Our results demonstrate the usefulness of this approach across different models and sizes, and also wit
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;Open-domain Urban Itinerary Planning (OUIP)&#20219;&#21153;&#65292;&#29992;&#20110;&#26681;&#25454;&#29992;&#25143;&#20197;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#30340;&#35831;&#27714;&#30452;&#25509;&#29983;&#25104;&#34892;&#31243;&#65292;&#36890;&#36807;&#32467;&#21512;&#31354;&#38388;&#20248;&#21270;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#65292;&#25552;&#20379;&#20010;&#24615;&#21270;&#30340;&#22478;&#24066;&#34892;&#31243;&#23450;&#21046;&#26381;&#21153;&#12290;</title><link>https://arxiv.org/abs/2402.07204</link><description>&lt;p&gt;
&#32467;&#21512;&#31354;&#38388;&#20248;&#21270;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24320;&#25918;&#39046;&#22495;&#22478;&#24066;&#34892;&#31243;&#35268;&#21010;
&lt;/p&gt;
&lt;p&gt;
Synergizing Spatial Optimization with Large Language Models for Open-Domain Urban Itinerary Planning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07204
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;Open-domain Urban Itinerary Planning (OUIP)&#20219;&#21153;&#65292;&#29992;&#20110;&#26681;&#25454;&#29992;&#25143;&#20197;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#30340;&#35831;&#27714;&#30452;&#25509;&#29983;&#25104;&#34892;&#31243;&#65292;&#36890;&#36807;&#32467;&#21512;&#31354;&#38388;&#20248;&#21270;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#65292;&#25552;&#20379;&#20010;&#24615;&#21270;&#30340;&#22478;&#24066;&#34892;&#31243;&#23450;&#21046;&#26381;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#27425;&#25552;&#20986;&#20102;Open-domain Urban Itinerary Planning (OUIP)&#20219;&#21153;&#65292;&#29992;&#20110;&#26681;&#25454;&#29992;&#25143;&#20197;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#30340;&#35831;&#27714;&#30452;&#25509;&#29983;&#25104;&#34892;&#31243;&#12290;OUIP&#19982;&#20256;&#32479;&#34892;&#31243;&#35268;&#21010;&#19981;&#21516;&#65292;&#20256;&#32479;&#35268;&#21010;&#38480;&#21046;&#20102;&#29992;&#25143;&#34920;&#36798;&#26356;&#35814;&#32454;&#30340;&#38656;&#27714;&#65292;&#38459;&#30861;&#20102;&#30495;&#27491;&#30340;&#20010;&#24615;&#21270;&#12290;&#26368;&#36817;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#22312;&#22788;&#29702;&#22810;&#26679;&#21270;&#20219;&#21153;&#26041;&#38754;&#34920;&#29616;&#20986;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#38750;&#23454;&#26102;&#20449;&#24687;&#12289;&#19981;&#23436;&#25972;&#30340;&#30693;&#35782;&#21644;&#19981;&#36275;&#30340;&#31354;&#38388;&#24847;&#35782;&#65292;&#23427;&#20204;&#26080;&#27861;&#29420;&#31435;&#22320;&#25552;&#20379;&#28385;&#24847;&#30340;&#29992;&#25143;&#20307;&#39564;&#12290;&#37492;&#20110;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;ItiNera&#30340;OUIP&#31995;&#32479;&#65292;&#23558;&#31354;&#38388;&#20248;&#21270;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#30456;&#32467;&#21512;&#65292;&#26681;&#25454;&#29992;&#25143;&#38656;&#27714;&#25552;&#20379;&#20010;&#24615;&#21270;&#30340;&#22478;&#24066;&#34892;&#31243;&#23450;&#21046;&#26381;&#21153;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#22522;&#20110;LLM&#30340;&#27969;&#27700;&#32447;&#65292;&#29992;&#20110;&#25552;&#21462;&#21644;&#26356;&#26032;&#20852;&#36259;&#28857;&#29305;&#24449;&#65292;&#20197;&#21019;&#24314;&#29992;&#25143;&#33258;&#24049;&#30340;&#20010;&#24615;&#21270;&#20852;&#36259;&#28857;&#25968;&#25454;&#24211;&#12290;&#23545;&#20110;&#27599;&#20010;&#29992;&#25143;&#35831;&#27714;&#65292;&#25105;&#20204;&#21033;&#29992;LLM&#36827;&#34892;&#21327;&#21516;&#23454;&#29616;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we for the first time propose the task of Open-domain Urban Itinerary Planning (OUIP) for citywalk, which directly generates itineraries based on users' requests described in natural language. OUIP is different from conventional itinerary planning, which limits users from expressing more detailed needs and hinders true personalization. Recently, large language models (LLMs) have shown potential in handling diverse tasks. However, due to non-real-time information, incomplete knowledge, and insufficient spatial awareness, they are unable to independently deliver a satisfactory user experience in OUIP. Given this, we present ItiNera, an OUIP system that synergizes spatial optimization with Large Language Models (LLMs) to provide services that customize urban itineraries based on users' needs. Specifically, we develop an LLM-based pipeline for extracting and updating POI features to create a user-owned personalized POI database. For each user request, we leverage LLM in coop
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25581;&#31034;&#20102;&#22270;&#25551;&#36848;&#30340;&#25991;&#26412;&#39034;&#24207;&#23545;&#22823;&#35821;&#35328;&#27169;&#22411;&#22312;&#22270;&#25512;&#29702;&#20013;&#30340;&#24615;&#33021;&#20135;&#29983;&#26174;&#33879;&#24433;&#21709;&#65292;&#24182;&#36890;&#36807;&#25913;&#21464;&#25991;&#26412;&#39034;&#24207;&#25552;&#39640;&#20102;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#21457;&#29616;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#24615;&#33021;&#19982;&#22270;&#22823;&#23567;&#20043;&#38388;&#30340;&#20851;&#31995;&#19981;&#26159;&#21333;&#35843;&#36882;&#20943;&#30340;&#12290;&#20026;&#20102;&#35780;&#20272;&#22823;&#35821;&#35328;&#27169;&#22411;&#22312;&#19981;&#21516;&#22270;&#22823;&#23567;&#19978;&#30340;&#24615;&#33021;&#65292;&#24341;&#20837;&#20102;&#35268;&#27169;&#21270;&#22270;&#25512;&#29702;&#22522;&#20934;&#12290;</title><link>https://arxiv.org/abs/2402.07140</link><description>&lt;p&gt;
&#25991;&#23383;&#25551;&#36848;&#20013;&#30340;&#39034;&#24207;&#23545;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#31354;&#38388;&#24863;&#30693;&#33021;&#21147;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Sequential Ordering in Textual Descriptions: Impact on Spatial Perception Abilities of Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07140
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25581;&#31034;&#20102;&#22270;&#25551;&#36848;&#30340;&#25991;&#26412;&#39034;&#24207;&#23545;&#22823;&#35821;&#35328;&#27169;&#22411;&#22312;&#22270;&#25512;&#29702;&#20013;&#30340;&#24615;&#33021;&#20135;&#29983;&#26174;&#33879;&#24433;&#21709;&#65292;&#24182;&#36890;&#36807;&#25913;&#21464;&#25991;&#26412;&#39034;&#24207;&#25552;&#39640;&#20102;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#21457;&#29616;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#24615;&#33021;&#19982;&#22270;&#22823;&#23567;&#20043;&#38388;&#30340;&#20851;&#31995;&#19981;&#26159;&#21333;&#35843;&#36882;&#20943;&#30340;&#12290;&#20026;&#20102;&#35780;&#20272;&#22823;&#35821;&#35328;&#27169;&#22411;&#22312;&#19981;&#21516;&#22270;&#22823;&#23567;&#19978;&#30340;&#24615;&#33021;&#65292;&#24341;&#20837;&#20102;&#35268;&#27169;&#21270;&#22270;&#25512;&#29702;&#22522;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#20960;&#24180;&#65292;&#22823;&#35821;&#35328;&#27169;&#22411;&#22312;&#22810;&#20010;&#39046;&#22495;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#22270;&#25512;&#29702;&#39046;&#22495;&#30340;&#36827;&#23637;&#20173;&#28982;&#26377;&#38480;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#28145;&#20837;&#30740;&#31350;&#20102;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#22270;&#25512;&#29702;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#25991;&#26412;&#39034;&#24207;&#23545;&#22823;&#35821;&#35328;&#27169;&#22411;&#31354;&#38388;&#29702;&#35299;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#22270;&#25551;&#36848;&#30340;&#25991;&#26412;&#39034;&#24207;&#26174;&#33879;&#24433;&#21709;&#22823;&#35821;&#35328;&#27169;&#22411;&#23545;&#22270;&#30340;&#25512;&#29702;&#24615;&#33021;&#12290;&#36890;&#36807;&#25913;&#21464;&#22270;&#25551;&#36848;&#30340;&#25991;&#26412;&#39034;&#24207;&#65292;&#25105;&#20204;&#23558;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#24615;&#33021;&#20174;42.22&#65285;&#25552;&#39640;&#21040;70&#65285;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#22823;&#35821;&#35328;&#27169;&#22411;&#24615;&#33021;&#21644;&#22270;&#22823;&#23567;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#21457;&#29616;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#24615;&#33021;&#19981;&#38543;&#22270;&#22823;&#23567;&#30340;&#22686;&#21152;&#32780;&#21333;&#35843;&#36882;&#20943;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#35268;&#27169;&#21270;&#22270;&#25512;&#29702;&#22522;&#20934;&#26469;&#35780;&#20272;&#22823;&#35821;&#35328;&#27169;&#22411;&#22312;&#19981;&#21516;&#22270;&#22823;&#23567;&#19978;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, Large Language Models have reached state-of-the-art performance across multiple domains. However, the progress in the field of graph reasoning remains limited. Our work delves into this gap by thoroughly investigating graph reasoning with LLM. In this work, we reveal the impact of text sequence on LLM spatial understanding, finding that graph-descriptive text sequences significantly affect LLM reasoning performance on graphs. By altering the graph-descriptive text sequences, we enhance the performance of LLM from 42.22\% to 70\%. Furthermore, we evaluate the relationship between LLM performance and graph size, discovering that the reasoning performance of LLM does not monotonically decrease with the increase in graph size. Conclusively, we introduce the Scaled Graph Reasoning benchmark for assessing LLM performance across varied graph sizes.
&lt;/p&gt;</description></item><item><title>&#25193;&#25955;&#19990;&#30028;&#27169;&#22411;&#26159;&#19968;&#20010;&#33021;&#22815;&#39044;&#27979;&#22810;&#27493;&#26410;&#26469;&#29366;&#24577;&#21644;&#22870;&#21169;&#30340;&#26465;&#20214;&#24615;&#25193;&#25955;&#27169;&#22411;&#65292;&#22312;&#27169;&#22411;&#25928;&#26524;&#21644;&#24615;&#33021;&#26041;&#38754;&#36229;&#36807;&#20102;&#20256;&#32479;&#30340;&#19968;&#27493;&#21160;&#21147;&#23398;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2402.03570</link><description>&lt;p&gt;
&#25193;&#25955;&#19990;&#30028;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Diffusion World Model
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03570
&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#19990;&#30028;&#27169;&#22411;&#26159;&#19968;&#20010;&#33021;&#22815;&#39044;&#27979;&#22810;&#27493;&#26410;&#26469;&#29366;&#24577;&#21644;&#22870;&#21169;&#30340;&#26465;&#20214;&#24615;&#25193;&#25955;&#27169;&#22411;&#65292;&#22312;&#27169;&#22411;&#25928;&#26524;&#21644;&#24615;&#33021;&#26041;&#38754;&#36229;&#36807;&#20102;&#20256;&#32479;&#30340;&#19968;&#27493;&#21160;&#21147;&#23398;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#25193;&#25955;&#19990;&#30028;&#27169;&#22411;&#65288;DWM&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#65292;&#33021;&#22815;&#21516;&#26102;&#39044;&#27979;&#22810;&#27493;&#30340;&#26410;&#26469;&#29366;&#24577;&#21644;&#22870;&#21169;&#12290;&#19982;&#20256;&#32479;&#30340;&#19968;&#27493;&#21160;&#21147;&#23398;&#27169;&#22411;&#30456;&#21453;&#65292;DWM&#36890;&#36807;&#21333;&#20010;&#21069;&#21521;&#20256;&#36882;&#25552;&#20379;&#20102;&#38271;&#26102;&#31243;&#30340;&#39044;&#27979;&#65292;&#28040;&#38500;&#20102;&#36882;&#24402;&#26597;&#35810;&#30340;&#38656;&#35201;&#12290;&#25105;&#20204;&#23558;DWM&#25972;&#21512;&#21040;&#22522;&#20110;&#27169;&#22411;&#30340;&#20215;&#20540;&#20272;&#35745;&#20013;&#65292;&#20854;&#20013;&#30701;&#26399;&#22238;&#25253;&#36890;&#36807;&#20174;DWM&#20013;&#37319;&#26679;&#30340;&#26410;&#26469;&#36712;&#36857;&#36827;&#34892;&#27169;&#25311;&#12290;&#22312;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#32972;&#26223;&#19979;&#65292;DWM&#21487;&#20197;&#34987;&#35270;&#20026;&#36890;&#36807;&#29983;&#25104;&#24314;&#27169;&#26469;&#23454;&#29616;&#20445;&#23432;&#30340;&#20540;&#27491;&#21017;&#21270;&#12290;&#21478;&#22806;&#65292;&#23427;&#20063;&#21487;&#20197;&#34987;&#35270;&#20026;&#19968;&#31181;&#25968;&#25454;&#28304;&#65292;&#20351;&#31163;&#32447;Q&#23398;&#20064;&#33021;&#22815;&#20351;&#29992;&#21512;&#25104;&#25968;&#25454;&#12290;&#25105;&#20204;&#22312;D4RL&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#23454;&#20102;DWM&#23545;&#38271;&#26102;&#31243;&#27169;&#25311;&#30340;&#40065;&#26834;&#24615;&#12290;&#22312;&#32477;&#23545;&#24615;&#33021;&#26041;&#38754;&#65292;DWM&#26174;&#33879;&#36229;&#36807;&#20102;&#19968;&#27493;&#21160;&#21147;&#23398;&#27169;&#22411;&#65292;&#24615;&#33021;&#25552;&#39640;&#20102;44%&#65292;&#24182;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#30340;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce Diffusion World Model (DWM), a conditional diffusion model capable of predicting multistep future states and rewards concurrently. As opposed to traditional one-step dynamics models, DWM offers long-horizon predictions in a single forward pass, eliminating the need for recursive quires. We integrate DWM into model-based value estimation, where the short-term return is simulated by future trajectories sampled from DWM. In the context of offline reinforcement learning, DWM can be viewed as a conservative value regularization through generative modeling. Alternatively, it can be seen as a data source that enables offline Q-learning with synthetic data. Our experiments on the D4RL dataset confirm the robustness of DWM to long-horizon simulation. In terms of absolute performance, DWM significantly surpasses one-step dynamics models with a $44\%$ performance gain, and achieves state-of-the-art performance.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#35777;&#30740;&#31350;&#65292;&#25581;&#31034;&#20102;&#22312;&#27979;&#35797;&#29615;&#22659;&#20855;&#26377;&#24178;&#25200;&#22240;&#32032;&#26102;&#24433;&#21709;&#35270;&#35273;&#24378;&#21270;&#23398;&#20064;&#20013;&#27867;&#21270;&#24046;&#36317;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#26368;&#23567;&#21270;&#35757;&#32451;&#21644;&#27979;&#35797;&#29615;&#22659;&#20043;&#38388;&#30340;&#34920;&#31034;&#36317;&#31163;&#26159;&#20943;&#23569;&#27867;&#21270;&#24046;&#36317;&#26368;&#20851;&#38190;&#30340;&#22240;&#32032;&#12290;</title><link>https://arxiv.org/abs/2402.02701</link><description>&lt;p&gt;
&#29702;&#35299;&#24433;&#21709;&#35270;&#35273;&#24378;&#21270;&#23398;&#20064;&#20013;&#27867;&#21270;&#24046;&#36317;&#30340;&#22240;&#32032;&#65306;&#29702;&#35770;&#21644;&#23454;&#35777;&#35777;&#25454;
&lt;/p&gt;
&lt;p&gt;
Understanding What Affects Generalization Gap in Visual Reinforcement Learning: Theory and Empirical Evidence
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02701
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#35777;&#30740;&#31350;&#65292;&#25581;&#31034;&#20102;&#22312;&#27979;&#35797;&#29615;&#22659;&#20855;&#26377;&#24178;&#25200;&#22240;&#32032;&#26102;&#24433;&#21709;&#35270;&#35273;&#24378;&#21270;&#23398;&#20064;&#20013;&#27867;&#21270;&#24046;&#36317;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#26368;&#23567;&#21270;&#35757;&#32451;&#21644;&#27979;&#35797;&#29615;&#22659;&#20043;&#38388;&#30340;&#34920;&#31034;&#36317;&#31163;&#26159;&#20943;&#23569;&#27867;&#21270;&#24046;&#36317;&#26368;&#20851;&#38190;&#30340;&#22240;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#26377;&#35768;&#22810;&#21162;&#21147;&#33268;&#21147;&#20110;&#22312;&#35270;&#35273;&#24378;&#21270;&#23398;&#20064;&#20013;&#23398;&#20064;&#23545;&#36830;&#32493;&#25511;&#21046;&#26377;&#29992;&#30340;&#31574;&#30053;&#12290;&#22312;&#36825;&#31181;&#22330;&#26223;&#19979;&#65292;&#23398;&#20064;&#19968;&#20010;&#20855;&#26377;&#27867;&#21270;&#33021;&#21147;&#30340;&#31574;&#30053;&#38750;&#24120;&#37325;&#35201;&#65292;&#22240;&#20026;&#27979;&#35797;&#29615;&#22659;&#21487;&#33021;&#19982;&#35757;&#32451;&#29615;&#22659;&#19981;&#21516;&#65292;&#20363;&#22914;&#22312;&#37096;&#32626;&#36807;&#31243;&#20013;&#23384;&#22312;&#24178;&#25200;&#22240;&#32032;&#12290;&#35768;&#22810;&#23454;&#38469;&#31639;&#27861;&#34987;&#25552;&#20986;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#23427;&#20204;&#20013;&#27809;&#26377;&#19968;&#31181;&#31639;&#27861;&#33021;&#22815;&#20174;&#29702;&#35770;&#19978;&#35299;&#37322;&#27867;&#21270;&#24046;&#36317;&#30340;&#24433;&#21709;&#22240;&#32032;&#20197;&#21450;&#20026;&#20160;&#20040;&#20182;&#20204;&#30340;&#26041;&#27861;&#26377;&#25928;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;&#27979;&#35797;&#29615;&#22659;&#20855;&#26377;&#24178;&#25200;&#22240;&#32032;&#26102;&#29702;&#35770;&#19978;&#22238;&#31572;&#24433;&#21709;&#27867;&#21270;&#24046;&#36317;&#30340;&#20851;&#38190;&#22240;&#32032;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#34920;&#26126;&#65292;&#26368;&#23567;&#21270;&#35757;&#32451;&#21644;&#27979;&#35797;&#29615;&#22659;&#20043;&#38388;&#30340;&#34920;&#31034;&#36317;&#31163;&#65288;&#19982;&#20154;&#31867;&#30452;&#35273;&#19968;&#33268;&#65289;&#23545;&#20110;&#20943;&#23569;&#27867;&#21270;&#24046;&#36317;&#30340;&#25928;&#30410;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#24471;&#21040;&#20102;DM&#25968;&#25454;&#30340;&#23454;&#35777;&#35777;&#25454;&#30340;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, there are many efforts attempting to learn useful policies for continuous control in visual reinforcement learning (RL). In this scenario, it is important to learn a generalizable policy, as the testing environment may differ from the training environment, e.g., there exist distractors during deployment. Many practical algorithms are proposed to handle this problem. However, to the best of our knowledge, none of them provide a theoretical understanding of what affects the generalization gap and why their proposed methods work. In this paper, we bridge this issue by theoretically answering the key factors that contribute to the generalization gap when the testing environment has distractors. Our theories indicate that minimizing the representation distance between training and testing environments, which aligns with human intuition, is the most critical for the benefit of reducing the generalization gap. Our theoretical results are supported by the empirical evidence in the DM
&lt;/p&gt;</description></item><item><title>MixedNUTS&#26159;&#19968;&#31181;&#26080;&#38656;&#35757;&#32451;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#38750;&#32447;&#24615;&#28151;&#21512;&#20998;&#31867;&#22120;&#30340;&#36716;&#25442;&#21644;&#27010;&#29575;&#28151;&#21512;&#26469;&#23454;&#29616;&#20934;&#30830;&#24615;&#21644;&#40065;&#26834;&#24615;&#30340;&#24179;&#34913;&#12290;</title><link>https://arxiv.org/abs/2402.02263</link><description>&lt;p&gt;
MixedNUTS: &#36890;&#36807;&#38750;&#32447;&#24615;&#28151;&#21512;&#20998;&#31867;&#22120;&#23454;&#29616;&#26080;&#38656;&#35757;&#32451;&#30340;&#20934;&#30830;&#24615;&#21644;&#40065;&#26834;&#24615;&#24179;&#34913;
&lt;/p&gt;
&lt;p&gt;
MixedNUTS: Training-Free Accuracy-Robustness Balance via Nonlinearly Mixed Classifiers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02263
&lt;/p&gt;
&lt;p&gt;
MixedNUTS&#26159;&#19968;&#31181;&#26080;&#38656;&#35757;&#32451;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#38750;&#32447;&#24615;&#28151;&#21512;&#20998;&#31867;&#22120;&#30340;&#36716;&#25442;&#21644;&#27010;&#29575;&#28151;&#21512;&#26469;&#23454;&#29616;&#20934;&#30830;&#24615;&#21644;&#40065;&#26834;&#24615;&#30340;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#40065;&#26834;&#24615;&#24448;&#24448;&#29306;&#29298;&#20102;&#20934;&#30830;&#24615;&#65292;&#38459;&#30861;&#20102;&#40065;&#26834;&#20998;&#31867;&#27169;&#22411;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#20351;&#29992;&#12290;&#22522;&#20110;&#35757;&#32451;&#30340;&#35299;&#20915;&#26041;&#26696;&#22312;&#19982;&#24050;&#35757;&#32451;&#30340;&#22823;&#22411;&#39640;&#24615;&#33021;&#27169;&#22411;&#20860;&#23481;&#24615;&#26041;&#38754;&#23384;&#22312;&#38480;&#21046;&#65292;&#22240;&#27492;&#38656;&#35201;&#25506;&#32034;&#26080;&#38656;&#35757;&#32451;&#30340;&#38598;&#25104;&#26041;&#27861;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#40065;&#26834;&#27169;&#22411;&#22312;&#24178;&#20928;&#25968;&#25454;&#21644;&#23545;&#25239;&#25968;&#25454;&#19978;&#30340;&#27491;&#30830;&#39044;&#27979;&#27604;&#38169;&#35823;&#39044;&#27979;&#26356;&#33258;&#20449;&#65292;&#25105;&#20204;&#25512;&#27979;&#36890;&#36807;&#22686;&#24378;&#36825;&#31181;&#8220;&#33391;&#24615;&#32622;&#20449;&#24230;&#29305;&#24615;&#8221;&#21487;&#20197;&#22312;&#38598;&#25104;&#29615;&#22659;&#20013;&#23454;&#29616;&#20934;&#30830;&#24615;&#21644;&#40065;&#26834;&#24615;&#30340;&#24179;&#34913;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#28857;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#8220;MixedNUTS&#8221;&#65292;&#19968;&#31181;&#26080;&#38656;&#35757;&#32451;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#20165;&#26377;&#19977;&#20010;&#21442;&#25968;&#30340;&#38750;&#32447;&#24615;&#36716;&#25442;&#26469;&#22788;&#29702;&#40065;&#26834;&#20998;&#31867;&#22120;&#21644;&#26631;&#20934;&#38750;&#40065;&#26834;&#20998;&#31867;&#22120;&#30340;&#36755;&#20986;Logits&#65292;&#24182;&#36890;&#36807;&#39640;&#25928;&#31639;&#27861;&#36827;&#34892;&#20248;&#21270;&#12290;&#28982;&#21518;&#65292;MixedNUTS&#23558;&#36716;&#25442;&#21518;&#30340;Logits&#36716;&#25442;&#20026;&#27010;&#29575;&#65292;&#24182;&#23558;&#23427;&#20204;&#28151;&#21512;&#20316;&#20026;&#26368;&#32456;&#30340;&#36755;&#20986;&#12290;&#22312;CIFAR-10&#12289;CIFAR-100&#21644;ImageNet&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adversarial robustness often comes at the cost of degraded accuracy, impeding the real-life application of robust classification models. Training-based solutions for better trade-offs are limited by incompatibilities with already-trained high-performance large models, necessitating the exploration of training-free ensemble approaches. Observing that robust models are more confident in correct predictions than in incorrect ones on clean and adversarial data alike, we speculate amplifying this "benign confidence property" can reconcile accuracy and robustness in an ensemble setting. To achieve so, we propose "MixedNUTS", a training-free method where the output logits of a robust classifier and a standard non-robust classifier are processed by nonlinear transformations with only three parameters, which are optimized through an efficient algorithm. MixedNUTS then converts the transformed logits into probabilities and mixes them as the overall output. On CIFAR-10, CIFAR-100, and ImageNet da
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25506;&#35752;&#20102;LLM&#20195;&#29702;&#22312;&#19982;&#20154;&#31867;&#21644;&#20854;&#20182;&#20195;&#29702;&#20114;&#21160;&#26102;&#23637;&#31034;&#30340;&#31038;&#20250;&#34892;&#20026;&#65292;&#21253;&#25324;&#31038;&#20250;&#23398;&#20064;&#12289;&#31038;&#20250;&#20559;&#22909;&#21644;&#21512;&#20316;&#34892;&#20026;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#26694;&#26550;&#26469;&#35780;&#20272;&#23427;&#20204;&#19982;&#20154;&#31867;&#23454;&#39564;&#23545;&#35937;&#30340;&#20114;&#21160;&#12290;</title><link>https://arxiv.org/abs/2312.15198</link><description>&lt;p&gt;
LLM&#20195;&#29702;&#34920;&#29616;&#20986;&#31038;&#20250;&#34892;&#20026;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Do LLM Agents Exhibit Social Behavior?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.15198
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25506;&#35752;&#20102;LLM&#20195;&#29702;&#22312;&#19982;&#20154;&#31867;&#21644;&#20854;&#20182;&#20195;&#29702;&#20114;&#21160;&#26102;&#23637;&#31034;&#30340;&#31038;&#20250;&#34892;&#20026;&#65292;&#21253;&#25324;&#31038;&#20250;&#23398;&#20064;&#12289;&#31038;&#20250;&#20559;&#22909;&#21644;&#21512;&#20316;&#34892;&#20026;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#26694;&#26550;&#26469;&#35780;&#20272;&#23427;&#20204;&#19982;&#20154;&#31867;&#23454;&#39564;&#23545;&#35937;&#30340;&#20114;&#21160;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#36827;&#23637;&#27491;&#22312;&#25193;&#22823;&#23427;&#20204;&#22312;&#23398;&#26415;&#30740;&#31350;&#21644;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#25928;&#29992;&#12290;&#26368;&#36817;&#30340;&#31038;&#20250;&#31185;&#23398;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#36825;&#20123;&#8220;&#40657;&#21283;&#23376;&#8221;LLM&#20195;&#29702;&#26469;&#27169;&#25311;&#22797;&#26434;&#31038;&#20250;&#31995;&#32479;&#24182;&#28508;&#22312;&#22320;&#26367;&#20195;&#20154;&#31867;&#23454;&#39564;&#23545;&#35937;&#30340;&#21487;&#33021;&#24615;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#28145;&#20837;&#25506;&#35752;&#20102;&#36825;&#19968;&#26032;&#20852;&#39046;&#22495;&#65292;&#35843;&#26597;&#20102;LLMs&#22312;&#19982;&#20154;&#31867;&#21644;&#20854;&#20182;&#20195;&#29702;&#36827;&#34892;&#20114;&#21160;&#26102;&#23637;&#31034;&#31038;&#20250;&#23398;&#20064;&#12289;&#31038;&#20250;&#20559;&#22909;&#21644;&#21512;&#20316;&#34892;&#20026;&#65288;&#38388;&#25509;&#20114;&#24800;&#65289;&#31561;&#20851;&#38190;&#31038;&#20250;&#20132;&#20114;&#21407;&#21017;&#30340;&#31243;&#24230;&#12290;&#25105;&#20204;&#20026;&#25105;&#20204;&#30340;&#30740;&#31350;&#21046;&#23450;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#20854;&#20013;&#28041;&#21450;&#23558;&#28041;&#21450;&#20154;&#31867;&#23454;&#39564;&#23545;&#35937;&#30340;&#32463;&#20856;&#23454;&#39564;&#35843;&#25972;&#20026;&#20351;&#29992;LLM&#20195;&#29702;&#12290;&#36825;&#31181;&#26041;&#27861;&#28041;&#21450;&#19968;&#27493;&#19968;&#27493;&#30340;&#25512;&#29702;&#65292;&#27169;&#25311;&#20154;&#31867;&#35748;&#30693;&#36807;&#31243;&#21644;&#38646;&#26679;&#26412;&#23398;&#20064;&#65292;&#20197;&#35780;&#20272;LLMs&#30340;&#22825;&#29983;&#20559;&#22909;&#12290;&#25105;&#20204;&#23545;LLM&#20195;&#29702;&#34892;&#20026;&#30340;&#20998;&#26512;&#21253;&#25324;&#20027;&#35201;&#25928;&#24212;&#21644;&#27425;&#35201;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.15198v2 Announce Type: replace  Abstract: The advances of Large Language Models (LLMs) are expanding their utility in both academic research and practical applications. Recent social science research has explored the use of these ``black-box'' LLM agents for simulating complex social systems and potentially substituting human subjects in experiments. Our study delves into this emerging domain, investigating the extent to which LLMs exhibit key social interaction principles, such as social learning, social preference, and cooperative behavior (indirect reciprocity), in their interactions with humans and other agents. We develop a framework for our study, wherein classical laboratory experiments involving human subjects are adapted to use LLM agents. This approach involves step-by-step reasoning that mirrors human cognitive processes and zero-shot learning to assess the innate preferences of LLMs. Our analysis of LLM agents' behavior includes both the primary effects and an in
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#28385;&#36275;&#27867;&#21270;&#24615;&#12289;&#25193;&#23637;&#24615;&#21644;&#35745;&#31639;&#36164;&#28304;&#20248;&#21270;&#30340;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#65292;&#21033;&#29992;&#24265;&#20215;&#30340;&#20195;&#29702;&#27169;&#22411;&#20272;&#35745;&#25968;&#25454;&#28857;&#30340;&#21487;&#23398;&#20064;&#24615;&#20998;&#25968;&#65292;&#20248;&#20808;&#36873;&#25321;&#35757;&#32451;&#26356;&#22823;&#30340;&#27169;&#22411;&#25152;&#38656;&#30340;&#25968;&#25454;&#65292;&#20174;&#32780;&#22312;&#22823;&#35268;&#27169;&#35270;&#35273;&#29702;&#35299;&#20219;&#21153;&#20013;&#21462;&#24471;&#30456;&#21516;&#24615;&#33021;&#30340;&#21516;&#26102;&#20943;&#23569;&#20102;&#35745;&#31639;&#37327;&#12290;</title><link>https://arxiv.org/abs/2312.05328</link><description>&lt;p&gt;
&#19981;&#33391;&#23398;&#29983;&#25104;&#23601;&#20102;&#20248;&#31168;&#25945;&#24072;&#65306;&#20027;&#21160;&#23398;&#20064;&#21152;&#36895;&#22823;&#35268;&#27169;&#35270;&#35273;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Bad Students Make Great Teachers: Active Learning Accelerates Large-Scale Visual Understanding
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.05328
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#28385;&#36275;&#27867;&#21270;&#24615;&#12289;&#25193;&#23637;&#24615;&#21644;&#35745;&#31639;&#36164;&#28304;&#20248;&#21270;&#30340;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#65292;&#21033;&#29992;&#24265;&#20215;&#30340;&#20195;&#29702;&#27169;&#22411;&#20272;&#35745;&#25968;&#25454;&#28857;&#30340;&#21487;&#23398;&#20064;&#24615;&#20998;&#25968;&#65292;&#20248;&#20808;&#36873;&#25321;&#35757;&#32451;&#26356;&#22823;&#30340;&#27169;&#22411;&#25152;&#38656;&#30340;&#25968;&#25454;&#65292;&#20174;&#32780;&#22312;&#22823;&#35268;&#27169;&#35270;&#35273;&#29702;&#35299;&#20219;&#21153;&#20013;&#21462;&#24471;&#30456;&#21516;&#24615;&#33021;&#30340;&#21516;&#26102;&#20943;&#23569;&#20102;&#35745;&#31639;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24130;&#24459;&#32553;&#25918;&#34920;&#26126;&#20351;&#29992;&#22343;&#21248;&#37319;&#26679;&#30340;&#22823;&#35268;&#27169;&#35757;&#32451;&#36895;&#24230;&#22826;&#24930;&#12290;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#26088;&#22312;&#36890;&#36807;&#20248;&#20808;&#23398;&#20064;&#26368;&#30456;&#20851;&#30340;&#31034;&#20363;&#26469;&#25552;&#39640;&#25968;&#25454;&#25928;&#29575;&#12290;&#23613;&#31649;&#36825;&#20123;&#26041;&#27861;&#20855;&#26377;&#21560;&#24341;&#21147;&#65292;&#20294;&#30001;&#20110;&#27809;&#26377;&#35777;&#26126; a) &#21487;&#20197;&#27867;&#21270;&#21040;&#21508;&#31181;&#27169;&#22411;&#21644;&#20219;&#21153; b) &#21487;&#20197;&#25193;&#23637;&#21040;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#24182;&#19988; c) &#22312;&#32771;&#34385;&#25968;&#25454;&#36873;&#25321;&#24320;&#38144;&#26102;&#33021;&#33410;&#30465;&#35745;&#31639;&#36164;&#28304;&#65292;&#22240;&#27492;&#23578;&#26410;&#34987;&#24191;&#27867;&#37319;&#29992;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#28385;&#36275;&#36825;&#19977;&#20010;&#23646;&#24615;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#23567;&#22411;&#24265;&#20215;&#30340;&#20195;&#29702;&#27169;&#22411;&#26469;&#20272;&#35745;&#25968;&#25454;&#28857;&#30340;&#8220;&#21487;&#23398;&#20064;&#24615;&#8221;&#20998;&#25968;&#65292;&#29992;&#20110;&#20248;&#20808;&#35757;&#32451;&#26356;&#22823;&#30340;&#27169;&#22411;&#25152;&#38656;&#30340;&#25968;&#25454;&#12290;&#32467;&#26524;&#19978;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;JFT&#19978;&#38656;&#35201;46%&#21644;51%&#26356;&#23569;&#30340;&#35757;&#32451;&#26356;&#26032;&#27425;&#25968;&#65292;&#24182;&#19988;&#35201;&#36798;&#21040;&#19982;&#22343;&#21248;&#35757;&#32451;&#30340;&#35270;&#35273;&#20998;&#31867;&#22120;&#22312;JFT&#21644;ALIGN&#19978;&#22810;&#27169;&#22411;&#30340;&#30456;&#21516;&#24615;&#33021;&#38656;&#35201;&#39640;&#36798;25%&#30340;&#26356;&#23569;&#30340;&#24635;&#35745;&#31639;&#37327;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#21457;&#29616;&#25105;&#20204;&#30340;&#25968;&#25454;&#20248;&#20808;&#26041;&#27861;&#33021;&#22815;&#22312;&#35270;&#35273;&#29702;&#35299;&#21644;&#22810;&#27169;&#22411;&#20219;&#21153;&#19978;&#21462;&#24471;&#19982;&#22343;&#21248;&#35757;&#32451;&#30456;&#24403;&#30340;&#24615;&#33021;&#65292;&#21516;&#26102;&#33410;&#30465;&#20102;&#35745;&#31639;&#36164;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.05328v3 Announce Type: replace Abstract: Power-law scaling indicates that large-scale training with uniform sampling is prohibitively slow. Active learning methods aim to increase data efficiency by prioritizing learning on the most relevant examples. Despite their appeal, these methods have yet to be widely adopted since no one algorithm has been shown to a) generalize across models and tasks b) scale to large datasets and c) yield overall FLOP savings when accounting for the overhead of data selection. In this work we propose a method which satisfies these three properties, leveraging small, cheap proxy models to estimate "learnability" scores for datapoints, which are used to prioritize data for the training of much larger models. As a result, our models require 46% and 51% fewer training updates and up to 25% less total computation to reach the same performance as uniformly trained visual classifiers on JFT and multimodal models on ALIGN. Finally, we find our data-priori
&lt;/p&gt;</description></item><item><title>MobileGPT&#26159;&#19968;&#31181;&#21019;&#26032;&#30340;&#22522;&#20110;LLM&#30340;&#31227;&#21160;&#20219;&#21153;&#33258;&#21160;&#21270;&#24037;&#20855;&#65292;&#36890;&#36807;&#31867;&#20154;&#24212;&#29992;&#35760;&#24518;&#27169;&#25311;&#20154;&#31867;&#19982;&#31227;&#21160;&#24212;&#29992;&#30340;&#35748;&#30693;&#36807;&#31243;&#65292;&#23454;&#29616;&#20219;&#21153;&#31243;&#24207;&#30340;&#31934;&#30830;&#39640;&#25928;&#23398;&#20064;&#12290;</title><link>https://arxiv.org/abs/2312.03003</link><description>&lt;p&gt;
&#25506;&#32034;&#12289;&#36873;&#25321;&#12289;&#25512;&#23548;&#21644;&#22238;&#24518;&#65306;&#20026;&#31227;&#21160;&#20219;&#21153;&#33258;&#21160;&#21270;&#22686;&#21152;&#31867;&#20154;&#35760;&#24518;&#30340;LLM
&lt;/p&gt;
&lt;p&gt;
Explore, Select, Derive, and Recall: Augmenting LLM with Human-like Memory for Mobile Task Automation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.03003
&lt;/p&gt;
&lt;p&gt;
MobileGPT&#26159;&#19968;&#31181;&#21019;&#26032;&#30340;&#22522;&#20110;LLM&#30340;&#31227;&#21160;&#20219;&#21153;&#33258;&#21160;&#21270;&#24037;&#20855;&#65292;&#36890;&#36807;&#31867;&#20154;&#24212;&#29992;&#35760;&#24518;&#27169;&#25311;&#20154;&#31867;&#19982;&#31227;&#21160;&#24212;&#29992;&#30340;&#35748;&#30693;&#36807;&#31243;&#65292;&#23454;&#29616;&#20219;&#21153;&#31243;&#24207;&#30340;&#31934;&#30830;&#39640;&#25928;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20986;&#29616;&#20026;&#31227;&#21160;&#20219;&#21153;&#33258;&#21160;&#21270;&#39046;&#22495;&#24102;&#26469;&#20102;&#26032;&#30340;&#26426;&#36935;&#12290;&#23427;&#20204;&#20248;&#36234;&#30340;&#35821;&#35328;&#29702;&#35299;&#21644;&#25512;&#29702;&#33021;&#21147;&#20351;&#29992;&#25143;&#33021;&#22815;&#33258;&#21160;&#25191;&#34892;&#22797;&#26434;&#21644;&#37325;&#22797;&#30340;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;LLMs&#22266;&#26377;&#30340;&#19981;&#21487;&#38752;&#24615;&#21644;&#39640;&#36816;&#34892;&#25104;&#26412;&#65292;&#23427;&#20204;&#30340;&#23454;&#38469;&#36866;&#29992;&#24615;&#30456;&#24403;&#26377;&#38480;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#26412;&#25991;&#24341;&#20837;&#20102;MobileGPT&#65292;&#36825;&#26159;&#19968;&#31181;&#21019;&#26032;&#30340;&#22522;&#20110;LLM&#30340;&#31227;&#21160;&#20219;&#21153;&#33258;&#21160;&#21270;&#24037;&#20855;&#65292;&#37197;&#22791;&#20102;&#31867;&#20154;&#24212;&#29992;&#35760;&#24518;&#12290;MobileGPT&#27169;&#25311;&#20102;&#20154;&#31867;&#19982;&#31227;&#21160;&#24212;&#29992;&#20132;&#20114;&#30340;&#35748;&#30693;&#36807;&#31243;--&#25506;&#32034;&#12289;&#36873;&#25321;&#12289;&#25512;&#23548;&#21644;&#22238;&#24518;&#12290;&#36825;&#31181;&#26041;&#27861;&#36890;&#36807;&#23558;&#20219;&#21153;&#31243;&#24207;&#20998;&#35299;&#20026;&#26356;&#23567;&#12289;&#27169;&#22359;&#21270;&#30340;&#23376;&#20219;&#21153;&#65292;&#20801;&#35768;&#26356;&#31934;&#30830;&#12289;&#39640;&#25928;&#22320;&#23398;&#20064;&#20219;&#21153;&#27969;&#31243;&#65292;&#20174;&#32780;&#23454;&#29616;&#23376;&#20219;&#21153;&#30340;&#37325;&#22797;&#20351;&#29992;&#12289;&#37325;&#26032;&#25490;&#21015;&#21644;&#36866;&#24212;&#21508;&#31181;&#30446;&#26631;&#12290;&#25105;&#20204;&#20351;&#29992;&#22312;&#32447;LLM&#26381;&#21153;&#65288;GPT-3.5&#21644;GPT-4&#65289;&#23454;&#29616;&#20102;MobileGPT&#65292;&#24182;&#22312;&#19968;&#32452;&#25968;&#25454;&#19978;&#35780;&#20272;&#20102;&#20854;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.03003v2 Announce Type: replace-cross  Abstract: The advent of large language models (LLMs) has opened up new opportunities in the field of mobile task automation. Their superior language understanding and reasoning capabilities allow users to automate complex and repetitive tasks. However, due to the inherent unreliability and high operational cost of LLMs, their practical applicability is quite limited. To address these issues, this paper introduces MobileGPT, an innovative LLM-based mobile task automator equipped with a human-like app memory. MobileGPT emulates the cognitive process of humans interacting with a mobile app -- explore, select, derive, and recall. This approach allows for a more precise and efficient learning of a task's procedure by breaking it down into smaller, modular sub-tasks that can be re-used, re-arranged, and adapted for various objectives. We implement MobileGPT using online LLMs services (GPT-3.5 and GPT-4) and evaluate its performance on a datase
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#39318;&#27425;&#25506;&#32034;&#24182;&#35757;&#32451;&#20102;&#24378;&#22823;&#30340;&#22810;&#35821;&#35328;&#25968;&#23398;&#25512;&#29702;&#27169;&#22411;&#65292;&#36890;&#36807;&#20351;&#29992;&#32763;&#35793;&#26500;&#24314;&#20102;&#22810;&#35821;&#35328;&#25968;&#25454;&#38598;&#65292;&#24182;&#25552;&#20986;&#20102;&#21508;&#31181;&#35757;&#32451;&#31574;&#30053;&#26469;&#26500;&#24314;&#24378;&#22823;&#30340;&#27169;&#22411;&#12290;&#23454;&#39564;&#35777;&#23454;&#21457;&#29616;&#22312;&#22810;&#35821;&#35328;&#35757;&#32451;&#20013;&#65292;&#23558;&#30446;&#26631;&#35821;&#35328;&#30340;&#32763;&#35793;&#19982;&#21407;&#22987;&#35821;&#35328;&#30340;&#34920;&#31034;&#32467;&#21512;&#36215;&#26469;&#20197;&#21450;&#20132;&#26367;&#35757;&#32451;&#21644;&#22810;&#35821;&#35328;&#27169;&#22411;&#30340;&#33258;&#20030;&#21487;&#20197;&#25552;&#39640;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#27169;&#22411;&#22312;&#22788;&#29702;&#20302;&#39057;&#35789;&#21644;&#38271;&#21477;&#23376;&#26041;&#38754;&#20173;&#38754;&#20020;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2310.20246</link><description>&lt;p&gt;
&#22312;&#22810;&#35821;&#35328;&#25968;&#23398;&#25512;&#29702;&#20013;&#25171;&#30772;&#35821;&#35328;&#38556;&#30861;&#65306;&#35265;&#35299;&#19982;&#35266;&#23519;
&lt;/p&gt;
&lt;p&gt;
Breaking Language Barriers in Multilingual Mathematical Reasoning: Insights and Observations. (arXiv:2310.20246v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20246
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#27425;&#25506;&#32034;&#24182;&#35757;&#32451;&#20102;&#24378;&#22823;&#30340;&#22810;&#35821;&#35328;&#25968;&#23398;&#25512;&#29702;&#27169;&#22411;&#65292;&#36890;&#36807;&#20351;&#29992;&#32763;&#35793;&#26500;&#24314;&#20102;&#22810;&#35821;&#35328;&#25968;&#25454;&#38598;&#65292;&#24182;&#25552;&#20986;&#20102;&#21508;&#31181;&#35757;&#32451;&#31574;&#30053;&#26469;&#26500;&#24314;&#24378;&#22823;&#30340;&#27169;&#22411;&#12290;&#23454;&#39564;&#35777;&#23454;&#21457;&#29616;&#22312;&#22810;&#35821;&#35328;&#35757;&#32451;&#20013;&#65292;&#23558;&#30446;&#26631;&#35821;&#35328;&#30340;&#32763;&#35793;&#19982;&#21407;&#22987;&#35821;&#35328;&#30340;&#34920;&#31034;&#32467;&#21512;&#36215;&#26469;&#20197;&#21450;&#20132;&#26367;&#35757;&#32451;&#21644;&#22810;&#35821;&#35328;&#27169;&#22411;&#30340;&#33258;&#20030;&#21487;&#20197;&#25552;&#39640;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#27169;&#22411;&#22312;&#22788;&#29702;&#20302;&#39057;&#35789;&#21644;&#38271;&#21477;&#23376;&#26041;&#38754;&#20173;&#38754;&#20020;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#24320;&#21457;&#36866;&#29992;&#20110;&#21333;&#35821;&#35328;&#20013;&#30340;&#25968;&#23398;&#25512;&#29702;&#30340;&#24378;&#22823;&#35821;&#35328;&#23398;&#20064;&#27169;&#22411;&#65288;LLM&#65289;&#65292;&#22312;&#22810;&#35821;&#35328;&#29615;&#22659;&#19979;&#20445;&#25345;&#25928;&#26524;&#30340;&#30740;&#31350;&#24456;&#23569;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#26412;&#25991;&#39318;&#27425;&#25506;&#32034;&#21644;&#35757;&#32451;&#24378;&#22823;&#30340;&#22810;&#35821;&#35328;&#25968;&#23398;&#25512;&#29702;&#65288;xMR&#65289;LLM&#12290;&#39318;&#20808;&#65292;&#36890;&#36807;&#21033;&#29992;&#32763;&#35793;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#31532;&#19968;&#20010;&#21253;&#21547;&#21313;&#31181;&#19981;&#21516;&#35821;&#35328;&#30340;&#22810;&#35821;&#35328;&#25968;&#23398;&#25512;&#29702;&#25351;&#23548;&#25968;&#25454;&#38598;MGSM8KInstruct&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;xMR&#20219;&#21153;&#20013;&#35757;&#32451;&#25968;&#25454;&#31232;&#32570;&#30340;&#38382;&#39064;&#12290;&#26681;&#25454;&#25910;&#38598;&#30340;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19981;&#21516;&#30340;&#35757;&#32451;&#31574;&#30053;&#26469;&#26500;&#24314;&#24378;&#22823;&#30340;xMR LLMs&#65292;&#34987;&#21629;&#21517;&#20026;MathOctopus&#65292;&#22312;&#20960;&#27425;&#35757;&#32451;&#20013;&#34920;&#29616;&#20986;&#20248;&#20110;&#20256;&#32479;&#24320;&#28304;LLMs&#21644;ChatGPT&#30340;&#33021;&#21147;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;MathOctopus-13B&#22312;MGSM&#27979;&#35797;&#38598;&#19978;&#36798;&#21040;&#20102;47.6%&#30340;&#20934;&#30830;&#29575;&#65292;&#36229;&#36807;&#20102;ChatGPT&#30340;46.3%&#12290;&#38500;&#20102;&#26174;&#33879;&#30340;&#32467;&#26524;&#65292;&#25105;&#20204;&#36824;&#20174;&#22823;&#37327;&#30340;&#23454;&#39564;&#35777;&#23454;&#20013;&#21457;&#29616;&#20102;&#19968;&#20123;&#37325;&#35201;&#30340;&#35266;&#23519;&#21644;&#35265;&#35299;&#65306;&#65288;1&#65289;&#22312;&#22810;&#35821;&#35328;&#19978;&#36827;&#34892;&#35757;&#32451;&#26102;&#65292;&#26368;&#22909;&#23558;&#30446;&#26631;&#35821;&#35328;&#30340;&#32763;&#35793;&#19982;&#21407;&#22987;&#35821;&#35328;&#30340;&#34920;&#31034;&#32467;&#21512;&#36215;&#26469;&#12290; &#65288;2&#65289;&#20132;&#26367;&#35757;&#32451;&#21644;&#22810;&#35821;&#35328;&#27169;&#22411;&#30340;&#33258;&#20030;&#26377;&#21161;&#20110;&#25552;&#39640;&#27169;&#22411;&#30340;&#34920;&#29616;&#12290; &#65288;3&#65289;&#27169;&#22411;&#23545;&#20110;&#20302;&#39057;&#35789;&#21644;&#38271;&#21477;&#23376;&#30340;&#22788;&#29702;&#26159;&#25361;&#25112;&#30340;&#65292;&#38656;&#35201;&#36827;&#19968;&#27493;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing research predominantly focuses on developing powerful language learning models (LLMs) for mathematical reasoning within monolingual languages, with few explorations in preserving efficacy in a multilingual context. To bridge this gap, this paper pioneers exploring and training powerful Multilingual Math Reasoning (xMR) LLMs. Firstly, by utilizing translation, we construct the first multilingual math reasoning instruction dataset, MGSM8KInstruct, encompassing ten distinct languages, thus addressing the issue of training data scarcity in xMR tasks. Based on the collected dataset, we propose different training strategies to build powerful xMR LLMs, named MathOctopus, notably outperform conventional open-source LLMs and exhibit superiority over ChatGPT in few-shot scenarios. Notably, MathOctopus-13B reaches 47.6% accuracy which exceeds ChatGPT 46.3% on MGSM testset. Beyond remarkable results, we unearth several pivotal observations and insights from extensive experiments: (1) When
&lt;/p&gt;</description></item><item><title>GraphMaker&#26159;&#19968;&#31181;&#19987;&#38376;&#35774;&#35745;&#29992;&#20110;&#29983;&#25104;&#22823;&#22411;&#24102;&#23646;&#24615;&#22270;&#30340;&#26032;&#39062;&#25193;&#25955;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2310.13833</link><description>&lt;p&gt;
GraphMaker: &#25193;&#25955;&#27169;&#22411;&#33021;&#29983;&#25104;&#22823;&#22411;&#24102;&#23646;&#24615;&#22270;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
GraphMaker: Can Diffusion Models Generate Large Attributed Graphs?. (arXiv:2310.13833v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13833
&lt;/p&gt;
&lt;p&gt;
GraphMaker&#26159;&#19968;&#31181;&#19987;&#38376;&#35774;&#35745;&#29992;&#20110;&#29983;&#25104;&#22823;&#22411;&#24102;&#23646;&#24615;&#22270;&#30340;&#26032;&#39062;&#25193;&#25955;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21508;&#31181;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#20855;&#26377;&#33410;&#28857;&#23646;&#24615;&#30340;&#22823;&#35268;&#27169;&#22270;&#21464;&#24471;&#36234;&#26469;&#36234;&#24120;&#35265;&#12290;&#21019;&#24314;&#19982;&#30495;&#23454;&#19990;&#30028;&#31034;&#20363;&#31867;&#20284;&#30340;&#21512;&#25104;&#12289;&#23500;&#23646;&#24615;&#22270;&#23545;&#20110;&#20849;&#20139;&#22270;&#25968;&#25454;&#36827;&#34892;&#20998;&#26512;&#21644;&#24320;&#21457;&#23398;&#20064;&#27169;&#22411;&#33267;&#20851;&#37325;&#35201;&#65292;&#23588;&#20854;&#26159;&#24403;&#21407;&#22987;&#25968;&#25454;&#38480;&#21046;&#34987;&#20849;&#20139;&#26102;&#12290;&#20256;&#32479;&#30340;&#22270;&#29983;&#25104;&#26041;&#27861;&#22312;&#22788;&#29702;&#36825;&#20123;&#22797;&#26434;&#32467;&#26500;&#26041;&#38754;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#26368;&#26032;&#30340;&#25193;&#25955;&#27169;&#22411;&#22312;&#29983;&#25104;&#27809;&#26377;&#23646;&#24615;&#21644;&#36739;&#23567;&#30340;&#20998;&#23376;&#22270;&#26041;&#38754;&#26174;&#31034;&#20986;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#22312;&#29983;&#25104;&#22823;&#22411;&#24102;&#23646;&#24615;&#22270;&#26041;&#38754;&#38754;&#20020;&#30528;&#25361;&#25112;&#65292;&#21407;&#22240;&#26159;&#22797;&#26434;&#30340;&#23646;&#24615;-&#32467;&#26500;&#30456;&#20851;&#24615;&#21644;&#22270;&#30340;&#22823;&#35268;&#27169;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#19987;&#38376;&#29992;&#20110;&#29983;&#25104;&#22823;&#22411;&#24102;&#23646;&#24615;&#22270;&#30340;&#26032;&#39062;&#25193;&#25955;&#27169;&#22411;&#65306;GraphMaker&#12290;&#25105;&#20204;&#25506;&#32034;&#20102;&#21508;&#31181;&#33410;&#28857;&#23646;&#24615;&#21644;&#22270;&#32467;&#26500;&#29983;&#25104;&#36807;&#31243;&#30340;&#32452;&#21512;&#65292;&#21457;&#29616;&#24322;&#27493;&#26041;&#27861;&#26356;&#26377;&#25928;&#22320;&#25429;&#25417;&#20102;&#20869;&#37096;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large-scale graphs with node attributes are increasingly common in various real-world applications. Creating synthetic, attribute-rich graphs that mirror real-world examples is crucial, especially for sharing graph data for analysis and developing learning models when original data is restricted to be shared. Traditional graph generation methods are limited in their capacity to handle these complex structures. Recent advances in diffusion models have shown potential in generating graph structures without attributes and smaller molecular graphs. However, these models face challenges in generating large attributed graphs due to the complex attribute-structure correlations and the large size of these graphs. This paper introduces a novel diffusion model, GraphMaker, specifically designed for generating large attributed graphs. We explore various combinations of node attribute and graph structure generation processes, finding that an asynchronous approach more effectively captures the intr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FedLPA&#30340;&#26032;&#39062;&#26041;&#27861;&#65292;&#37319;&#29992;&#20998;&#23618;&#21518;&#39564;&#32858;&#21512;&#30340;&#26041;&#24335;&#23454;&#29616;&#20010;&#24615;&#21270;&#21333;&#27425;&#32852;&#37030;&#23398;&#20064;&#12290;FedLPA&#33021;&#22815;&#39640;&#25928;&#22320;&#23558;&#26412;&#22320;&#27169;&#22411;&#32858;&#21512;&#21040;&#20840;&#23616;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#21333;&#27425;&#32858;&#21512;&#22312;&#38750;&#30456;&#21516;&#35757;&#32451;&#25968;&#25454;&#20998;&#24067;&#19979;&#30340;&#24615;&#33021;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.00339</link><description>&lt;p&gt;
FedLPA: &#20351;&#29992;&#20998;&#23618;&#21518;&#39564;&#32858;&#21512;&#30340;&#20010;&#24615;&#21270;&#21333;&#27425;&#32852;&#37030;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
FedLPA: Personalized One-shot Federated Learning with Layer-Wise Posterior Aggregation. (arXiv:2310.00339v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00339
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FedLPA&#30340;&#26032;&#39062;&#26041;&#27861;&#65292;&#37319;&#29992;&#20998;&#23618;&#21518;&#39564;&#32858;&#21512;&#30340;&#26041;&#24335;&#23454;&#29616;&#20010;&#24615;&#21270;&#21333;&#27425;&#32852;&#37030;&#23398;&#20064;&#12290;FedLPA&#33021;&#22815;&#39640;&#25928;&#22320;&#23558;&#26412;&#22320;&#27169;&#22411;&#32858;&#21512;&#21040;&#20840;&#23616;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#21333;&#27425;&#32858;&#21512;&#22312;&#38750;&#30456;&#21516;&#35757;&#32451;&#25968;&#25454;&#20998;&#24067;&#19979;&#30340;&#24615;&#33021;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#26412;&#22320;&#23458;&#25143;&#31471;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#39640;&#25928;&#22320;&#32858;&#21512;&#21040;&#26381;&#21153;&#22120;&#19978;&#30340;&#20840;&#23616;&#27169;&#22411;&#26159;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#24191;&#27867;&#30740;&#31350;&#35838;&#39064;&#12290;&#26368;&#36817;&#65292;&#21463;&#21040;&#38544;&#31169;&#38382;&#39064;&#20943;&#23569;&#12289;&#28508;&#22312;&#25915;&#20987;&#20943;&#24369;&#21644;&#36890;&#20449;&#24320;&#38144;&#38477;&#20302;&#30340;&#25512;&#21160;&#65292;&#21333;&#27425;&#32852;&#37030;&#23398;&#20064;&#65288;&#21363;&#23558;&#23458;&#25143;&#31471;&#19982;&#26381;&#21153;&#22120;&#38388;&#30340;&#36890;&#20449;&#38480;&#21046;&#20026;&#19968;&#36718;&#65289;&#22312;&#30740;&#31350;&#32773;&#20013;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#12290;&#28982;&#32780;&#65292;&#21333;&#27425;&#32858;&#21512;&#30340;&#24615;&#33021;&#23481;&#26131;&#21463;&#21040;&#38750;&#30456;&#21516;&#35757;&#32451;&#25968;&#25454;&#20998;&#24067;&#30340;&#24433;&#21709;&#65292;&#22312;&#19968;&#20123;&#23454;&#38469;&#22330;&#26223;&#20013;&#34920;&#29616;&#20986;&#39640;&#24230;&#30340;&#32479;&#35745;&#24322;&#36136;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21333;&#27425;&#32858;&#21512;&#26041;&#27861;&#8212;&#8212;&#20998;&#23618;&#21518;&#39564;&#32858;&#21512;&#65288;FedLPA&#65289;&#12290;FedLPA&#33021;&#22815;&#32858;&#21512;&#26412;&#22320;&#27169;&#22411;&#65292;&#33719;&#24471;&#26356;&#20934;&#30830;&#30340;&#20840;&#23616;&#27169;&#22411;&#65292;&#32780;&#26080;&#38656;&#39069;&#22806;&#30340;&#36741;&#21161;&#25968;&#25454;&#38598;&#25110;&#26292;&#38706;&#20219;&#20309;&#26426;&#23494;&#30340;&#26412;&#22320;&#20449;&#24687;&#65292;&#27604;&#22914;&#26631;&#31614;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
Efficiently aggregating trained neural networks from local clients into a global model on a server is a widely researched topic in federated learning. Recently, motivated by diminishing privacy concerns, mitigating potential attacks, and reducing the overhead of communication, one-shot federated learning (i.e., limiting client-server communication into a single round) has gained popularity among researchers. However, the one-shot aggregation performances are sensitively affected by the non-identical training data distribution, which exhibits high statistical heterogeneity in some real-world scenarios. To address this issue, we propose a novel one-shot aggregation method with Layer-wise Posterior Aggregation, named FedLPA. FedLPA aggregates local models to obtain a more accurate global model without requiring extra auxiliary datasets or exposing any confidential local information, e.g., label distributions. To effectively capture the statistics maintained in the biased local datasets in
&lt;/p&gt;</description></item><item><title>&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#38750;&#33258;&#22238;&#24402;TSP&#27714;&#35299;&#22120;NAR4TSP&#20351;&#29992;&#29305;&#21035;&#35774;&#35745;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#25512;&#29702;&#65292;&#28040;&#38500;&#20102;&#26114;&#36149;&#26631;&#31614;&#30340;&#20381;&#36182;&#65292;&#24182;&#22312;&#35299;&#20915;&#26041;&#26696;&#36136;&#37327;&#12289;&#25512;&#29702;&#24310;&#36831;&#21644;&#27867;&#21270;&#33021;&#21147;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#22235;&#20010;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2308.00560</link><description>&lt;p&gt;
&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#38750;&#33258;&#22238;&#24402;&#27714;&#35299;&#22120;&#29992;&#20110;&#26053;&#34892;&#25512;&#38144;&#21592;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning-based Non-Autoregressive Solver for Traveling Salesman Problems. (arXiv:2308.00560v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00560
&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#38750;&#33258;&#22238;&#24402;TSP&#27714;&#35299;&#22120;NAR4TSP&#20351;&#29992;&#29305;&#21035;&#35774;&#35745;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#25512;&#29702;&#65292;&#28040;&#38500;&#20102;&#26114;&#36149;&#26631;&#31614;&#30340;&#20381;&#36182;&#65292;&#24182;&#22312;&#35299;&#20915;&#26041;&#26696;&#36136;&#37327;&#12289;&#25512;&#29702;&#24310;&#36831;&#21644;&#27867;&#21270;&#33021;&#21147;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#22235;&#20010;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26053;&#34892;&#25512;&#38144;&#21592;&#38382;&#39064;&#65288;TSP&#65289;&#26159;&#32452;&#21512;&#20248;&#21270;&#20013;&#30340;&#19968;&#20010;&#20247;&#25152;&#21608;&#30693;&#30340;&#38382;&#39064;&#65292;&#20855;&#26377;&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;TSP&#27714;&#35299;&#22120;&#22312;&#20135;&#29983;&#39640;&#36136;&#37327;&#35299;&#20915;&#26041;&#26696;&#26102;&#38754;&#20020;&#20302;&#24310;&#36831;&#30340;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;NAR4TSP&#65292;&#23427;&#20351;&#29992;&#19968;&#20010;&#29305;&#21035;&#35774;&#35745;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#20197;&#38750;&#33258;&#22238;&#24402;&#65288;NAR&#65289;&#26041;&#24335;&#29983;&#25104;TSP&#35299;&#20915;&#26041;&#26696;&#65292;&#23454;&#29616;&#26356;&#24555;&#30340;&#25512;&#29702;&#36895;&#24230;&#12290;&#27492;&#22806;&#65292;NAR4TSP&#20351;&#29992;&#22686;&#24378;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#31574;&#30053;&#36827;&#34892;&#35757;&#32451;&#65292;&#28040;&#38500;&#20102;&#20256;&#32479;&#30417;&#30563;&#23398;&#20064;&#22522;&#20110;NAR&#27169;&#22411;&#35757;&#32451;&#25152;&#20351;&#29992;&#30340;&#26114;&#36149;&#26631;&#31614;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;NAR4TSP&#26159;&#31532;&#19968;&#20010;&#25104;&#21151;&#32467;&#21512;&#20102;RL&#21644;NAR&#35299;&#30721;&#30340;TSP&#27714;&#35299;&#22120;&#12290;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#30340;TSP&#23454;&#20363;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;NAR4TSP&#22312;&#35299;&#20915;&#26041;&#26696;&#36136;&#37327;&#12289;&#25512;&#29702;&#24310;&#36831;&#21644;&#27867;&#21270;&#33021;&#21147;&#26041;&#38754;&#20248;&#20110;&#22235;&#20010;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;NAR4TSP&#35299;&#30721;&#36807;&#31243;&#30340;&#21487;&#35270;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Traveling Salesman Problem (TSP) is a well-known problem in combinatorial optimization with applications in various domains. However, existing TSP solvers face challenges in producing high-quality solutions with low latency. To address this issue, we propose NAR4TSP, which produces TSP solutions in a Non-Autoregressive (NAR) manner using a specially designed Graph Neural Network (GNN), achieving faster inference speed. Moreover, NAR4TSP is trained using an enhanced Reinforcement Learning (RL) strategy, eliminating the dependency on costly labels used to train conventional supervised learning-based NAR models. To the best of our knowledge, NAR4TSP is the first TSP solver that successfully combines RL and NAR decoding. The experimental results on both synthetic and real-world TSP instances demonstrate that NAR4TSP outperforms four state-of-the-art models in terms of solution quality, inference latency, and generalization ability. Lastly, we present visualizations of NAR4TSP's decodin
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#36870;&#24378;&#21270;&#23398;&#20064;&#20013;&#26102;&#38388;&#35270;&#37326;&#30340;&#37325;&#35201;&#24615;&#65292;&#21457;&#29616;&#30701;&#20110;&#23454;&#38469;&#20540;&#30340;&#26377;&#25928;&#26102;&#38388;&#35270;&#37326;&#21487;&#20197;&#26356;&#24555;&#19988;&#26356;&#20934;&#30830;&#22320;&#20272;&#35745;&#22870;&#21169;&#20989;&#25968;&#65292;&#20943;&#36731;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#36824;&#21628;&#21505;&#22312;IRL&#20013;&#21516;&#26102;&#23398;&#20064;&#22870;&#21169;&#21644;&#26377;&#25928;&#26102;&#38388;&#35270;&#37326;&#12290;</title><link>http://arxiv.org/abs/2307.06541</link><description>&lt;p&gt;
&#36870;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#26377;&#25928;&#26102;&#38388;&#35270;&#37326;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Effective Horizon of Inverse Reinforcement Learning. (arXiv:2307.06541v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06541
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#36870;&#24378;&#21270;&#23398;&#20064;&#20013;&#26102;&#38388;&#35270;&#37326;&#30340;&#37325;&#35201;&#24615;&#65292;&#21457;&#29616;&#30701;&#20110;&#23454;&#38469;&#20540;&#30340;&#26377;&#25928;&#26102;&#38388;&#35270;&#37326;&#21487;&#20197;&#26356;&#24555;&#19988;&#26356;&#20934;&#30830;&#22320;&#20272;&#35745;&#22870;&#21169;&#20989;&#25968;&#65292;&#20943;&#36731;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#36824;&#21628;&#21505;&#22312;IRL&#20013;&#21516;&#26102;&#23398;&#20064;&#22870;&#21169;&#21644;&#26377;&#25928;&#26102;&#38388;&#35270;&#37326;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36870;&#24378;&#21270;&#23398;&#20064;&#65288;IRL&#65289;&#31639;&#27861;&#36890;&#24120;&#20381;&#36182;&#20110;&#22522;&#20110;&#32473;&#23450;&#26102;&#38388;&#35270;&#37326;&#30340;&#65288;&#21069;&#21521;&#65289;&#24378;&#21270;&#23398;&#20064;&#25110;&#35268;&#21010;&#26469;&#35745;&#31639;&#19968;&#20010;&#36817;&#20284;&#26368;&#20248;&#31574;&#30053;&#65292;&#28982;&#21518;&#23558;&#35813;&#31574;&#30053;&#19982;&#19987;&#23478;&#28436;&#31034;&#21305;&#37197;&#12290;&#26102;&#38388;&#35270;&#37326;&#22312;&#30830;&#23450;&#22870;&#21169;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#21644;IRL&#31639;&#27861;&#30340;&#35745;&#31639;&#25928;&#29575;&#26041;&#38754;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#27604;&#22320;&#38754;&#23454;&#38469;&#20540;&#26356;&#30701;&#30340;&#26377;&#25928;&#26102;&#38388;&#35270;&#37326;&#36890;&#24120;&#33021;&#26356;&#24555;&#22320;&#20135;&#29983;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;&#26412;&#25991;&#23545;&#27492;&#29616;&#35937;&#36827;&#34892;&#20102;&#27491;&#24335;&#20998;&#26512;&#24182;&#32473;&#20986;&#20102;&#35299;&#37322;&#65306;&#26102;&#38388;&#35270;&#37326;&#25511;&#21046;&#20102;&#24341;&#21457;&#31574;&#30053;&#31867;&#30340;&#22797;&#26434;&#24615;&#65292;&#24182;&#22312;&#26377;&#38480;&#25968;&#25454;&#19979;&#20943;&#36731;&#36807;&#25311;&#21512;&#12290;&#36825;&#19968;&#20998;&#26512;&#20026;IRL&#30340;&#26377;&#25928;&#35270;&#37326;&#36873;&#25321;&#25552;&#20379;&#20102;&#21407;&#21017;&#24615;&#25351;&#23548;&#12290;&#23427;&#20063;&#20419;&#20351;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#32463;&#20856;&#30340;IRL&#20844;&#24335;&#65306;&#19982;&#20165;&#20855;&#26377;&#32473;&#23450;&#35270;&#37326;&#30340;&#22870;&#21169;&#30456;&#27604;&#65292;&#20849;&#21516;&#23398;&#20064;&#22870;&#21169;&#21644;&#26377;&#25928;&#35270;&#37326;&#26356;&#21152;&#33258;&#28982;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#36827;&#19968;&#27493;&#39564;&#35777;&#20102;&#36825;&#19968;&#35266;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inverse reinforcement learning (IRL) algorithms often rely on (forward) reinforcement learning or planning over a given time horizon to compute an approximately optimal policy for a hypothesized reward function and then match this policy with expert demonstrations. The time horizon plays a critical role in determining both the accuracy of reward estimate and the computational efficiency of IRL algorithms. Interestingly, an effective time horizon shorter than the ground-truth value often produces better results faster. This work formally analyzes this phenomenon and provides an explanation: the time horizon controls the complexity of an induced policy class and mitigates overfitting with limited data. This analysis leads to a principled choice of the effective horizon for IRL. It also prompts us to reexamine the classic IRL formulation: it is more natural to learn jointly the reward and the effective horizon together rather than the reward alone with a given horizon. Our experimental re
&lt;/p&gt;</description></item><item><title>&#23545;&#27169;&#22411;&#35299;&#37322;&#30340;&#29992;&#25143;&#30740;&#31350;&#32508;&#36848;&#21457;&#29616;&#65292;&#21487;&#35299;&#37322;&#22411;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#27491;&#22312;&#26576;&#20123;&#24212;&#29992;&#39046;&#22495;&#24555;&#36895;&#25193;&#25955;&#65292;&#20294;&#29992;&#25143;&#35780;&#20272;&#20173;&#28982;&#31232;&#32570;&#19988;&#20960;&#20046;&#19981;&#28041;&#21450;&#35748;&#30693;&#25110;&#31038;&#20250;&#31185;&#23398;&#30340;&#35265;&#35299;&#12290;</title><link>http://arxiv.org/abs/2210.11584</link><description>&lt;p&gt;
&#26397;&#30528;&#20197;&#20154;&#20026;&#20013;&#24515;&#30340;&#21487;&#35299;&#37322;&#22411;&#20154;&#24037;&#26234;&#33021;&#65306;&#23545;&#27169;&#22411;&#35299;&#37322;&#30340;&#29992;&#25143;&#30740;&#31350;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Towards Human-centered Explainable AI: A Survey of User Studies for Model Explanations. (arXiv:2210.11584v3 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.11584
&lt;/p&gt;
&lt;p&gt;
&#23545;&#27169;&#22411;&#35299;&#37322;&#30340;&#29992;&#25143;&#30740;&#31350;&#32508;&#36848;&#21457;&#29616;&#65292;&#21487;&#35299;&#37322;&#22411;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#27491;&#22312;&#26576;&#20123;&#24212;&#29992;&#39046;&#22495;&#24555;&#36895;&#25193;&#25955;&#65292;&#20294;&#29992;&#25143;&#35780;&#20272;&#20173;&#28982;&#31232;&#32570;&#19988;&#20960;&#20046;&#19981;&#28041;&#21450;&#35748;&#30693;&#25110;&#31038;&#20250;&#31185;&#23398;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#35299;&#37322;&#22411;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#34987;&#24191;&#27867;&#35748;&#20026;&#26159;&#19981;&#26029;&#25193;&#23637;&#30340;&#20154;&#24037;&#26234;&#33021;&#30740;&#31350;&#30340;&#24517;&#38656;&#26465;&#20214;&#12290;&#23545;XAI&#29992;&#25143;&#38656;&#27714;&#30340;&#26356;&#22909;&#29702;&#35299;&#20197;&#21450;&#21487;&#35299;&#37322;&#27169;&#22411;&#30340;&#20154;&#26412;&#35780;&#20272;&#26082;&#26159;&#24517;&#35201;&#24615;&#20063;&#26159;&#25361;&#25112;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#31995;&#32479;&#24615;&#25991;&#29486;&#32508;&#36848;&#30740;&#31350;&#20102;HCI&#21644;AI&#30740;&#31350;&#20154;&#21592;&#22914;&#20309;&#36827;&#34892;XAI&#24212;&#29992;&#30340;&#29992;&#25143;&#30740;&#31350;&#12290;&#36890;&#36807;&#23545;&#36807;&#21435;&#20116;&#24180;&#20013;&#22522;&#20110;&#20154;&#31867;&#30340;XAI&#35780;&#20272;&#30340;97&#31687;&#26680;&#24515;&#35770;&#25991;&#36827;&#34892;&#35782;&#21035;&#21644;&#28145;&#20837;&#20998;&#26512;&#65292;&#25105;&#20204;&#23558;&#20854;&#25353;&#29031;&#35299;&#37322;&#26041;&#27861;&#30340;&#27979;&#37327;&#29305;&#24449;&#65288;&#20449;&#20219;&#12289;&#29702;&#35299;&#12289;&#21487;&#29992;&#24615;&#21644;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#30340;&#21512;&#20316;&#34920;&#29616;&#65289;&#36827;&#34892;&#20998;&#31867;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;XAI&#22312;&#26576;&#20123;&#24212;&#29992;&#39046;&#22495;&#65288;&#22914;&#25512;&#33616;&#31995;&#32479;&#65289;&#25193;&#25955;&#26356;&#36805;&#36895;&#65292;&#20294;&#29992;&#25143;&#35780;&#20272;&#20173;&#30456;&#24403;&#31232;&#32570;&#65292;&#24182;&#19988;&#20960;&#20046;&#27809;&#26377;&#34701;&#20837;&#35748;&#30693;&#25110;&#31038;&#20250;&#31185;&#23398;&#30340;&#20219;&#20309;&#35265;&#35299;&#12290;&#22522;&#20110;&#32508;&#21512;&#35752;&#35770;&#30340;&#26368;&#20339;&#23454;&#36341;&#65292;&#21363;&#24120;&#35265;&#27169;&#22411;&#12289;&#35774;&#35745;&#36873;&#25321;&#21644;&#24230;&#37327;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Explainable AI (XAI) is widely viewed as a sine qua non for ever-expanding AI research. A better understanding of the needs of XAI users, as well as human-centered evaluations of explainable models are both a necessity and a challenge. In this paper, we explore how HCI and AI researchers conduct user studies in XAI applications based on a systematic literature review. After identifying and thoroughly analyzing 97core papers with human-based XAI evaluations over the past five years, we categorize them along the measured characteristics of explanatory methods, namely trust, understanding, usability, and human-AI collaboration performance. Our research shows that XAI is spreading more rapidly in certain application domains, such as recommender systems than in others, but that user evaluations are still rather sparse and incorporate hardly any insights from cognitive or social sciences. Based on a comprehensive discussion of best practices, i.e., common models, design choices, and measures
&lt;/p&gt;</description></item></channel></rss>