<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#32039;&#32806;&#21512;LiDAR-IMU-&#36718;&#37324;&#31243;&#35745;&#31639;&#27861;&#65292;&#20351;&#29992;&#22312;&#32447;&#26657;&#20934;&#35299;&#20915;&#28369;&#31227;&#36716;&#21521;&#26426;&#22120;&#20154;&#22312;&#25361;&#25112;&#24615;&#29615;&#22659;&#20013;&#30340;&#28857;&#20113;&#36864;&#21270;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2404.02515</link><description>&lt;p&gt;
&#21033;&#29992;&#22312;&#32447;&#26657;&#20934;&#36816;&#21160;&#27169;&#22411;&#30340;&#32039;&#32806;&#21512;LiDAR-IMU-&#36718;&#37324;&#31243;&#35745;&#31639;&#27861;&#29992;&#20110;&#28369;&#31227;&#36716;&#21521;&#26426;&#22120;&#20154;
&lt;/p&gt;
&lt;p&gt;
Tightly-Coupled LiDAR-IMU-Wheel Odometry with Online Calibration of a Kinematic Model for Skid-Steering Robots
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02515
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#32039;&#32806;&#21512;LiDAR-IMU-&#36718;&#37324;&#31243;&#35745;&#31639;&#27861;&#65292;&#20351;&#29992;&#22312;&#32447;&#26657;&#20934;&#35299;&#20915;&#28369;&#31227;&#36716;&#21521;&#26426;&#22120;&#20154;&#22312;&#25361;&#25112;&#24615;&#29615;&#22659;&#20013;&#30340;&#28857;&#20113;&#36864;&#21270;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38567;&#36947;&#21644;&#38271;&#24266;&#26159;&#31227;&#21160;&#26426;&#22120;&#20154;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#29615;&#22659;&#65292;&#22240;&#20026;&#22312;&#36825;&#20123;&#29615;&#22659;&#20013;LiDAR&#28857;&#20113;&#20250;&#36864;&#21270;&#12290;&#20026;&#20102;&#35299;&#20915;&#28857;&#20113;&#36864;&#21270;&#38382;&#39064;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#28369;&#31227;&#36716;&#21521;&#26426;&#22120;&#20154;&#30340;&#32039;&#32806;&#21512;LiDAR-IMU-&#36718;&#37324;&#31243;&#35745;&#31639;&#27861;&#65292;&#21516;&#26102;&#36824;&#20351;&#29992;&#22312;&#32447;&#26657;&#20934;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23436;&#25972;&#30340;&#32447;&#24615;&#36718;&#23376;&#37324;&#31243;&#35745;&#22240;&#23376;&#65292;&#19981;&#20165;&#20316;&#20026;&#36816;&#21160;&#32422;&#26463;&#65292;&#36824;&#21487;&#20197;&#25191;&#34892;&#28369;&#31227;&#36716;&#21521;&#26426;&#22120;&#20154;&#36816;&#21160;&#27169;&#22411;&#30340;&#22312;&#32447;&#26657;&#20934;&#12290;&#23613;&#31649;&#36816;&#21160;&#27169;&#22411;&#21160;&#24577;&#21464;&#21270;&#65288;&#20363;&#22914;&#30001;&#20110;&#32974;&#21387;&#24341;&#36215;&#30340;&#36718;&#32974;&#21322;&#24452;&#21464;&#21270;&#65289;&#21644;&#22320;&#24418;&#26465;&#20214;&#21464;&#21270;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#36890;&#36807;&#22312;&#32447;&#26657;&#20934;&#26469;&#35299;&#20915;&#27169;&#22411;&#35823;&#24046;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#22312;&#36864;&#21270;&#29615;&#22659;&#19979;&#65288;&#22914;&#38271;&#30452;&#24266;&#65289;&#36890;&#36807;&#26657;&#20934;&#32780;&#23454;&#29616;&#20934;&#30830;&#23450;&#20301;&#65292;&#21516;&#26102;LiDAR-IMU&#34701;&#21512;&#36816;&#20316;&#33391;&#22909;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#20272;&#35745;&#20102;&#36718;&#23376;&#37324;&#31243;&#35745;&#30340;&#19981;&#30830;&#23450;&#24615;&#65288;&#21363;&#21327;&#26041;&#24046;&#30697;&#38453;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02515v1 Announce Type: cross  Abstract: Tunnels and long corridors are challenging environments for mobile robots because a LiDAR point cloud should degenerate in these environments. To tackle point cloud degeneration, this study presents a tightly-coupled LiDAR-IMU-wheel odometry algorithm with an online calibration for skid-steering robots. We propose a full linear wheel odometry factor, which not only serves as a motion constraint but also performs the online calibration of kinematic models for skid-steering robots. Despite the dynamically changing kinematic model (e.g., wheel radii changes caused by tire pressures) and terrain conditions, our method can address the model error via online calibration. Moreover, our method enables an accurate localization in cases of degenerated environments, such as long and straight corridors, by calibration while the LiDAR-IMU fusion sufficiently operates. Furthermore, we estimate the uncertainty (i.e., covariance matrix) of the wheel o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#23454;&#20363;&#32423;&#26816;&#32034;&#20219;&#21153;&#65306;PointCloud-Text&#21305;&#37197;&#65288;PTM&#65289;&#65292;&#24182;&#26500;&#24314;&#20102;&#19977;&#20010;&#26032;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#20197;&#35299;&#20915;&#25968;&#25454;&#31232;&#30095;&#12289;&#25991;&#26412;&#27169;&#31946;&#31561;&#25361;&#25112;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;RoMa&#26041;&#27861;&#20316;&#20026;PTM&#30340;&#22522;&#32447;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2403.19386</link><description>&lt;p&gt;
PointCloud-Text&#21305;&#37197;&#65306;&#22522;&#20934;&#25968;&#25454;&#38598;&#21644;&#19968;&#20010;&#22522;&#32447;
&lt;/p&gt;
&lt;p&gt;
PointCloud-Text Matching: Benchmark Datasets and a Baseline
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19386
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#23454;&#20363;&#32423;&#26816;&#32034;&#20219;&#21153;&#65306;PointCloud-Text&#21305;&#37197;&#65288;PTM&#65289;&#65292;&#24182;&#26500;&#24314;&#20102;&#19977;&#20010;&#26032;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#20197;&#35299;&#20915;&#25968;&#25454;&#31232;&#30095;&#12289;&#25991;&#26412;&#27169;&#31946;&#31561;&#25361;&#25112;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;RoMa&#26041;&#27861;&#20316;&#20026;PTM&#30340;&#22522;&#32447;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#21644;&#30740;&#31350;&#20102;&#19968;&#20010;&#26032;&#30340;&#23454;&#20363;&#32423;&#26816;&#32034;&#20219;&#21153;&#65306;PointCloud-Text Matching&#65288;PTM&#65289;&#65292;&#26088;&#22312;&#25214;&#21040;&#19982;&#32473;&#23450;&#30340;&#28857;&#20113;&#26597;&#35810;&#25110;&#25991;&#26412;&#26597;&#35810;&#21305;&#37197;&#30340;&#30830;&#20999;&#36328;&#27169;&#24577;&#23454;&#20363;&#12290;PTM&#21487;&#24212;&#29992;&#20110;&#21508;&#31181;&#22330;&#26223;&#65292;&#22914;&#23460;&#20869;/&#22478;&#24066;&#23777;&#35895;&#23450;&#20301;&#21644;&#22330;&#26223;&#26816;&#32034;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#23578;&#26080;&#36866;&#29992;&#30340;&#12289;&#26377;&#38024;&#23545;&#24615;&#30340;PTM&#25968;&#25454;&#38598;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19977;&#20010;&#26032;&#30340;PTM&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#20998;&#21035;&#20026;3D2T-SR&#12289;3D2T-NR&#21644;3D2T-QA&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#25968;&#25454;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#30001;&#20110;&#28857;&#20113;&#30340;&#31232;&#30095;&#12289;&#22122;&#22768;&#25110;&#26080;&#24207;&#65292;&#20197;&#21450;&#25991;&#26412;&#30340;&#27169;&#31946;&#12289;&#21547;&#31946;&#25110;&#19981;&#23436;&#25972;&#65292;&#23548;&#33268;&#23384;&#22312;&#22024;&#26434;&#30340;&#23545;&#24212;&#20851;&#31995;&#65292;&#20351;&#24471;&#29616;&#26377;&#30340;&#36328;&#27169;&#24577;&#21305;&#37197;&#26041;&#27861;&#23545;PTM&#26080;&#25928;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;PTM&#22522;&#32447;&#65292;&#21629;&#21517;&#20026;Robust PointCloud-Text Matching&#26041;&#27861;&#65288;RoMa&#65289;&#12290;RoMa&#21253;&#21547;&#20004;&#20010;&#27169;&#22359;&#65306;&#21452;&#37325;&#27880;&#24847;&#24863;&#30693;&#27169;&#22359;&#65288;DAP&#65289;&#21644;&#40065;&#26834;&#36127;&#23545;&#27604;&#27169;&#22359;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19386v1 Announce Type: cross  Abstract: In this paper, we present and study a new instance-level retrieval task: PointCloud-Text Matching~(PTM), which aims to find the exact cross-modal instance that matches a given point-cloud query or text query. PTM could be applied to various scenarios, such as indoor/urban-canyon localization and scene retrieval. However, there exists no suitable and targeted dataset for PTM in practice. Therefore, we construct three new PTM benchmark datasets, namely 3D2T-SR, 3D2T-NR, and 3D2T-QA. We observe that the data is challenging and with noisy correspondence due to the sparsity, noise, or disorder of point clouds and the ambiguity, vagueness, or incompleteness of texts, which make existing cross-modal matching methods ineffective for PTM. To tackle these challenges, we propose a PTM baseline, named Robust PointCloud-Text Matching method (RoMa). RoMa consists of two modules: a Dual Attention Perception module (DAP) and a Robust Negative Contrast
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#21487;&#22312;&#38382;&#39064;&#31354;&#38388;&#20869;&#26500;&#24314;&#23545;&#25239;&#26679;&#26412;&#65292;&#23545;&#25239;&#38450;&#30149;&#27602;&#36719;&#20214;&#20013;&#30340;&#24694;&#24847;&#36719;&#20214;&#25915;&#20987;&#12290;</title><link>https://arxiv.org/abs/2402.19027</link><description>&lt;p&gt;
&#22914;&#20309;&#35757;&#32451;&#24744;&#30340;&#38450;&#30149;&#27602;&#36719;&#20214;&#65306;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#38382;&#39064;&#31354;&#38388;&#21152;&#22266;
&lt;/p&gt;
&lt;p&gt;
How to Train your Antivirus: RL-based Hardening through the Problem-Space
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.19027
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#21487;&#22312;&#38382;&#39064;&#31354;&#38388;&#20869;&#26500;&#24314;&#23545;&#25239;&#26679;&#26412;&#65292;&#23545;&#25239;&#38450;&#30149;&#27602;&#36719;&#20214;&#20013;&#30340;&#24694;&#24847;&#36719;&#20214;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#19968;&#31181;&#29305;&#23450;&#30340;&#26426;&#22120;&#23398;&#20064;&#26550;&#26500;&#65292;&#29992;&#20110;&#21152;&#22266;&#19968;&#23478;&#33879;&#21517;&#21830;&#19994;&#38450;&#30149;&#27602;&#20844;&#21496;&#27969;&#31243;&#20013;&#30340;&#26426;&#22120;&#23398;&#20064;&#38450;&#24481;&#25216;&#26415;&#65292;&#20197;&#23545;&#25239;&#24694;&#24847;&#36719;&#20214;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#26500;&#24314;&#23545;&#25239;&#26679;&#26412;&#65292;&#36825;&#26159;&#23545;&#25239;&#36867;&#36991;&#25915;&#20987;&#30340;&#27169;&#22411;&#35757;&#32451;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.19027v1 Announce Type: cross  Abstract: ML-based malware detection on dynamic analysis reports is vulnerable to both evasion and spurious correlations. In this work, we investigate a specific ML architecture employed in the pipeline of a widely-known commercial antivirus company, with the goal to harden it against adversarial malware. Adversarial training, the sole defensive technique that can confer empirical robustness, is not applicable out of the box in this domain, for the principal reason that gradient-based perturbations rarely map back to feasible problem-space programs. We introduce a novel Reinforcement Learning approach for constructing adversarial examples, a constituent part of adversarially training a model against evasion. Our approach comes with multiple advantages. It performs modifications that are feasible in the problem-space, and only those; thus it circumvents the inverse mapping problem. It also makes possible to provide theoretical guarantees on the r
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#40784;&#21040;&#29305;&#23450;&#39046;&#22495;&#30340;&#22270;&#25968;&#25454;&#24211;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;ChatGPT&#29983;&#25104;NL-GQL&#25968;&#25454;&#23545;&#24182;&#24494;&#35843;LLMs&#65292;&#23454;&#29616;&#20102;&#20004;&#32773;&#20043;&#38388;&#30340;&#23545;&#40784;&#12290;</title><link>https://arxiv.org/abs/2402.16567</link><description>&lt;p&gt;
&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#40784;&#21040;&#29305;&#23450;&#39046;&#22495;&#30340;&#22270;&#25968;&#25454;&#24211;
&lt;/p&gt;
&lt;p&gt;
Aligning Large Language Models to a Domain-specific Graph Database
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16567
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#40784;&#21040;&#29305;&#23450;&#39046;&#22495;&#30340;&#22270;&#25968;&#25454;&#24211;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;ChatGPT&#29983;&#25104;NL-GQL&#25968;&#25454;&#23545;&#24182;&#24494;&#35843;LLMs&#65292;&#23454;&#29616;&#20102;&#20004;&#32773;&#20043;&#38388;&#30340;&#23545;&#40784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#25968;&#25454;&#24211;&#65288;Graph DB&#65289;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#37329;&#34701;&#12289;&#31038;&#20132;&#32593;&#32476;&#21644;&#21307;&#33647;&#31561;&#21508;&#20010;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#23558;&#33258;&#28982;&#35821;&#35328;&#65288;NL&#65289;&#36716;&#25442;&#20026;&#22270;&#26597;&#35810;&#35821;&#35328;&#65288;GQL&#65289;&#65292;&#36890;&#24120;&#31216;&#20026;NL2GQL&#65292;&#30001;&#20110;&#20854;&#22266;&#26377;&#22797;&#26434;&#24615;&#21644;&#19987;&#19994;&#21270;&#29305;&#24615;&#32780;&#21464;&#24471;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#19968;&#20123;&#26041;&#27861;&#35797;&#22270;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26469;&#35299;&#20915;&#31867;&#20284;&#30340;&#20219;&#21153;&#65292;&#22914;&#25991;&#26412;&#36716;SQL&#12290;&#28982;&#32780;&#65292;&#22312;&#29305;&#23450;&#39046;&#22495;&#30340;NL2GQL&#20219;&#21153;&#20013;&#65292;&#32570;&#20047;&#29305;&#23450;&#39046;&#22495;&#30340;NL-GQL&#25968;&#25454;&#23545;&#20351;&#24471;&#38590;&#20197;&#24314;&#31435;LLMs&#21644;&#22270;&#25968;&#25454;&#24211;&#20043;&#38388;&#30340;&#23545;&#40784;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26126;&#30830;&#23450;&#20041;&#30340;&#27969;&#27700;&#32447;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#21033;&#29992;ChatGPT&#22522;&#20110;&#32473;&#23450;&#30340;&#22270;&#25968;&#25454;&#24211;&#33258;&#25105;&#29983;&#25104;NL-GQL&#25968;&#25454;&#23545;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#21019;&#24314;&#30340;&#25968;&#25454;&#26469;&#23545;LLMs&#36827;&#34892;&#24494;&#35843;&#65292;&#20174;&#32780;&#23454;&#29616;LLMs&#19982;&#22270;&#25968;&#25454;&#24211;&#20043;&#38388;&#30340;&#23545;&#40784;&#12290;&#27492;&#22806;&#65292;&#22312;&#25512;&#26029;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25552;&#21462;&#30456;&#20851;&#20449;&#24687;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16567v1 Announce Type: new  Abstract: Graph Databases (Graph DB) are widely applied in various fields, including finance, social networks, and medicine. However, translating Natural Language (NL) into the Graph Query Language (GQL), commonly known as NL2GQL, proves to be challenging due to its inherent complexity and specialized nature. Some approaches have sought to utilize Large Language Models (LLMs) to address analogous tasks like text2SQL. Nevertheless, when it comes to NL2GQL taskson a particular domain, the absence of domain-specific NL-GQL data pairs makes it difficult to establish alignment between LLMs and the graph DB. To address this challenge, we propose a well-defined pipeline. Specifically, we utilize ChatGPT to create NL-GQL data pairs based on the given graph DB with self-instruct. Then, we use the created data to fine-tune LLMs, thereby achieving alignment between LLMs and the graph DB. Additionally, during inference, we propose a method that extracts relev
&lt;/p&gt;</description></item><item><title>&#35821;&#35328;&#24341;&#23548;&#30340;&#19990;&#30028;&#27169;&#22411;&#65288;LWMs&#65289;&#26159;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#20154;&#24037;&#26234;&#33021;&#25511;&#21046;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#38405;&#35835;&#35821;&#35328;&#25551;&#36848;&#26469;&#25429;&#25417;&#29615;&#22659;&#21160;&#24577;&#65292;&#25552;&#39640;&#20102;&#20195;&#29702;&#30340;&#27807;&#36890;&#25928;&#29575;&#65292;&#24182;&#20801;&#35768;&#20154;&#31867;&#36890;&#36807;&#31616;&#27905;&#30340;&#35821;&#35328;&#21453;&#39304;&#21516;&#26102;&#25913;&#21464;&#20182;&#20204;&#22312;&#22810;&#20010;&#20219;&#21153;&#19978;&#30340;&#34892;&#20026;&#12290;</title><link>https://arxiv.org/abs/2402.01695</link><description>&lt;p&gt;
&#35821;&#35328;&#24341;&#23548;&#30340;&#19990;&#30028;&#27169;&#22411;&#65306;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#20154;&#24037;&#26234;&#33021;&#25511;&#21046;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Language-Guided World Models: A Model-Based Approach to AI Control
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01695
&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#24341;&#23548;&#30340;&#19990;&#30028;&#27169;&#22411;&#65288;LWMs&#65289;&#26159;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#20154;&#24037;&#26234;&#33021;&#25511;&#21046;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#38405;&#35835;&#35821;&#35328;&#25551;&#36848;&#26469;&#25429;&#25417;&#29615;&#22659;&#21160;&#24577;&#65292;&#25552;&#39640;&#20102;&#20195;&#29702;&#30340;&#27807;&#36890;&#25928;&#29575;&#65292;&#24182;&#20801;&#35768;&#20154;&#31867;&#36890;&#36807;&#31616;&#27905;&#30340;&#35821;&#35328;&#21453;&#39304;&#21516;&#26102;&#25913;&#21464;&#20182;&#20204;&#22312;&#22810;&#20010;&#20219;&#21153;&#19978;&#30340;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#27010;&#29575;&#19990;&#30028;&#27169;&#22411;&#23433;&#35013;&#21040;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#20013;&#65292;&#20026;&#20154;&#31867;&#19982;&#36825;&#20123;&#20195;&#29702;&#27807;&#36890;&#21644;&#25511;&#21046;&#25171;&#24320;&#20102;&#19968;&#20010;&#39640;&#25928;&#30340;&#28192;&#36947;&#12290;&#38500;&#20102;&#26356;&#26032;&#20195;&#29702;&#31574;&#30053;&#65292;&#20154;&#31867;&#36824;&#21487;&#20197;&#20462;&#25913;&#20182;&#20204;&#30340;&#20869;&#37096;&#19990;&#30028;&#27169;&#22411;&#65292;&#20197;&#24433;&#21709;&#20195;&#29702;&#30340;&#20915;&#31574;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#29616;&#26377;&#30340;&#19990;&#30028;&#27169;&#22411;&#38590;&#20197;&#36866;&#24212;&#20154;&#31867;&#65292;&#22240;&#20026;&#23427;&#20204;&#32570;&#20047;&#33258;&#28982;&#30340;&#36890;&#20449;&#30028;&#38754;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#35821;&#35328;&#24341;&#23548;&#30340;&#19990;&#30028;&#27169;&#22411;&#65288;LWMs&#65289;&#65292;&#23427;&#20204;&#21487;&#20197;&#36890;&#36807;&#38405;&#35835;&#35821;&#35328;&#25551;&#36848;&#26469;&#25429;&#25417;&#29615;&#22659;&#21160;&#24577;&#12290;&#36825;&#20123;&#27169;&#22411;&#25552;&#39640;&#20102;&#20195;&#29702;&#30340;&#27807;&#36890;&#25928;&#29575;&#65292;&#20351;&#20154;&#31867;&#33021;&#22815;&#36890;&#36807;&#31616;&#27905;&#30340;&#35821;&#35328;&#21453;&#39304;&#21516;&#26102;&#25913;&#21464;&#20182;&#20204;&#22312;&#22810;&#20010;&#20219;&#21153;&#19978;&#30340;&#34892;&#20026;&#12290;&#23427;&#20204;&#36824;&#20351;&#20195;&#29702;&#33021;&#22815;&#20174;&#26368;&#21021;&#29992;&#20110;&#25351;&#23548;&#20154;&#31867;&#30340;&#25991;&#26412;&#20013;&#36827;&#34892;&#33258;&#25105;&#23398;&#20064;&#12290;&#20026;&#20102;&#20419;&#36827;LWMs&#30340;&#21457;&#23637;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#22522;&#20110;MESSENGER&#28216;&#25103;&#65288;Hanjie&#31561;&#20154;&#65292;2021&#65289;&#30340;&#25361;&#25112;&#22522;&#20934;&#65292;&#38656;&#35201;&#23545;&#26032;&#22330;&#26223;&#36827;&#34892;&#32452;&#21512;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Installing probabilistic world models into artificial agents opens an efficient channel for humans to communicate with and control these agents. In addition to updating agent policies, humans can modify their internal world models in order to influence their decisions. The challenge, however, is that currently existing world models are difficult for humans to adapt because they lack a natural communication interface. Aimed at addressing this shortcoming, we develop Language-Guided World Models (LWMs), which can capture environment dynamics by reading language descriptions. These models enhance agent communication efficiency, allowing humans to simultaneously alter their behavior on multiple tasks with concise language feedback. They also enable agents to self-learn from texts originally written to instruct humans. To facilitate the development of LWMs, we design a challenging benchmark based on the game of MESSENGER (Hanjie et al., 2021), requiring compositional generalization to new l
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#32508;&#21512;&#32479;&#35745;&#20915;&#31574;&#29702;&#35770;&#21644;&#20449;&#24687;&#32463;&#27982;&#23398;&#65292;&#25552;&#20986;&#20102;&#20915;&#31574;&#38382;&#39064;&#30340;&#24191;&#27867;&#36866;&#29992;&#23450;&#20041;&#12290;&#20026;&#20102;&#23558;&#20154;&#31867;&#20915;&#31574;&#30340;&#19979;&#38477;&#24402;&#21646;&#20110;&#20559;&#35265;&#24418;&#24335;&#65292;&#23454;&#39564;&#24517;&#39035;&#21521;&#21442;&#19982;&#32773;&#25552;&#20379;&#36275;&#22815;&#30340;&#20449;&#24687;&#26469;&#35782;&#21035;&#35268;&#33539;&#20915;&#31574;&#12290;&#28982;&#32780;&#65292;&#26681;&#25454;&#20316;&#32773;&#23545;AI&#36741;&#21161;&#20915;&#31574;&#30340;&#30740;&#31350;&#30340;&#35780;&#20272;&#65292;&#21482;&#26377;17%&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#36275;&#22815;&#30340;&#20449;&#24687;&#26469;&#25551;&#36848;&#21442;&#19982;&#32773;&#30340;&#34892;&#20026;&#20559;&#31163;&#20102;&#33391;&#22909;&#30340;&#20915;&#31574;&#12290;</title><link>http://arxiv.org/abs/2401.15106</link><description>&lt;p&gt;
&#20915;&#31574;&#29702;&#35770;&#22522;&#30784;&#23545;&#35780;&#20272;&#20154;&#31867;&#20915;&#31574;&#30340;&#23454;&#39564;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Decision Theoretic Foundations for Experiments Evaluating Human Decisions. (arXiv:2401.15106v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15106
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#32508;&#21512;&#32479;&#35745;&#20915;&#31574;&#29702;&#35770;&#21644;&#20449;&#24687;&#32463;&#27982;&#23398;&#65292;&#25552;&#20986;&#20102;&#20915;&#31574;&#38382;&#39064;&#30340;&#24191;&#27867;&#36866;&#29992;&#23450;&#20041;&#12290;&#20026;&#20102;&#23558;&#20154;&#31867;&#20915;&#31574;&#30340;&#19979;&#38477;&#24402;&#21646;&#20110;&#20559;&#35265;&#24418;&#24335;&#65292;&#23454;&#39564;&#24517;&#39035;&#21521;&#21442;&#19982;&#32773;&#25552;&#20379;&#36275;&#22815;&#30340;&#20449;&#24687;&#26469;&#35782;&#21035;&#35268;&#33539;&#20915;&#31574;&#12290;&#28982;&#32780;&#65292;&#26681;&#25454;&#20316;&#32773;&#23545;AI&#36741;&#21161;&#20915;&#31574;&#30340;&#30740;&#31350;&#30340;&#35780;&#20272;&#65292;&#21482;&#26377;17%&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#36275;&#22815;&#30340;&#20449;&#24687;&#26469;&#25551;&#36848;&#21442;&#19982;&#32773;&#30340;&#34892;&#20026;&#20559;&#31163;&#20102;&#33391;&#22909;&#30340;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20449;&#24687;&#23637;&#31034;&#30340;&#20915;&#31574;&#26159;&#21487;&#35299;&#37322;AI&#12289;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#30340;&#21512;&#20316;&#20197;&#21450;&#25968;&#25454;&#21487;&#35270;&#21270;&#31561;&#39046;&#22495;&#30740;&#31350;&#30340;&#37325;&#28857;&#12290;&#28982;&#32780;&#65292;&#20915;&#31574;&#38382;&#39064;&#30340;&#23450;&#20041;&#20197;&#21450;&#23454;&#39564;&#24517;&#39035;&#20855;&#22791;&#30340;&#26465;&#20214;&#20197;&#24471;&#20986;&#20154;&#31867;&#20915;&#31574;&#23384;&#22312;&#32570;&#38519;&#30340;&#32467;&#35770;&#20173;&#28982;&#23384;&#22312;&#20105;&#35758;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#24191;&#27867;&#36866;&#29992;&#30340;&#20915;&#31574;&#38382;&#39064;&#23450;&#20041;&#65292;&#35813;&#23450;&#20041;&#26159;&#20174;&#32479;&#35745;&#20915;&#31574;&#29702;&#35770;&#21644;&#20449;&#24687;&#32463;&#27982;&#23398;&#20013;&#32508;&#21512;&#25552;&#28860;&#32780;&#26469;&#30340;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#35201;&#23558;&#20154;&#31867;&#32489;&#25928;&#19979;&#38477;&#24402;&#21646;&#20110;&#26576;&#31181;&#20559;&#35265;&#24418;&#24335;&#65292;&#23454;&#39564;&#24517;&#39035;&#21521;&#21442;&#19982;&#32773;&#25552;&#20379;&#36275;&#22815;&#30340;&#20449;&#24687;&#65292;&#20197;&#20415;&#21512;&#29702;&#30340;&#20195;&#29702;&#33021;&#22815;&#35782;&#21035;&#35268;&#33539;&#20915;&#31574;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#26368;&#36817;&#26377;&#20851;AI&#36741;&#21161;&#20915;&#31574;&#30340;&#25991;&#29486;&#20013;&#23545;&#20915;&#31574;&#21046;&#23450;&#36827;&#34892;&#30340;&#35780;&#20272;&#22312;&#22810;&#22823;&#31243;&#24230;&#19978;&#36798;&#21040;&#20102;&#36825;&#19968;&#26631;&#20934;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#21482;&#26377;35&#39033;&#22768;&#31216;&#30830;&#23450;&#20102;&#26377;&#20559;&#24046;&#34892;&#20026;&#30340;&#30740;&#31350;&#20013;&#30340;6&#39033;&#65288;17%&#65289;&#21521;&#21442;&#19982;&#32773;&#25552;&#20379;&#20102;&#36275;&#22815;&#20449;&#24687;&#26469;&#25551;&#36848;&#20854;&#34892;&#20026;&#20559;&#31163;&#33391;&#22909;&#20915;&#31574;
&lt;/p&gt;
&lt;p&gt;
Decision-making with information displays is a key focus of research in areas like explainable AI, human-AI teaming, and data visualization. However, what constitutes a decision problem, and what is required for an experiment to be capable of concluding that human decisions are flawed in some way, remain open to speculation. We present a widely applicable definition of a decision problem synthesized from statistical decision theory and information economics. We argue that to attribute loss in human performance to forms of bias, an experiment must provide participants with the information that a rational agent would need to identify the normative decision. We evaluate the extent to which recent evaluations of decision-making from the literature on AI-assisted decisions achieve this criteria. We find that only 6 (17\%) of 35 studies that claim to identify biased behavior present participants with sufficient information to characterize their behavior as deviating from good decision-making
&lt;/p&gt;</description></item><item><title>Kun&#26159;&#19968;&#31181;&#20351;&#29992;&#25351;&#20196;&#21453;&#21521;&#32763;&#35793;&#21644;&#31572;&#26696;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#21019;&#24314;&#39640;&#36136;&#37327;&#30340;&#25351;&#23548;&#35843;&#25972;&#25968;&#25454;&#38598;&#65292;&#35813;&#26041;&#27861;&#19981;&#20381;&#36182;&#20110;&#25163;&#21160;&#27880;&#37322;&#65292;&#36890;&#36807;&#33258;&#25105;&#31579;&#36873;&#36807;&#31243;&#26469;&#25913;&#21892;&#21644;&#36873;&#25321;&#26368;&#26377;&#25928;&#30340;&#25351;&#20196;-&#36755;&#20986;&#23545;&#12290;&#23427;&#30340;&#20027;&#35201;&#21019;&#26032;&#22312;&#20110;&#36890;&#36807;&#31639;&#27861;&#25913;&#36827;&#25552;&#39640;&#25968;&#25454;&#30340;&#20445;&#30041;&#21644;&#28165;&#26224;&#24230;&#65292;&#24182;&#36890;&#36807;&#21019;&#26032;&#30340;&#25968;&#25454;&#29983;&#25104;&#26041;&#27861;&#20943;&#23569;&#20102;&#25163;&#21160;&#27880;&#37322;&#30340;&#20381;&#36182;&#12290;</title><link>http://arxiv.org/abs/2401.06477</link><description>&lt;p&gt;
Kun: &#20351;&#29992;&#25351;&#20196;&#21453;&#21521;&#32763;&#35793;&#30340;&#20013;&#22269;&#33258;&#23545;&#40784;&#38382;&#39064;&#30340;&#31572;&#26696;&#20248;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Kun: Answer Polishment for Chinese Self-Alignment with Instruction Back-Translation. (arXiv:2401.06477v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06477
&lt;/p&gt;
&lt;p&gt;
Kun&#26159;&#19968;&#31181;&#20351;&#29992;&#25351;&#20196;&#21453;&#21521;&#32763;&#35793;&#21644;&#31572;&#26696;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#21019;&#24314;&#39640;&#36136;&#37327;&#30340;&#25351;&#23548;&#35843;&#25972;&#25968;&#25454;&#38598;&#65292;&#35813;&#26041;&#27861;&#19981;&#20381;&#36182;&#20110;&#25163;&#21160;&#27880;&#37322;&#65292;&#36890;&#36807;&#33258;&#25105;&#31579;&#36873;&#36807;&#31243;&#26469;&#25913;&#21892;&#21644;&#36873;&#25321;&#26368;&#26377;&#25928;&#30340;&#25351;&#20196;-&#36755;&#20986;&#23545;&#12290;&#23427;&#30340;&#20027;&#35201;&#21019;&#26032;&#22312;&#20110;&#36890;&#36807;&#31639;&#27861;&#25913;&#36827;&#25552;&#39640;&#25968;&#25454;&#30340;&#20445;&#30041;&#21644;&#28165;&#26224;&#24230;&#65292;&#24182;&#36890;&#36807;&#21019;&#26032;&#30340;&#25968;&#25454;&#29983;&#25104;&#26041;&#27861;&#20943;&#23569;&#20102;&#25163;&#21160;&#27880;&#37322;&#30340;&#20381;&#36182;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;Kun&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#19981;&#20381;&#36182;&#25163;&#21160;&#27880;&#37322;&#30340;&#24773;&#20917;&#19979;&#20026;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#21019;&#24314;&#39640;&#36136;&#37327;&#30340;&#25351;&#23548;&#35843;&#25972;&#25968;&#25454;&#38598;&#12290;Kun&#21033;&#29992;&#26469;&#33258;&#21566;&#36947;&#12289;&#23436;&#21367;&#21644;SkyPile&#31561;&#22810;&#20010;&#26469;&#28304;&#30340;&#26410;&#26631;&#35760;&#25968;&#25454;&#65292;&#37319;&#29992;&#22522;&#20110;&#25351;&#20196;&#21453;&#21521;&#32763;&#35793;&#21644;&#31572;&#26696;&#20248;&#21270;&#30340;&#33258;&#25105;&#35757;&#32451;&#31639;&#27861;&#65292;&#29983;&#25104;&#20102;&#19968;&#20010;&#36229;&#36807;&#19968;&#30334;&#19975;&#20010;&#20013;&#25991;&#25351;&#23548;&#25968;&#25454;&#28857;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#20351;&#29992;&#33258;&#25105;&#31579;&#36873;&#36807;&#31243;&#26469;&#23436;&#21892;&#21644;&#36873;&#25321;&#26368;&#26377;&#25928;&#30340;&#25351;&#20196;-&#36755;&#20986;&#23545;&#65292;&#26174;&#33879;&#20559;&#31163;&#20256;&#32479;&#26041;&#27861;&#12290;&#25105;&#20204;&#22312;&#22810;&#20010;&#22522;&#20934;&#27979;&#35797;&#19978;&#23545;6B&#21442;&#25968;&#30340;Yi&#27169;&#22411;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#32467;&#26524;&#34920;&#26126;Kun&#20855;&#26377;&#40065;&#26834;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;&#25105;&#20204;&#26041;&#27861;&#30340;&#26680;&#24515;&#36129;&#29486;&#22312;&#20110;&#31639;&#27861;&#30340;&#25913;&#36827;&#65292;&#22686;&#24378;&#20102;&#25968;&#25454;&#30340;&#20445;&#30041;&#21644;&#28165;&#26224;&#24230;&#65292;&#24182;&#19988;&#21019;&#26032;&#30340;&#25968;&#25454;&#29983;&#25104;&#26041;&#27861;&#26497;&#22823;&#22320;&#20943;&#23569;&#20102;&#23545;&#26114;&#36149;&#21644;&#32791;&#26102;&#30340;&#25163;&#21160;&#27880;&#37322;&#30340;&#20381;&#36182;&#12290;&#36825;&#31181;&#26041;&#27861;ological&#26041;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#20013;&#25991;&#33258;&#23545;&#40784;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#39640;&#20102;&#25968;&#25454;&#30340;&#20934;&#30830;&#24615;&#21644;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce Kun, a novel approach for creating high-quality instruction-tuning datasets for large language models (LLMs) without relying on manual annotations. Adapting a self-training algorithm based on instruction back-translation and answer polishment, Kun leverages unlabelled data from diverse sources such as Wudao, Wanjuan, and SkyPile to generate a substantial dataset of over a million Chinese instructional data points. This approach significantly deviates from traditional methods by using a self-curation process to refine and select the most effective instruction-output pairs. Our experiments with the 6B-parameter Yi model across various benchmarks demonstrate Kun's robustness and scalability. Our method's core contributions lie in its algorithmic advancement, which enhances data retention and clarity, and its innovative data generation approach that substantially reduces the reliance on costly and time-consuming manual annotations. This methodology presents a sc
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;SALLMS&#35780;&#20272;LLM&#29983;&#25104;&#20195;&#30721;&#30340;&#23433;&#20840;&#24615;&#65292;&#25351;&#20986;&#29616;&#26377;&#25968;&#25454;&#38598;&#21644;&#35780;&#20272;&#25351;&#26631;&#26410;&#33021;&#20805;&#20998;&#32771;&#34385;&#21040;&#19982;&#23433;&#20840;&#30456;&#20851;&#30340;&#30495;&#23454;&#36719;&#20214;&#24037;&#31243;&#20219;&#21153;&#65292;&#20174;&#32780;&#23548;&#33268;&#19981;&#23433;&#20840;&#30340;&#20195;&#30721;&#29983;&#25104;&#12290;</title><link>http://arxiv.org/abs/2311.00889</link><description>&lt;p&gt;
&#29983;&#25104;&#21644;&#39564;&#35777;&#65306;&#20351;&#29992;SALLMS&#35780;&#20272;LLM&#29983;&#25104;&#30340;&#20195;&#30721;&#30340;&#23433;&#20840;&#24615;
&lt;/p&gt;
&lt;p&gt;
Generate and Pray: Using SALLMS to Evaluate the Security of LLM Generated Code. (arXiv:2311.00889v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00889
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;SALLMS&#35780;&#20272;LLM&#29983;&#25104;&#20195;&#30721;&#30340;&#23433;&#20840;&#24615;&#65292;&#25351;&#20986;&#29616;&#26377;&#25968;&#25454;&#38598;&#21644;&#35780;&#20272;&#25351;&#26631;&#26410;&#33021;&#20805;&#20998;&#32771;&#34385;&#21040;&#19982;&#23433;&#20840;&#30456;&#20851;&#30340;&#30495;&#23454;&#36719;&#20214;&#24037;&#31243;&#20219;&#21153;&#65292;&#20174;&#32780;&#23548;&#33268;&#19981;&#23433;&#20840;&#30340;&#20195;&#30721;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;&#20363;&#22914;GitHub Copilot&#65292;ChatGPT&#31561;&#65289;&#22312;&#36719;&#20214;&#24037;&#31243;&#24072;&#30340;&#26085;&#24120;&#23454;&#36341;&#20013;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#65292;&#30830;&#20445;&#36825;&#20123;&#24037;&#20855;&#29983;&#25104;&#30340;&#20195;&#30721;&#19981;&#20165;&#21151;&#33021;&#27491;&#30830;&#65292;&#32780;&#19988;&#27809;&#26377;&#28431;&#27934;&#21464;&#24471;&#38750;&#24120;&#37325;&#35201;&#12290;&#23613;&#31649;LLM&#21487;&#20197;&#24110;&#21161;&#24320;&#21457;&#20154;&#21592;&#25552;&#39640;&#29983;&#20135;&#21147;&#65292;&#20294;&#20043;&#21069;&#30340;&#23454;&#35777;&#30740;&#31350;&#34920;&#26126;LLM&#21487;&#33021;&#20250;&#29983;&#25104;&#19981;&#23433;&#20840;&#30340;&#20195;&#30721;&#12290;&#23384;&#22312;&#20004;&#20010;&#23548;&#33268;&#19981;&#23433;&#20840;&#20195;&#30721;&#29983;&#25104;&#30340;&#22240;&#32032;&#12290;&#39318;&#20808;&#65292;&#29992;&#20110;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#29616;&#26377;&#25968;&#25454;&#38598;&#27809;&#26377;&#20805;&#20998;&#22320;&#20195;&#34920;&#19982;&#23433;&#20840;&#30456;&#20851;&#30340;&#30495;&#23454;&#36719;&#20214;&#24037;&#31243;&#20219;&#21153;&#12290;&#30456;&#21453;&#65292;&#23427;&#20204;&#36890;&#24120;&#22522;&#20110;&#31454;&#25216;&#32534;&#31243;&#25361;&#25112;&#25110;&#20197;&#35838;&#22530;&#24418;&#24335;&#20026;&#22522;&#30784;&#30340;&#32534;&#30721;&#20219;&#21153;&#12290;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#24212;&#29992;&#20013;&#65292;&#29983;&#25104;&#30340;&#20195;&#30721;&#23558;&#34987;&#38598;&#25104;&#21040;&#26356;&#22823;&#30340;&#20195;&#30721;&#24211;&#20013;&#65292;&#24341;&#20837;&#28508;&#22312;&#30340;&#23433;&#20840;&#39118;&#38505;&#12290;&#30446;&#21069;&#32570;&#20047;&#19987;&#27880;&#20110;&#35780;&#20272;&#29983;&#25104;&#20195;&#30721;&#23433;&#20840;&#24615;&#30340;&#22522;&#20934;&#12290;&#20854;&#27425;&#65292;&#29616;&#26377;&#30340;&#35780;&#20272;&#25351;&#26631;&#20027;&#35201;&#20391;&#37325;&#20110;&#21151;&#33021;&#24615;&#32780;&#24573;&#35270;&#23433;&#20840;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the growing popularity of Large Language Models (e.g. GitHub Copilot, ChatGPT, etc.) in software engineers' daily practices, it is important to ensure that the code generated by these tools is not only functionally correct but also free of vulnerabilities. Although LLMs can help developers to be more productive, prior empirical studies have shown that LLMs can generate insecure code. There are two contributing factors to the insecure code generation. First, existing datasets used to evaluate Large Language Models (LLMs) do not adequately represent genuine software engineering tasks sensitive to security. Instead, they are often based on competitive programming challenges or classroom-type coding tasks. In real-world applications, the code produced is integrated into larger codebases, introducing potential security risks. There's a clear absence of benchmarks that focus on evaluating the security of the generated code. Second, existing evaluation metrics primarily focus on the func
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#35299;&#37322;&#20102;&#25552;&#31034;&#24037;&#31243;&#22312;&#37322;&#25918;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#21147;&#26041;&#38754;&#30340;&#20851;&#38190;&#20316;&#29992;&#65292;&#25506;&#35752;&#20102;&#19981;&#21516;&#30340;&#25552;&#31034;&#26041;&#27861;&#20197;&#21450;&#22806;&#37096;&#25554;&#20214;&#22914;&#20309;&#21327;&#21161;&#20943;&#23569;&#26426;&#22120;&#24187;&#24819;&#65292;&#24182;&#25351;&#20986;&#20102;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.14735</link><description>&lt;p&gt;
&#28608;&#21457;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#25552;&#31034;&#24037;&#31243;&#28508;&#21147;&#65306;&#19968;&#39033;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Unleashing the potential of prompt engineering in Large Language Models: a comprehensive review. (arXiv:2310.14735v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14735
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#35299;&#37322;&#20102;&#25552;&#31034;&#24037;&#31243;&#22312;&#37322;&#25918;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#21147;&#26041;&#38754;&#30340;&#20851;&#38190;&#20316;&#29992;&#65292;&#25506;&#35752;&#20102;&#19981;&#21516;&#30340;&#25552;&#31034;&#26041;&#27861;&#20197;&#21450;&#22806;&#37096;&#25554;&#20214;&#22914;&#20309;&#21327;&#21161;&#20943;&#23569;&#26426;&#22120;&#24187;&#24819;&#65292;&#24182;&#25351;&#20986;&#20102;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#28145;&#20837;&#25506;&#35752;&#20102;&#25552;&#31034;&#24037;&#31243;&#22312;&#37322;&#25918;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#33021;&#21147;&#26041;&#38754;&#30340;&#20851;&#38190;&#20316;&#29992;&#12290;&#25552;&#31034;&#24037;&#31243;&#26159;&#20026;LLM&#26500;&#24314;&#36755;&#20837;&#25991;&#26412;&#30340;&#36807;&#31243;&#65292;&#26159;&#20248;&#21270;LLM&#26377;&#25928;&#24615;&#30340;&#37325;&#35201;&#25216;&#26415;&#12290;&#26412;&#32508;&#36848;&#38416;&#26126;&#20102;&#25552;&#31034;&#24037;&#31243;&#30340;&#22522;&#26412;&#21407;&#29702;&#65292;&#22914;&#35282;&#33394;&#25552;&#31034;&#12289;&#19968;&#27425;&#24615;&#25552;&#31034;&#21644;&#23569;&#37327;&#25552;&#31034;&#65292;&#20197;&#21450;&#26356;&#39640;&#32423;&#30340;&#26041;&#27861;&#65292;&#22914;&#24605;&#32500;&#38142;&#21644;&#24605;&#32500;&#26641;&#25552;&#31034;&#12290;&#26412;&#25991;&#36824;&#38416;&#36848;&#20102;&#22806;&#37096;&#25554;&#20214;&#22914;&#20309;&#21327;&#21161;&#27492;&#20219;&#21153;&#65292;&#24182;&#36890;&#36807;&#26816;&#32034;&#22806;&#37096;&#30693;&#35782;&#26469;&#20943;&#23569;&#26426;&#22120;&#24187;&#24819;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#21246;&#21202;&#20102;&#25552;&#31034;&#24037;&#31243;&#30740;&#31350;&#30340;&#21069;&#26223;&#26041;&#21521;&#65292;&#24378;&#35843;&#20102;&#23545;&#32467;&#26500;&#21644;&#20195;&#29702;&#22312;&#20154;&#24037;&#26234;&#33021;&#29983;&#25104;&#20869;&#23481;&#65288;AIGC&#65289;&#24037;&#20855;&#20013;&#30340;&#20316;&#29992;&#30340;&#28145;&#20837;&#29702;&#35299;&#30340;&#24517;&#35201;&#24615;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#22914;&#20309;&#20174;&#19981;&#21516;&#35282;&#24230;&#21644;&#20351;&#29992;&#19981;&#21516;&#30340;&#26041;&#27861;&#35780;&#20272;&#25552;&#31034;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23637;&#26395;&#26410;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper delves into the pivotal role of prompt engineering in unleashing the capabilities of Large Language Models (LLMs). Prompt engineering is the process of structuring input text for LLMs and is a technique integral to optimizing the efficacy of LLMs. This survey elucidates foundational principles of prompt engineering, such as role-prompting, one-shot, and few-shot prompting, as well as more advanced methodologies such as the chain-of-thought and tree-of-thoughts prompting. The paper sheds light on how external assistance in the form of plugins can assist in this task, and reduce machine hallucination by retrieving external knowledge. We subsequently delineate prospective directions in prompt engineering research, emphasizing the need for a deeper understanding of structures and the role of agents in Artificial Intelligence-Generated Content (AIGC) tools. We discuss how to assess the efficacy of prompt methods from different perspectives and using different methods. Finally, we
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;QMLS&#30340;&#26032;&#27010;&#24565;&#65292;&#36890;&#36807;&#32467;&#21512;&#26426;&#22120;&#23398;&#20064;&#21644;&#37327;&#23376;&#27169;&#25311;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#32553;&#30701;&#33647;&#29289;&#30740;&#21457;&#30340;&#26102;&#38388;&#21644;&#38477;&#20302;&#25104;&#26412;&#12290;&#36890;&#36807;&#29983;&#25104;&#21629;&#20013;&#29289;&#21644;&#20248;&#21270;&#20998;&#23376;&#30340;&#36807;&#31243;&#65292;&#21487;&#20197;&#22823;&#22823;&#25552;&#39640;&#33647;&#29289;&#21457;&#29616;&#30340;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2308.08561</link><description>&lt;p&gt;
&#26410;&#26469;&#33647;&#29289;&#21457;&#29616;&#30340;&#23454;&#26045;&#65306;&#22522;&#20110;&#37327;&#23376;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#25311;(QMLS)&#12290;
&lt;/p&gt;
&lt;p&gt;
Implementation of The Future of Drug Discovery: QuantumBased Machine Learning Simulation (QMLS). (arXiv:2308.08561v1 [q-bio.BM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08561
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;QMLS&#30340;&#26032;&#27010;&#24565;&#65292;&#36890;&#36807;&#32467;&#21512;&#26426;&#22120;&#23398;&#20064;&#21644;&#37327;&#23376;&#27169;&#25311;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#32553;&#30701;&#33647;&#29289;&#30740;&#21457;&#30340;&#26102;&#38388;&#21644;&#38477;&#20302;&#25104;&#26412;&#12290;&#36890;&#36807;&#29983;&#25104;&#21629;&#20013;&#29289;&#21644;&#20248;&#21270;&#20998;&#23376;&#30340;&#36807;&#31243;&#65292;&#21487;&#20197;&#22823;&#22823;&#25552;&#39640;&#33647;&#29289;&#21457;&#29616;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33647;&#29289;&#30740;&#21457;&#30340;&#30740;&#31350;&#19982;&#24320;&#21457;(R&amp;D)&#38454;&#27573;&#26159;&#19968;&#20010;&#28459;&#38271;&#32780;&#26114;&#36149;&#30340;&#36807;&#31243;&#12290;&#20026;&#20102;&#25913;&#38761;&#36825;&#20010;&#36807;&#31243;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#26032;&#27010;&#24565;QMLS&#65292;&#23558;&#25972;&#20010;R&amp;D&#38454;&#27573;&#32553;&#30701;&#21040;&#19977;&#21040;&#20845;&#20010;&#26376;&#65292;&#25104;&#26412;&#20165;&#20026;&#20116;&#21040;&#20843;&#19975;&#32654;&#20803;&#12290;&#23545;&#20110;&#21629;&#20013;&#20135;&#29983;&#65292;&#26426;&#22120;&#23398;&#20064;&#20998;&#23376;&#29983;&#25104;(MLMG)&#26681;&#25454;&#30446;&#26631;&#34507;&#30333;&#30340;&#20998;&#23376;&#32467;&#26500;&#29983;&#25104;&#21487;&#33021;&#30340;&#21629;&#20013;&#29289;&#65292;&#32780;&#37327;&#23376;&#27169;&#25311;(QS)&#26681;&#25454;&#19982;&#30446;&#26631;&#34507;&#30333;&#30340;&#21453;&#24212;&#21644;&#32467;&#21512;&#25928;&#26524;&#36807;&#28388;&#21407;&#22987;&#23454;&#39564;&#20013;&#30340;&#20998;&#23376;&#12290;&#28982;&#21518;&#65292;&#23545;&#20110;&#38085;&#20248;&#21270;&#65292;&#20174;MLMG&#21644;QS&#29983;&#25104;&#21644;&#36807;&#28388;&#30340;&#32467;&#26524;&#20998;&#23376;&#36827;&#34892;&#27604;&#36739;&#65292;&#24182;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#20998;&#23376;&#21464;&#24322;(MLMV)&#23558;&#37027;&#20123;&#20986;&#29616;&#22312;&#20004;&#20010;&#36807;&#31243;&#20013;&#30340;&#20998;&#23376;&#21046;&#25104;&#25968;&#21313;&#31181;&#20998;&#23376;&#21464;&#20307;&#65292;&#32780;&#20854;&#20182;&#20998;&#23376;&#21482;&#21046;&#25104;&#20960;&#31181;&#21464;&#20307;&#12290;&#26368;&#21518;&#65292;&#25152;&#26377;&#20248;&#21270;&#30340;&#20998;&#23376;&#23558;&#32463;&#36807;&#22810;&#36718;&#39640;&#26631;&#20934;&#30340;QS&#36807;&#28388;&#65292;&#20197;&#30830;&#20445;&#21453;&#24212;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Research &amp; Development (R&amp;D) phase of drug development is a lengthy and costly process. To revolutionize this process, we introduce our new concept QMLS to shorten the whole R&amp;D phase to three to six months and decrease the cost to merely fifty to eighty thousand USD. For Hit Generation, Machine Learning Molecule Generation (MLMG) generates possible hits according to the molecular structure of the target protein while the Quantum Simulation (QS) filters molecules from the primary essay based on the reaction and binding effectiveness with the target protein. Then, For Lead Optimization, the resultant molecules generated and filtered from MLMG and QS are compared, and molecules that appear as a result of both processes will be made into dozens of molecular variations through Machine Learning Molecule Variation (MLMV), while others will only be made into a few variations. Lastly, all optimized molecules would undergo multiple rounds of QS filtering with a high standard for reaction ef
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#25968;&#25454;&#23494;&#38598;&#22411;&#38382;&#39064;&#21644;&#22810;&#30446;&#26631;&#20248;&#21270;&#35774;&#32622;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26694;&#26550;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#20102;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20195;&#29702;&#24314;&#27169;&#21644;&#21487;&#25193;&#23637;&#12289;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#30340;&#25910;&#36141;&#31574;&#30053;&#65292;&#33021;&#22815;&#22312;&#26368;&#23569;&#36845;&#20195;&#27425;&#25968;&#30340;&#24773;&#20917;&#19979;&#39640;&#25928;&#22320;&#36827;&#34892;&#20248;&#21270;&#12290;</title><link>http://arxiv.org/abs/2306.01095</link><description>&lt;p&gt;
&#22823;&#25209;&#37327;&#31070;&#32463;&#22810;&#30446;&#26631;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Large-Batch, Neural Multi-Objective Bayesian Optimization. (arXiv:2306.01095v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01095
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#25968;&#25454;&#23494;&#38598;&#22411;&#38382;&#39064;&#21644;&#22810;&#30446;&#26631;&#20248;&#21270;&#35774;&#32622;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26694;&#26550;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#20102;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20195;&#29702;&#24314;&#27169;&#21644;&#21487;&#25193;&#23637;&#12289;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#30340;&#25910;&#36141;&#31574;&#30053;&#65292;&#33021;&#22815;&#22312;&#26368;&#23569;&#36845;&#20195;&#27425;&#25968;&#30340;&#24773;&#20917;&#19979;&#39640;&#25928;&#22320;&#36827;&#34892;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#22312;&#20840;&#23616;&#20248;&#21270;&#40657;&#30418;&#39640;&#25104;&#26412;&#20989;&#25968;&#26041;&#38754;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#26694;&#26550;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#40664;&#35748;&#39640;&#26031;&#36807;&#31243;&#20195;&#29702;&#30340;&#21487;&#25193;&#23637;&#24615;&#24046;&#65292;&#23427;&#22312;&#22788;&#29702;&#25968;&#25454;&#23494;&#38598;&#22411;&#38382;&#39064;&#65292;&#29305;&#21035;&#26159;&#22312;&#22810;&#30446;&#26631;&#35774;&#32622;&#20013;&#30340;&#33021;&#21147;&#26377;&#38480;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26694;&#26550;&#65292;&#19987;&#20026;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#32780;&#35774;&#35745;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#20102;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#36827;&#34892;&#20195;&#29702;&#24314;&#27169;&#12290;&#36825;&#20351;&#24471;&#23427;&#33021;&#22815;&#26377;&#25928;&#22320;&#22788;&#29702;&#22823;&#25209;&#37327;&#25968;&#25454;&#65292;&#24314;&#27169;&#22797;&#26434;&#38382;&#39064;&#20197;&#21450;&#20135;&#29983;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#32467;&#21512;&#20102;&#19968;&#31181;&#22522;&#20110;&#20247;&#25152;&#21608;&#30693;&#19988;&#26131;&#20110;&#37096;&#32626;&#30340;NSGA-II&#30340;&#21487;&#25193;&#23637;&#30340;&#12289;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#30340;&#25910;&#36141;&#31574;&#30053;&#12290;&#36825;&#31181;&#23436;&#20840;&#21487;&#24182;&#34892;&#21270;&#30340;&#31574;&#30053;&#20419;&#36827;&#20102;&#26410;&#21208;&#25506;&#21306;&#22495;&#30340;&#26377;&#25928;&#25506;&#32034;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#20801;&#35768;&#22312;&#26368;&#23569;&#36845;&#20195;&#27425;&#25968;&#30340;&#24773;&#20917;&#19979;&#22312;&#25968;&#25454;&#23494;&#38598;&#29615;&#22659;&#20013;&#36827;&#34892;&#26377;&#25928;&#30340;&#20248;&#21270;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimization provides a powerful framework for global optimization of black-box, expensive-to-evaluate functions. However, it has a limited capacity in handling data-intensive problems, especially in multi-objective settings, due to the poor scalability of default Gaussian Process surrogates. We present a novel Bayesian optimization framework specifically tailored to address these limitations. Our method leverages a Bayesian neural networks approach for surrogate modeling. This enables efficient handling of large batches of data, modeling complex problems, and generating the uncertainty of the predictions. In addition, our method incorporates a scalable, uncertainty-aware acquisition strategy based on the well-known, easy-to-deploy NSGA-II. This fully parallelizable strategy promotes efficient exploration of uncharted regions. Our framework allows for effective optimization in data-intensive environments with a minimum number of iterations. We demonstrate the superiority of ou
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#36328;&#35821;&#35328;&#30340;&#35821;&#20041;&#30456;&#20284;&#24615;&#27169;&#22411;PESTS&#65292;&#24182;&#36890;&#36807;&#27874;&#26031;&#35821;-&#33521;&#35821;&#30340;&#36328;&#35821;&#35328;&#35821;&#26009;&#24211;&#26469;&#39564;&#35777;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.07893</link><description>&lt;p&gt;
PESTS: &#27874;&#26031;&#35821;-&#33521;&#35821;&#36328;&#35821;&#35328;&#35821;&#26009;&#24211;&#29992;&#20110;&#35821;&#20041;&#25991;&#26412;&#30456;&#20284;&#24230;
&lt;/p&gt;
&lt;p&gt;
PESTS: Persian_English Cross Lingual Corpus for Semantic Textual Similarity. (arXiv:2305.07893v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07893
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#36328;&#35821;&#35328;&#30340;&#35821;&#20041;&#30456;&#20284;&#24615;&#27169;&#22411;PESTS&#65292;&#24182;&#36890;&#36807;&#27874;&#26031;&#35821;-&#33521;&#35821;&#30340;&#36328;&#35821;&#35328;&#35821;&#26009;&#24211;&#26469;&#39564;&#35777;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26469;&#65292;&#35821;&#20041;&#25991;&#26412;&#30456;&#20284;&#24230;&#25104;&#20026;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#22791;&#21463;&#20851;&#27880;&#30340;&#32452;&#20214;&#12290;&#22312;&#35745;&#31639;&#35821;&#35328;&#23398;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#65292;&#35780;&#20272;&#21333;&#35789;&#12289;&#30701;&#35821;&#12289;&#27573;&#33853;&#21644;&#25991;&#26412;&#20043;&#38388;&#30340;&#35821;&#20041;&#30456;&#20284;&#24615;&#24456;&#37325;&#35201;&#12290;&#21516;&#26102;&#65292;&#35821;&#20041;&#30456;&#20284;&#24615;&#24230;&#37327;&#35201;&#27714;&#22312;&#28304;&#21644;&#30446;&#26631;&#35821;&#35328;&#20013;&#25552;&#20379;&#20855;&#26377;&#19968;&#23450;&#35821;&#20041;&#30456;&#20284;&#24615;&#30340;&#21477;&#23376;&#23545;&#12290;&#35768;&#22810;&#36328;&#35821;&#35328;&#30340;&#35821;&#20041;&#30456;&#20284;&#24230;&#27169;&#22411;&#20351;&#29992;&#26426;&#22120;&#32763;&#35793;&#26469;&#24357;&#34917;&#36328;&#35821;&#35328;&#35821;&#26009;&#24211;&#19981;&#21487;&#29992;&#30340;&#19981;&#36275;&#65292;&#20294;&#26426;&#22120;&#32763;&#35793;&#30340;&#35823;&#24046;&#20250;&#38477;&#20302;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#12290;&#28982;&#32780;&#65292;&#22312;&#20351;&#29992;&#35821;&#20041;&#30456;&#20284;&#24230;&#29305;&#24449;&#23454;&#29616;&#26426;&#22120;&#32763;&#35793;&#26102;&#65292;&#29992;&#30456;&#21516;&#30340;&#26426;&#22120;&#32763;&#35793;&#27169;&#22411;&#21487;&#20197;&#25552;&#39640;&#32467;&#26524;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
One of the components of natural language processing that has received a lot of investigation recently is semantic textual similarity. In computational linguistics and natural language processing, assessing the semantic similarity of words, phrases, paragraphs, and texts is crucial. Calculating the degree of semantic resemblance between two textual pieces, paragraphs, or phrases provided in both monolingual and cross-lingual versions is known as semantic similarity. Cross lingual semantic similarity requires corpora in which there are sentence pairs in both the source and target languages with a degree of semantic similarity between them. Many existing cross lingual semantic similarity models use a machine translation due to the unavailability of cross lingual semantic similarity dataset, which the propagation of the machine translation error reduces the accuracy of the model. On the other hand, when we want to use semantic similarity features for machine translation the same machine t
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;hGAIL&#30340;&#26550;&#26500;&#65292;&#29992;&#20110;&#35299;&#20915;&#36710;&#36742;&#30340;&#33258;&#20027;&#23548;&#33322;&#38382;&#39064;&#65292;&#36890;&#36807;&#23558;&#24863;&#30693;&#20449;&#24687;&#30452;&#25509;&#26144;&#23556;&#21040;&#20302;&#32423;&#21160;&#20316;&#30340;&#21516;&#26102;&#65292;&#23398;&#20064;&#36710;&#36742;&#29615;&#22659;&#30340;&#20013;&#32423;&#36755;&#20837;&#34920;&#31034;&#12290;</title><link>http://arxiv.org/abs/2302.04823</link><description>&lt;p&gt;
&#22522;&#20110;&#20998;&#23618;&#29983;&#25104;&#23545;&#25239;&#27169;&#25311;&#23398;&#20064;&#30340;&#33258;&#21160;&#39550;&#39542;&#22312;&#22478;&#24066;&#29615;&#22659;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Hierarchical Generative Adversarial Imitation Learning with Mid-level Input Generation for Autonomous Driving on Urban Environments. (arXiv:2302.04823v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.04823
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;hGAIL&#30340;&#26550;&#26500;&#65292;&#29992;&#20110;&#35299;&#20915;&#36710;&#36742;&#30340;&#33258;&#20027;&#23548;&#33322;&#38382;&#39064;&#65292;&#36890;&#36807;&#23558;&#24863;&#30693;&#20449;&#24687;&#30452;&#25509;&#26144;&#23556;&#21040;&#20302;&#32423;&#21160;&#20316;&#30340;&#21516;&#26102;&#65292;&#23398;&#20064;&#36710;&#36742;&#29615;&#22659;&#30340;&#20013;&#32423;&#36755;&#20837;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#29616;&#23454;&#20013;&#30340;&#22478;&#24066;&#23548;&#33322;&#22330;&#26223;&#65292;&#35774;&#35745;&#20581;&#22766;&#30340;&#25511;&#21046;&#31574;&#30053;&#24182;&#19981;&#26159;&#19968;&#39033;&#31616;&#21333;&#30340;&#20219;&#21153;&#12290;&#22312;&#31471;&#21040;&#31471;&#30340;&#26041;&#27861;&#20013;&#65292;&#36825;&#20123;&#31574;&#30053;&#24517;&#39035;&#23558;&#36710;&#36742;&#25668;&#20687;&#22836;&#33719;&#24471;&#30340;&#39640;&#32500;&#22270;&#20687;&#26144;&#23556;&#21040;&#20302;&#32423;&#21160;&#20316;&#65292;&#22914;&#36716;&#21521;&#21644;&#27833;&#38376;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;hGAIL&#30340;&#26550;&#26500;&#65292;&#29992;&#20110;&#35299;&#20915;&#36710;&#36742;&#30340;&#33258;&#20027;&#23548;&#33322;&#38382;&#39064;&#65292;&#36890;&#36807;&#23558;&#24863;&#30693;&#20449;&#24687;&#30452;&#25509;&#26144;&#23556;&#21040;&#20302;&#32423;&#21160;&#20316;&#30340;&#21516;&#26102;&#65292;&#23398;&#20064;&#36710;&#36742;&#29615;&#22659;&#30340;&#20013;&#32423;&#36755;&#20837;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deriving robust control policies for realistic urban navigation scenarios is not a trivial task. In an end-to-end approach, these policies must map high-dimensional images from the vehicle's cameras to low-level actions such as steering and throttle. While pure Reinforcement Learning (RL) approaches are based exclusively on rewards,Generative Adversarial Imitation Learning (GAIL) agents learn from expert demonstrations while interacting with the environment, which favors GAIL on tasks for which a reward signal is difficult to derive. In this work, the hGAIL architecture was proposed to solve the autonomous navigation of a vehicle in an end-to-end approach, mapping sensory perceptions directly to low-level actions, while simultaneously learning mid-level input representations of the agent's environment. The proposed hGAIL consists of an hierarchical Adversarial Imitation Learning architecture composed of two main modules: the GAN (Generative Adversarial Nets) which generates the Bird's-
&lt;/p&gt;</description></item></channel></rss>