<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>LLM&#21644;MLLM&#30340;&#36827;&#27493;&#20026;&#28216;&#25103;&#26234;&#33021;&#20307;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#20154;&#31867;&#20915;&#31574;&#33021;&#21147;&#65292;&#26412;&#25991;&#20840;&#38754;&#32508;&#36848;&#20102;&#22522;&#20110;LLM&#30340;&#28216;&#25103;&#26234;&#33021;&#20307;&#30340;&#27010;&#24565;&#26550;&#26500;&#12289;&#26041;&#27861;&#35770;&#21644;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;</title><link>https://arxiv.org/abs/2404.02039</link><description>&lt;p&gt;
&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#28216;&#25103;&#26234;&#33021;&#20307;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Survey on Large Language Model-Based Game Agents
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02039
&lt;/p&gt;
&lt;p&gt;
LLM&#21644;MLLM&#30340;&#36827;&#27493;&#20026;&#28216;&#25103;&#26234;&#33021;&#20307;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#20154;&#31867;&#20915;&#31574;&#33021;&#21147;&#65292;&#26412;&#25991;&#20840;&#38754;&#32508;&#36848;&#20102;&#22522;&#20110;LLM&#30340;&#28216;&#25103;&#26234;&#33021;&#20307;&#30340;&#27010;&#24565;&#26550;&#26500;&#12289;&#26041;&#27861;&#35770;&#21644;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28216;&#25103;&#26234;&#33021;&#20307;&#30340;&#21457;&#23637;&#22312;&#25512;&#21160;&#20154;&#24037;&#36890;&#29992;&#26234;&#33021;&#65288;AGI&#65289;&#26041;&#38754;&#25198;&#28436;&#30528;&#20851;&#38190;&#35282;&#33394;&#12290;LLM&#21450;&#20854;&#22810;&#27169;&#24577;&#23545;&#24212;&#29289;&#65288;MLLM&#65289;&#30340;&#36827;&#23637;&#20026;&#28216;&#25103;&#26234;&#33021;&#20307;&#22312;&#22797;&#26434;&#30340;&#30005;&#33041;&#28216;&#25103;&#29615;&#22659;&#20013;&#20855;&#22791;&#31867;&#20284;&#20154;&#31867;&#20915;&#31574;&#33021;&#21147;&#25552;&#20379;&#20102;&#21069;&#25152;&#26410;&#26377;&#30340;&#26426;&#20250;&#12290;&#26412;&#25991;&#20174;&#25972;&#20307;&#35270;&#35282;&#20840;&#38754;&#27010;&#36848;&#20102;&#22522;&#20110;LLM&#30340;&#28216;&#25103;&#26234;&#33021;&#20307;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#20197;&#24863;&#30693;&#12289;&#35760;&#24518;&#12289;&#24605;&#32500;&#12289;&#35282;&#33394;&#25198;&#28436;&#12289;&#34892;&#21160;&#21644;&#23398;&#20064;&#20026;&#20013;&#24515;&#30340;LLM&#28216;&#25103;&#26234;&#33021;&#20307;&#30340;&#27010;&#24565;&#26550;&#26500;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#25991;&#29486;&#20013;&#24050;&#26377;&#30340;&#20195;&#34920;&#24615;LLM&#28216;&#25103;&#26234;&#33021;&#20307;&#65292;&#28041;&#21450;&#21040;&#20845;&#31867;&#28216;&#25103;&#20013;&#30340;&#26041;&#27861;&#35770;&#21644;&#36866;&#24212;&#33021;&#21147;&#65292;&#21253;&#25324;&#20882;&#38505;&#12289;&#27807;&#36890;&#12289;&#31454;&#20105;&#12289;&#21512;&#20316;&#12289;&#27169;&#25311;&#20197;&#21450;&#21019;&#36896;&#19982;&#25506;&#32034;&#28216;&#25103;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#26395;&#20102;&#26410;&#26469;&#30740;&#31350;&#30340;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02039v1 Announce Type: new  Abstract: The development of game agents holds a critical role in advancing towards Artificial General Intelligence (AGI). The progress of LLMs and their multimodal counterparts (MLLMs) offers an unprecedented opportunity to evolve and empower game agents with human-like decision-making capabilities in complex computer game environments. This paper provides a comprehensive overview of LLM-based game agents from a holistic viewpoint. First, we introduce the conceptual architecture of LLM-based game agents, centered around six essential functional components: perception, memory, thinking, role-playing, action, and learning. Second, we survey existing representative LLM-based game agents documented in the literature with respect to methodologies and adaptation agility across six genres of games, including adventure, communication, competition, cooperation, simulation, and crafting &amp; exploration games. Finally, we present an outlook of future research
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35774;&#35745;&#20102;&#19968;&#31181;&#21033;&#29992;&#39044;&#35757;&#32451;&#25193;&#25955;&#27169;&#22411;&#30340;&#25193;&#25955;&#27748;&#26222;&#26862;&#37319;&#26679;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#22823;&#21160;&#20316;&#31354;&#38388;&#19979;&#36827;&#34892;&#39640;&#25928;&#30340;&#24773;&#22659;&#24378;&#21270;&#23398;&#20064;&#25506;&#32034;&#12290;&#23454;&#35777;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.10028</link><description>&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#19982;&#22823;&#21160;&#20316;&#31354;&#38388;&#24773;&#22659;&#24378;&#21270;&#23398;&#20064;&#30340;&#32467;&#21512;
&lt;/p&gt;
&lt;p&gt;
Diffusion Models Meet Contextual Bandits with Large Action Spaces
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10028
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35774;&#35745;&#20102;&#19968;&#31181;&#21033;&#29992;&#39044;&#35757;&#32451;&#25193;&#25955;&#27169;&#22411;&#30340;&#25193;&#25955;&#27748;&#26222;&#26862;&#37319;&#26679;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#22823;&#21160;&#20316;&#31354;&#38388;&#19979;&#36827;&#34892;&#39640;&#25928;&#30340;&#24773;&#22659;&#24378;&#21270;&#23398;&#20064;&#25506;&#32034;&#12290;&#23454;&#35777;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#21160;&#20316;&#31354;&#38388;&#36739;&#22823;&#65292;&#26377;&#25928;&#30340;&#25506;&#32034;&#26159;&#24773;&#22659;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#12290;&#26412;&#25991;&#36890;&#36807;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#26469;&#25429;&#25417;&#21160;&#20316;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#35774;&#35745;&#20102;&#25193;&#25955;&#27748;&#26222;&#26862;&#37319;&#26679;&#65288;dTS&#65289;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#25506;&#32034;&#12290;&#25105;&#20204;&#20026;dTS&#26041;&#27861;&#25552;&#20379;&#20102;&#29702;&#35770;&#21644;&#31639;&#27861;&#22522;&#30784;&#65292;&#24182;&#36890;&#36807;&#23454;&#35777;&#35780;&#20272;&#23637;&#31034;&#20102;&#23427;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10028v1 Announce Type: cross  Abstract: Efficient exploration is a key challenge in contextual bandits due to the large size of their action space, where uninformed exploration can result in computational and statistical inefficiencies. Fortunately, the rewards of actions are often correlated and this can be leveraged to explore them efficiently. In this work, we capture such correlations using pre-trained diffusion models; upon which we design diffusion Thompson sampling (dTS). Both theoretical and algorithmic foundations are developed for dTS, and empirical evaluation also shows its favorable performance.
&lt;/p&gt;</description></item></channel></rss>