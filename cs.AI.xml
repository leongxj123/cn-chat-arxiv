<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#35780;&#20998;&#35268;&#21017;&#35757;&#32451;&#29983;&#23384;&#27169;&#22411;&#30340;&#36890;&#29992;&#26041;&#27861;&#65292;&#23558;&#20854;&#24212;&#29992;&#20110;&#21508;&#31181;&#27169;&#22411;&#31867;&#21035;&#20013;&#24182;&#19982;&#31070;&#32463;&#32593;&#32476;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#21487;&#25193;&#23637;&#30340;&#20248;&#21270;&#20363;&#31243;&#65292;&#24182;&#23637;&#31034;&#20102;&#20248;&#20110;&#22522;&#20110;&#20284;&#28982;&#24615;&#26041;&#27861;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.13150</link><description>&lt;p&gt;
&#20351;&#29992;&#35780;&#20998;&#35268;&#21017;&#35757;&#32451;&#29983;&#23384;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Training Survival Models using Scoring Rules
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13150
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#35780;&#20998;&#35268;&#21017;&#35757;&#32451;&#29983;&#23384;&#27169;&#22411;&#30340;&#36890;&#29992;&#26041;&#27861;&#65292;&#23558;&#20854;&#24212;&#29992;&#20110;&#21508;&#31181;&#27169;&#22411;&#31867;&#21035;&#20013;&#24182;&#19982;&#31070;&#32463;&#32593;&#32476;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#21487;&#25193;&#23637;&#30340;&#20248;&#21270;&#20363;&#31243;&#65292;&#24182;&#23637;&#31034;&#20102;&#20248;&#20110;&#22522;&#20110;&#20284;&#28982;&#24615;&#26041;&#27861;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#23384;&#20998;&#26512;&#20026;&#21508;&#20010;&#39046;&#22495;&#20013;&#37096;&#20998;&#19981;&#23436;&#25972;&#30340;&#20107;&#20214;&#21457;&#29983;&#26102;&#38388;&#25968;&#25454;&#25552;&#20379;&#20102;&#20851;&#38190;&#35265;&#35299;&#12290;&#23427;&#20063;&#26159;&#27010;&#29575;&#26426;&#22120;&#23398;&#20064;&#30340;&#19968;&#20010;&#37325;&#35201;&#31034;&#20363;&#12290;&#25105;&#20204;&#30340;&#25552;&#26696;&#20197;&#19968;&#31181;&#36890;&#29992;&#30340;&#26041;&#24335;&#21033;&#29992;&#20102;&#39044;&#27979;&#30340;&#27010;&#29575;&#24615;&#36136;&#65292;&#36890;&#36807;&#22312;&#27169;&#22411;&#25311;&#21512;&#36807;&#31243;&#20013;&#20351;&#29992;&#65288;&#21512;&#36866;&#30340;&#65289;&#35780;&#20998;&#35268;&#21017;&#32780;&#38750;&#22522;&#20110;&#20284;&#28982;&#24615;&#30340;&#20248;&#21270;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#19981;&#21516;&#30340;&#21442;&#25968;&#21270;&#21644;&#38750;&#21442;&#25968;&#21270;&#23376;&#26694;&#26550;&#65292;&#20801;&#35768;&#19981;&#21516;&#31243;&#24230;&#30340;&#28789;&#27963;&#24615;&#12290;&#23558;&#20854;&#28151;&#20837;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#23548;&#33268;&#20102;&#19968;&#20010;&#35745;&#31639;&#26377;&#25928;&#19988;&#21487;&#25193;&#23637;&#30340;&#20248;&#21270;&#20363;&#31243;&#65292;&#20135;&#29983;&#20102;&#26368;&#20808;&#36827;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20351;&#29992;&#25105;&#20204;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#24674;&#22797;&#21508;&#31181;&#21442;&#25968;&#21270;&#27169;&#22411;&#65292;&#24182;&#35777;&#26126;&#22312;&#19982;&#22522;&#20110;&#20284;&#28982;&#24615;&#26041;&#27861;&#30340;&#27604;&#36739;&#20013;&#65292;&#20248;&#21270;&#25928;&#26524;&#21516;&#26679;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13150v1 Announce Type: new  Abstract: Survival Analysis provides critical insights for partially incomplete time-to-event data in various domains. It is also an important example of probabilistic machine learning. The probabilistic nature of the predictions can be exploited by using (proper) scoring rules in the model fitting process instead of likelihood-based optimization. Our proposal does so in a generic manner and can be used for a variety of model classes. We establish different parametric and non-parametric sub-frameworks that allow different degrees of flexibility. Incorporated into neural networks, it leads to a computationally efficient and scalable optimization routine, yielding state-of-the-art predictive performance. Finally, we show that using our framework, we can recover various parametric models and demonstrate that optimization works equally well when compared to likelihood-based methods.
&lt;/p&gt;</description></item><item><title>&#24418;&#24577;&#23545;&#31216;&#24615;&#26159;&#26426;&#22120;&#20154;&#31995;&#32479;&#20013;&#30340;&#22266;&#26377;&#24615;&#36136;&#65292;&#36890;&#36807;&#23545;&#36816;&#21160;&#32467;&#26500;&#21644;&#36136;&#37327;&#30340;&#23545;&#31216;&#20998;&#24067;&#65292;&#24310;&#20280;&#33267;&#26426;&#22120;&#20154;&#29366;&#24577;&#31354;&#38388;&#21644;&#20256;&#24863;&#22120;&#27979;&#37327;&#65292;&#36827;&#32780;&#24433;&#21709;&#26426;&#22120;&#20154;&#30340;&#36816;&#21160;&#26041;&#31243;&#21644;&#26368;&#20248;&#25511;&#21046;&#31574;&#30053;&#65292;&#24182;&#22312;&#26426;&#22120;&#20154;&#23398;&#24314;&#27169;&#12289;&#25511;&#21046;&#21644;&#35774;&#35745;&#20013;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>https://arxiv.org/abs/2402.15552</link><description>&lt;p&gt;
&#26426;&#22120;&#20154;&#23398;&#20013;&#30340;&#24418;&#24577;&#23545;&#31216;&#24615;
&lt;/p&gt;
&lt;p&gt;
Morphological Symmetries in Robotics
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15552
&lt;/p&gt;
&lt;p&gt;
&#24418;&#24577;&#23545;&#31216;&#24615;&#26159;&#26426;&#22120;&#20154;&#31995;&#32479;&#20013;&#30340;&#22266;&#26377;&#24615;&#36136;&#65292;&#36890;&#36807;&#23545;&#36816;&#21160;&#32467;&#26500;&#21644;&#36136;&#37327;&#30340;&#23545;&#31216;&#20998;&#24067;&#65292;&#24310;&#20280;&#33267;&#26426;&#22120;&#20154;&#29366;&#24577;&#31354;&#38388;&#21644;&#20256;&#24863;&#22120;&#27979;&#37327;&#65292;&#36827;&#32780;&#24433;&#21709;&#26426;&#22120;&#20154;&#30340;&#36816;&#21160;&#26041;&#31243;&#21644;&#26368;&#20248;&#25511;&#21046;&#31574;&#30053;&#65292;&#24182;&#22312;&#26426;&#22120;&#20154;&#23398;&#24314;&#27169;&#12289;&#25511;&#21046;&#21644;&#35774;&#35745;&#20013;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#26694;&#26550;&#26469;&#30740;&#31350;&#21644;&#21033;&#29992;&#26426;&#22120;&#20154;&#31995;&#32479;&#20013;&#30340;&#24418;&#24577;&#23545;&#31216;&#24615;&#12290;&#36825;&#20123;&#26159;&#26426;&#22120;&#20154;&#24418;&#24577;&#30340;&#22266;&#26377;&#29305;&#24615;&#65292;&#32463;&#24120;&#22312;&#21160;&#29289;&#29983;&#29289;&#23398;&#21644;&#26426;&#22120;&#20154;&#23398;&#20013;&#35266;&#23519;&#21040;&#65292;&#28304;&#20110;&#36816;&#21160;&#32467;&#26500;&#30340;&#22797;&#21046;&#21644;&#36136;&#37327;&#30340;&#23545;&#31216;&#20998;&#24067;&#12290;&#25105;&#20204;&#35828;&#26126;&#20102;&#36825;&#20123;&#23545;&#31216;&#24615;&#22914;&#20309;&#24310;&#20280;&#21040;&#26426;&#22120;&#20154;&#30340;&#29366;&#24577;&#31354;&#38388;&#20197;&#21450;&#26412;&#20307;&#24863;&#30693;&#21644;&#22806;&#37096;&#24863;&#30693;&#20256;&#24863;&#22120;&#27979;&#37327;&#65292;&#23548;&#33268;&#26426;&#22120;&#20154;&#30340;&#36816;&#21160;&#26041;&#31243;&#21644;&#26368;&#20248;&#25511;&#21046;&#31574;&#30053;&#30340;&#31561;&#19981;&#21464;&#24615;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#35748;&#35782;&#21040;&#24418;&#24577;&#23545;&#31216;&#24615;&#20316;&#20026;&#19968;&#20010;&#30456;&#20851;&#19988;&#20197;&#21069;&#26410;&#34987;&#25506;&#32034;&#30340;&#21463;&#29289;&#29702;&#21551;&#31034;&#30340;&#20960;&#20309;&#20808;&#39564;&#65292;&#23545;&#26426;&#22120;&#20154;&#24314;&#27169;&#12289;&#25511;&#21046;&#12289;&#20272;&#35745;&#21644;&#35774;&#35745;&#20013;&#20351;&#29992;&#30340;&#25968;&#25454;&#39537;&#21160;&#21644;&#20998;&#26512;&#26041;&#27861;&#37117;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;&#23545;&#20110;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#65292;&#25105;&#20204;&#28436;&#31034;&#20102;&#24418;&#24577;&#23545;&#31216;&#24615;&#22914;&#20309;&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#26679;&#26412;&#25928;&#29575;&#21644;&#27867;&#21270;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15552v1 Announce Type: cross  Abstract: We present a comprehensive framework for studying and leveraging morphological symmetries in robotic systems. These are intrinsic properties of the robot's morphology, frequently observed in animal biology and robotics, which stem from the replication of kinematic structures and the symmetrical distribution of mass. We illustrate how these symmetries extend to the robot's state space and both proprioceptive and exteroceptive sensor measurements, resulting in the equivariance of the robot's equations of motion and optimal control policies. Thus, we recognize morphological symmetries as a relevant and previously unexplored physics-informed geometric prior, with significant implications for both data-driven and analytical methods used in modeling, control, estimation and design in robotics. For data-driven methods, we demonstrate that morphological symmetries can enhance the sample efficiency and generalization of machine learning models 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#30340;&#30005;&#21160;&#27773;&#36710;&#20805;&#30005;&#31449;&#27169;&#22411;&#65292;&#36890;&#36807;&#29992;&#25143;&#34892;&#20026;&#24314;&#27169;&#21644;&#38543;&#26426;&#35268;&#21010;&#65292;&#35299;&#20915;&#20102;&#20805;&#30005;&#20250;&#35805;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#26041;&#27861;&#26469;&#20248;&#21270;&#25104;&#26412;&#24182;&#25552;&#39640;&#29992;&#25143;&#28385;&#24847;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.13224</link><description>&lt;p&gt;
&#36890;&#36807;&#29992;&#25143;&#34892;&#20026;&#24314;&#27169;&#21644;&#38543;&#26426;&#35268;&#21010;&#25511;&#21046;&#22823;&#22411;&#30005;&#21160;&#27773;&#36710;&#20805;&#30005;&#31449;
&lt;/p&gt;
&lt;p&gt;
Controlling Large Electric Vehicle Charging Stations via User Behavior Modeling and Stochastic Programming
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13224
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#30340;&#30005;&#21160;&#27773;&#36710;&#20805;&#30005;&#31449;&#27169;&#22411;&#65292;&#36890;&#36807;&#29992;&#25143;&#34892;&#20026;&#24314;&#27169;&#21644;&#38543;&#26426;&#35268;&#21010;&#65292;&#35299;&#20915;&#20102;&#20805;&#30005;&#20250;&#35805;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#26041;&#27861;&#26469;&#20248;&#21270;&#25104;&#26412;&#24182;&#25552;&#39640;&#29992;&#25143;&#28385;&#24847;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#30005;&#21160;&#27773;&#36710;&#20805;&#30005;&#31449;&#65288;EVCS&#65289;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#34701;&#21512;&#20102;&#30495;&#23454;&#19990;&#30028;&#30340;&#32422;&#26463;&#26465;&#20214;&#65292;&#22914;&#25554;&#27133;&#21151;&#29575;&#38480;&#21046;&#12289;&#21512;&#21516;&#38408;&#20540;&#36229;&#38480;&#24809;&#32602;&#20197;&#21450;&#30005;&#21160;&#27773;&#36710;&#65288;EVs&#65289;&#30340;&#26089;&#26399;&#26029;&#24320;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#19981;&#30830;&#23450;&#24615;&#19979;&#25511;&#21046;EVCS&#30340;&#38382;&#39064;&#24418;&#24335;&#65292;&#24182;&#23454;&#26045;&#20102;&#20004;&#31181;&#22810;&#38454;&#27573;&#38543;&#26426;&#35268;&#21010;&#26041;&#27861;&#65292;&#21033;&#29992;&#29992;&#25143;&#25552;&#20379;&#30340;&#20449;&#24687;&#65292;&#21363;&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;&#21644;&#20108;&#38454;&#27573;&#38543;&#26426;&#35268;&#21010;&#12290;&#35813;&#27169;&#22411;&#35299;&#20915;&#20102;&#20805;&#30005;&#20250;&#35805;&#24320;&#22987;&#21644;&#32467;&#26463;&#26102;&#38388;&#20197;&#21450;&#33021;&#37327;&#38656;&#27714;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#22522;&#20110;&#39547;&#30041;&#26102;&#38388;&#20381;&#36182;&#38543;&#26426;&#36807;&#31243;&#30340;&#29992;&#25143;&#34892;&#20026;&#27169;&#22411;&#22686;&#24378;&#20102;&#25104;&#26412;&#38477;&#20302;&#30340;&#21516;&#26102;&#20445;&#25345;&#23458;&#25143;&#28385;&#24847;&#24230;&#12290;&#36890;&#36807;&#20351;&#29992;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#36827;&#34892;&#30340;22&#22825;&#27169;&#25311;&#23637;&#31034;&#20102;&#20004;&#31181;&#25552;&#20986;&#26041;&#27861;&#30456;&#23545;&#20110;&#20004;&#20010;&#22522;&#32447;&#30340;&#20248;&#21183;&#12290;&#20004;&#38454;&#27573;&#26041;&#27861;&#35777;&#26126;&#20102;&#38024;&#23545;&#26089;&#26399;&#26029;&#24320;&#30340;&#40065;&#26834;&#24615;&#65292;&#32771;&#34385;&#20102;&#26356;&#22810;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13224v1 Announce Type: cross  Abstract: This paper introduces an Electric Vehicle Charging Station (EVCS) model that incorporates real-world constraints, such as slot power limitations, contract threshold overruns penalties, or early disconnections of electric vehicles (EVs). We propose a formulation of the problem of EVCS control under uncertainty, and implement two Multi-Stage Stochastic Programming approaches that leverage user-provided information, namely, Model Predictive Control and Two-Stage Stochastic Programming. The model addresses uncertainties in charging session start and end times, as well as in energy demand. A user's behavior model based on a sojourn-time-dependent stochastic process enhances cost reduction while maintaining customer satisfaction. The benefits of the two proposed methods are showcased against two baselines over a 22-day simulation using a real-world dataset. The two-stage approach proves robust against early disconnections, considering a more
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20445;&#30041;&#35821;&#20041;&#30340;&#36716;&#25442;&#30340;&#33258;&#28982;&#24615;&#21450;&#20854;&#23545;NPR&#35780;&#20272;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#20102;NPR&#31995;&#32479;&#22312;&#38754;&#23545;&#19981;&#33258;&#28982;&#30340;&#20195;&#30721;&#36716;&#25442;&#26102;&#20250;&#20135;&#29983;&#36739;&#39640;&#30340;&#35823;&#25253;&#29575;&#65292;&#19988;&#22312;&#20351;&#29992;&#33258;&#28982;&#36716;&#25442;&#36827;&#34892;&#35780;&#20272;&#26102;&#24615;&#33021;&#26126;&#26174;&#19979;&#38477;&#12290;</title><link>https://arxiv.org/abs/2402.11892</link><description>&lt;p&gt;
&#29992;&#20445;&#30041;&#35821;&#20041;&#30340;&#36716;&#25442;&#35780;&#20272;&#31243;&#24207;&#20462;&#22797;&#65306;&#33258;&#28982;&#24615;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Evaluating Program Repair with Semantic-Preserving Transformations: A Naturalness Assessment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11892
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20445;&#30041;&#35821;&#20041;&#30340;&#36716;&#25442;&#30340;&#33258;&#28982;&#24615;&#21450;&#20854;&#23545;NPR&#35780;&#20272;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#20102;NPR&#31995;&#32479;&#22312;&#38754;&#23545;&#19981;&#33258;&#28982;&#30340;&#20195;&#30721;&#36716;&#25442;&#26102;&#20250;&#20135;&#29983;&#36739;&#39640;&#30340;&#35823;&#25253;&#29575;&#65292;&#19988;&#22312;&#20351;&#29992;&#33258;&#28982;&#36716;&#25442;&#36827;&#34892;&#35780;&#20272;&#26102;&#24615;&#33021;&#26126;&#26174;&#19979;&#38477;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20445;&#30041;&#35821;&#20041;&#30340;&#36716;&#25442;&#30340;&#33258;&#28982;&#24615;&#21450;&#20854;&#23545;NPR&#35780;&#20272;&#30340;&#24433;&#21709;&#12290;&#20026;&#20102;&#36798;&#21040;&#36825;&#20010;&#30446;&#30340;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#30340;&#20154;&#31867;&#30740;&#31350;&#65292;&#21253;&#25324;(1)&#19982;&#36164;&#28145;&#36719;&#20214;&#24320;&#21457;&#20154;&#21592;&#30340;&#35775;&#35848;&#65292;&#20197;&#24314;&#31435;&#35780;&#20272;&#20195;&#30721;&#36716;&#25442;&#33258;&#28982;&#24615;&#30340;&#31532;&#19968;&#20010;&#20855;&#20307;&#26631;&#20934;&#65307;(2)&#36827;&#34892;&#20102;&#19968;&#39033;&#28041;&#21450;10&#21517;&#24320;&#21457;&#20154;&#21592;&#30340;&#35843;&#26597;&#65292;&#35780;&#20272;&#20102;&#24212;&#29992;&#20110;225&#20010;&#30495;&#23454;&#19990;&#30028;bug&#30340;1178&#20010;&#36716;&#25442;&#65288;&#21363;&#21407;&#22987;&#21644;&#36716;&#25442;&#31243;&#24207;&#25104;&#23545;&#30340;&#24773;&#20917;&#65289;&#30340;&#33258;&#28982;&#24615;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#65292;&#20854;&#20013;&#25509;&#36817;60%&#30340;&#36716;&#25442;&#34987;&#35748;&#20026;&#26159;&#33258;&#28982;&#30340;&#65292;20%&#30340;&#36716;&#25442;&#34987;&#35748;&#20026;&#26159;&#19981;&#33258;&#28982;&#30340;&#65292;&#24182;&#19988;&#22312;&#20154;&#31867;&#26631;&#27880;&#32773;&#20043;&#38388;&#26377;&#30456;&#24403;&#39640;&#30340;&#19968;&#33268;&#24615;&#12290;&#27492;&#22806;&#65292;&#19981;&#33258;&#28982;&#30340;&#20195;&#30721;&#36716;&#25442;&#24341;&#20837;&#20102;&#20116;&#20010;&#30693;&#21517;NPR&#31995;&#32479;&#30340;&#31283;&#20581;&#24615;&#30340;25.2%&#35823;&#25253;&#29575;&#12290;&#27492;&#22806;&#65292;&#24403;&#20351;&#29992;&#33258;&#28982;&#36716;&#25442;&#36827;&#34892;&#35780;&#20272;&#26102;&#65292;NPR&#31995;&#32479;&#30340;&#24615;&#33021;&#26174;&#30528;&#19979;&#38477;&#65292;&#21363;&#24615;&#33021;&#19979;&#38477;&#39640;&#36798;22.9%&#21644;23.6%&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11892v1 Announce Type: cross  Abstract: In this paper, we investigate the naturalness of semantic-preserving transformations and their impacts on the evaluation of NPR. To achieve this, we conduct a two-stage human study, including (1) interviews with senior software developers to establish the first concrete criteria for assessing the naturalness of code transformations and (2) a survey involving 10 developers to assess the naturalness of 1178 transformations, i.e., pairs of original and transformed programs, applied to 225 real-world bugs. Our findings reveal that nearly 60% and 20% of these transformations are considered natural and unnatural with substantially high agreement among human annotators. Furthermore, the unnatural code transformations introduce a 25.2% false alarm rate on robustness of five well-known NPR systems. Additionally, the performance of the NPR systems drops notably when evaluated using natural transformations, i.e., a drop of up to 22.9% and 23.6% i
&lt;/p&gt;</description></item><item><title>AutoSAT&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33258;&#21160;&#20248;&#21270;SAT&#27714;&#35299;&#22120;&#20013;&#30340;&#21551;&#21457;&#24335;&#65292;&#20943;&#23569;&#20154;&#20026;&#24178;&#39044;&#65292;&#25552;&#21319;&#27714;&#35299;&#22120;&#33021;&#21147;&#65292;&#23454;&#29616;&#20102;&#21363;&#25554;&#21363;&#29992;&#25805;&#20316;&#65292;&#20445;&#35777;&#20102;&#23481;&#38169;&#24615;&#65292;&#22312;&#24191;&#27867;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.10705</link><description>&lt;p&gt;
AutoSAT:&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33258;&#21160;&#20248;&#21270;SAT&#27714;&#35299;&#22120;
&lt;/p&gt;
&lt;p&gt;
AutoSAT: Automatically Optimize SAT Solvers via Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10705
&lt;/p&gt;
&lt;p&gt;
AutoSAT&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33258;&#21160;&#20248;&#21270;SAT&#27714;&#35299;&#22120;&#20013;&#30340;&#21551;&#21457;&#24335;&#65292;&#20943;&#23569;&#20154;&#20026;&#24178;&#39044;&#65292;&#25552;&#21319;&#27714;&#35299;&#22120;&#33021;&#21147;&#65292;&#23454;&#29616;&#20102;&#21363;&#25554;&#21363;&#29992;&#25805;&#20316;&#65292;&#20445;&#35777;&#20102;&#23481;&#38169;&#24615;&#65292;&#22312;&#24191;&#27867;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21551;&#21457;&#24335;&#22312;SAT&#27714;&#35299;&#22120;&#20013;&#33267;&#20851;&#37325;&#35201;&#65292;&#28982;&#32780;&#65292;&#24182;&#27809;&#26377;&#36866;&#29992;&#20110;&#25152;&#26377;&#38382;&#39064;&#23454;&#20363;&#30340;&#21551;&#21457;&#24335;&#35268;&#21017;&#12290;&#22240;&#27492;&#65292;&#36890;&#24120;&#38656;&#35201;&#20026;&#29305;&#23450;&#38382;&#39064;&#23454;&#20363;&#20248;&#21270;&#29305;&#23450;&#27714;&#35299;&#22120;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;AutoSAT&#65292;&#36825;&#26159;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#33258;&#21160;&#20248;&#21270;SAT&#27714;&#35299;&#22120;&#20013;&#30340;&#21551;&#21457;&#24335;&#12290;AutoSAT&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#33021;&#22815;&#33258;&#21160;&#29983;&#25104;&#20195;&#30721;&#65292;&#36827;&#34892;&#35780;&#20272;&#65292;&#28982;&#21518;&#21033;&#29992;&#21453;&#39304;&#36827;&#19968;&#27493;&#20248;&#21270;&#21551;&#21457;&#24335;&#65292;&#20174;&#32780;&#20943;&#23569;&#20154;&#20026;&#24178;&#39044;&#65292;&#22686;&#24378;&#27714;&#35299;&#22120;&#33021;&#21147;&#12290;AutoSAT&#22522;&#20110;&#21363;&#25554;&#21363;&#29992;&#30340;&#26041;&#24335;&#36816;&#34892;&#65292;&#28040;&#38500;&#20102;&#23545;&#24191;&#27867;&#30340;&#21021;&#27493;&#35774;&#32622;&#21644;&#27169;&#22411;&#35757;&#32451;&#30340;&#38656;&#27714;&#65292;&#24182;&#20419;&#36827;&#20102;&#19968;&#31181;&#24102;&#26377;&#23481;&#38169;&#33021;&#21147;&#30340;&#24605;&#32500;&#38142;&#21327;&#20316;&#36807;&#31243;&#65292;&#30830;&#20445;&#21551;&#21457;&#24335;&#20248;&#21270;&#30340;&#31283;&#20581;&#24615;&#12290;&#23545;&#20351;&#29992;&#20914;&#31361;&#39537;&#21160;&#23376;&#21477;&#23398;&#20064;&#65288;CDCL&#65289;&#27714;&#35299;&#22120;&#30340;&#24191;&#27867;&#23454;&#39564;&#34920;&#26126;AutoSAT&#30340;&#25972;&#20307;&#24615;&#33021;&#20248;&#36234;&#65292;&#29305;&#21035;&#22312;&#35299;&#20915;&#26576;&#20123;&#29305;&#23450;&#30340;SAT&#38382;&#39064;&#26102;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10705v1 Announce Type: new  Abstract: Heuristics are crucial in SAT solvers, while no heuristic rules are suitable for all problem instances. Therefore, it typically requires to refine specific solvers for specific problem instances. In this context, we present AutoSAT, a novel framework for automatically optimizing heuristics in SAT solvers. AutoSAT is based on Large Large Models (LLMs) which is able to autonomously generate code, conduct evaluation, then utilize the feedback to further optimize heuristics, thereby reducing human intervention and enhancing solver capabilities. AutoSAT operates on a plug-and-play basis, eliminating the need for extensive preliminary setup and model training, and fosters a Chain of Thought collaborative process with fault-tolerance, ensuring robust heuristic optimization. Extensive experiments on a Conflict-Driven Clause Learning (CDCL) solver demonstrates the overall superior performance of AutoSAT, especially in solving some specific SAT pr
&lt;/p&gt;</description></item><item><title>HEAM&#26159;&#19968;&#31181;&#37319;&#29992;&#24322;&#26500;&#20869;&#23384;&#26550;&#26500;&#30340;&#26041;&#27861;&#65292;&#23558;3D&#22534;&#21472;DRAM&#19982;DIMM&#38598;&#25104;&#65292;&#29992;&#20110;&#21152;&#36895;&#22788;&#29702;&#22823;&#35268;&#27169;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#23884;&#20837;&#25805;&#20316;&#12290;</title><link>https://arxiv.org/abs/2402.04032</link><description>&lt;p&gt;
HEAM: &#20351;&#29992;&#22788;&#29702;-&#20869;&#23384;&#36827;&#34892;&#25955;&#21015;&#23884;&#20837;&#21152;&#36895;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
HEAM : Hashed Embedding Acceleration using Processing-In-Memory
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04032
&lt;/p&gt;
&lt;p&gt;
HEAM&#26159;&#19968;&#31181;&#37319;&#29992;&#24322;&#26500;&#20869;&#23384;&#26550;&#26500;&#30340;&#26041;&#27861;&#65292;&#23558;3D&#22534;&#21472;DRAM&#19982;DIMM&#38598;&#25104;&#65292;&#29992;&#20110;&#21152;&#36895;&#22788;&#29702;&#22823;&#35268;&#27169;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#23884;&#20837;&#25805;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24403;&#20170;&#30340;&#25968;&#25454;&#20013;&#24515;&#20013;&#65292;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#38754;&#20020;&#30528;&#35832;&#22810;&#25361;&#25112;&#65292;&#29305;&#21035;&#26159;&#22312;&#25191;&#34892;&#23884;&#20837;&#25805;&#20316;&#26102;&#38656;&#35201;&#22823;&#23481;&#37327;&#30340;&#20869;&#23384;&#21644;&#39640;&#24102;&#23485;&#12290;&#20043;&#21069;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;DIMM-based&#36817;&#20869;&#23384;&#22788;&#29702;&#25216;&#26415;&#25110;&#24341;&#20837;3D&#22534;&#21472;DRAM&#26469;&#35299;&#20915;&#20869;&#23384;&#38480;&#21046;&#21644;&#25193;&#23637;&#20869;&#23384;&#24102;&#23485;&#30340;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#35299;&#20915;&#26041;&#26696;&#22312;&#22788;&#29702;&#26085;&#30410;&#25193;&#22823;&#30340;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#22823;&#23567;&#26102;&#23384;&#22312;&#19981;&#36275;&#20043;&#22788;&#12290;&#25512;&#33616;&#27169;&#22411;&#24050;&#32463;&#22686;&#38271;&#21040;&#36229;&#36807;&#25968;&#21313;TB&#30340;&#22823;&#23567;&#65292;&#23548;&#33268;&#22312;&#20256;&#32479;&#21333;&#33410;&#28857;&#25512;&#26029;&#26381;&#21153;&#22120;&#19978;&#39640;&#25928;&#36816;&#34892;&#21464;&#24471;&#22256;&#38590;&#12290;&#23613;&#31649;&#24050;&#32463;&#25552;&#20986;&#20102;&#21508;&#31181;&#31639;&#27861;&#26041;&#27861;&#26469;&#20943;&#23567;&#23884;&#20837;&#34920;&#23481;&#37327;&#65292;&#20294;&#36890;&#24120;&#20250;&#23548;&#33268;&#20869;&#23384;&#35775;&#38382;&#22686;&#21152;&#25110;&#20869;&#23384;&#36164;&#28304;&#21033;&#29992;&#20302;&#25928;&#30340;&#38382;&#39064;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;HEAM&#65292;&#19968;&#31181;&#24322;&#26500;&#20869;&#23384;&#26550;&#26500;&#65292;&#23558;3D&#22534;&#21472;DRAM&#19982;DIMM&#38598;&#25104;&#22312;&#19968;&#36215;&#65292;&#20197;&#21152;&#36895;&#32452;&#21512;&#23884;&#20837;&#30340;&#25512;&#33616;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;
In today's data centers, personalized recommendation systems face challenges such as the need for large memory capacity and high bandwidth, especially when performing embedding operations. Previous approaches have relied on DIMM-based near-memory processing techniques or introduced 3D-stacked DRAM to address memory-bound issues and expand memory bandwidth. However, these solutions fall short when dealing with the expanding size of personalized recommendation systems. Recommendation models have grown to sizes exceeding tens of terabytes, making them challenging to run efficiently on traditional single-node inference servers. Although various algorithmic methods have been proposed to reduce embedding table capacity, they often result in increased memory access or inefficient utilization of memory resources. This paper introduces HEAM, a heterogeneous memory architecture that integrates 3D-stacked DRAM with DIMM to accelerate recommendation systems in which compositional embedding is util
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#35268;&#21010;&#65288;UoT&#65289;&#31639;&#27861;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20027;&#21160;&#23547;&#27714;&#20449;&#24687;&#30340;&#33021;&#21147;&#65292;&#36890;&#36807;&#27169;&#25311;&#26410;&#26469;&#22330;&#26223;&#12289;&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#30340;&#22870;&#21169;&#26426;&#21046;&#21644;&#22870;&#21169;&#20256;&#25773;&#26041;&#26696;&#65292;&#20248;&#21270;&#38382;&#39064;&#25552;&#38382;&#26041;&#24335;&#12290;</title><link>https://arxiv.org/abs/2402.03271</link><description>&lt;p&gt;
&#24819;&#27861;&#30340;&#19981;&#30830;&#23450;&#24615;&#65306;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#35268;&#21010;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20449;&#24687;&#25628;&#32034;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Uncertainty of Thoughts: Uncertainty-Aware Planning Enhances Information Seeking in Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03271
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#35268;&#21010;&#65288;UoT&#65289;&#31639;&#27861;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20027;&#21160;&#23547;&#27714;&#20449;&#24687;&#30340;&#33021;&#21147;&#65292;&#36890;&#36807;&#27169;&#25311;&#26410;&#26469;&#22330;&#26223;&#12289;&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#30340;&#22870;&#21169;&#26426;&#21046;&#21644;&#22870;&#21169;&#20256;&#25773;&#26041;&#26696;&#65292;&#20248;&#21270;&#38382;&#39064;&#25552;&#38382;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#38754;&#23545;&#19981;&#30830;&#23450;&#24615;&#26102;&#65292;&#23547;&#27714;&#20449;&#24687;&#30340;&#33021;&#21147;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#27604;&#22914;&#21307;&#23398;&#35786;&#26029;&#21644;&#25925;&#38556;&#25490;&#38500;&#65292;&#35299;&#20915;&#20219;&#21153;&#25152;&#38656;&#30340;&#20449;&#24687;&#19981;&#26159;&#21021;&#22987;&#32473;&#23450;&#30340;&#65292;&#32780;&#38656;&#35201;&#36890;&#36807;&#35810;&#38382;&#21518;&#32493;&#38382;&#39064;&#26469;&#20027;&#21160;&#23547;&#27714;&#65288;&#20363;&#22914;&#65292;&#21307;&#29983;&#21521;&#24739;&#32773;&#35810;&#38382;&#30151;&#29366;&#30340;&#26356;&#22810;&#32454;&#33410;&#65289;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#24605;&#24819;&#30340;&#19981;&#30830;&#23450;&#24615;&#65288;UoT&#65289;&#65292;&#19968;&#31181;&#31639;&#27861;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#19982;&#20027;&#21160;&#25552;&#38382;&#20449;&#24687;&#30340;&#33021;&#21147;&#30456;&#32467;&#21512;&#12290;UoT&#32467;&#21512;&#20102;1&#65289;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#20223;&#30495;&#26041;&#27861;&#65292;&#20351;&#27169;&#22411;&#33021;&#22815;&#27169;&#25311;&#21487;&#33021;&#30340;&#26410;&#26469;&#22330;&#26223;&#65292;&#24182;&#20272;&#35745;&#20854;&#21457;&#29983;&#30340;&#21487;&#33021;&#24615;&#65307;2&#65289;&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#30340;&#22870;&#21169;&#26426;&#21046;&#65292;&#28608;&#21169;&#27169;&#22411;&#23547;&#27714;&#20449;&#24687;&#65307;3&#65289;&#22870;&#21169;&#20256;&#25773;&#26041;&#26696;&#65292;&#20197;&#26368;&#22823;&#21270;&#39044;&#26399;&#22870;&#21169;&#30340;&#26041;&#24335;&#36873;&#25321;&#26368;&#20339;&#30340;&#38382;&#39064;&#25552;&#38382;&#26041;&#24335;&#12290;&#22312;&#21307;&#23398;&#35786;&#26029;&#12289;&#25925;&#38556;&#25490;&#38500;&#21644;'20&#30340;&#23454;&#39564;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the face of uncertainty, the ability to seek information is of fundamental importance. In many practical applications, such as medical diagnosis and troubleshooting, the information needed to solve the task is not initially given, and has to be actively sought by asking follow-up questions (for example, a doctor asking a patient for more details about their symptoms). In this work, we introduce Uncertainty of Thoughts (UoT), an algorithm to augment large language models with the ability to actively seek information by asking effective questions. UoT combines 1) an uncertainty-aware simulation approach which enables the model to simulate possible future scenarios and how likely they are to occur, 2) uncertainty-based rewards motivated by information gain which incentivizes the model to seek information, and 3) a reward propagation scheme to select the optimal question to ask in a way that maximizes the expected reward. In experiments on medical diagnosis, troubleshooting and the '20 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21021;&#27493;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22522;&#20110;&#34920;&#26684;&#30340;&#20107;&#23454;&#26816;&#26597;&#26041;&#38754;&#30340;&#28508;&#21147;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#36890;&#36807;&#25552;&#31034;&#24037;&#31243;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#38646;&#26679;&#26412;&#21644;&#23569;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#21487;&#20197;&#23454;&#29616;&#21487;&#25509;&#21463;&#30340;&#34920;&#29616;&#12290;</title><link>https://arxiv.org/abs/2402.02549</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#36866;&#21512;&#22522;&#20110;&#34920;&#26684;&#30340;&#20107;&#23454;&#26816;&#26597;&#65311;
&lt;/p&gt;
&lt;p&gt;
Are Large Language Models Table-based Fact-Checkers?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02549
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21021;&#27493;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22522;&#20110;&#34920;&#26684;&#30340;&#20107;&#23454;&#26816;&#26597;&#26041;&#38754;&#30340;&#28508;&#21147;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#36890;&#36807;&#25552;&#31034;&#24037;&#31243;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#38646;&#26679;&#26412;&#21644;&#23569;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#21487;&#20197;&#23454;&#29616;&#21487;&#25509;&#21463;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#34920;&#26684;&#30340;&#20107;&#23454;&#39564;&#35777;&#65288;TFV&#65289;&#26088;&#22312;&#25552;&#21462;&#35821;&#21477;&#21644;&#32467;&#26500;&#21270;&#34920;&#26684;&#20043;&#38388;&#30340;&#34164;&#28085;&#20851;&#31995;&#12290;&#29616;&#26377;&#22522;&#20110;&#23567;&#35268;&#27169;&#27169;&#22411;&#30340;TFV&#26041;&#27861;&#22312;&#26631;&#27880;&#25968;&#25454;&#19981;&#36275;&#21644;&#38646;&#26679;&#26412;&#33021;&#21147;&#34180;&#24369;&#26041;&#38754;&#23384;&#22312;&#38382;&#39064;&#12290;&#36817;&#24180;&#26469;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#30740;&#31350;&#39046;&#22495;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#23427;&#20204;&#22312;&#20960;&#20010;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#19978;&#23637;&#31034;&#20102;&#24378;&#22823;&#30340;&#38646;&#26679;&#26412;&#21644;&#19978;&#19979;&#25991;&#23398;&#20064;&#33021;&#21147;&#65292;&#20294;&#23427;&#20204;&#22312;TFV&#39046;&#22495;&#30340;&#28508;&#21147;&#36824;&#19981;&#28165;&#26970;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#20851;&#20110;LLMs&#26159;&#21542;&#36866;&#21512;&#20316;&#20026;&#22522;&#20110;&#34920;&#26684;&#30340;&#20107;&#23454;&#26816;&#26597;&#22120;&#30340;&#21021;&#27493;&#30740;&#31350;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#22810;&#26679;&#21270;&#30340;&#25552;&#31034;&#35821;&#26469;&#25506;&#32034;&#19978;&#19979;&#25991;&#23398;&#20064;&#22914;&#20309;&#24110;&#21161;LLMs&#22312;TFV&#26041;&#38754;&#65292;&#21363;&#38646;&#26679;&#26412;&#21644;&#23569;&#26679;&#26412;TFV&#33021;&#21147;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#31934;&#24515;&#35774;&#35745;&#21644;&#26500;&#24314;&#20102;TFV&#25351;&#23548;&#20197;&#30740;&#31350;LLMs&#30340;&#25351;&#23548;&#35843;&#25972;&#24102;&#26469;&#30340;&#24615;&#33021;&#25913;&#36827;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#36890;&#36807;&#25552;&#31034;&#24037;&#31243;&#65292;LLMs&#22312;&#38646;&#26679;&#26412;&#21644;&#23569;&#26679;&#26412;TFV&#26041;&#38754;&#21487;&#20197;&#36798;&#21040;&#21487;&#25509;&#21463;&#30340;&#32467;&#26524;&#65292;&#32780;&#25351;&#23548;&#35843;&#25972;&#21017;&#36827;&#19968;&#27493;&#25552;&#21319;&#20102;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Table-based Fact Verification (TFV) aims to extract the entailment relation between statements and structured tables. Existing TFV methods based on small-scaled models suffer from insufficient labeled data and weak zero-shot ability. Recently, the appearance of Large Language Models (LLMs) has gained lots of attraction in research fields. They have shown powerful zero-shot and in-context learning abilities on several NLP tasks, but their potential on TFV is still unknown. In this work, we implement a preliminary study about whether LLMs are table-based fact-checkers. In detail, we design diverse prompts to explore how the in-context learning can help LLMs in TFV, i.e., zero-shot and few-shot TFV capability. Besides, we carefully design and construct TFV instructions to study the performance gain brought by the instruction tuning of LLMs. Experimental results demonstrate that LLMs can achieve acceptable results on zero-shot and few-shot TFV with prompt engineering, while instruction-tun
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25581;&#31034;&#20102;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#22312;&#35782;&#21035;&#26377;&#27602;&#12289;&#20882;&#29359;&#21644;&#20196;&#20154;&#35752;&#21388;&#30340;&#20869;&#23481;&#26041;&#38754;&#30340;&#36827;&#23637;&#65292;&#24182;&#25506;&#35752;&#20102;&#36825;&#20123;&#25913;&#36827;&#26159;&#21542;&#30495;&#27491;&#28385;&#36275;&#20102;&#24535;&#24895;&#20869;&#23481;&#31649;&#29702;&#21592;&#22312;&#24037;&#20316;&#20013;&#30340;&#38656;&#27714;&#12290;</title><link>https://arxiv.org/abs/2311.07879</link><description>&lt;p&gt;
&#27602;&#24615;&#26816;&#27979;&#24182;&#19981;&#26159;&#20320;&#25152;&#38656;&#35201;&#30340;&#20840;&#37096;&#65306;&#24357;&#21512;&#25903;&#25345;&#24535;&#24895;&#20869;&#23481;&#31649;&#29702;&#21592;&#30340;&#24046;&#36317;
&lt;/p&gt;
&lt;p&gt;
Toxicity Detection is NOT all you Need: Measuring the Gaps to Supporting Volunteer Content Moderators
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.07879
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25581;&#31034;&#20102;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#22312;&#35782;&#21035;&#26377;&#27602;&#12289;&#20882;&#29359;&#21644;&#20196;&#20154;&#35752;&#21388;&#30340;&#20869;&#23481;&#26041;&#38754;&#30340;&#36827;&#23637;&#65292;&#24182;&#25506;&#35752;&#20102;&#36825;&#20123;&#25913;&#36827;&#26159;&#21542;&#30495;&#27491;&#28385;&#36275;&#20102;&#24535;&#24895;&#20869;&#23481;&#31649;&#29702;&#21592;&#22312;&#24037;&#20316;&#20013;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#22312;&#35782;&#21035;&#26377;&#27602;&#12289;&#20882;&#29359;&#21644;&#20196;&#20154;&#35752;&#21388;&#30340;&#20869;&#23481;&#26041;&#38754;&#21462;&#24471;&#20102;&#38271;&#36275;&#30340;&#36827;&#23637;&#65292;&#26088;&#22312;&#20943;&#36731;&#31649;&#29702;&#21592;&#30340;&#24037;&#20316;&#36127;&#25285;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23578;&#19981;&#28165;&#26970;&#36825;&#20123;&#20219;&#21153;&#30340;&#25913;&#36827;&#26159;&#21542;&#30495;&#27491;&#28385;&#36275;&#20102;&#31649;&#29702;&#21592;&#22312;&#24037;&#20316;&#20013;&#30340;&#38656;&#27714;&#12290;&#26412;&#25991;&#25581;&#31034;&#20102;&#36807;&#21435;&#30740;&#31350;&#21162;&#21147;&#33268;&#21147;&#20110;&#20026;&#20869;&#23481;&#31649;&#29702;&#30340;&#21508;&#20010;&#26041;&#38754;&#25552;&#20379;&#33258;&#21160;&#21270;&#25903;&#25345;&#19982;&#24535;&#24895;&#20869;&#23481;&#31649;&#29702;&#21592;&#30340;&#38656;&#27714;&#20043;&#38388;&#23384;&#22312;&#30340;&#24046;&#36317;&#65292;&#23588;&#20854;&#26159;&#22312;&#35782;&#21035;&#36829;&#21453;&#21508;&#31181;&#31649;&#29702;&#35268;&#21017;&#26041;&#38754;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#22312;Hugging Face&#19978;&#23545;&#27169;&#22411;&#36827;&#34892;&#20102;&#35843;&#26597;&#65292;&#20197;&#25581;&#31034;&#28085;&#30422;&#19977;&#20010;&#31034;&#33539;&#35770;&#22363;&#30340;&#21508;&#31181;&#31649;&#29702;&#35268;&#21017;&#21644;&#25351;&#21335;&#30340;&#27169;&#22411;&#30340;&#21487;&#29992;&#24615;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23545;&#26368;&#20808;&#36827;&#30340;LLM&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#35780;&#20272;&#36825;&#20123;&#27169;&#22411;&#22312;&#26631;&#35760;&#26576;&#20010;&#29305;&#23450;&#35770;&#22363;&#30340;&#24179;&#21488;&#35268;&#21017;&#36829;&#35268;&#26041;&#38754;&#30340;&#34920;&#29616;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#29992;&#25143;&#35843;&#26597;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.07879v2 Announce Type: replace-cross  Abstract: Extensive efforts in automated approaches for content moderation have been focused on developing models to identify toxic, offensive, and hateful content with the aim of lightening the load for moderators. Yet, it remains uncertain whether improvements on those tasks have truly addressed moderators' needs in accomplishing their work. In this paper, we surface gaps between past research efforts that have aimed to provide automation for aspects of content moderation and the needs of volunteer content moderators, regarding identifying violations of various moderation rules. To do so, we conduct a model review on Hugging Face to reveal the availability of models to cover various moderation rules and guidelines from three exemplar forums. We further put state-of-the-art LLMs to the test, evaluating how well these models perform in flagging violations of platform rules from one particular forum. Finally, we conduct a user survey stud
&lt;/p&gt;</description></item><item><title>ShaRP&#26159;&#19968;&#20010;&#22522;&#20110;Shapley&#20540;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#37322;&#25490;&#21517;&#32467;&#26524;&#20013;&#21508;&#20010;&#29305;&#24449;&#30340;&#36129;&#29486;&#12290;&#21363;&#20351;&#20351;&#29992;&#32447;&#24615;&#35780;&#20998;&#20989;&#25968;&#65292;&#29305;&#24449;&#30340;&#26435;&#37325;&#20063;&#19981;&#19968;&#23450;&#23545;&#24212;&#20854;Shapley&#20540;&#30340;&#36129;&#29486;&#65292;&#32780;&#26159;&#21462;&#20915;&#20110;&#29305;&#24449;&#20998;&#24067;&#21644;&#35780;&#20998;&#29305;&#24449;&#20043;&#38388;&#30340;&#23616;&#37096;&#30456;&#20114;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2401.16744</link><description>&lt;p&gt;
ShaRP&#65306;&#29992;Shapley&#20540;&#35299;&#37322;&#25490;&#21517;
&lt;/p&gt;
&lt;p&gt;
ShaRP: Explaining Rankings with Shapley Values. (arXiv:2401.16744v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16744
&lt;/p&gt;
&lt;p&gt;
ShaRP&#26159;&#19968;&#20010;&#22522;&#20110;Shapley&#20540;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#37322;&#25490;&#21517;&#32467;&#26524;&#20013;&#21508;&#20010;&#29305;&#24449;&#30340;&#36129;&#29486;&#12290;&#21363;&#20351;&#20351;&#29992;&#32447;&#24615;&#35780;&#20998;&#20989;&#25968;&#65292;&#29305;&#24449;&#30340;&#26435;&#37325;&#20063;&#19981;&#19968;&#23450;&#23545;&#24212;&#20854;Shapley&#20540;&#30340;&#36129;&#29486;&#65292;&#32780;&#26159;&#21462;&#20915;&#20110;&#29305;&#24449;&#20998;&#24067;&#21644;&#35780;&#20998;&#29305;&#24449;&#20043;&#38388;&#30340;&#23616;&#37096;&#30456;&#20114;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25307;&#32856;&#12289;&#22823;&#23398;&#25307;&#29983;&#21644;&#36151;&#27454;&#31561;&#37325;&#35201;&#39046;&#22495;&#30340;&#31639;&#27861;&#20915;&#31574;&#24120;&#24120;&#26159;&#22522;&#20110;&#25490;&#21517;&#30340;&#12290;&#30001;&#20110;&#36825;&#20123;&#20915;&#31574;&#23545;&#20010;&#20154;&#12289;&#32452;&#32455;&#21644;&#20154;&#32676;&#30340;&#24433;&#21709;&#65292;&#26377;&#24517;&#35201;&#20102;&#35299;&#23427;&#20204;&#65306;&#20102;&#35299;&#20915;&#31574;&#26159;&#21542;&#36981;&#23432;&#27861;&#24459;&#65292;&#24110;&#21161;&#20010;&#20154;&#25552;&#39640;&#20182;&#20204;&#30340;&#25490;&#21517;&#65292;&#24182;&#35774;&#35745;&#26356;&#22909;&#30340;&#25490;&#21517;&#31243;&#24207;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;ShaRP&#65288;Shapley for Rankings and Preferences&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#22522;&#20110;Shapley&#20540;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#37322;&#29305;&#24449;&#23545;&#25490;&#21517;&#32467;&#26524;&#19981;&#21516;&#26041;&#38754;&#30340;&#36129;&#29486;&#12290;&#20351;&#29992;ShaRP&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21363;&#20351;&#31639;&#27861;&#25490;&#21517;&#22120;&#20351;&#29992;&#30340;&#35780;&#20998;&#20989;&#25968;&#26159;&#24050;&#30693;&#30340;&#19988;&#26159;&#32447;&#24615;&#30340;&#65292;&#27599;&#20010;&#29305;&#24449;&#30340;&#26435;&#37325;&#20063;&#19981;&#19968;&#23450;&#23545;&#24212;&#20854;Shapley&#20540;&#30340;&#36129;&#29486;&#12290;&#36129;&#29486;&#21462;&#20915;&#20110;&#29305;&#24449;&#30340;&#20998;&#24067;&#20197;&#21450;&#35780;&#20998;&#29305;&#24449;&#20043;&#38388;&#24494;&#22937;&#30340;&#23616;&#37096;&#30456;&#20114;&#20316;&#29992;&#12290;ShaRP&#22522;&#20110;&#37327;&#21270;&#36755;&#20837;&#24433;&#21709;&#26694;&#26550;&#65292;&#24182;&#21487;&#20197;&#35745;&#31639;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
Algorithmic decisions in critical domains such as hiring, college admissions, and lending are often based on rankings. Because of the impact these decisions have on individuals, organizations, and population groups, there is a need to understand them: to know whether the decisions are abiding by the law, to help individuals improve their rankings, and to design better ranking procedures.  In this paper, we present ShaRP (Shapley for Rankings and Preferences), a framework that explains the contributions of features to different aspects of a ranked outcome, and is based on Shapley values. Using ShaRP, we show that even when the scoring function used by an algorithmic ranker is known and linear, the weight of each feature does not correspond to its Shapley value contribution. The contributions instead depend on the feature distributions, and on the subtle local interactions between the scoring features. ShaRP builds on the Quantitative Input Influence framework, and can compute the contri
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#26041;&#27861;&#26469;&#38477;&#20302;&#26080;&#26381;&#21153;&#22120;&#35745;&#31639;&#20013;&#30340;&#20919;&#21551;&#21160;&#39057;&#29575;&#12290;&#36890;&#36807;&#20351;&#29992;Q&#23398;&#20064;&#21644;&#32771;&#34385;&#22810;&#31181;&#25351;&#26631;&#65292;&#25105;&#20204;&#21487;&#20197;&#22312;&#39044;&#26399;&#38656;&#27714;&#30340;&#22522;&#30784;&#19978;&#25552;&#21069;&#21021;&#22987;&#21270;&#20989;&#25968;&#65292;&#20174;&#32780;&#20943;&#23569;&#20919;&#21551;&#21160;&#27425;&#25968;&#12290;</title><link>http://arxiv.org/abs/2308.07541</link><description>&lt;p&gt;
&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#26080;&#26381;&#21153;&#22120;&#35745;&#31639;&#20013;&#20919;&#21551;&#21160;&#39057;&#29575;&#38477;&#20302;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning (RL) Augmented Cold Start Frequency Reduction in Serverless Computing. (arXiv:2308.07541v1 [cs.DC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07541
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#26041;&#27861;&#26469;&#38477;&#20302;&#26080;&#26381;&#21153;&#22120;&#35745;&#31639;&#20013;&#30340;&#20919;&#21551;&#21160;&#39057;&#29575;&#12290;&#36890;&#36807;&#20351;&#29992;Q&#23398;&#20064;&#21644;&#32771;&#34385;&#22810;&#31181;&#25351;&#26631;&#65292;&#25105;&#20204;&#21487;&#20197;&#22312;&#39044;&#26399;&#38656;&#27714;&#30340;&#22522;&#30784;&#19978;&#25552;&#21069;&#21021;&#22987;&#21270;&#20989;&#25968;&#65292;&#20174;&#32780;&#20943;&#23569;&#20919;&#21551;&#21160;&#27425;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20989;&#25968;&#21363;&#26381;&#21153;&#26159;&#19968;&#31181;&#20113;&#35745;&#31639;&#33539;&#20363;&#65292;&#20026;&#24212;&#29992;&#31243;&#24207;&#25552;&#20379;&#20102;&#20107;&#20214;&#39537;&#21160;&#25191;&#34892;&#27169;&#22411;&#12290;&#23427;&#36890;&#36807;&#20174;&#24320;&#21457;&#32773;&#37027;&#37324;&#28040;&#38500;&#36164;&#28304;&#31649;&#29702;&#36131;&#20219;&#65292;&#25552;&#20379;&#36879;&#26126;&#21644;&#25353;&#38656;&#21487;&#25193;&#23637;&#24615;&#26469;&#23454;&#29616;&#26080;&#26381;&#21153;&#22120;&#29305;&#24615;&#12290;&#20856;&#22411;&#30340;&#26080;&#26381;&#21153;&#22120;&#24212;&#29992;&#31243;&#24207;&#23545;&#21709;&#24212;&#26102;&#38388;&#21644;&#21487;&#25193;&#23637;&#24615;&#26377;&#20005;&#26684;&#35201;&#27714;&#65292;&#22240;&#27492;&#20381;&#36182;&#20110;&#37096;&#32626;&#30340;&#26381;&#21153;&#20026;&#23458;&#25143;&#25552;&#20379;&#24555;&#36895;&#21644;&#23481;&#38169;&#30340;&#21453;&#39304;&#12290;&#28982;&#32780;&#65292;&#20989;&#25968;&#21363;&#26381;&#21153;&#33539;&#20363;&#22312;&#38656;&#35201;&#25353;&#38656;&#21021;&#22987;&#21270;&#20989;&#25968;&#26102;&#23384;&#22312;&#38750;&#24120;&#21487;&#35266;&#30340;&#24310;&#36831;&#65292;&#21363;&#20919;&#21551;&#21160;&#38382;&#39064;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#36890;&#36807;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#26469;&#20943;&#23569;&#24179;&#21488;&#19978;&#30340;&#20919;&#21551;&#21160;&#39057;&#29575;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#29992;Q&#23398;&#20064;&#65292;&#24182;&#32771;&#34385;&#20989;&#25968;&#30340;CPU&#21033;&#29992;&#29575;&#12289;&#24050;&#26377;&#20989;&#25968;&#23454;&#20363;&#21644;&#21709;&#24212;&#22833;&#36133;&#29575;&#31561;&#25351;&#26631;&#65292;&#26681;&#25454;&#39044;&#26399;&#38656;&#27714;&#25552;&#21069;&#20027;&#21160;&#21021;&#22987;&#21270;&#20989;&#25968;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#35299;&#20915;&#26041;&#26696;&#22312;Kubeless&#19978;&#23454;&#29616;&#24182;&#36827;&#34892;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Function-as-a-Service is a cloud computing paradigm offering an event-driven execution model to applications. It features serverless attributes by eliminating resource management responsibilities from developers and offers transparent and on-demand scalability of applications. Typical serverless applications have stringent response time and scalability requirements and therefore rely on deployed services to provide quick and fault-tolerant feedback to clients. However, the FaaS paradigm suffers from cold starts as there is a non-negligible delay associated with on-demand function initialization. This work focuses on reducing the frequency of cold starts on the platform by using Reinforcement Learning. Our approach uses Q-learning and considers metrics such as function CPU utilization, existing function instances, and response failure rate to proactively initialize functions in advance based on the expected demand. The proposed solution was implemented on Kubeless and was evaluated usin
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#23545;&#34920;&#26684;&#25968;&#25454;&#38598;&#20013;&#30340;&#33258;&#28982;&#20559;&#31227;&#36827;&#34892;&#30740;&#31350;&#65292;&#21457;&#29616;$Y|X$-&#20559;&#31227;&#26368;&#20026;&#26222;&#36941;&#12290;&#20026;&#20102;&#25512;&#21160;&#30740;&#31350;&#20154;&#21592;&#24320;&#21457;&#25551;&#36848;&#25968;&#25454;&#20998;&#24067;&#20559;&#31227;&#30340;&#31934;&#32454;&#35821;&#35328;&#65292;&#20316;&#32773;&#26500;&#24314;&#20102;WhyShift&#23454;&#39564;&#24179;&#21488;&#65292;&#24182;&#35752;&#35770;&#20102;$Y|X$-&#20559;&#31227;&#23545;&#31639;&#27861;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2307.05284</link><description>&lt;p&gt;
&#20851;&#20110;&#38656;&#35201;&#25551;&#36848;&#20998;&#24067;&#20559;&#31227;&#30340;&#35821;&#35328;&#65306;&#22522;&#20110;&#34920;&#26684;&#25968;&#25454;&#38598;&#30340;&#26696;&#20363;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
On the Need for a Language Describing Distribution Shifts: Illustrations on Tabular Datasets. (arXiv:2307.05284v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05284
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#23545;&#34920;&#26684;&#25968;&#25454;&#38598;&#20013;&#30340;&#33258;&#28982;&#20559;&#31227;&#36827;&#34892;&#30740;&#31350;&#65292;&#21457;&#29616;$Y|X$-&#20559;&#31227;&#26368;&#20026;&#26222;&#36941;&#12290;&#20026;&#20102;&#25512;&#21160;&#30740;&#31350;&#20154;&#21592;&#24320;&#21457;&#25551;&#36848;&#25968;&#25454;&#20998;&#24067;&#20559;&#31227;&#30340;&#31934;&#32454;&#35821;&#35328;&#65292;&#20316;&#32773;&#26500;&#24314;&#20102;WhyShift&#23454;&#39564;&#24179;&#21488;&#65292;&#24182;&#35752;&#35770;&#20102;$Y|X$-&#20559;&#31227;&#23545;&#31639;&#27861;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#21516;&#30340;&#20998;&#24067;&#20559;&#31227;&#38656;&#35201;&#19981;&#21516;&#30340;&#31639;&#27861;&#21644;&#25805;&#20316;&#24178;&#39044;&#12290;&#26041;&#27861;&#30740;&#31350;&#24517;&#39035;&#20197;&#20854;&#25152;&#28041;&#21450;&#30340;&#20855;&#20307;&#20559;&#31227;&#20026;&#22522;&#30784;&#12290;&#23613;&#31649;&#26032;&#20852;&#30340;&#22522;&#20934;&#25968;&#25454;&#20026;&#23454;&#35777;&#30740;&#31350;&#25552;&#20379;&#20102;&#26377;&#24076;&#26395;&#30340;&#22522;&#30784;&#65292;&#20294;&#23427;&#20204;&#38544;&#21547;&#22320;&#20851;&#27880;&#21327;&#21464;&#37327;&#20559;&#31227;&#65292;&#24182;&#19988;&#23454;&#35777;&#21457;&#29616;&#30340;&#26377;&#25928;&#24615;&#21462;&#20915;&#20110;&#20559;&#31227;&#31867;&#22411;&#65292;&#20363;&#22914;&#65292;&#24403;$Y|X$&#20998;&#24067;&#21457;&#29983;&#21464;&#21270;&#26102;&#65292;&#20043;&#21069;&#20851;&#20110;&#31639;&#27861;&#24615;&#33021;&#30340;&#35266;&#23519;&#21487;&#33021;&#26080;&#25928;&#12290;&#25105;&#20204;&#23545;5&#20010;&#34920;&#26684;&#25968;&#25454;&#38598;&#20013;&#30340;&#33258;&#28982;&#20559;&#31227;&#36827;&#34892;&#20102;&#28145;&#20837;&#30740;&#31350;&#65292;&#36890;&#36807;&#23545;86,000&#20010;&#27169;&#22411;&#37197;&#32622;&#36827;&#34892;&#23454;&#39564;&#65292;&#21457;&#29616;$Y|X$-&#20559;&#31227;&#26368;&#20026;&#26222;&#36941;&#12290;&#20026;&#20102;&#40723;&#21169;&#30740;&#31350;&#20154;&#21592;&#24320;&#21457;&#19968;&#31181;&#31934;&#32454;&#30340;&#25551;&#36848;&#25968;&#25454;&#20998;&#24067;&#20559;&#31227;&#30340;&#35821;&#35328;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;WhyShift&#65292;&#19968;&#20010;&#30001;&#31574;&#21010;&#30340;&#30495;&#23454;&#19990;&#30028;&#20559;&#31227;&#27979;&#35797;&#24179;&#21488;&#65292;&#22312;&#20854;&#20013;&#25105;&#20204;&#23545;&#25105;&#20204;&#22522;&#20934;&#24615;&#33021;&#30340;&#20559;&#31227;&#31867;&#22411;&#36827;&#34892;&#20102;&#34920;&#24449;&#12290;&#30001;&#20110;$Y|X$-&#20559;&#31227;&#22312;&#34920;&#26684;&#35774;&#32622;&#20013;&#24456;&#24120;&#35265;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#21463;&#21040;&#26368;&#22823;$Y|X$-&#20559;&#31227;&#24433;&#21709;&#30340;&#21327;&#21464;&#37327;&#21306;&#22495;&#65292;&#24182;&#35752;&#35770;&#20102;&#23545;&#31639;&#27861;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Different distribution shifts require different algorithmic and operational interventions. Methodological research must be grounded by the specific shifts they address. Although nascent benchmarks provide a promising empirical foundation, they implicitly focus on covariate shifts, and the validity of empirical findings depends on the type of shift, e.g., previous observations on algorithmic performance can fail to be valid when the $Y|X$ distribution changes. We conduct a thorough investigation of natural shifts in 5 tabular datasets over 86,000 model configurations, and find that $Y|X$-shifts are most prevalent. To encourage researchers to develop a refined language for distribution shifts, we build WhyShift, an empirical testbed of curated real-world shifts where we characterize the type of shift we benchmark performance over. Since $Y|X$-shifts are prevalent in tabular settings, we identify covariate regions that suffer the biggest $Y|X$-shifts and discuss implications for algorithm
&lt;/p&gt;</description></item><item><title>V-LoL&#26159;&#19968;&#20010;&#32467;&#21512;&#35270;&#35273;&#21644;&#36923;&#36753;&#25361;&#25112;&#30340;&#35786;&#26029;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#25324;&#20102;V-LoL-Trains&#65292;&#35813;&#25968;&#25454;&#38598;&#39318;&#27425;&#23558;&#22797;&#26434;&#30340;&#35270;&#35273;&#22330;&#26223;&#21644;&#28789;&#27963;&#30340;&#36923;&#36753;&#25512;&#29702;&#20219;&#21153;&#32467;&#21512;&#36215;&#26469;&#65292;&#20026;&#30740;&#31350;&#24191;&#27867;&#30340;&#35270;&#35273;&#36923;&#36753;&#23398;&#20064;&#25361;&#25112;&#25552;&#20379;&#20102;&#24179;&#21488;&#12290;</title><link>http://arxiv.org/abs/2306.07743</link><description>&lt;p&gt;
V-LoL: &#19968;&#31181;&#29992;&#20110;&#35270;&#35273;&#36923;&#36753;&#23398;&#20064;&#30340;&#35786;&#26029;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
V-LoL: A Diagnostic Dataset for Visual Logical Learning. (arXiv:2306.07743v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07743
&lt;/p&gt;
&lt;p&gt;
V-LoL&#26159;&#19968;&#20010;&#32467;&#21512;&#35270;&#35273;&#21644;&#36923;&#36753;&#25361;&#25112;&#30340;&#35786;&#26029;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#25324;&#20102;V-LoL-Trains&#65292;&#35813;&#25968;&#25454;&#38598;&#39318;&#27425;&#23558;&#22797;&#26434;&#30340;&#35270;&#35273;&#22330;&#26223;&#21644;&#28789;&#27963;&#30340;&#36923;&#36753;&#25512;&#29702;&#20219;&#21153;&#32467;&#21512;&#36215;&#26469;&#65292;&#20026;&#30740;&#31350;&#24191;&#27867;&#30340;&#35270;&#35273;&#36923;&#36753;&#23398;&#20064;&#25361;&#25112;&#25552;&#20379;&#20102;&#24179;&#21488;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#36817;&#26399;&#22312;&#35270;&#35273;AI&#39046;&#22495;&#26377;&#20102;&#35768;&#22810;&#25104;&#21151;&#30340;&#36827;&#23637;&#65292;&#20294;&#20173;&#23384;&#22312;&#19981;&#21516;&#30340;&#32570;&#28857;&#65307;&#21253;&#25324;&#32570;&#23569;&#31934;&#30830;&#30340;&#36923;&#36753;&#25512;&#29702;&#12289;&#25277;&#35937;&#30340;&#27010;&#25324;&#33021;&#21147;&#20197;&#21450;&#29702;&#35299;&#22797;&#26434;&#21644;&#22024;&#26434;&#30340;&#22330;&#26223;&#31561;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#29616;&#26377;&#30340;&#22522;&#20934;&#27979;&#35797;&#25968;&#25454;&#38598;&#24182;&#19981;&#33021;&#25429;&#25417;&#21040;&#36825;&#20123;&#26041;&#38754;&#20013;&#30340;&#22810;&#25968;&#12290;&#28145;&#24230;&#23398;&#20064;&#25968;&#25454;&#38598;&#20851;&#27880;&#35270;&#35273;&#22797;&#26434;&#25968;&#25454;&#20294;&#21482;&#26377;&#31616;&#21333;&#30340;&#35270;&#35273;&#25512;&#29702;&#20219;&#21153;&#65292;&#24402;&#32435;&#36923;&#36753;&#25968;&#25454;&#38598;&#21253;&#25324;&#22797;&#26434;&#30340;&#36923;&#36753;&#23398;&#20064;&#20219;&#21153;&#65292;&#20294;&#26159;&#32570;&#20047;&#35270;&#35273;&#30340;&#32452;&#25104;&#37096;&#20998;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#35270;&#35273;&#36923;&#36753;&#23398;&#20064;&#25968;&#25454;&#38598;V-LoL&#65292;&#23427;&#26080;&#32541;&#22320;&#32467;&#21512;&#20102;&#35270;&#35273;&#21644;&#36923;&#36753;&#30340;&#25361;&#25112;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#39318;&#27425;&#25512;&#20986;&#20102;V-LoL&#30340;&#31532;&#19968;&#20010;&#23454;&#20363;&#65292;&#21517;&#20026;V-LoL-Trains&#65292;&#23427;&#26159;&#31526;&#21495;AI&#20013;&#19968;&#20010;&#32463;&#20856;&#22522;&#20934;&#27979;&#35797;&#30340;&#35270;&#35273;&#21576;&#29616;&#65292;&#21363;Michalski&#28779;&#36710;&#38382;&#39064;&#12290;&#36890;&#36807;&#22312;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#20869;&#32467;&#21512;&#22797;&#26434;&#30340;&#35270;&#35273;&#22330;&#26223;&#21644;&#28789;&#27963;&#30340;&#36923;&#36753;&#25512;&#29702;&#20219;&#21153;&#65292;V-LoL-Trains&#20026;&#30740;&#31350;&#24191;&#27867;&#30340;&#35270;&#35273;&#36923;&#36753;&#23398;&#20064;&#25361;&#25112;&#25552;&#20379;&#20102;&#24179;&#21488;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the successes of recent developments in visual AI, different shortcomings still exist; from missing exact logical reasoning, to abstract generalization abilities, to understanding complex and noisy scenes. Unfortunately, existing benchmarks, were not designed to capture more than a few of these aspects. Whereas deep learning datasets focus on visually complex data but simple visual reasoning tasks, inductive logic datasets involve complex logical learning tasks, however, lack the visual component. To address this, we propose the visual logical learning dataset, V-LoL, that seamlessly combines visual and logical challenges. Notably, we introduce the first instantiation of V-LoL, V-LoL-Trains, -- a visual rendition of a classic benchmark in symbolic AI, the Michalski train problem. By incorporating intricate visual scenes and flexible logical reasoning tasks within a versatile framework, V-LoL-Trains provides a platform for investigating a wide range of visual logical learning ch
&lt;/p&gt;</description></item><item><title>&#20013;&#22269;&#21644;&#32654;&#22269;&#22312;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#21512;&#20316;&#33021;&#20135;&#29983;&#26356;&#22823;&#24433;&#21709;&#21147;&#65292;&#26368;&#36817;&#25968;&#25454;&#26174;&#31034;&#20004;&#22269;&#33258;2000&#24180;&#26469;&#19968;&#30452;&#22788;&#20110;&#39046;&#23548;&#22320;&#20301;&#65292;&#32780;&#22823;&#22810;&#25968;&#20154;&#25165;&#27969;&#22833;&#22312;&#20004;&#22269;&#20043;&#38388;&#12290;</title><link>http://arxiv.org/abs/2304.11123</link><description>&lt;p&gt;
&#20013;&#32654;&#21512;&#20316;&#26102;&#65292;&#20013;&#22269;&#21644;&#32654;&#22269;&#22312;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#33021;&#22815;&#20135;&#29983;&#26356;&#22823;&#30340;&#24433;&#21709;&#21147;
&lt;/p&gt;
&lt;p&gt;
China and the U.S. produce more impactful AI research when collaborating together. (arXiv:2304.11123v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11123
&lt;/p&gt;
&lt;p&gt;
&#20013;&#22269;&#21644;&#32654;&#22269;&#22312;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#21512;&#20316;&#33021;&#20135;&#29983;&#26356;&#22823;&#24433;&#21709;&#21147;&#65292;&#26368;&#36817;&#25968;&#25454;&#26174;&#31034;&#20004;&#22269;&#33258;2000&#24180;&#26469;&#19968;&#30452;&#22788;&#20110;&#39046;&#23548;&#22320;&#20301;&#65292;&#32780;&#22823;&#22810;&#25968;&#20154;&#25165;&#27969;&#22833;&#22312;&#20004;&#22269;&#20043;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#24050;&#32463;&#25104;&#20026;&#39072;&#35206;&#24615;&#25216;&#26415;&#65292;&#26377;&#26395;&#20026;&#25484;&#25569;&#20854;&#21147;&#37327;&#30340;&#22269;&#23478;&#24102;&#26469;&#26174;&#33879;&#30340;&#32463;&#27982;&#21644;&#25112;&#30053;&#20248;&#21183;&#12290;&#26368;&#36817;&#65292;&#20013;&#22269;&#25512;&#21160;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#30340;&#37319;&#29992;&#65292;&#27491;&#22312;&#25361;&#25112;&#32654;&#22269;&#22312;&#36825;&#19968;&#39046;&#22495;&#30340;&#20840;&#29699;&#39046;&#23548;&#22320;&#20301;&#12290;&#32771;&#34385;&#21040;&#20154;&#24037;&#26234;&#33021;&#30340;&#24040;&#22823;&#28508;&#21147;&#65292;&#20197;&#21450;&#20004;&#22269;&#20043;&#38388;&#28608;&#28872;&#30340;&#22320;&#32536;&#25919;&#27835;&#32039;&#24352;&#23616;&#21183;&#65292;&#24050;&#32463;&#21046;&#23450;&#20102;&#19968;&#20123;&#25919;&#31574;&#65292;&#20197;&#38450;&#27490;&#20154;&#24037;&#26234;&#33021;&#31185;&#23398;&#23478;&#31227;&#27665;&#21040;&#23545;&#26041;&#22269;&#23478;&#25110;&#19982;&#20043;&#21512;&#20316;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#20154;&#25165;&#27969;&#22833;&#21644;&#36328;&#22659;&#21512;&#20316;&#30340;&#31243;&#24230;&#36824;&#27809;&#26377;&#34987;&#23436;&#20840;&#20102;&#35299;&#12290;&#22312;&#27492;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#36229;&#36807;350,000&#21517;&#20154;&#24037;&#26234;&#33021;&#31185;&#23398;&#23478;&#21644;5,000,000&#31687;&#20154;&#24037;&#26234;&#33021;&#25991;&#29486;&#30340;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#21457;&#29616;&#33258;2000&#24180;&#20197;&#26469;&#65292;&#20013;&#22269;&#21644;&#32654;&#22269;&#22312;&#24433;&#21709;&#21147;&#12289;&#21019;&#26032;&#24615;&#12289;&#29983;&#20135;&#21147;&#21644;&#21171;&#21160;&#21147;&#26041;&#38754;&#19968;&#30452;&#22788;&#20110;&#39046;&#20808;&#22320;&#20301;&#12290;&#22823;&#22810;&#25968;&#31227;&#27665;&#21040;&#20013;&#22269;&#30340;&#20154;&#24037;&#26234;&#33021;&#31185;&#23398;&#23478;&#26469;&#33258;&#32654;&#22269;&#65292;&#32780;&#31227;&#27665;&#21040;&#32654;&#22269;&#30340;&#20154;&#24037;&#26234;&#33021;&#31185;&#23398;&#23478;&#26469;&#33258;&#20013;&#22269;&#65292;&#20984;&#26174;&#20986;&#26126;&#26174;&#30340;&#20154;&#25165;&#27969;&#22833;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;
Artificial Intelligence (AI) has become a disruptive technology, promising to grant a significant economic and strategic advantage to the nations that harness its power. China, with its recent push towards AI adoption, is challenging the U.S.'s position as the global leader in this field. Given AI's massive potential, as well as the fierce geopolitical tensions between the two nations, a number of policies have been put in place that discourage AI scientists from migrating to, or collaborating with, the other country. However, the extents of such brain drain and cross-border collaboration are not fully understood. Here, we analyze a dataset of over 350,000 AI scientists and 5,000,000 AI papers. We find that, since the year 2000, China and the U.S. have been leading the field in terms of impact, novelty, productivity, and workforce. Most AI scientists who migrate to China come from the U.S., and most who migrate to the U.S. come from China, highlighting a notable brain drain in both dir
&lt;/p&gt;</description></item></channel></rss>