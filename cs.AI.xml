<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20855;&#26377;&#21331;&#36234;&#30340;&#33021;&#21147;&#65292;&#20294;&#20063;&#38754;&#20020;&#30528;&#23433;&#20840;&#21644;&#38544;&#31169;&#25915;&#20987;&#30340;&#23041;&#32961;&#12290;&#26412;&#35843;&#26597;&#20840;&#38754;&#23457;&#26597;&#20102;LLM&#30340;&#23433;&#20840;&#21644;&#38544;&#31169;&#25361;&#25112;&#65292;&#28085;&#30422;&#20102;&#35757;&#32451;&#25968;&#25454;&#12289;&#29992;&#25143;&#21644;&#24212;&#29992;&#39118;&#38505;&#31561;&#26041;&#38754;&#65292;&#24182;&#23545;&#35299;&#20915;&#26041;&#27861;&#36827;&#34892;&#20102;&#22238;&#39038;&#12290;</title><link>https://rss.arxiv.org/abs/2402.00888</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23433;&#20840;&#21644;&#38544;&#31169;&#25361;&#25112;&#65306;&#19968;&#39033;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Security and Privacy Challenges of Large Language Models: A Survey
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.00888
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20855;&#26377;&#21331;&#36234;&#30340;&#33021;&#21147;&#65292;&#20294;&#20063;&#38754;&#20020;&#30528;&#23433;&#20840;&#21644;&#38544;&#31169;&#25915;&#20987;&#30340;&#23041;&#32961;&#12290;&#26412;&#35843;&#26597;&#20840;&#38754;&#23457;&#26597;&#20102;LLM&#30340;&#23433;&#20840;&#21644;&#38544;&#31169;&#25361;&#25112;&#65292;&#28085;&#30422;&#20102;&#35757;&#32451;&#25968;&#25454;&#12289;&#29992;&#25143;&#21644;&#24212;&#29992;&#39118;&#38505;&#31561;&#26041;&#38754;&#65292;&#24182;&#23545;&#35299;&#20915;&#26041;&#27861;&#36827;&#34892;&#20102;&#22238;&#39038;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#23637;&#31034;&#20102;&#38750;&#20961;&#30340;&#33021;&#21147;&#65292;&#24182;&#22312;&#29983;&#25104;&#21644;&#24635;&#32467;&#25991;&#26412;&#12289;&#35821;&#35328;&#32763;&#35793;&#21644;&#38382;&#31572;&#31561;&#22810;&#20010;&#39046;&#22495;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;&#22914;&#20170;&#65292;LLM&#27491;&#22312;&#25104;&#20026;&#35745;&#31639;&#26426;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#20013;&#38750;&#24120;&#27969;&#34892;&#30340;&#24037;&#20855;&#65292;&#20855;&#22791;&#20998;&#26512;&#22797;&#26434;&#35821;&#35328;&#27169;&#24335;&#24182;&#26681;&#25454;&#19978;&#19979;&#25991;&#25552;&#20379;&#30456;&#20851;&#21644;&#36866;&#24403;&#22238;&#31572;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#20855;&#26377;&#26174;&#33879;&#20248;&#21183;&#65292;&#36825;&#20123;&#27169;&#22411;&#20063;&#23481;&#26131;&#21463;&#21040;&#23433;&#20840;&#21644;&#38544;&#31169;&#25915;&#20987;&#30340;&#23041;&#32961;&#65292;&#22914;&#36234;&#29425;&#25915;&#20987;&#12289;&#25968;&#25454;&#27745;&#26579;&#25915;&#20987;&#21644;&#20010;&#20154;&#21487;&#35782;&#21035;&#20449;&#24687;&#27844;&#38706;&#25915;&#20987;&#12290;&#26412;&#35843;&#26597;&#20840;&#38754;&#23457;&#26597;&#20102;LLM&#30340;&#23433;&#20840;&#21644;&#38544;&#31169;&#25361;&#25112;&#65292;&#21253;&#25324;&#35757;&#32451;&#25968;&#25454;&#21644;&#29992;&#25143;&#26041;&#38754;&#30340;&#38382;&#39064;&#65292;&#20197;&#21450;&#22312;&#20132;&#36890;&#12289;&#25945;&#32946;&#21644;&#21307;&#30103;&#31561;&#21508;&#20010;&#39046;&#22495;&#20013;&#24212;&#29992;&#24102;&#26469;&#30340;&#39118;&#38505;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;LLM&#30340;&#33030;&#24369;&#24615;&#31243;&#24230;&#65292;&#35843;&#26597;&#20102;&#20986;&#29616;&#30340;&#23433;&#20840;&#21644;&#38544;&#31169;&#25915;&#20987;&#65292;&#24182;&#23545;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#27861;&#36827;&#34892;&#20102;&#22238;&#39038;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have demonstrated extraordinary capabilities and contributed to multiple fields, such as generating and summarizing text, language translation, and question-answering. Nowadays, LLM is becoming a very popular tool in computerized language processing tasks, with the capability to analyze complicated linguistic patterns and provide relevant and appropriate responses depending on the context. While offering significant advantages, these models are also vulnerable to security and privacy attacks, such as jailbreaking attacks, data poisoning attacks, and Personally Identifiable Information (PII) leakage attacks. This survey provides a thorough review of the security and privacy challenges of LLMs for both training data and users, along with the application-based risks in various domains, such as transportation, education, and healthcare. We assess the extent of LLM vulnerabilities, investigate emerging security and privacy attacks for LLMs, and review the potent
&lt;/p&gt;</description></item><item><title>SHIELD&#24341;&#20837;&#20102;&#19968;&#31181;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#36890;&#36807;&#38544;&#34255;&#37096;&#20998;&#36755;&#20837;&#25968;&#25454;&#24182;&#35780;&#20272;&#39044;&#27979;&#32467;&#26524;&#30340;&#24046;&#24322;&#65292;&#20174;&#32780;&#25913;&#21892;&#20102;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#30340;&#36136;&#37327;&#12290;</title><link>https://arxiv.org/abs/2404.02611</link><description>&lt;p&gt;
SHIELD: &#19968;&#31181;&#29992;&#20110;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
SHIELD: A regularization technique for eXplainable Artificial Intelligence
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02611
&lt;/p&gt;
&lt;p&gt;
SHIELD&#24341;&#20837;&#20102;&#19968;&#31181;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#36890;&#36807;&#38544;&#34255;&#37096;&#20998;&#36755;&#20837;&#25968;&#25454;&#24182;&#35780;&#20272;&#39044;&#27979;&#32467;&#26524;&#30340;&#24046;&#24322;&#65292;&#20174;&#32780;&#25913;&#21892;&#20102;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#22312;&#21508;&#20010;&#39046;&#22495;&#21464;&#24471;&#19981;&#21487;&#25110;&#32570;&#65292;&#23545;&#21487;&#35299;&#37322;&#24615;&#30340;&#38656;&#27714;&#19982;&#26085;&#20465;&#22686;&#12290;&#23613;&#31649;&#31185;&#23398;&#30028;&#30340;&#21162;&#21147;&#20027;&#35201;&#38598;&#20013;&#22312;&#20026;&#27169;&#22411;&#33719;&#21462;&#26356;&#22909;&#30340;&#35299;&#37322;&#19978;&#65292;&#20294;&#37325;&#35201;&#30340;&#26159;&#19981;&#35201;&#24573;&#35270;&#36825;&#20010;&#35299;&#37322;&#36807;&#31243;&#23545;&#25913;&#21892;&#35757;&#32451;&#30340;&#28508;&#21147;&#12290;&#34429;&#28982;&#29616;&#26377;&#30340;&#21162;&#21147;&#20027;&#35201;&#38598;&#20013;&#22312;&#20026;&#40657;&#30418;&#27169;&#22411;&#29983;&#25104;&#21644;&#35780;&#20272;&#35299;&#37322;&#19978;&#65292;&#20294;&#30452;&#25509;&#36890;&#36807;&#36825;&#20123;&#35780;&#20272;&#26469;&#22686;&#24378;&#27169;&#22411;&#20173;&#23384;&#22312;&#20851;&#38190;&#24046;&#36317;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;SHIELD&#65288;&#36873;&#25321;&#24615;&#38544;&#34255;&#36755;&#20837;&#35780;&#20272;&#23398;&#20064;&#21160;&#24577;&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#36866;&#29992;&#20110;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#26088;&#22312;&#36890;&#36807;&#38544;&#34255;&#37096;&#20998;&#36755;&#20837;&#25968;&#25454;&#24182;&#35780;&#20272;&#39044;&#27979;&#32467;&#26524;&#30340;&#24046;&#24322;&#26469;&#25913;&#21892;&#27169;&#22411;&#36136;&#37327;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#27604;&#65292;SHIELD&#27491;&#21017;&#21270;&#26080;&#32541;&#38598;&#25104;&#21040;&#30446;&#26631;&#20989;&#25968;&#20013;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#21516;&#26102;&#20063;&#25913;&#21892;&#20102;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02611v1 Announce Type: new  Abstract: As Artificial Intelligence systems become integral across domains, the demand for explainability grows. While the effort by the scientific community is focused on obtaining a better explanation for the model, it is important not to ignore the potential of this explanation process to improve training as well. While existing efforts primarily focus on generating and evaluating explanations for black-box models, there remains a critical gap in directly enhancing models through these evaluations. This paper introduces SHIELD (Selective Hidden Input Evaluation for Learning Dynamics), a regularization technique for explainable artificial intelligence designed to improve model quality by concealing portions of input data and assessing the resulting discrepancy in predictions. In contrast to conventional approaches, SHIELD regularization seamlessly integrates into the objective function, enhancing model explainability while also improving perfor
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#20248;&#21270;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#26041;&#27861;&#65292;JudgeDeceiver&#65292;&#38024;&#23545;LLM-as-a-Judge&#65292;&#36890;&#36807;&#33258;&#21160;&#21270;&#29983;&#25104;&#23545;&#25239;&#24207;&#21015;&#23454;&#29616;&#20102;&#26377;&#38024;&#23545;&#24615;&#21644;&#39640;&#25928;&#30340;&#27169;&#22411;&#35780;&#20272;&#25805;&#25511;&#12290;</title><link>https://arxiv.org/abs/2403.17710</link><description>&lt;p&gt;
&#22522;&#20110;&#20248;&#21270;&#30340;&#23545;LLM&#35780;&#21028;&#31995;&#32479;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Optimization-based Prompt Injection Attack to LLM-as-a-Judge
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17710
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#20248;&#21270;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#26041;&#27861;&#65292;JudgeDeceiver&#65292;&#38024;&#23545;LLM-as-a-Judge&#65292;&#36890;&#36807;&#33258;&#21160;&#21270;&#29983;&#25104;&#23545;&#25239;&#24207;&#21015;&#23454;&#29616;&#20102;&#26377;&#38024;&#23545;&#24615;&#21644;&#39640;&#25928;&#30340;&#27169;&#22411;&#35780;&#20272;&#25805;&#25511;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
LLM-as-a-Judge &#26159;&#19968;&#31181;&#21487;&#20197;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#35780;&#20272;&#25991;&#26412;&#20449;&#24687;&#30340;&#26032;&#39062;&#35299;&#20915;&#26041;&#26696;&#12290;&#26681;&#25454;&#29616;&#26377;&#30740;&#31350;&#65292;LLMs&#22312;&#25552;&#20379;&#20256;&#32479;&#20154;&#31867;&#35780;&#20272;&#30340;&#24341;&#20154;&#27880;&#30446;&#26367;&#20195;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#31995;&#32479;&#38024;&#23545;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#20173;&#28982;&#26159;&#19968;&#20010;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;JudgeDeceiver&#65292;&#19968;&#31181;&#38024;&#23545;LLM-as-a-Judge&#37327;&#36523;&#23450;&#21046;&#30340;&#22522;&#20110;&#20248;&#21270;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21046;&#23450;&#20102;&#19968;&#20010;&#31934;&#30830;&#30340;&#20248;&#21270;&#30446;&#26631;&#65292;&#29992;&#20110;&#25915;&#20987;LLM-as-a-Judge&#30340;&#20915;&#31574;&#36807;&#31243;&#65292;&#24182;&#21033;&#29992;&#20248;&#21270;&#31639;&#27861;&#39640;&#25928;&#22320;&#33258;&#21160;&#21270;&#29983;&#25104;&#23545;&#25239;&#24207;&#21015;&#65292;&#23454;&#29616;&#23545;&#27169;&#22411;&#35780;&#20272;&#30340;&#26377;&#38024;&#23545;&#24615;&#21644;&#26377;&#25928;&#30340;&#25805;&#20316;&#12290;&#19982;&#25163;&#24037;&#21046;&#20316;&#30340;&#25552;&#31034;&#27880;&#20837;&#25915;&#20987;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#21151;&#25928;&#65292;&#32473;&#22522;&#20110;LLM&#30340;&#21028;&#26029;&#31995;&#32479;&#24403;&#21069;&#30340;&#23433;&#20840;&#33539;&#24335;&#24102;&#26469;&#20102;&#37325;&#22823;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17710v1 Announce Type: cross  Abstract: LLM-as-a-Judge is a novel solution that can assess textual information with large language models (LLMs). Based on existing research studies, LLMs demonstrate remarkable performance in providing a compelling alternative to traditional human assessment. However, the robustness of these systems against prompt injection attacks remains an open question. In this work, we introduce JudgeDeceiver, a novel optimization-based prompt injection attack tailored to LLM-as-a-Judge. Our method formulates a precise optimization objective for attacking the decision-making process of LLM-as-a-Judge and utilizes an optimization algorithm to efficiently automate the generation of adversarial sequences, achieving targeted and effective manipulation of model evaluations. Compared to handcraft prompt injection attacks, our method demonstrates superior efficacy, posing a significant challenge to the current security paradigms of LLM-based judgment systems. T
&lt;/p&gt;</description></item><item><title>ThermoHands&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;ThermoHands&#65292;&#26088;&#22312;&#35299;&#20915;&#28909;&#22270;&#20013;&#20027;&#35266;&#35270;&#35282;3D&#25163;&#37096;&#23039;&#21183;&#20272;&#35745;&#30340;&#25361;&#25112;&#65292;&#20171;&#32461;&#20102;&#19968;&#20010;&#20855;&#26377;&#21452;transformer&#27169;&#22359;&#30340;&#23450;&#21046;&#22522;&#32447;&#26041;&#27861;TheFormer&#65292;&#34920;&#26126;&#28909;&#25104;&#20687;&#22312;&#24694;&#21155;&#26465;&#20214;&#19979;&#23454;&#29616;&#31283;&#20581;&#30340;3D&#25163;&#37096;&#23039;&#21183;&#20272;&#35745;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.09871</link><description>&lt;p&gt;
ThermoHands&#65306;&#19968;&#31181;&#29992;&#20110;&#20174;&#20027;&#35266;&#35270;&#35282;&#28909;&#22270;&#20013;&#20272;&#35745;3D&#25163;&#37096;&#23039;&#21183;&#30340;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
ThermoHands: A Benchmark for 3D Hand Pose Estimation from Egocentric Thermal Image
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09871
&lt;/p&gt;
&lt;p&gt;
ThermoHands&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;ThermoHands&#65292;&#26088;&#22312;&#35299;&#20915;&#28909;&#22270;&#20013;&#20027;&#35266;&#35270;&#35282;3D&#25163;&#37096;&#23039;&#21183;&#20272;&#35745;&#30340;&#25361;&#25112;&#65292;&#20171;&#32461;&#20102;&#19968;&#20010;&#20855;&#26377;&#21452;transformer&#27169;&#22359;&#30340;&#23450;&#21046;&#22522;&#32447;&#26041;&#27861;TheFormer&#65292;&#34920;&#26126;&#28909;&#25104;&#20687;&#22312;&#24694;&#21155;&#26465;&#20214;&#19979;&#23454;&#29616;&#31283;&#20581;&#30340;3D&#25163;&#37096;&#23039;&#21183;&#20272;&#35745;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;ThermoHands&#65292;&#36825;&#26159;&#19968;&#20010;&#38024;&#23545;&#22522;&#20110;&#28909;&#22270;&#30340;&#20027;&#35266;&#35270;&#35282;3D&#25163;&#37096;&#23039;&#21183;&#20272;&#35745;&#30340;&#26032;&#22522;&#20934;&#65292;&#26088;&#22312;&#20811;&#26381;&#35832;&#22914;&#20809;&#29031;&#21464;&#21270;&#21644;&#36974;&#25377;&#65288;&#20363;&#22914;&#25163;&#37096;&#31359;&#25140;&#29289;&#65289;&#31561;&#25361;&#25112;&#12290;&#35813;&#22522;&#20934;&#21253;&#25324;&#26469;&#33258;28&#21517;&#20027;&#20307;&#36827;&#34892;&#25163;-&#29289;&#20307;&#21644;&#25163;-&#34394;&#25311;&#20132;&#20114;&#30340;&#22810;&#26679;&#25968;&#25454;&#38598;&#65292;&#32463;&#36807;&#33258;&#21160;&#21270;&#36807;&#31243;&#20934;&#30830;&#26631;&#27880;&#20102;3D&#25163;&#37096;&#23039;&#21183;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#23450;&#21046;&#30340;&#22522;&#32447;&#26041;&#27861;TheFormer&#65292;&#21033;&#29992;&#21452;transformer&#27169;&#22359;&#22312;&#28909;&#22270;&#20013;&#23454;&#29616;&#26377;&#25928;&#30340;&#20027;&#35266;&#35270;&#35282;3D&#25163;&#37096;&#23039;&#21183;&#20272;&#35745;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#31361;&#26174;&#20102;TheFormer&#30340;&#39046;&#20808;&#24615;&#33021;&#65292;&#24182;&#30830;&#35748;&#20102;&#28909;&#25104;&#20687;&#22312;&#23454;&#29616;&#24694;&#21155;&#26465;&#20214;&#19979;&#31283;&#20581;&#30340;3D&#25163;&#37096;&#23039;&#21183;&#20272;&#35745;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09871v1 Announce Type: cross  Abstract: In this work, we present ThermoHands, a new benchmark for thermal image-based egocentric 3D hand pose estimation, aimed at overcoming challenges like varying lighting and obstructions (e.g., handwear). The benchmark includes a diverse dataset from 28 subjects performing hand-object and hand-virtual interactions, accurately annotated with 3D hand poses through an automated process. We introduce a bespoken baseline method, TheFormer, utilizing dual transformer modules for effective egocentric 3D hand pose estimation in thermal imagery. Our experimental results highlight TheFormer's leading performance and affirm thermal imaging's effectiveness in enabling robust 3D hand pose estimation in adverse conditions.
&lt;/p&gt;</description></item><item><title>CLCE&#26041;&#27861;&#32467;&#21512;&#20102;&#26631;&#31614;&#24863;&#30693;&#23545;&#27604;&#23398;&#20064;&#19982;&#20132;&#21449;&#29109;&#25439;&#22833;&#65292;&#36890;&#36807;&#21327;&#21516;&#21033;&#29992;&#38590;&#20363;&#25366;&#25496;&#25552;&#39640;&#20102;&#24615;&#33021;&#34920;&#29616;</title><link>https://arxiv.org/abs/2402.14551</link><description>&lt;p&gt;
CLCE&#65306;&#19968;&#31181;&#20248;&#21270;&#23398;&#20064;&#34701;&#21512;&#30340;&#25913;&#36827;&#20132;&#21449;&#29109;&#21644;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
CLCE: An Approach to Refining Cross-Entropy and Contrastive Learning for Optimized Learning Fusion
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14551
&lt;/p&gt;
&lt;p&gt;
CLCE&#26041;&#27861;&#32467;&#21512;&#20102;&#26631;&#31614;&#24863;&#30693;&#23545;&#27604;&#23398;&#20064;&#19982;&#20132;&#21449;&#29109;&#25439;&#22833;&#65292;&#36890;&#36807;&#21327;&#21516;&#21033;&#29992;&#38590;&#20363;&#25366;&#25496;&#25552;&#39640;&#20102;&#24615;&#33021;&#34920;&#29616;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#20808;&#36827;&#30340;&#39044;&#35757;&#32451;&#22270;&#20687;&#27169;&#22411;&#20027;&#35201;&#37319;&#29992;&#20004;&#38454;&#27573;&#26041;&#27861;&#65306;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#21021;&#22987;&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#65292;&#28982;&#21518;&#20351;&#29992;&#20132;&#21449;&#29109;&#25439;&#22833;&#65288;CE&#65289;&#36827;&#34892;&#29305;&#23450;&#20219;&#21153;&#30340;&#24494;&#35843;&#12290;&#28982;&#32780;&#65292;&#24050;&#32463;&#35777;&#26126;CE&#21487;&#33021;&#20250;&#25439;&#23475;&#27169;&#22411;&#30340;&#27867;&#21270;&#24615;&#21644;&#31283;&#23450;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;CLCE&#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#23558;&#26631;&#31614;&#24863;&#30693;&#23545;&#27604;&#23398;&#20064;&#19982;CE&#30456;&#32467;&#21512;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#20165;&#20445;&#25345;&#20102;&#20004;&#31181;&#25439;&#22833;&#20989;&#25968;&#30340;&#20248;&#21183;&#65292;&#32780;&#19988;&#20197;&#21327;&#21516;&#26041;&#24335;&#21033;&#29992;&#38590;&#20363;&#25366;&#25496;&#26469;&#22686;&#24378;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14551v1 Announce Type: cross  Abstract: State-of-the-art pre-trained image models predominantly adopt a two-stage approach: initial unsupervised pre-training on large-scale datasets followed by task-specific fine-tuning using Cross-Entropy loss~(CE). However, it has been demonstrated that CE can compromise model generalization and stability. While recent works employing contrastive learning address some of these limitations by enhancing the quality of embeddings and producing better decision boundaries, they often overlook the importance of hard negative mining and rely on resource intensive and slow training using large sample batches. To counter these issues, we introduce a novel approach named CLCE, which integrates Label-Aware Contrastive Learning with CE. Our approach not only maintains the strengths of both loss functions but also leverages hard negative mining in a synergistic way to enhance performance. Experimental results demonstrate that CLCE significantly outperf
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20351;&#29992;&#38899;&#32032;&#34920;&#31034;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#35299;&#20915;&#26041;&#26696;&#26469;&#20943;&#32531;&#39640;&#36164;&#28304;&#35821;&#35328;&#21644;&#20302;&#36164;&#28304;&#35821;&#35328;&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#36317;&#65292;&#24182;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#21644;&#29702;&#35770;&#20998;&#26512;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.14279</link><description>&lt;p&gt;
&#20351;&#29992;&#38899;&#32032;&#34920;&#31034;&#20943;&#32531;&#35821;&#35328;&#24046;&#24322;&#65292;&#23454;&#29616;&#31283;&#20581;&#30340;&#22810;&#35821;&#35328;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Mitigating the Linguistic Gap with Phonemic Representations for Robust Multilingual Language Understanding
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14279
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#38899;&#32032;&#34920;&#31034;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#35299;&#20915;&#26041;&#26696;&#26469;&#20943;&#32531;&#39640;&#36164;&#28304;&#35821;&#35328;&#21644;&#20302;&#36164;&#28304;&#35821;&#35328;&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#36317;&#65292;&#24182;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#21644;&#29702;&#35770;&#20998;&#26512;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#25913;&#21892;&#22810;&#35821;&#35328;&#29702;&#35299;&#65292;&#36890;&#24120;&#38656;&#35201;&#22312;&#35757;&#32451;&#38454;&#27573;&#20351;&#29992;&#22810;&#31181;&#35821;&#35328;&#65292;&#20381;&#36182;&#22797;&#26434;&#30340;&#35757;&#32451;&#25216;&#26415;&#65292;&#24182;&#19988;&#22312;&#39640;&#36164;&#28304;&#35821;&#35328;&#21644;&#20302;&#36164;&#28304;&#35821;&#35328;&#20043;&#38388;&#23384;&#22312;&#26174;&#33879;&#30340;&#24615;&#33021;&#24046;&#36317;&#12290;&#25105;&#20204;&#20551;&#35774;&#35821;&#35328;&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#36317;&#21463;&#21040;&#36825;&#20123;&#35821;&#35328;&#20043;&#38388;&#30340;&#35821;&#35328;&#24046;&#24322;&#30340;&#24433;&#21709;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#38899;&#32032;&#34920;&#31034;&#65288;&#20855;&#20307;&#26469;&#35828;&#65292;&#23558;&#38899;&#32032;&#20316;&#20026;&#36755;&#20837;&#26631;&#35760;&#36755;&#20837;&#21040;&#35821;&#35328;&#27169;&#22411;&#20013;&#65292;&#32780;&#19981;&#26159;&#23376;&#35789;&#65289;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20197;&#23454;&#29616;&#31283;&#20581;&#30340;&#22810;&#35821;&#35328;&#24314;&#27169;&#12290;&#25105;&#20204;&#36890;&#36807;&#19977;&#20010;&#36328;&#35821;&#35328;&#20219;&#21153;&#30340;&#23450;&#37327;&#35777;&#25454;&#23637;&#31034;&#20102;&#38899;&#32032;&#34920;&#31034;&#30340;&#26377;&#25928;&#24615;&#65292;&#36825;&#36827;&#19968;&#27493;&#24471;&#21040;&#20102;&#23545;&#36328;&#35821;&#35328;&#24615;&#33021;&#24046;&#36317;&#30340;&#29702;&#35770;&#20998;&#26512;&#30340;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14279v1 Announce Type: cross  Abstract: Approaches to improving multilingual language understanding often require multiple languages during the training phase, rely on complicated training techniques, and -- importantly -- struggle with significant performance gaps between high-resource and low-resource languages. We hypothesize that the performance gaps between languages are affected by linguistic gaps between those languages and provide a novel solution for robust multilingual language modeling by employing phonemic representations (specifically, using phonemes as input tokens to LMs rather than subwords). We present quantitative evidence from three cross-lingual tasks that demonstrate the effectiveness of phonemic representation, which is further justified by a theoretical analysis of the cross-lingual performance gap.
&lt;/p&gt;</description></item><item><title>ConSmax&#26159;&#19968;&#31181;&#30828;&#20214;&#21451;&#22909;&#22411;Softmax&#26367;&#20195;&#26041;&#26696;&#65292;&#36890;&#36807;&#24341;&#20837;&#21487;&#23398;&#20064;&#21442;&#25968;&#65292;&#22312;&#19981;&#24433;&#21709;&#24615;&#33021;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#23545;&#21407;Softmax&#20851;&#38190;&#20219;&#21153;&#30340;&#39640;&#25928;&#22788;&#29702;&#12290;</title><link>https://arxiv.org/abs/2402.10930</link><description>&lt;p&gt;
ConSmax: &#20855;&#26377;&#21487;&#23398;&#20064;&#21442;&#25968;&#30340;&#30828;&#20214;&#21451;&#22909;&#22411;Softmax&#26367;&#20195;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
ConSmax: Hardware-Friendly Alternative Softmax with Learnable Parameters
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10930
&lt;/p&gt;
&lt;p&gt;
ConSmax&#26159;&#19968;&#31181;&#30828;&#20214;&#21451;&#22909;&#22411;Softmax&#26367;&#20195;&#26041;&#26696;&#65292;&#36890;&#36807;&#24341;&#20837;&#21487;&#23398;&#20064;&#21442;&#25968;&#65292;&#22312;&#19981;&#24433;&#21709;&#24615;&#33021;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#23545;&#21407;Softmax&#20851;&#38190;&#20219;&#21153;&#30340;&#39640;&#25928;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#27880;&#24847;&#26426;&#21046;&#23558;&#22522;&#20110;transformer&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#19982;&#21367;&#31215;&#21644;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#21306;&#20998;&#24320;&#26469;&#12290;&#23613;&#31649;&#24615;&#33021;&#26377;&#25152;&#25552;&#21319;&#65292;&#20294;&#30001;&#20110;&#33258;&#27880;&#24847;&#20013;&#24191;&#27867;&#20351;&#29992;Softmax&#65292;&#22312;&#30789;&#19978;&#23454;&#29616;&#23454;&#26102;LLM&#25512;&#26029;&#20173;&#20855;&#25361;&#25112;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Constant Softmax&#65288;ConSmax&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#39640;&#25928;&#30340;Softmax&#26367;&#20195;&#26041;&#26696;&#65292;&#37319;&#29992;&#21487;&#24494;&#30340;&#35268;&#33539;&#21270;&#21442;&#25968;&#26469;&#28040;&#38500;Softmax&#20013;&#30340;&#26368;&#22823;&#25628;&#32034;&#21644;&#20998;&#27597;&#27714;&#21644;&#65292;&#23454;&#29616;&#20102;&#22823;&#35268;&#27169;&#24182;&#34892;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10930v1 Announce Type: cross  Abstract: The self-attention mechanism sets transformer-based large language model (LLM) apart from the convolutional and recurrent neural networks. Despite the performance improvement, achieving real-time LLM inference on silicon is challenging due to the extensively used Softmax in self-attention. Apart from the non-linearity, the low arithmetic intensity greatly reduces the processing parallelism, which becomes the bottleneck especially when dealing with a longer context. To address this challenge, we propose Constant Softmax (ConSmax), a software-hardware co-design as an efficient Softmax alternative. ConSmax employs differentiable normalization parameters to remove the maximum searching and denominator summation in Softmax. It allows for massive parallelization while performing the critical tasks of Softmax. In addition, a scalable ConSmax hardware utilizing a bitwidth-split look-up table (LUT) can produce lossless non-linear operation and 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#25511;&#21046;&#22312;&#24314;&#31569;&#33021;&#28304;&#31995;&#32479;&#20013;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#36890;&#36807;&#23558;Shapley&#20540;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30456;&#32467;&#21512;&#65292;&#25552;&#39640;&#20102;&#26426;&#22120;&#23398;&#20064;&#25511;&#21046;&#27169;&#22411;&#30340;&#36879;&#26126;&#24615;&#21644;&#29702;&#35299;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.09584</link><description>&lt;p&gt;
&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24314;&#31569;&#33021;&#28304;&#31995;&#32479;&#26426;&#22120;&#23398;&#20064;&#25511;&#21046;&#30340;&#21487;&#35299;&#37322;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Large Language Model-Based Interpretable Machine Learning Control in Building Energy Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09584
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#25511;&#21046;&#22312;&#24314;&#31569;&#33021;&#28304;&#31995;&#32479;&#20013;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#36890;&#36807;&#23558;Shapley&#20540;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30456;&#32467;&#21512;&#65292;&#25552;&#39640;&#20102;&#26426;&#22120;&#23398;&#20064;&#25511;&#21046;&#27169;&#22411;&#30340;&#36879;&#26126;&#24615;&#21644;&#29702;&#35299;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#25511;&#21046;&#22312;&#26262;&#36890;&#31354;&#35843;&#31995;&#32479;&#20013;&#30340;&#28508;&#21147;&#21463;&#38480;&#20110;&#20854;&#19981;&#36879;&#26126;&#30340;&#24615;&#36136;&#21644;&#25512;&#29702;&#26426;&#21046;&#65292;&#36825;&#23545;&#20110;&#29992;&#25143;&#21644;&#24314;&#27169;&#32773;&#26469;&#35828;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#38590;&#20197;&#23436;&#20840;&#29702;&#35299;&#65292;&#26368;&#32456;&#23548;&#33268;&#23545;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#25511;&#21046;&#30340;&#20915;&#31574;&#32570;&#20047;&#20449;&#20219;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#26412;&#25991;&#30740;&#31350;&#21644;&#25506;&#32034;&#20102;&#21487;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#65288;IML&#65289;&#65292;&#23427;&#26159;&#26426;&#22120;&#23398;&#20064;&#30340;&#19968;&#20010;&#20998;&#25903;&#65292;&#21487;&#20197;&#22686;&#24378;&#27169;&#22411;&#21644;&#25512;&#29702;&#30340;&#36879;&#26126;&#24615;&#21644;&#29702;&#35299;&#24615;&#65292;&#20197;&#25552;&#39640;MLC&#21450;&#20854;&#22312;&#26262;&#36890;&#31354;&#35843;&#31995;&#32479;&#20013;&#30340;&#24037;&#19994;&#24212;&#29992;&#30340;&#21487;&#20449;&#24230;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#21019;&#26032;&#24615;&#30340;&#26694;&#26550;&#65292;&#23558;Shapley&#20540;&#30340;&#21407;&#21017;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#29305;&#24615;&#30456;&#32467;&#21512;&#12290;&#32780;Shapley&#20540;&#22312;&#35299;&#21078;ML&#27169;&#22411;&#20013;&#21508;&#31181;&#29305;&#24449;&#30340;&#36129;&#29486;&#26041;&#38754;&#36215;&#21040;&#20102;&#37325;&#35201;&#20316;&#29992;&#65292;LLM&#21017;&#21487;&#20197;&#28145;&#20837;&#29702;&#35299;MLC&#20013;&#22522;&#20110;&#35268;&#21017;&#30340;&#37096;&#20998;&#65307;&#23558;&#23427;&#20204;&#32467;&#21512;&#36215;&#26469;&#65292;LLM&#36827;&#19968;&#27493;&#23558;&#36825;&#20123;&#27934;&#35265;&#25171;&#21253;&#21040;&#19968;&#20010;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09584v1 Announce Type: new  Abstract: The potential of Machine Learning Control (MLC) in HVAC systems is hindered by its opaque nature and inference mechanisms, which is challenging for users and modelers to fully comprehend, ultimately leading to a lack of trust in MLC-based decision-making. To address this challenge, this paper investigates and explores Interpretable Machine Learning (IML), a branch of Machine Learning (ML) that enhances transparency and understanding of models and their inferences, to improve the credibility of MLC and its industrial application in HVAC systems. Specifically, we developed an innovative framework that combines the principles of Shapley values and the in-context learning feature of Large Language Models (LLMs). While the Shapley values are instrumental in dissecting the contributions of various features in ML models, LLM provides an in-depth understanding of rule-based parts in MLC; combining them, LLM further packages these insights into a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;ChatGPT&#19982;EnergyPlus&#24314;&#31569;&#33021;&#28304;&#24314;&#27169;&#36719;&#20214;&#34701;&#21512;&#30340;&#21019;&#26032;&#26041;&#27861;&#65292;&#24182;&#24378;&#35843;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#35299;&#20915;&#24314;&#31569;&#33021;&#28304;&#24314;&#27169;&#25361;&#25112;&#26041;&#38754;&#30340;&#28508;&#21147;&#21644;&#22810;&#31181;&#24212;&#29992;&#12290;</title><link>https://arxiv.org/abs/2402.09579</link><description>&lt;p&gt;
&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25512;&#21160;&#24314;&#31569;&#33021;&#28304;&#24314;&#27169;&#65306;&#25506;&#32034;&#21644;&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Advancing Building Energy Modeling with Large Language Models: Exploration and Case Studies
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09579
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;ChatGPT&#19982;EnergyPlus&#24314;&#31569;&#33021;&#28304;&#24314;&#27169;&#36719;&#20214;&#34701;&#21512;&#30340;&#21019;&#26032;&#26041;&#27861;&#65292;&#24182;&#24378;&#35843;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#35299;&#20915;&#24314;&#31569;&#33021;&#28304;&#24314;&#27169;&#25361;&#25112;&#26041;&#38754;&#30340;&#28508;&#21147;&#21644;&#22810;&#31181;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#30340;&#24555;&#36895;&#21457;&#23637;&#20419;&#36827;&#20102;&#20687;ChatGPT&#36825;&#26679;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20986;&#29616;&#65292;&#20026;&#19987;&#38376;&#30340;&#24037;&#31243;&#24314;&#27169;&#65288;&#23588;&#20854;&#26159;&#22522;&#20110;&#29289;&#29702;&#30340;&#24314;&#31569;&#33021;&#28304;&#24314;&#27169;&#65289;&#25552;&#20379;&#20102;&#28508;&#22312;&#30340;&#24212;&#29992;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#24314;&#31569;&#33021;&#28304;&#24314;&#27169;&#36719;&#20214;&#65288;&#20855;&#20307;&#20026;EnergyPlus&#65289;&#34701;&#21512;&#30340;&#21019;&#26032;&#26041;&#27861;&#12290;&#39318;&#20808;&#36827;&#34892;&#20102;&#25991;&#29486;&#32508;&#36848;&#65292;&#25581;&#31034;&#20102;&#22312;&#24037;&#31243;&#24314;&#27169;&#20013;&#25972;&#21512;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22686;&#38271;&#36235;&#21183;&#65292;&#20294;&#22312;&#24314;&#31569;&#33021;&#28304;&#24314;&#27169;&#20013;&#30340;&#24212;&#29992;&#30740;&#31350;&#20173;&#28982;&#26377;&#38480;&#12290;&#25105;&#20204;&#24378;&#35843;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#35299;&#20915;&#24314;&#31569;&#33021;&#28304;&#24314;&#27169;&#25361;&#25112;&#26041;&#38754;&#30340;&#28508;&#21147;&#65292;&#24182;&#27010;&#36848;&#20102;&#28508;&#22312;&#30340;&#24212;&#29992;&#65292;&#21253;&#25324;&#65306;1&#65289;&#27169;&#25311;&#36755;&#20837;&#29983;&#25104;&#65292;2&#65289;&#27169;&#25311;&#36755;&#20986;&#20998;&#26512;&#21644;&#21487;&#35270;&#21270;&#65292;3&#65289;&#36827;&#34892;&#38169;&#35823;&#20998;&#26512;&#65292;4&#65289;&#20849;&#27169;&#25311;&#65292;5&#65289;&#27169;&#25311;&#30693;&#35782;&#25552;&#21462;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09579v1 Announce Type: cross  Abstract: The rapid progression in artificial intelligence has facilitated the emergence of large language models like ChatGPT, offering potential applications extending into specialized engineering modeling, especially physics-based building energy modeling. This paper investigates the innovative integration of large language models with building energy modeling software, focusing specifically on the fusion of ChatGPT with EnergyPlus. A literature review is first conducted to reveal a growing trend of incorporating of large language models in engineering modeling, albeit limited research on their application in building energy modeling. We underscore the potential of large language models in addressing building energy modeling challenges and outline potential applications including 1) simulation input generation, 2) simulation output analysis and visualization, 3) conducting error analysis, 4) co-simulation, 5) simulation knowledge extraction a
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#35780;&#20272;&#20102;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;GPT-4&#65289;&#22312;&#30693;&#35782;&#22270;&#35889;&#19978;&#30340;&#23545;&#35805;&#25512;&#29702;&#33021;&#21147;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;KG&#25512;&#29702;&#30340;LLM&#22522;&#20934;&#20195;&#29702;&#65288;LLM-ARK&#65289;&#65292;&#35813;&#20195;&#29702;&#21033;&#29992;&#20840;&#25991;&#29615;&#22659;&#25552;&#31034;&#26469;&#23454;&#29616;&#31934;&#30830;&#21644;&#36866;&#24212;&#24615;&#24378;&#30340;KG&#36335;&#24452;&#39044;&#27979;&#65292;&#24182;&#37319;&#29992;&#36817;&#31471;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#35757;&#32451;&#12290;</title><link>https://arxiv.org/abs/2312.11282</link><description>&lt;p&gt;
&#35780;&#20272;&#21644;&#22686;&#24378;&#29992;&#20110;&#30693;&#35782;&#22270;&#35889;&#19978;&#30340;&#23545;&#35805;&#25512;&#29702;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Evaluating and Enhancing Large Language Models for Conversational Reasoning on Knowledge Graphs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.11282
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35780;&#20272;&#20102;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;GPT-4&#65289;&#22312;&#30693;&#35782;&#22270;&#35889;&#19978;&#30340;&#23545;&#35805;&#25512;&#29702;&#33021;&#21147;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;KG&#25512;&#29702;&#30340;LLM&#22522;&#20934;&#20195;&#29702;&#65288;LLM-ARK&#65289;&#65292;&#35813;&#20195;&#29702;&#21033;&#29992;&#20840;&#25991;&#29615;&#22659;&#25552;&#31034;&#26469;&#23454;&#29616;&#31934;&#30830;&#21644;&#36866;&#24212;&#24615;&#24378;&#30340;KG&#36335;&#24452;&#39044;&#27979;&#65292;&#24182;&#37319;&#29992;&#36817;&#31471;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#21457;&#23637;&#24471;&#30410;&#20110;&#39044;&#35757;&#32451;&#25216;&#26415;&#30340;&#36827;&#23637;&#12290;&#36890;&#36807;&#25163;&#21160;&#35774;&#35745;&#30340;&#25552;&#31034;&#65292;&#36825;&#20123;&#27169;&#22411;&#23637;&#31034;&#20102;&#24378;&#22823;&#30340;&#25512;&#29702;&#33021;&#21147;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;LLM&#65288;GPT-4&#65289;&#22312;&#30693;&#35782;&#22270;&#35889;&#65288;KG&#65289;&#19978;&#30340;&#23545;&#35805;&#25512;&#29702;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#32570;&#20047;KG&#29615;&#22659;&#24847;&#35782;&#21644;&#24320;&#21457;&#26377;&#25928;&#30340;&#20013;&#38388;&#25512;&#29702;&#38454;&#27573;&#20248;&#21270;&#26426;&#21046;&#30340;&#22256;&#38590;&#65292;LLM&#30340;&#24615;&#33021;&#21463;&#21040;&#38480;&#21046;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#24341;&#20837;&#20102;LLM-ARK&#65292;&#19968;&#20010;&#22522;&#20110;KG&#25512;&#29702;&#30340;LLM&#22522;&#20934;&#20195;&#29702;&#65292;&#26088;&#22312;&#25552;&#20379;&#31934;&#30830;&#21644;&#36866;&#24212;&#24615;&#24378;&#30340;KG&#36335;&#24452;&#39044;&#27979;&#12290;LLM-ARK&#21033;&#29992;&#20840;&#25991;&#29615;&#22659;&#65288;FTE&#65289;&#25552;&#31034;&#26469;&#21560;&#25910;&#27599;&#20010;&#25512;&#29702;&#27493;&#39588;&#20013;&#30340;&#29366;&#24577;&#20449;&#24687;&#12290;&#25105;&#20204;&#23558;KG&#19978;&#30340;&#22810;&#36339;&#25512;&#29702;&#25361;&#25112;&#37325;&#26032;&#26694;&#23450;&#20026;&#39034;&#24207;&#20915;&#31574;&#20219;&#21153;&#12290;&#21033;&#29992;&#36817;&#31471;&#31574;&#30053;&#20248;&#21270;&#65288;PPO&#65289;&#22312;&#32447;&#31574;&#30053;&#26799;&#24230;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;...
&lt;/p&gt;
&lt;p&gt;
The development of large language models (LLMs) has been catalyzed by advancements in pre-training techniques. These models have demonstrated robust reasoning capabilities through manually designed prompts. In this work, we evaluate the conversational reasoning capabilities of the current state-of-the-art LLM (GPT-4) on knowledge graphs (KGs). However, the performance of LLMs is constrained due to a lack of KG environment awareness and the difficulties in developing effective optimization mechanisms for intermediary reasoning stages. We further introduce LLM-ARK, a LLM grounded KG reasoning agent designed to deliver precise and adaptable predictions on KG paths. LLM-ARK leverages Full Textual Environment (FTE) prompt to assimilate state information within each reasoning step. We reframe the challenge of multi-hop reasoning on the KG as a sequential decision-making task. Utilizing the Proximal Policy Optimization (PPO) online policy gradient reinforcement learning algorithm, our model i
&lt;/p&gt;</description></item><item><title>ShaRP&#26159;&#19968;&#20010;&#22522;&#20110;Shapley&#20540;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#37322;&#25490;&#21517;&#32467;&#26524;&#20013;&#21508;&#20010;&#29305;&#24449;&#30340;&#36129;&#29486;&#12290;&#21363;&#20351;&#20351;&#29992;&#32447;&#24615;&#35780;&#20998;&#20989;&#25968;&#65292;&#29305;&#24449;&#30340;&#26435;&#37325;&#20063;&#19981;&#19968;&#23450;&#23545;&#24212;&#20854;Shapley&#20540;&#30340;&#36129;&#29486;&#65292;&#32780;&#26159;&#21462;&#20915;&#20110;&#29305;&#24449;&#20998;&#24067;&#21644;&#35780;&#20998;&#29305;&#24449;&#20043;&#38388;&#30340;&#23616;&#37096;&#30456;&#20114;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2401.16744</link><description>&lt;p&gt;
ShaRP&#65306;&#29992;Shapley&#20540;&#35299;&#37322;&#25490;&#21517;
&lt;/p&gt;
&lt;p&gt;
ShaRP: Explaining Rankings with Shapley Values. (arXiv:2401.16744v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16744
&lt;/p&gt;
&lt;p&gt;
ShaRP&#26159;&#19968;&#20010;&#22522;&#20110;Shapley&#20540;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#37322;&#25490;&#21517;&#32467;&#26524;&#20013;&#21508;&#20010;&#29305;&#24449;&#30340;&#36129;&#29486;&#12290;&#21363;&#20351;&#20351;&#29992;&#32447;&#24615;&#35780;&#20998;&#20989;&#25968;&#65292;&#29305;&#24449;&#30340;&#26435;&#37325;&#20063;&#19981;&#19968;&#23450;&#23545;&#24212;&#20854;Shapley&#20540;&#30340;&#36129;&#29486;&#65292;&#32780;&#26159;&#21462;&#20915;&#20110;&#29305;&#24449;&#20998;&#24067;&#21644;&#35780;&#20998;&#29305;&#24449;&#20043;&#38388;&#30340;&#23616;&#37096;&#30456;&#20114;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25307;&#32856;&#12289;&#22823;&#23398;&#25307;&#29983;&#21644;&#36151;&#27454;&#31561;&#37325;&#35201;&#39046;&#22495;&#30340;&#31639;&#27861;&#20915;&#31574;&#24120;&#24120;&#26159;&#22522;&#20110;&#25490;&#21517;&#30340;&#12290;&#30001;&#20110;&#36825;&#20123;&#20915;&#31574;&#23545;&#20010;&#20154;&#12289;&#32452;&#32455;&#21644;&#20154;&#32676;&#30340;&#24433;&#21709;&#65292;&#26377;&#24517;&#35201;&#20102;&#35299;&#23427;&#20204;&#65306;&#20102;&#35299;&#20915;&#31574;&#26159;&#21542;&#36981;&#23432;&#27861;&#24459;&#65292;&#24110;&#21161;&#20010;&#20154;&#25552;&#39640;&#20182;&#20204;&#30340;&#25490;&#21517;&#65292;&#24182;&#35774;&#35745;&#26356;&#22909;&#30340;&#25490;&#21517;&#31243;&#24207;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;ShaRP&#65288;Shapley for Rankings and Preferences&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#22522;&#20110;Shapley&#20540;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#37322;&#29305;&#24449;&#23545;&#25490;&#21517;&#32467;&#26524;&#19981;&#21516;&#26041;&#38754;&#30340;&#36129;&#29486;&#12290;&#20351;&#29992;ShaRP&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21363;&#20351;&#31639;&#27861;&#25490;&#21517;&#22120;&#20351;&#29992;&#30340;&#35780;&#20998;&#20989;&#25968;&#26159;&#24050;&#30693;&#30340;&#19988;&#26159;&#32447;&#24615;&#30340;&#65292;&#27599;&#20010;&#29305;&#24449;&#30340;&#26435;&#37325;&#20063;&#19981;&#19968;&#23450;&#23545;&#24212;&#20854;Shapley&#20540;&#30340;&#36129;&#29486;&#12290;&#36129;&#29486;&#21462;&#20915;&#20110;&#29305;&#24449;&#30340;&#20998;&#24067;&#20197;&#21450;&#35780;&#20998;&#29305;&#24449;&#20043;&#38388;&#24494;&#22937;&#30340;&#23616;&#37096;&#30456;&#20114;&#20316;&#29992;&#12290;ShaRP&#22522;&#20110;&#37327;&#21270;&#36755;&#20837;&#24433;&#21709;&#26694;&#26550;&#65292;&#24182;&#21487;&#20197;&#35745;&#31639;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
Algorithmic decisions in critical domains such as hiring, college admissions, and lending are often based on rankings. Because of the impact these decisions have on individuals, organizations, and population groups, there is a need to understand them: to know whether the decisions are abiding by the law, to help individuals improve their rankings, and to design better ranking procedures.  In this paper, we present ShaRP (Shapley for Rankings and Preferences), a framework that explains the contributions of features to different aspects of a ranked outcome, and is based on Shapley values. Using ShaRP, we show that even when the scoring function used by an algorithmic ranker is known and linear, the weight of each feature does not correspond to its Shapley value contribution. The contributions instead depend on the feature distributions, and on the subtle local interactions between the scoring features. ShaRP builds on the Quantitative Input Influence framework, and can compute the contri
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#23558;&#31070;&#32463;&#32593;&#32476;&#21644;&#31526;&#21495;&#25512;&#29702;&#32467;&#21512;&#36215;&#26469;&#65292;&#25552;&#20986;&#20102;Spatial Reasoning Integrated Generator (SPRING)&#65292;&#29992;&#20110;&#35774;&#35745;&#29983;&#25104;&#12290;SPRING&#36890;&#36807;&#23558;&#31070;&#32463;&#32593;&#32476;&#21644;&#31526;&#21495;&#32422;&#26463;&#28385;&#36275;&#32467;&#21512;&#36215;&#26469;&#65292;&#33021;&#22815;&#29983;&#25104;&#28385;&#36275;&#29992;&#25143;&#35268;&#26684;&#21644;&#23454;&#29992;&#35201;&#27714;&#30340;&#35774;&#35745;&#12290;</title><link>http://arxiv.org/abs/2310.09383</link><description>&lt;p&gt;
&#23558;&#31526;&#21495;&#25512;&#29702;&#25972;&#21512;&#21040;&#31070;&#32463;&#29983;&#25104;&#27169;&#22411;&#20013;&#30340;&#35774;&#35745;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Integrating Symbolic Reasoning into Neural Generative Models for Design Generation. (arXiv:2310.09383v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09383
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#23558;&#31070;&#32463;&#32593;&#32476;&#21644;&#31526;&#21495;&#25512;&#29702;&#32467;&#21512;&#36215;&#26469;&#65292;&#25552;&#20986;&#20102;Spatial Reasoning Integrated Generator (SPRING)&#65292;&#29992;&#20110;&#35774;&#35745;&#29983;&#25104;&#12290;SPRING&#36890;&#36807;&#23558;&#31070;&#32463;&#32593;&#32476;&#21644;&#31526;&#21495;&#32422;&#26463;&#28385;&#36275;&#32467;&#21512;&#36215;&#26469;&#65292;&#33021;&#22815;&#29983;&#25104;&#28385;&#36275;&#29992;&#25143;&#35268;&#26684;&#21644;&#23454;&#29992;&#35201;&#27714;&#30340;&#35774;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35774;&#35745;&#29983;&#25104;&#38656;&#35201;&#23558;&#31070;&#32463;&#21644;&#31526;&#21495;&#25512;&#29702;&#32039;&#23494;&#32467;&#21512;&#65292;&#22240;&#20026;&#33391;&#22909;&#30340;&#35774;&#35745;&#24517;&#39035;&#28385;&#36275;&#26174;&#24335;&#29992;&#25143;&#38656;&#27714;&#21644;&#38544;&#21547;&#30340;&#32654;&#23398;&#12289;&#23454;&#29992;&#24615;&#21644;&#20415;&#21033;&#24615;&#35268;&#21017;&#12290;&#24403;&#21069;&#30001;&#31070;&#32463;&#32593;&#32476;&#39537;&#21160;&#30340;&#33258;&#21160;&#21270;&#35774;&#35745;&#24037;&#20855;&#33021;&#22815;&#29983;&#25104;&#21560;&#24341;&#20154;&#30340;&#35774;&#35745;&#65292;&#20294;&#19981;&#33021;&#28385;&#36275;&#29992;&#25143;&#30340;&#35268;&#26684;&#21644;&#23454;&#29992;&#35201;&#27714;&#12290;&#31526;&#21495;&#25512;&#29702;&#24037;&#20855;&#65288;&#22914;&#32422;&#26463;&#32534;&#31243;&#65289;&#19981;&#33021;&#24863;&#30693;&#22270;&#20687;&#20013;&#30340;&#20302;&#32423;&#35270;&#35273;&#20449;&#24687;&#25110;&#25429;&#25417;&#21040;&#32654;&#23398;&#31561;&#24494;&#22937;&#26041;&#38754;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;Spatial Reasoning Integrated Generator (SPRING)&#29992;&#20110;&#35774;&#35745;&#29983;&#25104;&#12290;SPRING&#22312;&#28145;&#24230;&#29983;&#25104;&#32593;&#32476;&#20013;&#23884;&#20837;&#20102;&#19968;&#20010;&#31070;&#32463;&#21644;&#31526;&#21495;&#25972;&#21512;&#30340;&#31354;&#38388;&#25512;&#29702;&#27169;&#22359;&#12290;&#31354;&#38388;&#25512;&#29702;&#27169;&#22359;&#36890;&#36807;&#19968;&#20010;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#24182;&#36890;&#36807;&#31526;&#21495;&#32422;&#26463;&#28385;&#36275;&#26469;&#20915;&#23450;&#35201;&#29983;&#25104;&#30340;&#23545;&#35937;&#30340;&#20301;&#32622;&#65292;&#20197;&#36793;&#30028;&#26694;&#30340;&#24418;&#24335;&#34920;&#31034;&#12290;&#23558;&#31526;&#21495;&#25512;&#29702;&#23884;&#20837;&#31070;&#32463;&#29983;&#25104;&#20445;&#35777;&#20102;SPRING&#30340;&#36755;&#20986;&#28385;&#36275;&#29992;&#25143;&#30340;&#35268;&#26684;&#21644;&#23454;&#29992;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
Design generation requires tight integration of neural and symbolic reasoning, as good design must meet explicit user needs and honor implicit rules for aesthetics, utility, and convenience. Current automated design tools driven by neural networks produce appealing designs, but cannot satisfy user specifications and utility requirements. Symbolic reasoning tools, such as constraint programming, cannot perceive low-level visual information in images or capture subtle aspects such as aesthetics. We introduce the Spatial Reasoning Integrated Generator (SPRING) for design generation. SPRING embeds a neural and symbolic integrated spatial reasoning module inside the deep generative network. The spatial reasoning module decides the locations of objects to be generated in the form of bounding boxes, which are predicted by a recurrent neural network and filtered by symbolic constraint satisfaction. Embedding symbolic reasoning into neural generation guarantees that the output of SPRING satisfi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#25925;&#38556;&#27880;&#20837;&#21644;&#23433;&#20840;&#38169;&#35823;&#25915;&#20987;&#29992;&#20110;&#25552;&#21462;&#23884;&#20837;&#24335;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#24182;&#38416;&#36848;&#20102;&#23545;32&#20301;&#24494;&#25511;&#21046;&#22120;&#19978;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#27169;&#22411;&#25552;&#21462;&#25915;&#20987;&#30340;&#23454;&#39564;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.16703</link><description>&lt;p&gt;
&#25925;&#38556;&#27880;&#20837;&#21644;&#23433;&#20840;&#38169;&#35823;&#25915;&#20987;&#29992;&#20110;&#25552;&#21462;&#23884;&#20837;&#24335;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Fault Injection and Safe-Error Attack for Extraction of Embedded Neural Network Models. (arXiv:2308.16703v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16703
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#25925;&#38556;&#27880;&#20837;&#21644;&#23433;&#20840;&#38169;&#35823;&#25915;&#20987;&#29992;&#20110;&#25552;&#21462;&#23884;&#20837;&#24335;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#24182;&#38416;&#36848;&#20102;&#23545;32&#20301;&#24494;&#25511;&#21046;&#22120;&#19978;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#27169;&#22411;&#25552;&#21462;&#25915;&#20987;&#30340;&#23454;&#39564;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#22411;&#25552;&#21462;&#20316;&#20026;&#19968;&#31181;&#20851;&#38190;&#30340;&#23433;&#20840;&#23041;&#32961;&#32780;&#20986;&#29616;&#65292;&#25915;&#20987;&#21521;&#37327;&#21033;&#29992;&#20102;&#31639;&#27861;&#21644;&#23454;&#29616;&#26041;&#38754;&#30340;&#26041;&#27861;&#12290;&#25915;&#20987;&#32773;&#30340;&#20027;&#35201;&#30446;&#26631;&#26159;&#23613;&#21487;&#33021;&#22810;&#22320;&#31363;&#21462;&#21463;&#20445;&#25252;&#30340;&#21463;&#23475;&#32773;&#27169;&#22411;&#30340;&#20449;&#24687;&#65292;&#20197;&#20415;&#20182;&#21487;&#20197;&#29992;&#26367;&#20195;&#27169;&#22411;&#26469;&#27169;&#20223;&#23427;&#65292;&#21363;&#20351;&#21482;&#26377;&#26377;&#38480;&#30340;&#35775;&#38382;&#30456;&#20284;&#30340;&#35757;&#32451;&#25968;&#25454;&#12290;&#26368;&#36817;&#65292;&#29289;&#29702;&#25915;&#20987;&#65292;&#22914;&#25925;&#38556;&#27880;&#20837;&#65292;&#24050;&#32463;&#26174;&#31034;&#20986;&#23545;&#23884;&#20837;&#24335;&#27169;&#22411;&#30340;&#23436;&#25972;&#24615;&#21644;&#26426;&#23494;&#24615;&#30340;&#20196;&#20154;&#25285;&#24551;&#30340;&#25928;&#26524;&#12290;&#25105;&#20204;&#30340;&#37325;&#28857;&#26159;32&#20301;&#24494;&#25511;&#21046;&#22120;&#19978;&#30340;&#23884;&#20837;&#24335;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#36825;&#26159;&#29289;&#32852;&#32593;&#20013;&#24191;&#27867;&#20351;&#29992;&#30340;&#30828;&#20214;&#24179;&#21488;&#31995;&#21015;&#65292;&#20197;&#21450;&#20351;&#29992;&#26631;&#20934;&#25925;&#38556;&#27880;&#20837;&#31574;&#30053;-&#23433;&#20840;&#38169;&#35823;&#25915;&#20987;&#65288;SEA&#65289;&#26469;&#36827;&#34892;&#20855;&#26377;&#26377;&#38480;&#35757;&#32451;&#25968;&#25454;&#35775;&#38382;&#30340;&#27169;&#22411;&#25552;&#21462;&#25915;&#20987;&#12290;&#30001;&#20110;&#25915;&#20987;&#24378;&#28872;&#20381;&#36182;&#20110;&#36755;&#20837;&#26597;&#35810;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#40657;&#30418;&#26041;&#27861;&#26469;&#26500;&#24314;&#19968;&#20010;&#25104;&#21151;&#30340;&#25915;&#20987;&#38598;&#12290;&#23545;&#20110;&#19968;&#20010;&#32463;&#20856;&#30340;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#25104;&#21151;&#22320;&#24674;&#22797;&#20102;&#33267;&#23569;90%&#30340;
&lt;/p&gt;
&lt;p&gt;
Model extraction emerges as a critical security threat with attack vectors exploiting both algorithmic and implementation-based approaches. The main goal of an attacker is to steal as much information as possible about a protected victim model, so that he can mimic it with a substitute model, even with a limited access to similar training data. Recently, physical attacks such as fault injection have shown worrying efficiency against the integrity and confidentiality of embedded models. We focus on embedded deep neural network models on 32-bit microcontrollers, a widespread family of hardware platforms in IoT, and the use of a standard fault injection strategy - Safe Error Attack (SEA) - to perform a model extraction attack with an adversary having a limited access to training data. Since the attack strongly depends on the input queries, we propose a black-box approach to craft a successful attack set. For a classical convolutional neural network, we successfully recover at least 90% of
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#20855;&#26377;&#30701;&#26399;&#12289;&#24773;&#33410;&#21644;&#35821;&#20041;&#20869;&#23384;&#31995;&#32479;&#30340;&#26426;&#22120;&#20195;&#29702;&#27169;&#22411;&#65292;&#36890;&#36807;&#22522;&#20110;&#30693;&#35782;&#22270;&#35889;&#30340;&#24314;&#27169;&#65292;&#22312;&#24378;&#21270;&#23398;&#20064;&#29615;&#22659;&#20013;&#23454;&#29616;&#20102;&#30701;&#26399;&#35760;&#24518;&#30340;&#31649;&#29702;&#21644;&#23384;&#20648;&#65292;&#23454;&#39564;&#35777;&#26126;&#36825;&#31181;&#20154;&#31867;&#35760;&#24518;&#31995;&#32479;&#32467;&#26500;&#30340;&#20195;&#29702;&#27604;&#27809;&#26377;&#35813;&#32467;&#26500;&#30340;&#20195;&#29702;&#34920;&#29616;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2212.02098</link><description>&lt;p&gt;
&#19968;&#20010;&#20855;&#26377;&#30701;&#26399;&#12289;&#24773;&#33410;&#21644;&#35821;&#20041;&#20869;&#23384;&#31995;&#32479;&#30340;&#26426;&#22120;
&lt;/p&gt;
&lt;p&gt;
A Machine with Short-Term, Episodic, and Semantic Memory Systems. (arXiv:2212.02098v2 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.02098
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#20855;&#26377;&#30701;&#26399;&#12289;&#24773;&#33410;&#21644;&#35821;&#20041;&#20869;&#23384;&#31995;&#32479;&#30340;&#26426;&#22120;&#20195;&#29702;&#27169;&#22411;&#65292;&#36890;&#36807;&#22522;&#20110;&#30693;&#35782;&#22270;&#35889;&#30340;&#24314;&#27169;&#65292;&#22312;&#24378;&#21270;&#23398;&#20064;&#29615;&#22659;&#20013;&#23454;&#29616;&#20102;&#30701;&#26399;&#35760;&#24518;&#30340;&#31649;&#29702;&#21644;&#23384;&#20648;&#65292;&#23454;&#39564;&#35777;&#26126;&#36825;&#31181;&#20154;&#31867;&#35760;&#24518;&#31995;&#32479;&#32467;&#26500;&#30340;&#20195;&#29702;&#27604;&#27809;&#26377;&#35813;&#32467;&#26500;&#30340;&#20195;&#29702;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#35748;&#30693;&#31185;&#23398;&#29702;&#35770;&#20013;&#26174;&#24615;&#20154;&#31867;&#35760;&#24518;&#31995;&#32479;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#20855;&#26377;&#30701;&#26399;&#12289;&#24773;&#33410;&#21644;&#35821;&#20041;&#35760;&#24518;&#31995;&#32479;&#30340;&#20195;&#29702;&#27169;&#22411;&#65292;&#27599;&#20010;&#35760;&#24518;&#31995;&#32479;&#37117;&#29992;&#30693;&#35782;&#22270;&#35889;&#24314;&#27169;&#12290;&#20026;&#20102;&#35780;&#20272;&#35813;&#31995;&#32479;&#24182;&#20998;&#26512;&#35813;&#20195;&#29702;&#30340;&#34892;&#20026;&#65292;&#25105;&#20204;&#35774;&#35745;&#24182;&#21457;&#24067;&#20102;&#25105;&#20204;&#33258;&#24049;&#30340;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#29615;&#22659;&#8220;&#25151;&#38388;&#8221;&#65292;&#22312;&#36825;&#20010;&#29615;&#22659;&#20013;&#65292;&#20195;&#29702;&#24517;&#39035;&#23398;&#20064;&#22914;&#20309;&#32534;&#30721;&#12289;&#23384;&#20648;&#21644;&#26816;&#32034;&#35760;&#24518;&#65292;&#36890;&#36807;&#22238;&#31572;&#38382;&#39064;&#26469;&#26368;&#22823;&#21270;&#22238;&#25253;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#22522;&#20110;&#28145;&#24230;Q&#23398;&#20064;&#30340;&#20195;&#29702;&#25104;&#21151;&#23398;&#20064;&#20102;&#30701;&#26399;&#35760;&#24518;&#26159;&#21542;&#24212;&#35813;&#34987;&#36951;&#24536;&#65292;&#36824;&#26159;&#24212;&#35813;&#23384;&#20648;&#22312;&#24773;&#33410;&#25110;&#35821;&#20041;&#35760;&#24518;&#31995;&#32479;&#20013;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#20855;&#26377;&#31867;&#20154;&#35760;&#24518;&#31995;&#32479;&#30340;&#20195;&#29702;&#22312;&#29615;&#22659;&#20013;&#34920;&#29616;&#20248;&#20110;&#27809;&#26377;&#36825;&#31181;&#35760;&#24518;&#32467;&#26500;&#30340;&#20195;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inspired by the cognitive science theory of the explicit human memory systems, we have modeled an agent with short-term, episodic, and semantic memory systems, each of which is modeled with a knowledge graph. To evaluate this system and analyze the behavior of this agent, we designed and released our own reinforcement learning agent environment, "the Room", where an agent has to learn how to encode, store, and retrieve memories to maximize its return by answering questions. We show that our deep Q-learning based agent successfully learns whether a short-term memory should be forgotten, or rather be stored in the episodic or semantic memory systems. Our experiments indicate that an agent with human-like memory systems can outperform an agent without this memory structure in the environment.
&lt;/p&gt;</description></item></channel></rss>