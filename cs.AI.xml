<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#26412;&#32508;&#36848;&#20840;&#38754;&#23457;&#35270;&#20102;&#22522;&#20110;&#20248;&#21270;&#30340;&#20219;&#21153;&#19982;&#36816;&#21160;&#35268;&#21010;&#65292;&#37325;&#28857;&#35752;&#35770;&#20102;&#22914;&#20309;&#36890;&#36807;&#28151;&#21512;&#20248;&#21270;&#26041;&#27861;&#35299;&#20915;&#39640;&#24230;&#22797;&#26434;&#12289;&#25509;&#35302;&#20016;&#23500;&#30340;&#26426;&#22120;&#20154;&#36816;&#21160;&#21644;&#25805;&#20316;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2404.02817</link><description>&lt;p&gt;
&#20248;&#21270;&#22411;&#20219;&#21153;&#19982;&#36816;&#21160;&#35268;&#21010;&#32508;&#36848;&#65306;&#20174;&#32463;&#20856;&#21040;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Survey of Optimization-based Task and Motion Planning: From Classical To Learning Approaches
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02817
&lt;/p&gt;
&lt;p&gt;
&#26412;&#32508;&#36848;&#20840;&#38754;&#23457;&#35270;&#20102;&#22522;&#20110;&#20248;&#21270;&#30340;&#20219;&#21153;&#19982;&#36816;&#21160;&#35268;&#21010;&#65292;&#37325;&#28857;&#35752;&#35770;&#20102;&#22914;&#20309;&#36890;&#36807;&#28151;&#21512;&#20248;&#21270;&#26041;&#27861;&#35299;&#20915;&#39640;&#24230;&#22797;&#26434;&#12289;&#25509;&#35302;&#20016;&#23500;&#30340;&#26426;&#22120;&#20154;&#36816;&#21160;&#21644;&#25805;&#20316;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20219;&#21153;&#19982;&#36816;&#21160;&#35268;&#21010;&#65288;TAMP&#65289;&#23558;&#39640;&#23618;&#20219;&#21153;&#35268;&#21010;&#21644;&#20302;&#23618;&#36816;&#21160;&#35268;&#21010;&#32467;&#21512;&#36215;&#26469;&#65292;&#20351;&#26426;&#22120;&#20154;&#33021;&#22815;&#26377;&#25928;&#22320;&#25512;&#29702;&#35299;&#20915;&#38271;&#26102;&#22495;&#12289;&#21160;&#24577;&#20219;&#21153;&#12290;&#22522;&#20110;&#20248;&#21270;&#30340;TAMP&#19987;&#27880;&#20110;&#36890;&#36807;&#30446;&#26631;&#20989;&#25968;&#23450;&#20041;&#30446;&#26631;&#26465;&#20214;&#30340;&#28151;&#21512;&#20248;&#21270;&#26041;&#27861;&#65292;&#24182;&#19988;&#33021;&#22815;&#22788;&#29702;&#24320;&#25918;&#24335;&#30446;&#26631;&#12289;&#26426;&#22120;&#20154;&#21160;&#24577;&#21644;&#26426;&#22120;&#20154;&#19982;&#29615;&#22659;&#20043;&#38388;&#30340;&#29289;&#29702;&#20132;&#20114;&#12290;&#22240;&#27492;&#65292;&#22522;&#20110;&#20248;&#21270;&#30340;TAMP&#29305;&#21035;&#36866;&#21512;&#35299;&#20915;&#39640;&#24230;&#22797;&#26434;&#12289;&#25509;&#35302;&#20016;&#23500;&#30340;&#36816;&#21160;&#21644;&#25805;&#20316;&#38382;&#39064;&#12290;&#26412;&#32508;&#36848;&#20840;&#38754;&#23457;&#35270;&#20102;&#22522;&#20110;&#20248;&#21270;&#30340;TAMP&#65292;&#28085;&#30422;&#20102;&#65288;i&#65289;&#35268;&#21010;&#39046;&#22495;&#34920;&#31034;&#65292;&#21253;&#25324;&#21160;&#20316;&#25551;&#36848;&#35821;&#35328;&#21644;&#26102;&#24577;&#36923;&#36753;&#65292;&#65288;ii&#65289;TAMP&#21508;&#32452;&#20214;&#30340;&#20010;&#21035;&#35299;&#20915;&#31574;&#30053;&#65292;&#21253;&#25324;&#20154;&#24037;&#26234;&#33021;&#35268;&#21010;&#21644;&#36712;&#36857;&#20248;&#21270;&#65288;TO&#65289;&#65292;&#20197;&#21450;&#65288;iii&#65289;&#22522;&#20110;&#36923;&#36753;&#30340;&#20219;&#21153;&#35268;&#21010;&#19982;&#22522;&#20110;&#27169;&#22411;&#30340;TO&#20043;&#38388;&#30340;&#21160;&#24577;&#30456;&#20114;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02817v1 Announce Type: cross  Abstract: Task and Motion Planning (TAMP) integrates high-level task planning and low-level motion planning to equip robots with the autonomy to effectively reason over long-horizon, dynamic tasks. Optimization-based TAMP focuses on hybrid optimization approaches that define goal conditions via objective functions and are capable of handling open-ended goals, robotic dynamics, and physical interaction between the robot and the environment. Therefore, optimization-based TAMP is particularly suited to solve highly complex, contact-rich locomotion and manipulation problems. This survey provides a comprehensive review on optimization-based TAMP, covering (i) planning domain representations, including action description languages and temporal logic, (ii) individual solution strategies for components of TAMP, including AI planning and trajectory optimization (TO), and (iii) the dynamic interplay between logic-based task planning and model-based TO. A 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#20197;&#25552;&#20379;&#32508;&#21512;&#24615;&#24615;&#21035;&#27602;&#24615;&#25351;&#26631;&#30340;&#27169;&#22411;&#65292;&#26377;&#21161;&#20110;&#25919;&#31574;&#21046;&#23450;&#32773;&#12289;&#22312;&#32447;&#31038;&#21306;&#31649;&#29702;&#21592;&#21644;&#35745;&#31639;&#31038;&#20250;&#31185;&#23398;&#23478;&#26356;&#22909;&#22320;&#29702;&#35299;&#21644;&#31649;&#29702;&#22312;&#32447;&#24615;&#21035;&#27495;&#35270;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2404.02205</link><description>&lt;p&gt;
&#19968;&#20010;&#25972;&#20307;&#24615;&#26497;&#21270;&#25351;&#26631;&#20197;&#34913;&#37327;&#22312;&#32447;&#24615;&#21035;&#27495;&#35270;
&lt;/p&gt;
&lt;p&gt;
A Holistic Indicator of Polarization to Measure Online Sexism
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02205
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#20197;&#25552;&#20379;&#32508;&#21512;&#24615;&#24615;&#21035;&#27602;&#24615;&#25351;&#26631;&#30340;&#27169;&#22411;&#65292;&#26377;&#21161;&#20110;&#25919;&#31574;&#21046;&#23450;&#32773;&#12289;&#22312;&#32447;&#31038;&#21306;&#31649;&#29702;&#21592;&#21644;&#35745;&#31639;&#31038;&#20250;&#31185;&#23398;&#23478;&#26356;&#22909;&#22320;&#29702;&#35299;&#21644;&#31649;&#29702;&#22312;&#32447;&#24615;&#21035;&#27495;&#35270;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02205v1 &#20844;&#21578;&#31867;&#22411;: &#36328;&#39046;&#22495; &#25688;&#35201;: &#30007;&#26435;&#20027;&#20041;&#32773;&#21644;&#22899;&#26435;&#20027;&#20041;&#32773;&#22312;&#31038;&#20132;&#32593;&#32476;&#19978;&#30340;&#22312;&#32447;&#36235;&#21183;&#38656;&#35201;&#19968;&#20010;&#25972;&#20307;&#24615;&#30340;&#34913;&#37327;&#24615;&#21035;&#27495;&#35270;&#27700;&#24179;&#30340;&#25351;&#26631;&#12290;&#36825;&#20010;&#25351;&#26631;&#23545;&#20110;&#25919;&#31574;&#21046;&#23450;&#32773;&#21644;&#22312;&#32447;&#31038;&#21306;&#30340;&#31649;&#29702;&#21592;&#65288;&#22914;subreddits&#65289;&#20197;&#21450;&#35745;&#31639;&#31038;&#20250;&#31185;&#23398;&#23478;&#33267;&#20851;&#37325;&#35201;&#65292;&#20182;&#20204;&#21487;&#20197;&#26681;&#25454;&#24615;&#21035;&#27495;&#35270;&#31243;&#24230;&#20462;&#25913;&#31649;&#29702;&#31574;&#30053;&#65292;&#25110;&#32773;&#21305;&#37197;&#21644;&#27604;&#36739;&#19981;&#21516;&#24179;&#21488;&#21644;&#31038;&#21306;&#19978;&#30340;&#26102;&#24577;&#24615;&#21035;&#27495;&#35270;&#65292;&#20197;&#21450;&#25512;&#26029;&#31038;&#20250;&#31185;&#23398;&#35265;&#35299;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#27169;&#22411;&#65292;&#21487;&#20197;&#25552;&#20379;&#19968;&#20010;&#21487;&#27604;&#36739;&#30340;&#38024;&#23545;&#30007;&#24615;&#12289;&#22899;&#24615;&#36523;&#20221;&#20197;&#21450;&#30007;&#24615;&#12289;&#22899;&#24615;&#20010;&#20154;&#30340;&#27602;&#24615;&#25972;&#20307;&#25351;&#26631;&#12290;&#23613;&#31649;&#20808;&#21069;&#30340;&#30417;&#30563;NLP&#26041;&#27861;&#38656;&#35201;&#22312;&#30446;&#26631;&#32423;&#21035;&#23545;&#26377;&#27602;&#35780;&#35770;&#36827;&#34892;&#27880;&#37322;&#65288;&#20363;&#22914;&#27880;&#37322;&#29305;&#21035;&#38024;&#23545;&#22899;&#24615;&#26377;&#27602;&#30340;&#35780;&#35770;&#65289;&#26469;&#26816;&#27979;&#38024;&#23545;&#24615;&#26377;&#27602;&#35780;&#35770;&#65292;&#25105;&#20204;&#30340;&#25351;&#26631;&#21033;&#29992;&#30417;&#30563;&#24335;NLP&#26469;&#26816;&#27979;&#27602;&#24615;&#30340;&#23384;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02205v1 Announce Type: cross  Abstract: The online trend of the manosphere and feminist discourse on social networks requires a holistic measure of the level of sexism in an online community. This indicator is important for policymakers and moderators of online communities (e.g., subreddits) and computational social scientists, either to revise moderation strategies based on the degree of sexism or to match and compare the temporal sexism across different platforms and communities with real-time events and infer social scientific insights.   In this paper, we build a model that can provide a comparable holistic indicator of toxicity targeted toward male and female identity and male and female individuals. Despite previous supervised NLP methods that require annotation of toxic comments at the target level (e.g. annotating comments that are specifically toxic toward women) to detect targeted toxic comments, our indicator uses supervised NLP to detect the presence of toxicity 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22534;&#21472;&#33258;&#21160;&#32534;&#30721;&#22120;&#21644;&#32858;&#31867;&#23454;&#29616;&#36965;&#24863;&#25968;&#25454;&#22320;&#36136;&#21046;&#22270;&#30340;&#26080;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;</title><link>https://arxiv.org/abs/2404.02180</link><description>&lt;p&gt;
&#36890;&#36807;&#22534;&#21472;&#33258;&#21160;&#32534;&#30721;&#22120;&#21644;&#32858;&#31867;&#23454;&#29616;&#22320;&#36136;&#21046;&#22270;&#30340;&#36965;&#24863;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Remote sensing framework for geological mapping via stacked autoencoders and clustering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02180
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22534;&#21472;&#33258;&#21160;&#32534;&#30721;&#22120;&#21644;&#32858;&#31867;&#23454;&#29616;&#36965;&#24863;&#25968;&#25454;&#22320;&#36136;&#21046;&#22270;&#30340;&#26080;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26377;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#22312;&#36965;&#24863;&#22320;&#36136;&#21046;&#22270;&#20013;&#38754;&#20020;&#30528;&#30001;&#20110;&#20934;&#30830;&#26631;&#35760;&#35757;&#32451;&#25968;&#25454;&#30340;&#31232;&#32570;&#24615;&#32780;&#38480;&#21046;&#30340;&#38382;&#39064;&#12290;&#30456;&#21453;&#65292;&#26080;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#65292;&#22914;&#38477;&#32500;&#21644;&#32858;&#31867;&#65292;&#33021;&#22815;&#22312;&#19981;&#20381;&#36182;&#39044;&#23450;&#20041;&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#25581;&#31034;&#36965;&#24863;&#25968;&#25454;&#20013;&#30340;&#27169;&#24335;&#21644;&#32467;&#26500;&#12290;&#38477;&#32500;&#26041;&#27861;&#20855;&#26377;&#22312;&#25552;&#39640;&#22320;&#36136;&#22270;&#20934;&#30830;&#24615;&#26041;&#38754;&#21457;&#25381;&#20851;&#38190;&#20316;&#29992;&#30340;&#28508;&#21147;&#12290;&#34429;&#28982;&#20256;&#32479;&#30340;&#38477;&#32500;&#26041;&#27861;&#21487;&#33021;&#22312;&#38750;&#32447;&#24615;&#25968;&#25454;&#19978;&#36935;&#21040;&#22256;&#38590;&#65292;&#20294;&#26080;&#30417;&#30563;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#22914;&#33258;&#21160;&#32534;&#30721;&#22120;&#65292;&#33021;&#22815;&#27169;&#25311;&#25968;&#25454;&#20013;&#30340;&#38750;&#32447;&#24615;&#20851;&#31995;&#12290;&#22534;&#21472;&#33258;&#21160;&#32534;&#30721;&#22120;&#20855;&#26377;&#22810;&#20010;&#30456;&#20114;&#36830;&#25509;&#30340;&#23618;&#65292;&#29992;&#20110;&#25429;&#33719;&#23545;&#36965;&#24863;&#25968;&#25454;&#26377;&#29992;&#30340;&#20998;&#23618;&#25968;&#25454;&#34920;&#31034;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21033;&#29992;&#22534;&#21472;&#33258;&#21160;&#32534;&#30721;&#22120;&#21644;&#32858;&#31867;&#22788;&#29702;&#36965;&#24863;&#25968;&#25454;&#30340;&#26080;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02180v1 Announce Type: cross  Abstract: Supervised learning methods for geological mapping via remote sensing face limitations due to the scarcity of accurately labelled training data. In contrast, unsupervised learning methods, such as dimensionality reduction and clustering have the ability to uncover patterns and structures in remote sensing data without relying on predefined labels. Dimensionality reduction methods have the potential to play a crucial role in improving the accuracy of geological maps. Although conventional dimensionality reduction methods may struggle with nonlinear data, unsupervised deep learning models such as autoencoders have the ability to model nonlinear relationship in data. Stacked autoencoders feature multiple interconnected layers to capture hierarchical data representations that can be useful for remote sensing data. In this study, we present an unsupervised machine learning framework for processing remote sensing data by utilizing stacked au
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20174;&#23545;&#25239;&#30340;&#35282;&#24230;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26426;&#22120;&#36951;&#24536;&#35780;&#20272;&#26041;&#27861;&#65292;&#36890;&#36807;&#30830;&#23450;&#26368;&#20855;&#25361;&#25112;&#24615;&#30340;&#25968;&#25454;&#23376;&#38598;&#65292;&#21363;&#26368;&#22351;&#24773;&#20917;&#36951;&#24536;&#38598;&#65292;&#26469;&#22686;&#24378;&#23545;&#24433;&#21709;&#25830;&#38500;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2403.07362</link><description>&lt;p&gt;
&#25361;&#25112;&#36951;&#24536;&#65306;&#25581;&#31034;&#26426;&#22120;&#36951;&#24536;&#20013;&#26368;&#22351;&#24773;&#20917;&#36951;&#24536;&#38598;
&lt;/p&gt;
&lt;p&gt;
Challenging Forgets: Unveiling the Worst-Case Forget Sets in Machine Unlearning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07362
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20174;&#23545;&#25239;&#30340;&#35282;&#24230;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26426;&#22120;&#36951;&#24536;&#35780;&#20272;&#26041;&#27861;&#65292;&#36890;&#36807;&#30830;&#23450;&#26368;&#20855;&#25361;&#25112;&#24615;&#30340;&#25968;&#25454;&#23376;&#38598;&#65292;&#21363;&#26368;&#22351;&#24773;&#20917;&#36951;&#24536;&#38598;&#65292;&#26469;&#22686;&#24378;&#23545;&#24433;&#21709;&#25830;&#38500;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38752;&#35889;&#30340;&#26426;&#22120;&#23398;&#20064;(Machine Learning, ML)&#31038;&#21306;&#36234;&#26469;&#36234;&#35748;&#35782;&#21040;&#27169;&#22411;&#22312;&#35757;&#32451;&#21518;&#26377;&#36873;&#25321;&#24615;&#22320;&#8220;&#36951;&#24536;&#8221;&#25968;&#25454;&#28857;&#30340;&#37325;&#35201;&#24615;&#12290;&#36825;&#24341;&#20986;&#20102;&#26426;&#22120;&#36951;&#24536;(Machine Unlearning, MU)&#38382;&#39064;&#65292;&#26088;&#22312;&#28040;&#38500;&#36873;&#23450;&#25968;&#25454;&#28857;&#23545;&#27169;&#22411;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#21516;&#26102;&#20173;&#20445;&#25345;&#27169;&#22411;&#22312;&#36951;&#24536;&#21518;&#30340;&#23454;&#29992;&#24615;&#12290;&#23613;&#31649;&#26377;&#21508;&#31181;MU&#26041;&#27861;&#26469;&#25830;&#38500;&#25968;&#25454;&#24433;&#21709;&#65292;&#35780;&#20272;&#20027;&#35201;&#38598;&#20013;&#22312;&#38543;&#26426;&#25968;&#25454;&#36951;&#24536;&#19978;&#65292;&#24573;&#35270;&#20102;&#23545;&#20110;&#30495;&#23454;&#34913;&#37327;&#36951;&#24536;&#24615;&#33021;&#30340;&#25968;&#25454;&#23376;&#38598;&#36873;&#25321;&#30340;&#37325;&#35201;&#25506;&#31350;&#12290;&#20026;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#20174;&#23545;&#25239;&#30340;&#35282;&#24230;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;MU&#35780;&#20272;&#35270;&#35282;&#12290;&#25105;&#20204;&#25552;&#20986;&#30830;&#23450;&#37027;&#20123;&#23545;&#24433;&#21709;&#25830;&#38500;&#26500;&#25104;&#26368;&#22823;&#25361;&#25112;&#30340;&#25968;&#25454;&#23376;&#38598;&#65292;&#21363;&#25214;&#20986;&#26368;&#22351;&#24773;&#20917;&#36951;&#24536;&#38598;&#12290;&#21033;&#29992;&#21452;&#23618;&#20248;&#21270;&#21407;&#21017;&#65292;&#25105;&#20204;&#22686;&#24378;&#20102;&#22312;&#19978;&#23618;&#20248;&#21270;&#20013;&#30340;&#36951;&#24536;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07362v1 Announce Type: cross  Abstract: The trustworthy machine learning (ML) community is increasingly recognizing the crucial need for models capable of selectively 'unlearning' data points after training. This leads to the problem of machine unlearning (MU), aiming to eliminate the influence of chosen data points on model performance, while still maintaining the model's utility post-unlearning. Despite various MU methods for data influence erasure, evaluations have largely focused on random data forgetting, ignoring the vital inquiry into which subset should be chosen to truly gauge the authenticity of unlearning performance. To tackle this issue, we introduce a new evaluative angle for MU from an adversarial viewpoint. We propose identifying the data subset that presents the most significant challenge for influence erasure, i.e., pinpointing the worst-case forget set. Utilizing a bi-level optimization principle, we amplify unlearning challenges at the upper optimization 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;E2URec&#65292;&#36825;&#26159;&#20026;&#20102;&#35299;&#20915;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#36951;&#24536;&#29305;&#23450;&#29992;&#25143;&#25968;&#25454;&#25152;&#38754;&#20020;&#30340;&#25928;&#29575;&#21644;&#26377;&#25928;&#24615;&#26041;&#38754;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2403.03536</link><description>&lt;p&gt;
&#20026;&#25512;&#33616;&#32780;&#35774;&#35745;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#39640;&#25928;&#21644;&#26377;&#25928;&#30340;&#36951;&#24536;
&lt;/p&gt;
&lt;p&gt;
Towards Efficient and Effective Unlearning of Large Language Models for Recommendation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03536
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;E2URec&#65292;&#36825;&#26159;&#20026;&#20102;&#35299;&#20915;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#36951;&#24536;&#29305;&#23450;&#29992;&#25143;&#25968;&#25454;&#25152;&#38754;&#20020;&#30340;&#25928;&#29575;&#21644;&#26377;&#25928;&#24615;&#26041;&#38754;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#26174;&#33879;&#36827;&#23637;&#20135;&#29983;&#20102;&#19968;&#39033;&#26377;&#21069;&#36884;&#30340;&#30740;&#31350;&#26041;&#21521;&#65292;&#21363;&#21033;&#29992;LLMs&#20316;&#20026;&#25512;&#33616;&#31995;&#32479;&#65288;LLMRec&#65289;&#12290; LLMRec&#30340;&#26377;&#25928;&#24615;&#28304;&#33258;LLMs&#22266;&#26377;&#30340;&#24320;&#25918;&#19990;&#30028;&#30693;&#35782;&#21644;&#25512;&#29702;&#33021;&#21147;&#12290; LLMRec&#36890;&#36807;&#22522;&#20110;&#29992;&#25143;&#20114;&#21160;&#25968;&#25454;&#30340;&#25351;&#23548;&#35843;&#25972;&#33719;&#24471;&#25512;&#33616;&#21151;&#33021;&#12290; &#28982;&#32780;&#65292;&#20026;&#20102;&#20445;&#25252;&#29992;&#25143;&#38544;&#31169;&#24182;&#20248;&#21270;&#25928;&#29992;&#65292;LLMRec&#36824;&#24517;&#39035;&#26377;&#24847;&#24536;&#35760;&#29305;&#23450;&#29992;&#25143;&#25968;&#25454;&#65292;&#36825;&#36890;&#24120;&#31216;&#20026;&#25512;&#33616;&#36951;&#24536;&#12290; &#22312;LLMs&#26102;&#20195;&#65292;&#25512;&#33616;&#36951;&#24536;&#22312;\textit{&#25928;&#29575;}&#21644;\textit{&#26377;&#25928;&#24615;}&#26041;&#38754;&#20026;LLMRec&#24102;&#26469;&#20102;&#26032;&#25361;&#25112;&#12290; &#29616;&#26377;&#30340;&#36951;&#24536;&#26041;&#27861;&#38656;&#35201;&#26356;&#26032;LLMRec&#20013;&#25968;&#21313;&#20159;&#21442;&#25968;&#65292;&#36825;&#26159;&#26114;&#36149;&#19988;&#32791;&#26102;&#30340;&#12290; &#27492;&#22806;&#65292;&#23427;&#20204;&#22312;&#36951;&#24536;&#36807;&#31243;&#20013;&#24635;&#26159;&#24433;&#21709;&#27169;&#22411;&#25928;&#29992;&#12290; &#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;\textbf{E2URec}&#65292;&#31532;&#19968;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03536v1 Announce Type: cross  Abstract: The significant advancements in large language models (LLMs) give rise to a promising research direction, i.e., leveraging LLMs as recommenders (LLMRec). The efficacy of LLMRec arises from the open-world knowledge and reasoning capabilities inherent in LLMs. LLMRec acquires the recommendation capabilities through instruction tuning based on user interaction data. However, in order to protect user privacy and optimize utility, it is also crucial for LLMRec to intentionally forget specific user data, which is generally referred to as recommendation unlearning. In the era of LLMs, recommendation unlearning poses new challenges for LLMRec in terms of \textit{inefficiency} and \textit{ineffectiveness}. Existing unlearning methods require updating billions of parameters in LLMRec, which is costly and time-consuming. Besides, they always impact the model utility during the unlearning process. To this end, we propose \textbf{E2URec}, the first
&lt;/p&gt;</description></item><item><title>&#35777;&#26126;&#22312;1-D&#25968;&#25454;&#19978;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#31561;&#20215;&#20110;&#35299;&#20915;&#19968;&#20010;&#20855;&#26377;&#22266;&#23450;&#29305;&#24449;&#23383;&#20856;&#30697;&#38453;&#30340;&#20984;Lasso&#38382;&#39064;&#65292;&#20026;&#20840;&#23616;&#26368;&#20248;&#32593;&#32476;&#21644;&#35299;&#31354;&#38388;&#25552;&#20379;&#20102;&#27934;&#23519;&#12290;</title><link>https://arxiv.org/abs/2403.01046</link><description>&lt;p&gt;
&#19968;&#20010;&#38236;&#23376;&#30340;&#24211;&#65306;&#20302;&#32500;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26159;&#20855;&#26377;&#21453;&#23556;&#29305;&#24449;&#30340;&#20984;Lasso&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Library of Mirrors: Deep Neural Nets in Low Dimensions are Convex Lasso Models with Reflection Features
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01046
&lt;/p&gt;
&lt;p&gt;
&#35777;&#26126;&#22312;1-D&#25968;&#25454;&#19978;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#31561;&#20215;&#20110;&#35299;&#20915;&#19968;&#20010;&#20855;&#26377;&#22266;&#23450;&#29305;&#24449;&#23383;&#20856;&#30697;&#38453;&#30340;&#20984;Lasso&#38382;&#39064;&#65292;&#20026;&#20840;&#23616;&#26368;&#20248;&#32593;&#32476;&#21644;&#35299;&#31354;&#38388;&#25552;&#20379;&#20102;&#27934;&#23519;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;&#22312;1-D&#25968;&#25454;&#19978;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#31561;&#20215;&#20110;&#35299;&#20915;&#19968;&#20010;&#24102;&#26377;&#22266;&#23450;&#12289;&#26126;&#30830;&#23450;&#20041;&#30340;&#29305;&#24449;&#23383;&#20856;&#30697;&#38453;&#30340;&#20984;Lasso&#38382;&#39064;&#12290;&#20855;&#20307;&#30340;&#23383;&#20856;&#21462;&#20915;&#20110;&#28608;&#27963;&#20989;&#25968;&#21644;&#28145;&#24230;&#12290;&#25105;&#20204;&#32771;&#34385;&#20855;&#26377;&#20998;&#27573;&#32447;&#24615;&#28608;&#27963;&#20989;&#25968;&#30340;&#20004;&#23618;&#32593;&#32476;&#65292;&#28145;&#31364;&#30340;ReLU&#32593;&#32476;&#26368;&#22810;&#26377;4&#23618;&#65292;&#20197;&#21450;&#20855;&#26377;&#31526;&#21495;&#28608;&#27963;&#21644;&#20219;&#24847;&#28145;&#24230;&#30340;&#30697;&#24418;&#21644;&#26641;&#32593;&#32476;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#22312;ReLU&#32593;&#32476;&#20013;&#65292;&#31532;&#22235;&#23618;&#21019;&#24314;&#20195;&#34920;&#35757;&#32451;&#25968;&#25454;&#20851;&#20110;&#33258;&#36523;&#30340;&#21453;&#23556;&#30340;&#29305;&#24449;&#12290;Lasso&#34920;&#31034;&#27861;&#25581;&#31034;&#20102;&#20840;&#23616;&#26368;&#20248;&#32593;&#32476;&#21644;&#35299;&#31354;&#38388;&#30340;&#27934;&#23519;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01046v1 Announce Type: cross  Abstract: We prove that training neural networks on 1-D data is equivalent to solving a convex Lasso problem with a fixed, explicitly defined dictionary matrix of features. The specific dictionary depends on the activation and depth. We consider 2-layer networks with piecewise linear activations, deep narrow ReLU networks with up to 4 layers, and rectangular and tree networks with sign activation and arbitrary depth. Interestingly in ReLU networks, a fourth layer creates features that represent reflections of training data about themselves. The Lasso representation sheds insight to globally optimal networks and the solution landscape.
&lt;/p&gt;</description></item><item><title>LangGPT&#25552;&#20986;&#20102;&#19968;&#20010;&#21452;&#23618;&#25552;&#31034;&#35774;&#35745;&#26694;&#26550;&#65292;&#20316;&#20026;LLMs&#30340;&#32534;&#31243;&#35821;&#35328;&#65292;&#22823;&#22823;&#22686;&#24378;&#20102;LLMs&#20135;&#29983;&#39640;&#36136;&#37327;&#21709;&#24212;&#30340;&#33021;&#21147;&#65292;&#24182;&#22312;&#24341;&#23548;LLMs&#29983;&#25104;&#39640;&#36136;&#37327;&#25552;&#31034;&#26041;&#38754;&#20855;&#26377;&#26174;&#33879;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.16929</link><description>&lt;p&gt;
LangGPT&#65306;&#37325;&#26032;&#24605;&#32771;&#38754;&#21521;LLMs&#30340;&#32467;&#26500;&#21270;&#21487;&#37325;&#22797;&#20351;&#29992;&#25552;&#31034;&#35774;&#35745;&#26694;&#26550;&#20174;&#32534;&#31243;&#35821;&#35328;&#20986;&#21457;
&lt;/p&gt;
&lt;p&gt;
LangGPT: Rethinking Structured Reusable Prompt Design Framework for LLMs from the Programming Language
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16929
&lt;/p&gt;
&lt;p&gt;
LangGPT&#25552;&#20986;&#20102;&#19968;&#20010;&#21452;&#23618;&#25552;&#31034;&#35774;&#35745;&#26694;&#26550;&#65292;&#20316;&#20026;LLMs&#30340;&#32534;&#31243;&#35821;&#35328;&#65292;&#22823;&#22823;&#22686;&#24378;&#20102;LLMs&#20135;&#29983;&#39640;&#36136;&#37327;&#21709;&#24212;&#30340;&#33021;&#21147;&#65292;&#24182;&#22312;&#24341;&#23548;LLMs&#29983;&#25104;&#39640;&#36136;&#37327;&#25552;&#31034;&#26041;&#38754;&#20855;&#26377;&#26174;&#33879;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
LLMs&#24050;&#32463;&#23637;&#31034;&#20986;&#22312;&#19981;&#21516;&#39046;&#22495;&#21462;&#24471;&#20102;&#20196;&#20154;&#30633;&#30446;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#20026;&#20102;&#26377;&#25928;&#25351;&#23548;LLMs&#21046;&#23450;&#39640;&#36136;&#37327;&#30340;&#25552;&#31034;&#23545;&#20110;&#38750;AI&#19987;&#23478;&#26469;&#35828;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;&#29616;&#26377;&#30340;&#25552;&#31034;&#24037;&#31243;&#30740;&#31350;&#24314;&#35758;&#20102;&#19968;&#20123;&#30053;&#26174;&#38646;&#30862;&#30340;&#20248;&#21270;&#21407;&#21017;&#21644;&#35774;&#35745;&#65292;&#20197;&#21450;&#20973;&#32463;&#39564;&#20381;&#36182;&#30340;&#25552;&#31034;&#20248;&#21270;&#22120;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#36825;&#20123;&#21162;&#21147;&#32570;&#20047;&#19968;&#20010;&#32467;&#26500;&#21270;&#30340;&#35774;&#35745;&#27169;&#26495;&#65292;&#23548;&#33268;&#23398;&#20064;&#25104;&#26412;&#39640;&#65292;&#37325;&#22797;&#20351;&#29992;&#24615;&#20302;&#12290;&#21463;&#32467;&#26500;&#21270;&#21487;&#37325;&#22797;&#20351;&#29992;&#30340;&#32534;&#31243;&#35821;&#35328;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;LangGPT&#65292;&#20316;&#20026;LLMs&#30340;&#32534;&#31243;&#35821;&#35328;&#30340;&#21452;&#23618;&#25552;&#31034;&#35774;&#35745;&#26694;&#26550;&#12290;LangGPT&#20855;&#26377;&#26131;&#20110;&#23398;&#20064;&#30340;&#35268;&#33539;&#32467;&#26500;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#25193;&#23637;&#32467;&#26500;&#20197;&#36827;&#34892;&#36801;&#31227;&#21644;&#37325;&#29992;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#19982;&#22522;&#20934;&#30456;&#27604;&#65292;LangGPT&#26174;&#33879;&#22686;&#24378;&#20102;LLMs&#20135;&#29983;&#39640;&#36136;&#37327;&#21709;&#24212;&#30340;&#33021;&#21147;&#12290;&#27492;&#22806;&#65292;LangGPT&#24050;&#34987;&#35777;&#26126;&#22312;&#24341;&#23548;LLMs&#29983;&#25104;&#39640;&#36136;&#37327;&#25552;&#31034;&#26041;&#38754;&#26159;&#26377;&#25928;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16929v1 Announce Type: cross  Abstract: LLMs have demonstrated commendable performance across diverse domains. Nevertheless, formulating high-quality prompts to effectively instruct LLMs poses a challenge for non-AI experts. Existing research in prompt engineering suggests somewhat fragmented optimization principles and designs empirically dependent prompt optimizers. Unfortunately, these endeavors lack a structured design template, incurring high learning costs and resulting in low reusability. Inspired by structured reusable programming languages, we propose LangGPT, a dual-layer prompt design framework as the programming language for LLMs. LangGPT has an easy-to-learn normative structure and provides an extended structure for migration and reuse. Experiments illustrate that LangGPT significantly enhances the capacity of LLMs to produce responses of superior quality compared to baselines. Moreover, LangGPT has proven effective in guiding LLMs to generate high-quality promp
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#27604;&#36739;&#20102; GPT-4 &#21644; MTurk &#31649;&#36947;&#30340;&#25968;&#25454;&#26631;&#27880;&#20934;&#30830;&#24615;&#65292;&#21457;&#29616;&#23613;&#31649; MTurk &#37319;&#29992;&#20102;&#26368;&#20339;&#23454;&#36341;&#65292;&#20294; GPT-4 &#30340;&#20934;&#30830;&#29575;&#26356;&#39640;&#65292;&#24182;&#19988;&#32467;&#21512; GPT-4 &#21644;&#20247;&#21253;&#26631;&#31614;&#20351;&#29992;&#32858;&#21512;&#31639;&#27861;&#21487;&#20197;&#25552;&#39640;&#20934;&#30830;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.16795</link><description>&lt;p&gt;
&#22914;&#26524;&#22312;&#19968;&#20010;&#20247;&#21253;&#25968;&#25454;&#26631;&#27880;&#31649;&#36947;&#20013;&#65292;GPT-4
&lt;/p&gt;
&lt;p&gt;
If in a Crowdsourced Data Annotation Pipeline, a GPT-4
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16795
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27604;&#36739;&#20102; GPT-4 &#21644; MTurk &#31649;&#36947;&#30340;&#25968;&#25454;&#26631;&#27880;&#20934;&#30830;&#24615;&#65292;&#21457;&#29616;&#23613;&#31649; MTurk &#37319;&#29992;&#20102;&#26368;&#20339;&#23454;&#36341;&#65292;&#20294; GPT-4 &#30340;&#20934;&#30830;&#29575;&#26356;&#39640;&#65292;&#24182;&#19988;&#32467;&#21512; GPT-4 &#21644;&#20247;&#21253;&#26631;&#31614;&#20351;&#29992;&#32858;&#21512;&#31639;&#27861;&#21487;&#20197;&#25552;&#39640;&#20934;&#30830;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;GPT-4&#22312;&#25968;&#25454;&#26631;&#27880;&#20934;&#30830;&#24615;&#26041;&#38754;&#20248;&#20110;&#22312;&#32447;&#20247;&#21253;&#24037;&#20316;&#32773;&#65292;&#23588;&#20854;&#26159;&#26469;&#33258;&#20122;&#39532;&#36874;&#26426;&#26800;&#22303;&#32819;&#20854;&#65288;MTurk&#65289;&#30340;&#24037;&#20316;&#32773;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#30740;&#31350;&#22240;&#20559;&#31163;&#26631;&#20934;&#20247;&#21253;&#23454;&#36341;&#24182;&#24378;&#35843;&#20010;&#21035;&#24037;&#20316;&#32773;&#30340;&#34920;&#29616;&#32780;&#21463;&#21040;&#25209;&#35780;&#65292;&#32780;&#19981;&#26159;&#25972;&#20010;&#25968;&#25454;&#26631;&#27880;&#36807;&#31243;&#12290;&#26412;&#25991;&#27604;&#36739;&#20102;GPT-4&#21644;&#19968;&#20010;&#36947;&#24503;&#19988;&#25191;&#34892;&#33391;&#22909;&#30340;MTurk&#31649;&#36947;&#65292;&#20351;&#29992;415&#21517;&#24037;&#20316;&#32773;&#26631;&#27880;&#20102;&#26469;&#33258;200&#31687;&#23398;&#26415;&#25991;&#31456;&#30340;3,177&#20010;&#21477;&#27573;&#65292;&#20351;&#29992;&#20102;CODA-19&#26041;&#26696;&#12290;&#20004;&#20010;&#24037;&#20316;&#32773;&#30028;&#38754;&#20135;&#29983;&#20102;127,080&#20010;&#26631;&#31614;&#65292;&#28982;&#21518;&#36890;&#36807;&#20843;&#31181;&#26631;&#31614;&#32858;&#21512;&#31639;&#27861;&#25512;&#26029;&#20986;&#26368;&#32456;&#30340;&#26631;&#31614;&#12290;&#25105;&#20204;&#30340;&#35780;&#20272;&#32467;&#26524;&#26174;&#31034;&#65292;&#23613;&#31649;&#37319;&#29992;&#20102;&#26368;&#20339;&#23454;&#36341;&#65292;MTurk&#31649;&#36947;&#30340;&#26368;&#39640;&#20934;&#30830;&#29575;&#20026;81.5%&#65292;&#32780;GPT-4&#36798;&#21040;&#20102;83.6%&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#24403;&#23558;GPT-4&#30340;&#26631;&#31614;&#19982;&#36890;&#36807;&#20808;&#36827;&#24037;&#20316;&#32773;&#30028;&#38754;&#25910;&#38598;&#30340;&#20247;&#21253;&#26631;&#31614;&#32467;&#21512;&#36215;&#26469;&#36827;&#34892;&#32858;&#21512;&#26102;&#65292;8&#31181;&#31639;&#27861;&#20013;&#26377;2&#31181;&#23454;&#29616;&#20102;&#26356;&#39640;&#30340;&#20934;&#30830;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16795v1 Announce Type: cross  Abstract: Recent studies indicated GPT-4 outperforms online crowd workers in data labeling accuracy, notably workers from Amazon Mechanical Turk (MTurk). However, these studies were criticized for deviating from standard crowdsourcing practices and emphasizing individual workers' performances over the whole data-annotation process. This paper compared GPT-4 and an ethical and well-executed MTurk pipeline, with 415 workers labeling 3,177 sentence segments from 200 scholarly articles using the CODA-19 scheme. Two worker interfaces yielded 127,080 labels, which were then used to infer the final labels through eight label-aggregation algorithms. Our evaluation showed that despite best practices, MTurk pipeline's highest accuracy was 81.5%, whereas GPT-4 achieved 83.6%. Interestingly, when combining GPT-4's labels with crowd labels collected via an advanced worker interface for aggregation, 2 out of the 8 algorithms achieved an even higher accuracy (
&lt;/p&gt;</description></item><item><title>&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#19982;&#33258;&#36866;&#24212;&#23398;&#20064;&#27010;&#24565;&#30340;&#20132;&#21449;&#30740;&#31350;&#23558;&#23545;&#25945;&#32946;&#20013;&#19979;&#19968;&#38454;&#27573;&#23398;&#20064;&#26684;&#24335;&#30340;&#21457;&#23637;&#20570;&#20986;&#37325;&#35201;&#36129;&#29486;&#12290;</title><link>https://arxiv.org/abs/2402.14601</link><description>&lt;p&gt;
&#23558;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#24341;&#20837;&#25945;&#32946;&#20013;&#30340;&#33258;&#36866;&#24212;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Bringing Generative AI to Adaptive Learning in Education
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14601
&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#19982;&#33258;&#36866;&#24212;&#23398;&#20064;&#27010;&#24565;&#30340;&#20132;&#21449;&#30740;&#31350;&#23558;&#23545;&#25945;&#32946;&#20013;&#19979;&#19968;&#38454;&#27573;&#23398;&#20064;&#26684;&#24335;&#30340;&#21457;&#23637;&#20570;&#20986;&#37325;&#35201;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#30340;&#28608;&#22686;&#65292;&#22914;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#25193;&#25955;&#27169;&#22411;&#65292;&#25512;&#21160;&#20102;&#20154;&#24037;&#26234;&#33021;&#22312;&#31185;&#23398;&#12289;&#37329;&#34701;&#21644;&#25945;&#32946;&#31561;&#21508;&#20010;&#39046;&#22495;&#30340;&#24212;&#29992;&#21457;&#23637;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#33258;&#36866;&#24212;&#23398;&#20064;&#36825;&#19968;&#27010;&#24565;&#22312;&#25945;&#32946;&#39046;&#22495;&#24341;&#36215;&#20102;&#26497;&#22823;&#20851;&#27880;&#65292;&#24182;&#35777;&#26126;&#20854;&#22312;&#25552;&#39640;&#23398;&#29983;&#23398;&#20064;&#25928;&#29575;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;&#22312;&#26412;&#31435;&#22330;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#25506;&#35752;&#23558;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#19982;&#33258;&#36866;&#24212;&#23398;&#20064;&#27010;&#24565;&#32467;&#21512;&#36215;&#26469;&#30340;&#20132;&#21449;&#30740;&#31350;&#12290;&#36890;&#36807;&#35752;&#35770;&#36825;&#19968;&#39046;&#22495;&#30340;&#22909;&#22788;&#12289;&#25361;&#25112;&#21644;&#28508;&#21147;&#65292;&#25105;&#20204;&#35748;&#20026;&#36825;&#31181;&#32467;&#21512;&#23558;&#20026;&#25945;&#32946;&#20013;&#19979;&#19968;&#38454;&#27573;&#23398;&#20064;&#24418;&#24335;&#30340;&#21457;&#23637;&#20570;&#20986;&#37325;&#35201;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14601v1 Announce Type: cross  Abstract: The recent surge in generative AI technologies, such as large language models and diffusion models, have boosted the development of AI applications in various domains, including science, finance, and education. Concurrently, adaptive learning, a concept that has gained substantial interest in the educational sphere, has proven its efficacy in enhancing students' learning efficiency. In this position paper, we aim to shed light on the intersectional studies of these two methods, which combine generative AI with adaptive learning concepts. By presenting discussions about the benefits, challenges, and potentials in this field, we argue that this union will contribute significantly to the development of the next stage learning format in education.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38754;&#21521;&#25351;&#20196;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#33258;&#21160;&#35780;&#20272;&#26041;&#27861;&#30340;&#21487;&#38752;&#24615;&#65292;&#21457;&#29616;&#33258;&#21160;&#26041;&#27861;&#22312;&#19981;&#21516;&#20219;&#21153;&#31867;&#22411;&#19979;&#19982;&#20154;&#24037;&#35780;&#20272;&#32773;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#23384;&#22312;&#24040;&#22823;&#21464;&#21270;&#65292;&#19988;&#22312;&#33258;&#30001;&#24418;&#24335;&#29983;&#25104;&#20219;&#21153;&#21644;&#36328;&#35821;&#35328;&#36716;&#31227;&#20013;&#21487;&#33021;&#19981;&#21487;&#38752;&#12290;</title><link>https://arxiv.org/abs/2402.10770</link><description>&lt;p&gt;
&#33258;&#21160;&#35780;&#20272;&#26041;&#27861;&#22312;&#38754;&#21521;&#25351;&#20196;&#30340;LLM&#20013;&#26377;&#22810;&#21487;&#38752;&#65311;
&lt;/p&gt;
&lt;p&gt;
How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10770
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38754;&#21521;&#25351;&#20196;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#33258;&#21160;&#35780;&#20272;&#26041;&#27861;&#30340;&#21487;&#38752;&#24615;&#65292;&#21457;&#29616;&#33258;&#21160;&#26041;&#27861;&#22312;&#19981;&#21516;&#20219;&#21153;&#31867;&#22411;&#19979;&#19982;&#20154;&#24037;&#35780;&#20272;&#32773;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#23384;&#22312;&#24040;&#22823;&#21464;&#21270;&#65292;&#19988;&#22312;&#33258;&#30001;&#24418;&#24335;&#29983;&#25104;&#20219;&#21153;&#21644;&#36328;&#35821;&#35328;&#36716;&#31227;&#20013;&#21487;&#33021;&#19981;&#21487;&#38752;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38754;&#21521;&#25351;&#20196;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#30340;&#30740;&#31350;&#20351;&#29992;&#22522;&#20110;&#25991;&#26412;&#37325;&#21472;&#21644;LLM&#21028;&#26029;&#30340;&#33258;&#21160;&#26041;&#27861;&#20316;&#20026;&#20154;&#24037;&#35780;&#20272;&#30340;&#25104;&#26412;&#26377;&#25928;&#26367;&#20195;&#26041;&#26696;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#36825;&#20123;&#26041;&#27861;&#22312;&#24191;&#27867;&#30340;&#20219;&#21153;&#33539;&#22260;&#21644;&#36328;&#35821;&#35328;&#29615;&#22659;&#20013;&#30340;&#21487;&#38752;&#24615;&#12290;&#19982;&#20808;&#21069;&#30340;&#30740;&#31350;&#32467;&#26524;&#30456;&#21453;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#22312;&#20219;&#21153;&#31867;&#22411;&#19981;&#21516;&#30340;&#24773;&#20917;&#19979;&#65292;&#33258;&#21160;&#26041;&#27861;&#19982;&#20154;&#24037;&#35780;&#20272;&#32773;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#23384;&#22312;&#26174;&#33879;&#21464;&#21270;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#24191;&#27867;&#20351;&#29992;&#30340;ROUGE-L&#24230;&#37327;&#22312;&#30701;&#31572;&#26696;&#33521;&#35821;&#20219;&#21153;&#20013;&#19982;&#20154;&#31867;&#21028;&#26029;&#24378;&#30456;&#20851;&#65292;&#20294;&#22312;&#33258;&#30001;&#24418;&#24335;&#29983;&#25104;&#20219;&#21153;&#21644;&#36328;&#35821;&#35328;&#36716;&#31227;&#20013;&#19981;&#21487;&#38752;&#12290;&#20351;&#29992;GPT-4&#20316;&#20026;&#35780;&#20272;&#21592;&#30340;&#26377;&#25928;&#24615;&#21462;&#20915;&#20110;&#22312;&#35201;&#27714;&#35780;&#20272;&#26102;&#21253;&#21547;&#21442;&#32771;&#31572;&#26696;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#22312;&#33258;&#30001;&#24418;&#24335;&#29983;&#25104;&#20219;&#21153;&#20013;&#35780;&#20272;&#36807;&#20110;&#20005;&#26684;&#12290;&#24635;&#30340;&#26469;&#35828;&#65292;&#25105;&#20204;&#21457;&#29616;&#65292;&#23613;&#31649;&#33258;&#21160;&#35780;&#20272;&#26041;&#27861;&#21487;&#20197;&#36817;&#20284;&#20154;&#31867;&#21028;&#26029;&#65292;&#20294;&#20854;&#20934;&#30830;&#24615;&#21487;&#33021;&#22240;&#20219;&#21153;&#31867;&#22411;&#21644;&#35780;&#20272;&#35774;&#32622;&#32780;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10770v1 Announce Type: cross  Abstract: Work on instruction-tuned Large Language Models (LLMs) has used automatic methods based on text overlap and LLM judgments as cost-effective alternatives to human evaluation. In this paper, we study the reliability of such methods across a broad range of tasks and in a cross-lingual setting. In contrast to previous findings, we observe considerable variability in correlations between automatic methods and human evaluators when scores are differentiated by task type. Specifically, the widely-used ROUGE-L metric strongly correlates with human judgments for short-answer English tasks but is unreliable in free-form generation tasks and cross-lingual transfer. The effectiveness of GPT-4 as an evaluator depends on including reference answers when prompting for assessments, which can lead to overly strict evaluations in free-form generation tasks. In summary, we find that, while automatic evaluation methods can approximate human judgements und
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;LLMs&#21644;&#36923;&#36753;&#20013;&#38388;&#34920;&#31034;&#26469;&#29983;&#25104;&#20934;&#30830;&#30340;"&#25991;&#26412;&#21040;&#35745;&#21010;"&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#23558;LLMs&#29992;&#20110;&#29983;&#25104;&#35745;&#21010;&#20219;&#21153;&#35831;&#27714;&#30340;PDDL&#34920;&#31034;&#20197;&#21450;&#32463;&#20856;&#35268;&#21010;&#22120;&#30340;&#20351;&#29992;&#65292;&#33021;&#22815;&#26356;&#22909;&#22320;&#35299;&#20915;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#35745;&#21010;&#20219;&#21153;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;</title><link>https://arxiv.org/abs/2402.06608</link><description>&lt;p&gt;
TIC&#65306;&#21033;&#29992;LLMs&#21644;&#36923;&#36753;&#20013;&#38388;&#34920;&#31034;&#31934;&#30830;&#36827;&#34892;&#8220;&#25991;&#26412;&#21040;&#35745;&#21010;&#8221;&#30340;&#32763;&#35793;-&#25512;&#26029;-&#32534;&#35793;
&lt;/p&gt;
&lt;p&gt;
TIC: Translate-Infer-Compile for accurate 'text to plan' using LLMs and logical intermediate representations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06608
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;LLMs&#21644;&#36923;&#36753;&#20013;&#38388;&#34920;&#31034;&#26469;&#29983;&#25104;&#20934;&#30830;&#30340;"&#25991;&#26412;&#21040;&#35745;&#21010;"&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#23558;LLMs&#29992;&#20110;&#29983;&#25104;&#35745;&#21010;&#20219;&#21153;&#35831;&#27714;&#30340;PDDL&#34920;&#31034;&#20197;&#21450;&#32463;&#20856;&#35268;&#21010;&#22120;&#30340;&#20351;&#29992;&#65292;&#33021;&#22815;&#26356;&#22909;&#22320;&#35299;&#20915;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#35745;&#21010;&#20219;&#21153;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20026;&#32473;&#23450;&#30340;&#33258;&#28982;&#35821;&#35328;&#35745;&#21010;&#20219;&#21153;&#35831;&#27714;&#29983;&#25104;&#35745;&#21010;&#30340;&#38382;&#39064;&#12290;&#19968;&#26041;&#38754;&#65292;LLMs&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#22312;&#35745;&#21010;&#26041;&#38754;&#34920;&#29616;&#19981;&#20339;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#32463;&#20856;&#35745;&#21010;&#24037;&#20855;&#22312;&#35745;&#21010;&#20219;&#21153;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#38656;&#35201;&#20351;&#29992;&#32467;&#26500;&#21270;&#35821;&#35328;&#65288;&#22914;Planning Domain Definition Language&#65288;PDDL&#65289;&#65289;&#20316;&#20026;&#36755;&#20837;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#20004;&#31181;&#25216;&#26415;&#30340;&#20248;&#28857;&#65292;&#36890;&#36807;&#20351;&#29992;LLMs&#29983;&#25104;&#35745;&#21010;&#20219;&#21153;&#35831;&#27714;&#30340;PDDL&#34920;&#31034;&#65288;&#20219;&#21153;PDDL&#65289;&#65292;&#28982;&#21518;&#20351;&#29992;&#32463;&#20856;&#35268;&#21010;&#22120;&#35745;&#31639;&#35745;&#21010;&#12290;&#19982;&#30452;&#25509;&#20351;&#29992;LLMs&#29983;&#25104;&#20219;&#21153;PDDL&#30340;&#20808;&#21069;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21253;&#25324;&#65288;a&#65289;&#32763;&#35793;&#65306;&#20165;&#20351;&#29992;LLMs&#29983;&#25104;&#33258;&#28982;&#35821;&#35328;&#20219;&#21153;&#25551;&#36848;&#30340;&#36923;&#36753;&#21487;&#35299;&#37322;&#30340;&#20013;&#38388;&#34920;&#31034;&#65292;&#65288;b&#65289;&#25512;&#26029;&#65306;&#20351;&#29992;&#36923;&#36753;&#25512;&#29702;&#22120;&#65288;&#30446;&#21069;&#26159;Answer Set Programming solver&#65289;&#20174;&#20013;&#38388;&#34920;&#31034;&#20013;&#25512;&#23548;&#20986;&#39069;&#22806;&#30340;&#36923;&#36753;&#30456;&#20851;&#20449;&#24687;&#65292;&#20197;&#21450;&#65288;c&#65289;&#32534;&#35793;&#65306;&#29983;&#25104;&#30446;&#26631;&#35745;&#21010;&#30340;PDDL&#25551;&#36848;&#30340;&#32534;&#35793;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of generating plans for given natural language planning task requests. On one hand, LLMs excel at natural language processing but do not perform well on planning. On the other hand, classical planning tools excel at planning tasks but require input in a structured language such as the Planning Domain Definition Language (PDDL). We leverage the strengths of both the techniques by using an LLM for generating the PDDL representation (task PDDL) of planning task requests followed by using a classical planner for computing a plan. Unlike previous approaches that use LLMs for generating task PDDLs directly, our approach comprises of (a) translate: using an LLM only for generating a logically interpretable intermediate representation of natural language task descriptions, (b) infer: deriving additional logically dependent information from the intermediate representation using a logic reasoner (currently, Answer Set Programming solver), and (c) compile: generating the targ
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#20462;&#21098;&#21644;&#20302;&#31209;&#20462;&#25913;&#65292;&#21457;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#23433;&#20840;&#26426;&#21046;&#22266;&#26377;&#26131;&#30862;&#24615;&#65292;&#21435;&#38500;&#23433;&#20840;&#20851;&#38190;&#21306;&#22495;&#20250;&#25439;&#23475;&#23433;&#20840;&#24615;&#65292;&#20294;&#23545;&#25928;&#29992;&#24433;&#21709;&#19981;&#22823;&#65292;&#38656;&#35201;&#26356;&#24378;&#20581;&#30340;&#23433;&#20840;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2402.05162</link><description>&lt;p&gt;
&#36890;&#36807;&#20462;&#21098;&#21644;&#20302;&#31209;&#20462;&#25913;&#35780;&#20272;&#23433;&#20840;&#23545;&#40784;&#30340;&#26131;&#30862;&#24615;
&lt;/p&gt;
&lt;p&gt;
Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank Modifications
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05162
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#20462;&#21098;&#21644;&#20302;&#31209;&#20462;&#25913;&#65292;&#21457;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#23433;&#20840;&#26426;&#21046;&#22266;&#26377;&#26131;&#30862;&#24615;&#65292;&#21435;&#38500;&#23433;&#20840;&#20851;&#38190;&#21306;&#22495;&#20250;&#25439;&#23475;&#23433;&#20840;&#24615;&#65292;&#20294;&#23545;&#25928;&#29992;&#24433;&#21709;&#19981;&#22823;&#65292;&#38656;&#35201;&#26356;&#24378;&#20581;&#30340;&#23433;&#20840;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#20854;&#23433;&#20840;&#26426;&#21046;&#26041;&#38754;&#34920;&#29616;&#20986;&#22266;&#26377;&#30340;&#26131;&#30862;&#24615;&#65292;&#36825;&#21487;&#20174;&#23427;&#20204;&#26131;&#21463;&#36234;&#29425;&#21644;&#21363;&#20351;&#26159;&#38750;&#24694;&#24847;&#24494;&#35843;&#20063;&#26131;&#21463;&#24433;&#21709;&#26469;&#35828;&#26126;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#21033;&#29992;&#20462;&#21098;&#21644;&#20302;&#31209;&#20462;&#25913;&#25506;&#35752;&#20102;&#23433;&#20840;&#23545;&#40784;&#30340;&#26131;&#30862;&#24615;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#26041;&#27861;&#65292;&#33021;&#22815;&#35782;&#21035;&#23545;&#20110;&#23433;&#20840;&#38450;&#25252;&#33267;&#20851;&#37325;&#35201;&#65292;&#19988;&#22312;&#31070;&#32463;&#20803;&#21644;&#31209;&#32423;&#21035;&#19978;&#19982;&#25928;&#29992;&#30456;&#20851;&#30340;&#21306;&#22495;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;&#30340;&#23396;&#31435;&#21306;&#22495;&#26159;&#31232;&#30095;&#30340;&#65292;&#32422;&#21344;&#21442;&#25968;&#32423;&#21035;&#30340;$3\%$&#21644;&#25490;&#21517;&#32423;&#21035;&#30340;$2.5\%$&#12290;&#21435;&#38500;&#36825;&#20123;&#21306;&#22495;&#20250;&#25439;&#23475;&#23433;&#20840;&#24615;&#65292;&#32780;&#23545;&#25928;&#29992;&#30340;&#24433;&#21709;&#19981;&#22823;&#65292;&#20174;&#32780;&#35777;&#23454;&#20102;&#35813;&#27169;&#22411;&#23433;&#20840;&#26426;&#21046;&#30340;&#22266;&#26377;&#26131;&#30862;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#34920;&#26126;&#65292;&#21363;&#20351;&#38480;&#21046;&#23545;&#23433;&#20840;&#20851;&#38190;&#21306;&#22495;&#36827;&#34892;&#20462;&#25913;&#65292;LLMs&#20173;&#28982;&#23481;&#26131;&#21463;&#21040;&#20302;&#25104;&#26412;&#30340;&#24494;&#35843;&#25915;&#20987;&#12290;&#36825;&#20123;&#21457;&#29616;&#24378;&#35843;&#20102;&#22312;LLMs&#20013;&#26356;&#24378;&#22823;&#30340;&#23433;&#20840;&#31574;&#30053;&#30340;&#32039;&#36843;&#24615;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) show inherent brittleness in their safety mechanisms, as evidenced by their susceptibility to jailbreaking and even non-malicious fine-tuning. This study explores this brittleness of safety alignment by leveraging pruning and low-rank modifications. We develop methods to identify critical regions that are vital for safety guardrails, and that are disentangled from utility-relevant regions at both the neuron and rank levels. Surprisingly, the isolated regions we find are sparse, comprising about $3\%$ at the parameter level and $2.5\%$ at the rank level. Removing these regions compromises safety without significantly impacting utility, corroborating the inherent brittleness of the model's safety mechanisms. Moreover, we show that LLMs remain vulnerable to low-cost fine-tuning attacks even when modifications to the safety-critical regions are restricted. These findings underscore the urgent need for more robust safety strategies in LLMs.
&lt;/p&gt;</description></item><item><title>CodeIt&#26159;&#19968;&#31181;&#20855;&#22791;&#20248;&#20808;&#32423;&#22238;&#39038;&#37325;&#25918;&#30340;&#33258;&#25105;&#25913;&#36827;&#35821;&#35328;&#27169;&#22411;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#30446;&#26631;&#37325;&#26631;&#35760;&#20026;&#37319;&#26679;&#31243;&#24207;&#30340;&#23454;&#38469;&#36755;&#20986;&#65292;&#26377;&#25928;&#35299;&#20915;&#20102;&#31243;&#24207;&#21512;&#25104;&#20013;&#22870;&#21169;&#31232;&#30095;&#24615;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#25277;&#35937;&#21644;&#25512;&#29702;&#35821;&#26009;&#24211;&#65288;ARC&#65289;&#19978;&#23454;&#29616;&#20102;&#25104;&#21151;&#30340;&#36328;&#20219;&#21153;&#27867;&#21270;&#12290;</title><link>https://arxiv.org/abs/2402.04858</link><description>&lt;p&gt;
CodeIt&#65306;&#20855;&#26377;&#20248;&#20808;&#32423;&#22238;&#39038;&#37325;&#25918;&#30340;&#33258;&#25105;&#25913;&#36827;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
CodeIt: Self-Improving Language Models with Prioritized Hindsight Replay
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04858
&lt;/p&gt;
&lt;p&gt;
CodeIt&#26159;&#19968;&#31181;&#20855;&#22791;&#20248;&#20808;&#32423;&#22238;&#39038;&#37325;&#25918;&#30340;&#33258;&#25105;&#25913;&#36827;&#35821;&#35328;&#27169;&#22411;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#30446;&#26631;&#37325;&#26631;&#35760;&#20026;&#37319;&#26679;&#31243;&#24207;&#30340;&#23454;&#38469;&#36755;&#20986;&#65292;&#26377;&#25928;&#35299;&#20915;&#20102;&#31243;&#24207;&#21512;&#25104;&#20013;&#22870;&#21169;&#31232;&#30095;&#24615;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#25277;&#35937;&#21644;&#25512;&#29702;&#35821;&#26009;&#24211;&#65288;ARC&#65289;&#19978;&#23454;&#29616;&#20102;&#25104;&#21151;&#30340;&#36328;&#20219;&#21153;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36234;&#26469;&#36234;&#33021;&#22815;&#35299;&#20915;&#36890;&#24120;&#34987;&#35748;&#20026;&#38656;&#35201;&#20154;&#31867;&#27700;&#24179;&#25512;&#29702;&#33021;&#21147;&#30340;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#22312;&#36890;&#29992;&#26234;&#33021;&#22522;&#20934;&#27979;&#35797;&#20363;&#22914;&#25277;&#35937;&#21644;&#25512;&#29702;&#35821;&#26009;&#24211;&#65288;ARC&#65289;&#19978;&#34920;&#29616;&#20173;&#28982;&#38750;&#24120;&#24046;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;ARC&#35270;&#20026;&#19968;&#20010;&#20197;&#32534;&#31243;&#31034;&#20363;&#20026;&#22522;&#30784;&#30340;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;Code Iteration&#65288;CodeIt&#65289;&#30340;&#26032;&#39062;&#19988;&#21487;&#25193;&#23637;&#30340;&#35821;&#35328;&#27169;&#22411;&#33258;&#25105;&#25913;&#36827;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;1&#65289;&#31243;&#24207;&#25277;&#26679;&#21644;&#22238;&#39038;&#37325;&#26631;&#35760;&#20197;&#21450;2&#65289;&#22522;&#20110;&#20248;&#20808;&#32423;&#30340;&#32463;&#39564;&#22238;&#25918;&#20043;&#38388;&#36827;&#34892;&#36845;&#20195;&#12290;&#36890;&#36807;&#23558;&#19968;&#20010;episode&#30340;&#30446;&#26631;&#65288;&#21363;&#32473;&#23450;&#36755;&#20837;&#30340;&#30446;&#26631;&#31243;&#24207;&#36755;&#20986;&#65289;&#37325;&#26631;&#35760;&#20026;&#37319;&#26679;&#31243;&#24207;&#20135;&#29983;&#30340;&#23454;&#38469;&#36755;&#20986;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26377;&#25928;&#22320;&#22788;&#29702;&#20102;&#31243;&#24207;&#21512;&#25104;&#20013;&#22870;&#21169;&#26497;&#24230;&#31232;&#30095;&#24615;&#30340;&#38382;&#39064;&#12290;&#24212;&#29992;CodeIt&#20110;ARC&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20248;&#20808;&#32423;&#22238;&#39038;&#37325;&#25918;&#12289;&#39044;&#35757;&#32451;&#21644;&#25968;&#25454;&#22686;&#24378;&#21487;&#20197;&#23454;&#29616;&#25104;&#21151;&#30340;&#36328;&#20219;&#21153;&#27867;&#21270;&#12290;CodeIt&#26159;&#31532;&#19968;&#20010;&#31070;&#32463;&#20803;-&#21512;&#25104;&#26426;&#21046;&#19968;&#20307;&#30340;&#33258;&#25105;&#25913;&#36827;&#35821;&#35328;&#27169;&#22411;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models are increasingly solving tasks that are commonly believed to require human-level reasoning ability. However, these models still perform very poorly on benchmarks of general intelligence such as the Abstraction and Reasoning Corpus (ARC). In this paper, we approach ARC as a programming-by-examples problem, and introduce a novel and scalable method for language model self-improvement called Code Iteration (CodeIt). Our method iterates between 1) program sampling and hindsight relabeling, and 2) learning from prioritized experience replay. By relabeling the goal of an episode (i.e., the target program output given input) to the realized output produced by the sampled program, our method effectively deals with the extreme sparsity of rewards in program synthesis. Applying CodeIt to the ARC dataset, we demonstrate that prioritized hindsight replay, along with pre-training and data-augmentation, leads to successful inter-task generalization. CodeIt is the first neuro-sy
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#32508;&#36848;&#35843;&#30740;&#20102;&#22270;&#32553;&#20943;&#26041;&#27861;&#65292;&#21253;&#25324;&#31232;&#30095;&#21270;&#12289;&#31895;&#21270;&#21644;&#27987;&#32553;&#65292;&#22312;&#35299;&#20915;&#22823;&#22411;&#22270;&#24418;&#25968;&#25454;&#20998;&#26512;&#21644;&#35745;&#31639;&#22797;&#26434;&#24615;&#26041;&#38754;&#36215;&#21040;&#20102;&#37325;&#35201;&#20316;&#29992;&#12290;&#35843;&#30740;&#23545;&#36825;&#20123;&#26041;&#27861;&#30340;&#25216;&#26415;&#32454;&#33410;&#36827;&#34892;&#20102;&#31995;&#32479;&#30340;&#22238;&#39038;&#65292;&#24182;&#24378;&#35843;&#20102;&#23427;&#20204;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#20851;&#38190;&#24615;&#12290;&#21516;&#26102;&#65292;&#35843;&#30740;&#36824;&#25552;&#20986;&#20102;&#20445;&#35777;&#22270;&#32553;&#20943;&#25216;&#26415;&#25345;&#32493;&#26377;&#25928;&#24615;&#30340;&#20851;&#38190;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>https://arxiv.org/abs/2402.03358</link><description>&lt;p&gt;
&#22270;&#32553;&#20943;&#30340;&#32508;&#21512;&#35843;&#30740;&#65306;&#31232;&#30095;&#21270;&#12289;&#31895;&#21270;&#21644;&#27987;&#32553;
&lt;/p&gt;
&lt;p&gt;
A Comprehensive Survey on Graph Reduction: Sparsification, Coarsening, and Condensation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03358
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#32508;&#36848;&#35843;&#30740;&#20102;&#22270;&#32553;&#20943;&#26041;&#27861;&#65292;&#21253;&#25324;&#31232;&#30095;&#21270;&#12289;&#31895;&#21270;&#21644;&#27987;&#32553;&#65292;&#22312;&#35299;&#20915;&#22823;&#22411;&#22270;&#24418;&#25968;&#25454;&#20998;&#26512;&#21644;&#35745;&#31639;&#22797;&#26434;&#24615;&#26041;&#38754;&#36215;&#21040;&#20102;&#37325;&#35201;&#20316;&#29992;&#12290;&#35843;&#30740;&#23545;&#36825;&#20123;&#26041;&#27861;&#30340;&#25216;&#26415;&#32454;&#33410;&#36827;&#34892;&#20102;&#31995;&#32479;&#30340;&#22238;&#39038;&#65292;&#24182;&#24378;&#35843;&#20102;&#23427;&#20204;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#20851;&#38190;&#24615;&#12290;&#21516;&#26102;&#65292;&#35843;&#30740;&#36824;&#25552;&#20986;&#20102;&#20445;&#35777;&#22270;&#32553;&#20943;&#25216;&#26415;&#25345;&#32493;&#26377;&#25928;&#24615;&#30340;&#20851;&#38190;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#21487;&#20197;&#33258;&#28982;&#22320;&#34920;&#31034;&#20026;&#22270;&#65292;&#28085;&#30422;&#20102;&#24191;&#27867;&#30340;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#22270;&#25968;&#25454;&#38598;&#30340;&#22797;&#26434;&#24615;&#21644;&#35268;&#27169;&#30340;&#22686;&#21152;&#20026;&#20998;&#26512;&#21644;&#35745;&#31639;&#24102;&#26469;&#20102;&#26174;&#33879;&#30340;&#25361;&#25112;&#12290;&#20026;&#27492;&#65292;&#22270;&#32553;&#20943;&#25216;&#26415;&#22312;&#20445;&#30041;&#20851;&#38190;&#23646;&#24615;&#30340;&#21516;&#26102;&#31616;&#21270;&#22823;&#22411;&#22270;&#24418;&#25968;&#25454;&#21464;&#24471;&#36234;&#26469;&#36234;&#21463;&#20851;&#27880;&#12290;&#22312;&#26412;&#35843;&#30740;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#25552;&#20379;&#23545;&#22270;&#32553;&#20943;&#26041;&#27861;&#30340;&#20840;&#38754;&#29702;&#35299;&#65292;&#21253;&#25324;&#22270;&#31232;&#30095;&#21270;&#12289;&#22270;&#31895;&#21270;&#21644;&#22270;&#27987;&#32553;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#32479;&#19968;&#23450;&#20041;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#20998;&#23618;&#20998;&#31867;&#27861;&#26469;&#20998;&#31867;&#36825;&#20123;&#26041;&#27861;&#25152;&#35299;&#20915;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#30340;&#35843;&#30740;&#31995;&#32479;&#22320;&#22238;&#39038;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#25216;&#26415;&#32454;&#33410;&#65292;&#24182;&#24378;&#35843;&#20102;&#23427;&#20204;&#22312;&#21508;&#31181;&#22330;&#26223;&#20013;&#30340;&#23454;&#38469;&#24212;&#29992;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#27010;&#36848;&#20102;&#20445;&#35777;&#22270;&#32553;&#20943;&#25216;&#26415;&#25345;&#32493;&#26377;&#25928;&#24615;&#30340;&#20851;&#38190;&#30740;&#31350;&#26041;&#21521;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#35814;&#32454;&#30340;&#35770;&#25991;&#21015;&#34920;&#38142;&#25509;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many real-world datasets can be naturally represented as graphs, spanning a wide range of domains. However, the increasing complexity and size of graph datasets present significant challenges for analysis and computation. In response, graph reduction techniques have gained prominence for simplifying large graphs while preserving essential properties. In this survey, we aim to provide a comprehensive understanding of graph reduction methods, including graph sparsification, graph coarsening, and graph condensation. Specifically, we establish a unified definition for these methods and introduce a hierarchical taxonomy to categorize the challenges they address. Our survey then systematically reviews the technical details of these methods and emphasizes their practical applications across diverse scenarios. Furthermore, we outline critical research directions to ensure the continued effectiveness of graph reduction techniques, as well as provide a comprehensive paper list at https://github.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;CLLM&#26041;&#27861;&#65292;&#21033;&#29992;LLMs&#21644;&#25968;&#25454;&#31579;&#36873;&#22312;&#20302;&#25968;&#25454;&#29615;&#22659;&#20013;&#36827;&#34892;&#34920;&#26684;&#22686;&#24378;&#12290;&#36890;&#36807;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20808;&#39564;&#30693;&#35782;&#20197;&#21450;&#22522;&#20110;&#23398;&#20064;&#21160;&#24577;&#12289;&#32622;&#20449;&#24230;&#21644;&#19981;&#30830;&#23450;&#24230;&#25351;&#26631;&#30340;&#31579;&#36873;&#26426;&#21046;&#65292;CLLM&#21462;&#24471;&#20102;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2312.12112</link><description>&lt;p&gt;
LLM&#31934;&#36873;&#65306;&#22312;&#36229;&#20302;&#25968;&#25454;&#29615;&#22659;&#20013;&#21033;&#29992;LLMs&#21644;&#25968;&#25454;&#31579;&#36873;&#36827;&#34892;&#34920;&#26684;&#22686;&#24378;
&lt;/p&gt;
&lt;p&gt;
Curated LLM: Synergy of LLMs and Data Curation for tabular augmentation in ultra low-data regimes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.12112
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;CLLM&#26041;&#27861;&#65292;&#21033;&#29992;LLMs&#21644;&#25968;&#25454;&#31579;&#36873;&#22312;&#20302;&#25968;&#25454;&#29615;&#22659;&#20013;&#36827;&#34892;&#34920;&#26684;&#22686;&#24378;&#12290;&#36890;&#36807;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20808;&#39564;&#30693;&#35782;&#20197;&#21450;&#22522;&#20110;&#23398;&#20064;&#21160;&#24577;&#12289;&#32622;&#20449;&#24230;&#21644;&#19981;&#30830;&#23450;&#24230;&#25351;&#26631;&#30340;&#31579;&#36873;&#26426;&#21046;&#65292;CLLM&#21462;&#24471;&#20102;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20302;&#25968;&#25454;&#24773;&#20917;&#19979;&#30340;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#20173;&#28982;&#26159;&#19968;&#20010;&#34987;&#20302;&#20272;&#20294;&#33267;&#20851;&#37325;&#35201;&#30340;&#38382;&#39064;&#12290;&#22240;&#27492;&#65292;&#22686;&#21152;ML&#25152;&#38656;&#30340;&#25968;&#25454;&#26679;&#26412;&#22823;&#23567;&#30340;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#23545;&#20110;&#37322;&#25918;ML&#22312;&#25968;&#25454;&#21294;&#20047;&#30340;&#22320;&#21306;&#21644;&#39046;&#22495;&#30340;&#21464;&#38761;&#28508;&#21147;&#33267;&#20851;&#37325;&#35201;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#26377;&#38480;&#30340;&#35757;&#32451;&#38598;&#38480;&#21046;&#20102;&#20256;&#32479;&#30340;&#34920;&#26684;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#22120;&#22312;&#29983;&#25104;ML&#20219;&#21153;&#25152;&#38656;&#30340;&#22823;&#35268;&#27169;&#19988;&#22810;&#26679;&#21270;&#30340;&#22686;&#24378;&#25968;&#25454;&#38598;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;CLLM&#65292;&#23427;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#20302;&#25968;&#25454;&#29615;&#22659;&#20013;&#36827;&#34892;&#25968;&#25454;&#22686;&#24378;&#30340;&#20808;&#39564;&#30693;&#35782;&#12290;&#28982;&#32780;&#65292;&#20687;&#20219;&#20309;&#29983;&#25104;&#27169;&#22411;&#19968;&#26679;&#65292;&#24182;&#38750;LLMs&#29983;&#25104;&#30340;&#25152;&#26377;&#25968;&#25454;&#37117;&#33021;&#25552;&#39640;&#19979;&#28216;&#30340;&#25928;&#29992;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#21160;&#24577;&#12289;&#32622;&#20449;&#24230;&#21644;&#19981;&#30830;&#23450;&#24230;&#25351;&#26631;&#30340;&#21407;&#21017;&#24615;&#31579;&#36873;&#26426;&#21046;&#65292;&#20197;&#33719;&#21462;&#39640;&#36136;&#37327;&#30340;&#25968;&#25454;&#38598;&#12290;&#36890;&#36807;&#22810;&#20010;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#30340;&#23454;&#35777;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;CLLM&#22312;&#20302;&#25968;&#25454;&#29615;&#22659;&#20013;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine Learning (ML) in low-data settings remains an underappreciated yet crucial problem. Hence, data augmentation methods to increase the sample size of datasets needed for ML are key to unlocking the transformative potential of ML in data-deprived regions and domains. Unfortunately, the limited training set constrains traditional tabular synthetic data generators in their ability to generate a large and diverse augmented dataset needed for ML tasks. To address this challenge, we introduce CLLM, which leverages the prior knowledge of Large Language Models (LLMs) for data augmentation in the low-data regime. However, not all the data generated by LLMs will improve downstream utility, as for any generative model. Consequently, we introduce a principled curation mechanism, leveraging learning dynamics, coupled with confidence and uncertainty metrics, to obtain a high-quality dataset. Empirically, on multiple real-world datasets, we demonstrate the superior performance of CLLM in the lo
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#20351;&#29992;&#20803;&#21551;&#21457;&#24335;&#30340;&#25552;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#27979;&#35797;&#20845;&#31181;&#20856;&#22411;&#30340;&#20803;&#21551;&#21457;&#24335;&#26041;&#27861;&#65292;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25552;&#31034;&#20248;&#21270;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2311.08364</link><description>&lt;p&gt;
Plum: &#20351;&#29992;&#20803;&#21551;&#21457;&#24335;&#30340;&#25552;&#31034;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Plum: Prompt Learning using Metaheuristic
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.08364
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#20351;&#29992;&#20803;&#21551;&#21457;&#24335;&#30340;&#25552;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#27979;&#35797;&#20845;&#31181;&#20856;&#22411;&#30340;&#20803;&#21551;&#21457;&#24335;&#26041;&#27861;&#65292;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25552;&#31034;&#20248;&#21270;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#20174;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20986;&#29616;&#20197;&#26469;&#65292;&#25552;&#31034;&#23398;&#20064;&#24050;&#25104;&#20026;&#20248;&#21270;&#21644;&#23450;&#21046;&#36825;&#20123;&#27169;&#22411;&#30340;&#19968;&#31181;&#27969;&#34892;&#26041;&#27861;&#12290;&#29305;&#27530;&#25552;&#31034;&#65292;&#22914;&#8220;&#24605;&#32500;&#38142;&#8221;&#65292;&#29978;&#33267;&#25581;&#31034;&#20102;&#36825;&#20123;&#27169;&#22411;&#20869;&#37096;&#20808;&#21069;&#26410;&#30693;&#30340;&#25512;&#29702;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#21457;&#29616;&#26377;&#25928;&#25552;&#31034;&#30340;&#36827;&#23637;&#32531;&#24930;&#65292;&#20419;&#20351;&#20154;&#20204;&#28212;&#26395;&#19968;&#31181;&#36890;&#29992;&#30340;&#25552;&#31034;&#20248;&#21270;&#26041;&#27861;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#29616;&#26377;&#30340;&#25552;&#31034;&#23398;&#20064;&#26041;&#27861;&#20013;&#24456;&#23569;&#26377;&#28385;&#36275;&#8220;&#36890;&#29992;&#8221;&#30340;&#26631;&#20934;&#65292;&#21363;&#21516;&#26102;&#20855;&#22791;&#33258;&#21160;&#12289;&#31163;&#25955;&#12289;&#40657;&#30418;&#12289;&#26080;&#26799;&#24230;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20803;&#21551;&#21457;&#24335;&#65292;&#20316;&#20026;&#19968;&#31181;&#26377;&#24076;&#26395;&#30340;&#25552;&#31034;&#23398;&#20064;&#26041;&#27861;&#30340;&#31163;&#25955;&#38750;&#20984;&#20248;&#21270;&#26041;&#27861;&#20998;&#25903;&#65292;&#25317;&#26377;100&#22810;&#31181;&#36873;&#39033;&#12290;&#22312;&#25105;&#20204;&#30340;&#33539;&#24335;&#20013;&#65292;&#25105;&#20204;&#27979;&#35797;&#20102;&#20845;&#31181;&#20856;&#22411;&#26041;&#27861;&#65306;&#29228;&#23665;&#12289;&#27169;&#25311;&#36864;&#28779;&#12289;&#36951;&#20256;&#31639;&#27861;&#65288;&#24102;/&#19981;&#24102;&#20132;&#21449;&#65289;&#12289;&#31105;&#24524;&#25628;&#32034;&#21644;&#21644;&#35856;&#25628;&#32034;&#65292;&#23637;&#31034;&#20102;&#23427;&#20204;&#22312;&#30333;&#30418;&#27169;&#24335;&#19979;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.08364v2 Announce Type: replace-cross  Abstract: Since the emergence of large language models, prompt learning has become a popular method for optimizing and customizing these models. Special prompts, such as Chain-of-Thought, have even revealed previously unknown reasoning capabilities within these models. However, the progress of discovering effective prompts has been slow, driving a desire for general prompt optimization methods. Unfortunately, few existing prompt learning methods satisfy the criteria of being truly "general", i.e., automatic, discrete, black-box, gradient-free, and interpretable all at once. In this paper, we introduce metaheuristics, a branch of discrete non-convex optimization methods with over 100 options, as a promising approach to prompt learning. Within our paradigm, we test six typical methods: hill climbing, simulated annealing, genetic algorithms with/without crossover, tabu search, and harmony search, demonstrating their effectiveness in white-b
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#36328;&#39046;&#22495;&#32852;&#21512;&#23398;&#20064;&#20013;&#22522;&#20110;&#35760;&#24405;&#32423;&#20010;&#24615;&#21270;&#24046;&#20998;&#38544;&#31169;&#30340;&#38382;&#39064;&#65292;&#35774;&#35745;&#20102;&#19968;&#20010;&#21517;&#20026;rPDP-FL&#30340;&#26032;&#22411;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#22810;&#21151;&#33021;&#35299;&#20915;&#26041;&#26696;&#8220;&#27169;&#25311;-&#26354;&#32447;&#25311;&#21512;&#8221;&#65292;&#20197;&#28385;&#36275;&#19981;&#21516;&#35760;&#24405;&#30340;&#38544;&#31169;&#38656;&#27714;&#12290;</title><link>http://arxiv.org/abs/2401.16251</link><description>&lt;p&gt;
&#36328;&#39046;&#22495;&#32852;&#21512;&#23398;&#20064;&#20013;&#22522;&#20110;&#35760;&#24405;&#32423;&#20010;&#24615;&#21270;&#24046;&#20998;&#38544;&#31169;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Cross-silo Federated Learning with Record-level Personalized Differential Privacy. (arXiv:2401.16251v2 [cs.CR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16251
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36328;&#39046;&#22495;&#32852;&#21512;&#23398;&#20064;&#20013;&#22522;&#20110;&#35760;&#24405;&#32423;&#20010;&#24615;&#21270;&#24046;&#20998;&#38544;&#31169;&#30340;&#38382;&#39064;&#65292;&#35774;&#35745;&#20102;&#19968;&#20010;&#21517;&#20026;rPDP-FL&#30340;&#26032;&#22411;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#22810;&#21151;&#33021;&#35299;&#20915;&#26041;&#26696;&#8220;&#27169;&#25311;-&#26354;&#32447;&#25311;&#21512;&#8221;&#65292;&#20197;&#28385;&#36275;&#19981;&#21516;&#35760;&#24405;&#30340;&#38544;&#31169;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#24046;&#20998;&#38544;&#31169;&#22686;&#24378;&#30340;&#32852;&#21512;&#23398;&#20064;&#25104;&#20026;&#20102;&#20445;&#25252;&#23458;&#25143;&#31471;&#25968;&#25454;&#38544;&#31169;&#30340;&#24120;&#29992;&#26041;&#27861;&#65292;&#20294;&#29616;&#26377;&#26041;&#26696;&#36890;&#24120;&#20551;&#35774;&#25152;&#26377;&#35760;&#24405;&#30340;&#38544;&#31169;&#39044;&#31639;&#22343;&#30456;&#21516;&#65292;&#25552;&#20379;&#19968;&#31181;&#36866;&#29992;&#20110;&#25152;&#26377;&#35760;&#24405;&#30340;&#36890;&#29992;&#35299;&#20915;&#26041;&#26696;&#65292;&#21487;&#33021;&#26080;&#27861;&#28385;&#36275;&#27599;&#20010;&#35760;&#24405;&#30340;&#38544;&#31169;&#38656;&#27714;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#36328;&#39046;&#22495;&#32852;&#21512;&#23398;&#20064;&#20013;&#22522;&#20110;&#35760;&#24405;&#32423;&#20010;&#24615;&#21270;&#24046;&#20998;&#38544;&#31169;&#30340;&#26410;&#30693;&#39046;&#22495;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#21517;&#20026;rPDP-FL&#30340;&#26032;&#22411;&#26694;&#26550;&#65292;&#37319;&#29992;&#20004;&#38454;&#27573;&#28151;&#21512;&#25277;&#26679;&#26041;&#26696;&#65292;&#26082;&#21253;&#25324;&#23458;&#25143;&#31471;&#32423;&#21035;&#25277;&#26679;&#65292;&#21448;&#21253;&#25324;&#38750;&#22343;&#21248;&#35760;&#24405;&#32423;&#21035;&#25277;&#26679;&#65292;&#20197;&#36866;&#24212;&#19981;&#21516;&#30340;&#38544;&#31169;&#38656;&#27714;&#12290;&#19968;&#20010;&#20851;&#38190;&#19988;&#38750;&#24179;&#20961;&#30340;&#38382;&#39064;&#26159;&#22312;&#32473;&#23450;&#20010;&#24615;&#21270;&#38544;&#31169;&#39044;&#31639;&#949;&#30340;&#24773;&#20917;&#19979;&#36873;&#25321;&#29702;&#24819;&#30340;&#27599;&#35760;&#24405;&#25277;&#26679;&#27010;&#29575;q&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#21151;&#33021;&#35299;&#20915;&#26041;&#26696;&#8220;&#27169;&#25311;-&#26354;&#32447;&#25311;&#21512;&#8221;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#25581;&#31034;&#38750;&#32447;&#24615;&#30456;&#20851;&#24615;&#30340;&#37325;&#35201;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated learning enhanced by differential privacy has emerged as a popular approach to better safeguard the privacy of client-side data by protecting clients' contributions during the training process. Existing solutions typically assume a uniform privacy budget for all records and provide one-size-fits-all solutions that may not be adequate to meet each record's privacy requirement. In this paper, we explore the uncharted territory of cross-silo FL with record-level personalized differential privacy. We devise a novel framework named rPDP-FL, employing a two-stage hybrid sampling scheme with both client-level sampling and non-uniform record-level sampling to accommodate varying privacy requirements. A critical and non-trivial problem is to select the ideal per-record sampling probability q given the personalized privacy budget {\epsilon}. We introduce a versatile solution named Simulation-CurveFitting, allowing us to uncover a significant insight into the nonlinear correlation betwe
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#36827;&#21270;&#31639;&#27861;&#30340;&#32467;&#21512;&#20855;&#26377;&#24378;&#22823;&#30340;&#19968;&#33268;&#24615;&#65292;&#21253;&#25324;&#26631;&#35760;&#23884;&#20837;&#21644;&#22522;&#22240;&#22411;-&#34920;&#29616;&#22411;&#26144;&#23556;&#12289;&#20301;&#32622;&#32534;&#30721;&#21644;&#36866;&#24212;&#24615;&#22609;&#36896;&#12289;&#20301;&#32622;&#23884;&#20837;&#21644;&#36873;&#25321;&#12289;&#27880;&#24847;&#21147;&#21644;&#20132;&#21449;&#12289;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#21644;&#31361;&#21464;&#12289;&#27169;&#22411;&#35757;&#32451;&#21644;&#21442;&#25968;&#26356;&#26032;&#20197;&#21450;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#22810;&#30446;&#26631;&#20248;&#21270;&#31561;&#22810;&#20010;&#26680;&#24515;&#29305;&#24449;&#12290;&#26412;&#25991;&#20998;&#26512;&#20102;&#29616;&#26377;&#30340;&#32806;&#21512;&#30740;&#31350;&#65292;&#24182;&#20026;&#26410;&#26469;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#22522;&#26412;&#36335;&#32447;&#21644;&#20851;&#38190;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2401.10510</link><description>&lt;p&gt;
&#22825;&#20316;&#20043;&#21512;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#36827;&#21270;&#31639;&#27861;&#30340;&#32467;&#21512;
&lt;/p&gt;
&lt;p&gt;
A match made in consistency heaven: when large language models meet evolutionary algorithms. (arXiv:2401.10510v1 [cs.NE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10510
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#36827;&#21270;&#31639;&#27861;&#30340;&#32467;&#21512;&#20855;&#26377;&#24378;&#22823;&#30340;&#19968;&#33268;&#24615;&#65292;&#21253;&#25324;&#26631;&#35760;&#23884;&#20837;&#21644;&#22522;&#22240;&#22411;-&#34920;&#29616;&#22411;&#26144;&#23556;&#12289;&#20301;&#32622;&#32534;&#30721;&#21644;&#36866;&#24212;&#24615;&#22609;&#36896;&#12289;&#20301;&#32622;&#23884;&#20837;&#21644;&#36873;&#25321;&#12289;&#27880;&#24847;&#21147;&#21644;&#20132;&#21449;&#12289;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#21644;&#31361;&#21464;&#12289;&#27169;&#22411;&#35757;&#32451;&#21644;&#21442;&#25968;&#26356;&#26032;&#20197;&#21450;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#22810;&#30446;&#26631;&#20248;&#21270;&#31561;&#22810;&#20010;&#26680;&#24515;&#29305;&#24449;&#12290;&#26412;&#25991;&#20998;&#26512;&#20102;&#29616;&#26377;&#30340;&#32806;&#21512;&#30740;&#31350;&#65292;&#24182;&#20026;&#26410;&#26469;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#22522;&#26412;&#36335;&#32447;&#21644;&#20851;&#38190;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#29983;&#25104;&#21019;&#36896;&#24615;&#30340;&#33258;&#28982;&#25991;&#26412;&#26041;&#38754;&#20855;&#26377;&#24378;&#22823;&#30340;&#33021;&#21147;&#12290;&#36827;&#21270;&#31639;&#27861;&#65288;EAs&#65289;&#21487;&#20197;&#21457;&#29616;&#22797;&#26434;&#23454;&#38469;&#38382;&#39064;&#30340;&#22810;&#26679;&#35299;&#20915;&#26041;&#26696;&#12290;&#26412;&#25991;&#36890;&#36807;&#27604;&#36739;&#25991;&#26412;&#24207;&#21015;&#29983;&#25104;&#21644;&#36827;&#21270;&#30340;&#20849;&#21516;&#29305;&#28857;&#21644;&#26041;&#21521;&#24615;&#65292;&#38416;&#36848;&#20102;LLMs&#19982;EAs&#20043;&#38388;&#30340;&#24378;&#22823;&#19968;&#33268;&#24615;&#65292;&#21253;&#25324;&#22810;&#20010;&#19968;&#23545;&#19968;&#30340;&#26680;&#24515;&#29305;&#24449;&#65306;&#26631;&#35760;&#23884;&#20837;&#21644;&#22522;&#22240;&#22411;-&#34920;&#29616;&#22411;&#26144;&#23556;&#12289;&#20301;&#32622;&#32534;&#30721;&#21644;&#36866;&#24212;&#24615;&#22609;&#36896;&#12289;&#20301;&#32622;&#23884;&#20837;&#21644;&#36873;&#25321;&#12289;&#27880;&#24847;&#21147;&#21644;&#20132;&#21449;&#12289;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#21644;&#31361;&#21464;&#12289;&#27169;&#22411;&#35757;&#32451;&#21644;&#21442;&#25968;&#26356;&#26032;&#20197;&#21450;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#22810;&#30446;&#26631;&#20248;&#21270;&#12290;&#22312;&#36825;&#31181;&#19968;&#33268;&#24615;&#35270;&#35282;&#19979;&#65292;&#20998;&#26512;&#20102;&#29616;&#26377;&#30340;&#32806;&#21512;&#30740;&#31350;&#65292;&#21253;&#25324;&#36827;&#21270;&#24494;&#35843;&#21644;LLM&#22686;&#24378;&#22411;EAs&#12290;&#20511;&#21161;&#36825;&#20123;&#27934;&#35265;&#65292;&#25105;&#20204;&#27010;&#36848;&#20102;&#26410;&#26469;&#22312;LLMs&#21644;EAs&#32806;&#21512;&#26041;&#38754;&#30340;&#22522;&#26412;&#30740;&#31350;&#36335;&#32447;&#65292;&#24182;&#31361;&#20986;&#20102;&#20854;&#20013;&#30340;&#20851;&#38190;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pre-trained large language models (LLMs) have powerful capabilities for generating creative natural text. Evolutionary algorithms (EAs) can discover diverse solutions to complex real-world problems. Motivated by the common collective and directionality of text sequence generation and evolution, this paper illustrates the strong consistency of LLMs and EAs, which includes multiple one-to-one key characteristics: token embedding and genotype-phenotype mapping, position encoding and fitness shaping, position embedding and selection, attention and crossover, feed-forward neural network and mutation, model training and parameter update, and multi-task learning and multi-objective optimization. Based on this consistency perspective, existing coupling studies are analyzed, including evolutionary fine-tuning and LLM-enhanced EAs. Leveraging these insights, we outline a fundamental roadmap for future research in coupling LLMs and EAs, while highlighting key challenges along the way. The consist
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#19977;&#23618;&#20998;&#23618;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#24341;&#20837;&#20102;&#31354;&#38388;&#21644;&#26102;&#38388;&#30446;&#26631;&#25277;&#35937;&#21270;&#12290;&#30740;&#31350;&#32773;&#25552;&#20379;&#20102;&#23398;&#20064;&#31574;&#30053;&#30340;&#29702;&#35770;&#36951;&#25022;&#36793;&#30028;&#65292;&#24182;&#22312;&#22810;&#20010;&#20219;&#21153;&#19978;&#23545;&#31639;&#27861;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2401.09870</link><description>&lt;p&gt;
&#35843;&#21644;&#31354;&#38388;&#21644;&#26102;&#38388;&#25277;&#35937;&#21270;&#20197;&#23454;&#29616;&#30446;&#26631;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Reconciling Spatial and Temporal Abstractions for Goal Representation. (arXiv:2401.09870v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09870
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#19977;&#23618;&#20998;&#23618;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#24341;&#20837;&#20102;&#31354;&#38388;&#21644;&#26102;&#38388;&#30446;&#26631;&#25277;&#35937;&#21270;&#12290;&#30740;&#31350;&#32773;&#25552;&#20379;&#20102;&#23398;&#20064;&#31574;&#30053;&#30340;&#29702;&#35770;&#36951;&#25022;&#36793;&#30028;&#65292;&#24182;&#22312;&#22810;&#20010;&#20219;&#21153;&#19978;&#23545;&#31639;&#27861;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#26631;&#34920;&#31034;&#36890;&#36807;&#23558;&#22797;&#26434;&#30340;&#23398;&#20064;&#38382;&#39064;&#20998;&#35299;&#20026;&#26356;&#23481;&#26131;&#30340;&#23376;&#20219;&#21153;&#26469;&#24433;&#21709;&#20998;&#23618;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#20445;&#30041;&#26102;&#38388;&#25277;&#35937;&#29615;&#22659;&#21160;&#24577;&#30340;&#34920;&#31034;&#26041;&#27861;&#22312;&#35299;&#20915;&#22256;&#38590;&#38382;&#39064;&#21644;&#25552;&#20379;&#20248;&#21270;&#29702;&#35770;&#20445;&#35777;&#26041;&#38754;&#26159;&#25104;&#21151;&#30340;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#29615;&#22659;&#21160;&#24577;&#36234;&#26469;&#36234;&#22797;&#26434;&#65288;&#21363;&#26102;&#38388;&#25277;&#35937;&#36716;&#25442;&#20851;&#31995;&#20381;&#36182;&#26356;&#22810;&#21464;&#37327;&#65289;&#30340;&#20219;&#21153;&#20013;&#26080;&#27861;&#25193;&#23637;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#20854;&#20182;&#26041;&#27861;&#21017;&#23581;&#35797;&#20351;&#29992;&#31354;&#38388;&#25277;&#35937;&#26469;&#32531;&#35299;&#21069;&#38754;&#30340;&#38382;&#39064;&#12290;&#23427;&#20204;&#30340;&#38480;&#21046;&#21253;&#25324;&#26080;&#27861;&#36866;&#24212;&#39640;&#32500;&#29615;&#22659;&#21644;&#23545;&#20808;&#21069;&#30693;&#35782;&#30340;&#20381;&#36182;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19977;&#23618;&#20998;&#23618;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#20998;&#23618;&#32467;&#26500;&#30340;&#19981;&#21516;&#23618;&#27425;&#24341;&#20837;&#20102;&#31354;&#38388;&#21644;&#26102;&#38388;&#30446;&#26631;&#25277;&#35937;&#21270;&#12290;&#25105;&#20204;&#23545;&#23398;&#20064;&#31574;&#30053;&#30340;&#36951;&#25022;&#36793;&#30028;&#36827;&#34892;&#20102;&#29702;&#35770;&#30740;&#31350;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#22312;&#19981;&#21516;&#20219;&#21153;&#19978;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Goal representation affects the performance of Hierarchical Reinforcement Learning (HRL) algorithms by decomposing the complex learning problem into easier subtasks. Recent studies show that representations that preserve temporally abstract environment dynamics are successful in solving difficult problems and provide theoretical guarantees for optimality. These methods however cannot scale to tasks where environment dynamics increase in complexity i.e. the temporally abstract transition relations depend on larger number of variables. On the other hand, other efforts have tried to use spatial abstraction to mitigate the previous issues. Their limitations include scalability to high dimensional environments and dependency on prior knowledge.  In this paper, we propose a novel three-layer HRL algorithm that introduces, at different levels of the hierarchy, both a spatial and a temporal goal abstraction. We provide a theoretical study of the regret bounds of the learned policies. We evalua
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38646;&#26679;&#26412;&#20301;&#32622;&#21435;&#20559;&#26041;&#27861;&#65288;ZOE&#65289;&#26469;&#38477;&#20302;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20301;&#32622;&#20559;&#24046;&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;LLMs&#30340;&#26080;&#30417;&#30563;&#21709;&#24212;&#36827;&#34892;&#21435;&#20559;&#12290;&#23454;&#39564;&#35777;&#23454;ZOE&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#21644;&#20219;&#21153;&#20013;&#22343;&#34920;&#29616;&#20986;&#20248;&#24322;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.01218</link><description>&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#38646;&#26679;&#26412;&#20301;&#32622;&#21435;&#20559;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Zero-Shot Position Debiasing for Large Language Models. (arXiv:2401.01218v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01218
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38646;&#26679;&#26412;&#20301;&#32622;&#21435;&#20559;&#26041;&#27861;&#65288;ZOE&#65289;&#26469;&#38477;&#20302;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20301;&#32622;&#20559;&#24046;&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;LLMs&#30340;&#26080;&#30417;&#30563;&#21709;&#24212;&#36827;&#34892;&#21435;&#20559;&#12290;&#23454;&#39564;&#35777;&#23454;ZOE&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#21644;&#20219;&#21153;&#20013;&#22343;&#34920;&#29616;&#20986;&#20248;&#24322;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24494;&#35843;&#24050;&#34987;&#35777;&#26126;&#26159;&#25913;&#21892;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#39046;&#22495;&#24615;&#33021;&#30340;&#26377;&#25928;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;LLMs&#21487;&#33021;&#36866;&#24212;&#25968;&#25454;&#38598;&#20559;&#35265;&#21644;&#39044;&#27979;&#30340;&#25463;&#24452;&#65292;&#23548;&#33268;&#29983;&#25104;&#24615;&#33021;&#24046;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;LLMs&#23481;&#26131;&#34920;&#29616;&#20986;&#20301;&#32622;&#20559;&#24046;&#65292;&#21363;&#21033;&#29992;&#20301;&#20110;&#24320;&#22836;&#25110;&#26411;&#23614;&#25110;&#36755;&#20837;&#20013;&#29305;&#23450;&#20301;&#32622;&#32447;&#32034;&#30340;&#20449;&#24687;&#12290;&#29616;&#26377;&#30340;&#20943;&#36731;&#20301;&#32622;&#20559;&#24046;&#30340;&#24037;&#20316;&#38656;&#35201;&#22806;&#37096;&#20559;&#24046;&#30693;&#35782;&#25110;&#24102;&#27880;&#37322;&#30340;&#38750;&#20559;&#20506;&#26679;&#26412;&#65292;&#22312;&#23454;&#38469;&#20013;&#19981;&#22826;&#23454;&#29992;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38646;&#26679;&#26412;&#20301;&#32622;&#21435;&#20559;&#65288;ZOE&#65289;&#26694;&#26550;&#23545;LLMs&#36827;&#34892;&#20301;&#32622;&#21435;&#20559;&#12290;ZOE&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;LLMs&#30340;&#26080;&#30417;&#30563;&#21709;&#24212;&#36827;&#34892;&#21435;&#20559;&#65292;&#22240;&#27492;&#19981;&#38656;&#35201;&#20219;&#20309;&#22806;&#37096;&#30693;&#35782;&#25110;&#25968;&#25454;&#38598;&#12290;&#20026;&#20102;&#25552;&#39640;&#26080;&#30417;&#30563;&#21709;&#24212;&#30340;&#36136;&#37327;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20027;&#20174;&#23545;&#40784;&#65288;MSA&#65289;&#27169;&#22359;&#26469;&#20462;&#21098;&#36825;&#20123;&#21709;&#24212;&#12290;&#23545;&#20843;&#20010;&#25968;&#25454;&#38598;&#21644;&#20116;&#20010;&#20219;&#21153;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;ZOE&#22987;&#32456;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fine-tuning has been demonstrated to be an effective method to improve the domain performance of large language models (LLMs). However, LLMs might fit the dataset bias and shortcuts for prediction, leading to poor generation performance. Experimental result shows that LLMs are prone to exhibit position bias, i.e., leveraging information positioned at the beginning or end, or specific positional cues within the input. Existing works on mitigating position bias require external bias knowledge or annotated non-biased samples, which is unpractical in reality. In this work, we propose a zero-shot position debiasing (ZOE) framework to mitigate position bias for LLMs. ZOE leverages unsupervised responses from pre-trained LLMs for debiasing, thus without any external knowledge or datasets. To improve the quality of unsupervised responses, we propose a master-slave alignment (MSA) module to prune these responses. Experiments on eight datasets and five tasks show that ZOE consistently outperform
&lt;/p&gt;</description></item><item><title>&#26412;&#32508;&#36848;&#23545;&#28041;&#21450;&#21033;&#29992;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#25968;&#25454;&#30340;&#21307;&#30103;&#20154;&#24037;&#26234;&#33021;&#30740;&#31350;&#20013;&#30340;&#20559;&#35265;&#36827;&#34892;&#20102;&#31995;&#32479;&#32508;&#36848;&#65292;&#20849;&#28085;&#30422;&#20102;&#20845;&#31181;&#20027;&#35201;&#30340;&#20559;&#35265;&#31867;&#22411;&#65292;&#21516;&#26102;&#24635;&#32467;&#20102;&#29616;&#26377;&#30340;&#20559;&#35265;&#22788;&#29702;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.19917</link><description>&lt;p&gt;
&#25581;&#31034;&#20559;&#35265;&#21644;&#19981;&#24179;&#31561;&#65306;&#21033;&#29992;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#30340;&#21307;&#30103;&#20154;&#24037;&#26234;&#33021;&#20013;&#20559;&#35265;&#26816;&#27979;&#21644;&#32531;&#35299;&#30340;&#31995;&#32479;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Unmasking Bias and Inequities: A Systematic Review of Bias Detection and Mitigation in Healthcare Artificial Intelligence Using Electronic Health Records. (arXiv:2310.19917v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19917
&lt;/p&gt;
&lt;p&gt;
&#26412;&#32508;&#36848;&#23545;&#28041;&#21450;&#21033;&#29992;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#25968;&#25454;&#30340;&#21307;&#30103;&#20154;&#24037;&#26234;&#33021;&#30740;&#31350;&#20013;&#30340;&#20559;&#35265;&#36827;&#34892;&#20102;&#31995;&#32479;&#32508;&#36848;&#65292;&#20849;&#28085;&#30422;&#20102;&#20845;&#31181;&#20027;&#35201;&#30340;&#20559;&#35265;&#31867;&#22411;&#65292;&#21516;&#26102;&#24635;&#32467;&#20102;&#29616;&#26377;&#30340;&#20559;&#35265;&#22788;&#29702;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#30340;&#65306;&#21033;&#29992;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#30340;&#20154;&#24037;&#26234;&#33021;&#24212;&#29992;&#22312;&#21307;&#30103;&#39046;&#22495;&#36234;&#26469;&#36234;&#21463;&#21040;&#27426;&#36814;&#65292;&#20294;&#20063;&#24341;&#20837;&#20102;&#21508;&#31181;&#31867;&#22411;&#30340;&#20559;&#35265;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#31995;&#32479;&#32508;&#36848;&#28041;&#21450;&#21033;&#29992;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#25968;&#25454;&#30340;&#20154;&#24037;&#26234;&#33021;&#30740;&#31350;&#20013;&#30340;&#20559;&#35265;&#12290;&#26041;&#27861;&#65306;&#36981;&#24490;Preferred Reporting Items for Systematic Reviews and Meta-analyses (PRISMA)&#20934;&#21017;&#36827;&#34892;&#20102;&#31995;&#32479;&#32508;&#36848;&#12290;&#20174;PubMed&#12289;Web of Science&#21644;&#30005;&#27668;&#21644;&#30005;&#23376;&#24037;&#31243;&#24072;&#23398;&#20250;&#20013;&#26816;&#32034;&#20102;2010&#24180;1&#26376;1&#26085;&#33267;2022&#24180;10&#26376;31&#26085;&#26399;&#38388;&#21457;&#34920;&#30340;&#25991;&#31456;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#20845;&#31181;&#20027;&#35201;&#30340;&#20559;&#35265;&#31867;&#22411;&#65292;&#24182;&#24635;&#32467;&#20102;&#29616;&#26377;&#30340;&#20559;&#35265;&#22788;&#29702;&#26041;&#27861;&#12290;&#32467;&#26524;&#65306;&#22312;&#26816;&#32034;&#21040;&#30340;252&#31687;&#25991;&#31456;&#20013;&#65292;&#26377;20&#31687;&#31526;&#21512;&#26368;&#32456;&#32508;&#36848;&#30340;&#32435;&#20837;&#26631;&#20934;&#12290;&#26412;&#32508;&#36848;&#28085;&#30422;&#20102;&#20845;&#31181;&#20559;&#35265;&#20013;&#30340;&#20116;&#31181;&#65306;&#20843;&#39033;&#30740;&#31350;&#20998;&#26512;&#20102;&#36873;&#25321;&#20559;&#35265;&#65307;&#20845;&#39033;&#30740;&#31350;&#38024;&#23545;&#38544;&#24615;&#20559;&#35265;&#65307;&#20116;&#39033;&#30740;&#31350;&#23545;&#28151;&#26434;&#20559;&#35265;&#36827;&#34892;&#20102;&#30740;&#31350;&#65307;&#22235;&#39033;&#30740;&#31350;&#23545;&#27979;&#37327;&#20559;&#35265;&#36827;&#34892;&#20102;&#30740;&#31350;&#65307;&#20004;&#39033;&#30740;&#31350;&#23545;&#31639;&#27861;&#20559;&#35265;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#22312;&#20559;&#35265;&#22788;&#29702;&#26041;&#27861;&#26041;&#38754;&#65292;&#26377;&#21313;&#39033;&#30740;&#31350;&#36827;&#34892;&#20102;&#25506;&#35752;&#12290;
&lt;/p&gt;
&lt;p&gt;
Objectives: Artificial intelligence (AI) applications utilizing electronic health records (EHRs) have gained popularity, but they also introduce various types of bias. This study aims to systematically review the literature that address bias in AI research utilizing EHR data. Methods: A systematic review was conducted following the Preferred Reporting Items for Systematic Reviews and Meta-analyses (PRISMA) guideline. We retrieved articles published between January 1, 2010, and October 31, 2022, from PubMed, Web of Science, and the Institute of Electrical and Electronics Engineers. We defined six major types of bias and summarized the existing approaches in bias handling. Results: Out of the 252 retrieved articles, 20 met the inclusion criteria for the final review. Five out of six bias were covered in this review: eight studies analyzed selection bias; six on implicit bias; five on confounding bias; four on measurement bias; two on algorithmic bias. For bias handling approaches, ten st
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#25552;&#20986;ConfAIde&#22522;&#20934;&#65292;&#25581;&#31034;&#20102;LLMs&#30340;&#19978;&#19979;&#25991;&#38544;&#31169;&#25512;&#29702;&#33021;&#21147;&#20013;&#30340;&#37325;&#35201;&#24369;&#28857;&#65292;&#23454;&#39564;&#35777;&#26126;&#21363;&#20351;&#26159;&#26368;&#24378;&#22823;&#30340;&#27169;&#22411;&#20063;&#20250;&#22312;&#20154;&#31867;&#19981;&#20250;&#30340;&#19978;&#19979;&#25991;&#20013;&#27844;&#38706;&#31169;&#20154;&#20449;&#24687;&#65292;&#24378;&#35843;&#20102;&#25506;&#32034;&#26032;&#22411;&#25512;&#29702;&#26102;&#38544;&#31169;&#20445;&#25252;&#26041;&#27861;&#30340;&#36843;&#20999;&#38656;&#27714;&#12290;</title><link>http://arxiv.org/abs/2310.17884</link><description>&lt;p&gt;
LLM&#33021;&#20445;&#23432;&#31192;&#23494;&#21527;&#65311;&#36890;&#36807;&#19978;&#19979;&#25991;&#23436;&#25972;&#24615;&#29702;&#35770;&#27979;&#35797;&#35821;&#35328;&#27169;&#22411;&#30340;&#38544;&#31169;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Can LLMs Keep a Secret? Testing Privacy Implications of Language Models via Contextual Integrity Theory. (arXiv:2310.17884v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17884
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#25552;&#20986;ConfAIde&#22522;&#20934;&#65292;&#25581;&#31034;&#20102;LLMs&#30340;&#19978;&#19979;&#25991;&#38544;&#31169;&#25512;&#29702;&#33021;&#21147;&#20013;&#30340;&#37325;&#35201;&#24369;&#28857;&#65292;&#23454;&#39564;&#35777;&#26126;&#21363;&#20351;&#26159;&#26368;&#24378;&#22823;&#30340;&#27169;&#22411;&#20063;&#20250;&#22312;&#20154;&#31867;&#19981;&#20250;&#30340;&#19978;&#19979;&#25991;&#20013;&#27844;&#38706;&#31169;&#20154;&#20449;&#24687;&#65292;&#24378;&#35843;&#20102;&#25506;&#32034;&#26032;&#22411;&#25512;&#29702;&#26102;&#38544;&#31169;&#20445;&#25252;&#26041;&#27861;&#30340;&#36843;&#20999;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;AI&#21161;&#25163;&#65288;&#24037;&#20316;&#12289;&#23478;&#24237;&#31561;&#65289;&#20013;&#20132;&#20114;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24341;&#20837;&#20102;&#19968;&#31995;&#21015;&#26032;&#30340;&#25512;&#29702;&#26102;&#38544;&#31169;&#39118;&#38505;&#65306;LLMs&#20174;&#22810;&#20010;&#26469;&#28304;&#30340;&#36755;&#20837;&#20013;&#33719;&#21462;&#19981;&#21516;&#31867;&#22411;&#30340;&#20449;&#24687;&#65292;&#24182;&#26399;&#26395;&#22312;&#32473;&#23450;&#30340;&#19978;&#19979;&#25991;&#20013;&#25512;&#29702;&#20986;&#22312;&#20309;&#31181;&#30446;&#30340;&#21644;&#19982;&#35841;&#20998;&#20139;&#30340;&#20869;&#23481;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;ConfAIde&#65292;&#19968;&#20010;&#26088;&#22312;&#35782;&#21035;&#25351;&#20196;&#35843;&#25972;&#30340;LLMs&#38544;&#31169;&#25512;&#29702;&#33021;&#21147;&#20013;&#37325;&#35201;&#24369;&#28857;&#30340;&#22522;&#20934;&#65292;&#26469;&#24341;&#36215;&#20154;&#20204;&#23545;&#19978;&#19979;&#25991;&#38544;&#31169;&#36825;&#19968;&#26497;&#20854;&#20851;&#38190;&#20294;&#32463;&#24120;&#34987;&#24573;&#35270;&#30340;&#27010;&#24565;&#30340;&#20851;&#27880;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#21363;&#20351;&#26159;GPT-4&#21644;ChatGPT&#31561;&#26368;&#24378;&#22823;&#30340;&#27169;&#22411;&#65292;&#22312;&#20154;&#31867;&#19981;&#20250;&#30340;&#19978;&#19979;&#25991;&#20013;&#65292;&#20063;&#20250;&#27844;&#38706;39&#65285;&#21644;57&#65285;&#30340;&#31169;&#20154;&#20449;&#24687;&#12290;&#21363;&#20351;&#25105;&#20204;&#20351;&#29992;&#20445;&#25252;&#38544;&#31169;&#30340;&#25552;&#31034;&#25110;&#24605;&#32500;&#38142;&#25512;&#29702;&#65292;&#36825;&#31181;&#27844;&#28431;&#20063;&#20250;&#25345;&#32493;&#23384;&#22312;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#24378;&#35843;&#20102;&#36843;&#20999;&#38656;&#35201;&#25506;&#32034;&#22522;&#20110;&#25512;&#29702;&#21644;&#29702;&#35770;&#30340;&#26032;&#22411;&#25512;&#29702;&#26102;&#38544;&#31169;&#20445;&#25252;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The interactive use of large language models (LLMs) in AI assistants (at work, home, etc.) introduces a new set of inference-time privacy risks: LLMs are fed different types of information from multiple sources in their inputs and are expected to reason about what to share in their outputs, for what purpose and with whom, within a given context. In this work, we draw attention to the highly critical yet overlooked notion of contextual privacy by proposing ConfAIde, a benchmark designed to identify critical weaknesses in the privacy reasoning capabilities of instruction-tuned LLMs. Our experiments show that even the most capable models such as GPT-4 and ChatGPT reveal private information in contexts that humans would not, 39% and 57% of the time, respectively. This leakage persists even when we employ privacy-inducing prompts or chain-of-thought reasoning. Our work underscores the immediate need to explore novel inference-time privacy-preserving approaches, based on reasoning and theory
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#19978;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#20146;&#21644;&#24230;&#35780;&#20998;&#36861;&#36394;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#38750;&#32447;&#24615;&#20256;&#25773;&#65292;&#23588;&#20854;&#20851;&#27880;&#35745;&#31639;&#26426;&#35270;&#35273;&#24212;&#29992;&#12290;&#23454;&#39564;&#35777;&#23454;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#21644;&#23545;&#24191;&#27867;&#24212;&#29992;&#30340;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.11439</link><description>&lt;p&gt;
&#36890;&#36807;&#38750;&#32447;&#24615;&#30740;&#31350;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Understanding deep neural networks through the lens of their non-linearity. (arXiv:2310.11439v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11439
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#19978;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#20146;&#21644;&#24230;&#35780;&#20998;&#36861;&#36394;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#38750;&#32447;&#24615;&#20256;&#25773;&#65292;&#23588;&#20854;&#20851;&#27880;&#35745;&#31639;&#26426;&#35270;&#35273;&#24212;&#29992;&#12290;&#23454;&#39564;&#35777;&#23454;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#21644;&#23545;&#24191;&#27867;&#24212;&#29992;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNN)&#30340;&#26174;&#33879;&#25104;&#21151;&#24120;&#24120;&#24402;&#22240;&#20110;&#23427;&#20204;&#30340;&#39640;&#34920;&#36798;&#33021;&#21147;&#21644;&#36817;&#20284;&#20219;&#24847;&#22797;&#26434;&#20989;&#25968;&#30340;&#33021;&#21147;&#12290;&#20107;&#23454;&#19978;&#65292;DNN&#26159;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#27169;&#22411;&#65292;&#20854;&#20013;&#24341;&#20837;&#30340;&#28608;&#27963;&#20989;&#25968;&#22312;&#20854;&#20013;&#36215;&#21040;&#20102;&#37325;&#35201;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#35768;&#22810;&#30740;&#31350;&#36890;&#36807;&#36817;&#20284;&#33021;&#21147;&#30340;&#35270;&#35282;&#30740;&#31350;&#20102;DNN&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#20294;&#37327;&#21270;DNN&#25110;&#20010;&#21035;&#28608;&#27963;&#20989;&#25968;&#30340;&#38750;&#32447;&#24615;&#20173;&#28982;&#26159;&#19968;&#20010;&#24320;&#25918;&#24615;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#22312;&#20855;&#20307;&#20851;&#27880;&#35745;&#31639;&#26426;&#35270;&#35273;&#24212;&#29992;&#20013;&#36861;&#36394;&#38750;&#32447;&#24615;&#20256;&#25773;&#30340;&#29702;&#35770;&#26377;&#25928;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#20146;&#21644;&#24230;&#35780;&#20998;&#20801;&#35768;&#25105;&#20204;&#28145;&#20837;&#20102;&#35299;&#21508;&#31181;&#19981;&#21516;&#20307;&#31995;&#32467;&#26500;&#21644;&#23398;&#20064;&#33539;&#24335;&#30340;&#20869;&#37096;&#24037;&#20316;&#21407;&#29702;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#22823;&#37327;&#30340;&#23454;&#39564;&#32467;&#26524;&#65292;&#31361;&#20986;&#20102;&#25152;&#25552;&#20986;&#30340;&#20146;&#21644;&#24230;&#35780;&#20998;&#30340;&#23454;&#38469;&#25928;&#29992;&#21644;&#28508;&#22312;&#24212;&#29992;&#30340;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The remarkable success of deep neural networks (DNN) is often attributed to their high expressive power and their ability to approximate functions of arbitrary complexity. Indeed, DNNs are highly non-linear models, and activation functions introduced into them are largely responsible for this. While many works studied the expressive power of DNNs through the lens of their approximation capabilities, quantifying the non-linearity of DNNs or of individual activation functions remains an open problem. In this paper, we propose the first theoretically sound solution to track non-linearity propagation in deep neural networks with a specific focus on computer vision applications. Our proposed affinity score allows us to gain insights into the inner workings of a wide range of different architectures and learning paradigms. We provide extensive experimental results that highlight the practical utility of the proposed affinity score and its potential for long-reaching applications.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;"RAFA"&#30340;&#21407;&#21017;&#26694;&#26550;&#65292;&#36890;&#36807;&#22312;LLM&#20013;&#23558;&#25512;&#29702;&#35270;&#20026;&#23398;&#20064;&#21644;&#35268;&#21010;&#30340;&#36125;&#21494;&#26031;&#38382;&#39064;&#65292;&#21327;&#35843;&#25512;&#29702;&#21644;&#34892;&#21160;&#12290;&#36890;&#36807;&#19968;&#20010;&#25552;&#31034;&#27169;&#26495;&#36827;&#34892;&#25512;&#29702;&#65292;&#23398;&#20064;&#24182;&#21046;&#23450;&#26410;&#26469;&#30340;&#36712;&#36857;&#35268;&#21010;&#65292;&#28982;&#21518;&#22312;&#27599;&#19968;&#27493;&#20013;&#37319;&#21462;&#35745;&#21010;&#36712;&#36857;&#30340;&#21021;&#22987;&#34892;&#21160;&#24182;&#37325;&#26032;&#35268;&#21010;&#26410;&#26469;&#36712;&#36857;&#12290;&#36825;&#20010;&#26694;&#26550;&#20855;&#26377;&#21487;&#35777;&#26126;&#30340;&#36951;&#25022;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2309.17382</link><description>&lt;p&gt;
&#26410;&#26469;&#30340;&#21407;&#22240;&#65292;&#29616;&#22312;&#30340;&#34892;&#21160;&#65306;&#19968;&#31181;&#21487;&#35777;&#26126;&#26679;&#26412;&#25928;&#29575;&#30340;&#33258;&#20027;LLM&#26234;&#33021;&#20307;&#30340;&#21407;&#21017;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Reason for Future, Act for Now: A Principled Framework for Autonomous LLM Agents with Provable Sample Efficiency. (arXiv:2309.17382v2 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.17382
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;"RAFA"&#30340;&#21407;&#21017;&#26694;&#26550;&#65292;&#36890;&#36807;&#22312;LLM&#20013;&#23558;&#25512;&#29702;&#35270;&#20026;&#23398;&#20064;&#21644;&#35268;&#21010;&#30340;&#36125;&#21494;&#26031;&#38382;&#39064;&#65292;&#21327;&#35843;&#25512;&#29702;&#21644;&#34892;&#21160;&#12290;&#36890;&#36807;&#19968;&#20010;&#25552;&#31034;&#27169;&#26495;&#36827;&#34892;&#25512;&#29702;&#65292;&#23398;&#20064;&#24182;&#21046;&#23450;&#26410;&#26469;&#30340;&#36712;&#36857;&#35268;&#21010;&#65292;&#28982;&#21518;&#22312;&#27599;&#19968;&#27493;&#20013;&#37319;&#21462;&#35745;&#21010;&#36712;&#36857;&#30340;&#21021;&#22987;&#34892;&#21160;&#24182;&#37325;&#26032;&#35268;&#21010;&#26410;&#26469;&#36712;&#36857;&#12290;&#36825;&#20010;&#26694;&#26550;&#20855;&#26377;&#21487;&#35777;&#26126;&#30340;&#36951;&#25022;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#23637;&#31034;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#20294;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#23558;&#25512;&#29702;&#36716;&#21270;&#20026;&#34892;&#21160;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#29305;&#21035;&#26159;&#65292;&#22914;&#20309;&#36890;&#36807;&#25512;&#29702;&#30340;&#20869;&#37096;&#26426;&#21046;&#22312;&#19982;&#22806;&#37096;&#29615;&#22659;&#30340;&#26368;&#23569;&#20132;&#20114;&#27425;&#25968;&#20869;&#21487;&#35777;&#26126;&#22320;&#23436;&#25104;&#32473;&#23450;&#20219;&#21153;&#20173;&#28982;&#19981;&#28165;&#26970;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26377;&#21487;&#35777;&#26126;&#36951;&#25022;&#20445;&#35777;&#30340;&#21407;&#21017;&#26694;&#26550;&#26469;&#21327;&#35843;&#25512;&#29702;&#21644;&#34892;&#21160;&#65292;&#31216;&#20043;&#20026;&#8220;&#20026;&#26410;&#26469;&#32780;&#25512;&#29702;&#65292;&#20026;&#29616;&#22312;&#32780;&#34892;&#21160;&#8221;&#65288;RAFA&#65289;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#25512;&#29702;&#30340;&#25552;&#31034;&#27169;&#26495;&#65292;&#20174;&#20869;&#23384;&#32531;&#20914;&#21306;&#20013;&#23398;&#20064;&#24182;&#21046;&#23450;&#26410;&#26469;&#30340;&#38271;&#26399;&#36712;&#36857;&#35268;&#21010;&#65288;&#8220;&#20026;&#26410;&#26469;&#32780;&#25512;&#29702;&#8221;&#65289;&#12290;&#22312;&#27599;&#19968;&#27493;&#20013;&#65292;LLM&#26234;&#33021;&#20307;&#37319;&#21462;&#35745;&#21010;&#36712;&#36857;&#30340;&#21021;&#22987;&#34892;&#21160;&#65288;&#8220;&#20026;&#29616;&#22312;&#32780;&#34892;&#21160;&#8221;&#65289;&#65292;&#23558;&#25910;&#38598;&#21040;&#30340;&#21453;&#39304;&#23384;&#20648;&#22312;&#20869;&#23384;&#32531;&#20914;&#21306;&#20013;&#65292;&#24182;&#37325;&#26032;&#35843;&#29992;&#25512;&#29702;&#36807;&#31243;&#20174;&#26032;&#29366;&#24577;&#37325;&#26032;&#35268;&#21010;&#26410;&#26469;&#30340;&#36712;&#36857;&#12290;&#20851;&#38190;&#24605;&#24819;&#26159;&#23558;LLM&#20013;&#30340;&#25512;&#29702;&#35270;&#20026;&#23398;&#20064;&#21644;&#35268;&#21010;&#30340;&#36125;&#21494;&#26031;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) demonstrate impressive reasoning abilities, but translating reasoning into actions in the real world remains challenging. In particular, it remains unclear how to complete a given task provably within a minimum number of interactions with the external environment, e.g., through an internal mechanism of reasoning. To this end, we propose a principled framework with provable regret guarantees to orchestrate reasoning and acting, which we call "reason for future, act for now" (\texttt{RAFA}). Specifically, we design a prompt template for reasoning that learns from the memory buffer and plans a future trajectory over a long horizon ("reason for future"). At each step, the LLM agent takes the initial action of the planned trajectory ("act for now"), stores the collected feedback in the memory buffer, and reinvokes the reasoning routine to replan the future trajectory from the new state.  The key idea is to cast reasoning in LLMs as learning and planning in Bayes
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21551;&#21457;&#24335;&#20840;&#23616;&#25628;&#32034;&#30340;&#31639;&#27861;&#65288;UMCTS&#65289;&#29992;&#20110;&#26689;&#26550;&#32467;&#26500;&#23610;&#23544;&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#32467;&#21512;&#26356;&#26032;&#36807;&#31243;&#21644;&#33945;&#29305;&#21345;&#27931;&#26641;&#25628;&#32034;&#65288;MCTS&#65289;&#20197;&#21450;&#20351;&#29992;&#19978;&#30028;&#32622;&#20449;&#24230;&#65288;UCB&#65289;&#26469;&#33719;&#24471;&#21512;&#36866;&#30340;&#35774;&#35745;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2309.06045</link><description>&lt;p&gt;
&#22522;&#20110;&#21551;&#21457;&#24335;&#20840;&#23616;&#25628;&#32034;&#30340;&#26689;&#26550;&#32467;&#26500;&#23610;&#23544;&#20248;&#21270;&#38382;&#39064;&#30340;&#25913;&#36827;&#33945;&#29305;&#21345;&#27931;&#26641;&#25628;&#32034;&#65288;UMCTS&#65289;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Update Monte Carlo tree search (UMCTS) algorithm for heuristic global search of sizing optimization problems for truss structures. (arXiv:2309.06045v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06045
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21551;&#21457;&#24335;&#20840;&#23616;&#25628;&#32034;&#30340;&#31639;&#27861;&#65288;UMCTS&#65289;&#29992;&#20110;&#26689;&#26550;&#32467;&#26500;&#23610;&#23544;&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#32467;&#21512;&#26356;&#26032;&#36807;&#31243;&#21644;&#33945;&#29305;&#21345;&#27931;&#26641;&#25628;&#32034;&#65288;MCTS&#65289;&#20197;&#21450;&#20351;&#29992;&#19978;&#30028;&#32622;&#20449;&#24230;&#65288;UCB&#65289;&#26469;&#33719;&#24471;&#21512;&#36866;&#30340;&#35774;&#35745;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26689;&#26550;&#32467;&#26500;&#23610;&#23544;&#20248;&#21270;&#26159;&#19968;&#20010;&#22797;&#26434;&#30340;&#35745;&#31639;&#38382;&#39064;&#65292;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#36866;&#29992;&#20110;&#22788;&#29702;&#26080;&#26799;&#24230;&#35745;&#31639;&#30340;&#22810;&#27169;&#24577;&#38382;&#39064;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39640;&#25928;&#20248;&#21270;&#31639;&#27861;&#8212;&#8212;&#26356;&#26032;&#33945;&#29305;&#21345;&#27931;&#26641;&#25628;&#32034;&#65288;UMCTS&#65289;&#65292;&#29992;&#20110;&#33719;&#24471;&#21512;&#36866;&#30340;&#26689;&#26550;&#32467;&#26500;&#35774;&#35745;&#12290;UMCTS&#26159;&#19968;&#31181;&#22522;&#20110;RL&#30340;&#26041;&#27861;&#65292;&#23558;&#26032;&#39062;&#30340;&#26356;&#26032;&#36807;&#31243;&#21644;&#33945;&#29305;&#21345;&#27931;&#26641;&#25628;&#32034;&#65288;MCTS&#65289;&#19982;&#19978;&#30028;&#32622;&#20449;&#24230;&#65288;UCB&#65289;&#30456;&#32467;&#21512;&#12290;&#26356;&#26032;&#36807;&#31243;&#24847;&#21619;&#30528;&#22312;&#27599;&#19968;&#36718;&#20013;&#65292;&#27599;&#20010;&#26500;&#20214;&#30340;&#26368;&#20339;&#25130;&#38754;&#31215;&#36890;&#36807;&#25628;&#32034;&#26641;&#30830;&#23450;&#65292;&#20854;&#21021;&#22987;&#29366;&#24577;&#26159;&#19978;&#19968;&#36718;&#30340;&#26368;&#32456;&#29366;&#24577;&#12290;&#22312;UMCTS&#31639;&#27861;&#20013;&#65292;&#24341;&#20837;&#20102;&#21152;&#36895;&#36873;&#25321;&#25104;&#21592;&#38754;&#31215;&#21644;&#36845;&#20195;&#27425;&#25968;&#30340;&#21152;&#36895;&#22120;&#65292;&#20197;&#20943;&#23569;&#35745;&#31639;&#26102;&#38388;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#27599;&#20010;&#29366;&#24577;&#65292;&#24179;&#22343;&#22870;&#21169;&#34987;&#26368;&#20339;&#22870;&#21169;&#30340;&#27169;&#25311;&#36807;&#31243;&#20013;&#25910;&#38598;&#26469;&#30340;&#22870;&#21169;&#26367;&#20195;&#65292;&#30830;&#23450;&#26368;&#20248;&#35299;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20248;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#26356;&#26032;&#36807;&#31243;&#21644;MCTS&#65292;&#20197;&#21450;&#20351;&#29992;UCB&#26469;&#20248;&#21270;&#26689;&#26550;&#32467;&#26500;&#35774;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sizing optimization of truss structures is a complex computational problem, and the reinforcement learning (RL) is suitable for dealing with multimodal problems without gradient computations. In this paper, a new efficient optimization algorithm called update Monte Carlo tree search (UMCTS) is developed to obtain the appropriate design for truss structures. UMCTS is an RL-based method that combines the novel update process and Monte Carlo tree search (MCTS) with the upper confidence bound (UCB). Update process means that in each round, the optimal cross-sectional area of each member is determined by search tree, and its initial state is the final state in the previous round. In the UMCTS algorithm, an accelerator for the number of selections for member area and iteration number is introduced to reduce the computation time. Moreover, for each state, the average reward is replaced by the best reward collected on the simulation process to determine the optimal solution. The proposed optim
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;HYPER&#29992;&#20110;&#35843;&#25972;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#24322;&#24120;&#20540;&#26816;&#27979;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#26080;&#30417;&#30563;DOD&#27169;&#22411;&#20013;&#30340;&#36229;&#21442;&#25968;&#35843;&#25972;&#21644;&#27169;&#22411;&#36873;&#25321;&#30340;&#25361;&#25112;&#65292;&#36890;&#36807;&#35774;&#35745;&#21644;&#35757;&#32451;&#36229;&#32593;&#32476;(HN)&#23558;&#36229;&#21442;&#25968;&#26144;&#23556;&#21040;&#20027;&#35201;DOD&#27169;&#22411;&#30340;&#26368;&#20248;&#26435;&#37325;&#19978;&#12290;</title><link>http://arxiv.org/abs/2307.10529</link><description>&lt;p&gt;
&#24555;&#36895;&#26080;&#30417;&#30563;&#28145;&#24230;&#24322;&#24120;&#20540;&#27169;&#22411;&#36873;&#25321;&#19982;&#36229;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Fast Unsupervised Deep Outlier Model Selection with Hypernetworks. (arXiv:2307.10529v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10529
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;HYPER&#29992;&#20110;&#35843;&#25972;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#24322;&#24120;&#20540;&#26816;&#27979;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#26080;&#30417;&#30563;DOD&#27169;&#22411;&#20013;&#30340;&#36229;&#21442;&#25968;&#35843;&#25972;&#21644;&#27169;&#22411;&#36873;&#25321;&#30340;&#25361;&#25112;&#65292;&#36890;&#36807;&#35774;&#35745;&#21644;&#35757;&#32451;&#36229;&#32593;&#32476;(HN)&#23558;&#36229;&#21442;&#25968;&#26144;&#23556;&#21040;&#20027;&#35201;DOD&#27169;&#22411;&#30340;&#26368;&#20248;&#26435;&#37325;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24322;&#24120;&#20540;&#26816;&#27979;(OD)&#22312;&#35768;&#22810;&#39046;&#22495;&#37117;&#26377;&#24212;&#29992;&#65292;&#24182;&#26377;&#35768;&#22810;&#25216;&#26415;&#30340;&#20016;&#23500;&#25991;&#29486;&#12290;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;OD(DOD)&#30001;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#35768;&#22810;&#36827;&#23637;&#32780;&#21463;&#21040;&#20102;&#26368;&#36817;&#30340;&#20851;&#27880;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#20851;&#38190;&#20294;&#40092;&#20026;&#20154;&#30693;&#30340;&#38382;&#39064;&#65292;&#21363;&#26080;&#30417;&#30563;DOD&#30340;&#26377;&#25928;&#36229;&#21442;&#25968;(HP)&#35843;&#25972;/&#27169;&#22411;&#36873;&#25321;&#12290;&#34429;&#28982;&#19968;&#20123;&#20808;&#21069;&#30340;&#24037;&#20316;&#25253;&#21578;&#20102;OD&#27169;&#22411;&#23545;HP&#30340;&#25935;&#24863;&#24615;&#65292;&#20294;&#23545;&#20110;&#23637;&#31034;&#20102;&#38271;&#21015;&#34920;HP&#30340;&#29616;&#20195;DOD&#27169;&#22411;&#26469;&#35828;&#65292;&#36825;&#21464;&#24471;&#38750;&#24120;&#20851;&#38190;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;HYPER&#26469;&#35843;&#25972;DOD&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#20004;&#20010;&#22522;&#26412;&#25361;&#25112;&#65306;(1)&#26080;&#30417;&#30563;&#24773;&#20917;&#19979;&#30340;&#39564;&#35777;(&#30001;&#20110;&#32570;&#20047;&#26631;&#35760;&#30340;&#24322;&#24120;&#20540;)&#65292;&#20197;&#21450;(2) HP/&#27169;&#22411;&#31354;&#38388;&#30340;&#39640;&#25928;&#25628;&#32034; (&#30001;&#20110;HP&#25968;&#37327;&#30340;&#25351;&#25968;&#22686;&#38271;)&#12290;&#20851;&#38190;&#24605;&#24819;&#26159;&#35774;&#35745;&#21644;&#35757;&#32451;&#19968;&#20010;&#26032;&#39062;&#30340;&#36229;&#32593;&#32476;(HN)&#65292;&#20854;&#23558;HP&#26144;&#23556;&#21040;&#20027;&#35201;DOD&#27169;&#22411;&#30340;&#26368;&#20248;&#26435;&#37325;&#19978;&#12290;&#21453;&#36807;&#26469;&#65292;HYPER&#21033;&#29992;&#19968;&#20010;&#21333;&#29420;&#30340;HN&#65292;&#21487;&#20197;&#21160;&#24577;&#29983;&#25104;&#22810;&#20010;DOD&#27169;&#22411;&#30340;&#26435;&#37325; (&#23545;&#24212;&#20110;...)&#12290;
&lt;/p&gt;
&lt;p&gt;
Outlier detection (OD) finds many applications with a rich literature of numerous techniques. Deep neural network based OD (DOD) has seen a recent surge of attention thanks to the many advances in deep learning. In this paper, we consider a critical-yet-understudied challenge with unsupervised DOD, that is, effective hyperparameter (HP) tuning/model selection. While several prior work report the sensitivity of OD models to HPs, it becomes ever so critical for the modern DOD models that exhibit a long list of HPs. We introduce HYPER for tuning DOD models, tackling two fundamental challenges: (1) validation without supervision (due to lack of labeled anomalies), and (2) efficient search of the HP/model space (due to exponential growth in the number of HPs). A key idea is to design and train a novel hypernetwork (HN) that maps HPs onto optimal weights of the main DOD model. In turn, HYPER capitalizes on a single HN that can dynamically generate weights for many DOD models (corresponding t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#27979;&#35797;&#26102;&#39046;&#22495;&#27867;&#21270;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#27979;&#35797;&#26102;&#20351;&#29992;&#27010;&#29575;&#20266;&#26631;&#31614;&#21644;&#21464;&#20998;&#37051;&#23621;&#26631;&#31614;&#26469;&#25512;&#24191;&#28304;&#22495;&#35757;&#32451;&#30340;&#27169;&#22411;&#21040;&#30446;&#26631;&#39046;&#22495;&#65292;&#20197;&#25552;&#39640;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#21644;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.04033</link><description>&lt;p&gt;
&#23398;&#20064;&#29992;&#20110;&#27979;&#35797;&#26102;&#39046;&#22495;&#27867;&#21270;&#30340;&#21464;&#20998;&#37051;&#23621;&#26631;&#31614;
&lt;/p&gt;
&lt;p&gt;
Learning Variational Neighbor Labels for Test-Time Domain Generalization. (arXiv:2307.04033v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.04033
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#27979;&#35797;&#26102;&#39046;&#22495;&#27867;&#21270;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#27979;&#35797;&#26102;&#20351;&#29992;&#27010;&#29575;&#20266;&#26631;&#31614;&#21644;&#21464;&#20998;&#37051;&#23621;&#26631;&#31614;&#26469;&#25512;&#24191;&#28304;&#22495;&#35757;&#32451;&#30340;&#27169;&#22411;&#21040;&#30446;&#26631;&#39046;&#22495;&#65292;&#20197;&#25552;&#39640;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#21644;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#33268;&#21147;&#20110;&#39046;&#22495;&#27867;&#21270;&#65292;&#22312;&#26410;&#30693;&#30340;&#30446;&#26631;&#39046;&#22495;&#20013;&#21482;&#22312;&#28304;&#39046;&#22495;&#19978;&#36827;&#34892;&#35757;&#32451;&#27169;&#22411;&#12290;&#25105;&#20204;&#22312;&#28304;&#22495;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#28982;&#21518;&#22312;&#30446;&#26631;&#22495;&#19978;&#36827;&#34892;&#25512;&#29702;&#65292;&#21033;&#29992;&#26080;&#26631;&#31614;&#30446;&#26631;&#25968;&#25454;&#26412;&#36523;&#30340;&#20215;&#20540;&#12290;&#25105;&#20204;&#20570;&#20986;&#20102;&#19977;&#20010;&#36129;&#29486;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#30446;&#26631;&#26679;&#26412;&#30340;&#27010;&#29575;&#20266;&#26631;&#31614;&#65292;&#20197;&#22312;&#27979;&#35797;&#26102;&#23558;&#28304;&#39046;&#22495;&#35757;&#32451;&#30340;&#27169;&#22411;&#25512;&#24191;&#21040;&#30446;&#26631;&#39046;&#22495;&#12290;&#25105;&#20204;&#23558;&#27979;&#35797;&#26102;&#30340;&#25512;&#24191;&#24314;&#27169;&#20026;&#21464;&#20998;&#25512;&#29702;&#38382;&#39064;&#65292;&#36890;&#36807;&#23558;&#20266;&#26631;&#31614;&#24314;&#27169;&#20026;&#20998;&#24067;&#65292;&#32771;&#34385;&#27867;&#21270;&#36807;&#31243;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#20943;&#36731;&#20266;&#26631;&#31614;&#19981;&#20934;&#30830;&#24615;&#24102;&#26469;&#30340;&#35823;&#23548;&#20449;&#21495;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#23398;&#20064;&#20102;&#21464;&#20998;&#37051;&#23621;&#26631;&#31614;&#65292;&#23558;&#37051;&#36817;&#30446;&#26631;&#26679;&#26412;&#30340;&#20449;&#24687;&#32435;&#20837;&#21040;&#29983;&#25104;&#26356;&#24378;&#40065;&#26834;&#20266;&#26631;&#31614;&#30340;&#36807;&#31243;&#20013;&#12290;&#31532;&#19977;&#65292;&#20026;&#20102;&#23398;&#20064;&#23558;&#26356;&#20855;&#20195;&#34920;&#24615;&#30340;&#30446;&#26631;&#20449;&#24687;&#32435;&#20837;&#21040;&#29983;&#25104;&#26356;&#20934;&#30830;&#12289;&#26356;&#24378;&#40065;&#26834;&#30340;&#21464;&#20998;&#37051;&#23621;&#26631;&#31614;&#30340;&#33021;&#21147;&#20013;&#65292;&#25105;&#20204;
&lt;/p&gt;
&lt;p&gt;
This paper strives for domain generalization, where models are trained exclusively on source domains before being deployed at unseen target domains. We follow the strict separation of source training and target testing but exploit the value of the unlabeled target data itself during inference. We make three contributions. First, we propose probabilistic pseudo-labeling of target samples to generalize the source-trained model to the target domain at test time. We formulate the generalization at test time as a variational inference problem by modeling pseudo labels as distributions to consider the uncertainty during generalization and alleviate the misleading signal of inaccurate pseudo labels. Second, we learn variational neighbor labels that incorporate the information of neighboring target samples to generate more robust pseudo labels. Third, to learn the ability to incorporate more representative target information and generate more precise and robust variational neighbor labels, we 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26631;&#20934;&#26041;&#27861;&#26469;&#35780;&#20272;&#20219;&#20309;&#27169;&#24577;&#30340;&#29983;&#25104;AI&#31995;&#32479;&#30340;&#31038;&#20250;&#24433;&#21709;&#65292;&#20998;&#20026;&#22522;&#30784;&#31995;&#32479;&#21644;&#31038;&#20250;&#26041;&#38754;&#30340;&#35780;&#20272;&#65292;&#28085;&#30422;7&#20010;&#31038;&#20250;&#24433;&#21709;&#31867;&#21035;&#65292;&#21253;&#25324;&#20559;&#35265;&#12289;&#38544;&#31169;&#20445;&#25252;&#12289;&#29615;&#22659;&#25104;&#26412;&#31561;&#12290;</title><link>http://arxiv.org/abs/2306.05949</link><description>&lt;p&gt;
&#35780;&#20272;&#29983;&#25104;AI&#31995;&#32479;&#22312;&#31995;&#32479;&#21644;&#31038;&#20250;&#20013;&#30340;&#31038;&#20250;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Evaluating the Social Impact of Generative AI Systems in Systems and Society. (arXiv:2306.05949v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05949
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26631;&#20934;&#26041;&#27861;&#26469;&#35780;&#20272;&#20219;&#20309;&#27169;&#24577;&#30340;&#29983;&#25104;AI&#31995;&#32479;&#30340;&#31038;&#20250;&#24433;&#21709;&#65292;&#20998;&#20026;&#22522;&#30784;&#31995;&#32479;&#21644;&#31038;&#20250;&#26041;&#38754;&#30340;&#35780;&#20272;&#65292;&#28085;&#30422;7&#20010;&#31038;&#20250;&#24433;&#21709;&#31867;&#21035;&#65292;&#21253;&#25324;&#20559;&#35265;&#12289;&#38544;&#31169;&#20445;&#25252;&#12289;&#29615;&#22659;&#25104;&#26412;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;AI&#31995;&#32479;&#36328;&#36234;&#25991;&#26412;&#12289;&#22270;&#20687;&#12289;&#38899;&#39057;&#12289;&#35270;&#39057;&#31561;&#22810;&#31181;&#27169;&#24577;&#65292;&#20855;&#26377;&#24191;&#27867;&#30340;&#31038;&#20250;&#24433;&#21709;&#65292;&#20294;&#30446;&#21069;&#19981;&#23384;&#22312;&#23448;&#26041;&#26631;&#20934;&#26469;&#35780;&#20272;&#36825;&#20123;&#24433;&#21709;&#21644;&#24212;&#35813;&#35780;&#20272;&#21738;&#20123;&#24433;&#21709;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26631;&#20934;&#26041;&#27861;&#26469;&#35780;&#20272;&#20219;&#20309;&#27169;&#24577;&#30340;&#29983;&#25104;AI&#31995;&#32479;&#65292;&#20998;&#20026;&#20004;&#22823;&#31867;&#21035;&#65306;&#23545;&#20110;&#27809;&#26377;&#39044;&#23450;&#24212;&#29992;&#30340;&#22522;&#30784;&#31995;&#32479;&#21487;&#20197;&#35780;&#20272;&#20160;&#20040;&#65292;&#20197;&#21450;&#21487;&#20197;&#22312;&#31038;&#20250;&#20013;&#35780;&#20272;&#20160;&#20040;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#20855;&#20307;&#30340;&#31038;&#20250;&#24433;&#21709;&#31867;&#21035;&#20197;&#21450;&#22914;&#20309;&#35780;&#20272;&#22522;&#30784;&#25216;&#26415;&#31995;&#32479;&#12289;&#20154;&#27665;&#21644;&#31038;&#20250;&#12290;&#25105;&#20204;&#30340;&#22522;&#30784;&#31995;&#32479;&#26694;&#26550;&#23450;&#20041;&#20102;&#19971;&#20010;&#31038;&#20250;&#24433;&#21709;&#31867;&#21035;&#65306;&#20559;&#35265;&#12289;&#21051;&#26495;&#21360;&#35937;&#21644;&#34920;&#29616;&#24615;&#20260;&#23475;&#65307;&#25991;&#21270;&#20215;&#20540;&#21644;&#25935;&#24863;&#20869;&#23481;&#65307;&#19981;&#23545;&#31561;&#30340;&#24615;&#33021;&#65307;&#38544;&#31169;&#21644;&#25968;&#25454;&#20445;&#25252;&#65307;&#36130;&#21153;&#25104;&#26412;&#65307;&#29615;&#22659;&#25104;&#26412;&#65307;&#20197;&#21450;&#25968;&#25454;&#21644;&#20869;&#23481;&#30417;&#31649;&#21171;&#21160;&#25104;&#26412;&#12290;&#24314;&#35758;&#30340;&#35780;&#20272;&#26041;&#27861;&#36866;&#29992;&#20110;&#25152;&#26377;&#27169;&#24577;&#21644;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative AI systems across modalities, ranging from text, image, audio, and video, have broad social impacts, but there exists no official standard for means of evaluating those impacts and which impacts should be evaluated. We move toward a standard approach in evaluating a generative AI system for any modality, in two overarching categories: what is able to be evaluated in a base system that has no predetermined application and what is able to be evaluated in society. We describe specific social impact categories and how to approach and conduct evaluations in the base technical system, then in people and society. Our framework for a base system defines seven categories of social impact: bias, stereotypes, and representational harms; cultural values and sensitive content; disparate performance; privacy and data protection; financial costs; environmental costs; and data and content moderation labor costs. Suggested methods for evaluation apply to all modalities and analyses of the li
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#31995;&#32479;&#22320;&#20998;&#26512;&#20102;&#22810;&#27169;&#24577;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#65288;MXAI&#65289;&#39046;&#22495;&#30340;&#26368;&#26032;&#36827;&#23637;&#21644;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#65292;&#20174;&#39044;&#27979;&#20219;&#21153;&#21644;&#25968;&#25454;&#38598;&#21040;MXAI&#26041;&#27861;&#21644;&#35780;&#20272;&#24230;&#37327;&#26631;&#20934;&#36827;&#34892;&#20102;&#20840;&#38754;&#20171;&#32461;&#21644;&#35752;&#35770;&#12290;</title><link>http://arxiv.org/abs/2306.05731</link><description>&lt;p&gt;
&#22810;&#27169;&#24577;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#65306;&#26041;&#27861;&#23398;&#36827;&#23637;&#21644;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#30340;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Multimodal Explainable Artificial Intelligence: A Comprehensive Review of Methodological Advances and Future Research Directions. (arXiv:2306.05731v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05731
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#31995;&#32479;&#22320;&#20998;&#26512;&#20102;&#22810;&#27169;&#24577;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#65288;MXAI&#65289;&#39046;&#22495;&#30340;&#26368;&#26032;&#36827;&#23637;&#21644;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#65292;&#20174;&#39044;&#27979;&#20219;&#21153;&#21644;&#25968;&#25454;&#38598;&#21040;MXAI&#26041;&#27861;&#21644;&#35780;&#20272;&#24230;&#37327;&#26631;&#20934;&#36827;&#34892;&#20102;&#20840;&#38754;&#20171;&#32461;&#21644;&#35752;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#31995;&#32479;&#22320;&#20998;&#26512;&#20102;&#22810;&#27169;&#24577;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#65288;MXAI&#65289;&#39046;&#22495;&#30340;&#26368;&#26032;&#36827;&#23637;&#12290;&#29305;&#21035;&#26159;&#65292;&#39318;&#20808;&#25551;&#36848;&#20102;&#30456;&#20851;&#30340;&#20027;&#35201;&#39044;&#27979;&#20219;&#21153;&#21644;&#20844;&#24320;&#21487;&#29992;&#25968;&#25454;&#38598;&#12290;&#38543;&#21518;&#65292;&#25552;&#20379;&#20102;&#25991;&#29486;&#20013;MXAI&#26041;&#27861;&#30340;&#32467;&#26500;&#21270;&#20171;&#32461;&#65292;&#32771;&#34385;&#21040;&#20197;&#19979;&#26631;&#20934;&#65306;a&#65289;&#28041;&#21450;&#30340;&#27169;&#24577;&#25968;&#37327;&#65292;b&#65289;&#20135;&#29983;&#35299;&#37322;&#30340;&#38454;&#27573;&#65292;&#20197;&#21450;c&#65289;&#37319;&#29992;&#30340;&#26041;&#27861;&#35770;&#31867;&#22411;&#65288;&#21363;&#25968;&#23398;&#24418;&#24335;&#21270;&#65289;&#12290;&#28982;&#21518;&#65292;&#35752;&#35770;&#20102;&#29992;&#20110;MXAI&#35780;&#20272;&#30340;&#24230;&#37327;&#26631;&#20934;&#12290;&#26368;&#21518;&#65292;&#25552;&#20379;&#20102;&#24403;&#21069;&#25361;&#25112;&#21644;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#30340;&#20840;&#38754;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
The current study focuses on systematically analyzing the recent advances in the field of Multimodal eXplainable Artificial Intelligence (MXAI). In particular, the relevant primary prediction tasks and publicly available datasets are initially described. Subsequently, a structured presentation of the MXAI methods of the literature is provided, taking into account the following criteria: a) The number of the involved modalities, b) The stage at which explanations are produced, and c) The type of the adopted methodology (i.e. mathematical formalism). Then, the metrics used for MXAI evaluation are discussed. Finally, a comprehensive analysis of current challenges and future research directions is provided.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25506;&#32034;&#25216;&#26415;&#65292;&#20351;&#29992;&#20540;&#26465;&#20214;&#29366;&#24577;&#29109;&#26469;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#20013;&#25506;&#32034;&#19981;&#36275;&#30340;&#38382;&#39064;&#65292;&#21487;&#20197;&#22343;&#34913;&#22320;&#35206;&#30422;&#20302;&#20215;&#20540;&#21644;&#39640;&#20215;&#20540;&#29366;&#24577;&#65292;&#30456;&#36739;&#20110;&#29616;&#26377;&#22522;&#20110;&#29109;&#30340;&#25506;&#32034;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;MuJoCo&#22522;&#20934;&#27979;&#35797;&#21644;Atari&#28216;&#25103;&#19978;&#26377;&#30528;&#26174;&#33879;&#30340;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2305.19476</link><description>&lt;p&gt;
&#20351;&#29992;&#20540;&#26465;&#20214;&#29366;&#24577;&#29109;&#25506;&#32034;&#21152;&#36895;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Accelerating Reinforcement Learning with Value-Conditional State Entropy Exploration. (arXiv:2305.19476v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19476
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25506;&#32034;&#25216;&#26415;&#65292;&#20351;&#29992;&#20540;&#26465;&#20214;&#29366;&#24577;&#29109;&#26469;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#20013;&#25506;&#32034;&#19981;&#36275;&#30340;&#38382;&#39064;&#65292;&#21487;&#20197;&#22343;&#34913;&#22320;&#35206;&#30422;&#20302;&#20215;&#20540;&#21644;&#39640;&#20215;&#20540;&#29366;&#24577;&#65292;&#30456;&#36739;&#20110;&#29616;&#26377;&#22522;&#20110;&#29109;&#30340;&#25506;&#32034;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;MuJoCo&#22522;&#20934;&#27979;&#35797;&#21644;Atari&#28216;&#25103;&#19978;&#26377;&#30528;&#26174;&#33879;&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25506;&#32034;&#30340;&#19968;&#31181;&#26377;&#25928;&#25216;&#26415;&#26159;&#36890;&#36807;&#40723;&#21169;&#23545;&#35775;&#38382;&#29366;&#24577;&#31354;&#38388;&#30340;&#22343;&#21248;&#35206;&#30422;&#26469;&#26368;&#22823;&#21270;&#24050;&#35775;&#38382;&#29366;&#24577;&#20998;&#24067;&#30340;&#29109;&#65292;&#21363;&#29366;&#24577;&#29109;&#12290;&#28982;&#32780;&#65292;&#23427;&#22312;&#26377;&#20219;&#21153;&#22870;&#21169;&#30340;&#30417;&#30563;&#35774;&#32622;&#20013;&#24448;&#24448;&#38590;&#20197;&#24212;&#23545;&#65292;&#20854;&#20013;&#20195;&#29702;&#36235;&#21521;&#20110;&#35775;&#38382;&#39640;&#20215;&#20540;&#29366;&#24577;&#20197;&#21033;&#29992;&#20219;&#21153;&#22870;&#21169;&#12290;&#36825;&#20010;&#20559;&#22909;&#20250;&#23548;&#33268;&#39640;&#20215;&#20540;&#29366;&#24577;&#21644;&#20302;&#20215;&#20540;&#29366;&#24577;&#30340;&#20998;&#24067;&#19981;&#24179;&#34913;&#65292;&#24403;&#20998;&#24067;&#21464;&#24471;&#26356;&#21152;&#22343;&#21248;&#26102;&#65292;&#29366;&#24577;&#29109;&#20250;&#22686;&#21152;&#65292;&#20174;&#32780;&#20559;&#21521;&#20110;&#25506;&#32034;&#20302;&#20215;&#20540;&#21306;&#22495;&#12290;&#24403;&#39640;&#20215;&#20540;&#29366;&#24577;&#22312;&#29366;&#24577;&#31354;&#38388;&#20013;&#20998;&#24067;&#29421;&#31364;&#26102;&#65292;&#36825;&#20010;&#38382;&#39064;&#20250;&#36827;&#19968;&#27493;&#24694;&#21270;&#65292;&#20351;&#24471;&#20195;&#29702;&#23436;&#25104;&#20219;&#21153;&#21464;&#24471;&#26356;&#21152;&#22256;&#38590;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25506;&#32034;&#25216;&#26415;&#65292;&#26368;&#22823;&#21270;&#20540;&#26465;&#20214;&#29366;&#24577;&#29109;&#65292;&#23427;&#20998;&#21035;&#20272;&#35745;&#27599;&#20010;&#29366;&#24577;&#20215;&#20540;&#20272;&#35745;&#26465;&#20214;&#19979;&#30340;&#29366;&#24577;&#29109;&#65292;&#28982;&#21518;&#26368;&#22823;&#21270;&#23427;&#20204;&#30340;&#21152;&#26435;&#21644;&#12290;&#20540;&#26465;&#20214;&#29366;&#24577;&#29109;&#37327;&#21270;&#20102;&#20302;&#20215;&#20540;&#21644;&#39640;&#20215;&#20540;&#29366;&#24577;&#21306;&#22495;&#30340;&#35206;&#30422;&#33539;&#22260;&#65292;&#20174;&#32780;&#20351;&#20854;&#23545;&#19981;&#24179;&#34913;&#38382;&#39064;&#26356;&#21152;&#20581;&#22766;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#19968;&#31995;&#21015;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;MuJoCo&#22522;&#20934;&#27979;&#35797;&#21644;Atari&#28216;&#25103;&#19978;&#26174;&#33879;&#20248;&#20110;&#29616;&#26377;&#30340;&#22522;&#20110;&#29109;&#30340;&#25506;&#32034;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
A promising technique for exploration is to maximize the entropy of visited state distribution, i.e., state entropy, by encouraging uniform coverage of visited state space. While it has been effective for an unsupervised setup, it tends to struggle in a supervised setup with a task reward, where an agent prefers to visit high-value states to exploit the task reward. Such a preference can cause an imbalance between the distributions of high-value states and low-value states, which biases exploration towards low-value state regions as a result of the state entropy increasing when the distribution becomes more uniform. This issue is exacerbated when high-value states are narrowly distributed within the state space, making it difficult for the agent to complete the tasks. In this paper, we present a novel exploration technique that maximizes the value-conditional state entropy, which separately estimates the state entropies that are conditioned on the value estimates of each state, then ma
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#33021;&#22815;&#36890;&#36807;&#26497;&#38480;&#39044;&#27979;&#23454;&#29616;&#33258;&#36866;&#24212;&#30340;&#25512;&#26029;&#24310;&#36831;&#65292;&#20174;&#32780;&#33410;&#32422;&#33021;&#28304;&#19982;&#25552;&#39640;&#21487;&#38752;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.11322</link><description>&lt;p&gt;
SpikeCP: &#36890;&#36807;&#26497;&#38480;&#39044;&#27979;&#23454;&#29616;&#24310;&#36831;&#33258;&#36866;&#24212;&#21487;&#38752;&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
SpikeCP: Delay-Adaptive Reliable Spiking Neural Networks via Conformal Prediction. (arXiv:2305.11322v1 [cs.NE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11322
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#33021;&#22815;&#36890;&#36807;&#26497;&#38480;&#39044;&#27979;&#23454;&#29616;&#33258;&#36866;&#24212;&#30340;&#25512;&#26029;&#24310;&#36831;&#65292;&#20174;&#32780;&#33410;&#32422;&#33021;&#28304;&#19982;&#25552;&#39640;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;&#65288;SNN&#65289;&#36890;&#36807;&#20869;&#37096;&#20107;&#20214;&#39537;&#21160;&#30340;&#31070;&#32463;&#21160;&#24577;&#22788;&#29702;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65292;&#20854;&#33021;&#37327;&#28040;&#32791;&#21462;&#20915;&#20110;&#36755;&#20837;&#28436;&#31034;&#26399;&#38388;&#31070;&#32463;&#20803;&#20043;&#38388;&#20132;&#25442;&#30340;&#33033;&#20914;&#25968;&#37327;&#12290;&#22312;&#20856;&#22411;&#30340;SNN&#20998;&#31867;&#22120;&#23454;&#29616;&#20013;&#65292;&#20915;&#31574;&#26159;&#22312;&#25972;&#20010;&#36755;&#20837;&#24207;&#21015;&#34987;&#22788;&#29702;&#21518;&#20135;&#29983;&#30340;&#65292;&#23548;&#33268;&#24310;&#36831;&#21644;&#33021;&#37327;&#28040;&#32791;&#27700;&#24179;&#22312;&#36755;&#20837;&#20043;&#38388;&#26159;&#30456;&#23545;&#22343;&#21248;&#30340;&#12290;&#26368;&#36817;&#24341;&#20837;&#30340;&#24310;&#36831;&#33258;&#36866;&#24212;SNN&#21487;&#26681;&#25454;&#27599;&#20010;&#31034;&#20363;&#30340;&#38590;&#24230;&#26469;&#23450;&#21046;&#25512;&#26029;&#24310;&#36831; - &#20197;&#21450;&#38543;&#20043;&#32780;&#26469;&#30340;&#33021;&#32791; - &#36890;&#36807;&#22312;SNN&#27169;&#22411;&#36275;&#22815;&#8220;&#33258;&#20449;&#8221;&#26102;&#20135;&#29983;&#26089;&#26399;&#20915;&#31574;&#26469;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Spiking neural networks (SNNs) process time-series data via internal event-driven neural dynamics whose energy consumption depends on the number of spikes exchanged between neurons over the course of the input presentation. In typical implementations of an SNN classifier, decisions are produced after the entire input sequence has been processed, resulting in latency and energy consumption levels that are fairly uniform across inputs. Recently introduced delay-adaptive SNNs tailor the inference latency -- and, with it, the energy consumption -- to the difficulty of each example, by producing an early decision when the SNN model is sufficiently ``confident''. In this paper, we start by observing that, as an SNN processes input samples, its classification decisions tend to be first under-confident and then over-confident with respect to the decision's ground-truth, unknown, test accuracy. This makes it difficult to determine a stopping time that ensures a desired level of accuracy. To add
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#65292;&#21457;&#29616;&#20854;&#21487;&#20197;&#23558;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#36716;&#21270;&#20026;&#36866;&#24403;&#30340;&#34892;&#20026;&#65292;&#20294;&#22312;&#21306;&#20998;&#32454;&#24494;&#30340;&#21512;&#20316;&#21644;&#31454;&#20105;&#27700;&#24179;&#26041;&#38754;&#30340;&#33021;&#21147;&#21463;&#21040;&#38480;&#21046;&#65292;&#20026;&#20351;&#29992;LLMs&#22312;&#20154;&#31867;&#20915;&#31574;&#21046;&#23450;&#32972;&#26223;&#19979;&#30340;&#20262;&#29702;&#24847;&#20041;&#21644;&#23616;&#38480;&#24615;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;</title><link>http://arxiv.org/abs/2305.07970</link><description>&lt;p&gt;
&#21033;&#29992;&#23454;&#39564;&#32463;&#27982;&#23398;&#30740;&#31350;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#20986;&#29616;&#30340;&#31867;&#20284;&#30446;&#26631;&#34892;&#20026;
&lt;/p&gt;
&lt;p&gt;
Investigating Emergent Goal-Like Behaviour in Large Language Models Using Experimental Economics. (arXiv:2305.07970v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07970
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#65292;&#21457;&#29616;&#20854;&#21487;&#20197;&#23558;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#36716;&#21270;&#20026;&#36866;&#24403;&#30340;&#34892;&#20026;&#65292;&#20294;&#22312;&#21306;&#20998;&#32454;&#24494;&#30340;&#21512;&#20316;&#21644;&#31454;&#20105;&#27700;&#24179;&#26041;&#38754;&#30340;&#33021;&#21147;&#21463;&#21040;&#38480;&#21046;&#65292;&#20026;&#20351;&#29992;LLMs&#22312;&#20154;&#31867;&#20915;&#31574;&#21046;&#23450;&#32972;&#26223;&#19979;&#30340;&#20262;&#29702;&#24847;&#20041;&#21644;&#23616;&#38480;&#24615;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#29305;&#21035;&#26159;GPT-3.5&#65292;&#23454;&#29616;&#21512;&#20316;&#12289;&#31454;&#20105;&#12289;&#21033;&#20182;&#21644;&#33258;&#31169;&#34892;&#20026;&#30340;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#22312;&#31038;&#20250;&#22256;&#22659;&#19979;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#32858;&#28966;&#20110;&#36845;&#20195;&#22234;&#24466;&#22256;&#22659;&#65292;&#36825;&#26159;&#19968;&#20010;&#38750;&#38646;&#21644;&#20114;&#21160;&#30340;&#32463;&#20856;&#20363;&#23376;&#65292;&#20294;&#25105;&#20204;&#30340;&#26356;&#24191;&#27867;&#30740;&#31350;&#35745;&#21010;&#21253;&#25324;&#19968;&#31995;&#21015;&#23454;&#39564;&#32463;&#27982;&#23398;&#22330;&#26223;&#65292;&#21253;&#25324;&#26368;&#21518;&#36890;&#29266;&#21338;&#24328;&#12289;&#29420;&#35009;&#32773;&#21338;&#24328;&#21644;&#20844;&#20849;&#29289;&#21697;&#28216;&#25103;&#12290;&#20351;&#29992;&#34987;&#35797;&#20869;&#23454;&#39564;&#35774;&#35745;&#65292;&#25105;&#20204;&#36816;&#29992;&#19981;&#21516;&#30340;&#25552;&#31034;&#20449;&#24687;&#23454;&#20363;&#21270;&#30001;LLM&#29983;&#25104;&#30340;&#26234;&#33021;&#20307;&#65292;&#34920;&#36798;&#19981;&#21516;&#30340;&#21512;&#20316;&#21644;&#31454;&#20105;&#31435;&#22330;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#26234;&#33021;&#20307;&#22312;&#36845;&#20195;&#22234;&#24466;&#22256;&#22659;&#20013;&#30340;&#21512;&#20316;&#27700;&#24179;&#65292;&#21516;&#26102;&#32771;&#34385;&#21040;&#23427;&#20204;&#23545;&#21512;&#20316;&#25110;&#20986;&#23572;&#21453;&#23572;&#30340;&#20249;&#20276;&#34892;&#21160;&#30340;&#21709;&#24212;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;LLMs&#22312;&#26576;&#31181;&#31243;&#24230;&#19978;&#21487;&#20197;&#23558;&#21033;&#20182;&#21644;&#33258;&#31169;&#30340;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#36716;&#21270;&#20026;&#36866;&#24403;&#30340;&#34892;&#20026;&#65292;&#20294;&#23637;&#31034;&#20986;&#21306;&#20998;&#21512;&#20316;&#21644;&#31454;&#20105;&#27700;&#24179;&#30340;&#33021;&#21147;&#26377;&#38480;&#12290;&#24635;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#20026;&#22312;&#20154;&#31867;&#20915;&#31574;&#21046;&#23450;&#30340;&#32972;&#26223;&#19979;&#20351;&#29992;LLMs&#30340;&#20262;&#29702;&#24847;&#20041;&#21644;&#23616;&#38480;&#24615;&#25552;&#20379;&#20102;&#35777;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this study, we investigate the capacity of large language models (LLMs), specifically GPT-3.5, to operationalise natural language descriptions of cooperative, competitive, altruistic, and self-interested behavior in social dilemmas. Our focus is on the iterated Prisoner's Dilemma, a classic example of a non-zero-sum interaction, but our broader research program encompasses a range of experimental economics scenarios, including the ultimatum game, dictator game, and public goods game. Using a within-subject experimental design, we instantiated LLM-generated agents with various prompts that conveyed different cooperative and competitive stances. We then assessed the agents' level of cooperation in the iterated Prisoner's Dilemma, taking into account their responsiveness to the cooperative or defection actions of their partners. Our results provide evidence that LLMs can translate natural language descriptions of altruism and selfishness into appropriate behaviour to some extent, but e
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#23545;&#22242;&#38431;&#22312; AI &#31995;&#32479;&#20013;&#30340;&#30417;&#31649;&#27969;&#31243;&#30340;&#32437;&#21521;&#35266;&#23519;&#65292;&#25506;&#35752;&#20102; AI &#31995;&#32479;&#23545;&#20020;&#24202;&#20915;&#31574;&#21046;&#23450;&#20013;&#22242;&#38431;&#30417;&#31649;&#30340;&#24433;&#21709;&#65292;&#30740;&#31350;&#21457;&#29616;&#27492;&#21069;&#30340;&#19987;&#19994;&#22242;&#38431;&#30417;&#31649;&#26041;&#27861;&#20027;&#35201;&#20381;&#38752;&#35299;&#37322;&#21644;&#38382;&#35810;&#26469;&#33719;&#21462;&#20449;&#24687;&#65292;&#32780; AI &#30340;&#24341;&#20837;&#23558;&#21487;&#33021;&#22312;&#20449;&#24687;&#25259;&#38706;&#21644;&#20915;&#31574;&#21046;&#23450;&#26041;&#38754;&#36896;&#25104;&#19968;&#23450;&#31243;&#24230;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2303.14007</link><description>&lt;p&gt;
&#39640;&#39118;&#38505; AI &#30340;&#22242;&#38431;&#30417;&#31649;&#65306;&#22242;&#38431;&#22312;&#24490;&#29615;&#20013;
&lt;/p&gt;
&lt;p&gt;
'Team-in-the-loop' organisational oversight of high-stakes AI. (arXiv:2303.14007v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14007
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#23545;&#22242;&#38431;&#22312; AI &#31995;&#32479;&#20013;&#30340;&#30417;&#31649;&#27969;&#31243;&#30340;&#32437;&#21521;&#35266;&#23519;&#65292;&#25506;&#35752;&#20102; AI &#31995;&#32479;&#23545;&#20020;&#24202;&#20915;&#31574;&#21046;&#23450;&#20013;&#22242;&#38431;&#30417;&#31649;&#30340;&#24433;&#21709;&#65292;&#30740;&#31350;&#21457;&#29616;&#27492;&#21069;&#30340;&#19987;&#19994;&#22242;&#38431;&#30417;&#31649;&#26041;&#27861;&#20027;&#35201;&#20381;&#38752;&#35299;&#37322;&#21644;&#38382;&#35810;&#26469;&#33719;&#21462;&#20449;&#24687;&#65292;&#32780; AI &#30340;&#24341;&#20837;&#23558;&#21487;&#33021;&#22312;&#20449;&#24687;&#25259;&#38706;&#21644;&#20915;&#31574;&#21046;&#23450;&#26041;&#38754;&#36896;&#25104;&#19968;&#23450;&#31243;&#24230;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30417;&#31649;&#23545;&#20110;&#39640;&#39118;&#38505;&#20844;&#20849;&#37096;&#38376; AI &#24212;&#29992;&#31243;&#24207;&#33267;&#20851;&#37325;&#35201;&#65292;&#22240;&#20026;&#20915;&#31574;&#21487;&#33021;&#20250;&#23545;&#20010;&#20154;&#21644;&#38598;&#20307;&#20135;&#29983;&#28145;&#36828;&#24433;&#21709;&#12290;&#30446;&#21069;&#22312;&#20844;&#20849;&#37096;&#38376;&#20013;&#20851;&#20110; AI &#30417;&#31649;&#26426;&#21046;&#30340;&#35768;&#22810;&#24605;&#32771;&#37117;&#22260;&#32469;&#30528;&#20154;&#31867;&#20915;&#31574;&#32773;&#22788;&#20110; "&#24490;&#29615;&#20013; "&#36825;&#19968;&#27010;&#24565;&#65292;&#24182;&#19988;&#33021;&#22815;&#24178;&#39044;&#20197;&#38450;&#27490;&#38169;&#35823;&#21644;&#28508;&#22312;&#21361;&#23475;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#39640;&#39118;&#38505;&#20844;&#20849;&#37096;&#38376;&#32972;&#26223;&#19979;&#65292;&#20915;&#31574;&#30340;&#36816;&#33829;&#30417;&#31649;&#26159;&#30001;&#19987;&#19994;&#22242;&#38431;&#32780;&#19981;&#26159;&#20010;&#20154;&#36827;&#34892;&#30340;&#12290;&#37096;&#32626;&#30340; AI &#31995;&#32479;&#22914;&#20309;&#25972;&#21512;&#21040;&#36825;&#20123;&#29616;&#26377;&#30340;&#22242;&#38431;&#30417;&#31649;&#27969;&#31243;&#20013;&#65292;&#23578;&#26410;&#24341;&#36215;&#22826;&#22810;&#27880;&#24847;&#12290;&#25105;&#20204;&#36890;&#36807;&#21046;&#24230;&#20998;&#26512;&#25506;&#35752; AI &#23545;&#20020;&#24202;&#20915;&#31574;&#21046;&#23450;&#30340;&#29616;&#26377;&#30417;&#31649;&#30340;&#24433;&#21709;&#65292;&#22635;&#34917;&#35813;&#26041;&#38754;&#30340;&#31354;&#30333;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#29616;&#26377;&#30340;&#30417;&#31649;&#23884;&#22871;&#22312;&#19987;&#19994;&#22521;&#35757;&#35201;&#27714;&#20013;&#65292;&#24182;&#19988;&#22312;&#24449;&#35810;&#20851;&#38190;&#20449;&#24687;&#26102; heavilyrely  &#20110;&#35299;&#37322;&#21644;&#25552;&#38382;&#12290;&#19987;&#19994;&#22242;&#38431;&#20351;&#29992;&#21508;&#31181;&#20250;&#35745;&#25259;&#38706;&#25216;&#26415;&#26469;&#35686;&#21578;&#21516;&#20107;&#21644;&#30417;&#31649;&#34892;&#20026;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#22312; AI &#31995;&#32479;&#24341;&#20837;&#21040;&#29616;&#26377;&#30340;&#22242;&#38431;&#30417;&#31649;&#27969;&#31243;&#20013;&#65292;&#20449;&#24687;&#25259;&#38706;&#21644;&#20915;&#31574;&#21046;&#23450;&#21487;&#33021;&#21457;&#29983;&#25913;&#21464;&#30340;&#20960;&#31181;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Oversight is rightly recognised as vital within high-stakes public sector AI applications, where decisions can have profound individual and collective impacts. Much current thinking regarding forms of oversight mechanisms for AI within the public sector revolves around the idea of human decision makers being 'in-the-loop' and thus being able to intervene to prevent errors and potential harm. However, in a number of high-stakes public sector contexts, operational oversight of decisions is made by expert teams rather than individuals. The ways in which deployed AI systems can be integrated into these existing operational team oversight processes has yet to attract much attention. We address this gap by exploring the impacts of AI upon pre-existing oversight of clinical decision-making through institutional analysis. We find that existing oversight is nested within professional training requirements and relies heavily upon explanation and questioning to elicit vital information. Professio
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;&#34588;&#34562;&#31639;&#27861;&#20248;&#21270;&#20102;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#21442;&#25968;&#65292;&#25552;&#39640;&#20102;&#21307;&#23398;&#25991;&#26412;&#20998;&#31867;&#30340;&#20934;&#30830;&#24615;&#65292;&#26368;&#39640;&#20934;&#30830;&#29575;&#22312;&#33521;&#35821;&#25968;&#25454;&#38598;&#19978;&#36798;&#21040;&#20102;99.63%&#65292;&#22312;&#38463;&#25289;&#20271;&#35821;&#25968;&#25454;&#38598;&#19978;&#36798;&#21040;&#20102;88%&#12290;</title><link>http://arxiv.org/abs/2303.08021</link><description>&lt;p&gt;
&#29992;&#34588;&#34562;&#31639;&#27861;&#20248;&#21270;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#21442;&#25968;&#65292;&#25552;&#39640;&#21307;&#23398;&#25991;&#26412;&#20998;&#31867;&#20934;&#30830;&#24615;
&lt;/p&gt;
&lt;p&gt;
Optimizing Deep Learning Model Parameters with the Bees Algorithm for Improved Medical Text Classification. (arXiv:2303.08021v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08021
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#34588;&#34562;&#31639;&#27861;&#20248;&#21270;&#20102;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#21442;&#25968;&#65292;&#25552;&#39640;&#20102;&#21307;&#23398;&#25991;&#26412;&#20998;&#31867;&#30340;&#20934;&#30830;&#24615;&#65292;&#26368;&#39640;&#20934;&#30830;&#29575;&#22312;&#33521;&#35821;&#25968;&#25454;&#38598;&#19978;&#36798;&#21040;&#20102;99.63%&#65292;&#22312;&#38463;&#25289;&#20271;&#35821;&#25968;&#25454;&#38598;&#19978;&#36798;&#21040;&#20102;88%&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#34588;&#34562;&#31639;&#27861;&#23545;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#21442;&#25968;&#20248;&#21270;&#30340;&#26032;&#26426;&#21046;&#65292;&#36825;&#26159;&#19968;&#31181;&#26368;&#36817;&#24456;&#26377;&#21069;&#36884;&#30340;&#32676;&#26234;&#33021;&#31639;&#27861;&#12290;&#20248;&#21270;&#38382;&#39064;&#26159;&#22312;&#32473;&#23450;&#21021;&#22987;&#36229;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#30830;&#23450;&#30340;&#36845;&#20195;&#27425;&#25968;&#26469;&#26368;&#22823;&#21270;&#22522;&#20110;&#21307;&#23398;&#25991;&#26412;&#20998;&#31867;&#30142;&#30149;&#30340;&#20934;&#30830;&#24615;&#12290;&#23454;&#39564;&#21253;&#25324;&#20004;&#20010;&#19981;&#21516;&#30340;&#25968;&#25454;&#38598;&#65306;&#33521;&#35821;&#21644;&#38463;&#25289;&#20271;&#35821;&#12290;&#20351;&#29992;&#38271;&#30701;&#26399;&#35760;&#24518; (LSTM) &#21644;&#34588;&#34562;&#31639;&#27861;&#65292;&#22312;&#33521;&#35821;&#25968;&#25454;&#38598;&#19978;&#33719;&#24471;&#20102;99.63%&#30340;&#26368;&#39640;&#20934;&#30830;&#29575;&#65292;&#22312;&#38463;&#25289;&#20271;&#35821;&#25968;&#25454;&#38598;&#19978;&#20351;&#29992;AraBERT&#33719;&#24471;&#20102;88%&#30340;&#26368;&#39640;&#20934;&#30830;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a novel mechanism to obtain the optimal parameters of a deep learning model using the Bees Algorithm, which is a recent promising swarm intelligence algorithm. The optimization problem is to maximize the accuracy of classifying ailments based on medical text given the initial hyper-parameters to be adjusted throughout a definite number of iterations. Experiments included two different datasets: English and Arabic. The highest accuracy achieved is 99.63% on the English dataset using Long Short-Term Memory (LSTM) along with the Bees Algorithm, and 88% on the Arabic dataset using AraBERT.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#38750;&#27431;&#20960;&#37324;&#24503;&#26053;&#34892;&#21830;&#38382;&#39064;&#30340;&#20984;&#21253;&#26368;&#20415;&#23452;&#25554;&#20837;&#21551;&#21457;&#24335;&#35299;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#22810;&#32500;&#32553;&#25918;&#23558;&#38750;&#27431;&#20960;&#37324;&#24503;&#31354;&#38388;&#30340;&#28857;&#36817;&#20284;&#21040;&#27431;&#20960;&#37324;&#24503;&#31354;&#38388;&#65292;&#29983;&#25104;&#20102;&#21021;&#22987;&#21270;&#31639;&#27861;&#30340;&#20984;&#21253;&#12290;&#22312;&#35780;&#20272;&#20013;&#21457;&#29616;&#65292;&#35813;&#31639;&#27861;&#22312;&#22823;&#22810;&#25968;&#24773;&#20917;&#19979;&#20248;&#20110;&#26368;&#37051;&#36817;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2302.06582</link><description>&lt;p&gt;
&#38750;&#27431;&#20960;&#37324;&#24503;&#26053;&#34892;&#21830;&#38382;&#39064;&#30340;&#20984;&#21253;&#26368;&#20415;&#23452;&#25554;&#20837;&#21551;&#21457;&#24335;&#35299;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Convex Hull Cheapest Insertion Heuristic for the Non-Euclidean TSP. (arXiv:2302.06582v2 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.06582
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#38750;&#27431;&#20960;&#37324;&#24503;&#26053;&#34892;&#21830;&#38382;&#39064;&#30340;&#20984;&#21253;&#26368;&#20415;&#23452;&#25554;&#20837;&#21551;&#21457;&#24335;&#35299;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#22810;&#32500;&#32553;&#25918;&#23558;&#38750;&#27431;&#20960;&#37324;&#24503;&#31354;&#38388;&#30340;&#28857;&#36817;&#20284;&#21040;&#27431;&#20960;&#37324;&#24503;&#31354;&#38388;&#65292;&#29983;&#25104;&#20102;&#21021;&#22987;&#21270;&#31639;&#27861;&#30340;&#20984;&#21253;&#12290;&#22312;&#35780;&#20272;&#20013;&#21457;&#29616;&#65292;&#35813;&#31639;&#27861;&#22312;&#22823;&#22810;&#25968;&#24773;&#20917;&#19979;&#20248;&#20110;&#26368;&#37051;&#36817;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20247;&#25152;&#21608;&#30693;&#65292;&#20984;&#21253;&#26368;&#20415;&#23452;&#25554;&#20837;&#21551;&#21457;&#24335;&#31639;&#27861;&#21487;&#20197;&#22312;&#27431;&#20960;&#37324;&#24503;&#31354;&#38388;&#20013;&#20135;&#29983;&#33391;&#22909;&#30340;&#26053;&#34892;&#21830;&#38382;&#39064;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#36824;&#26410;&#22312;&#38750;&#27431;&#20960;&#37324;&#24503;&#24773;&#20917;&#19979;&#36827;&#34892;&#25193;&#23637;&#12290;&#20026;&#20102;&#35299;&#20915;&#38750;&#27431;&#20960;&#37324;&#24503;&#31354;&#38388;&#20013;&#22788;&#29702;&#38556;&#30861;&#29289;&#30340;&#22256;&#38590;&#65292;&#25552;&#20986;&#30340;&#25913;&#36827;&#26041;&#27861;&#20351;&#29992;&#22810;&#32500;&#32553;&#25918;&#23558;&#36825;&#20123;&#28857;&#39318;&#20808;&#36817;&#20284;&#21040;&#27431;&#20960;&#37324;&#24503;&#31354;&#38388;&#65292;&#20174;&#32780;&#21487;&#20197;&#29983;&#25104;&#21021;&#22987;&#21270;&#31639;&#27861;&#30340;&#20984;&#21253;&#12290;&#36890;&#36807;&#20462;&#25913;TSPLIB&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#21521;&#20854;&#20013;&#28155;&#21152;&#19981;&#21487;&#36890;&#36807;&#30340;&#20998;&#21106;&#22120;&#26469;&#20135;&#29983;&#38750;&#27431;&#20960;&#37324;&#24503;&#31354;&#38388;&#65292;&#35780;&#20272;&#20102;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#12290;&#22312;&#25152;&#30740;&#31350;&#30340;&#26696;&#20363;&#20013;&#65292;&#35813;&#31639;&#27861;&#34920;&#29616;&#20986;&#20248;&#20110;&#24120;&#29992;&#30340;&#26368;&#37051;&#36817;&#31639;&#27861;&#30340;&#24615;&#33021;&#65292;&#36798;&#21040;96%&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
The convex hull cheapest insertion heuristic is known to generate good solutions to the Traveling Salesperson Problem in Euclidean spaces, but it has not been extended to the non-Euclidean case. To address the difficulty of dealing with obstacles in the non-Euclidean space, the proposed adaptation uses multidimensional scaling to first approximate these points in a Euclidean space, thereby enabling the generation of the convex hull that initializes the algorithm. To evaluate the proposed algorithm, the TSPLIB benchmark data-set is modified by adding impassable separators that produce non-Euclidean spaces. The algorithm is demonstrated to outperform the commonly used Nearest Neighbor algorithm in 96% of the cases studied.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#35299;&#37322;&#26041;&#27861;&#65292;&#24182;&#22312;&#22810;&#31181;&#25968;&#25454;&#38598;&#19978;&#27979;&#35797;&#20102;&#21313;&#31181;&#35299;&#37322;&#22120;&#30340;&#34920;&#29616;&#65292;&#25552;&#20379;&#20102;&#19981;&#21516;GNN&#20307;&#31995;&#32467;&#26500;&#26131;&#35299;&#37322;&#24615;&#30340;&#20851;&#38190;&#27934;&#23519;&#12290;</title><link>http://arxiv.org/abs/2210.15304</link><description>&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#35299;&#37322;&#26041;&#27861;&#65306;&#19968;&#39033;&#27604;&#36739;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Explaining the Explainers in Graph Neural Networks: a Comparative Study. (arXiv:2210.15304v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.15304
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#35299;&#37322;&#26041;&#27861;&#65292;&#24182;&#22312;&#22810;&#31181;&#25968;&#25454;&#38598;&#19978;&#27979;&#35797;&#20102;&#21313;&#31181;&#35299;&#37322;&#22120;&#30340;&#34920;&#29616;&#65292;&#25552;&#20379;&#20102;&#19981;&#21516;GNN&#20307;&#31995;&#32467;&#26500;&#26131;&#35299;&#37322;&#24615;&#30340;&#20851;&#38190;&#27934;&#23519;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#24555;&#36895;&#21457;&#23637;&#21518;&#65292;GNN&#24050;&#32463;&#22312;&#35768;&#22810;&#31185;&#23398;&#21644;&#24037;&#31243;&#39046;&#22495;&#24212;&#29992;&#24191;&#27867;&#65292;&#36825;&#20419;&#20351;&#38656;&#35201;&#26041;&#27861;&#26469;&#29702;&#35299;&#23427;&#20204;&#30340;&#20915;&#31574;&#36807;&#31243;&#12290;&#26368;&#36817;&#20960;&#24180;&#65292;GNN&#35299;&#37322;&#22120;&#24320;&#22987;&#20986;&#29616;&#65292;&#26377;&#22810;&#31181;&#26041;&#27861;&#65292;&#19968;&#20123;&#26159;&#26032;&#39062;&#30340;&#65292;&#19968;&#20123;&#26159;&#20174;&#20854;&#20182;&#39046;&#22495;&#25913;&#32534;&#32780;&#26469;&#30340;&#12290;&#20026;&#20102;&#25972;&#29702;&#36825;&#31181;&#28023;&#37327;&#30340;&#35299;&#37322;&#26041;&#27861;&#65292;&#19968;&#20123;&#30740;&#31350;&#22312;&#21508;&#31181;&#21487;&#35299;&#37322;&#24615;&#25351;&#26631;&#26041;&#38754;&#23545;&#19981;&#21516;&#30340;&#35299;&#37322;&#22120;&#24615;&#33021;&#36827;&#34892;&#20102;&#22522;&#20934;&#27979;&#35797;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26089;&#26399;&#30340;&#24037;&#20316;&#27809;&#26377;&#23581;&#35797;&#25552;&#20379;&#20851;&#20110;&#19981;&#21516;&#30340;GNN&#20307;&#31995;&#32467;&#26500;&#26356;&#25110;&#19981;&#26131;&#35299;&#37322;&#30340;&#27934;&#23519;&#65292;&#20063;&#27809;&#26377;&#35828;&#26126;&#22312;&#32473;&#23450;&#29615;&#22659;&#20013;&#24212;&#35813;&#36873;&#25321;&#21738;&#31181;&#35299;&#37322;&#22120;&#12290;&#22312;&#26412;&#27425;&#35843;&#26597;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#35774;&#35745;&#31995;&#32479;&#24615;&#23454;&#39564;&#30740;&#31350;&#65292;&#23545;&#20843;&#20010;&#20195;&#34920;&#24615;&#20307;&#31995;&#32467;&#26500;&#19978;&#35757;&#32451;&#30340;&#21313;&#31181;&#35299;&#37322;&#22120;&#22312;&#20845;&#20010;&#31934;&#24515;&#35774;&#35745;&#30340;&#22270;&#21644;&#33410;&#28857;&#20998;&#31867;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#22635;&#34917;&#20102;&#36825;&#20123;&#31354;&#30333;&#65292;&#24182;&#25552;&#20379;&#20102;&#20851;&#38190;&#30340;&#35266;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Following a fast initial breakthrough in graph based learning, Graph Neural Networks (GNNs) have reached a widespread application in many science and engineering fields, prompting the need for methods to understand their decision process.  GNN explainers have started to emerge in recent years, with a multitude of methods both novel or adapted from other domains. To sort out this plethora of alternative approaches, several studies have benchmarked the performance of different explainers in terms of various explainability metrics. However, these earlier works make no attempts at providing insights into why different GNN architectures are more or less explainable, or which explainer should be preferred in a given setting.  In this survey, we fill these gaps by devising a systematic experimental study, which tests ten explainers on eight representative architectures trained on six carefully designed graph and node classification datasets. With our results we provide key insights on the cho
&lt;/p&gt;</description></item></channel></rss>