<rss version="2.0"><channel><title>Chat Arxiv physics.data-an</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for physics.data-an</description><item><title>&#36890;&#36807;&#23545;&#20849;&#21516;&#21407;&#22240;$C$&#36827;&#34892;&#26465;&#20214;&#35774;&#23450;&#65292;&#35299;&#20915;&#20102;&#36763;&#26222;&#26862;&#24726;&#35770;&#65292;&#25512;&#24191;&#20102;&#24726;&#35770;&#65292;&#24182;&#34920;&#26126;&#22312;&#20108;&#20803;&#20849;&#21516;&#21407;&#22240;$C$&#19978;&#36827;&#34892;&#26465;&#20214;&#35774;&#23450;&#30340;&#20851;&#32852;&#26041;&#21521;&#19982;&#21407;&#22987;$B$&#19978;&#36827;&#34892;&#26465;&#20214;&#35774;&#23450;&#30456;&#21516;</title><link>https://arxiv.org/abs/2403.00957</link><description>&lt;p&gt;
&#21033;&#29992;&#20849;&#22240;&#21407;&#21017;&#35299;&#20915;&#36763;&#26222;&#26862;&#24726;&#35770;
&lt;/p&gt;
&lt;p&gt;
Resolution of Simpson's paradox via the common cause principle
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00957
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;&#20849;&#21516;&#21407;&#22240;$C$&#36827;&#34892;&#26465;&#20214;&#35774;&#23450;&#65292;&#35299;&#20915;&#20102;&#36763;&#26222;&#26862;&#24726;&#35770;&#65292;&#25512;&#24191;&#20102;&#24726;&#35770;&#65292;&#24182;&#34920;&#26126;&#22312;&#20108;&#20803;&#20849;&#21516;&#21407;&#22240;$C$&#19978;&#36827;&#34892;&#26465;&#20214;&#35774;&#23450;&#30340;&#20851;&#32852;&#26041;&#21521;&#19982;&#21407;&#22987;$B$&#19978;&#36827;&#34892;&#26465;&#20214;&#35774;&#23450;&#30456;&#21516;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36763;&#26222;&#26862;&#24726;&#35770;&#26159;&#24314;&#31435;&#20004;&#20010;&#20107;&#20214;$a_1$&#21644;$a_2$&#20043;&#38388;&#30340;&#27010;&#29575;&#20851;&#32852;&#26102;&#30340;&#38556;&#30861;&#65292;&#32473;&#23450;&#31532;&#19977;&#20010;&#65288;&#28508;&#22312;&#30340;&#65289;&#38543;&#26426;&#21464;&#37327;$B$&#12290;&#25105;&#20204;&#20851;&#27880;&#30340;&#24773;&#26223;&#26159;&#38543;&#26426;&#21464;&#37327;$A$&#65288;&#27719;&#24635;&#20102;$a_1$&#12289;$a_2$&#21450;&#20854;&#34917;&#38598;&#65289;&#21644;$B$&#26377;&#19968;&#20010;&#21487;&#33021;&#26410;&#34987;&#35266;&#23519;&#21040;&#30340;&#20849;&#21516;&#21407;&#22240;$C$&#12290;&#25110;&#32773;&#65292;&#25105;&#20204;&#21487;&#20197;&#20551;&#35774;$C$&#23558;$A$&#20174;$B$&#20013;&#31579;&#36873;&#20986;&#21435;&#12290;&#23545;&#20110;&#36825;&#31181;&#24773;&#20917;&#65292;&#27491;&#30830;&#30340;$a_1$&#21644;$a_2$&#20043;&#38388;&#30340;&#20851;&#32852;&#24212;&#35813;&#36890;&#36807;&#23545;$C$&#36827;&#34892;&#26465;&#20214;&#35774;&#23450;&#26469;&#23450;&#20041;&#12290;&#36825;&#19968;&#35774;&#32622;&#23558;&#21407;&#22987;&#36763;&#26222;&#26862;&#24726;&#35770;&#25512;&#24191;&#20102;&#12290;&#29616;&#22312;&#23427;&#30340;&#20004;&#20010;&#30456;&#20114;&#30683;&#30462;&#30340;&#36873;&#39033;&#31616;&#21333;&#22320;&#25351;&#30340;&#26159;&#20004;&#20010;&#29305;&#23450;&#19988;&#19981;&#21516;&#30340;&#21407;&#22240;$C$&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#22914;&#26524;$B$&#21644;$C$&#26159;&#20108;&#36827;&#21046;&#30340;&#65292;$A$&#26159;&#22235;&#36827;&#21046;&#30340;&#65288;&#23545;&#20110;&#26377;&#25928;&#30340;&#36763;&#26222;&#26862;&#24726;&#35770;&#26469;&#35828;&#26159;&#26368;&#23567;&#19988;&#26368;&#24120;&#35265;&#30340;&#24773;&#20917;&#65289;&#65292;&#22312;&#20219;&#20309;&#20108;&#20803;&#20849;&#21516;&#21407;&#22240;$C$&#19978;&#36827;&#34892;&#26465;&#20214;&#35774;&#23450;&#23558;&#24314;&#31435;&#19982;&#22312;&#21407;&#22987;$B$&#19978;&#36827;&#34892;&#26465;&#20214;&#35774;&#23450;&#30456;&#21516;&#30340;$a_1$&#21644;$a_2$&#20043;&#38388;&#30340;&#20851;&#32852;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00957v1 Announce Type: cross  Abstract: Simpson's paradox is an obstacle to establishing a probabilistic association between two events $a_1$ and $a_2$, given the third (lurking) random variable $B$. We focus on scenarios when the random variables $A$ (which combines $a_1$, $a_2$, and their complements) and $B$ have a common cause $C$ that need not be observed. Alternatively, we can assume that $C$ screens out $A$ from $B$. For such cases, the correct association between $a_1$ and $a_2$ is to be defined via conditioning over $C$. This set-up generalizes the original Simpson's paradox. Now its two contradicting options simply refer to two particular and different causes $C$. We show that if $B$ and $C$ are binary and $A$ is quaternary (the minimal and the most widespread situation for valid Simpson's paradox), the conditioning over any binary common cause $C$ establishes the same direction of the association between $a_1$ and $a_2$ as the conditioning over $B$ in the original
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#23398;&#20064;&#38750;&#20998;&#31163;&#21704;&#23494;&#39039;&#31995;&#32479;&#30340;&#32467;&#26500;&#20445;&#25345;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#32479;&#35745;&#30456;&#20851;&#30340;&#21152;&#24615;&#21644;&#20056;&#24615;&#22122;&#22768;&#65292;&#24182;&#19988;&#36890;&#36807;&#23558;&#32467;&#26500;&#20445;&#25345;&#26041;&#27861;&#32435;&#20837;&#26694;&#26550;&#20013;&#65292;&#25552;&#20379;&#20102;&#23545;&#39640;&#32500;&#31995;&#32479;&#30340;&#39640;&#25928;&#35782;&#21035;&#12290;</title><link>http://arxiv.org/abs/2401.12476</link><description>&lt;p&gt;
&#29992;&#28145;&#24230;&#23398;&#20064;&#21644;&#38477;&#38454;&#24314;&#27169;&#36827;&#34892;&#36125;&#21494;&#26031;&#38750;&#20998;&#31163;&#21704;&#23494;&#39039;&#31995;&#32479;&#30340;&#35782;&#21035;&#21644;&#22810;&#39033;&#24335;&#22122;&#22768; (arXiv:2401.12476v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
Bayesian identification of nonseparable Hamiltonians with multiplicative noise using deep learning and reduced-order modeling. (arXiv:2401.12476v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12476
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#23398;&#20064;&#38750;&#20998;&#31163;&#21704;&#23494;&#39039;&#31995;&#32479;&#30340;&#32467;&#26500;&#20445;&#25345;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#32479;&#35745;&#30456;&#20851;&#30340;&#21152;&#24615;&#21644;&#20056;&#24615;&#22122;&#22768;&#65292;&#24182;&#19988;&#36890;&#36807;&#23558;&#32467;&#26500;&#20445;&#25345;&#26041;&#27861;&#32435;&#20837;&#26694;&#26550;&#20013;&#65292;&#25552;&#20379;&#20102;&#23545;&#39640;&#32500;&#31995;&#32479;&#30340;&#39640;&#25928;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#26500;&#20445;&#25345;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#20351;&#29992;&#38543;&#26426;&#21160;&#21147;&#27169;&#22411;&#30340;&#38750;&#20998;&#31163;&#21704;&#23494;&#39039;&#31995;&#32479;&#65292;&#35813;&#31995;&#32479;&#20801;&#35768;&#32479;&#35745;&#30456;&#20851;&#30340;&#65292;&#30690;&#37327;&#20540;&#30340;&#21152;&#24615;&#21644;&#20056;&#24615;&#27979;&#37327;&#22122;&#22768;&#12290;&#35813;&#26041;&#27861;&#30001;&#19977;&#20010;&#20027;&#35201;&#26041;&#38754;&#32452;&#25104;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;&#36125;&#21494;&#26031;&#21518;&#39564;&#20013;&#30340;&#20284;&#28982;&#20989;&#25968;&#25152;&#38656;&#30340;&#32479;&#35745;&#30456;&#20851;&#30340;&#65292;&#30690;&#37327;&#20540;&#30340;&#21152;&#24615;&#21644;&#20056;&#24615;&#22122;&#22768;&#27169;&#22411;&#30340;&#39640;&#26031;&#28388;&#27874;&#22120;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;&#29992;&#20110;&#23545;&#39640;&#32500;&#31995;&#32479;&#36827;&#34892;&#39640;&#25928;&#30340;&#36125;&#21494;&#26031;&#31995;&#32479;&#35782;&#21035;&#12290;&#31532;&#19977;&#65292;&#25105;&#20204;&#28436;&#31034;&#20102;&#22914;&#20309;&#23558;&#32467;&#26500;&#20445;&#25345;&#26041;&#27861;&#32435;&#20837;&#25152;&#25552;&#35758;&#30340;&#26694;&#26550;&#20013;&#65292;&#20351;&#29992;&#38750;&#20998;&#31163;&#21704;&#23494;&#39039;&#31995;&#32479;&#20316;&#20026;&#19968;&#20010;&#20030;&#20363;&#30340;&#31995;&#32479;&#31867;&#21035;&#12290;&#25105;&#20204;&#23558;&#36125;&#21494;&#26031;&#26041;&#27861;&#19982;&#19968;&#31181;&#26368;&#20808;&#36827;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#19968;&#20010;&#20856;&#22411;&#30340;&#38750;&#20998;&#31163;&#21704;&#23494;&#39039;&#27169;&#22411;&#21644;&#24102;&#26377;&#23567;&#22411;&#22122;&#22768;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#28151;&#27788;&#21452;&#25670;&#27169;&#22411;&#19978;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;
&lt;/p&gt;
&lt;p&gt;
This paper presents a structure-preserving Bayesian approach for learning nonseparable Hamiltonian systems using stochastic dynamic models allowing for statistically-dependent, vector-valued additive and multiplicative measurement noise. The approach is comprised of three main facets. First, we derive a Gaussian filter for a statistically-dependent, vector-valued, additive and multiplicative noise model that is needed to evaluate the likelihood within the Bayesian posterior. Second, we develop a novel algorithm for cost-effective application of Bayesian system identification to high-dimensional systems. Third, we demonstrate how structure-preserving methods can be incorporated into the proposed framework, using nonseparable Hamiltonians as an illustrative system class. We compare the Bayesian method to a state-of-the-art machine learning method on a canonical nonseparable Hamiltonian model and a chaotic double pendulum model with small, noisy training datasets. The results show that us
&lt;/p&gt;</description></item></channel></rss>