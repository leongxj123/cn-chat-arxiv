<rss version="2.0"><channel><title>Chat Arxiv physics.data-an</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for physics.data-an</description><item><title>&#25105;&#20204;&#30740;&#31350;&#20102;&#20108;&#20803;&#20998;&#31867;&#24615;&#33021;&#30340;&#20869;&#22312;&#25968;&#25454;&#38480;&#21046;&#21644;&#19978;&#30028;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#24182;&#36827;&#34892;&#20102;&#29702;&#35770;&#25512;&#29702;&#21644;&#23454;&#35777;&#26816;&#39564;&#65292;&#21457;&#29616;&#29702;&#35770;&#19978;&#38480;&#26159;&#21487;&#20197;&#34987;&#36798;&#21040;&#30340;&#65292;&#24182;&#35745;&#31639;&#20986;&#20102;&#19977;&#20010;&#24120;&#29992;&#35780;&#20272;&#25351;&#26631;&#30340;&#31934;&#30830;&#19978;&#38480;&#12290;</title><link>http://arxiv.org/abs/2401.17036</link><description>&lt;p&gt;
&#20108;&#20803;&#20998;&#31867;&#24615;&#33021;&#20013;&#30340;&#20869;&#22312;&#25968;&#25454;&#38480;&#21046;&#21644;&#19978;&#30028;
&lt;/p&gt;
&lt;p&gt;
Intrinsic Data Constraints and Upper Bounds in Binary Classification Performance. (arXiv:2401.17036v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.17036
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20108;&#20803;&#20998;&#31867;&#24615;&#33021;&#30340;&#20869;&#22312;&#25968;&#25454;&#38480;&#21046;&#21644;&#19978;&#30028;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#24182;&#36827;&#34892;&#20102;&#29702;&#35770;&#25512;&#29702;&#21644;&#23454;&#35777;&#26816;&#39564;&#65292;&#21457;&#29616;&#29702;&#35770;&#19978;&#38480;&#26159;&#21487;&#20197;&#34987;&#36798;&#21040;&#30340;&#65292;&#24182;&#35745;&#31639;&#20986;&#20102;&#19977;&#20010;&#24120;&#29992;&#35780;&#20272;&#25351;&#26631;&#30340;&#31934;&#30830;&#19978;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#32452;&#32455;&#30340;&#32467;&#26500;&#34987;&#24191;&#27867;&#35748;&#20026;&#23545;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#26377;&#37325;&#35201;&#24433;&#21709;&#65292;&#23588;&#20854;&#26159;&#22312;&#20108;&#20803;&#20998;&#31867;&#20219;&#21153;&#20013;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#35748;&#20026;&#32473;&#23450;&#25968;&#25454;&#38598;&#19978;&#20108;&#20803;&#20998;&#31867;&#22120;&#30340;&#26368;&#22823;&#28508;&#21147;&#20027;&#35201;&#21463;&#21040;&#25968;&#25454;&#30340;&#20869;&#22312;&#29305;&#24615;&#30340;&#38480;&#21046;&#12290;&#36890;&#36807;&#29702;&#35770;&#25512;&#29702;&#21644;&#23454;&#35777;&#26816;&#39564;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#26631;&#20934;&#30446;&#26631;&#20989;&#25968;&#12289;&#35780;&#20272;&#25351;&#26631;&#21644;&#20108;&#20803;&#20998;&#31867;&#22120;&#65292;&#24471;&#20986;&#20102;&#20004;&#20010;&#20027;&#35201;&#32467;&#35770;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#20108;&#20803;&#20998;&#31867;&#24615;&#33021;&#30340;&#29702;&#35770;&#19978;&#38480;&#26159;&#21487;&#20197;&#34987;&#29702;&#35770;&#19978;&#36798;&#21040;&#30340;&#12290;&#36825;&#20010;&#19978;&#38480;&#20195;&#34920;&#20102;&#23398;&#20064;&#25439;&#22833;&#21644;&#35780;&#20272;&#25351;&#26631;&#20043;&#38388;&#30340;&#21487;&#35745;&#31639;&#24179;&#34913;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#35745;&#31639;&#20102;&#19977;&#20010;&#24120;&#29992;&#35780;&#20272;&#25351;&#26631;&#30340;&#31934;&#30830;&#19978;&#38480;&#65292;&#25581;&#31034;&#20102;&#19982;&#25105;&#20204;&#24635;&#20307;&#35770;&#28857;&#30340;&#26681;&#26412;&#19968;&#33268;&#24615;&#65306;&#19978;&#30028;&#19982;&#20869;&#22312;&#25968;&#25454;&#38480;&#21046;&#23494;&#20999;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;
The structure of data organization is widely recognized as having a substantial influence on the efficacy of machine learning algorithms, particularly in binary classification tasks. Our research provides a theoretical framework suggesting that the maximum potential of binary classifiers on a given dataset is primarily constrained by the inherent qualities of the data. Through both theoretical reasoning and empirical examination, we employed standard objective functions, evaluative metrics, and binary classifiers to arrive at two principal conclusions. Firstly, we show that the theoretical upper bound of binary classification performance on actual datasets can be theoretically attained. This upper boundary represents a calculable equilibrium between the learning loss and the metric of evaluation. Secondly, we have computed the precise upper bounds for three commonly used evaluation metrics, uncovering a fundamental uniformity with our overarching thesis: the upper bound is intricately 
&lt;/p&gt;</description></item></channel></rss>