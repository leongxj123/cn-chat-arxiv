<rss version="2.0"><channel><title>Chat Arxiv cs.GR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.GR</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Res2Net&#30340;&#32418;&#22806;&#21644;&#21487;&#35265;&#20809;&#22270;&#20687;&#34701;&#21512;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#35757;&#32451;&#31574;&#30053;&#21644;&#34701;&#21512;&#31574;&#30053;&#65292;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#34701;&#21512;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2112.14540</link><description>&lt;p&gt;
Res2NetFuse&#65306;&#19968;&#31181;&#36866;&#29992;&#20110;&#32418;&#22806;&#21644;&#21487;&#35265;&#20809;&#22270;&#20687;&#30340;&#34701;&#21512;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Res2NetFuse: A Fusion Method for Infrared and Visible Images. (arXiv:2112.14540v3 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.14540
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Res2Net&#30340;&#32418;&#22806;&#21644;&#21487;&#35265;&#20809;&#22270;&#20687;&#34701;&#21512;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#35757;&#32451;&#31574;&#30053;&#21644;&#34701;&#21512;&#31574;&#30053;&#65292;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#34701;&#21512;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Res2Net&#30340;&#32418;&#22806;&#21644;&#21487;&#35265;&#20809;&#22270;&#20687;&#34701;&#21512;&#26694;&#26550;&#12290;&#25552;&#20986;&#30340;&#34701;&#21512;&#27169;&#22411;&#21253;&#25324;&#32534;&#30721;&#22120;&#12289;&#34701;&#21512;&#23618;&#21644;&#35299;&#30721;&#22120;&#19977;&#20010;&#37096;&#20998;&#12290;&#21033;&#29992;&#22522;&#20110;Res2Net&#30340;&#32534;&#30721;&#22120;&#25552;&#21462;&#28304;&#22270;&#20687;&#30340;&#22810;&#23610;&#24230;&#29305;&#24449;&#65292;&#24341;&#20837;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#31574;&#30053;&#65292;&#20165;&#20351;&#29992;&#21333;&#20010;&#22270;&#20687;&#36827;&#34892;&#35757;&#32451;&#12290;&#28982;&#21518;&#65292;&#22522;&#20110;&#27880;&#24847;&#21147;&#27169;&#22411;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#34701;&#21512;&#31574;&#30053;&#12290;&#26368;&#21518;&#65292;&#36890;&#36807;&#35299;&#30721;&#22120;&#37325;&#26500;&#34701;&#21512;&#22270;&#20687;&#12290;&#26412;&#25991;&#36824;&#23545;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#35814;&#32454;&#20998;&#26512;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#23458;&#35266;&#21644;&#20027;&#35266;&#35780;&#20272;&#20013;&#37117;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#34701;&#21512;&#24615;&#33021;&#65292;&#19982;&#29616;&#26377;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a novel Res2Net-based fusion framework for infrared and visible images. The proposed fusion model has three parts: an encoder, a fusion layer and a decoder, respectively. The Res2Net-based encoder is used to extract multi-scale features of source images, the paper introducing a new training strategy for training a Res2Net-based encoder that uses only a single image. Then, a new fusion strategy is developed based on the attention model. Finally, the fused image is reconstructed by the decoder. The proposed approach is also analyzed in detail. Experiments show that our method achieves state-of-the-art fusion performance in objective and subjective assessment by comparing with the existing methods.
&lt;/p&gt;</description></item></channel></rss>