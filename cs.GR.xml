<rss version="2.0"><channel><title>Chat Arxiv cs.GR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.GR</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;3D&#27169;&#25311;&#36229;&#20998;&#36776;&#29575;&#26694;&#26550;&#65292;&#33021;&#22815;&#39640;&#25928;&#12289;&#36924;&#30495;&#22320;&#22686;&#24378;&#20302;&#25104;&#26412;&#12289;&#23454;&#26102;&#29289;&#29702;&#27169;&#25311;&#20135;&#29983;&#30340;&#38754;&#37096;&#34920;&#29616;&#65292;&#20351;&#20854;&#25509;&#36817;&#20110;&#20855;&#26377;&#26356;&#39640;&#20998;&#36776;&#29575;&#21644;&#20934;&#30830;&#29289;&#29702;&#24314;&#27169;&#30340;&#21442;&#32771;&#36136;&#37327;&#31163;&#32447;&#27169;&#25311;&#22120;&#12290;</title><link>http://arxiv.org/abs/2305.03216</link><description>&lt;p&gt;
&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;3D&#27169;&#25311;&#36229;&#20998;&#36776;&#29575;&#23454;&#29616;&#36817;&#23454;&#26102;&#38754;&#37096;&#21160;&#30011;&#34920;&#29616;
&lt;/p&gt;
&lt;p&gt;
Near-realtime Facial Animation by Deep 3D Simulation Super-Resolution. (arXiv:2305.03216v1 [cs.GR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03216
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;3D&#27169;&#25311;&#36229;&#20998;&#36776;&#29575;&#26694;&#26550;&#65292;&#33021;&#22815;&#39640;&#25928;&#12289;&#36924;&#30495;&#22320;&#22686;&#24378;&#20302;&#25104;&#26412;&#12289;&#23454;&#26102;&#29289;&#29702;&#27169;&#25311;&#20135;&#29983;&#30340;&#38754;&#37096;&#34920;&#29616;&#65292;&#20351;&#20854;&#25509;&#36817;&#20110;&#20855;&#26377;&#26356;&#39640;&#20998;&#36776;&#29575;&#21644;&#20934;&#30830;&#29289;&#29702;&#24314;&#27169;&#30340;&#21442;&#32771;&#36136;&#37327;&#31163;&#32447;&#27169;&#25311;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#27169;&#25311;&#36229;&#20998;&#36776;&#29575;&#26694;&#26550;&#65292;&#33021;&#22815;&#39640;&#25928;&#12289;&#36924;&#30495;&#22320;&#22686;&#24378;&#20302;&#25104;&#26412;&#12289;&#23454;&#26102;&#29289;&#29702;&#27169;&#25311;&#20135;&#29983;&#30340;&#38754;&#37096;&#34920;&#29616;&#65292;&#20351;&#20854;&#25509;&#36817;&#20110;&#20855;&#26377;&#26356;&#39640;&#20998;&#36776;&#29575;&#65288;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#39640;&#36798;26&#20493;&#30340;&#20803;&#32032;&#25968;&#65289;&#21644;&#20934;&#30830;&#29289;&#29702;&#24314;&#27169;&#30340;&#21442;&#32771;&#36136;&#37327;&#31163;&#32447;&#27169;&#25311;&#22120;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#28304;&#20110;&#25105;&#20204;&#36890;&#36807;&#27169;&#25311;&#26500;&#24314;&#19968;&#32452;&#37197;&#23545;&#24103;&#24207;&#21015;&#30340;&#33021;&#21147;&#65292;&#36825;&#20123;&#24207;&#21015;&#20998;&#21035;&#26469;&#33258;&#20110;&#20302;&#20998;&#36776;&#29575;&#21644;&#39640;&#20998;&#36776;&#29575;&#27169;&#25311;&#22120;&#65292;&#24182;&#19988;&#22312;&#35821;&#20041;&#19978;&#30456;&#20114;&#23545;&#24212;&#12290;&#25105;&#20204;&#20197;&#38754;&#37096;&#21160;&#30011;&#20026;&#20363;&#65292;&#21019;&#36896;&#36825;&#31181;&#35821;&#20041;&#19968;&#33268;&#24615;&#30340;&#26041;&#24335;&#23601;&#26159;&#22312;&#20004;&#20010;&#27169;&#25311;&#22120;&#20013;&#35843;&#25972;&#21516;&#26679;&#30340;&#32908;&#32905;&#28608;&#27963;&#25511;&#21046;&#21644;&#39592;&#26550;&#23039;&#21183;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#31070;&#32463;&#32593;&#32476;&#36229;&#20998;&#36776;&#29575;&#26694;&#26550;&#20174;&#36825;&#20010;&#35757;&#32451;&#38598;&#20013;&#27867;&#21270;&#21040;&#30475;&#19981;&#35265;&#30340;&#34920;&#24773;&#65292;&#24182;&#19988;&#34917;&#20607;&#20004;&#20010;&#27169;&#25311;&#20043;&#38388;&#30340;&#24314;&#27169;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a neural network-based simulation super-resolution framework that can efficiently and realistically enhance a facial performance produced by a low-cost, realtime physics-based simulation to a level of detail that closely approximates that of a reference-quality off-line simulator with much higher resolution (26x element count in our examples) and accurate physical modeling. Our approach is rooted in our ability to construct - via simulation - a training set of paired frames, from the low- and high-resolution simulators respectively, that are in semantic correspondence with each other. We use face animation as an exemplar of such a simulation domain, where creating this semantic congruence is achieved by simply dialing in the same muscle actuation controls and skeletal pose in the two simulators. Our proposed neural network super-resolution framework generalizes from this training set to unseen expressions, compensates for modeling discrepancies between the two simulations du
&lt;/p&gt;</description></item></channel></rss>