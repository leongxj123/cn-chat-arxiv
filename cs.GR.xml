<rss version="2.0"><channel><title>Chat Arxiv cs.GR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.GR</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#21487;&#25511;&#36816;&#21160;&#25193;&#25955;&#27169;&#22411;&#65288;COMODO&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#33258;&#22238;&#24402;&#36816;&#21160;&#25193;&#25955;&#27169;&#22411;&#65288;A-MDM&#65289;&#29983;&#25104;&#39640;&#20445;&#30495;&#24230;&#12289;&#38271;&#26102;&#38388;&#20869;&#30340;&#36816;&#21160;&#24207;&#21015;&#65292;&#20197;&#23454;&#29616;&#22312;&#21709;&#24212;&#20110;&#26102;&#21464;&#25511;&#21046;&#20449;&#21495;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#23454;&#26102;&#36816;&#21160;&#21512;&#25104;&#12290;</title><link>http://arxiv.org/abs/2306.00416</link><description>&lt;p&gt;
&#21487;&#25511;&#36816;&#21160;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Controllable Motion Diffusion Model. (arXiv:2306.00416v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00416
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#21487;&#25511;&#36816;&#21160;&#25193;&#25955;&#27169;&#22411;&#65288;COMODO&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#33258;&#22238;&#24402;&#36816;&#21160;&#25193;&#25955;&#27169;&#22411;&#65288;A-MDM&#65289;&#29983;&#25104;&#39640;&#20445;&#30495;&#24230;&#12289;&#38271;&#26102;&#38388;&#20869;&#30340;&#36816;&#21160;&#24207;&#21015;&#65292;&#20197;&#23454;&#29616;&#22312;&#21709;&#24212;&#20110;&#26102;&#21464;&#25511;&#21046;&#20449;&#21495;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#23454;&#26102;&#36816;&#21160;&#21512;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35745;&#31639;&#26426;&#21160;&#30011;&#20013;&#65292;&#20026;&#34394;&#25311;&#35282;&#33394;&#29983;&#25104;&#36924;&#30495;&#19988;&#21487;&#25511;&#30340;&#36816;&#21160;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#20174;&#22270;&#20687;&#29983;&#25104;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#25104;&#21151;&#20013;&#27762;&#21462;&#28789;&#24863;&#65292;&#23637;&#31034;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#30740;&#31350;&#22823;&#22810;&#38480;&#20110;&#31163;&#32447;&#24212;&#29992;&#65292;&#30446;&#26631;&#26159;&#29983;&#25104;&#21516;&#26102;&#29983;&#25104;&#25152;&#26377;&#27493;&#39588;&#30340;&#24207;&#21015;&#32423;&#29983;&#25104;&#12290;&#20026;&#20102;&#33021;&#22815;&#22312;&#21709;&#24212;&#20110;&#26102;&#21464;&#25511;&#21046;&#20449;&#21495;&#30340;&#24773;&#20917;&#19979;&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#23454;&#29616;&#23454;&#26102;&#36816;&#21160;&#21512;&#25104;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21487;&#25511;&#36816;&#21160;&#25193;&#25955;&#27169;&#22411;&#65288;COMODO&#65289;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#20197;&#33258;&#22238;&#24402;&#36816;&#21160;&#25193;&#25955;&#27169;&#22411;&#65288;A-MDM&#65289;&#20026;&#22522;&#30784;&#65292;&#36880;&#27493;&#29983;&#25104;&#36816;&#21160;&#24207;&#21015;&#12290;&#36890;&#36807;&#31616;&#21333;&#22320;&#20351;&#29992;&#26631;&#20934;DDPM&#31639;&#27861;&#32780;&#26080;&#38656;&#20219;&#20309;&#39069;&#22806;&#22797;&#26434;&#24615;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#33021;&#22815;&#20135;&#29983;&#22312;&#19981;&#21516;&#31867;&#22411;&#30340;&#36816;&#21160;&#25511;&#21046;&#19979;&#38271;&#26102;&#38388;&#20869;&#30340;&#39640;&#20445;&#30495;&#24230;&#36816;&#21160;&#24207;&#21015;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generating realistic and controllable motions for virtual characters is a challenging task in computer animation, and its implications extend to games, simulations, and virtual reality. Recent studies have drawn inspiration from the success of diffusion models in image generation, demonstrating the potential for addressing this task. However, the majority of these studies have been limited to offline applications that target at sequence-level generation that generates all steps simultaneously. To enable real-time motion synthesis with diffusion models in response to time-varying control signals, we propose the framework of the Controllable Motion Diffusion Model (COMODO). Our framework begins with an auto-regressive motion diffusion model (A-MDM), which generates motion sequences step by step. In this way, simply using the standard DDPM algorithm without any additional complexity, our framework is able to generate high-fidelity motion sequences over extended periods with different type
&lt;/p&gt;</description></item></channel></rss>