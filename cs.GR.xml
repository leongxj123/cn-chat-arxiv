<rss version="2.0"><channel><title>Chat Arxiv cs.GR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.GR</description><item><title>&#21033;&#29992;Nested Neural Feature Fields (N2F2) &#23454;&#29616;&#20102;&#23618;&#27425;&#21270;&#30417;&#30563;&#23398;&#20064;&#65292;&#25552;&#20379;&#20102;&#23545;&#29289;&#29702;&#32500;&#24230;&#25110;&#35821;&#20041;&#32500;&#24230;&#31561;&#19981;&#21516;&#31890;&#24230;&#30340;&#22330;&#26223;&#23646;&#24615;&#20840;&#38754;&#21644;&#32454;&#33268;&#30340;&#29702;&#35299;&#12290;</title><link>https://arxiv.org/abs/2403.10997</link><description>&lt;p&gt;
&#23884;&#22871;&#31070;&#32463;&#29305;&#24449;&#22330;&#30340;&#23618;&#27425;&#22330;&#26223;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
N2F2: Hierarchical Scene Understanding with Nested Neural Feature Fields
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10997
&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;Nested Neural Feature Fields (N2F2) &#23454;&#29616;&#20102;&#23618;&#27425;&#21270;&#30417;&#30563;&#23398;&#20064;&#65292;&#25552;&#20379;&#20102;&#23545;&#29289;&#29702;&#32500;&#24230;&#25110;&#35821;&#20041;&#32500;&#24230;&#31561;&#19981;&#21516;&#31890;&#24230;&#30340;&#22330;&#26223;&#23646;&#24615;&#20840;&#38754;&#21644;&#32454;&#33268;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#20013;&#65292;&#29702;&#35299;&#22810;&#23618;&#25277;&#35937;&#30340;&#22797;&#26434;&#22330;&#26223;&#20173;&#28982;&#26159;&#19968;&#20010;&#24040;&#22823;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#23884;&#22871;&#31070;&#32463;&#29305;&#24449;&#22330; (N2F2)&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#20998;&#23618;&#30417;&#30563;&#26469;&#23398;&#20064;&#21333;&#20010;&#29305;&#24449;&#22330;&#65292;&#22312;&#21516;&#19968;&#39640;&#32500;&#29305;&#24449;&#20013;&#30340;&#19981;&#21516;&#32500;&#24230;&#32534;&#30721;&#19981;&#21516;&#31890;&#24230;&#30340;&#22330;&#26223;&#23646;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20801;&#35768;&#28789;&#27963;&#23450;&#20041;&#23618;&#27425;&#65292;&#21487;&#20197;&#26681;&#25454;&#29289;&#29702;&#32500;&#24230;&#12289;&#35821;&#20041;&#32500;&#24230;&#25110;&#20004;&#32773;&#22343;&#21305;&#37197;&#65292;&#20174;&#32780;&#23454;&#29616;&#23545;&#22330;&#26223;&#30340;&#20840;&#38754;&#21644;&#32454;&#33268;&#29702;&#35299;&#12290;&#25105;&#20204;&#21033;&#29992;2D&#31867;&#21035;&#26080;&#20851;&#20998;&#21106;&#27169;&#22411;&#22312;&#22270;&#20687;&#31354;&#38388;&#30340;&#20219;&#24847;&#23610;&#24230;&#25552;&#20379;&#35821;&#20041;&#26377;&#24847;&#20041;&#30340;&#20687;&#32032;&#20998;&#32452;&#65292;&#24182;&#26597;&#35810;CLIP&#35270;&#35273;&#32534;&#30721;&#22120;&#65292;&#20026;&#36825;&#20123;&#27573;&#33853;&#20013;&#30340;&#27599;&#20010;&#37096;&#20998;&#33719;&#24471;&#19982;&#35821;&#35328;&#23545;&#40784;&#30340;&#23884;&#20837;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#20998;&#23618;&#30417;&#30563;&#26041;&#27861;&#23558;&#19981;&#21516;&#30340;&#23884;&#22871;&#29305;&#24449;&#22330;&#32500;&#24230;&#20998;&#37197;&#32473;&#25552;&#21462;C
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10997v1 Announce Type: cross  Abstract: Understanding complex scenes at multiple levels of abstraction remains a formidable challenge in computer vision. To address this, we introduce Nested Neural Feature Fields (N2F2), a novel approach that employs hierarchical supervision to learn a single feature field, wherein different dimensions within the same high-dimensional feature encode scene properties at varying granularities. Our method allows for a flexible definition of hierarchies, tailored to either the physical dimensions or semantics or both, thereby enabling a comprehensive and nuanced understanding of scenes. We leverage a 2D class-agnostic segmentation model to provide semantically meaningful pixel groupings at arbitrary scales in the image space, and query the CLIP vision-encoder to obtain language-aligned embeddings for each of these segments. Our proposed hierarchical supervision method then assigns different nested dimensions of the feature field to distill the C
&lt;/p&gt;</description></item></channel></rss>