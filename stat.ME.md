# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Statistical exploration of the Manifold Hypothesis](https://arxiv.org/abs/2208.11665) | 这篇论文通过潜在度量模型从数据中得出了丰富而复杂的流形结构，并提供了解释流形假设的统计解释。该研究为发现和解释高维数据的几何结构以及探索数据生成机制提供了方法。 |

# 详细

[^1]: 统计对流形假设的探索

    Statistical exploration of the Manifold Hypothesis

    [https://arxiv.org/abs/2208.11665](https://arxiv.org/abs/2208.11665)

    这篇论文通过潜在度量模型从数据中得出了丰富而复杂的流形结构，并提供了解释流形假设的统计解释。该研究为发现和解释高维数据的几何结构以及探索数据生成机制提供了方法。

    

    流形假设是机器学习中广为接受的理论，它认为名义上的高维数据实际上集中在高维空间中的低维流形中。这种现象在许多真实世界的情况中经验性地观察到，在过去几十年中已经导致了多种统计方法的发展，并被认为是现代人工智能技术成功的关键因素。我们表明，通过潜在度量模型这种通用且非常简单的统计模型，可以从数据中生成丰富而有时复杂的流形结构，通过潜变量、相关性和平稳性等基本概念。这为为什么流形假设在这么多情况下似乎成立提供了一个一般的统计解释。在潜在度量模型的基础上，我们提出了发现和解释高维数据几何结构以及探索数据生成机制的程序。

    The Manifold Hypothesis is a widely accepted tenet of Machine Learning which asserts that nominally high-dimensional data are in fact concentrated near a low-dimensional manifold, embedded in high-dimensional space. This phenomenon is observed empirically in many real world situations, has led to development of a wide range of statistical methods in the last few decades, and has been suggested as a key factor in the success of modern AI technologies. We show that rich and sometimes intricate manifold structure in data can emerge from a generic and remarkably simple statistical model -- the Latent Metric Model -- via elementary concepts such as latent variables, correlation and stationarity. This establishes a general statistical explanation for why the Manifold Hypothesis seems to hold in so many situations. Informed by the Latent Metric Model we derive procedures to discover and interpret the geometry of high-dimensional data, and explore hypotheses about the data generating mechanism
    

