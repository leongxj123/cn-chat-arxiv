<rss version="2.0"><channel><title>Chat Arxiv cs.SE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SE</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797; NoFunEval&#65292;&#29992;&#20110;&#35780;&#20272;&#20195;&#30721;&#35821;&#35328;&#27169;&#22411;&#22312;&#38750;&#21151;&#33021;&#24615;&#35201;&#27714;&#21644;&#31616;&#21333;&#20998;&#31867;&#23454;&#20363;&#26041;&#38754;&#30340;&#34920;&#29616;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#30446;&#21069;&#30340;&#20195;&#30721;&#35821;&#35328;&#27169;&#22411;&#22312;&#22788;&#29702;&#36825;&#20123;&#35201;&#27714;&#26102;&#23384;&#22312;&#26681;&#26412;&#24615;&#30340;&#30450;&#28857;&#12290;</title><link>https://rss.arxiv.org/abs/2401.15963</link><description>&lt;p&gt;
NoFunEval: &#26377;&#36259;&#30340;&#26159;&#65292;&#20195;&#30721;&#35821;&#35328;&#27169;&#22411;&#22312;&#36229;&#20986;&#21151;&#33021;&#27491;&#30830;&#24615;&#30340;&#35201;&#27714;&#19978;&#36935;&#21040;&#22256;&#38590;
&lt;/p&gt;
&lt;p&gt;
NoFunEval: Funny How Code LMs Falter on Requirements Beyond Functional Correctness
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2401.15963
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797; NoFunEval&#65292;&#29992;&#20110;&#35780;&#20272;&#20195;&#30721;&#35821;&#35328;&#27169;&#22411;&#22312;&#38750;&#21151;&#33021;&#24615;&#35201;&#27714;&#21644;&#31616;&#21333;&#20998;&#31867;&#23454;&#20363;&#26041;&#38754;&#30340;&#34920;&#29616;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#30446;&#21069;&#30340;&#20195;&#30721;&#35821;&#35328;&#27169;&#22411;&#22312;&#22788;&#29702;&#36825;&#20123;&#35201;&#27714;&#26102;&#23384;&#22312;&#26681;&#26412;&#24615;&#30340;&#30450;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#20195;&#30721;&#35821;&#35328;&#27169;&#22411;&#65288;code LMs&#65289;&#30340;&#35780;&#20272;&#22522;&#20934;&#20960;&#20046;&#23436;&#20840;&#38598;&#20013;&#22312;LMs&#26159;&#21542;&#33021;&#22815;&#29983;&#25104;&#21151;&#33021;&#27491;&#30830;&#30340;&#20195;&#30721;&#19978;&#12290;&#22312;&#23454;&#38469;&#30340;&#36719;&#20214;&#24037;&#31243;&#20013;&#65292;&#24320;&#21457;&#20154;&#21592;&#20250;&#32771;&#34385;&#36229;&#20986;&#21151;&#33021;&#27491;&#30830;&#24615;&#30340;&#35201;&#27714;&#12290;&#20182;&#20204;&#23545;&#20110;&#8220;&#22914;&#20309;&#8221;&#23454;&#29616;&#21151;&#33021;&#26377;&#30528;&#23545;&#25972;&#20307;&#31995;&#32479;&#35774;&#35745;&#30446;&#26631;&#65288;&#22914;&#25928;&#29575;&#12289;&#23433;&#20840;&#24615;&#21644;&#21487;&#32500;&#25252;&#24615;&#65289;&#30340;&#35201;&#27714;&#12290;&#22914;&#26524;LMs&#33021;&#22815;&#23637;&#31034;&#23545;&#35201;&#27714;&#21644;&#20195;&#30721;&#35821;&#20041;&#30340;&#24378;&#22823;&#29702;&#35299;&#33021;&#21147;&#65292;&#20182;&#20204;&#20063;&#20250;&#26356;&#21152;&#20449;&#20219;&#36825;&#20123;LMs&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797;NoFunEval&#26469;&#35780;&#20272;&#20195;&#30721;LMs&#22312;&#38750;&#21151;&#33021;&#24615;&#35201;&#27714;&#21644;&#31616;&#21333;&#20998;&#31867;&#23454;&#20363;&#26041;&#38754;&#30340;&#34920;&#29616;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#25552;&#31034;&#26041;&#27861;Coding Concepts (CoCo)&#65292;&#21487;&#20197;&#29992;&#20110;&#24320;&#21457;&#20154;&#21592;&#21521;LMs&#20256;&#36798;&#39046;&#22495;&#30693;&#35782;&#12290;&#25105;&#20204;&#23545;22&#20010;&#20195;&#30721;LMs&#36827;&#34892;&#20102;&#24191;&#27867;&#35780;&#20272;&#65292;&#21457;&#29616;&#23427;&#20204;&#22312;&#25105;&#20204;&#30340;&#22522;&#20934;&#27979;&#35797;&#20013;&#26222;&#36941;&#34920;&#29616;&#19981;&#20339;&#65292;&#26263;&#31034;&#30528;&#23427;&#20204;&#22312;&#22788;&#29702;&#36825;&#20123;&#38382;&#39064;&#26102;&#23384;&#22312;&#26681;&#26412;&#24615;&#30340;&#30450;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing evaluation benchmarks of language models of code (code LMs) focus almost exclusively on whether the LMs can generate functionally-correct code. In real-world software engineering, developers think beyond functional correctness. They have requirements on "how" a functionality should be implemented to meet overall system design objectives like efficiency, security, and maintainability. They would also trust the code LMs more if the LMs demonstrate robust understanding of requirements and code semantics.   We propose a new benchmark NoFunEval to evaluate code LMs on non-functional requirements and simple classification instances for both functional and non-functional requirements. We propose a prompting method, Coding Concepts (CoCo), as a way for a developer to communicate the domain knowledge to the LMs. We conduct an extensive evaluation of twenty-two code LMs. Our finding is that they generally falter when tested on our benchmark, hinting at fundamental blindspots in their tr
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20851;&#27880;&#22914;&#20309;&#22312;&#35757;&#32451;&#20195;&#30721;&#30340;&#35821;&#35328;&#27169;&#22411;&#20013;&#26816;&#27979;&#20195;&#30721;&#21253;&#21547;&#65292;&#20197;&#35299;&#20915;&#20351;&#29992;&#36825;&#20123;&#27169;&#22411;&#36827;&#34892;&#20195;&#30721;&#23457;&#35745;&#26102;&#30340;&#29256;&#26435;&#20405;&#26435;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.09299</link><description>&lt;p&gt;
&#26410;&#32463;&#26412;&#20154;&#21516;&#24847;&#30340;&#35757;&#32451;&#65306;&#22312;&#35757;&#32451;&#20195;&#30721;&#30340;&#35821;&#35328;&#27169;&#22411;&#20013;&#26816;&#27979;&#20195;&#30721;&#21253;&#21547;
&lt;/p&gt;
&lt;p&gt;
Trained Without My Consent: Detecting Code Inclusion In Language Models Trained on Code
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09299
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20851;&#27880;&#22914;&#20309;&#22312;&#35757;&#32451;&#20195;&#30721;&#30340;&#35821;&#35328;&#27169;&#22411;&#20013;&#26816;&#27979;&#20195;&#30721;&#21253;&#21547;&#65292;&#20197;&#35299;&#20915;&#20351;&#29992;&#36825;&#20123;&#27169;&#22411;&#36827;&#34892;&#20195;&#30721;&#23457;&#35745;&#26102;&#30340;&#29256;&#26435;&#20405;&#26435;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20195;&#30721;&#23457;&#35745;&#36890;&#36807;&#39564;&#35777;&#24320;&#21457;&#30340;&#20195;&#30721;&#26159;&#21542;&#31526;&#21512;&#26631;&#20934;&#12289;&#27861;&#35268;&#21644;&#29256;&#26435;&#20445;&#25252;&#65292;&#30830;&#20445;&#20854;&#19981;&#21253;&#21547;&#26469;&#33258;&#21463;&#20445;&#25252;&#26469;&#28304;&#30340;&#20195;&#30721;&#12290;&#22312;&#36719;&#20214;&#24320;&#21457;&#36807;&#31243;&#20013;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#20316;&#20026;&#32534;&#30721;&#21161;&#25163;&#30340;&#20986;&#29616;&#32473;&#20195;&#30721;&#23457;&#35745;&#24102;&#26469;&#20102;&#26032;&#30340;&#25361;&#25112;&#12290;&#35757;&#32451;&#36825;&#20123;&#27169;&#22411;&#30340;&#25968;&#25454;&#38598;&#20027;&#35201;&#26469;&#33258;&#20844;&#24320;&#21487;&#29992;&#30340;&#26469;&#28304;&#12290;&#36825;&#24341;&#21457;&#20102;&#30693;&#35782;&#20135;&#26435;&#20405;&#26435;&#38382;&#39064;&#65292;&#22240;&#20026;&#24320;&#21457;&#32773;&#30340;&#20195;&#30721;&#24050;&#21253;&#21547;&#22312;&#25968;&#25454;&#38598;&#20013;&#12290;&#22240;&#27492;&#65292;&#20351;&#29992;LLMs&#24320;&#21457;&#30340;&#20195;&#30721;&#23457;&#35745;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;&#25105;&#20204;&#26080;&#27861;&#20934;&#30830;&#30830;&#23450;&#24320;&#21457;&#36807;&#31243;&#20013;&#20351;&#29992;&#30340;LLM&#26159;&#21542;&#24050;&#32463;&#22312;&#29305;&#23450;&#30340;&#21463;&#29256;&#26435;&#20445;&#25252;&#30340;&#20195;&#30721;&#19978;&#36827;&#34892;&#20102;&#35757;&#32451;&#65292;&#22240;&#20026;&#25105;&#20204;&#26080;&#27861;&#33719;&#24471;&#36825;&#20123;&#27169;&#22411;&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#12290;&#37492;&#20110;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#20445;&#23494;&#24615;&#65292;&#20256;&#32479;&#30340;&#20195;&#30721;&#20811;&#38534;&#26816;&#27979;&#31561;&#26041;&#27861;&#26080;&#27861;&#30830;&#20445;&#29256;&#26435;&#20405;&#26435;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09299v1 Announce Type: cross Abstract: Code auditing ensures that the developed code adheres to standards, regulations, and copyright protection by verifying that it does not contain code from protected sources. The recent advent of Large Language Models (LLMs) as coding assistants in the software development process poses new challenges for code auditing. The dataset for training these models is mainly collected from publicly available sources. This raises the issue of intellectual property infringement as developers' codes are already included in the dataset. Therefore, auditing code developed using LLMs is challenging, as it is difficult to reliably assert if an LLM used during development has been trained on specific copyrighted codes, given that we do not have access to the training datasets of these models. Given the non-disclosure of the training datasets, traditional approaches such as code clone detection are insufficient for asserting copyright infringement. To add
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20197;&#26500;&#24314;&#19968;&#20010;&#26032;&#30340;&#26368;&#22823;&#20551;&#35774;&#25968;&#25454;&#38598;&#20026;&#22522;&#30784;&#65292;&#38024;&#23545;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#24320;&#21457;&#20013;&#25163;&#21160;&#35782;&#21035;&#20551;&#35774;&#30340;&#38382;&#39064;&#36827;&#34892;&#20102;&#25506;&#32034;&#24615;&#30740;&#31350;&#12290;&#22312;&#35813;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#25163;&#21160;&#35782;&#21035;&#20551;&#35774;&#30340;&#25104;&#26412;&#39640;&#65292;&#22240;&#27492;&#25506;&#35752;&#20102;&#20351;&#29992;&#20256;&#32479;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21644;&#27969;&#34892;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#26469;&#35782;&#21035;&#20551;&#35774;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.03653</link><description>&lt;p&gt;
&#20851;&#20110;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#24320;&#21457;&#20013;&#33258;&#21160;&#35782;&#21035;&#20551;&#35774;&#30340;&#25506;&#32034;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
An exploratory study on automatic identification of assumptions in the development of deep learning frameworks. (arXiv:2401.03653v2 [cs.SE] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03653
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20197;&#26500;&#24314;&#19968;&#20010;&#26032;&#30340;&#26368;&#22823;&#20551;&#35774;&#25968;&#25454;&#38598;&#20026;&#22522;&#30784;&#65292;&#38024;&#23545;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#24320;&#21457;&#20013;&#25163;&#21160;&#35782;&#21035;&#20551;&#35774;&#30340;&#38382;&#39064;&#36827;&#34892;&#20102;&#25506;&#32034;&#24615;&#30740;&#31350;&#12290;&#22312;&#35813;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#25163;&#21160;&#35782;&#21035;&#20551;&#35774;&#30340;&#25104;&#26412;&#39640;&#65292;&#22240;&#27492;&#25506;&#35752;&#20102;&#20351;&#29992;&#20256;&#32479;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21644;&#27969;&#34892;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#26469;&#35782;&#21035;&#20551;&#35774;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21033;&#30410;&#30456;&#20851;&#26041;&#22312;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#24320;&#21457;&#20013;&#32463;&#24120;&#20570;&#20986;&#20551;&#35774;&#12290;&#36825;&#20123;&#20551;&#35774;&#28041;&#21450;&#21508;&#31181;&#36719;&#20214;&#26500;&#20214;&#65288;&#20363;&#22914;&#38656;&#27714;&#12289;&#35774;&#35745;&#20915;&#31574;&#21644;&#25216;&#26415;&#20538;&#21153;&#65289;&#65292;&#21487;&#33021;&#20250;&#34987;&#35777;&#26126;&#26080;&#25928;&#65292;&#20174;&#32780;&#23548;&#33268;&#31995;&#32479;&#25925;&#38556;&#12290;&#29616;&#26377;&#30340;&#20551;&#35774;&#31649;&#29702;&#26041;&#27861;&#21644;&#24037;&#20855;&#36890;&#24120;&#20381;&#36182;&#20110;&#25163;&#21160;&#35782;&#21035;&#20551;&#35774;&#12290;&#28982;&#32780;&#65292;&#20551;&#35774;&#20998;&#25955;&#22312;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#24320;&#21457;&#30340;&#21508;&#31181;&#28304;&#22836;&#65288;&#20363;&#22914;&#20195;&#30721;&#27880;&#37322;&#12289;&#25552;&#20132;&#12289;&#25289;&#21462;&#35831;&#27714;&#21644;&#38382;&#39064;&#65289;&#20013;&#65292;&#25163;&#21160;&#35782;&#21035;&#20551;&#35774;&#25104;&#26412;&#36739;&#39640;&#65288;&#20363;&#22914;&#26102;&#38388;&#21644;&#36164;&#28304;&#28040;&#32791;&#65289;&#12290;&#20026;&#20102;&#35299;&#20915;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#24320;&#21457;&#20013;&#25163;&#21160;&#35782;&#21035;&#20551;&#35774;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#26032;&#30340;&#24182;&#19988;&#26368;&#22823;&#30340;&#20551;&#35774;&#25968;&#25454;&#38598;&#65288;&#31216;&#20026;AssuEval&#65289;&#65292;&#35813;&#25968;&#25454;&#38598;&#25910;&#38598;&#33258;GitHub&#19978;&#30340;TensorFlow&#21644;Keras&#20195;&#30721;&#24211;&#65307;&#25105;&#20204;&#25506;&#35752;&#20102;&#19971;&#20010;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65288;&#20363;&#22914;&#25903;&#25345;&#21521;&#37327;&#26426;&#12289;&#20998;&#31867;&#22238;&#24402;&#26641;&#65289;&#21644;&#19968;&#20010;&#27969;&#34892;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stakeholders constantly make assumptions in the development of deep learning (DL) frameworks. These assumptions are related to various types of software artifacts (e.g., requirements, design decisions, and technical debt) and can turn out to be invalid, leading to system failures. Existing approaches and tools for assumption management usually depend on manual identification of assumptions. However, assumptions are scattered in various sources (e.g., code comments, commits, pull requests, and issues) of DL framework development, and manually identifying assumptions has high costs (e.g., time and resources). To overcome the issues of manually identifying assumptions in DL framework development, we constructed a new and largest dataset (i.e., AssuEval) of assumptions collected from the TensorFlow and Keras repositories on GitHub; explored the performance of seven traditional machine learning models (e.g., Support Vector Machine, Classification and Regression Trees), a popular DL model (i
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;Bug&#23450;&#20301;&#26041;&#27861;RLocator&#65292;&#30456;&#36739;&#20110;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;Bug&#23450;&#20301;&#25216;&#26415;&#20855;&#26377;&#26356;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.05586</link><description>&lt;p&gt;
RLocator: &#21033;&#29992;&#24378;&#21270;&#23398;&#20064;&#36827;&#34892;Bug&#23450;&#20301;
&lt;/p&gt;
&lt;p&gt;
RLocator: Reinforcement Learning for Bug Localization. (arXiv:2305.05586v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05586
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;Bug&#23450;&#20301;&#26041;&#27861;RLocator&#65292;&#30456;&#36739;&#20110;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;Bug&#23450;&#20301;&#25216;&#26415;&#20855;&#26377;&#26356;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36719;&#20214;&#24320;&#21457;&#32773;&#22312;&#20182;&#20204;&#30340;&#39033;&#30446;&#20013;&#33457;&#36153;&#20102;&#22823;&#37327;&#30340;&#26102;&#38388;&#26469;&#20462;&#22797;Bugs&#12290;&#20026;&#20102;&#31616;&#21270;&#36825;&#20010;&#36807;&#31243;&#65292;&#25552;&#20986;&#20102;Bug&#23450;&#20301;&#26041;&#27861;&#26469;&#30830;&#23450;&#21738;&#20123;&#28304;&#20195;&#30721;&#25991;&#20214;&#21487;&#33021;&#26159;&#36127;&#36131;&#29305;&#23450;Bug&#30340;&#28304;&#22836;&#12290;&#20043;&#21069;&#30340;&#24037;&#20316;&#25552;&#20986;&#20102;&#20960;&#31181;&#22522;&#20110;&#30456;&#20284;&#24615;&#30340;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#65292;&#29992;&#20110;Bug&#23450;&#20301;&#12290;&#23613;&#31649;&#36825;&#20123;&#25216;&#26415;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#20294;&#23427;&#20204;&#24182;&#27809;&#26377;&#30452;&#25509;&#20248;&#21270;&#35780;&#20272;&#25351;&#26631;&#12290;&#30456;&#21453;&#65292;&#22312;&#35757;&#32451;&#21644;&#27979;&#35797;&#38454;&#27573;&#20351;&#29992;&#20102;&#19981;&#21516;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#36825;&#20250;&#23545;&#26816;&#32034;&#20219;&#21153;&#30340;&#27169;&#22411;&#24615;&#33021;&#20135;&#29983;&#36127;&#38754;&#24433;&#21709;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;Bug&#23450;&#20301;&#26041;&#27861;RLocator&#12290;&#25105;&#20204;&#20351;&#29992;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDP&#65289;&#26469;&#20248;&#21270;&#35780;&#20272;&#25351;&#26631;&#65292;&#20174;&#32780;&#23545;Bug&#23450;&#20301;&#38382;&#39064;&#36827;&#34892;&#20844;&#24335;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#35813;&#25216;&#26415;&#65292;&#24182;&#22522;&#20110;&#20845;&#31181;&#39640;&#24230;&#27969;&#34892;&#30340;Apache&#39033;&#30446;&#30340;8,316&#20010;Bug&#25253;&#21578;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#23454;&#39564;&#35780;&#20272;&#12290;&#25105;&#20204;&#30340;&#35780;&#20272;&#34920;&#26126;&#65292;RLocator&#30456;&#36739;&#20110;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;Bug&#23450;&#20301;&#25216;&#26415;&#20855;&#26377;&#26356;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Software developers spend a significant portion of time fixing bugs in their projects. To streamline this process, bug localization approaches have been proposed to identify the source code files that are likely responsible for a particular bug. Prior work proposed several similarity-based machine-learning techniques for bug localization. Despite significant advances in these techniques, they do not directly optimize the evaluation measures. Instead, they use different metrics in the training and testing phases, which can negatively impact the model performance in retrieval tasks. In this paper, we propose RLocator, a Reinforcement Learning-based (RL) bug localization approach. We formulate the bug localization problem using a Markov Decision Process (MDP) to optimize the evaluation measures directly. We present the technique and experimentally evaluate it based on a benchmark dataset of 8,316 bug reports from six highly popular Apache projects. Our evaluation shows that RLocator achie
&lt;/p&gt;</description></item></channel></rss>