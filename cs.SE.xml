<rss version="2.0"><channel><title>Chat Arxiv cs.SE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SE</description><item><title>&#31070;&#32463;&#20195;&#30721;&#26234;&#33021;&#39046;&#22495;&#30340;&#35843;&#26597;&#31995;&#32479;&#22238;&#39038;&#20102;50&#22810;&#31181;&#20195;&#34920;&#24615;&#27169;&#22411;&#21644;&#36229;&#36807;680&#39033;&#30456;&#20851;&#20316;&#21697;&#65292;&#31361;&#20986;&#20102;&#19981;&#21516;&#30740;&#31350;&#38454;&#27573;&#30340;&#33539;&#24335;&#21644;&#25216;&#26415;&#36716;&#21464;&#12290;</title><link>https://arxiv.org/abs/2403.14734</link><description>&lt;p&gt;
&#19968;&#39033;&#31070;&#32463;&#20195;&#30721;&#26234;&#33021;&#30340;&#35843;&#26597;&#65306;&#33539;&#24335;&#12289;&#36827;&#23637;&#19982;&#26410;&#26469;
&lt;/p&gt;
&lt;p&gt;
A Survey of Neural Code Intelligence: Paradigms, Advances and Beyond
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14734
&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#20195;&#30721;&#26234;&#33021;&#39046;&#22495;&#30340;&#35843;&#26597;&#31995;&#32479;&#22238;&#39038;&#20102;50&#22810;&#31181;&#20195;&#34920;&#24615;&#27169;&#22411;&#21644;&#36229;&#36807;680&#39033;&#30456;&#20851;&#20316;&#21697;&#65292;&#31361;&#20986;&#20102;&#19981;&#21516;&#30740;&#31350;&#38454;&#27573;&#30340;&#33539;&#24335;&#21644;&#25216;&#26415;&#36716;&#21464;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14734v1 &#20844;&#21578;&#31867;&#22411;: &#36328;&#39046;&#22495; &#25688;&#35201;: &#31070;&#32463;&#20195;&#30721;&#26234;&#33021;--&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#29702;&#35299;&#12289;&#29983;&#25104;&#21644;&#20248;&#21270;&#20195;&#30721;--&#22312;&#25972;&#20010;&#31038;&#20250;&#19978;&#20855;&#26377;&#24040;&#22823;&#30340;&#28508;&#21147;&#65292;&#21487;&#20135;&#29983;&#28145;&#36828;&#24433;&#21709;&#12290;&#20316;&#20026;&#33258;&#28982;&#35821;&#35328;&#21644;&#32534;&#31243;&#35821;&#35328;&#20043;&#38388;&#30340;&#26725;&#26753;&#65292;&#36825;&#19968;&#39046;&#22495;&#22312;&#36807;&#21435;&#20960;&#24180;&#24341;&#36215;&#20102;&#20004;&#20010;&#30740;&#31350;&#31038;&#21306;&#30740;&#31350;&#20154;&#21592;&#30340;&#26497;&#22823;&#20851;&#27880;&#12290;&#26412;&#35843;&#26597;&#31995;&#32479;&#22320;&#21644;&#25353;&#26102;&#38388;&#39034;&#24207;&#22238;&#39038;&#20102;&#20195;&#30721;&#26234;&#33021;&#26041;&#38754;&#30340;&#36827;&#23637;&#65292;&#21253;&#25324;50&#22810;&#31181;&#20195;&#34920;&#24615;&#27169;&#22411;&#21450;&#20854;&#21464;&#20307;&#12289;20&#22810;&#31181;&#20219;&#21153;&#31867;&#21035;&#20197;&#21450;&#36229;&#36807;680&#39033;&#30456;&#20851;&#20316;&#21697;&#12290;&#25105;&#20204;&#36981;&#24490;&#21382;&#21490;&#36827;&#23637;&#65292;&#36319;&#36394;&#19981;&#21516;&#30740;&#31350;&#38454;&#27573;&#30340;&#33539;&#24335;&#36716;&#21464;&#65288;&#20363;&#22914;&#65292;&#20174;&#20351;&#29992;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#23545;&#20195;&#30721;&#24314;&#27169;&#21040;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26102;&#20195;&#65289;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#37325;&#28857;&#20171;&#32461;&#20102;&#19981;&#21516;&#38454;&#27573;&#28085;&#30422;&#30340;&#27169;&#22411;&#12289;&#20219;&#21153;&#21644;&#35780;&#20272;&#30340;&#20027;&#35201;&#25216;&#26415;&#36716;&#21464;&#12290;&#23545;&#20110;&#24212;&#29992;&#65292;&#25105;&#20204;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14734v1 Announce Type: cross  Abstract: Neural Code Intelligence -- leveraging deep learning to understand, generate, and optimize code -- holds immense potential for transformative impacts on the whole society. Bridging the gap between Natural Language and Programming Language, this domain has drawn significant attention from researchers in both research communities over the past few years. This survey presents a systematic and chronological review of the advancements in code intelligence, encompassing over 50 representative models and their variants, more than 20 categories of tasks, and an extensive coverage of over 680 related works. We follow the historical progression to trace the paradigm shifts across different research phases (e.g., from modeling code with recurrent neural networks to the era of Large Language Models). Concurrently, we highlight the major technical transitions in models, tasks, and evaluations spanning through different stages. For applications, we 
&lt;/p&gt;</description></item><item><title>&#24615;&#33021;&#26159;&#21487;&#37197;&#32622;&#36719;&#20214;&#31995;&#32479;&#34892;&#20026;&#30340;&#20851;&#38190;&#23646;&#24615;&#65292;&#26412;&#25991;&#38024;&#23545;&#28145;&#24230;&#23398;&#20064;&#22312;&#21487;&#37197;&#32622;&#36719;&#20214;&#24615;&#33021;&#23398;&#20064;&#26041;&#38754;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#35843;&#26597;&#19982;&#20998;&#31867;&#30740;&#31350;&#12290;</title><link>https://arxiv.org/abs/2403.03322</link><description>&lt;p&gt;
&#28145;&#24230;&#37197;&#32622;&#24615;&#33021;&#23398;&#20064;&#65306;&#19968;&#39033;&#31995;&#32479;&#24615;&#35843;&#26597;&#19982;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Deep Configuration Performance Learning: A Systematic Survey and Taxonomy
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03322
&lt;/p&gt;
&lt;p&gt;
&#24615;&#33021;&#26159;&#21487;&#37197;&#32622;&#36719;&#20214;&#31995;&#32479;&#34892;&#20026;&#30340;&#20851;&#38190;&#23646;&#24615;&#65292;&#26412;&#25991;&#38024;&#23545;&#28145;&#24230;&#23398;&#20064;&#22312;&#21487;&#37197;&#32622;&#36719;&#20214;&#24615;&#33021;&#23398;&#20064;&#26041;&#38754;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#35843;&#26597;&#19982;&#20998;&#31867;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24615;&#33021;&#21487;&#20197;&#35828;&#26159;&#21453;&#26144;&#21487;&#37197;&#32622;&#36719;&#20214;&#31995;&#32479;&#34892;&#20026;&#30340;&#26368;&#20851;&#38190;&#23646;&#24615;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#29616;&#20195;&#36719;&#20214;&#35268;&#27169;&#21644;&#22797;&#26434;&#24615;&#19981;&#26029;&#22686;&#21152;&#65292;&#23545;&#21508;&#31181;&#37197;&#32622;&#22914;&#20309;&#24433;&#21709;&#24615;&#33021;&#36827;&#34892;&#24314;&#27169;&#21644;&#39044;&#27979;&#25104;&#20026;&#36719;&#20214;&#32500;&#25252;&#20013;&#30340;&#20027;&#35201;&#25361;&#25112;&#20043;&#19968;&#12290;&#22240;&#27492;&#65292;&#24615;&#33021;&#36890;&#24120;&#26159;&#22312;&#27809;&#26377;&#23545;&#36719;&#20214;&#31995;&#32479;&#26377;&#36879;&#24443;&#20102;&#35299;&#30340;&#24773;&#20917;&#19979;&#24314;&#27169;&#30340;&#65292;&#20027;&#35201;&#20381;&#36182;&#25968;&#25454;&#65292;&#36825;&#27491;&#22909;&#31526;&#21512;&#28145;&#24230;&#23398;&#20064;&#30340;&#30446;&#30340;&#12290;&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#28145;&#24230;&#23398;&#20064;&#22312;&#21487;&#37197;&#32622;&#36719;&#20214;&#24615;&#33021;&#23398;&#20064;&#26041;&#38754;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#22238;&#39038;&#65292;&#28085;&#30422;&#20102;948&#31687;&#26469;&#33258;&#20845;&#20010;&#32034;&#24341;&#26381;&#21153;&#30340;&#35770;&#25991;&#65292;&#22522;&#20110;&#27492;&#25552;&#21462;&#24182;&#20998;&#26512;&#20102;85&#31687;&#20027;&#35201;&#35770;&#25991;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#24635;&#32467;&#20102;&#37197;&#32622;&#25968;&#25454;&#22914;&#20309;&#20934;&#22791;&#65292;&#28145;&#24230;&#37197;&#32622;&#24615;&#33021;&#23398;&#20064;&#27169;&#22411;&#22914;&#20309;&#26500;&#24314;&#65292;&#20197;&#21450;&#35813;&#27169;&#22411;&#22914;&#20309;&#36827;&#34892;&#35780;&#20272;&#31561;&#20851;&#38190;&#20027;&#39064;&#21644;&#32479;&#35745;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03322v1 Announce Type: cross  Abstract: Performance is arguably the most crucial attribute that reflects the behavior of a configurable software system. However, given the increasing scale and complexity of modern software, modeling and predicting how various configurations can impact performance becomes one of the major challenges in software maintenance. As such, performance is often modeled without having a thorough knowledge of the software system, but relying mainly on data, which fits precisely with the purpose of deep learning.   In this paper, we conduct a comprehensive review exclusively on the topic of deep learning for performance learning of configurable software, covering 948 searched papers spanning six indexing services, based on which 85 primary papers were extracted and analyzed. Our results summarize the key topics and statistics on how the configuration data is prepared; how the deep configuration performance learning model is built; how the model is evalu
&lt;/p&gt;</description></item></channel></rss>