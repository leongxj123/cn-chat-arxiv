<rss version="2.0"><channel><title>Chat Arxiv cs.SE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SE</description><item><title>&#20171;&#32461;&#20102; CodeUltraFeedback &#25968;&#25454;&#38598;&#65292;&#36890;&#36807; AI &#21453;&#39304;&#20351; 14 &#31181;&#19981;&#21516;&#30340; LLMs &#23545; 10,000 &#20010;&#22797;&#26434;&#25351;&#20196;&#29983;&#25104;&#21709;&#24212;&#65292;&#24182;&#20351;&#29992; LLM-as-a-Judge &#26041;&#27861;&#35780;&#20272;&#23427;&#20204;&#19982;&#20116;&#31181;&#32534;&#31243;&#20559;&#22909;&#30340;&#23545;&#40784;&#24773;&#20917;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#29992;&#20110;&#35780;&#20272; LLM &#23545;&#32534;&#31243;&#20559;&#22909;&#23545;&#40784;&#30340;&#22522;&#20934; CODAL-Bench&#12290;</title><link>https://arxiv.org/abs/2403.09032</link><description>&lt;p&gt;
CodeUltraFeedback&#65306;&#19968;&#31181;&#29992;&#20110;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#32534;&#31243;&#20559;&#22909;&#23545;&#40784;&#30340;LLM&#20316;&#20026;&#27861;&#23448;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
CodeUltraFeedback: An LLM-as-a-Judge Dataset for Aligning Large Language Models to Coding Preferences
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09032
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102; CodeUltraFeedback &#25968;&#25454;&#38598;&#65292;&#36890;&#36807; AI &#21453;&#39304;&#20351; 14 &#31181;&#19981;&#21516;&#30340; LLMs &#23545; 10,000 &#20010;&#22797;&#26434;&#25351;&#20196;&#29983;&#25104;&#21709;&#24212;&#65292;&#24182;&#20351;&#29992; LLM-as-a-Judge &#26041;&#27861;&#35780;&#20272;&#23427;&#20204;&#19982;&#20116;&#31181;&#32534;&#31243;&#20559;&#22909;&#30340;&#23545;&#40784;&#24773;&#20917;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#29992;&#20110;&#35780;&#20272; LLM &#23545;&#32534;&#31243;&#20559;&#22909;&#23545;&#40784;&#30340;&#22522;&#20934; CODAL-Bench&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#19982;&#29992;&#25143;&#23450;&#20041;&#30340;&#32534;&#31243;&#20559;&#22909;&#30340;&#23545;&#40784;&#24615;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24037;&#20316;&#65292;&#38656;&#35201;&#35780;&#20272;&#22797;&#26434;&#25991;&#26412;LLMs&#30340;&#36755;&#20986;&#12290;&#29616;&#26377;&#22522;&#20934;&#20208;&#36182;&#33258;&#21160;&#21270;&#25351;&#26631;&#21644;&#38745;&#24577;&#20998;&#26512;&#24037;&#20855;&#65292;&#26410;&#33021;&#35780;&#20272;&#29992;&#25143;&#25351;&#20196;&#21644;LLM&#36755;&#20986;&#20013;&#30340;&#24494;&#22937;&#20043;&#22788;&#65292;&#31361;&#26174;&#20102;&#23545;LLM&#20559;&#22909;&#23545;&#40784;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#21644;&#22522;&#20934;&#30340;&#38656;&#27714;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;CodeUltraFeedback&#65292;&#19968;&#20010;&#21253;&#21547;10,000&#20010;&#22797;&#26434;&#25351;&#20196;&#30340;&#20559;&#22909;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;AI&#21453;&#39304;&#26469;&#35843;&#25972;&#21644;&#23545;&#40784;LLMs&#19982;&#32534;&#31243;&#20559;&#22909;&#12290;&#25105;&#20204;&#20351;&#29992;14&#31181;&#19981;&#21516;&#30340;LLMs&#23545;&#36825;&#20123;&#25351;&#20196;&#29983;&#25104;&#21709;&#24212;&#65292;&#28982;&#21518;&#26681;&#25454;&#23427;&#20204;&#19982;&#20116;&#31181;&#32534;&#31243;&#20559;&#22909;&#30340;&#23545;&#40784;&#24773;&#20917;&#36827;&#34892;&#27880;&#37322;&#65292;&#20351;&#29992;GPT-3.5&#30340;LLM&#20316;&#20026;&#27861;&#23448;&#26041;&#27861;&#20135;&#29983;&#25968;&#23383;&#21644;&#25991;&#26412;&#21453;&#39304;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;CODAL-Bench&#65292;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;LLM&#19982;&#36825;&#20123;&#32534;&#31243;&#20559;&#22909;&#23545;&#40784;&#30340;&#22522;&#20934;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26174;&#31034;C
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09032v1 Announce Type: cross  Abstract: Evaluating the alignment of large language models (LLMs) with user-defined coding preferences is a challenging endeavour that requires assessing intricate textual LLMs' outputs. By relying on automated metrics and static analysis tools, existing benchmarks fail to assess nuances in user instructions and LLM outputs, highlighting the need for large-scale datasets and benchmarks for LLM preference alignment. In this paper, we introduce CodeUltraFeedback, a preference dataset of 10,000 complex instructions to tune and align LLMs to coding preferences through AI feedback. We generate responses to the instructions using a pool of 14 diverse LLMs, which we then annotate according to their alignment with five coding preferences using the LLM-as-a-Judge approach with GPT-3.5, producing both numerical and textual feedback. We also present CODAL-Bench, a benchmark for assessing LLM alignment with these coding preferences. Our results show that C
&lt;/p&gt;</description></item></channel></rss>