<rss version="2.0"><channel><title>Chat Arxiv cs.SE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SE</description><item><title>&#26412;&#25991;&#36890;&#36807;&#23545;&#26426;&#22120;/&#28145;&#24230;&#23398;&#20064;&#30340;&#36719;&#20214;&#24037;&#31243;&#39046;&#22495;&#20013;&#21487;&#35299;&#37322;&#24615;&#30340;&#31995;&#32479;&#25991;&#29486;&#32508;&#36848;&#65292;&#24635;&#32467;&#20102;XAI&#25216;&#26415;&#22312;&#36719;&#20214;&#24037;&#31243;&#20013;&#30340;&#24212;&#29992;&#24773;&#20917;&#65292;&#26088;&#22312;&#25552;&#39640;AI&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#20197;&#35299;&#20915;&#23454;&#38469;&#37096;&#32626;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#21644;&#39118;&#38505;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.14617</link><description>&lt;p&gt;
&#12298;&#22522;&#20110;&#26426;&#22120;/&#28145;&#24230;&#23398;&#20064;&#30340;&#36719;&#20214;&#24037;&#31243;&#30740;&#31350;&#20013;&#21487;&#35299;&#37322;&#24615;&#30340;&#31995;&#32479;&#25991;&#29486;&#32508;&#36848;&#12299;
&lt;/p&gt;
&lt;p&gt;
A Systematic Literature Review on Explainability for Machine/Deep Learning-based Software Engineering Research. (arXiv:2401.14617v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14617
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23545;&#26426;&#22120;/&#28145;&#24230;&#23398;&#20064;&#30340;&#36719;&#20214;&#24037;&#31243;&#39046;&#22495;&#20013;&#21487;&#35299;&#37322;&#24615;&#30340;&#31995;&#32479;&#25991;&#29486;&#32508;&#36848;&#65292;&#24635;&#32467;&#20102;XAI&#25216;&#26415;&#22312;&#36719;&#20214;&#24037;&#31243;&#20013;&#30340;&#24212;&#29992;&#24773;&#20917;&#65292;&#26088;&#22312;&#25552;&#39640;AI&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#20197;&#35299;&#20915;&#23454;&#38469;&#37096;&#32626;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#21644;&#39118;&#38505;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#31639;&#27861;&#65292;&#29305;&#21035;&#26159;&#26426;&#22120;&#23398;&#20064;&#21644;&#28145;&#24230;&#23398;&#20064;&#65292;&#22312;&#36719;&#20214;&#24037;&#31243;&#39046;&#22495;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#23601;&#65292;&#24182;&#24471;&#21040;&#20102;&#24191;&#27867;&#30340;&#24212;&#29992;&#65292;&#20294;&#30001;&#20110;&#23427;&#20204;&#30340;&#40657;&#30418;&#29305;&#24615;&#65292;&#36825;&#20123;&#20855;&#26377;&#28508;&#21147;&#30340;AI&#39537;&#21160;&#30340;&#36719;&#20214;&#24037;&#31243;&#27169;&#22411;&#31163;&#23454;&#38469;&#37096;&#32626;&#36824;&#26377;&#24456;&#22823;&#30340;&#24046;&#36317;&#12290;&#36825;&#31181;&#32570;&#20047;&#21487;&#35299;&#37322;&#24615;&#23545;&#20110;&#22312;&#20851;&#38190;&#20219;&#21153;&#20013;&#24212;&#29992;&#36825;&#20123;&#27169;&#22411;&#65292;&#22914;&#28431;&#27934;&#26816;&#27979;&#65292;&#20915;&#31574;&#36879;&#26126;&#24615;&#33267;&#20851;&#37325;&#35201;&#65292;&#21364;&#24102;&#26469;&#20102;&#19981;&#24517;&#35201;&#30340;&#39118;&#38505;&#12290;&#26412;&#25991;&#36890;&#36807;&#23545;SE&#39046;&#22495;&#20013;&#26088;&#22312;&#25552;&#39640;AI&#27169;&#22411;&#21487;&#35299;&#37322;&#24615;&#30340;&#26041;&#27861;&#36827;&#34892;&#31995;&#32479;&#25991;&#29486;&#32508;&#36848;&#26469;&#38416;&#26126;&#36825;&#20010;&#36328;&#23398;&#31185;&#39046;&#22495;&#12290;&#35813;&#32508;&#36848;&#35206;&#30422;&#20102;SE&#21644;AI&#23398;&#26415;&#20250;&#35758;&#21644;&#26399;&#21002;&#20013;&#20986;&#29616;&#30340;&#30740;&#31350;&#65292;&#28085;&#30422;&#20102;21&#20010;&#29420;&#29305;&#30340;SE&#20219;&#21153;&#30340;63&#31687;&#35770;&#25991;&#12290;&#22522;&#20110;&#19977;&#20010;&#20851;&#38190;&#30340;&#30740;&#31350;&#38382;&#39064;&#65292;&#25105;&#20204;&#26088;&#22312;&#24635;&#32467;XAI&#25216;&#26415;&#22312;SE&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
The remarkable achievements of Artificial Intelligence (AI) algorithms, particularly in Machine Learning (ML) and Deep Learning (DL), have fueled their extensive deployment across multiple sectors, including Software Engineering (SE). However, due to their black-box nature, these promising AI-driven SE models are still far from being deployed in practice. This lack of explainability poses unwanted risks for their applications in critical tasks, such as vulnerability detection, where decision-making transparency is of paramount importance. This paper endeavors to elucidate this interdisciplinary domain by presenting a systematic literature review of approaches that aim to improve the explainability of AI models within the context of SE. The review canvasses work appearing in the most prominent SE &amp; AI conferences and journals, and spans 63 papers across 21 unique SE tasks. Based on three key Research Questions (RQs), we aim to (1) summarize the SE tasks where XAI techniques have shown s
&lt;/p&gt;</description></item></channel></rss>