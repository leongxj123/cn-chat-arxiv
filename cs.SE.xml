<rss version="2.0"><channel><title>Chat Arxiv cs.SE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SE</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;&#22810;&#35282;&#24230;&#33258;&#19968;&#33268;&#24615;&#65288;MPSC&#65289;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#25552;&#21319;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#22312;&#22797;&#26434;&#30340;&#20195;&#30721;&#29983;&#25104;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#12290;&#35813;&#26694;&#26550;&#36890;&#36807;&#20174;&#22810;&#20010;&#35282;&#24230;&#37319;&#26679;&#22810;&#20010;&#36755;&#20986;&#24182;&#26500;&#24314;&#19968;&#20010;&#22810;&#37096;&#20998;&#22270;&#65292;&#21033;&#29992;&#20132;&#21449;&#19968;&#33268;&#24615;&#21644;&#20869;&#19968;&#33268;&#24615;&#20449;&#24687;&#26469;&#36873;&#25321;&#26368;&#20248;&#36755;&#20986;&#12290;</title><link>http://arxiv.org/abs/2309.17272</link><description>&lt;p&gt;
&#25552;&#21319;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#22312;&#32534;&#30721;&#20013;&#30340;&#33021;&#21147;&#36890;&#36807;&#22810;&#35282;&#24230;&#33258;&#19968;&#33268;&#24615;
&lt;/p&gt;
&lt;p&gt;
Enhancing Large Language Models in Coding Through Multi-Perspective Self-Consistency. (arXiv:2309.17272v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.17272
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;&#22810;&#35282;&#24230;&#33258;&#19968;&#33268;&#24615;&#65288;MPSC&#65289;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#25552;&#21319;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#22312;&#22797;&#26434;&#30340;&#20195;&#30721;&#29983;&#25104;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#12290;&#35813;&#26694;&#26550;&#36890;&#36807;&#20174;&#22810;&#20010;&#35282;&#24230;&#37319;&#26679;&#22810;&#20010;&#36755;&#20986;&#24182;&#26500;&#24314;&#19968;&#20010;&#22810;&#37096;&#20998;&#22270;&#65292;&#21033;&#29992;&#20132;&#21449;&#19968;&#33268;&#24615;&#21644;&#20869;&#19968;&#33268;&#24615;&#20449;&#24687;&#26469;&#36873;&#25321;&#26368;&#20248;&#36755;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#25991;&#26412;&#29983;&#25104;&#26041;&#38754;&#23637;&#29616;&#20102;&#21331;&#36234;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#22312;&#22797;&#26434;&#30340;&#25512;&#29702;&#20219;&#21153;&#65292;&#22914;&#20195;&#30721;&#29983;&#25104;&#20013;&#65292;LLMs&#20173;&#28982;&#38590;&#20197;&#22312;&#19968;&#27425;&#23581;&#35797;&#20013;&#29983;&#25104;&#27491;&#30830;&#30340;&#31572;&#26696;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#36890;&#36807;&#32858;&#21512;&#22810;&#20010;&#36755;&#20986;&#65292;&#21033;&#29992;&#23427;&#20204;&#20043;&#38388;&#30340;&#19968;&#33268;&#24615;&#26469;&#25506;&#32034;&#35299;&#20915;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#30740;&#31350;&#27809;&#26377;&#20840;&#38754;&#22320;&#20174;&#19981;&#21516;&#30340;&#35282;&#24230;&#25429;&#25417;&#36825;&#31181;&#19968;&#33268;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22810;&#35282;&#24230;&#33258;&#19968;&#33268;&#24615;&#65288;MPSC&#65289;&#26694;&#26550;&#30340;&#26032;&#30340;&#35299;&#30721;&#31574;&#30053;&#65292;&#29992;&#20110;LLM&#65292;&#23427;&#23558;&#26469;&#33258;&#22810;&#20010;&#35282;&#24230;&#30340;&#36755;&#20986;&#20043;&#38388;&#30340;&#20132;&#21449;&#19968;&#33268;&#24615;&#21644;&#21333;&#20010;&#35282;&#24230;&#20869;&#30340;&#20869;&#19968;&#33268;&#24615;&#32467;&#21512;&#36215;&#26469;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35201;&#27714;LLMs&#23545;&#32473;&#23450;&#26597;&#35810;&#20174;&#21508;&#20010;&#35282;&#24230;&#37319;&#26679;&#22810;&#20010;&#22810;&#26679;&#21270;&#30340;&#36755;&#20986;&#65292;&#24182;&#22522;&#20110;&#23427;&#20204;&#26500;&#24314;&#19968;&#20010;&#22810;&#37096;&#20998;&#22270;&#12290;&#36890;&#36807;&#20004;&#20010;&#39044;&#23450;&#20041;&#30340;&#19968;&#33268;&#24615;&#24230;&#37327;&#65292;&#25105;&#20204;&#23558;&#20132;&#21449;&#19968;&#33268;&#24615;&#21644;&#20869;&#19968;&#33268;&#24615;&#20449;&#24687;&#23884;&#20837;&#21040;&#22270;&#20013;&#12290;&#26368;&#20339;&#36873;&#25321;&#26159;&#26681;&#25454;&#36825;&#20123;&#19968;&#33268;&#24615;&#24230;&#37327;&#26469;&#36873;&#25321;&#36755;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have exhibited remarkable ability in textual generation. However, in complex reasoning tasks such as code generation, generating the correct answer in a single attempt remains a formidable challenge for LLMs. Previous research has explored solutions by aggregating multiple outputs, leveraging the consistency among them. However, none of them have comprehensively captured this consistency from different perspectives. In this paper, we propose the Multi-Perspective Self-Consistency (MPSC) framework, a novel decoding strategy for LLM that incorporates both inter-consistency across outputs from multiple perspectives and intra-consistency within a single perspective. Specifically, we ask LLMs to sample multiple diverse outputs from various perspectives for a given query and then construct a multipartite graph based on them. With two predefined measures of consistency, we embed both inter- and intra-consistency information into the graph. The optimal choice is th
&lt;/p&gt;</description></item></channel></rss>