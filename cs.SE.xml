<rss version="2.0"><channel><title>Chat Arxiv cs.SE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SE</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26234;&#33021;&#30028;&#38754;&#22312;&#36719;&#20214;&#39033;&#30446;&#20013;&#36827;&#34892;&#24037;&#20316;&#37327;&#21644;&#35268;&#27169;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#27604;&#36739;&#20256;&#32479;&#26041;&#27861;&#65292;&#25506;&#35752;&#20102;&#22914;&#20309;&#36890;&#36807;&#22686;&#24378;&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#30340;&#38382;&#39064;&#35268;&#33539;&#26469;&#23454;&#29616;&#24320;&#21457;&#24037;&#20316;&#37327;&#30340;&#20934;&#30830;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2402.07158</link><description>&lt;p&gt;
&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26234;&#33021;&#30028;&#38754;&#22312;&#36719;&#20214;&#39033;&#30446;&#20013;&#30340;&#24037;&#20316;&#37327;&#21644;&#35268;&#27169;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Effort and Size Estimation in Software Projects with Large Language Model-based Intelligent Interfaces
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07158
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26234;&#33021;&#30028;&#38754;&#22312;&#36719;&#20214;&#39033;&#30446;&#20013;&#36827;&#34892;&#24037;&#20316;&#37327;&#21644;&#35268;&#27169;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#27604;&#36739;&#20256;&#32479;&#26041;&#27861;&#65292;&#25506;&#35752;&#20102;&#22914;&#20309;&#36890;&#36807;&#22686;&#24378;&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#30340;&#38382;&#39064;&#35268;&#33539;&#26469;&#23454;&#29616;&#24320;&#21457;&#24037;&#20316;&#37327;&#30340;&#20934;&#30830;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#21457;&#23637;&#20063;&#23548;&#33268;&#20854;&#24212;&#29992;&#30340;&#24191;&#27867;&#22686;&#21152;&#12290;&#36719;&#20214;&#35774;&#35745;&#20316;&#20026;&#20854;&#20013;&#20043;&#19968;&#65292;&#22312;&#20351;&#29992;LLM&#20316;&#20026;&#25193;&#23637;&#22266;&#23450;&#29992;&#25143;&#25925;&#20107;&#30340;&#25509;&#21475;&#32452;&#20214;&#26041;&#38754;&#33719;&#24471;&#20102;&#24040;&#22823;&#30340;&#22909;&#22788;&#12290;&#28982;&#32780;&#65292;&#23558;&#22522;&#20110;LLM&#30340;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#21253;&#21547;&#22312;&#36719;&#20214;&#35774;&#35745;&#20013;&#24120;&#24120;&#24102;&#26469;&#24847;&#24819;&#19981;&#21040;&#30340;&#25361;&#25112;&#65292;&#29305;&#21035;&#26159;&#22312;&#24320;&#21457;&#24037;&#20316;&#37327;&#30340;&#20272;&#35745;&#26041;&#38754;&#12290;&#36890;&#36807;&#22522;&#20110;&#29992;&#25143;&#30028;&#38754;&#30340;&#29992;&#25143;&#25925;&#20107;&#30340;&#20363;&#23376;&#65292;&#25105;&#20204;&#23545;&#27604;&#20102;&#20256;&#32479;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#22686;&#24378;&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#30340;&#38382;&#39064;&#30340;&#35268;&#33539;&#65292;&#36890;&#36807;&#32771;&#34385;&#25968;&#25454;&#28304;&#12289;&#25509;&#21475;&#21644;&#31639;&#27861;&#26469;&#36827;&#34892;&#24320;&#21457;&#24037;&#20316;&#37327;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
The advancement of Large Language Models (LLM) has also resulted in an equivalent proliferation in its applications. Software design, being one, has gained tremendous benefits in using LLMs as an interface component that extends fixed user stories. However, inclusion of LLM-based AI agents in software design often poses unexpected challenges, especially in the estimation of development efforts. Through the example of UI-based user stories, we provide a comparison against traditional methods and propose a new way to enhance specifications of natural language-based questions that allows for the estimation of development effort by taking into account data sources, interfaces and algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35774;&#35745;&#20102;&#19968;&#20010;&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#27969;&#27700;&#32447;&#65292;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#35268;&#26684;&#29983;&#25104;&#33521;&#35821;&#12289;&#32447;&#24615;&#26102;&#24577;&#36923;&#36753;&#21644;SVA&#26029;&#35328;&#65292;&#24182;&#25104;&#21151;&#20943;&#23569;&#20102;&#26029;&#35328;&#38169;&#35823;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.00093</link><description>&lt;p&gt;
ChIRAAG: &#36890;&#36807;ChatGPT&#29983;&#25104;&#24555;&#36895;&#21644;&#33258;&#21160;&#26029;&#35328;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
ChIRAAG: ChatGPT Informed Rapid and Automated Assertion Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00093
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35774;&#35745;&#20102;&#19968;&#20010;&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#27969;&#27700;&#32447;&#65292;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#35268;&#26684;&#29983;&#25104;&#33521;&#35821;&#12289;&#32447;&#24615;&#26102;&#24577;&#36923;&#36753;&#21644;SVA&#26029;&#35328;&#65292;&#24182;&#25104;&#21151;&#20943;&#23569;&#20102;&#26029;&#35328;&#38169;&#35823;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
System Verilog Assertion (SVA)&#30340;&#24418;&#24335;&#21270;&#26159;Formal Property Verification (FPV)&#36807;&#31243;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#20294;&#22797;&#26434;&#30340;&#20219;&#21153;&#12290;&#20256;&#32479;&#19978;&#65292;SVA&#30340;&#24418;&#24335;&#21270;&#38656;&#35201;&#32463;&#39564;&#20016;&#23500;&#30340;&#19987;&#23478;&#35299;&#37322;&#35268;&#26684;&#12290;&#36825;&#26159;&#32791;&#26102;&#19988;&#23481;&#26131;&#20986;&#38169;&#30340;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#36827;&#23637;&#20351;&#24471;&#22522;&#20110;LLM&#30340;&#33258;&#21160;&#26029;&#35328;&#29983;&#25104;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20852;&#36259;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;LLM&#30340;&#27969;&#27700;&#32447;&#65292;&#29992;&#20110;&#20174;&#33258;&#28982;&#35821;&#35328;&#35268;&#26684;&#20013;&#29983;&#25104;&#33521;&#35821;&#12289;&#32447;&#24615;&#26102;&#24577;&#36923;&#36753;&#21644;SVA&#30340;&#26029;&#35328;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#22522;&#20110;OpenAI GPT4&#30340;&#33258;&#23450;&#20041;LLM&#29992;&#20110;&#23454;&#39564;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#27979;&#35797;&#24179;&#21488;&#26469;&#39564;&#35777;LLM&#29983;&#25104;&#30340;&#26029;&#35328;&#12290;&#21482;&#26377;43%&#30340;LLM&#29983;&#25104;&#30340;&#21407;&#22987;&#26029;&#35328;&#23384;&#22312;&#38169;&#35823;&#65292;&#21253;&#25324;&#35821;&#27861;&#21644;&#36923;&#36753;&#38169;&#35823;&#12290;&#36890;&#36807;&#20351;&#29992;&#20174;&#27979;&#35797;&#26696;&#20363;&#22833;&#36133;&#20013;&#24471;&#20986;&#30340;&#31934;&#24515;&#35774;&#35745;&#30340;&#25552;&#31034;&#65292;&#36845;&#20195;&#22320;&#20419;&#20351;LLM&#65292;&#35813;&#27969;&#27700;&#32447;&#22312;&#26368;&#22810;&#20061;&#27425;&#25552;&#31034;&#36845;&#20195;&#21518;&#21487;&#20197;&#29983;&#25104;&#27491;&#30830;&#30340;SVA&#12290;
&lt;/p&gt;
&lt;p&gt;
System Verilog Assertion (SVA) formulation, a critical yet complex task, is a pre-requisite in the Formal Property Verification (FPV) process. Traditionally, SVA formulation involves expert-driven interpretation of specifications. This is time consuming and prone to human error. However, recent advances in Large Language Models (LLM), LLM-informed automatic assertion generation is gaining interest. We designed a novel LLM-based pipeline to generate assertions in English Language, Linear Temporal Logic, and SVA from natural language specifications. We developed a custom LLM-based on OpenAI GPT4 for our experiments. Furthermore, we developed testbenches to verify/validate the LLM-generated assertions. Only 43% of LLM-generated raw assertions had errors, including syntax and logical errors. By iteratively prompting the LLMs using carefully crafted prompts derived from test case failures, the pipeline could generate correct SVAs after a maximum of nine iterations of prompting. Our results 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#32467;&#21512;&#22823;&#35821;&#35328;&#27169;&#22411;&#21644;&#24418;&#24335;&#39564;&#35777;&#30340;&#26041;&#27861;&#26469;&#33258;&#21160;&#39564;&#35777;&#21644;&#20462;&#22797;&#36719;&#20214;&#28431;&#27934;&#65292;&#24182;&#36890;&#36807;ESBMC-AI&#20570;&#20986;&#20102;&#27010;&#24565;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2305.14752</link><description>&lt;p&gt;
&#36208;&#21521;&#36719;&#20214;&#33258;&#24840;&#65306;&#32467;&#21512;&#22823;&#35821;&#35328;&#27169;&#22411;&#21644;&#24418;&#24335;&#39564;&#35777;&#35299;&#20915;&#36719;&#20214;&#23433;&#20840;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
A New Era in Software Security: Towards Self-Healing Software via Large Language Models and Formal Verification. (arXiv:2305.14752v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14752
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#32467;&#21512;&#22823;&#35821;&#35328;&#27169;&#22411;&#21644;&#24418;&#24335;&#39564;&#35777;&#30340;&#26041;&#27861;&#26469;&#33258;&#21160;&#39564;&#35777;&#21644;&#20462;&#22797;&#36719;&#20214;&#28431;&#27934;&#65292;&#24182;&#36890;&#36807;ESBMC-AI&#20570;&#20986;&#20102;&#27010;&#24565;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#23558;&#22823;&#35821;&#35328;&#27169;&#22411;&#21644;&#24418;&#24335;&#21270;&#39564;&#35777;&#31574;&#30053;&#30456;&#32467;&#21512;&#65292;&#20351;&#24471;&#36719;&#20214;&#28431;&#27934;&#21487;&#20197;&#24471;&#21040;&#39564;&#35777;&#21644;&#33258;&#21160;&#20462;&#22797;&#12290;&#39318;&#20808;&#21033;&#29992;&#26377;&#38480;&#27169;&#22411;&#26816;&#26597;&#65288;BMC&#65289;&#23450;&#20301;&#36719;&#20214;&#28431;&#27934;&#21644;&#27966;&#29983;&#21453;&#20363;&#12290;&#28982;&#21518;&#65292;&#23558;&#21453;&#20363;&#21644;&#28304;&#20195;&#30721;&#25552;&#20379;&#32473;&#22823;&#35821;&#35328;&#27169;&#22411;&#24341;&#25806;&#36827;&#34892;&#20195;&#30721;&#35843;&#35797;&#21644;&#29983;&#25104;&#65292;&#20174;&#32780;&#25214;&#21040;&#28431;&#27934;&#30340;&#26681;&#26412;&#21407;&#22240;&#24182;&#20462;&#22797;&#20195;&#30721;&#12290;&#26368;&#21518;&#65292;&#21017;&#20351;&#29992;BMC&#39564;&#35777;&#22823;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#30340;&#20462;&#27491;&#29256;&#26412;&#30340;&#20195;&#30721;&#12290; &#20316;&#20026;&#27010;&#24565;&#35777;&#26126;&#65292;&#25105;&#20204;&#21019;&#24314;&#20102;ESBMC-AI&#65292;&#23427;&#22522;&#20110;&#39640;&#25928;&#30340;&#22522;&#20110;SMT&#30340;&#19978;&#19979;&#25991;&#26377;&#30028;&#27169;&#22411;&#26816;&#26597;&#22120;&#65288;ESBMC&#65289;&#21644;&#19968;&#20010;&#39044;&#35757;&#32451;&#30340;Transformer&#27169;&#22411;gpt-3.5-turbo&#26469;&#26816;&#27979;&#21644;&#20462;&#22797;C&#31243;&#24207;&#20013;&#30340;&#38169;&#35823;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we present a novel solution that combines the capabilities of Large Language Models (LLMs) with Formal Verification strategies to verify and automatically repair software vulnerabilities. Initially, we employ Bounded Model Checking (BMC) to locate the software vulnerability and derive a counterexample. The counterexample provides evidence that the system behaves incorrectly or contains a vulnerability. The counterexample that has been detected, along with the source code, are provided to the LLM engine. Our approach involves establishing a specialized prompt language for conducting code debugging and generation to understand the vulnerability's root cause and repair the code. Finally, we use BMC to verify the corrected version of the code generated by the LLM. As a proof of concept, we create ESBMC-AI based on the Efficient SMT-based Context-Bounded Model Checker (ESBMC) and a pre-trained Transformer model, specifically gpt-3.5-turbo, to detect and fix errors in C program
&lt;/p&gt;</description></item></channel></rss>