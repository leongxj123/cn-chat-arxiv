<rss version="2.0"><channel><title>Chat Arxiv cs.SE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SE</description><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;PrimeVul&#65292;&#29992;&#20110;&#35757;&#32451;&#21644;&#35780;&#20272;&#20195;&#30721;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#28431;&#27934;&#26816;&#27979;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#22871;&#26032;&#39062;&#30340;&#25968;&#25454;&#26631;&#35760;&#25216;&#26415;&#65292;&#23454;&#29616;&#20102;&#19982;&#20154;&#24037;&#39564;&#35777;&#22522;&#20934;&#30456;&#24403;&#30340;&#26631;&#31614;&#20934;&#30830;&#24615;&#65292;&#26174;&#33879;&#25193;&#22823;&#20102;&#25968;&#25454;&#38598;&#12290;</title><link>https://arxiv.org/abs/2403.18624</link><description>&lt;p&gt;
&#20351;&#29992;&#20195;&#30721;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#28431;&#27934;&#26816;&#27979;&#65306;&#25105;&#20204;&#31163;&#30446;&#26631;&#26377;&#22810;&#36828;&#65311;
&lt;/p&gt;
&lt;p&gt;
Vulnerability Detection with Code Language Models: How Far Are We?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18624
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;PrimeVul&#65292;&#29992;&#20110;&#35757;&#32451;&#21644;&#35780;&#20272;&#20195;&#30721;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#28431;&#27934;&#26816;&#27979;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#22871;&#26032;&#39062;&#30340;&#25968;&#25454;&#26631;&#35760;&#25216;&#26415;&#65292;&#23454;&#29616;&#20102;&#19982;&#20154;&#24037;&#39564;&#35777;&#22522;&#20934;&#30456;&#24403;&#30340;&#26631;&#31614;&#20934;&#30830;&#24615;&#65292;&#26174;&#33879;&#25193;&#22823;&#20102;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20195;&#30721;&#35821;&#35328;&#27169;&#22411;&#65288;code LMs&#65289;&#21644;&#28431;&#27934;&#26816;&#27979;&#22791;&#21463;&#20851;&#27880;&#30340;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20195;&#30721;&#35821;&#35328;&#27169;&#22411;&#29992;&#20110;&#26816;&#27979;&#28431;&#27934;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#25581;&#31034;&#20102;&#29616;&#26377;&#28431;&#27934;&#25968;&#25454;&#38598;&#23384;&#22312;&#30340;&#37325;&#22823;&#32570;&#38519;&#65292;&#21253;&#25324;&#25968;&#25454;&#36136;&#37327;&#20302;&#12289;&#26631;&#31614;&#20934;&#30830;&#24615;&#24046;&#20197;&#21450;&#39640;&#37325;&#22797;&#29575;&#65292;&#23548;&#33268;&#22312;&#29616;&#23454;&#28431;&#27934;&#26816;&#27979;&#22330;&#26223;&#20013;&#27169;&#22411;&#24615;&#33021;&#19981;&#21487;&#38752;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#25968;&#25454;&#38598;&#20351;&#29992;&#30340;&#35780;&#20272;&#26041;&#27861;&#20063;&#19981;&#33021;&#20195;&#34920;&#30495;&#23454;&#19990;&#30028;&#30340;&#28431;&#27934;&#26816;&#27979;&#24773;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18624v1 Announce Type: cross  Abstract: In the context of the rising interest in code language models (code LMs) and vulnerability detection, we study the effectiveness of code LMs for detecting vulnerabilities. Our analysis reveals significant shortcomings in existing vulnerability datasets, including poor data quality, low label accuracy, and high duplication rates, leading to unreliable model performance in realistic vulnerability detection scenarios. Additionally, the evaluation methods used with these datasets are not representative of real-world vulnerability detection.   To address these challenges, we introduce PrimeVul, a new dataset for training and evaluating code LMs for vulnerability detection. PrimeVul incorporates a novel set of data labeling techniques that achieve comparable label accuracy to human-verified benchmarks while significantly expanding the dataset. It also implements a rigorous data de-duplication and chronological data splitting strategy to miti
&lt;/p&gt;</description></item><item><title>CodeGeeX&#26159;&#19968;&#20010;&#22810;&#35821;&#35328;&#27169;&#22411;&#65292;&#20855;&#26377;130&#20159;&#21442;&#25968;&#65292;&#29992;&#20110;&#20195;&#30721;&#29983;&#25104;&#12290;&#32463;&#36807;&#24191;&#27867;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;CodeGeeX&#22312;HumanEval-X&#19978;&#30340;&#20195;&#30721;&#29983;&#25104;&#21644;&#32763;&#35793;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;&#27492;&#22806;&#65292;CodeGeeX&#21487;&#20197;&#23558;&#31243;&#24207;&#21592;&#30340;&#29983;&#20135;&#21147;&#25552;&#39640;22%&#12290;</title><link>http://arxiv.org/abs/2303.17568</link><description>&lt;p&gt;
CodeGeeX&#65306;&#22810;&#35821;&#35328;&#35780;&#20272;&#19979;&#30340;&#39044;&#35757;&#32451;&#20195;&#30721;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Evaluations on HumanEval-X. (arXiv:2303.17568v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.17568
&lt;/p&gt;
&lt;p&gt;
CodeGeeX&#26159;&#19968;&#20010;&#22810;&#35821;&#35328;&#27169;&#22411;&#65292;&#20855;&#26377;130&#20159;&#21442;&#25968;&#65292;&#29992;&#20110;&#20195;&#30721;&#29983;&#25104;&#12290;&#32463;&#36807;&#24191;&#27867;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;CodeGeeX&#22312;HumanEval-X&#19978;&#30340;&#20195;&#30721;&#29983;&#25104;&#21644;&#32763;&#35793;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;&#27492;&#22806;&#65292;CodeGeeX&#21487;&#20197;&#23558;&#31243;&#24207;&#21592;&#30340;&#29983;&#20135;&#21147;&#25552;&#39640;22%&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#39044;&#35757;&#32451;&#20195;&#30721;&#29983;&#25104;&#27169;&#22411;&#65288;&#22914;OpenAI Codex&#65289;&#21487;&#20197;&#29983;&#25104;&#27491;&#30830;&#35821;&#27861;&#21644;&#21151;&#33021;&#30340;&#20195;&#30721;&#65292;&#20351;&#31243;&#24207;&#21592;&#30340;&#32534;&#30721;&#26356;&#21152;&#39640;&#25928;&#65292;&#20351;&#25105;&#20204;&#23545;&#20154;&#24037;&#26234;&#33021;&#30340;&#36861;&#27714;&#26356;&#21152;&#36148;&#36817;&#29616;&#23454;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;CodeGeeX&#65292;&#19968;&#20010;&#20855;&#26377;130&#20159;&#21442;&#25968;&#30340;&#22810;&#35821;&#35328;&#27169;&#22411;&#65292;&#29992;&#20110;&#20195;&#30721;&#29983;&#25104;&#12290;CodeGeeX&#22312;2022&#24180;6&#26376;&#26102;&#22522;&#20110;23&#31181;&#32534;&#31243;&#35821;&#35328;&#30340;8500&#20159;&#20196;&#29260;&#36827;&#34892;&#20102;&#39044;&#35757;&#32451;&#12290;&#25105;&#20204;&#30340;&#24191;&#27867;&#23454;&#39564;&#34920;&#26126;&#65292;CodeGeeX&#22312;HumanEval-X&#19978;&#30340;&#20195;&#30721;&#29983;&#25104;&#21644;&#32763;&#35793;&#20219;&#21153;&#20013;&#22343;&#20248;&#20110;&#35268;&#27169;&#30456;&#20284;&#30340;&#22810;&#35821;&#35328;&#20195;&#30721;&#27169;&#22411;&#12290;&#22312;HumanEval&#65288;&#20165;&#38480;Python&#65289;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;HumanEval-X&#22522;&#20934;&#27979;&#35797;&#65292;&#36890;&#36807;&#25163;&#20889;C ++&#12289;Java&#12289;JavaScript&#21644;Go&#30340;&#35299;&#20915;&#26041;&#26696;&#26469;&#35780;&#20272;&#22810;&#35821;&#35328;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22312;Visual Studio Code&#12289;JetBrains&#21644;Cloud Studio&#19978;&#26500;&#24314;&#20102;&#22522;&#20110;CodeGeeX&#30340;&#25193;&#23637;&#65292;&#27599;&#21608;&#20026;&#25968;&#20197;&#19975;&#35745;&#30340;&#27963;&#36291;&#29992;&#25143;&#29983;&#25104;47&#20159;&#20196;&#29260;&#12290;&#25105;&#20204;&#30340;&#29992;&#25143;&#30740;&#31350;&#34920;&#26126;&#65292;CodeGeeX&#21487;&#20197;&#23558;&#31243;&#24207;&#21592;&#30340;&#29983;&#20135;&#21147;&#25552;&#39640;22%&#12290;
&lt;/p&gt;
&lt;p&gt;
Large pre-trained code generation models, such as OpenAI Codex, can generate syntax- and function-correct code, making the coding of programmers more productive and our pursuit of artificial general intelligence closer. In this paper, we introduce CodeGeeX, a multilingual model with 13 billion parameters for code generation. CodeGeeX is pre-trained on 850 billion tokens of 23 programming languages as of June 2022. Our extensive experiments suggest that CodeGeeX outperforms multilingual code models of similar scale for both the tasks of code generation and translation on HumanEval-X. Building upon HumanEval (Python only), we develop the HumanEval-X benchmark for evaluating multilingual models by hand-writing the solutions in C++, Java, JavaScript, and Go. In addition, we build CodeGeeX-based extensions on Visual Studio Code, JetBrains, and Cloud Studio, generating 4.7 billion tokens for tens of thousands of active users per week. Our user study demonstrates that CodeGeeX can help to inc
&lt;/p&gt;</description></item></channel></rss>