<rss version="2.0"><channel><title>Chat Arxiv cs.SE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SE</description><item><title>&#26412;&#30740;&#31350;&#23454;&#35777;&#20998;&#26512;&#20102;11&#31181;&#27969;&#34892;&#30340;&#19987;&#38376;&#35843;&#25972;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#20116;&#31181;&#35821;&#35328;&#19978;&#29983;&#25104;&#30340;&#36755;&#20986;&#65292;&#21457;&#29616;&#20854;&#20013;26.4%&#21040;73.7%&#30340;&#20195;&#30721;&#32763;&#35793;&#38656;&#35201;&#21518;&#22788;&#29702;&#12290;</title><link>https://arxiv.org/abs/2403.17214</link><description>&lt;p&gt;
&#25506;&#31350;&#36755;&#20986;&#26684;&#24335;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#20195;&#30721;&#32763;&#35793;&#35780;&#20272;&#20013;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Exploring the Impact of the Output Format on the Evaluation of Large Language Models for Code Translation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17214
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23454;&#35777;&#20998;&#26512;&#20102;11&#31181;&#27969;&#34892;&#30340;&#19987;&#38376;&#35843;&#25972;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#20116;&#31181;&#35821;&#35328;&#19978;&#29983;&#25104;&#30340;&#36755;&#20986;&#65292;&#21457;&#29616;&#20854;&#20013;26.4%&#21040;73.7%&#30340;&#20195;&#30721;&#32763;&#35793;&#38656;&#35201;&#21518;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32534;&#31243;&#35821;&#35328;&#20043;&#38388;&#30340;&#20195;&#30721;&#32763;&#35793;&#26159;&#36719;&#20214;&#24037;&#31243;&#20013;&#38271;&#26399;&#23384;&#22312;&#19988;&#33267;&#20851;&#37325;&#35201;&#30340;&#20219;&#21153;&#65292;&#26377;&#21161;&#20110;&#29616;&#20195;&#21270;&#36951;&#30041;&#31995;&#32479;&#65292;&#30830;&#20445;&#36328;&#24179;&#21488;&#20860;&#23481;&#24615;&#65292;&#25552;&#21319;&#36719;&#20214;&#24615;&#33021;&#12290;&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#21450;&#20854;&#22312;&#20195;&#30721;&#32763;&#35793;&#20013;&#30340;&#24212;&#29992;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#23545;&#36825;&#20123;&#27169;&#22411;&#36827;&#34892;&#20840;&#38754;&#35780;&#20272;&#30340;&#38656;&#27714;&#36234;&#26469;&#36234;&#24378;&#28872;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#22312;&#20116;&#31181;&#35821;&#35328;&#65288;&#21253;&#25324;C&#12289;C++&#12289;Go&#12289;Java&#21644;Python&#65289;&#19978;&#65292;&#20174;1B&#21040;46.7B&#30340;&#21442;&#25968;&#33539;&#22260;&#20869;&#23545;&#21313;&#19968;&#31181;&#27969;&#34892;&#30340;&#19987;&#38376;&#35843;&#25972;&#30340;LLMs&#29983;&#25104;&#30340;&#36755;&#20986;&#36827;&#34892;&#20102;&#23454;&#35777;&#20998;&#26512;&#65292;&#24182;&#28085;&#30422;3820&#20010;&#32763;&#35793;&#23545;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#21457;&#29616;&#65292;&#22312;&#25105;&#20204;&#35780;&#20272;&#30340;LLMs&#20013;&#65292;26.4%&#21040;73.7%&#30340;&#20195;&#30721;&#32763;&#35793;&#38656;&#35201;&#21518;&#22788;&#29702;&#65292;&#22240;&#20026;&#36825;&#20123;&#32763;&#35793;&#36890;&#24120;&#21253;&#21547;&#20195;&#30721;&#12289;&#24341;&#21495;&#21644;&#25991;&#26412;&#30340;&#28151;&#21512;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#32431;&#28304;&#20195;&#30721;&#12290;&#24573;&#35270;&#36825;&#20123;&#27169;&#22411;&#30340;&#36755;&#20986;&#26684;&#24335;&#21487;&#33021;&#19981;&#32463;&#24847;&#38388;&#23548;&#33268;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17214v1 Announce Type: cross  Abstract: Code translation between programming languages is a long-existing and critical task in software engineering, facilitating the modernization of legacy systems, ensuring cross-platform compatibility, and enhancing software performance. With the recent advances in large language models (LLMs) and their applications to code translation, there is an increasing need for comprehensive evaluation of these models. In this study, we empirically analyze the generated outputs of eleven popular instruct-tuned LLMs with parameters ranging from 1B up to 46.7B on 3,820 translation pairs across five languages, including C, C++, Go, Java, and Python. Our analysis found that between 26.4% and 73.7% of code translations produced by our evaluated LLMs necessitate post-processing, as these translations often include a mix of code, quotes, and text rather than being purely source code. Overlooking the output format of these models can inadvertently lead to u
&lt;/p&gt;</description></item></channel></rss>