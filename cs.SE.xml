<rss version="2.0"><channel><title>Chat Arxiv cs.SE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SE</description><item><title>AI&#20174;&#19994;&#32773;&#23545;&#20110;&#20844;&#24179;AI/ML&#30340;&#29702;&#35299;&#12289;&#38754;&#20020;&#30340;&#25361;&#25112;&#12289;&#19981;&#20844;&#24179;AI/ML&#30340;&#21518;&#26524;&#20197;&#21450;&#30830;&#20445;AI/ML&#20844;&#24179;&#24615;&#30340;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2403.15481</link><description>&lt;p&gt;
AI/ML &#21457;&#23637;&#20013;&#30340;&#20844;&#24179;&#23548;&#33322;: &#20174;&#19994;&#32773;&#23545;AI/ML&#24320;&#21457;&#20013;&#30340;&#29702;&#35299;&#12289;&#25361;&#25112;&#21644;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Navigating Fairness: Practitioners' Understanding, Challenges, and Strategies in AI/ML Development
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15481
&lt;/p&gt;
&lt;p&gt;
AI&#20174;&#19994;&#32773;&#23545;&#20110;&#20844;&#24179;AI/ML&#30340;&#29702;&#35299;&#12289;&#38754;&#20020;&#30340;&#25361;&#25112;&#12289;&#19981;&#20844;&#24179;AI/ML&#30340;&#21518;&#26524;&#20197;&#21450;&#30830;&#20445;AI/ML&#20844;&#24179;&#24615;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#21508;&#34892;&#19994;&#23545;AI/ML&#24212;&#29992;&#30340;&#22686;&#21152;&#24341;&#21457;&#20102;&#23545;AI/ML&#20844;&#24179;&#24615;&#30340;&#26356;&#22810;&#35752;&#35770;&#12290;&#34429;&#28982;&#24050;&#26377;&#20851;&#20110;AI/ML&#20844;&#24179;&#24615;&#30340;&#20808;&#21069;&#30740;&#31350;&#65292;&#20294;&#32570;&#20047;&#38024;&#23545;&#20102;&#35299;AI&#20174;&#19994;&#32773;&#22312;&#24320;&#21457;&#20844;&#24179;AI/ML&#36807;&#31243;&#20013;&#30340;&#35266;&#28857;&#21644;&#32463;&#39564;&#30340;&#23454;&#35777;&#30740;&#31350;&#12290;&#20102;&#35299;AI&#20174;&#19994;&#32773;&#23545;AI/ML&#20844;&#24179;&#24615;&#30340;&#30475;&#27861;&#21644;&#32463;&#39564;&#24456;&#37325;&#35201;&#65292;&#22240;&#20026;&#20182;&#20204;&#30452;&#25509;&#21442;&#19982;&#20854;&#20013;&#30340;&#24320;&#21457;&#21644;&#37096;&#32626;&#65292;&#20182;&#20204;&#30340;&#35265;&#35299;&#21487;&#20197;&#25552;&#20379;&#26377;&#20215;&#20540;&#30340;&#29616;&#23454;&#19990;&#30028;&#35270;&#35282;&#65292;&#24110;&#21161;&#29702;&#35299;&#30830;&#20445;AI/ML&#20844;&#24179;&#24615;&#25152;&#28041;&#21450;&#25361;&#25112;&#30340;&#37325;&#35201;&#24615;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;22&#20301;AI&#20174;&#19994;&#32773;&#30340;&#21322;&#32467;&#26500;&#21270;&#35775;&#35848;&#65292;&#20197;&#35843;&#26597;&#20182;&#20204;&#23545;&#8220;&#20844;&#24179;AI/ML&#8221;&#26159;&#20160;&#20040;&#30340;&#29702;&#35299;&#65292;&#20182;&#20204;&#22312;&#24320;&#21457;&#20844;&#24179;AI/ML&#20013;&#38754;&#20020;&#30340;&#25361;&#25112;&#65292;&#24320;&#21457;&#19981;&#20844;&#24179;AI/ML&#30340;&#21518;&#26524;&#65292;&#20197;&#21450;&#20182;&#20204;&#37319;&#21462;&#30340;&#31574;&#30053;&#26469;&#30830;&#20445;AI/ML&#30340;&#20844;&#24179;&#24615;&#12290;&#25105;&#20204;&#21046;&#23450;&#20102;&#19968;&#20010;&#26694;&#26550;&#23637;&#31034;&#20102;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15481v1 Announce Type: cross  Abstract: The rise in the use of AI/ML applications across industries has sparked more discussions about the fairness of AI/ML in recent times. While prior research on the fairness of AI/ML exists, there is a lack of empirical studies focused on understanding the views and experiences of AI practitioners in developing a fair AI/ML. Understanding AI practitioners' views and experiences on the fairness of AI/ML is important because they are directly involved in its development and deployment and their insights can offer valuable real-world perspectives on the challenges associated with ensuring fairness in AI/ML. We conducted semi-structured interviews with 22 AI practitioners to investigate their understanding of what a 'fair AI/ML' is, the challenges they face in developing a fair AI/ML, the consequences of developing an unfair AI/ML, and the strategies they employ to ensure AI/ML fairness. We developed a framework showcasing the relationship be
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;AI&#22522;&#20110;&#31227;&#21160;&#24212;&#29992;&#35780;&#20215;&#20013;&#30340;&#20844;&#24179;&#20851;&#27880;&#65292;&#24182;&#36890;&#36807;&#26500;&#24314;&#25968;&#25454;&#38598;&#21644;&#24320;&#21457;&#20998;&#31867;&#22120;&#30340;&#26041;&#27861;&#65292;&#25104;&#21151;&#26816;&#27979;&#20986;&#20844;&#24179;&#24615;&#35780;&#35770;&#65292;&#24182;&#35782;&#21035;&#20986;&#32422;92000&#26465;&#20844;&#24179;&#24615;&#35780;&#35770;&#12290;</title><link>https://arxiv.org/abs/2401.08097</link><description>&lt;p&gt;
AI&#22522;&#20110;&#31227;&#21160;&#24212;&#29992;&#35780;&#20215;&#30340;&#20844;&#24179;&#20851;&#27880;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A Study of Fairness Concerns in AI-based Mobile App Reviews
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.08097
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;AI&#22522;&#20110;&#31227;&#21160;&#24212;&#29992;&#35780;&#20215;&#20013;&#30340;&#20844;&#24179;&#20851;&#27880;&#65292;&#24182;&#36890;&#36807;&#26500;&#24314;&#25968;&#25454;&#38598;&#21644;&#24320;&#21457;&#20998;&#31867;&#22120;&#30340;&#26041;&#27861;&#65292;&#25104;&#21151;&#26816;&#27979;&#20986;&#20844;&#24179;&#24615;&#35780;&#35770;&#65292;&#24182;&#35782;&#21035;&#20986;&#32422;92000&#26465;&#20844;&#24179;&#24615;&#35780;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20844;&#24179;&#26159;AI&#31995;&#32479;&#20013;&#24517;&#39035;&#35299;&#20915;&#30340;&#31038;&#20250;&#25216;&#26415;&#38382;&#39064;&#20043;&#19968;&#12290;&#19981;&#20844;&#24179;&#30340;AI&#31995;&#32479;&#65292;&#29305;&#21035;&#26159;&#19981;&#20844;&#24179;&#30340;AI&#22522;&#20110;&#31227;&#21160;&#24212;&#29992;&#65292;&#21487;&#33021;&#32473;&#20840;&#29699;&#24456;&#22823;&#19968;&#37096;&#20998;&#20154;&#21475;&#24102;&#26469;&#22256;&#38590;&#12290;&#26412;&#25991;&#26088;&#22312;&#20998;&#26512;AI&#22522;&#20110;&#24212;&#29992;&#35780;&#20215;&#20013;&#30340;&#20844;&#24179;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#25163;&#21160;&#26500;&#24314;&#20102;&#19968;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#21253;&#25324;&#20844;&#24179;&#24615;&#21644;&#38750;&#20844;&#24179;&#24615;&#35780;&#35770;&#30340;&#32479;&#35745;&#26679;&#26412;&#12290;&#21033;&#29992;&#36825;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#24320;&#21457;&#21644;&#35780;&#20272;&#20102;&#19968;&#32452;&#26426;&#22120;&#23398;&#20064;&#21644;&#28145;&#24230;&#23398;&#20064;&#20998;&#31867;&#22120;&#65292;&#29992;&#20110;&#21306;&#20998;&#20844;&#24179;&#24615;&#35780;&#35770;&#21644;&#38750;&#20844;&#24179;&#24615;&#35780;&#35770;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#25105;&#20204;&#26368;&#20339;&#30340;&#20998;&#31867;&#22120;&#21487;&#20197;&#20197;94%&#30340;&#31934;&#30830;&#24230;&#26816;&#27979;&#21040;&#20844;&#24179;&#24615;&#35780;&#35770;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#26368;&#20339;&#20998;&#31867;&#22120;&#24212;&#29992;&#20110;&#20174;108&#20010;AI&#22522;&#20110;&#24212;&#29992;&#25910;&#38598;&#30340;&#32422;950&#19975;&#26465;&#35780;&#35770;&#65292;&#35782;&#21035;&#20986;&#32422;92000&#26465;&#20844;&#24179;&#24615;&#35780;&#35770;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#23558;K-means&#32858;&#31867;&#25216;&#26415;&#24212;&#29992;&#20110;&#36825;92000&#26465;&#20844;&#24179;&#24615;&#35780;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2401.08097v2 Announce Type: replace-cross Abstract: Fairness is one of the socio-technical concerns that must be addressed in AI-based systems. Unfair AI-based systems, particularly unfair AI-based mobile apps, can pose difficulties for a significant proportion of the global population. This paper aims to analyze fairness concerns in AI-based app reviews.We first manually constructed a ground-truth dataset, including a statistical sample of fairness and non-fairness reviews. Leveraging the ground-truth dataset, we developed and evaluated a set of machine learning and deep learning classifiers that distinguish fairness reviews from non-fairness reviews. Our experiments show that our best-performing classifier can detect fairness reviews with a precision of 94%. We then applied the best-performing classifier on approximately 9.5M reviews collected from 108 AI-based apps and identified around 92K fairness reviews. Next, applying the K-means clustering technique to the 92K fairness r
&lt;/p&gt;</description></item></channel></rss>