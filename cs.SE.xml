<rss version="2.0"><channel><title>Chat Arxiv cs.SE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SE</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;EffiBench&#22522;&#20934;&#27979;&#35797;&#65292;&#29992;&#20110;&#35780;&#20272;&#20195;&#30721;&#29983;&#25104;&#27169;&#22411;&#29983;&#25104;&#30340;&#20195;&#30721;&#30340;&#25928;&#29575;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;GPT-4-turbo&#29983;&#25104;&#30340;&#20195;&#30721;&#26368;&#39640;&#25928;&#12290;</title><link>https://arxiv.org/abs/2402.02037</link><description>&lt;p&gt;
EffiBench:&#35780;&#20272;&#33258;&#21160;&#29983;&#25104;&#20195;&#30721;&#30340;&#25928;&#29575;&#30340;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
EffiBench: Benchmarking the Efficiency of Automatically Generated Code
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02037
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;EffiBench&#22522;&#20934;&#27979;&#35797;&#65292;&#29992;&#20110;&#35780;&#20272;&#20195;&#30721;&#29983;&#25104;&#27169;&#22411;&#29983;&#25104;&#30340;&#20195;&#30721;&#30340;&#25928;&#29575;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;GPT-4-turbo&#29983;&#25104;&#30340;&#20195;&#30721;&#26368;&#39640;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20195;&#30721;&#29983;&#25104;&#27169;&#22411;&#22312;&#36741;&#21161;&#36719;&#20214;&#24320;&#21457;&#26041;&#38754;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#65292;&#21487;&#20197;&#24110;&#21161;&#23436;&#25104;&#20195;&#30721;&#34917;&#20840;&#12289;&#35843;&#35797;&#21644;&#20195;&#30721;&#36716;&#25442;&#31561;&#20219;&#21153;&#12290;&#23613;&#31649;&#24403;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#28145;&#20837;&#30740;&#31350;&#20102;&#20195;&#30721;&#29983;&#25104;&#27169;&#22411;&#29983;&#25104;&#30340;&#27491;&#30830;&#24615;&#65292;&#20294;&#29983;&#25104;&#20195;&#30721;&#30340;&#25928;&#29575;&#36825;&#19968;&#37325;&#35201;&#26041;&#38754;&#24120;&#24120;&#34987;&#24573;&#35270;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;EffiBench&#65292;&#19968;&#20010;&#21253;&#21547;1,000&#20010;&#25928;&#29575;&#20851;&#38190;&#30340;&#32534;&#30721;&#38382;&#39064;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#29992;&#20110;&#35780;&#20272;&#20195;&#30721;&#29983;&#25104;&#27169;&#22411;&#29983;&#25104;&#30340;&#20195;&#30721;&#30340;&#25928;&#29575;&#12290;EffiBench&#21253;&#21547;&#20102;&#19968;&#31995;&#21015;&#22810;&#26679;&#21270;&#30340;LeetCode&#32534;&#30721;&#38382;&#39064;&#65292;&#27599;&#20010;&#38382;&#39064;&#37117;&#19982;&#19968;&#20010;&#21487;&#25191;&#34892;&#30340;&#20154;&#24037;&#32534;&#20889;&#30340;&#20856;&#22411;&#35299;&#20915;&#26041;&#26696;&#37197;&#23545;&#12290;&#36890;&#36807;EffiBench&#65292;&#25105;&#20204;&#22312;&#23454;&#36341;&#20013;&#32771;&#23519;&#20102;21&#31181;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;&#20854;&#20013;13&#31181;&#26159;&#24320;&#28304;&#30340;&#65292;8&#31181;&#26159;&#38381;&#28304;&#30340;&#65289;&#22312;&#29983;&#25104;&#39640;&#25928;&#20195;&#30721;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;GPT-4-turbo&#29983;&#25104;&#30340;&#20195;&#30721;&#26368;&#39640;&#25928;&#65292;&#26126;&#26174;&#20248;&#20110;Palm-2-chat-bison&#12289;Claude-instant-1&#12289;Gemini-pro&#12289;GPT-4&#21644;GPT-3.5&#12290;
&lt;/p&gt;
&lt;p&gt;
Code generation models have increasingly become integral to aiding software development, offering assistance in tasks such as code completion, debugging, and code translation. Although current research has thoroughly examined the correctness of code produced by code generation models, a vital aspect, i.e., the efficiency of the generated code, has often been neglected. This paper presents EffiBench, a benchmark with 1,000 efficiency-critical coding problems for assessing the efficiency of code generated by code generation models. EffiBench contains a diverse set of LeetCode coding problems. Each problem is paired with an executable human-written canonical solution. With EffiBench, we empirically examine the capability of 21 Large Language Models (13 open-sourced and 8 closed-sourced) in generating efficient code. The results demonstrate that GPT-4-turbo generates the most efficient code, significantly outperforming Palm-2-chat-bison, Claude-instant-1, Gemini-pro, GPT-4, and GPT-3.5. Ne
&lt;/p&gt;</description></item></channel></rss>