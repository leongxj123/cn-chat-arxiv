<rss version="2.0"><channel><title>Chat Arxiv cs.SE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SE</description><item><title>&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#21313;&#19968;&#31181;&#39046;&#20808;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#28431;&#27934;&#26816;&#27979;&#20013;&#30340;&#33021;&#21147;&#65292;&#24182;&#35780;&#20272;&#20102;&#23427;&#20204;&#30340;&#24615;&#33021;&#65292;&#20026;&#25506;&#32034;LLMs&#25512;&#29702;&#33021;&#21147;&#30340;&#26497;&#38480;&#25552;&#20379;&#20102;&#37325;&#35201;&#26696;&#20363;&#30740;&#31350;&#12290;</title><link>https://arxiv.org/abs/2403.17218</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#28431;&#27934;&#26816;&#27979;&#26041;&#38754;&#30340;&#33021;&#21147;&#32508;&#21512;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A Comprehensive Study of the Capabilities of Large Language Models for Vulnerability Detection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17218
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#21313;&#19968;&#31181;&#39046;&#20808;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#28431;&#27934;&#26816;&#27979;&#20013;&#30340;&#33021;&#21147;&#65292;&#24182;&#35780;&#20272;&#20102;&#23427;&#20204;&#30340;&#24615;&#33021;&#65292;&#20026;&#25506;&#32034;LLMs&#25512;&#29702;&#33021;&#21147;&#30340;&#26497;&#38480;&#25552;&#20379;&#20102;&#37325;&#35201;&#26696;&#20363;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24050;&#32463;&#23637;&#29616;&#20986;&#22312;&#20195;&#30721;&#29983;&#25104;&#21644;&#20854;&#20182;&#36719;&#20214;&#24037;&#31243;&#20219;&#21153;&#26041;&#38754;&#20855;&#26377;&#24040;&#22823;&#28508;&#21147;&#12290;&#28431;&#27934;&#26816;&#27979;&#23545;&#20110;&#32500;&#25252;&#36719;&#20214;&#31995;&#32479;&#30340;&#23433;&#20840;&#12289;&#23436;&#25972;&#24615;&#21644;&#21487;&#20449;&#24230;&#33267;&#20851;&#37325;&#35201;&#12290;&#31934;&#30830;&#30340;&#28431;&#27934;&#26816;&#27979;&#38656;&#35201;&#23545;&#20195;&#30721;&#36827;&#34892;&#25512;&#29702;&#65292;&#36825;&#20351;&#24471;&#23427;&#25104;&#20026;&#25506;&#32034;LLMs&#25512;&#29702;&#33021;&#21147;&#26497;&#38480;&#30340;&#33391;&#22909;&#26696;&#20363;&#30740;&#31350;&#12290;&#23613;&#31649;&#26368;&#36817;&#30340;&#30740;&#31350;&#24050;&#32463;&#21033;&#29992;&#36890;&#29992;&#25552;&#31034;&#25216;&#26415;&#23558;LLMs&#24212;&#29992;&#20110;&#28431;&#27934;&#26816;&#27979;&#65292;&#20294;&#23427;&#20204;&#22312;&#36825;&#19968;&#20219;&#21153;&#20013;&#30340;&#23436;&#25972;&#33021;&#21147;&#20197;&#21450;&#22312;&#35299;&#37322;&#30830;&#23450;&#30340;&#28431;&#27934;&#26102;&#25152;&#29359;&#30340;&#38169;&#35823;&#31867;&#22411;&#20173;&#19981;&#28165;&#26970;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#21313;&#19968;&#31181;&#39046;&#20808;&#30340;&#22312;&#20195;&#30721;&#29983;&#25104;&#26041;&#38754;&#22788;&#20110;&#26368;&#21069;&#27839;&#19988;&#36890;&#24120;&#29992;&#20316;&#32534;&#30721;&#21161;&#25163;&#30340;LLMs&#65292;&#24182;&#35780;&#20272;&#20102;&#23427;&#20204;&#22312;&#28431;&#27934;&#26816;&#27979;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#31995;&#32479;&#22320;&#25628;&#32034;&#20102;&#25928;&#26524;&#26368;&#20339;&#30340;&#25552;&#31034;&#65292;&#32467;&#21512;&#20102;&#35832;&#22914;&#19978;&#19979;&#25991;&#23398;&#20064;&#21644;&#38142;&#24335;&#23398;&#20064;&#31561;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17218v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have demonstrated great potential for code generation and other software engineering tasks. Vulnerability detection is of crucial importance to maintaining the security, integrity, and trustworthiness of software systems. Precise vulnerability detection requires reasoning about the code, making it a good case study for exploring the limits of LLMs' reasoning capabilities. Although recent work has applied LLMs to vulnerability detection using generic prompting techniques, their full capabilities for this task and the types of errors they make when explaining identified vulnerabilities remain unclear.   In this paper, we surveyed eleven LLMs that are state-of-the-art in code generation and commonly used as coding assistants, and evaluated their capabilities for vulnerability detection. We systematically searched for the best-performing prompts, incorporating techniques such as in-context learning and chain-of
&lt;/p&gt;</description></item><item><title>Lemur&#25552;&#20986;&#20102;&#19968;&#31181;&#20808;&#36827;&#30340;&#26085;&#24535;&#35299;&#26512;&#26694;&#26550;&#65292;&#37319;&#29992;&#29109;&#25277;&#26679;&#21644;&#24605;&#32500;&#38142;&#21512;&#24182;&#65292;&#35299;&#20915;&#20102;&#26085;&#24535;&#35299;&#26512;&#20013;&#23384;&#22312;&#30340;&#20154;&#24037;&#35268;&#21017;&#20381;&#36182;&#21644;&#35821;&#20041;&#20449;&#24687;&#24573;&#30053;&#31561;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.18205</link><description>&lt;p&gt;
Lemur: &#20351;&#29992;&#29109;&#25277;&#26679;&#21644;&#24605;&#32500;&#38142;&#21512;&#24182;&#36827;&#34892;&#26085;&#24535;&#35299;&#26512;
&lt;/p&gt;
&lt;p&gt;
Lemur: Log Parsing with Entropy Sampling and Chain-of-Thought Merging
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18205
&lt;/p&gt;
&lt;p&gt;
Lemur&#25552;&#20986;&#20102;&#19968;&#31181;&#20808;&#36827;&#30340;&#26085;&#24535;&#35299;&#26512;&#26694;&#26550;&#65292;&#37319;&#29992;&#29109;&#25277;&#26679;&#21644;&#24605;&#32500;&#38142;&#21512;&#24182;&#65292;&#35299;&#20915;&#20102;&#26085;&#24535;&#35299;&#26512;&#20013;&#23384;&#22312;&#30340;&#20154;&#24037;&#35268;&#21017;&#20381;&#36182;&#21644;&#35821;&#20041;&#20449;&#24687;&#24573;&#30053;&#31561;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#36719;&#20214;&#31995;&#32479;&#20135;&#29983;&#30340;&#26085;&#24535;&#23545;&#30417;&#35270;&#31995;&#32479;&#34892;&#20026;&#33267;&#20851;&#37325;&#35201;&#12290;&#20808;&#36827;&#30340;&#26085;&#24535;&#20998;&#26512;&#26377;&#21161;&#20110;&#26816;&#27979;&#12289;&#25253;&#35686;&#21644;&#35786;&#26029;&#31995;&#32479;&#25925;&#38556;&#12290;&#26085;&#24535;&#35299;&#26512;&#26159;&#26085;&#24535;&#20998;&#26512;&#33258;&#21160;&#21270;&#30340;&#20851;&#38190;&#38454;&#27573;&#65292;&#23427;&#28041;&#21450;&#23558;&#21407;&#22987;&#26085;&#24535;&#28040;&#24687;&#36716;&#25442;&#20026;&#32467;&#26500;&#21270;&#27169;&#26495;&#12290;&#29616;&#26377;&#30340;&#26085;&#24535;&#35299;&#26512;&#22120;&#30001;&#20110;&#20381;&#36182;&#20110;&#20154;&#24037;&#21046;&#23450;&#30340;&#35268;&#21017;&#32780;&#26080;&#27861;&#35782;&#21035;&#27491;&#30830;&#30340;&#27169;&#26495;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#26041;&#27861;&#20391;&#37325;&#20110;&#32479;&#35745;&#29305;&#24449;&#65292;&#32780;&#24573;&#30053;&#20102;&#26085;&#24535;&#28040;&#24687;&#20013;&#30340;&#35821;&#20041;&#20449;&#24687;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20808;&#36827;&#30340;&#26085;&#24535;&#35299;&#26512;&#26694;&#26550;&#65292;&#37319;&#29992;&#29109;&#25277;&#26679;&#21644;&#24605;&#32500;&#38142;&#21512;&#24182;&#65288;Lemur&#65289;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#20026;&#20102;&#25670;&#33073;&#32321;&#29712;&#30340;&#25163;&#21160;&#35268;&#21017;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21463;&#20449;&#24687;&#29109;&#21551;&#21457;&#30340;&#26032;&#22411;&#25277;&#26679;&#26041;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#23545;&#20856;&#22411;&#26085;&#24535;&#36827;&#34892;&#32858;&#31867;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#22686;&#24378;&#26085;&#24535;&#27169;&#26495;&#30340;&#21512;&#24182;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#24605;&#32500;&#38142;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18205v1 Announce Type: cross  Abstract: Logs produced by extensive software systems are integral to monitoring system behaviors. Advanced log analysis facilitates the detection, alerting, and diagnosis of system faults. Log parsing, which entails transforming raw log messages into structured templates, constitutes a critical phase in the automation of log analytics. Existing log parsers fail to identify the correct templates due to reliance on human-made rules. Besides, These methods focus on statistical features while ignoring semantic information in log messages. To address these challenges, we introduce a cutting-edge \textbf{L}og parsing framework with \textbf{E}ntropy sampling and Chain-of-Thought \textbf{M}erging (Lemur). Specifically, to discard the tedious manual rules. We propose a novel sampling method inspired by information entropy, which efficiently clusters typical logs. Furthermore, to enhance the merging of log templates, we design a chain-of-thought method f
&lt;/p&gt;</description></item></channel></rss>