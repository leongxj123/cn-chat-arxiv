<rss version="2.0"><channel><title>Chat Arxiv cs.SE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SE</description><item><title>&#26412;&#35770;&#25991;&#24341;&#20837;&#20102;CodeAttack&#26694;&#26550;&#29992;&#20110;&#27979;&#35797;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23433;&#20840;&#27867;&#21270;&#65292;&#30740;&#31350;&#21457;&#29616;GPT-4&#12289;Claude-2&#21644;Llama-2&#31995;&#21015;&#31561;&#26368;&#26032;&#27169;&#22411;&#23384;&#22312;&#20195;&#30721;&#36755;&#20837;&#30340;&#23433;&#20840;&#28431;&#27934;&#12290;</title><link>https://arxiv.org/abs/2403.07865</link><description>&lt;p&gt;
&#36890;&#36807;&#20195;&#30721;&#25506;&#32034;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23433;&#20840;&#27867;&#21270;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;
Exploring Safety Generalization Challenges of Large Language Models via Code
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07865
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#24341;&#20837;&#20102;CodeAttack&#26694;&#26550;&#29992;&#20110;&#27979;&#35797;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23433;&#20840;&#27867;&#21270;&#65292;&#30740;&#31350;&#21457;&#29616;GPT-4&#12289;Claude-2&#21644;Llama-2&#31995;&#21015;&#31561;&#26368;&#26032;&#27169;&#22411;&#23384;&#22312;&#20195;&#30721;&#36755;&#20837;&#30340;&#23433;&#20840;&#28431;&#27934;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#24555;&#36895;&#21457;&#23637;&#24102;&#26469;&#20102;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#26041;&#38754;&#30340;&#26174;&#33879;&#33021;&#21147;&#65292;&#20294;&#20063;&#24341;&#21457;&#20102;&#20154;&#20204;&#23545;&#23427;&#20204;&#28508;&#22312;&#35823;&#29992;&#30340;&#25285;&#24551;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;CodeAttack&#65292;&#19968;&#20010;&#23558;&#33258;&#28982;&#35821;&#35328;&#36755;&#20837;&#36716;&#25442;&#20026;&#20195;&#30721;&#36755;&#20837;&#30340;&#26694;&#26550;&#65292;&#20026;&#27979;&#35797;LLMs&#30340;&#23433;&#20840;&#27867;&#21270;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#29615;&#22659;&#12290;&#25105;&#20204;&#23545;&#21253;&#25324;GPT-4&#12289;Claude-2&#21644;Llama-2&#31995;&#21015;&#22312;&#20869;&#30340;&#26368;&#26032;LLMs&#36827;&#34892;&#20102;&#20840;&#38754;&#30740;&#31350;&#65292;&#21457;&#29616;&#36825;&#20123;&#27169;&#22411;&#23545;&#20110;&#20195;&#30721;&#36755;&#20837;&#23384;&#22312;&#20849;&#21516;&#30340;&#23433;&#20840;&#28431;&#27934;&#65306;CodeAttack&#22312;&#36229;&#36807;80%&#30340;&#26102;&#38388;&#20869;&#22987;&#32456;&#32469;&#36807;&#25152;&#26377;&#27169;&#22411;&#30340;&#23433;&#20840;&#20445;&#25252;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07865v1 Announce Type: cross  Abstract: The rapid advancement of Large Language Models (LLMs) has brought about remarkable capabilities in natural language processing but also raised concerns about their potential misuse. While strategies like supervised fine-tuning and reinforcement learning from human feedback have enhanced their safety, these methods primarily focus on natural languages, which may not generalize to other domains. This paper introduces CodeAttack, a framework that transforms natural language inputs into code inputs, presenting a novel environment for testing the safety generalization of LLMs. Our comprehensive studies on state-of-the-art LLMs including GPT-4, Claude-2, and Llama-2 series reveal a common safety vulnerability of these models against code input: CodeAttack consistently bypasses the safety guardrails of all models more than 80\% of the time. Furthermore, we find that a larger distribution gap between CodeAttack and natural language leads to we
&lt;/p&gt;</description></item><item><title>AIOptimizer&#26159;&#19968;&#31181;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#36719;&#20214;&#24615;&#33021;&#20248;&#21270;&#24037;&#20855;&#21407;&#22411;&#65292;&#26088;&#22312;&#23454;&#29616;&#25104;&#26412;&#26368;&#23567;&#21270;&#12290;&#23427;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#39537;&#21160;&#30340;&#25512;&#33616;&#31995;&#32479;&#26469;&#25913;&#21892;&#36719;&#20214;&#31995;&#32479;&#30340;&#25928;&#29575;&#21644;&#21487;&#36127;&#25285;&#24615;&#65292;&#24182;&#31361;&#20986;&#20102;&#20934;&#30830;&#24615;&#12289;&#36866;&#24212;&#24615;&#12289;&#21487;&#25193;&#23637;&#24615;&#21644;&#29992;&#25143;&#21451;&#22909;&#24615;&#31561;&#35774;&#35745;&#22240;&#32032;&#12290;AIOptimizer&#36824;&#25552;&#20379;&#25925;&#38556;&#35782;&#21035;&#12289;&#25104;&#26412;&#20248;&#21270;&#24314;&#35758;&#12289;&#25928;&#29575;&#39044;&#27979;&#21644;&#21327;&#20316;&#31561;&#21151;&#33021;&#65292;&#24182;&#20351;&#29992;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#25512;&#33616;&#24341;&#25806;&#36827;&#34892;&#25104;&#26412;&#20248;&#21270;&#12290;</title><link>http://arxiv.org/abs/2307.07846</link><description>&lt;p&gt;
AIOptimizer &#8212;&#8212;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#36719;&#20214;&#24615;&#33021;&#20248;&#21270;&#21407;&#22411;&#65292;&#26088;&#22312;&#23454;&#29616;&#25104;&#26412;&#26368;&#23567;&#21270;
&lt;/p&gt;
&lt;p&gt;
AIOptimizer -- A reinforcement learning-based software performance optimisation prototype for cost minimisation. (arXiv:2307.07846v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07846
&lt;/p&gt;
&lt;p&gt;
AIOptimizer&#26159;&#19968;&#31181;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#36719;&#20214;&#24615;&#33021;&#20248;&#21270;&#24037;&#20855;&#21407;&#22411;&#65292;&#26088;&#22312;&#23454;&#29616;&#25104;&#26412;&#26368;&#23567;&#21270;&#12290;&#23427;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#39537;&#21160;&#30340;&#25512;&#33616;&#31995;&#32479;&#26469;&#25913;&#21892;&#36719;&#20214;&#31995;&#32479;&#30340;&#25928;&#29575;&#21644;&#21487;&#36127;&#25285;&#24615;&#65292;&#24182;&#31361;&#20986;&#20102;&#20934;&#30830;&#24615;&#12289;&#36866;&#24212;&#24615;&#12289;&#21487;&#25193;&#23637;&#24615;&#21644;&#29992;&#25143;&#21451;&#22909;&#24615;&#31561;&#35774;&#35745;&#22240;&#32032;&#12290;AIOptimizer&#36824;&#25552;&#20379;&#25925;&#38556;&#35782;&#21035;&#12289;&#25104;&#26412;&#20248;&#21270;&#24314;&#35758;&#12289;&#25928;&#29575;&#39044;&#27979;&#21644;&#21327;&#20316;&#31561;&#21151;&#33021;&#65292;&#24182;&#20351;&#29992;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#25512;&#33616;&#24341;&#25806;&#36827;&#34892;&#25104;&#26412;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25991;&#31456;&#20171;&#32461;&#20102;AIOptimizer&#65292;&#19968;&#20010;&#22522;&#20110;&#25104;&#26412;&#38477;&#20302;&#30340;&#36719;&#20214;&#24615;&#33021;&#20248;&#21270;&#24037;&#20855;&#30340;&#21407;&#22411;&#12290;AIOptimizer&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#39537;&#21160;&#30340;&#25512;&#33616;&#31995;&#32479;&#26469;&#25913;&#21892;&#36719;&#20214;&#31995;&#32479;&#30340;&#25928;&#29575;&#21644;&#21487;&#36127;&#25285;&#24615;&#12290;&#26412;&#25991;&#24378;&#35843;&#20102;AIOptimizer&#30340;&#35774;&#35745;&#22240;&#32032;&#65292;&#22914;&#20934;&#30830;&#24615;&#12289;&#36866;&#24212;&#24615;&#12289;&#21487;&#25193;&#23637;&#24615;&#21644;&#29992;&#25143;&#21451;&#22909;&#24615;&#12290;&#20026;&#20102;&#25552;&#20379;&#26377;&#25928;&#30340;&#29992;&#25143;&#20013;&#24515;&#30340;&#24615;&#33021;&#20248;&#21270;&#35299;&#20915;&#26041;&#26696;&#65292;&#23427;&#24378;&#35843;&#20102;&#27169;&#22359;&#21270;&#35774;&#35745;&#12289;&#25968;&#25454;&#25910;&#38598;&#25216;&#26415;&#12289;&#25345;&#32493;&#23398;&#20064;&#21644;&#24377;&#24615;&#38598;&#25104;&#30340;&#20351;&#29992;&#12290;&#26412;&#25991;&#36824;&#35843;&#26597;&#20102;AIOptimizer&#30340;&#29305;&#24615;&#65292;&#22914;&#25925;&#38556;&#35782;&#21035;&#12289;&#25104;&#26412;&#20248;&#21270;&#24314;&#35758;&#12289;&#25928;&#29575;&#39044;&#27979;&#21644;&#21327;&#20316;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#36824;&#25506;&#35752;&#20102;&#20960;&#20010;&#36719;&#20214;&#24320;&#21457;&#29983;&#21629;&#21608;&#26399;&#27169;&#22411;&#65292;&#24182;&#20171;&#32461;&#20102;AIOptimizer&#20351;&#29992;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#25512;&#33616;&#24341;&#25806;&#36827;&#34892;&#25104;&#26412;&#20248;&#21270;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#31361;&#20986;AIOptimizer&#20316;&#20026;&#19968;&#31181;&#21033;&#29992;&#20808;&#36827;&#25216;&#26415;&#36827;&#34892;&#25104;&#26412;&#20248;&#21270;&#30340;&#21407;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
This research article introduces AIOptimizer, a prototype for a software performance optimisation tool based on cost reduction. AIOptimizer uses a recommendation system driven by reinforcement learning to improve software system efficiency and affordability. The paper highlights AIOptimizer's design factors, such as accuracy, adaptability, scalability, and user-friendliness. To provide effective and user-centric performance optimisation solutions, it emphasises the use of a modular design, data gathering techniques, continuous learning, and resilient integration. The article also investigates AIOptimizer features such as fault identification, cost optimisation recommendations, efficiency prediction, and cooperation. Furthermore, it explores several software development life cycle models and introduces AIOptimizer uses a reinforcement learning-based recommendation engine for cost optimisation. The purpose of this research study is to highlight AIOptimizer as a prototype that uses advanc
&lt;/p&gt;</description></item></channel></rss>