<rss version="2.0"><channel><title>Chat Arxiv cs.SE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SE</description><item><title>DevBench&#26159;&#19968;&#20010;&#32508;&#21512;&#22522;&#20934;&#27979;&#35797;&#65292;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#36719;&#20214;&#24320;&#21457;&#29983;&#21629;&#21608;&#26399;&#21508;&#20010;&#38454;&#27573;&#30340;&#34920;&#29616;&#65292;&#24182;&#21457;&#29616;&#29616;&#26377;&#30340;&#27169;&#22411;&#22312;&#20854;&#20013;&#23384;&#22312;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2403.08604</link><description>&lt;p&gt;
DevBench&#65306;&#36719;&#20214;&#24320;&#21457;&#30340;&#32508;&#21512;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
DevBench: A Comprehensive Benchmark for Software Development
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08604
&lt;/p&gt;
&lt;p&gt;
DevBench&#26159;&#19968;&#20010;&#32508;&#21512;&#22522;&#20934;&#27979;&#35797;&#65292;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#36719;&#20214;&#24320;&#21457;&#29983;&#21629;&#21608;&#26399;&#21508;&#20010;&#38454;&#27573;&#30340;&#34920;&#29616;&#65292;&#24182;&#21457;&#29616;&#29616;&#26377;&#30340;&#27169;&#22411;&#22312;&#20854;&#20013;&#23384;&#22312;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08604v1&#23459;&#24067;&#31867;&#22411;&#65306;&#26032;&#30340;&#25688;&#35201;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#26368;&#26032;&#36827;&#23637;&#26174;&#33879;&#25552;&#21319;&#20102;&#23427;&#20204;&#30340;&#32534;&#30721;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#22522;&#20934;&#27979;&#35797;&#20027;&#35201;&#20851;&#27880;&#32534;&#31243;&#30340;&#31616;&#21270;&#25110;&#23396;&#31435;&#26041;&#38754;&#65292;&#22914;&#21333;&#25991;&#20214;&#20195;&#30721;&#29983;&#25104;&#25110;&#23384;&#20648;&#24211;&#38382;&#39064;&#35843;&#35797;&#65292;&#26410;&#33021;&#20840;&#38754;&#34913;&#37327;&#30001;&#30495;&#23454;&#19990;&#30028;&#32534;&#31243;&#27963;&#21160;&#25552;&#20986;&#30340;&#21508;&#31181;&#25361;&#25112;&#30340;&#20840;&#35889;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;DevBench&#65292;&#19968;&#20010;&#32508;&#21512;&#22522;&#20934;&#27979;&#35797;&#65292;&#35780;&#20272;LLMs&#22312;&#36719;&#20214;&#24320;&#21457;&#29983;&#21629;&#21608;&#26399;&#30340;&#21508;&#20010;&#38454;&#27573;&#65292;&#21253;&#25324;&#36719;&#20214;&#35774;&#35745;&#12289;&#29615;&#22659;&#35774;&#32622;&#12289;&#23454;&#29616;&#12289;&#39564;&#25910;&#27979;&#35797;&#21644;&#21333;&#20803;&#27979;&#35797;&#12290;DevBench&#20855;&#26377;&#21508;&#31181;&#32534;&#31243;&#35821;&#35328;&#21644;&#39046;&#22495;&#65292;&#39640;&#36136;&#37327;&#25968;&#25454;&#25910;&#38598;&#65292;&#24182;&#38024;&#23545;&#27599;&#20010;&#20219;&#21153;&#31934;&#24515;&#35774;&#35745;&#21644;&#39564;&#35777;&#30340;&#25351;&#26631;&#12290;&#23454;&#35777;&#30740;&#31350;&#34920;&#26126;&#65292;&#24403;&#21069;&#30340;LLMs&#65292;&#21253;&#25324;GPT-4-Turbo&#65292;&#26080;&#27861;&#35299;&#20915;DevBench&#25552;&#20986;&#30340;&#25361;&#25112;&#12290;&#20998;&#26512;&#34920;&#26126;&#65292;&#27169;&#22411;&#38590;&#20197;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08604v1 Announce Type: new  Abstract: Recent advancements in large language models (LLMs) have significantly enhanced their coding capabilities. However, existing benchmarks predominantly focused on simplified or isolated aspects of programming, such as single-file code generation or repository issue debugging, falling short of measuring the full spectrum of challenges raised by real-world programming activities. To this end, we propose DevBench, a comprehensive benchmark that evaluates LLMs across various stages of the software development lifecycle, including software design, environment setup, implementation, acceptance testing, and unit testing. DevBench features a wide range of programming languages and domains, high-quality data collection, and carefully designed and verified metrics for each task. Empirical studies show that current LLMs, including GPT-4-Turbo, fail to solve the challenges presented within DevBench. Analyses reveal that models struggle with understand
&lt;/p&gt;</description></item><item><title>&#39640;&#25928;&#34920;&#31034;&#21644;&#24494;&#35843;&#36866;&#37197;&#22120;&#30456;&#32467;&#21512;&#30340;&#26032;&#22411;&#31243;&#24207;&#20462;&#22797;&#26041;&#27861;RepairLLaMA&#21487;&#20026;&#35821;&#35328;&#27169;&#22411;&#20462;&#22797;&#38169;&#35823;&#20135;&#29983;&#39640;&#25928;&#30340;&#36866;&#37197;&#22120;&#12290;</title><link>https://arxiv.org/abs/2312.15698</link><description>&lt;p&gt;
RepairLLaMA&#65306;&#39640;&#25928;&#34920;&#31034;&#21644;&#24494;&#35843;&#36866;&#37197;&#22120;&#29992;&#20110;&#31243;&#24207;&#20462;&#22797;
&lt;/p&gt;
&lt;p&gt;
RepairLLaMA: Efficient Representations and Fine-Tuned Adapters for Program Repair
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.15698
&lt;/p&gt;
&lt;p&gt;
&#39640;&#25928;&#34920;&#31034;&#21644;&#24494;&#35843;&#36866;&#37197;&#22120;&#30456;&#32467;&#21512;&#30340;&#26032;&#22411;&#31243;&#24207;&#20462;&#22797;&#26041;&#27861;RepairLLaMA&#21487;&#20026;&#35821;&#35328;&#27169;&#22411;&#20462;&#22797;&#38169;&#35823;&#20135;&#29983;&#39640;&#25928;&#30340;&#36866;&#37197;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#31243;&#24207;&#20462;&#22797;&#65288;APR&#65289;&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20986;&#29616;&#24050;&#26377;&#20102;&#26174;&#33879;&#21457;&#23637;&#12290;&#23545;&#20110;&#31243;&#24207;&#20462;&#22797;&#36827;&#34892;LLMs&#30340;&#24494;&#35843;&#26159;&#26368;&#36817;&#30740;&#31350;&#30340;&#19968;&#20010;&#26032;&#39046;&#22495;&#65292;&#26377;&#35768;&#22810;&#26410;&#34987;&#25506;&#32034;&#30340;&#32500;&#24230;&#12290;&#29616;&#26377;&#24037;&#20316;&#22823;&#22810;&#20351;&#29992;&#31616;&#21333;&#30340;&#20195;&#30721;&#34920;&#31034;&#23545;LLMs&#36827;&#34892;&#24494;&#35843;&#65292;&#24182;&#22312;&#33021;&#22815;&#24494;&#35843;&#26356;&#22823;&#22411;LLMs&#30340;&#33021;&#21147;&#26041;&#38754;&#23384;&#22312;&#26681;&#26412;&#24615;&#23616;&#38480;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;RepairLLaMA&#65292;&#19968;&#20010;&#32467;&#21512;&#20102;1&#65289;&#29992;&#20110;APR&#30340;&#20195;&#30721;&#34920;&#31034;&#21644;2&#65289;&#26368;&#20808;&#36827;&#30340;&#21442;&#25968;&#39640;&#25928;&#30340;LLM&#24494;&#35843;&#25216;&#26415;LoRA&#30340;&#26032;&#22411;&#31243;&#24207;&#20462;&#22797;&#26041;&#27861;&#12290;&#36825;&#20351;&#24471;RepairLLaMA&#20135;&#29983;&#20102;&#19968;&#20010;&#39640;&#25928;&#30340;&#8220;&#31243;&#24207;&#20462;&#22797;&#36866;&#37197;&#22120;&#8221;&#65292;&#29992;&#20110;&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#20462;&#22797;&#38169;&#35823;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#20004;&#20010;&#27010;&#24565;&#30340;&#26377;&#25928;&#24615;&#12290;&#39318;&#20808;&#65292;&#20351;&#29992;&#20855;&#26377;&#31243;&#24207;&#20462;&#22797;&#29305;&#23450;&#20195;&#30721;&#34920;&#31034;&#30340;&#24494;&#35843;&#36866;&#37197;&#22120;&#20351;&#27169;&#22411;&#33021;&#22815;&#20351;&#29992;&#26377;&#24847;&#20041;&#30340;&#20462;&#22797;&#20449;&#21495;&#12290;&#20854;&#27425;&#65292;&#21442;&#25968;&#39640;&#25928;&#30340;&#24494;&#35843;&#26377;&#21161;&#20110;&#24494;&#35843;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.15698v2 Announce Type: replace-cross  Abstract: Automated Program Repair (APR) has evolved significantly with the advent of Large Language Models (LLMs). Fine-tuning LLMs for program repair is a recent avenue of research, with many dimensions which have not been explored. Existing work mostly fine-tunes LLMs with naive code representations and is fundamentally limited in its ability to fine-tune larger LLMs. To address this problem, we propose RepairLLaMA, a novel program repair approach that combines 1) code representations for APR and 2) the state-of-the-art parameter-efficient LLM fine-tuning technique called LoRA. This results in RepairLLaMA producing a highly effective `program repair adapter' for fixing bugs with language models. Our experiments demonstrate the validity of both concepts. First, fine-tuning adapters with program repair specific code representations enables the model to use meaningful repair signals. Second, parameter-efficient fine-tuning helps fine-tun
&lt;/p&gt;</description></item></channel></rss>