<rss version="2.0"><channel><title>Chat Arxiv cs.SE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SE</description><item><title>&#35813;&#30740;&#31350;&#24341;&#20837;&#20102;&#22522;&#20110;LLM&#30340;&#20195;&#30721;&#29983;&#25104;&#26694;&#26550;LCG&#65292;&#36890;&#36807;&#27169;&#25311;&#21508;&#31181;&#36719;&#20214;&#36807;&#31243;&#27169;&#22411;&#20197;&#21450;&#21033;&#29992;&#21327;&#20316;&#21644;&#25216;&#26415;&#25552;&#39640;&#20195;&#30721;&#36136;&#37327;&#12290;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126;&#20854;&#22312;&#20195;&#30721;&#29983;&#25104;&#22522;&#20934;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.15852</link><description>&lt;p&gt;
&#24403;&#22522;&#20110;LLM&#30340;&#20195;&#30721;&#29983;&#25104;&#36935;&#19978;&#36719;&#20214;&#24320;&#21457;&#27969;&#31243;
&lt;/p&gt;
&lt;p&gt;
When LLM-based Code Generation Meets the Software Development Process
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15852
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#24341;&#20837;&#20102;&#22522;&#20110;LLM&#30340;&#20195;&#30721;&#29983;&#25104;&#26694;&#26550;LCG&#65292;&#36890;&#36807;&#27169;&#25311;&#21508;&#31181;&#36719;&#20214;&#36807;&#31243;&#27169;&#22411;&#20197;&#21450;&#21033;&#29992;&#21327;&#20316;&#21644;&#25216;&#26415;&#25552;&#39640;&#20195;&#30721;&#36136;&#37327;&#12290;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126;&#20854;&#22312;&#20195;&#30721;&#29983;&#25104;&#22522;&#20934;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36719;&#20214;&#36807;&#31243;&#27169;&#22411;&#22312;&#20419;&#36827;&#36719;&#20214;&#22242;&#38431;&#20869;&#21327;&#20316;&#19982;&#27807;&#36890;&#65292;&#20351;&#20854;&#33021;&#22815;&#26377;&#25928;&#24212;&#23545;&#22797;&#26434;&#30340;&#24320;&#21457;&#20219;&#21153;&#26041;&#38754;&#25285;&#24403;&#30528;&#20851;&#38190;&#35282;&#33394;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;LCG&#65292;&#36825;&#26159;&#19968;&#20010;&#21463;&#21040;&#25104;&#29087;&#36719;&#20214;&#24037;&#31243;&#23454;&#36341;&#21551;&#21457;&#30340;&#20195;&#30721;&#29983;&#25104;&#26694;&#26550;&#12290;LCG&#21033;&#29992;&#22810;&#20010;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#20195;&#29702;&#26469;&#27169;&#25311;&#21508;&#31181;&#36719;&#20214;&#36807;&#31243;&#27169;&#22411;&#65292;&#21363;LCGWaterfall&#12289;LCGTDD&#21644;LCGScrum&#12290;&#27599;&#20010;&#27169;&#22411;&#20026;LLM&#20195;&#29702;&#20998;&#37197;&#29305;&#23450;&#35282;&#33394;&#65292;&#22914;&#38656;&#27714;&#24037;&#31243;&#24072;&#12289;&#26550;&#26500;&#24072;&#12289;&#24320;&#21457;&#20154;&#21592;&#12289;&#27979;&#35797;&#20154;&#21592;&#21644;Scrum Master&#65292;&#21453;&#26144;&#20102;&#20856;&#22411;&#30340;&#24320;&#21457;&#27963;&#21160;&#21644;&#27807;&#36890;&#27169;&#24335;&#12290;&#36890;&#36807;&#21033;&#29992;&#24605;&#32500;&#38142;&#21644;&#25552;&#31034;&#32452;&#21512;&#25216;&#26415;&#36827;&#34892;&#21327;&#20316;&#65292;&#20195;&#29702;&#19981;&#26029;&#23436;&#21892;&#33258;&#36523;&#20197;&#25552;&#39640;&#20195;&#30721;&#36136;&#37327;&#12290;&#22312;GPT3.5&#20316;&#20026;&#22522;&#30784;LLM&#21644;&#22522;&#20934;(GPT)&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;LCG&#22312;&#22235;&#20010;&#20195;&#30721;&#29983;&#25104;&#22522;&#20934;&#27979;&#35797;&#19978;&#30340;&#34920;&#29616;&#65306;HumanEval&#12289;HumanEval-ET&#12289;MBPP&#21644;MBPP-ET&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15852v1 Announce Type: cross  Abstract: Software process models play a pivotal role in fostering collaboration and communication within software teams, enabling them to tackle intricate development tasks effectively. This paper introduces LCG, a code generation framework inspired by established software engineering practices. LCG leverages multiple Large Language Model (LLM) agents to emulate various software process models, namely LCGWaterfall, LCGTDD, and LCGScrum. Each model assigns LLM agents specific roles such as requirement engineer, architect, developer, tester, and scrum master, mirroring typical development activities and communication patterns. Through collaborative efforts utilizing chain-of-thought and prompt composition techniques, the agents continuously refine themselves to enhance code quality. Utilizing GPT3.5 as the underlying LLM and baseline (GPT), we evaluate LCG across four code generation benchmarks: HumanEval, HumanEval-ET, MBPP, and MBPP-ET. Results
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20851;&#27880;&#22914;&#20309;&#22312;&#35757;&#32451;&#20195;&#30721;&#30340;&#35821;&#35328;&#27169;&#22411;&#20013;&#26816;&#27979;&#20195;&#30721;&#21253;&#21547;&#65292;&#20197;&#35299;&#20915;&#20351;&#29992;&#36825;&#20123;&#27169;&#22411;&#36827;&#34892;&#20195;&#30721;&#23457;&#35745;&#26102;&#30340;&#29256;&#26435;&#20405;&#26435;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.09299</link><description>&lt;p&gt;
&#26410;&#32463;&#26412;&#20154;&#21516;&#24847;&#30340;&#35757;&#32451;&#65306;&#22312;&#35757;&#32451;&#20195;&#30721;&#30340;&#35821;&#35328;&#27169;&#22411;&#20013;&#26816;&#27979;&#20195;&#30721;&#21253;&#21547;
&lt;/p&gt;
&lt;p&gt;
Trained Without My Consent: Detecting Code Inclusion In Language Models Trained on Code
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09299
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20851;&#27880;&#22914;&#20309;&#22312;&#35757;&#32451;&#20195;&#30721;&#30340;&#35821;&#35328;&#27169;&#22411;&#20013;&#26816;&#27979;&#20195;&#30721;&#21253;&#21547;&#65292;&#20197;&#35299;&#20915;&#20351;&#29992;&#36825;&#20123;&#27169;&#22411;&#36827;&#34892;&#20195;&#30721;&#23457;&#35745;&#26102;&#30340;&#29256;&#26435;&#20405;&#26435;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20195;&#30721;&#23457;&#35745;&#36890;&#36807;&#39564;&#35777;&#24320;&#21457;&#30340;&#20195;&#30721;&#26159;&#21542;&#31526;&#21512;&#26631;&#20934;&#12289;&#27861;&#35268;&#21644;&#29256;&#26435;&#20445;&#25252;&#65292;&#30830;&#20445;&#20854;&#19981;&#21253;&#21547;&#26469;&#33258;&#21463;&#20445;&#25252;&#26469;&#28304;&#30340;&#20195;&#30721;&#12290;&#22312;&#36719;&#20214;&#24320;&#21457;&#36807;&#31243;&#20013;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#20316;&#20026;&#32534;&#30721;&#21161;&#25163;&#30340;&#20986;&#29616;&#32473;&#20195;&#30721;&#23457;&#35745;&#24102;&#26469;&#20102;&#26032;&#30340;&#25361;&#25112;&#12290;&#35757;&#32451;&#36825;&#20123;&#27169;&#22411;&#30340;&#25968;&#25454;&#38598;&#20027;&#35201;&#26469;&#33258;&#20844;&#24320;&#21487;&#29992;&#30340;&#26469;&#28304;&#12290;&#36825;&#24341;&#21457;&#20102;&#30693;&#35782;&#20135;&#26435;&#20405;&#26435;&#38382;&#39064;&#65292;&#22240;&#20026;&#24320;&#21457;&#32773;&#30340;&#20195;&#30721;&#24050;&#21253;&#21547;&#22312;&#25968;&#25454;&#38598;&#20013;&#12290;&#22240;&#27492;&#65292;&#20351;&#29992;LLMs&#24320;&#21457;&#30340;&#20195;&#30721;&#23457;&#35745;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;&#25105;&#20204;&#26080;&#27861;&#20934;&#30830;&#30830;&#23450;&#24320;&#21457;&#36807;&#31243;&#20013;&#20351;&#29992;&#30340;LLM&#26159;&#21542;&#24050;&#32463;&#22312;&#29305;&#23450;&#30340;&#21463;&#29256;&#26435;&#20445;&#25252;&#30340;&#20195;&#30721;&#19978;&#36827;&#34892;&#20102;&#35757;&#32451;&#65292;&#22240;&#20026;&#25105;&#20204;&#26080;&#27861;&#33719;&#24471;&#36825;&#20123;&#27169;&#22411;&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#12290;&#37492;&#20110;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#20445;&#23494;&#24615;&#65292;&#20256;&#32479;&#30340;&#20195;&#30721;&#20811;&#38534;&#26816;&#27979;&#31561;&#26041;&#27861;&#26080;&#27861;&#30830;&#20445;&#29256;&#26435;&#20405;&#26435;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09299v1 Announce Type: cross Abstract: Code auditing ensures that the developed code adheres to standards, regulations, and copyright protection by verifying that it does not contain code from protected sources. The recent advent of Large Language Models (LLMs) as coding assistants in the software development process poses new challenges for code auditing. The dataset for training these models is mainly collected from publicly available sources. This raises the issue of intellectual property infringement as developers' codes are already included in the dataset. Therefore, auditing code developed using LLMs is challenging, as it is difficult to reliably assert if an LLM used during development has been trained on specific copyrighted codes, given that we do not have access to the training datasets of these models. Given the non-disclosure of the training datasets, traditional approaches such as code clone detection are insufficient for asserting copyright infringement. To add
&lt;/p&gt;</description></item></channel></rss>