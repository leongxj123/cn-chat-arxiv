<rss version="2.0"><channel><title>Chat Arxiv cs.SE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SE</description><item><title>&#31070;&#32463;&#20195;&#30721;&#26234;&#33021;&#39046;&#22495;&#30340;&#35843;&#26597;&#31995;&#32479;&#22238;&#39038;&#20102;50&#22810;&#31181;&#20195;&#34920;&#24615;&#27169;&#22411;&#21644;&#36229;&#36807;680&#39033;&#30456;&#20851;&#20316;&#21697;&#65292;&#31361;&#20986;&#20102;&#19981;&#21516;&#30740;&#31350;&#38454;&#27573;&#30340;&#33539;&#24335;&#21644;&#25216;&#26415;&#36716;&#21464;&#12290;</title><link>https://arxiv.org/abs/2403.14734</link><description>&lt;p&gt;
&#19968;&#39033;&#31070;&#32463;&#20195;&#30721;&#26234;&#33021;&#30340;&#35843;&#26597;&#65306;&#33539;&#24335;&#12289;&#36827;&#23637;&#19982;&#26410;&#26469;
&lt;/p&gt;
&lt;p&gt;
A Survey of Neural Code Intelligence: Paradigms, Advances and Beyond
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14734
&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#20195;&#30721;&#26234;&#33021;&#39046;&#22495;&#30340;&#35843;&#26597;&#31995;&#32479;&#22238;&#39038;&#20102;50&#22810;&#31181;&#20195;&#34920;&#24615;&#27169;&#22411;&#21644;&#36229;&#36807;680&#39033;&#30456;&#20851;&#20316;&#21697;&#65292;&#31361;&#20986;&#20102;&#19981;&#21516;&#30740;&#31350;&#38454;&#27573;&#30340;&#33539;&#24335;&#21644;&#25216;&#26415;&#36716;&#21464;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14734v1 &#20844;&#21578;&#31867;&#22411;: &#36328;&#39046;&#22495; &#25688;&#35201;: &#31070;&#32463;&#20195;&#30721;&#26234;&#33021;--&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#29702;&#35299;&#12289;&#29983;&#25104;&#21644;&#20248;&#21270;&#20195;&#30721;--&#22312;&#25972;&#20010;&#31038;&#20250;&#19978;&#20855;&#26377;&#24040;&#22823;&#30340;&#28508;&#21147;&#65292;&#21487;&#20135;&#29983;&#28145;&#36828;&#24433;&#21709;&#12290;&#20316;&#20026;&#33258;&#28982;&#35821;&#35328;&#21644;&#32534;&#31243;&#35821;&#35328;&#20043;&#38388;&#30340;&#26725;&#26753;&#65292;&#36825;&#19968;&#39046;&#22495;&#22312;&#36807;&#21435;&#20960;&#24180;&#24341;&#36215;&#20102;&#20004;&#20010;&#30740;&#31350;&#31038;&#21306;&#30740;&#31350;&#20154;&#21592;&#30340;&#26497;&#22823;&#20851;&#27880;&#12290;&#26412;&#35843;&#26597;&#31995;&#32479;&#22320;&#21644;&#25353;&#26102;&#38388;&#39034;&#24207;&#22238;&#39038;&#20102;&#20195;&#30721;&#26234;&#33021;&#26041;&#38754;&#30340;&#36827;&#23637;&#65292;&#21253;&#25324;50&#22810;&#31181;&#20195;&#34920;&#24615;&#27169;&#22411;&#21450;&#20854;&#21464;&#20307;&#12289;20&#22810;&#31181;&#20219;&#21153;&#31867;&#21035;&#20197;&#21450;&#36229;&#36807;680&#39033;&#30456;&#20851;&#20316;&#21697;&#12290;&#25105;&#20204;&#36981;&#24490;&#21382;&#21490;&#36827;&#23637;&#65292;&#36319;&#36394;&#19981;&#21516;&#30740;&#31350;&#38454;&#27573;&#30340;&#33539;&#24335;&#36716;&#21464;&#65288;&#20363;&#22914;&#65292;&#20174;&#20351;&#29992;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#23545;&#20195;&#30721;&#24314;&#27169;&#21040;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26102;&#20195;&#65289;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#37325;&#28857;&#20171;&#32461;&#20102;&#19981;&#21516;&#38454;&#27573;&#28085;&#30422;&#30340;&#27169;&#22411;&#12289;&#20219;&#21153;&#21644;&#35780;&#20272;&#30340;&#20027;&#35201;&#25216;&#26415;&#36716;&#21464;&#12290;&#23545;&#20110;&#24212;&#29992;&#65292;&#25105;&#20204;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14734v1 Announce Type: cross  Abstract: Neural Code Intelligence -- leveraging deep learning to understand, generate, and optimize code -- holds immense potential for transformative impacts on the whole society. Bridging the gap between Natural Language and Programming Language, this domain has drawn significant attention from researchers in both research communities over the past few years. This survey presents a systematic and chronological review of the advancements in code intelligence, encompassing over 50 representative models and their variants, more than 20 categories of tasks, and an extensive coverage of over 680 related works. We follow the historical progression to trace the paradigm shifts across different research phases (e.g., from modeling code with recurrent neural networks to the era of Large Language Models). Concurrently, we highlight the major technical transitions in models, tasks, and evaluations spanning through different stages. For applications, we 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797;Turbulence&#26469;&#31995;&#32479;&#35780;&#20272;&#38024;&#23545;&#20195;&#30721;&#29983;&#25104;&#30340;&#25351;&#20196;&#35843;&#25972;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#27491;&#30830;&#24615;&#21644;&#40065;&#26834;&#24615;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#26500;&#24314;&#19968;&#32452;&#38382;&#39064;&#27169;&#26495;&#65292;&#21487;&#20197;&#35780;&#20272;LLMs&#22312;&#35299;&#20915;&#30456;&#20284;&#32534;&#31243;&#38382;&#39064;&#26102;&#30340;&#20934;&#30830;&#24615;&#65292;&#24182;&#21457;&#29616;&#20854;&#20195;&#30721;&#29983;&#25104;&#33021;&#21147;&#30340;&#32570;&#38519;&#21644;&#24322;&#24120;&#24773;&#20917;&#12290;&#36825;&#39033;&#30740;&#31350;&#22312;&#20116;&#20010;LLMs&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#12290;</title><link>http://arxiv.org/abs/2312.14856</link><description>&lt;p&gt;
&#31995;&#32479;&#21270;&#21644;&#33258;&#21160;&#21270;&#27979;&#35797;&#38024;&#23545;&#20195;&#30721;&#30340;&#25351;&#20196;&#35843;&#25972;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#28065;&#27969;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Turbulence: Systematically and Automatically Testing Instruction-Tuned Large Language Models for Code. (arXiv:2312.14856v2 [cs.SE] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.14856
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797;Turbulence&#26469;&#31995;&#32479;&#35780;&#20272;&#38024;&#23545;&#20195;&#30721;&#29983;&#25104;&#30340;&#25351;&#20196;&#35843;&#25972;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#27491;&#30830;&#24615;&#21644;&#40065;&#26834;&#24615;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#26500;&#24314;&#19968;&#32452;&#38382;&#39064;&#27169;&#26495;&#65292;&#21487;&#20197;&#35780;&#20272;LLMs&#22312;&#35299;&#20915;&#30456;&#20284;&#32534;&#31243;&#38382;&#39064;&#26102;&#30340;&#20934;&#30830;&#24615;&#65292;&#24182;&#21457;&#29616;&#20854;&#20195;&#30721;&#29983;&#25104;&#33021;&#21147;&#30340;&#32570;&#38519;&#21644;&#24322;&#24120;&#24773;&#20917;&#12290;&#36825;&#39033;&#30740;&#31350;&#22312;&#20116;&#20010;LLMs&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797;Turbulence&#65292;&#31995;&#32479;&#35780;&#20272;&#38024;&#23545;&#20195;&#30721;&#29983;&#25104;&#30340;&#25351;&#20196;&#35843;&#25972;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#27491;&#30830;&#24615;&#21644;&#40065;&#26834;&#24615;&#30340;&#26041;&#27861;&#12290;Turbulence&#21253;&#21547;&#19968;&#32452;&#22823;&#37327;&#30340;&#33258;&#28982;&#35821;&#35328;&#8220;&#38382;&#39064;&#27169;&#26495;&#8221;&#65292;&#27599;&#20010;&#27169;&#26495;&#37117;&#26159;&#19968;&#20010;&#32534;&#31243;&#38382;&#39064;&#65292;&#21442;&#25968;&#21270;&#20351;&#24471;&#21487;&#20197;&#20197;&#22810;&#31181;&#19981;&#21516;&#24418;&#24335;&#25552;&#38382;&#12290;&#27599;&#20010;&#38382;&#39064;&#27169;&#26495;&#37117;&#26377;&#19968;&#20010;&#30456;&#20851;&#30340;&#8220;&#27979;&#35797;&#39044;&#27979;&#22120;&#8221;&#65292;&#29992;&#26469;&#21028;&#26029;LLM&#36820;&#22238;&#30340;&#20195;&#30721;&#35299;&#20915;&#26041;&#26696;&#26159;&#21542;&#27491;&#30830;&#12290;&#22240;&#27492;&#65292;&#36890;&#36807;&#19968;&#20010;&#38382;&#39064;&#27169;&#26495;&#65292;&#21487;&#20197;&#21521;LLM&#25552;&#38382;&#19968;&#20010;&#38750;&#24120;&#30456;&#20284;&#30340;&#32534;&#31243;&#38382;&#39064;&#8220;&#37051;&#22495;&#8221;&#65292;&#24182;&#35780;&#20272;&#27599;&#20010;&#38382;&#39064;&#36820;&#22238;&#30340;&#32467;&#26524;&#30340;&#27491;&#30830;&#24615;&#12290;&#36825;&#20801;&#35768;&#35782;&#21035;LLM&#20195;&#30721;&#29983;&#25104;&#33021;&#21147;&#30340;&#24046;&#36317;&#65292;&#21253;&#25324;LLM&#22312;&#37051;&#22495;&#20013;&#35299;&#20915;&#8220;&#20960;&#20046;&#25152;&#26377;&#8221;&#38382;&#39064;&#20294;&#23545;&#29305;&#23450;&#21442;&#25968;&#23454;&#20363;&#21270;&#22833;&#36133;&#30340;&#8220;&#24322;&#24120;&#8221;&#12290;&#25105;&#20204;&#38024;&#23545;OpenAI&#12289;Co&#31561;&#20116;&#20010;LLM&#36827;&#34892;&#20102;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a method for systematically evaluating the correctness and robustness of instruction-tuned large language models (LLMs) for code generation via a new benchmark, Turbulence. Turbulence consists of a large set of natural language $\textit{question templates}$, each of which is a programming problem, parameterised so that it can be asked in many different forms. Each question template has an associated $\textit{test oracle}$ that judges whether a code solution returned by an LLM is correct. Thus, from a single question template, it is possible to ask an LLM a $\textit{neighbourhood}$ of very similar programming questions, and assess the correctness of the result returned for each question. This allows gaps in an LLM's code generation abilities to be identified, including $\textit{anomalies}$ where the LLM correctly solves $\textit{almost all}$ questions in a neighbourhood but fails for particular parameter instantiations. We present experiments against five LLMs from OpenAI, Co
&lt;/p&gt;</description></item></channel></rss>