<rss version="2.0"><channel><title>Chat Arxiv cs.SE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SE</description><item><title>Ansible Lightspeed&#26159;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26381;&#21153;&#65292;&#19987;&#27880;&#20110;&#23558;&#33258;&#28982;&#35821;&#35328;&#36716;&#25442;&#20026;Ansible&#20195;&#30721;&#65292;&#20026;IT&#33258;&#21160;&#21270;&#39046;&#22495;&#24102;&#26469;&#20102;&#21019;&#26032;&#12290;</title><link>https://arxiv.org/abs/2402.17442</link><description>&lt;p&gt;
Ansible Lightspeed: &#19968;&#31181;&#29992;&#20110;IT&#33258;&#21160;&#21270;&#30340;&#20195;&#30721;&#29983;&#25104;&#26381;&#21153;
&lt;/p&gt;
&lt;p&gt;
Ansible Lightspeed: A Code Generation Service for IT Automation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17442
&lt;/p&gt;
&lt;p&gt;
Ansible Lightspeed&#26159;&#19968;&#31181;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26381;&#21153;&#65292;&#19987;&#27880;&#20110;&#23558;&#33258;&#28982;&#35821;&#35328;&#36716;&#25442;&#20026;Ansible&#20195;&#30721;&#65292;&#20026;IT&#33258;&#21160;&#21270;&#39046;&#22495;&#24102;&#26469;&#20102;&#21019;&#26032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#38382;&#19990;&#20351;&#24471;&#21019;&#24314;&#21487;&#25552;&#39640;&#24320;&#21457;&#32773;&#29983;&#20135;&#21147;&#30340;&#24037;&#20855;&#25104;&#20026;&#21487;&#33021;&#65292;&#38598;&#25104;&#24320;&#21457;&#29615;&#22659;&#65288;IDEs&#65289;&#24120;&#34987;&#29992;&#20316;&#19982;LLMs&#20132;&#20114;&#30340;&#25509;&#21475;&#12290;&#24050;&#21457;&#24067;&#35768;&#22810;&#36825;&#31867;&#24037;&#20855;&#65292;&#20294;&#20960;&#20046;&#20840;&#37096;&#37117;&#19987;&#27880;&#20110;&#36890;&#29992;&#32534;&#31243;&#35821;&#35328;&#65292;&#24456;&#23569;&#20851;&#27880;&#23545;IT&#33258;&#21160;&#21270;&#33267;&#20851;&#37325;&#35201;&#30340;&#29305;&#23450;&#39046;&#22495;&#35821;&#35328;&#12290;Ansible&#26159;&#19968;&#31181;&#22522;&#20110;YAML&#30340;IT&#33258;&#21160;&#21270;&#29305;&#23450;&#35821;&#35328;&#12290;Red Hat Ansible Lightspeed&#19982;IBM Watson Code Assistant&#21512;&#20316;&#30340;Ansible Lightspeed&#26159;&#19968;&#31181;&#22522;&#20110;LLM&#30340;&#26381;&#21153;&#65292;&#19987;&#38376;&#29992;&#20110;&#23558;&#33258;&#28982;&#35821;&#35328;&#36716;&#25442;&#20026;Ansible&#20195;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17442v1 Announce Type: cross  Abstract: The availability of Large Language Models (LLMs) which can generate code, has made it possible to create tools that improve developer productivity. Integrated development environments or IDEs which developers use to write software are often used as an interface to interact with LLMs. Although many such tools have been released, almost all of them focus on general-purpose programming languages. Domain-specific languages, such as those crucial for IT automation, have not received much attention. Ansible is one such YAML-based IT automation-specific language. Red Hat Ansible Lightspeed with IBM Watson Code Assistant, further referred to as Ansible Lightspeed, is an LLM-based service designed explicitly for natural language to Ansible code generation.   In this paper, we describe the design and implementation of the Ansible Lightspeed service and analyze feedback from thousands of real users. We examine diverse performance indicators, clas
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#26088;&#22312;&#25552;&#39640;&#28145;&#24230;&#23398;&#20064;Bug&#30340;&#21487;&#22797;&#29616;&#24615;&#65292;&#36890;&#36807;&#26500;&#24314;&#25968;&#25454;&#38598;&#21644;&#30830;&#23450;&#32534;&#36753;&#21160;&#20316;&#21644;&#26377;&#29992;&#20449;&#24687;&#65292;&#36825;&#33021;&#22815;&#35299;&#20915;&#30446;&#21069;&#30740;&#31350;&#20013;&#24573;&#35270;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.03069</link><description>&lt;p&gt;
&#25552;&#39640;&#28145;&#24230;&#23398;&#20064;Bug&#21487;&#22797;&#29616;&#24615;&#30340;&#25506;&#32034;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Towards Enhancing the Reproducibility of Deep Learning Bugs: An Empirical Study. (arXiv:2401.03069v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03069
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#26088;&#22312;&#25552;&#39640;&#28145;&#24230;&#23398;&#20064;Bug&#30340;&#21487;&#22797;&#29616;&#24615;&#65292;&#36890;&#36807;&#26500;&#24314;&#25968;&#25454;&#38598;&#21644;&#30830;&#23450;&#32534;&#36753;&#21160;&#20316;&#21644;&#26377;&#29992;&#20449;&#24687;&#65292;&#36825;&#33021;&#22815;&#35299;&#20915;&#30446;&#21069;&#30740;&#31350;&#20013;&#24573;&#35270;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32972;&#26223;&#65306;&#28145;&#24230;&#23398;&#20064;&#22312;&#21508;&#20010;&#39046;&#22495;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#19982;&#20256;&#32479;&#36719;&#20214;&#31995;&#32479;&#19968;&#26679;&#65292;&#28145;&#24230;&#23398;&#20064;&#31995;&#32479;&#20063;&#23384;&#22312;Bug&#65292;&#36825;&#21487;&#33021;&#23545;&#33258;&#21160;&#39550;&#39542;&#31561;&#39046;&#22495;&#20135;&#29983;&#20005;&#37325;&#24433;&#21709;&#12290;&#23613;&#31649;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#21462;&#24471;&#20102;&#37325;&#22823;&#36827;&#23637;&#65292;&#20294;&#24456;&#23569;&#26377;&#30740;&#31350;&#20851;&#27880;&#28145;&#24230;&#23398;&#20064;Bug&#30340;&#21487;&#22797;&#29616;&#24615;&#65292;&#36825;&#38459;&#30861;&#20102;Bug&#30340;&#35299;&#20915;&#12290;&#29616;&#26377;&#25991;&#29486;&#25351;&#20986;&#65292;&#20165;&#26377;3%&#30340;&#28145;&#24230;&#23398;&#20064;Bug&#26159;&#21487;&#22797;&#29616;&#30340;&#65292;&#36825;&#20984;&#26174;&#20102;&#36827;&#19968;&#27493;&#30740;&#31350;&#30340;&#24517;&#35201;&#24615;&#12290;&#30446;&#26631;&#65306;&#26412;&#25991;&#32771;&#23519;&#28145;&#24230;&#23398;&#20064;Bug&#30340;&#21487;&#22797;&#29616;&#24615;&#65292;&#35782;&#21035;&#21487;&#25552;&#39640;&#28145;&#24230;&#23398;&#20064;Bug&#21487;&#22797;&#29616;&#24615;&#30340;&#32534;&#36753;&#21160;&#20316;&#21644;&#26377;&#29992;&#20449;&#24687;&#12290;&#26041;&#27861;&#65306;&#39318;&#20808;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#21253;&#21547;&#26469;&#33258;Stack Overflow&#21644;Defects4ML&#30340;3&#20010;&#26694;&#26550;&#21644;22&#20010;&#26550;&#26500;&#30340;668&#20010;&#28145;&#24230;&#23398;&#20064;Bug&#30340;&#25968;&#25454;&#38598;&#12290;&#20854;&#27425;&#65292;&#20351;&#29992;&#20998;&#23618;&#25277;&#26679;&#36873;&#25321;&#20102;102&#20010;Bug&#65292;&#24182;&#23581;&#35797;&#30830;&#23450;&#23427;&#20204;&#30340;&#21487;&#22797;&#29616;&#24615;&#12290;&#22312;&#22797;&#29616;&#36825;&#20123;Bug&#30340;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#35782;&#21035;&#20102;&#32534;&#36753;&#21160;&#20316;&#21644;&#26377;&#29992;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
Context: Deep learning has achieved remarkable progress in various domains. However, like traditional software systems, deep learning systems contain bugs, which can have severe impacts, as evidenced by crashes involving autonomous vehicles. Despite substantial advancements in deep learning techniques, little research has focused on reproducing deep learning bugs, which hinders resolving them. Existing literature suggests that only 3% of deep learning bugs are reproducible, underscoring the need for further research.  Objective: This paper examines the reproducibility of deep learning bugs. We identify edit actions and useful information that could improve deep learning bug reproducibility.  Method: First, we construct a dataset of 668 deep learning bugs from Stack Overflow and Defects4ML across 3 frameworks and 22 architectures. Second, we select 102 bugs using stratified sampling and try to determine their reproducibility. While reproducing these bugs, we identify edit actions and us
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#23433;&#20840;&#30417;&#27979;&#26041;&#27861;SMARLA&#65292;&#29992;&#20110;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#26234;&#33021;&#20307;&#12290;&#35813;&#26041;&#27861;&#35774;&#35745;&#20026;&#40657;&#30418;&#23376;&#65292;&#21033;&#29992;&#29366;&#24577;&#25277;&#35937;&#20943;&#23569;&#29366;&#24577;&#31354;&#38388;&#65292;&#23454;&#29616;&#23545;&#26234;&#33021;&#20307;&#29366;&#24577;&#30340;&#23433;&#20840;&#36829;&#35268;&#39044;&#27979;&#12290;&#32463;&#39564;&#35777;&#65292;SMARLA&#20855;&#26377;&#20934;&#30830;&#30340;&#36829;&#35268;&#39044;&#27979;&#33021;&#21147;&#65292;&#24182;&#21487;&#22312;&#26234;&#33021;&#20307;&#25191;&#34892;&#30340;&#26089;&#26399;&#38454;&#27573;&#36827;&#34892;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2308.02594</link><description>&lt;p&gt;
SMARLA&#65306;&#19968;&#31181;&#29992;&#20110;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#26234;&#33021;&#20307;&#30340;&#23433;&#20840;&#30417;&#27979;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
SMARLA: A Safety Monitoring Approach for Deep Reinforcement Learning Agents. (arXiv:2308.02594v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02594
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#23433;&#20840;&#30417;&#27979;&#26041;&#27861;SMARLA&#65292;&#29992;&#20110;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#26234;&#33021;&#20307;&#12290;&#35813;&#26041;&#27861;&#35774;&#35745;&#20026;&#40657;&#30418;&#23376;&#65292;&#21033;&#29992;&#29366;&#24577;&#25277;&#35937;&#20943;&#23569;&#29366;&#24577;&#31354;&#38388;&#65292;&#23454;&#29616;&#23545;&#26234;&#33021;&#20307;&#29366;&#24577;&#30340;&#23433;&#20840;&#36829;&#35268;&#39044;&#27979;&#12290;&#32463;&#39564;&#35777;&#65292;SMARLA&#20855;&#26377;&#20934;&#30830;&#30340;&#36829;&#35268;&#39044;&#27979;&#33021;&#21147;&#65292;&#24182;&#21487;&#22312;&#26234;&#33021;&#20307;&#25191;&#34892;&#30340;&#26089;&#26399;&#38454;&#27573;&#36827;&#34892;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;(DRL)&#36234;&#26469;&#36234;&#22810;&#22320;&#24212;&#29992;&#20110;&#23433;&#20840;&#20851;&#38190;&#31995;&#32479;&#12290;&#30830;&#20445;DRL&#26234;&#33021;&#20307;&#30340;&#23433;&#20840;&#24615;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#26159;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#20165;&#20381;&#38752;&#27979;&#35797;&#26159;&#19981;&#36275;&#20197;&#30830;&#20445;&#23433;&#20840;&#24615;&#30340;&#65292;&#22240;&#20026;&#23427;&#19981;&#33021;&#25552;&#20379;&#20445;&#35777;&#12290;&#26500;&#24314;&#23433;&#20840;&#30417;&#27979;&#22120;&#26159;&#32531;&#35299;&#36825;&#19968;&#25361;&#25112;&#30340;&#19968;&#31181;&#35299;&#20915;&#26041;&#26696;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;SMARLA&#65292;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#23433;&#20840;&#30417;&#27979;&#26041;&#27861;&#65292;&#19987;&#20026;DRL&#26234;&#33021;&#20307;&#35774;&#35745;&#12290;&#20986;&#20110;&#23454;&#38469;&#21407;&#22240;&#65292;SMARLA&#34987;&#35774;&#35745;&#20026;&#40657;&#30418;&#23376;(&#22240;&#20026;&#23427;&#19981;&#38656;&#35201;&#35775;&#38382;&#26234;&#33021;&#20307;&#30340;&#20869;&#37096;)&#65292;&#24182;&#21033;&#29992;&#29366;&#24577;&#25277;&#35937;&#26469;&#20943;&#23569;&#29366;&#24577;&#31354;&#38388;&#65292;&#20174;&#32780;&#20419;&#36827;&#20174;&#26234;&#33021;&#20307;&#30340;&#29366;&#24577;&#23398;&#20064;&#23433;&#20840;&#36829;&#35268;&#39044;&#27979;&#27169;&#22411;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#30693;&#21517;&#30340;RL&#26696;&#20363;&#30740;&#31350;&#20013;&#39564;&#35777;&#20102;SMARLA&#12290;&#32463;&#39564;&#20998;&#26512;&#34920;&#26126;&#65292;SMARLA&#20855;&#26377;&#20934;&#30830;&#30340;&#36829;&#35268;&#39044;&#27979;&#33021;&#21147;&#65292;&#35823;&#25253;&#29575;&#20302;&#65292;&#24182;&#19988;&#21487;&#20197;&#22312;&#26234;&#33021;&#20307;&#25191;&#34892;&#30340;&#19968;&#21322;&#24038;&#21491;&#30340;&#26089;&#26399;&#38454;&#27573;&#39044;&#27979;&#23433;&#20840;&#36829;&#35268;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep reinforcement learning algorithms (DRL) are increasingly being used in safety-critical systems. Ensuring the safety of DRL agents is a critical concern in such contexts. However, relying solely on testing is not sufficient to ensure safety as it does not offer guarantees. Building safety monitors is one solution to alleviate this challenge. This paper proposes SMARLA, a machine learning-based safety monitoring approach designed for DRL agents. For practical reasons, SMARLA is designed to be black-box (as it does not require access to the internals of the agent) and leverages state abstraction to reduce the state space and thus facilitate the learning of safety violation prediction models from agent's states. We validated SMARLA on two well-known RL case studies. Empirical analysis reveals that SMARLA achieves accurate violation prediction with a low false positive rate, and can predict safety violations at an early stage, approximately halfway through the agent's execution before 
&lt;/p&gt;</description></item></channel></rss>