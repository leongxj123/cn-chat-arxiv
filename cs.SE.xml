<rss version="2.0"><channel><title>Chat Arxiv cs.SE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SE</description><item><title>&#31070;&#32463;&#20195;&#30721;&#26234;&#33021;&#39046;&#22495;&#30340;&#35843;&#26597;&#31995;&#32479;&#22238;&#39038;&#20102;50&#22810;&#31181;&#20195;&#34920;&#24615;&#27169;&#22411;&#21644;&#36229;&#36807;680&#39033;&#30456;&#20851;&#20316;&#21697;&#65292;&#31361;&#20986;&#20102;&#19981;&#21516;&#30740;&#31350;&#38454;&#27573;&#30340;&#33539;&#24335;&#21644;&#25216;&#26415;&#36716;&#21464;&#12290;</title><link>https://arxiv.org/abs/2403.14734</link><description>&lt;p&gt;
&#19968;&#39033;&#31070;&#32463;&#20195;&#30721;&#26234;&#33021;&#30340;&#35843;&#26597;&#65306;&#33539;&#24335;&#12289;&#36827;&#23637;&#19982;&#26410;&#26469;
&lt;/p&gt;
&lt;p&gt;
A Survey of Neural Code Intelligence: Paradigms, Advances and Beyond
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14734
&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#20195;&#30721;&#26234;&#33021;&#39046;&#22495;&#30340;&#35843;&#26597;&#31995;&#32479;&#22238;&#39038;&#20102;50&#22810;&#31181;&#20195;&#34920;&#24615;&#27169;&#22411;&#21644;&#36229;&#36807;680&#39033;&#30456;&#20851;&#20316;&#21697;&#65292;&#31361;&#20986;&#20102;&#19981;&#21516;&#30740;&#31350;&#38454;&#27573;&#30340;&#33539;&#24335;&#21644;&#25216;&#26415;&#36716;&#21464;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14734v1 &#20844;&#21578;&#31867;&#22411;: &#36328;&#39046;&#22495; &#25688;&#35201;: &#31070;&#32463;&#20195;&#30721;&#26234;&#33021;--&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#29702;&#35299;&#12289;&#29983;&#25104;&#21644;&#20248;&#21270;&#20195;&#30721;--&#22312;&#25972;&#20010;&#31038;&#20250;&#19978;&#20855;&#26377;&#24040;&#22823;&#30340;&#28508;&#21147;&#65292;&#21487;&#20135;&#29983;&#28145;&#36828;&#24433;&#21709;&#12290;&#20316;&#20026;&#33258;&#28982;&#35821;&#35328;&#21644;&#32534;&#31243;&#35821;&#35328;&#20043;&#38388;&#30340;&#26725;&#26753;&#65292;&#36825;&#19968;&#39046;&#22495;&#22312;&#36807;&#21435;&#20960;&#24180;&#24341;&#36215;&#20102;&#20004;&#20010;&#30740;&#31350;&#31038;&#21306;&#30740;&#31350;&#20154;&#21592;&#30340;&#26497;&#22823;&#20851;&#27880;&#12290;&#26412;&#35843;&#26597;&#31995;&#32479;&#22320;&#21644;&#25353;&#26102;&#38388;&#39034;&#24207;&#22238;&#39038;&#20102;&#20195;&#30721;&#26234;&#33021;&#26041;&#38754;&#30340;&#36827;&#23637;&#65292;&#21253;&#25324;50&#22810;&#31181;&#20195;&#34920;&#24615;&#27169;&#22411;&#21450;&#20854;&#21464;&#20307;&#12289;20&#22810;&#31181;&#20219;&#21153;&#31867;&#21035;&#20197;&#21450;&#36229;&#36807;680&#39033;&#30456;&#20851;&#20316;&#21697;&#12290;&#25105;&#20204;&#36981;&#24490;&#21382;&#21490;&#36827;&#23637;&#65292;&#36319;&#36394;&#19981;&#21516;&#30740;&#31350;&#38454;&#27573;&#30340;&#33539;&#24335;&#36716;&#21464;&#65288;&#20363;&#22914;&#65292;&#20174;&#20351;&#29992;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#23545;&#20195;&#30721;&#24314;&#27169;&#21040;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26102;&#20195;&#65289;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#37325;&#28857;&#20171;&#32461;&#20102;&#19981;&#21516;&#38454;&#27573;&#28085;&#30422;&#30340;&#27169;&#22411;&#12289;&#20219;&#21153;&#21644;&#35780;&#20272;&#30340;&#20027;&#35201;&#25216;&#26415;&#36716;&#21464;&#12290;&#23545;&#20110;&#24212;&#29992;&#65292;&#25105;&#20204;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14734v1 Announce Type: cross  Abstract: Neural Code Intelligence -- leveraging deep learning to understand, generate, and optimize code -- holds immense potential for transformative impacts on the whole society. Bridging the gap between Natural Language and Programming Language, this domain has drawn significant attention from researchers in both research communities over the past few years. This survey presents a systematic and chronological review of the advancements in code intelligence, encompassing over 50 representative models and their variants, more than 20 categories of tasks, and an extensive coverage of over 680 related works. We follow the historical progression to trace the paradigm shifts across different research phases (e.g., from modeling code with recurrent neural networks to the era of Large Language Models). Concurrently, we highlight the major technical transitions in models, tasks, and evaluations spanning through different stages. For applications, we 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#33258;&#21160;&#29983;&#25104;&#26131;&#20986;&#38169;&#27979;&#35797;&#30340;&#26631;&#35760;&#25968;&#25454;&#38598;&#65292;&#24182;&#36890;&#36807;&#20998;&#26512;&#27979;&#35797;&#20195;&#30721;&#26469;&#39044;&#27979;&#27979;&#35797;&#30340;&#20462;&#22797;&#31867;&#21035;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;UniXcoder&#20248;&#20110;CodeBERT&#12290;</title><link>http://arxiv.org/abs/2307.00012</link><description>&lt;p&gt;
&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#30340;&#40657;&#30418;&#39044;&#27979;&#26131;&#20986;&#38169;&#27979;&#35797;&#20462;&#22797;&#31867;&#21035;
&lt;/p&gt;
&lt;p&gt;
Black-Box Prediction of Flaky Test Fix Categories Using Language Models. (arXiv:2307.00012v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00012
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#33258;&#21160;&#29983;&#25104;&#26131;&#20986;&#38169;&#27979;&#35797;&#30340;&#26631;&#35760;&#25968;&#25454;&#38598;&#65292;&#24182;&#36890;&#36807;&#20998;&#26512;&#27979;&#35797;&#20195;&#30721;&#26469;&#39044;&#27979;&#27979;&#35797;&#30340;&#20462;&#22797;&#31867;&#21035;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;UniXcoder&#20248;&#20110;CodeBERT&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26131;&#20986;&#38169;&#27979;&#35797;&#20250;&#22312;&#30456;&#21516;&#36719;&#20214;&#29256;&#26412;&#30340;&#27979;&#35797;&#19979;&#38750;&#30830;&#23450;&#24615;&#22320;&#36890;&#36807;&#25110;&#22833;&#36133;&#65292;&#24341;&#36215;&#28151;&#20081;&#24182;&#28010;&#36153;&#24320;&#21457;&#32773;&#26102;&#38388;&#12290;&#23613;&#31649;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#24050;&#32463;&#34987;&#29992;&#20110;&#39044;&#27979;&#26131;&#20986;&#38169;&#24615;&#21450;&#20854;&#26681;&#26412;&#21407;&#22240;&#65292;&#20294;&#22312;&#25552;&#20379;&#20462;&#22797;&#25903;&#25345;&#26041;&#38754;&#20173;&#26377;&#36739;&#23569;&#24037;&#20316;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#36890;&#36807;&#20165;&#20998;&#26512;&#27979;&#35797;&#20195;&#30721;&#33258;&#21160;&#29983;&#25104;13&#20010;&#20462;&#22797;&#31867;&#21035;&#30340;&#26631;&#35760;&#25968;&#25454;&#38598;&#65292;&#24182;&#35757;&#32451;&#27169;&#22411;&#26469;&#39044;&#27979;&#26131;&#20986;&#38169;&#27979;&#35797;&#30340;&#20462;&#22797;&#31867;&#21035;&#12290;&#34429;&#28982;&#22312;&#24403;&#21069;&#38454;&#27573;&#20934;&#30830;&#39044;&#27979;&#20462;&#22797;&#26412;&#36523;&#26159;&#19981;&#29616;&#23454;&#30340;&#65292;&#20294;&#36825;&#20123;&#31867;&#21035;&#25552;&#20379;&#20102;&#20851;&#20110;&#38656;&#35201;&#26816;&#26597;&#30340;&#27979;&#35797;&#20195;&#30721;&#37096;&#20998;&#30340;&#31934;&#30830;&#25351;&#23548;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#65292;&#21363;CodeBERT&#21644;UniXcoder&#65292;&#20854;&#36755;&#20986;&#32463;&#36807;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#65288;FNN&#65289;&#25110;&#22522;&#20110;&#23402;&#29983;&#32593;&#32476;&#30340;Few Shot Learning&#65288;FSL&#65289;&#36827;&#34892;&#20102;&#24494;&#35843;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;UniXcoder&#22312;&#27491;&#30830;&#39044;&#27979;&#22823;&#22810;&#25968;&#20462;&#22797;&#31867;&#21035;&#26041;&#38754;&#34920;&#29616;&#20248;&#20110;CodeBERT&#12290;
&lt;/p&gt;
&lt;p&gt;
Flaky tests are problematic because they non-deterministically pass or fail for the same software version under test, causing confusion and wasting developer time. While machine learning models have been used to predict flakiness and its root causes, there is less work on providing support to fix the problem. To address this gap, we propose a framework that automatically generates labeled datasets for 13 fix categories and train models to predict the fix category of a flaky test by analyzing the test code only. Though it is unrealistic at this stage to accurately predict the fix itself, the categories provide precise guidance about what part of the test code to look at. Our approach is based on language models, namely CodeBERT and UniXcoder, whose output is fine-tuned with a Feed Forward Neural Network (FNN) or a Siamese Network-based Few Shot Learning (FSL). Our experimental results show that UniXcoder outperforms CodeBERT, in correctly predicting most of the categories of fixes a dev
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35814;&#32454;&#20998;&#26512;&#20102;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#36716;&#25442;&#22120;&#30340;&#25925;&#38556;&#24773;&#20917;&#65292;&#29305;&#21035;&#26159;&#23545;ONNX&#30456;&#20851;&#30340;&#36716;&#25442;&#22120;&#36827;&#34892;&#20102;&#39318;&#27425;&#25925;&#38556;&#20998;&#26512;&#65292;&#24182;&#35814;&#32454;&#25253;&#21578;&#20102;&#25925;&#38556;&#30340;&#30151;&#29366;&#65292;&#21407;&#22240;&#21644;&#20301;&#32622;&#20197;&#21450;&#38543;&#26102;&#38388;&#30340;&#36235;&#21183;&#12290;</title><link>http://arxiv.org/abs/2303.17708</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#36716;&#25442;&#22120;&#20013;&#30340;&#25925;&#38556;&#21644;&#39118;&#38505;&#20998;&#26512;&#65306;&#20197;ONNX&#29983;&#24577;&#31995;&#32479;&#30340;&#26696;&#20363;&#30740;&#31350;&#20026;&#20363;
&lt;/p&gt;
&lt;p&gt;
Analysis of Failures and Risks in Deep Learning Model Converters: A Case Study in the ONNX Ecosystem. (arXiv:2303.17708v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.17708
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35814;&#32454;&#20998;&#26512;&#20102;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#36716;&#25442;&#22120;&#30340;&#25925;&#38556;&#24773;&#20917;&#65292;&#29305;&#21035;&#26159;&#23545;ONNX&#30456;&#20851;&#30340;&#36716;&#25442;&#22120;&#36827;&#34892;&#20102;&#39318;&#27425;&#25925;&#38556;&#20998;&#26512;&#65292;&#24182;&#35814;&#32454;&#25253;&#21578;&#20102;&#25925;&#38556;&#30340;&#30151;&#29366;&#65292;&#21407;&#22240;&#21644;&#20301;&#32622;&#20197;&#21450;&#38543;&#26102;&#38388;&#30340;&#36235;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36719;&#20214;&#24037;&#31243;&#24072;&#24320;&#21457;&#65292;&#20248;&#21270;&#21644;&#37096;&#32626;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#12290;&#20182;&#20204;&#22312;&#21508;&#31181;&#24320;&#21457;&#26694;&#26550;&#20013;&#20351;&#29992;&#21644;&#37325;&#26032;&#20351;&#29992;&#27169;&#22411;&#65292;&#24182;&#22312;&#21508;&#31181;&#36816;&#34892;&#26102;&#29615;&#22659;&#20013;&#37096;&#32626;&#23427;&#20204;&#12290;&#22312;&#36825;&#20010;&#22810;&#26679;&#21270;&#30340;&#29983;&#24577;&#31995;&#32479;&#20013;&#65292;&#24037;&#31243;&#24072;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#36716;&#25442;&#22120;&#23558;&#27169;&#22411;&#20174;&#26694;&#26550;&#31227;&#21160;&#21040;&#36816;&#34892;&#26102;&#29615;&#22659;&#12290;&#28982;&#32780;&#65292;&#36716;&#25442;&#22120;&#20013;&#30340;&#38169;&#35823;&#21487;&#33021;&#20250;&#24433;&#21709;&#27169;&#22411;&#36136;&#37327;&#24182;&#30772;&#22351;&#37096;&#32626;&#12290;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#36716;&#25442;&#22120;&#30340;&#25925;&#38556;&#39057;&#29575;&#21644;&#25925;&#38556;&#27169;&#24335;&#23578;&#19981;&#28165;&#26970;&#12290;&#26412;&#25991;&#38024;&#23545;ONNX (Open Neural Network eXchange)&#30456;&#20851;&#30340;&#27169;&#22411;&#36716;&#25442;&#22120;&#36827;&#34892;&#20102;&#39318;&#27425;&#25925;&#38556;&#20998;&#26512;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;ONNX&#36716;&#25442;&#22120;&#22312;&#20004;&#20010;&#37325;&#35201;&#30340;DL&#26694;&#26550;PyTorch&#21644;TensorFlow&#20013;&#30340;&#36807;&#21435;&#25925;&#38556;&#12290;&#36824;&#25253;&#21578;&#20102;&#25925;&#38556;&#65288;N=200&#20010;&#38382;&#39064;&#65289;&#30340;&#30151;&#29366;&#65292;&#21407;&#22240;&#21644;&#20301;&#32622;&#20197;&#21450;&#38543;&#26102;&#38388;&#30340;&#36235;&#21183;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#36716;&#25442;8,797&#20010;&#27169;&#22411;&#65288;&#30495;&#23454;&#19990;&#30028;&#21644;&#20154;&#24037;&#29983;&#25104;&#30340;&#23454;&#20363;&#65289;&#26469;&#35780;&#20272;&#24403;&#20170;&#30340;&#25925;&#38556;&#12290;
&lt;/p&gt;
&lt;p&gt;
Software engineers develop, fine-tune, and deploy deep learning (DL) models. They use and re-use models in a variety of development frameworks and deploy them on a range of runtime environments. In this diverse ecosystem, engineers use DL model converters to move models from frameworks to runtime environments. However, errors in converters can compromise model quality and disrupt deployment. The failure frequency and failure modes of DL model converters are unknown.  In this paper, we conduct the first failure analysis on DL model converters. Specifically, we characterize failures in model converters associated with ONNX (Open Neural Network eXchange). We analyze past failures in the ONNX converters in two major DL frameworks, PyTorch and TensorFlow. The symptoms, causes, and locations of failures (for N=200 issues), and trends over time are also reported. We also evaluate present-day failures by converting 8,797 models, both real-world and synthetically generated instances. The consis
&lt;/p&gt;</description></item></channel></rss>