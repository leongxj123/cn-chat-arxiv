<rss version="2.0"><channel><title>Chat Arxiv cs.SE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SE</description><item><title>&#26412;&#30740;&#31350;&#39318;&#27425;&#31995;&#32479;&#30740;&#31350;&#20102;&#39044;&#35757;&#32451;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#21629;&#21517;&#24815;&#20363;&#21644;&#30456;&#20851;&#32570;&#38519;&#65292;&#20026;&#25105;&#20204;&#20102;&#35299;&#30740;&#31350;&#21040;&#23454;&#36341;&#36807;&#31243;&#25552;&#20379;&#20102;&#30693;&#35782;&#21644;&#35748;&#35782;&#12290;</title><link>http://arxiv.org/abs/2310.01642</link><description>&lt;p&gt;
&#25506;&#32034;Hugging Face&#21644;&#20854;&#20182;&#27169;&#22411;&#20179;&#24211;&#20013;&#39044;&#35757;&#32451;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#21629;&#21517;&#24815;&#20363;&#65288;&#21450;&#32570;&#38519;&#65289;
&lt;/p&gt;
&lt;p&gt;
Exploring Naming Conventions (and Defects) of Pre-trained Deep Learning Models in Hugging Face and Other Model Hubs. (arXiv:2310.01642v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01642
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#39318;&#27425;&#31995;&#32479;&#30740;&#31350;&#20102;&#39044;&#35757;&#32451;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#21629;&#21517;&#24815;&#20363;&#21644;&#30456;&#20851;&#32570;&#38519;&#65292;&#20026;&#25105;&#20204;&#20102;&#35299;&#30740;&#31350;&#21040;&#23454;&#36341;&#36807;&#31243;&#25552;&#20379;&#20102;&#30693;&#35782;&#21644;&#35748;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#28145;&#24230;&#23398;&#20064;&#30340;&#21019;&#26032;&#19981;&#26029;&#25512;&#36827;&#65292;&#35768;&#22810;&#24037;&#31243;&#24072;&#24076;&#26395;&#23558;&#39044;&#35757;&#32451;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65288;PTMs&#65289;&#20316;&#20026;&#35745;&#31639;&#31995;&#32479;&#30340;&#32452;&#25104;&#37096;&#20998;&#12290;PTMs&#26159;&#30740;&#31350;&#21040;&#23454;&#36341;&#30340;&#27969;&#31243;&#30340;&#19968;&#37096;&#20998;&#65306;&#30740;&#31350;&#20154;&#21592;&#21457;&#24067;PTMs&#65292;&#24037;&#31243;&#24072;&#26681;&#25454;&#36136;&#37327;&#25110;&#24615;&#33021;&#36827;&#34892;&#35843;&#25972;&#24182;&#37096;&#32626;&#12290;&#22914;&#26524;PTM&#30340;&#20316;&#32773;&#20026;&#20854;&#36873;&#25321;&#36866;&#24403;&#30340;&#21517;&#31216;&#65292;&#21487;&#20197;&#20419;&#36827;&#27169;&#22411;&#30340;&#21457;&#29616;&#21644;&#22797;&#29992;&#12290;&#28982;&#32780;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#25253;&#36947;&#20102;&#27169;&#22411;&#21517;&#31216;&#24182;&#19981;&#24635;&#26159;&#36873;&#25321;&#24471;&#24456;&#22909;&#65292;&#26377;&#26102;&#29978;&#33267;&#26159;&#38169;&#35823;&#30340;&#12290;PTM&#21253;&#30340;&#21629;&#21517;&#24815;&#20363;&#21644;&#21629;&#21517;&#32570;&#38519;&#23578;&#26410;&#24471;&#21040;&#31995;&#32479;&#30340;&#30740;&#31350;&#65292;&#20102;&#35299;&#23427;&#20204;&#23558;&#22686;&#21152;&#25105;&#20204;&#23545;PTM&#21253;&#30340;&#30740;&#31350;&#21040;&#23454;&#36341;&#36807;&#31243;&#36816;&#20316;&#26041;&#24335;&#30340;&#35748;&#35782;&#12290;&#26412;&#25991;&#25253;&#21578;&#20102;&#23545;PTM&#21629;&#21517;&#24815;&#20363;&#21450;&#30456;&#20851;&#21629;&#21517;&#32570;&#38519;&#30340;&#39318;&#27425;&#30740;&#31350;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;PTM&#21253;&#21517;&#31216;&#30340;&#32452;&#25104;&#37096;&#20998;&#65292;&#21253;&#25324;&#20803;&#25968;&#25454;&#20013;&#30340;&#21253;&#21517;&#31216;&#21644;&#22768;&#26126;&#30340;&#26550;&#26500;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#31532;&#19968;&#39033;&#26088;&#22312;&#25551;&#36848;PTM&#21629;&#21517;&#24615;&#36136;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
As innovation in deep learning continues, many engineers want to adopt Pre-Trained deep learning Models (PTMs) as components in computer systems. PTMs are part of a research-to-practice pipeline: researchers publish PTMs, which engineers adapt for quality or performance and then deploy. If PTM authors choose appropriate names for their PTMs, it could facilitate model discovery and reuse. However, prior research has reported that model names are not always well chosen, and are sometimes erroneous. The naming conventions and naming defects for PTM packages have not been systematically studied - understanding them will add to our knowledge of how the research-to-practice process works for PTM packages  In this paper, we report the first study of PTM naming conventions and the associated PTM naming defects. We define the components of a PTM package name, comprising the package name and claimed architecture from the metadata. We present the first study focused on characterizing the nature o
&lt;/p&gt;</description></item></channel></rss>