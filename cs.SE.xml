<rss version="2.0"><channel><title>Chat Arxiv cs.SE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SE</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#22810;&#35821;&#35328;&#20811;&#38534;&#26816;&#27979;&#38382;&#39064;&#65292;&#24182;&#20174;CodeForces&#25968;&#25454;&#38598;&#24320;&#21457;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;XCD&#12290;&#25105;&#20204;&#20351;&#29992;&#36328;&#35821;&#35328;&#19968;&#33268;&#24615;&#35757;&#32451;&#65288;CCT&#65289;&#26041;&#27861;&#35757;&#32451;&#20102;&#35821;&#35328;&#27169;&#22411;&#65292;&#24471;&#21040;&#20102;&#20855;&#26377;&#26032;&#39062;&#24615;&#33021;&#30340;CCT-LM&#27169;&#22411;&#65292;&#36229;&#36807;&#20102;&#29616;&#26377;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.11626</link><description>&lt;p&gt;
CCT-Code&#65306;&#38754;&#21521;&#22810;&#35821;&#35328;&#20811;&#38534;&#26816;&#27979;&#21644;&#20195;&#30721;&#25628;&#32034;&#30340;&#36328;&#35821;&#35328;&#19968;&#33268;&#24615;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
CCT-Code: Cross-Consistency Training for Multilingual Clone Detection and Code Search. (arXiv:2305.11626v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11626
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#22810;&#35821;&#35328;&#20811;&#38534;&#26816;&#27979;&#38382;&#39064;&#65292;&#24182;&#20174;CodeForces&#25968;&#25454;&#38598;&#24320;&#21457;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;XCD&#12290;&#25105;&#20204;&#20351;&#29992;&#36328;&#35821;&#35328;&#19968;&#33268;&#24615;&#35757;&#32451;&#65288;CCT&#65289;&#26041;&#27861;&#35757;&#32451;&#20102;&#35821;&#35328;&#27169;&#22411;&#65292;&#24471;&#21040;&#20102;&#20855;&#26377;&#26032;&#39062;&#24615;&#33021;&#30340;CCT-LM&#27169;&#22411;&#65292;&#36229;&#36807;&#20102;&#29616;&#26377;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#28304;&#20195;&#30721;&#30340;&#20811;&#38534;&#26816;&#27979;&#21644;&#20449;&#24687;&#26816;&#32034;&#38382;&#39064;&#65292;&#36825;&#20004;&#20010;&#38382;&#39064;&#23545;&#20110;&#20219;&#20309;&#32534;&#31243;&#35821;&#35328;&#37117;&#38750;&#24120;&#37325;&#35201;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#22810;&#35821;&#35328;&#20811;&#38534;&#26816;&#27979;&#38382;&#39064;&#65292;&#24182;&#20174;CodeForces&#25552;&#20132;&#25968;&#25454;&#38598;&#20135;&#29983;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;XCD&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#31216;&#20026;&#36328;&#35821;&#35328;&#19968;&#33268;&#24615;&#35757;&#32451;&#65288;CCT&#65289;&#65292;&#29992;&#20110;&#22312;&#19981;&#21516;&#30340;&#32534;&#31243;&#35821;&#35328;&#20013;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65292;&#36827;&#32780;&#24471;&#21040;&#22522;&#20110;CCT-LM &#27169;&#22411;&#12290;&#35813;&#27169;&#22411;&#32487;&#25215;&#20102;GraphCodeBERT&#24182;&#29992;CCT&#24494;&#35843;&#65292;&#36798;&#21040;&#20102;95.67\% MAP&#21644;47.18\% MRR&#30340;&#24615;&#33021;&#65292;&#25104;&#21151;&#21019;&#36896;&#20102;&#26032;&#30340;&#26368;&#20248;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the clone detection and information retrieval problems for source code, well-known tasks important for any programming language. Although it is also an important and interesting problem to find code snippets that operate identically but are written in different programming languages, to the best of our knowledge multilingual clone detection has not been studied in literature. In this work, we formulate the multilingual clone detection problem and present XCD, a new benchmark dataset produced from the CodeForces submissions dataset. Moreover, we present a novel training procedure, called cross-consistency training (CCT), that we apply to train language models on source code in different programming languages. The resulting CCT-LM model, initialized with GraphCodeBERT and fine-tuned with CCT, achieves new state of the art, outperforming existing approaches on the POJ-104 clone detection benchmark with 95.67\% MAP and AdvTest code search benchmark with 47.18\% MRR; it also sho
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#39044;&#35757;&#32451;&#20108;&#36827;&#21046;&#20195;&#30721;&#34920;&#31034;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#23558;&#28304;&#20195;&#30721;&#21644;&#27880;&#37322;&#20449;&#24687;&#32435;&#20837;&#20108;&#36827;&#21046;&#20195;&#30721;&#30340;&#34920;&#31034;&#23398;&#20064;&#20013;&#65292;&#23545;&#20110;&#21453;&#21521;&#24037;&#31243;&#21644;&#35745;&#31639;&#26426;&#23433;&#20840;&#20219;&#21153;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2210.05102</link><description>&lt;p&gt;
&#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#39044;&#35757;&#32451;&#20108;&#36827;&#21046;&#20195;&#30721;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Pre-Training Representations of Binary Code Using Contrastive Learning. (arXiv:2210.05102v2 [cs.SE] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.05102
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#39044;&#35757;&#32451;&#20108;&#36827;&#21046;&#20195;&#30721;&#34920;&#31034;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#23558;&#28304;&#20195;&#30721;&#21644;&#27880;&#37322;&#20449;&#24687;&#32435;&#20837;&#20108;&#36827;&#21046;&#20195;&#30721;&#30340;&#34920;&#31034;&#23398;&#20064;&#20013;&#65292;&#23545;&#20110;&#21453;&#21521;&#24037;&#31243;&#21644;&#35745;&#31639;&#26426;&#23433;&#20840;&#20219;&#21153;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32534;&#35793;&#21518;&#30340;&#36719;&#20214;&#20197;&#21487;&#25191;&#34892;&#30340;&#20108;&#36827;&#21046;&#20195;&#30721;&#24418;&#24335;&#20132;&#20184;&#12290;&#24320;&#21457;&#20154;&#21592;&#32534;&#20889;&#28304;&#20195;&#30721;&#26469;&#34920;&#36798;&#36719;&#20214;&#30340;&#35821;&#20041;&#65292;&#20294;&#32534;&#35793;&#22120;&#23558;&#20854;&#36716;&#25442;&#20026;CPU&#21487;&#20197;&#30452;&#25509;&#25191;&#34892;&#30340;&#20108;&#36827;&#21046;&#26684;&#24335;&#12290;&#22240;&#27492;&#65292;&#20108;&#36827;&#21046;&#20195;&#30721;&#20998;&#26512;&#23545;&#20110;&#21453;&#21521;&#24037;&#31243;&#21644;&#35745;&#31639;&#26426;&#23433;&#20840;&#20219;&#21153;&#31561;&#27809;&#26377;&#28304;&#20195;&#30721;&#30340;&#24212;&#29992;&#31243;&#24207;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#19982;&#21253;&#21547;&#20016;&#23500;&#35821;&#20041;&#20449;&#24687;&#30340;&#28304;&#20195;&#30721;&#21644;&#33258;&#28982;&#35821;&#35328;&#19981;&#21516;&#65292;&#20108;&#36827;&#21046;&#20195;&#30721;&#36890;&#24120;&#38590;&#20197;&#29702;&#35299;&#21644;&#20998;&#26512;&#12290;&#34429;&#28982;&#29616;&#26377;&#30340;&#24037;&#20316;&#20351;&#29992;AI&#27169;&#22411;&#36741;&#21161;&#28304;&#20195;&#30721;&#20998;&#26512;&#65292;&#20294;&#24456;&#23569;&#26377;&#30740;&#31350;&#32771;&#34385;&#20108;&#36827;&#21046;&#20195;&#30721;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#28304;&#20195;&#30721;&#21644;&#27880;&#37322;&#20449;&#24687;&#32435;&#20837;&#20108;&#36827;&#21046;&#20195;&#30721;&#36827;&#34892;&#34920;&#31034;&#23398;&#20064;&#30340;&#23545;&#27604;&#23398;&#20064;&#27169;&#22411;&#65292;&#31216;&#20026;COMBO&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#22312;COMBO&#20013;&#25552;&#20986;&#20102;&#19977;&#20010;&#32452;&#20214;&#65306;&#65288;1&#65289;&#29992;&#20110;&#20919;&#21551;&#21160;&#39044;&#35757;&#32451;&#30340;&#20027;&#35201;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#65292;&#65288;2&#65289;&#29992;&#20110;&#23558;&#28304;&#20195;&#30721;&#21644;&#27880;&#37322;&#20449;&#24687;&#25554;&#20837;&#21040;&#20108;&#36827;&#21046;&#20195;&#30721;&#20013;&#30340;&#21333;&#32431;&#25554;&#20540;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Compiled software is delivered as executable binary code. Developers write source code to express the software semantics, but the compiler converts it to a binary format that the CPU can directly execute. Therefore, binary code analysis is critical to applications in reverse engineering and computer security tasks where source code is not available. However, unlike source code and natural language that contain rich semantic information, binary code is typically difficult for human engineers to understand and analyze. While existing work uses AI models to assist source code analysis, few studies have considered binary code. In this paper, we propose a COntrastive learning Model for Binary cOde Analysis, or COMBO, that incorporates source code and comment information into binary code during representation learning. Specifically, we present three components in COMBO: (1) a primary contrastive learning method for cold-start pre-training, (2) a simplex interpolation method to incorporate so
&lt;/p&gt;</description></item></channel></rss>