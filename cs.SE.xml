<rss version="2.0"><channel><title>Chat Arxiv cs.SE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SE</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20108;&#36827;&#21046;&#20195;&#30721;&#23884;&#20837;&#27169;&#22411;UniASM&#65292;&#24182;&#35774;&#35745;&#20102;&#20004;&#20010;&#26032;&#30340;&#35757;&#32451;&#20219;&#21153;&#65292;&#20351;&#24471;&#29983;&#25104;&#21521;&#37327;&#30340;&#31354;&#38388;&#20998;&#24067;&#26356;&#21152;&#22343;&#21248;&#65292;&#30452;&#25509;&#21487;&#20197;&#22312;&#26080;&#38656;&#20219;&#20309;&#24494;&#35843;&#30340;&#24773;&#20917;&#19979;&#29992;&#20110;&#20108;&#36827;&#21046;&#20195;&#30721;&#30456;&#20284;&#24615;&#26816;&#27979;&#12290;&#27492;&#22806;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20108;&#36827;&#21046;&#20989;&#25968;tokenization&#26041;&#27861;&#65292;&#32531;&#35299;&#20102;&#35789;&#27719;&#22806;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#28040;&#34701;&#23454;&#39564;&#24471;&#21040;&#20102;&#19968;&#20123;&#26032;&#30340;&#26377;&#20215;&#20540;&#30340;&#21457;&#29616;&#65292;&#23454;&#39564;&#35777;&#26126;UniASM&#20248;&#20110;&#20854;&#20182;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2211.01144</link><description>&lt;p&gt;
UniASM&#65306;&#26080;&#38656;&#24494;&#35843;&#30340;&#20108;&#36827;&#21046;&#20195;&#30721;&#30456;&#20284;&#24615;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
UniASM: Binary Code Similarity Detection without Fine-tuning. (arXiv:2211.01144v3 [cs.CR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.01144
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20108;&#36827;&#21046;&#20195;&#30721;&#23884;&#20837;&#27169;&#22411;UniASM&#65292;&#24182;&#35774;&#35745;&#20102;&#20004;&#20010;&#26032;&#30340;&#35757;&#32451;&#20219;&#21153;&#65292;&#20351;&#24471;&#29983;&#25104;&#21521;&#37327;&#30340;&#31354;&#38388;&#20998;&#24067;&#26356;&#21152;&#22343;&#21248;&#65292;&#30452;&#25509;&#21487;&#20197;&#22312;&#26080;&#38656;&#20219;&#20309;&#24494;&#35843;&#30340;&#24773;&#20917;&#19979;&#29992;&#20110;&#20108;&#36827;&#21046;&#20195;&#30721;&#30456;&#20284;&#24615;&#26816;&#27979;&#12290;&#27492;&#22806;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20108;&#36827;&#21046;&#20989;&#25968;tokenization&#26041;&#27861;&#65292;&#32531;&#35299;&#20102;&#35789;&#27719;&#22806;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#28040;&#34701;&#23454;&#39564;&#24471;&#21040;&#20102;&#19968;&#20123;&#26032;&#30340;&#26377;&#20215;&#20540;&#30340;&#21457;&#29616;&#65292;&#23454;&#39564;&#35777;&#26126;UniASM&#20248;&#20110;&#20854;&#20182;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20108;&#36827;&#21046;&#20195;&#30721;&#30456;&#20284;&#24615;&#26816;&#27979;&#34987;&#24191;&#27867;&#29992;&#20110;&#21508;&#31181;&#20108;&#36827;&#21046;&#20998;&#26512;&#20219;&#21153;&#65292;&#22914;&#28431;&#27934;&#25628;&#32034;&#12289;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#12289;&#20811;&#38534;&#26816;&#27979;&#21644;&#34917;&#19969;&#20998;&#26512;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22522;&#20110;&#23398;&#20064;&#30340;&#20108;&#36827;&#21046;&#20195;&#30721;&#23884;&#20837;&#27169;&#22411;&#27604;&#20256;&#32479;&#30340;&#22522;&#20110;&#29305;&#24449;&#30340;&#26041;&#27861;&#26356;&#22909;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;transformer&#30340;&#20108;&#36827;&#21046;&#20195;&#30721;&#23884;&#20837;&#27169;&#22411;UniASM&#65292;&#29992;&#20110;&#23398;&#20064;&#20108;&#36827;&#21046;&#20989;&#25968;&#30340;&#34920;&#31034;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#20004;&#20010;&#26032;&#30340;&#35757;&#32451;&#20219;&#21153;&#65292;&#20351;&#24471;&#29983;&#25104;&#21521;&#37327;&#30340;&#31354;&#38388;&#20998;&#24067;&#26356;&#21152;&#22343;&#21248;&#65292;&#30452;&#25509;&#21487;&#20197;&#22312;&#26080;&#38656;&#20219;&#20309;&#24494;&#35843;&#30340;&#24773;&#20917;&#19979;&#29992;&#20110;&#20108;&#36827;&#21046;&#20195;&#30721;&#30456;&#20284;&#24615;&#26816;&#27979;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20108;&#36827;&#21046;&#20989;&#25968;tokenization&#26041;&#27861;&#65292;&#22686;&#21152;&#20102;tokens&#30340;&#35821;&#20041;&#20449;&#24687;&#24182;&#32531;&#35299;&#20102;&#35789;&#27719;&#22806;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#28040;&#34701;&#23454;&#39564;&#36827;&#34892;&#20102;&#28145;&#20837;&#20998;&#26512;&#65292;&#24471;&#21040;&#20102;&#19968;&#20123;&#26032;&#30340;&#26377;&#20215;&#20540;&#30340;&#21457;&#29616;&#65292;&#23454;&#39564;&#35777;&#26126;UniASM&#20248;&#20110;&#20854;&#20182;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Binary code similarity detection (BCSD) is widely used in various binary analysis tasks such as vulnerability search, malware detection, clone detection, and patch analysis. Recent studies have shown that the learning-based binary code embedding models perform better than the traditional feature-based approaches. In this paper, we propose a novel transformer-based binary code embedding model named UniASM to learn representations of the binary functions. We design two new training tasks to make the spatial distribution of the generated vectors more uniform, which can be used directly in BCSD without any fine-tuning. In addition, we present a new tokenization approach for binary functions, which increases the token's semantic information and mitigates the out-of-vocabulary (OOV) problem. We conduct an in-depth analysis of the factors affecting model performance through ablation experiments and obtain some new and valuable findings. The experimental results show that UniASM outperforms th
&lt;/p&gt;</description></item></channel></rss>