<rss version="2.0"><channel><title>Chat Arxiv cs.SE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SE</description><item><title>CONLINE&#26694;&#26550;&#25552;&#20986;&#20102;&#36890;&#36807;&#22312;&#32447;&#25628;&#32034;&#21644;&#27491;&#30830;&#24615;&#27979;&#35797;&#26469;&#22686;&#24378;&#22797;&#26434;&#20195;&#30721;&#29983;&#25104;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#26174;&#33879;&#25552;&#39640;&#20102;&#20195;&#30721;&#29983;&#25104;&#36136;&#37327;&#12290;</title><link>https://arxiv.org/abs/2403.13583</link><description>&lt;p&gt;
CONLINE: &#22797;&#26434;&#20195;&#30721;&#29983;&#25104;&#19982;&#22312;&#32447;&#25628;&#32034;&#21644;&#27491;&#30830;&#24615;&#27979;&#35797;&#30340;&#31934;&#28860;
&lt;/p&gt;
&lt;p&gt;
CONLINE: Complex Code Generation and Refinement with Online Searching and Correctness Testing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13583
&lt;/p&gt;
&lt;p&gt;
CONLINE&#26694;&#26550;&#25552;&#20986;&#20102;&#36890;&#36807;&#22312;&#32447;&#25628;&#32034;&#21644;&#27491;&#30830;&#24615;&#27979;&#35797;&#26469;&#22686;&#24378;&#22797;&#26434;&#20195;&#30721;&#29983;&#25104;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#26174;&#33879;&#25552;&#39640;&#20102;&#20195;&#30721;&#29983;&#25104;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36890;&#36807;&#23558;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#36716;&#25442;&#20026;&#21487;&#25191;&#34892;&#20195;&#30721;&#65292;&#24443;&#24213;&#25913;&#21464;&#20102;&#20195;&#30721;&#29983;&#25104;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#22312;&#30495;&#23454;&#22330;&#26223;&#19979;&#29983;&#25104;&#22797;&#26434;&#20195;&#30721;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#21407;&#22240;&#22312;&#20110;&#22797;&#26434;&#30340;&#32467;&#26500;&#12289;&#24494;&#22937;&#30340;&#38169;&#35823;&#12289;&#23545;&#39640;&#32423;&#25968;&#25454;&#31867;&#22411;&#30340;&#29702;&#35299;&#20197;&#21450;&#32570;&#23569;&#36741;&#21161;&#20869;&#23481;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;CONLINE&#26694;&#26550;&#65292;&#36890;&#36807;&#35745;&#21010;&#30340;&#22312;&#32447;&#25628;&#32034;&#20449;&#24687;&#26816;&#32034;&#21644;&#33258;&#21160;&#27491;&#30830;&#24615;&#27979;&#35797;&#26469;&#22686;&#24378;&#20195;&#30721;&#29983;&#25104;&#65292;&#36827;&#34892;&#36845;&#20195;&#31934;&#28860;&#12290;CONLINE&#36824;&#20018;&#34892;&#21270;&#20102;&#22797;&#26434;&#30340;&#36755;&#20837;&#21644;&#36755;&#20986;&#65292;&#20197;&#25913;&#21892;&#29702;&#35299;&#65292;&#24182;&#29983;&#25104;&#27979;&#35797;&#29992;&#20363;&#65292;&#30830;&#20445;&#26694;&#26550;&#36866;&#29992;&#20110;&#29616;&#23454;&#24212;&#29992;&#12290;CONLINE&#36890;&#36807;&#23545;DS-1000&#21644;ClassEval&#25968;&#25454;&#38598;&#36827;&#34892;&#20005;&#26684;&#23454;&#39564;&#39564;&#35777;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;CONLINE&#26174;&#33879;&#25552;&#39640;&#20102;&#22797;&#26434;&#20195;&#30721;&#29983;&#25104;&#30340;&#36136;&#37327;&#65292;&#31361;&#26174;&#20102;&#20854;&#25552;&#21319;&#23454;&#36341;&#24212;&#29992;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13583v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have revolutionized code generation ability by converting natural language descriptions into executable code. However, generating complex code within real-world scenarios remains challenging due to intricate structures, subtle bugs, understanding of advanced data types, and lack of supplementary contents. To address these challenges, we introduce the CONLINE framework, which enhances code generation by incorporating planned online searches for information retrieval and automated correctness testing for iterative refinement. CONLINE also serializes the complex inputs and outputs to improve comprehension and generate test case to ensure the framework's adaptability for real-world applications. CONLINE is validated through rigorous experiments on the DS-1000 and ClassEval datasets. It shows that CONLINE substantially improves the quality of complex code generation, highlighting its potential to enhance the pra
&lt;/p&gt;</description></item><item><title>LangGPT&#25552;&#20986;&#20102;&#19968;&#20010;&#21452;&#23618;&#25552;&#31034;&#35774;&#35745;&#26694;&#26550;&#65292;&#20316;&#20026;LLMs&#30340;&#32534;&#31243;&#35821;&#35328;&#65292;&#22823;&#22823;&#22686;&#24378;&#20102;LLMs&#20135;&#29983;&#39640;&#36136;&#37327;&#21709;&#24212;&#30340;&#33021;&#21147;&#65292;&#24182;&#22312;&#24341;&#23548;LLMs&#29983;&#25104;&#39640;&#36136;&#37327;&#25552;&#31034;&#26041;&#38754;&#20855;&#26377;&#26174;&#33879;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.16929</link><description>&lt;p&gt;
LangGPT&#65306;&#37325;&#26032;&#24605;&#32771;&#38754;&#21521;LLMs&#30340;&#32467;&#26500;&#21270;&#21487;&#37325;&#22797;&#20351;&#29992;&#25552;&#31034;&#35774;&#35745;&#26694;&#26550;&#20174;&#32534;&#31243;&#35821;&#35328;&#20986;&#21457;
&lt;/p&gt;
&lt;p&gt;
LangGPT: Rethinking Structured Reusable Prompt Design Framework for LLMs from the Programming Language
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16929
&lt;/p&gt;
&lt;p&gt;
LangGPT&#25552;&#20986;&#20102;&#19968;&#20010;&#21452;&#23618;&#25552;&#31034;&#35774;&#35745;&#26694;&#26550;&#65292;&#20316;&#20026;LLMs&#30340;&#32534;&#31243;&#35821;&#35328;&#65292;&#22823;&#22823;&#22686;&#24378;&#20102;LLMs&#20135;&#29983;&#39640;&#36136;&#37327;&#21709;&#24212;&#30340;&#33021;&#21147;&#65292;&#24182;&#22312;&#24341;&#23548;LLMs&#29983;&#25104;&#39640;&#36136;&#37327;&#25552;&#31034;&#26041;&#38754;&#20855;&#26377;&#26174;&#33879;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
LLMs&#24050;&#32463;&#23637;&#31034;&#20986;&#22312;&#19981;&#21516;&#39046;&#22495;&#21462;&#24471;&#20102;&#20196;&#20154;&#30633;&#30446;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#20026;&#20102;&#26377;&#25928;&#25351;&#23548;LLMs&#21046;&#23450;&#39640;&#36136;&#37327;&#30340;&#25552;&#31034;&#23545;&#20110;&#38750;AI&#19987;&#23478;&#26469;&#35828;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;&#29616;&#26377;&#30340;&#25552;&#31034;&#24037;&#31243;&#30740;&#31350;&#24314;&#35758;&#20102;&#19968;&#20123;&#30053;&#26174;&#38646;&#30862;&#30340;&#20248;&#21270;&#21407;&#21017;&#21644;&#35774;&#35745;&#65292;&#20197;&#21450;&#20973;&#32463;&#39564;&#20381;&#36182;&#30340;&#25552;&#31034;&#20248;&#21270;&#22120;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#36825;&#20123;&#21162;&#21147;&#32570;&#20047;&#19968;&#20010;&#32467;&#26500;&#21270;&#30340;&#35774;&#35745;&#27169;&#26495;&#65292;&#23548;&#33268;&#23398;&#20064;&#25104;&#26412;&#39640;&#65292;&#37325;&#22797;&#20351;&#29992;&#24615;&#20302;&#12290;&#21463;&#32467;&#26500;&#21270;&#21487;&#37325;&#22797;&#20351;&#29992;&#30340;&#32534;&#31243;&#35821;&#35328;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;LangGPT&#65292;&#20316;&#20026;LLMs&#30340;&#32534;&#31243;&#35821;&#35328;&#30340;&#21452;&#23618;&#25552;&#31034;&#35774;&#35745;&#26694;&#26550;&#12290;LangGPT&#20855;&#26377;&#26131;&#20110;&#23398;&#20064;&#30340;&#35268;&#33539;&#32467;&#26500;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#25193;&#23637;&#32467;&#26500;&#20197;&#36827;&#34892;&#36801;&#31227;&#21644;&#37325;&#29992;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#19982;&#22522;&#20934;&#30456;&#27604;&#65292;LangGPT&#26174;&#33879;&#22686;&#24378;&#20102;LLMs&#20135;&#29983;&#39640;&#36136;&#37327;&#21709;&#24212;&#30340;&#33021;&#21147;&#12290;&#27492;&#22806;&#65292;LangGPT&#24050;&#34987;&#35777;&#26126;&#22312;&#24341;&#23548;LLMs&#29983;&#25104;&#39640;&#36136;&#37327;&#25552;&#31034;&#26041;&#38754;&#26159;&#26377;&#25928;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16929v1 Announce Type: cross  Abstract: LLMs have demonstrated commendable performance across diverse domains. Nevertheless, formulating high-quality prompts to effectively instruct LLMs poses a challenge for non-AI experts. Existing research in prompt engineering suggests somewhat fragmented optimization principles and designs empirically dependent prompt optimizers. Unfortunately, these endeavors lack a structured design template, incurring high learning costs and resulting in low reusability. Inspired by structured reusable programming languages, we propose LangGPT, a dual-layer prompt design framework as the programming language for LLMs. LangGPT has an easy-to-learn normative structure and provides an extended structure for migration and reuse. Experiments illustrate that LangGPT significantly enhances the capacity of LLMs to produce responses of superior quality compared to baselines. Moreover, LangGPT has proven effective in guiding LLMs to generate high-quality promp
&lt;/p&gt;</description></item></channel></rss>