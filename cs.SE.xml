<rss version="2.0"><channel><title>Chat Arxiv cs.SE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SE</description><item><title>&#20171;&#32461;&#20102; CodeUltraFeedback &#25968;&#25454;&#38598;&#65292;&#36890;&#36807; AI &#21453;&#39304;&#20351; 14 &#31181;&#19981;&#21516;&#30340; LLMs &#23545; 10,000 &#20010;&#22797;&#26434;&#25351;&#20196;&#29983;&#25104;&#21709;&#24212;&#65292;&#24182;&#20351;&#29992; LLM-as-a-Judge &#26041;&#27861;&#35780;&#20272;&#23427;&#20204;&#19982;&#20116;&#31181;&#32534;&#31243;&#20559;&#22909;&#30340;&#23545;&#40784;&#24773;&#20917;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#29992;&#20110;&#35780;&#20272; LLM &#23545;&#32534;&#31243;&#20559;&#22909;&#23545;&#40784;&#30340;&#22522;&#20934; CODAL-Bench&#12290;</title><link>https://arxiv.org/abs/2403.09032</link><description>&lt;p&gt;
CodeUltraFeedback&#65306;&#19968;&#31181;&#29992;&#20110;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#32534;&#31243;&#20559;&#22909;&#23545;&#40784;&#30340;LLM&#20316;&#20026;&#27861;&#23448;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
CodeUltraFeedback: An LLM-as-a-Judge Dataset for Aligning Large Language Models to Coding Preferences
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09032
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102; CodeUltraFeedback &#25968;&#25454;&#38598;&#65292;&#36890;&#36807; AI &#21453;&#39304;&#20351; 14 &#31181;&#19981;&#21516;&#30340; LLMs &#23545; 10,000 &#20010;&#22797;&#26434;&#25351;&#20196;&#29983;&#25104;&#21709;&#24212;&#65292;&#24182;&#20351;&#29992; LLM-as-a-Judge &#26041;&#27861;&#35780;&#20272;&#23427;&#20204;&#19982;&#20116;&#31181;&#32534;&#31243;&#20559;&#22909;&#30340;&#23545;&#40784;&#24773;&#20917;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#29992;&#20110;&#35780;&#20272; LLM &#23545;&#32534;&#31243;&#20559;&#22909;&#23545;&#40784;&#30340;&#22522;&#20934; CODAL-Bench&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#19982;&#29992;&#25143;&#23450;&#20041;&#30340;&#32534;&#31243;&#20559;&#22909;&#30340;&#23545;&#40784;&#24615;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24037;&#20316;&#65292;&#38656;&#35201;&#35780;&#20272;&#22797;&#26434;&#25991;&#26412;LLMs&#30340;&#36755;&#20986;&#12290;&#29616;&#26377;&#22522;&#20934;&#20208;&#36182;&#33258;&#21160;&#21270;&#25351;&#26631;&#21644;&#38745;&#24577;&#20998;&#26512;&#24037;&#20855;&#65292;&#26410;&#33021;&#35780;&#20272;&#29992;&#25143;&#25351;&#20196;&#21644;LLM&#36755;&#20986;&#20013;&#30340;&#24494;&#22937;&#20043;&#22788;&#65292;&#31361;&#26174;&#20102;&#23545;LLM&#20559;&#22909;&#23545;&#40784;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#21644;&#22522;&#20934;&#30340;&#38656;&#27714;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;CodeUltraFeedback&#65292;&#19968;&#20010;&#21253;&#21547;10,000&#20010;&#22797;&#26434;&#25351;&#20196;&#30340;&#20559;&#22909;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;AI&#21453;&#39304;&#26469;&#35843;&#25972;&#21644;&#23545;&#40784;LLMs&#19982;&#32534;&#31243;&#20559;&#22909;&#12290;&#25105;&#20204;&#20351;&#29992;14&#31181;&#19981;&#21516;&#30340;LLMs&#23545;&#36825;&#20123;&#25351;&#20196;&#29983;&#25104;&#21709;&#24212;&#65292;&#28982;&#21518;&#26681;&#25454;&#23427;&#20204;&#19982;&#20116;&#31181;&#32534;&#31243;&#20559;&#22909;&#30340;&#23545;&#40784;&#24773;&#20917;&#36827;&#34892;&#27880;&#37322;&#65292;&#20351;&#29992;GPT-3.5&#30340;LLM&#20316;&#20026;&#27861;&#23448;&#26041;&#27861;&#20135;&#29983;&#25968;&#23383;&#21644;&#25991;&#26412;&#21453;&#39304;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;CODAL-Bench&#65292;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;LLM&#19982;&#36825;&#20123;&#32534;&#31243;&#20559;&#22909;&#23545;&#40784;&#30340;&#22522;&#20934;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26174;&#31034;C
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09032v1 Announce Type: cross  Abstract: Evaluating the alignment of large language models (LLMs) with user-defined coding preferences is a challenging endeavour that requires assessing intricate textual LLMs' outputs. By relying on automated metrics and static analysis tools, existing benchmarks fail to assess nuances in user instructions and LLM outputs, highlighting the need for large-scale datasets and benchmarks for LLM preference alignment. In this paper, we introduce CodeUltraFeedback, a preference dataset of 10,000 complex instructions to tune and align LLMs to coding preferences through AI feedback. We generate responses to the instructions using a pool of 14 diverse LLMs, which we then annotate according to their alignment with five coding preferences using the LLM-as-a-Judge approach with GPT-3.5, producing both numerical and textual feedback. We also present CODAL-Bench, a benchmark for assessing LLM alignment with these coding preferences. Our results show that C
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#32034;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#36164;&#28304;&#26377;&#38480;&#30340;&#29615;&#22659;&#19979;&#29992;&#20110;&#20195;&#30721;&#29983;&#25104;&#30340;&#21442;&#25968;&#39640;&#25928;&#24494;&#35843;&#25216;&#26415;&#65292;&#24182;&#25552;&#20986;&#20102;&#21442;&#25968;&#39640;&#25928;&#24494;&#35843;&#20316;&#20026;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#20445;&#25345;&#21512;&#29702;&#36164;&#28304;&#28040;&#32791;&#30340;&#21516;&#26102;&#65292;&#39640;&#25928;&#22320;&#23558;&#35821;&#35328;&#27169;&#22411;&#19987;&#38376;&#29992;&#20110;&#20219;&#21153;&#29305;&#23450;&#30340;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2308.10462</link><description>&lt;p&gt;
&#25506;&#32034;&#22823;&#35821;&#35328;&#27169;&#22411;&#29992;&#20110;&#20195;&#30721;&#29983;&#25104;&#30340;&#21442;&#25968;&#39640;&#25928;&#24494;&#35843;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
Exploring Parameter-Efficient Fine-Tuning Techniques for Code Generation with Large Language Models. (arXiv:2308.10462v2 [cs.SE] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.10462
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#32034;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#36164;&#28304;&#26377;&#38480;&#30340;&#29615;&#22659;&#19979;&#29992;&#20110;&#20195;&#30721;&#29983;&#25104;&#30340;&#21442;&#25968;&#39640;&#25928;&#24494;&#35843;&#25216;&#26415;&#65292;&#24182;&#25552;&#20986;&#20102;&#21442;&#25968;&#39640;&#25928;&#24494;&#35843;&#20316;&#20026;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#20445;&#25345;&#21512;&#29702;&#36164;&#28304;&#28040;&#32791;&#30340;&#21516;&#26102;&#65292;&#39640;&#25928;&#22320;&#23558;&#35821;&#35328;&#27169;&#22411;&#19987;&#38376;&#29992;&#20110;&#20219;&#21153;&#29305;&#23450;&#30340;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#23637;&#31034;&#20102;&#22312;&#27809;&#26377;&#29305;&#23450;&#24494;&#35843;&#30340;&#24773;&#20917;&#19979;&#65292;&#21363;&#21487;&#26681;&#25454;&#33258;&#28982;&#35821;&#35328;&#24847;&#22270;&#29983;&#25104;&#20934;&#30830;&#30340;&#20195;&#30721;&#29255;&#27573;&#30340;&#21360;&#35937;&#33021;&#21147;&#12290;&#23613;&#31649;&#20808;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#31361;&#20986;&#20102;&#24494;&#35843;LLMs&#30340;&#20248;&#21183;&#65292;&#20294;&#36825;&#20010;&#36807;&#31243;&#20195;&#20215;&#39640;&#65292;&#23545;&#20110;&#25317;&#26377;&#25968;&#21313;&#20159;&#20010;&#21442;&#25968;&#30340;&#27169;&#22411;&#26469;&#35828;&#65292;&#22312;&#36164;&#28304;&#31232;&#32570;&#30340;&#29615;&#22659;&#19979;&#26159;&#19981;&#20999;&#23454;&#38469;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#20197;&#21069;&#30340;&#30740;&#31350;&#25506;&#32034;&#20102;&#22312;&#19978;&#19979;&#25991;&#23398;&#20064;&#65288;ICL&#65289;&#20316;&#20026;&#19968;&#31181;&#31574;&#30053;&#65292;&#29992;&#20219;&#21153;&#29305;&#23450;&#30340;&#25552;&#31034;&#31034;&#20363;&#25351;&#23548;LLM&#29983;&#25104;&#36807;&#31243;&#12290;&#28982;&#32780;&#65292;ICL&#24341;&#20837;&#20102;&#19968;&#20123;&#19981;&#20415;&#20043;&#22788;&#65292;&#27604;&#22914;&#38656;&#35201;&#35774;&#35745;&#19978;&#19979;&#25991;&#30456;&#20851;&#30340;&#25552;&#31034;&#21644;&#27809;&#26377;&#23398;&#20064;&#20219;&#21153;&#29305;&#23450;&#30340;&#21442;&#25968;&#65292;&#20174;&#32780;&#38480;&#21046;&#20102;&#19979;&#28216;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#39044;&#35265;&#21442;&#25968;&#39640;&#25928;&#24494;&#35843;&#65288;PEFT&#65289;&#25216;&#26415;&#20316;&#20026;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#20445;&#25345;&#21512;&#29702;&#36164;&#28304;&#28040;&#32791;&#30340;&#21516;&#26102;&#65292;&#39640;&#25928;&#22320;&#23558;LLM&#19987;&#38376;&#29992;&#20110;&#20219;&#21153;&#29305;&#23450;&#30340;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) demonstrate impressive capabilities to generate accurate code snippets given natural language intents in zero-shot, i.e., without the need for specific fine-tuning. While prior studies have highlighted the advantages of fine-tuning LLMs, this process incurs high computational costs, making it impractical in resource-scarce environments, particularly for models with billions of parameters. To address these challenges, previous research explored In-Context Learning (ICL) as a strategy to guide the LLM generative process with task-specific prompt examples. However, ICL introduces inconveniences, such as the need for designing contextually relevant prompts and the absence of learning task-specific parameters, thereby limiting downstream task performance. In this context, we foresee Parameter-Efficient Fine-Tuning (PEFT) techniques as a promising approach to efficiently specialize LLMs to task-specific data while maintaining reasonable resource consumption. In t
&lt;/p&gt;</description></item></channel></rss>