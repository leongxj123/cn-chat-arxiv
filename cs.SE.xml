<rss version="2.0"><channel><title>Chat Arxiv cs.SE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.SE</description><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#29983;&#25104;&#20195;&#30721;&#30340;&#36136;&#37327;&#21644;&#20449;&#20219;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#26657;&#20934;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#25506;&#35752;&#20102;&#22914;&#20309;&#30830;&#23450;&#27169;&#22411;&#29983;&#25104;&#20195;&#30721;&#30340;&#27491;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.02047</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#29983;&#25104;&#20195;&#30721;&#30340;&#36136;&#37327;&#21644;&#20449;&#20219;
&lt;/p&gt;
&lt;p&gt;
Quality and Trust in LLM-generated Code
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02047
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#29983;&#25104;&#20195;&#30721;&#30340;&#36136;&#37327;&#21644;&#20449;&#20219;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#26657;&#20934;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#25506;&#35752;&#20102;&#22914;&#20309;&#30830;&#23450;&#27169;&#22411;&#29983;&#25104;&#20195;&#30721;&#30340;&#27491;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#24191;&#27867;&#24212;&#29992;&#65292;&#20294;&#24120;&#24120;&#20250;&#20986;&#38169;&#12290;&#29992;&#25143;&#38656;&#35201;&#21487;&#38752;&#30340;&#25351;&#31034;&#65292;&#20197;&#30830;&#23450;&#32473;&#23450;&#27169;&#22411;&#30340;&#36755;&#20986;&#26159;&#21542;&#21487;&#20449;&#65292;&#20174;&#32780;&#21487;&#20197;&#20570;&#20986;&#29702;&#24615;&#20915;&#31574;&#26159;&#21542;&#20351;&#29992;&#35813;&#36755;&#20986;&#12290;&#20363;&#22914;&#65292;&#21487;&#20197;&#23558;&#36755;&#20986;&#19982;&#32622;&#20449;&#24230;&#30456;&#20851;&#32852;&#65307;&#22914;&#26524;&#32622;&#20449;&#24230;&#19982;&#27491;&#30830;&#24615;&#30340;&#21487;&#33021;&#24615;&#24378;&#30456;&#20851;&#65292;&#21017;&#31216;&#35813;&#27169;&#22411;&#20026;&#33391;&#22909;&#26657;&#20934;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#39640;&#32622;&#20449;&#24230;&#30340;&#36755;&#20986;&#21487;&#20197;&#23433;&#20840;&#25509;&#21463;&#65292;&#20302;&#32622;&#20449;&#24230;&#30340;&#36755;&#20986;&#21487;&#20197;&#25298;&#32477;&#12290;&#26657;&#20934;&#36804;&#20170;&#20027;&#35201;&#22312;&#38750;&#29983;&#25104;&#24615;&#65288;&#20363;&#22914;&#20998;&#31867;&#65289;&#29615;&#22659;&#20013;&#36827;&#34892;&#30740;&#31350;&#65292;&#29305;&#21035;&#26159;&#22312;&#36719;&#20214;&#24037;&#31243;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#29983;&#25104;&#20195;&#30721;&#24456;&#23481;&#26131;&#20986;&#38169;&#65306;&#24320;&#21457;&#20154;&#21592;&#38656;&#35201;&#30693;&#36947;&#20309;&#26102;&#30452;&#25509;&#20351;&#29992;&#12289;&#32463;&#36807;&#20180;&#32454;&#23457;&#26597;&#21518;&#20351;&#29992;&#25110;&#20002;&#24323;&#27169;&#22411;&#29983;&#25104;&#30340;&#20195;&#30721;&#65292;&#22240;&#27492;&#22312;&#29983;&#25104;&#29615;&#22659;&#20013;&#65292;&#26657;&#20934;&#38750;&#24120;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#29983;&#25104;&#20195;&#30721;&#30340;&#27491;&#30830;&#24615;&#27010;&#24565;&#24182;&#19981;&#31616;&#21333;&#65292;&#22240;&#27492;&#26657;&#20934;&#20063;&#26159;&#22914;&#27492;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning models are widely used but can also often be wrong. Users would benefit from a reliable indication of whether a given output from a given model should be trusted, so a rational decision can be made whether to use the output or not. For example, outputs can be associated with a confidence measure; if this confidence measure is strongly associated with likelihood of correctness, then the model is said to be well-calibrated. In this case, for example, high-confidence outputs could be safely accepted, and low-confidence outputs rejected.   Calibration has so far been studied in non-generative (e.g., classification) settings, especially in Software Engineering. However, generated code can quite often be wrong: Developers need to know when they should e.g., directly use, use after careful review, or discard model-generated code; thus Calibration is vital in generative settings. However, the notion of correctness of generated code is non-trivial, and thus so is Calibration. I
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#26088;&#22312;&#25506;&#32034;Copilot&#29983;&#25104;&#30340;Python&#20195;&#30721;&#20013;&#30340;&#20195;&#30721;&#24322;&#21619;&#65292;&#35780;&#20272;Copilot&#20462;&#22797;&#36825;&#20123;&#38382;&#39064;&#30340;&#33021;&#21147;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#26377;8&#31181;Python&#20195;&#30721;&#24322;&#21619;&#21487;&#20197;&#22312;Copilot&#29983;&#25104;&#30340;&#20195;&#30721;&#20013;&#26816;&#27979;&#21040;&#12290;</title><link>http://arxiv.org/abs/2401.14176</link><description>&lt;p&gt;
Copilot&#32454;&#21270;&#65306;&#35299;&#20915;Copilot&#29983;&#25104;&#30340;Python&#20195;&#30721;&#20013;&#30340;&#20195;&#30721;&#24322;&#21619;
&lt;/p&gt;
&lt;p&gt;
Copilot Refinement: Addressing Code Smells in Copilot-Generated Python Code. (arXiv:2401.14176v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14176
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#26088;&#22312;&#25506;&#32034;Copilot&#29983;&#25104;&#30340;Python&#20195;&#30721;&#20013;&#30340;&#20195;&#30721;&#24322;&#21619;&#65292;&#35780;&#20272;Copilot&#20462;&#22797;&#36825;&#20123;&#38382;&#39064;&#30340;&#33021;&#21147;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#26377;8&#31181;Python&#20195;&#30721;&#24322;&#21619;&#21487;&#20197;&#22312;Copilot&#29983;&#25104;&#30340;&#20195;&#30721;&#20013;&#26816;&#27979;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20316;&#20026;&#26368;&#27969;&#34892;&#30340;&#21160;&#24577;&#35821;&#35328;&#20043;&#19968;&#65292;Python&#22312;&#23384;&#22312;&#20195;&#30721;&#24322;&#21619;&#26102;&#21487;&#35835;&#24615;&#21644;&#21487;&#32500;&#25252;&#24615;&#20250;&#19979;&#38477;&#12290;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26368;&#26032;&#36827;&#23637;&#24341;&#21457;&#20102;&#23545;AI&#25903;&#25345;&#30340;&#20195;&#30721;&#29983;&#25104;&#21644;&#37325;&#26500;&#24037;&#20855;&#30340;&#26085;&#30410;&#20851;&#27880;&#12290;GitHub Copilot&#26159;&#20854;&#20013;&#19968;&#31181;&#34987;&#24191;&#27867;&#20351;&#29992;&#30340;&#24037;&#20855;&#12290;Copilot Chat&#26159;&#22312;2023&#24180;9&#26376;&#21457;&#24067;&#30340;&#19968;&#31181;&#20132;&#20114;&#24335;&#24037;&#20855;&#65292;&#26088;&#22312;&#20026;&#33258;&#28982;&#35821;&#35328;&#39537;&#21160;&#30340;&#32534;&#30721;&#25552;&#20379;&#20415;&#21033;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#29702;&#35299;Copilot&#29983;&#25104;&#30340;Python&#20195;&#30721;&#20013;&#30340;&#20195;&#30721;&#24322;&#21619;&#20197;&#21450;Copilot&#20462;&#22797;&#20854;&#29983;&#25104;&#30340;&#20195;&#30721;&#24322;&#21619;&#30340;&#33021;&#21147;&#65292;&#20154;&#20204;&#24182;&#27809;&#26377;&#32473;&#20104;&#36275;&#22815;&#30340;&#20851;&#27880;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#21253;&#21547;102&#20010;Copilot&#29983;&#25104;&#30340;Python&#20195;&#30721;&#20013;&#30340;&#20195;&#30721;&#24322;&#21619;&#30340;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#39318;&#20808;&#25506;&#32034;Copilot&#29983;&#25104;&#30340;Python&#20195;&#30721;&#20013;&#20195;&#30721;&#24322;&#21619;&#30340;&#21457;&#29983;&#24773;&#20917;&#65292;&#28982;&#21518;&#35780;&#20272;Copilot&#22312;&#20351;&#29992;&#19981;&#21516;&#25552;&#31034;&#20462;&#22797;&#36825;&#20123;&#20195;&#30721;&#24322;&#21619;&#26102;&#30340;&#26377;&#25928;&#24615;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;10&#31181;Python&#20195;&#30721;&#24322;&#21619;&#20013;&#26377;8&#31181;&#21487;&#20197;&#22312;Copilot&#29983;&#25104;&#30340;&#20195;&#30721;&#20013;&#26816;&#27979;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
As one of the most popular dynamic languages, Python experiences a decrease in readability and maintainability when code smells are present. Recent advancements in Large Language Models have sparked growing interest in AI-enabled tools for both code generation and refactoring. GitHub Copilot is one such tool that has gained widespread usage. Copilot Chat, released on September 2023, functions as an interactive tool aims at facilitating natural language-powered coding. However, limited attention has been given to understanding code smells in Copilot-generated Python code and Copilot's ability to fix the code smells it generates. To this end, we built a dataset comprising 102 code smells in Copilot-generated Python code. Our aim is to first explore the occurrence of code smells in Copilot-generated Python code and then evaluate the effectiveness of Copilot in fixing these code smells employing different prompts. The results show that 8 out of 10 types of Python smells can be detected in 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#39044;&#35757;&#32451;&#20108;&#36827;&#21046;&#20195;&#30721;&#34920;&#31034;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#23558;&#28304;&#20195;&#30721;&#21644;&#27880;&#37322;&#20449;&#24687;&#32435;&#20837;&#20108;&#36827;&#21046;&#20195;&#30721;&#30340;&#34920;&#31034;&#23398;&#20064;&#20013;&#65292;&#23545;&#20110;&#21453;&#21521;&#24037;&#31243;&#21644;&#35745;&#31639;&#26426;&#23433;&#20840;&#20219;&#21153;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2210.05102</link><description>&lt;p&gt;
&#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#39044;&#35757;&#32451;&#20108;&#36827;&#21046;&#20195;&#30721;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Pre-Training Representations of Binary Code Using Contrastive Learning. (arXiv:2210.05102v2 [cs.SE] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.05102
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#39044;&#35757;&#32451;&#20108;&#36827;&#21046;&#20195;&#30721;&#34920;&#31034;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#23558;&#28304;&#20195;&#30721;&#21644;&#27880;&#37322;&#20449;&#24687;&#32435;&#20837;&#20108;&#36827;&#21046;&#20195;&#30721;&#30340;&#34920;&#31034;&#23398;&#20064;&#20013;&#65292;&#23545;&#20110;&#21453;&#21521;&#24037;&#31243;&#21644;&#35745;&#31639;&#26426;&#23433;&#20840;&#20219;&#21153;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32534;&#35793;&#21518;&#30340;&#36719;&#20214;&#20197;&#21487;&#25191;&#34892;&#30340;&#20108;&#36827;&#21046;&#20195;&#30721;&#24418;&#24335;&#20132;&#20184;&#12290;&#24320;&#21457;&#20154;&#21592;&#32534;&#20889;&#28304;&#20195;&#30721;&#26469;&#34920;&#36798;&#36719;&#20214;&#30340;&#35821;&#20041;&#65292;&#20294;&#32534;&#35793;&#22120;&#23558;&#20854;&#36716;&#25442;&#20026;CPU&#21487;&#20197;&#30452;&#25509;&#25191;&#34892;&#30340;&#20108;&#36827;&#21046;&#26684;&#24335;&#12290;&#22240;&#27492;&#65292;&#20108;&#36827;&#21046;&#20195;&#30721;&#20998;&#26512;&#23545;&#20110;&#21453;&#21521;&#24037;&#31243;&#21644;&#35745;&#31639;&#26426;&#23433;&#20840;&#20219;&#21153;&#31561;&#27809;&#26377;&#28304;&#20195;&#30721;&#30340;&#24212;&#29992;&#31243;&#24207;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#19982;&#21253;&#21547;&#20016;&#23500;&#35821;&#20041;&#20449;&#24687;&#30340;&#28304;&#20195;&#30721;&#21644;&#33258;&#28982;&#35821;&#35328;&#19981;&#21516;&#65292;&#20108;&#36827;&#21046;&#20195;&#30721;&#36890;&#24120;&#38590;&#20197;&#29702;&#35299;&#21644;&#20998;&#26512;&#12290;&#34429;&#28982;&#29616;&#26377;&#30340;&#24037;&#20316;&#20351;&#29992;AI&#27169;&#22411;&#36741;&#21161;&#28304;&#20195;&#30721;&#20998;&#26512;&#65292;&#20294;&#24456;&#23569;&#26377;&#30740;&#31350;&#32771;&#34385;&#20108;&#36827;&#21046;&#20195;&#30721;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#28304;&#20195;&#30721;&#21644;&#27880;&#37322;&#20449;&#24687;&#32435;&#20837;&#20108;&#36827;&#21046;&#20195;&#30721;&#36827;&#34892;&#34920;&#31034;&#23398;&#20064;&#30340;&#23545;&#27604;&#23398;&#20064;&#27169;&#22411;&#65292;&#31216;&#20026;COMBO&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#22312;COMBO&#20013;&#25552;&#20986;&#20102;&#19977;&#20010;&#32452;&#20214;&#65306;&#65288;1&#65289;&#29992;&#20110;&#20919;&#21551;&#21160;&#39044;&#35757;&#32451;&#30340;&#20027;&#35201;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#65292;&#65288;2&#65289;&#29992;&#20110;&#23558;&#28304;&#20195;&#30721;&#21644;&#27880;&#37322;&#20449;&#24687;&#25554;&#20837;&#21040;&#20108;&#36827;&#21046;&#20195;&#30721;&#20013;&#30340;&#21333;&#32431;&#25554;&#20540;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Compiled software is delivered as executable binary code. Developers write source code to express the software semantics, but the compiler converts it to a binary format that the CPU can directly execute. Therefore, binary code analysis is critical to applications in reverse engineering and computer security tasks where source code is not available. However, unlike source code and natural language that contain rich semantic information, binary code is typically difficult for human engineers to understand and analyze. While existing work uses AI models to assist source code analysis, few studies have considered binary code. In this paper, we propose a COntrastive learning Model for Binary cOde Analysis, or COMBO, that incorporates source code and comment information into binary code during representation learning. Specifically, we present three components in COMBO: (1) a primary contrastive learning method for cold-start pre-training, (2) a simplex interpolation method to incorporate so
&lt;/p&gt;</description></item></channel></rss>