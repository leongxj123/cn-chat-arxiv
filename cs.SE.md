# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Bias Assessment and Mitigation in LLM-based Code Generation.](http://arxiv.org/abs/2309.14345) | 这项研究提出了一个新颖的偏差评估框架，针对代码生成任务进行设计。通过对九个最先进的基于LLM的代码生成模型进行广泛评估，发现其中31.45\%到79.93\%的代码函数具有偏见，并提出了如何缓解这种偏见的方法。 |

# 详细

[^1]: 基于LLM的代码生成中的偏差评估与缓解

    Bias Assessment and Mitigation in LLM-based Code Generation. (arXiv:2309.14345v1 [cs.SE])

    [http://arxiv.org/abs/2309.14345](http://arxiv.org/abs/2309.14345)

    这项研究提出了一个新颖的偏差评估框架，针对代码生成任务进行设计。通过对九个最先进的基于LLM的代码生成模型进行广泛评估，发现其中31.45\%到79.93\%的代码函数具有偏见，并提出了如何缓解这种偏见的方法。

    

    利用最新的大型语言模型（LLM），自动代码生成模型在提高软件开发编码过程的生产力和效率方面起着至关重要的作用。随着LLM在软件编码生态系统中的普及，一个紧迫的问题已经出现：生成的代码是否包含与年龄、性别和种族相关的社会偏见？这个问题关系到依赖于这些模型生成的代码的软件应用的完整性、公平性和道德基础，然而在文献中还没有得到充分探讨。本文提出了一个专为代码生成任务设计的新颖偏差评估框架。基于该框架，我们对九个最先进的基于LLM的代码生成模型的偏差进行了广泛评估。我们的发现揭示了，首先，我们评估的代码生成模型生成的31.45\%到79.93\%的代码函数具有偏见，9.68\%到37.37\%的代码函数的功能使

    Utilizing state-of-the-art Large Language Models (LLMs), automatic code generation models play a pivotal role in enhancing the productivity and efficiency of software development coding procedures. As the adoption of LLMs becomes more widespread in software coding ecosystems, a pressing issue has emerged: does the generated code contain social biases, such as those related to age, gender, and race? This issue concerns the integrity, fairness, and ethical foundation of software applications that depend on the code generated by these models, yet is under-explored in the literature. This paper presents a novel bias assessment framework that is specifically designed for code generation tasks. Based on this framework, we conduct an extensive evaluation on the bias of nine state-of-the-art LLM-based code generation models. Our findings reveal that first, 31.45\% to 79.93\% code functions generated by our evaluated code generation models are biased, and 9.68\% to 37.37\% code functions' funct
    

