# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Navigating Fairness: Practitioners' Understanding, Challenges, and Strategies in AI/ML Development](https://arxiv.org/abs/2403.15481) | AI从业者对于公平AI/ML的理解、面临的挑战、不公平AI/ML的后果以及确保AI/ML公平性的策略。 |
| [^2] | [A Study of Fairness Concerns in AI-based Mobile App Reviews](https://arxiv.org/abs/2401.08097) | 本文研究了AI基于移动应用评价中的公平关注，并通过构建数据集和开发分类器的方法，成功检测出公平性评论，并识别出约92000条公平性评论。 |

# 详细

[^1]: AI/ML 发展中的公平导航: 从业者对AI/ML开发中的理解、挑战和策略

    Navigating Fairness: Practitioners' Understanding, Challenges, and Strategies in AI/ML Development

    [https://arxiv.org/abs/2403.15481](https://arxiv.org/abs/2403.15481)

    AI从业者对于公平AI/ML的理解、面临的挑战、不公平AI/ML的后果以及确保AI/ML公平性的策略。

    

    近年来，各行业对AI/ML应用的增加引发了对AI/ML公平性的更多讨论。虽然已有关于AI/ML公平性的先前研究，但缺乏针对了解AI从业者在开发公平AI/ML过程中的观点和经验的实证研究。了解AI从业者对AI/ML公平性的看法和经验很重要，因为他们直接参与其中的开发和部署，他们的见解可以提供有价值的现实世界视角，帮助理解确保AI/ML公平性所涉及挑战的重要性。我们进行了22位AI从业者的半结构化访谈，以调查他们对“公平AI/ML”是什么的理解，他们在开发公平AI/ML中面临的挑战，开发不公平AI/ML的后果，以及他们采取的策略来确保AI/ML的公平性。我们制定了一个框架展示了

    arXiv:2403.15481v1 Announce Type: cross  Abstract: The rise in the use of AI/ML applications across industries has sparked more discussions about the fairness of AI/ML in recent times. While prior research on the fairness of AI/ML exists, there is a lack of empirical studies focused on understanding the views and experiences of AI practitioners in developing a fair AI/ML. Understanding AI practitioners' views and experiences on the fairness of AI/ML is important because they are directly involved in its development and deployment and their insights can offer valuable real-world perspectives on the challenges associated with ensuring fairness in AI/ML. We conducted semi-structured interviews with 22 AI practitioners to investigate their understanding of what a 'fair AI/ML' is, the challenges they face in developing a fair AI/ML, the consequences of developing an unfair AI/ML, and the strategies they employ to ensure AI/ML fairness. We developed a framework showcasing the relationship be
    
[^2]: AI基于移动应用评价的公平关注研究

    A Study of Fairness Concerns in AI-based Mobile App Reviews

    [https://arxiv.org/abs/2401.08097](https://arxiv.org/abs/2401.08097)

    本文研究了AI基于移动应用评价中的公平关注，并通过构建数据集和开发分类器的方法，成功检测出公平性评论，并识别出约92000条公平性评论。

    

    公平是AI系统中必须解决的社会技术问题之一。不公平的AI系统，特别是不公平的AI基于移动应用，可能给全球很大一部分人口带来困难。本文旨在分析AI基于应用评价中的公平问题。我们首先手动构建了一个基准数据集，包括公平性和非公平性评论的统计样本。利用这个基准数据集，我们开发和评估了一组机器学习和深度学习分类器，用于区分公平性评论和非公平性评论。我们的实验结果显示，我们最佳的分类器可以以94%的精确度检测到公平性评论。然后，我们将最佳分类器应用于从108个AI基于应用收集的约950万条评论，识别出约92000条公平性评论。接下来，我们将K-means聚类技术应用于这92000条公平性评论。

    arXiv:2401.08097v2 Announce Type: replace-cross Abstract: Fairness is one of the socio-technical concerns that must be addressed in AI-based systems. Unfair AI-based systems, particularly unfair AI-based mobile apps, can pose difficulties for a significant proportion of the global population. This paper aims to analyze fairness concerns in AI-based app reviews.We first manually constructed a ground-truth dataset, including a statistical sample of fairness and non-fairness reviews. Leveraging the ground-truth dataset, we developed and evaluated a set of machine learning and deep learning classifiers that distinguish fairness reviews from non-fairness reviews. Our experiments show that our best-performing classifier can detect fairness reviews with a precision of 94%. We then applied the best-performing classifier on approximately 9.5M reviews collected from 108 AI-based apps and identified around 92K fairness reviews. Next, applying the K-means clustering technique to the 92K fairness r
    

