# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Equilibria in Repeated Games under No-Regret with Dynamic Benchmarks.](http://arxiv.org/abs/2212.03152) | 该论文研究了在重复博弈中，采用无悔性策略的玩家创造的联合经验分布的一致性，并提出了一种动态基准一致策略，该策略在允许的行动变化次数有限的情况下保证了最佳动态行动序列的表现。在时间足够长时，所有玩家采用该策略后将出现相同的经验分布。 |

# 详细

[^1]: 在无懊悔策略下的重复博弈中的均衡

    Equilibria in Repeated Games under No-Regret with Dynamic Benchmarks. (arXiv:2212.03152v2 [cs.GT] UPDATED)

    [http://arxiv.org/abs/2212.03152](http://arxiv.org/abs/2212.03152)

    该论文研究了在重复博弈中，采用无悔性策略的玩家创造的联合经验分布的一致性，并提出了一种动态基准一致策略，该策略在允许的行动变化次数有限的情况下保证了最佳动态行动序列的表现。在时间足够长时，所有玩家采用该策略后将出现相同的经验分布。

    

    在重复博弈中，策略通常通过它们能否保证事后选择的最佳行动的表现来进行评估，这被称为Hannan一致性或无悔性。然而，单个最佳行动作为评估策略的基准的有效性是有限的，因为在常见的动态环境中，任何静态行动可能表现不佳。因此，我们的工作转向了更为宏大的“动态基准一致性”概念，它保证了选择事后的最佳“动态”行动序列的表现，同时对允许的行动变化次数有限制。我们的主要结果表明，对于所有玩家都采用无悔策略可能出现的任何联合经验分布，存在动态基准一致策略，如果所有玩家都采用这些策略，当时间足够长时，将出现相同的经验分布。

    In repeated games, strategies are often evaluated by their ability to guarantee the performance of the single best action that is selected in hindsight, a property referred to as \emph{Hannan consistency}, or \emph{no-regret}. However, the effectiveness of the single best action as a yardstick to evaluate strategies is limited, as any static action may perform poorly in common dynamic settings. Our work therefore turns to a more ambitious notion of \emph{dynamic benchmark consistency}, which guarantees the performance of the best \emph{dynamic} sequence of actions, selected in hindsight subject to a constraint on the allowable number of action changes. Our main result establishes that for any joint empirical distribution of play that may arise when all players deploy no-regret strategies, there exist dynamic benchmark consistent strategies such that if all players deploy these strategies the same empirical distribution emerges when the horizon is large enough. This result demonstrates 
    

